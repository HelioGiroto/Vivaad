Cuban missile crisis
The Cuban missile crisis—known as the October crisis in Cuba and the Caribbean crisis (, tr. "Karibskiy krizis") in the USSR—was a 13-day confrontation between the Soviet Union and Cuba on one side, and the United States on the other, in October 1962. It is one of the major confrontations of the Cold War, and is generally regarded as the moment in which the Cold War came closest to turning into a nuclear conflict. It is also the first documented instance of the threat of mutual assured destruction (MAD) being discussed as a determining factor in a major international arms agreement.
After provocative political moves and the failed US attempt to overthrow the Cuban regime (Bay of Pigs, Operation Mongoose), in May 1962 Nikita Khrushchev proposed the idea of placing Soviet nuclear missiles on Cuba to deter any future invasion attempt. During a meeting between Khrushchev and Raúl Castro that July, a secret agreement was reached and construction of several missile sites began in the late summer. These preparations were noticed, and on 14 October a US U-2 aircraft took several pictures clearly showing sites for medium-range and intermediate-range ballistic nuclear missiles (MRBMs and IRBMs) under construction. These images were processed and presented on October 15, which marks the beginning of the 13-day crisis from the US perspective.
The United States considered attacking Cuba via air and sea, but decided on a military blockade instead, calling it a "quarantine" for legal and other reasons. The US announced that it would not permit offensive weapons to be delivered to Cuba, demanded that the Soviets dismantle the missile bases already under construction or completed, and return all offensive weapons to the USSR. The Kennedy administration held only a slim hope that the Kremlin would agree to their demands, and expected a military confrontation.
On the Soviet side, Premier Nikita Khrushchev wrote in a letter from October 24, 1962 to President John F. Kennedy that his blockade of "navigation in international waters and air space" constituted "an act of aggression propelling humankind into the abyss of a world nuclear-missile war". However, in secret back-channel communications the President and Premier initiated a proposal to resolve the crisis. While this was taking place, several Soviet ships attempted to run the blockade, increasing tensions to the point that orders were sent out to US Navy ships to fire warning shots and then open fire. On 27 October a U-2 was shot down by a Soviet missile crew, an action that could have resulted in immediate retaliation from the Kennedy crisis cabinet, according to Secretary of Defense McNamara's later testimony. However, in the event itself, Kennedy stayed his hand and the negotiations continued.
The confrontation ended on October 28, 1962, when Kennedy and United Nations Secretary-General U Thant reached an agreement with Khrushchev. Publicly, the Soviets would dismantle their offensive weapons in Cuba and return them to the Soviet Union, subject to United Nations verification, in exchange for a US public declaration and agreement never to invade Cuba. Secretly, the US agreed that it would dismantle all US-built Jupiter IRBMs deployed in Turkey and Italy.
After the removal of the missiles and Ilyushin Il-28 light bombers, the blockade was formally ended at 6:45 pm EDT on November 20, 1962. An additional outcome of the negotiations was the creation of the Moscow–Washington hotline, a direct communications link between Moscow and Washington, D.C.
Earlier actions by the United States.
The United States was concerned about the Soviet expansion of Communism, but for a Latin American country to ally openly with the USSR was regarded as unacceptable, given the US-Soviet enmity since the end of World War II in 1945. Such an involvement would also directly defy the Monroe Doctrine; a United States policy which, while limiting the United States' involvement with European colonies and European affairs, held that European powers ought not to have involvement with states in the Western Hemisphere.
The United States had been embarrassed publicly by the failed Bay of Pigs Invasion in April 1961, which had been launched under President John F. Kennedy by CIA-trained forces of Cuban exiles. Afterward, former President Eisenhower told Kennedy that "the failure of the Bay of Pigs will embolden the Soviets to do something that they would otherwise not do." The half-hearted invasion left Soviet premier Nikita Khrushchev and his advisers with the impression that Kennedy was indecisive and, as one Soviet adviser wrote, "too young, intellectual, not prepared well for decision making in crisis situations ... too intelligent and too weak." US covert operations continued in 1961 with the unsuccessful Operation Mongoose.
In addition, Khrushchev’s impression of Kennedy’s weakness was confirmed by the President’s soft response during the Berlin Crisis of 1961, particularly the building of the Berlin Wall. Speaking to Soviet officials in the aftermath of the crisis, Khrushchev asserted, "I know for certain that Kennedy doesn’t have a strong background, nor, generally speaking, does he have the courage to stand up to a serious challenge." He also told his son Sergei that on Cuba, Kennedy "would make a fuss, make more of a fuss, and then agree".
In January 1962, General Edward Lansdale described plans to overthrow the Cuban Government in a top-secret report (partially declassified 1989), addressed to President Kennedy and officials involved with Operation Mongoose. CIA agents or "pathfinders" from the Special Activities Division were to be infiltrated into Cuba to carry out sabotage and organization, including radio broadcasts. In February 1962, the United States launched an embargo against Cuba, and Lansdale presented a 26-page, top-secret timetable for implementation of the overthrow of the Cuban Government, mandating that guerrilla operations begin in August and September, and in the first two weeks of October: "Open revolt and overthrow of the Communist regime".
Balance of power.
When Kennedy ran for president in 1960, one of his key election issues was an alleged "missile gap", with the Soviets leading. In fact, the United States led the Soviets. In 1961, the Soviets had only four intercontinental ballistic missiles (ICBMs). By October 1962, they may have had a few dozen, although some intelligence estimates were as high as 75.
The United States, on the other hand, had 170 ICBMs and was quickly building more. It also had eight George Washington and Ethan Allen class ballistic missile submarines with the capability to launch 16 Polaris missiles each, with a range of .
Khrushchev increased the perception of a missile gap when he loudly boasted to the world that the USSR was building missiles "like sausages" whose numbers and capabilities actually were nowhere close to his assertions. The Soviet Union did have medium-range ballistic missiles in quantity, about 700 of them, however, these were very unreliable and inaccurate. Overall, the United States had a very considerable advantage in total number of nuclear warheads (27,000 against 3,600) at the time and, more importantly, in all the technologies needed to deliver them accurately.
The United States also led in missile defensive capabilities, Naval and Air power; but the USSR enjoyed a two-to-one advantage in conventional ground forces, more pronounced in field guns and tanks.
Soviet deployment of missiles in Cuba.
In May 1962, Soviet Premier Nikita Khrushchev was persuaded by the idea of countering the United States' growing lead in developing and deploying strategic missiles by placing Soviet intermediate-range nuclear missiles in Cuba. He faced a strategic situation where the U.S. was perceived to have a “splendid first strike” capability against the Soviet Union. In 1962, the Soviets had only 20 ICBMs capable of delivering nuclear warheads to the United States from inside the Soviet Union. The poor accuracy and reliability of these missiles raised serious doubts about their effectiveness. A newer, more reliable generation of ICBMs would only become operational after 1965. Therefore, Soviet nuclear capability in 1962 placed less emphasis on ICBMs than on medium and intermediate-range ballistic missiles (MRBMs and IRBMs). These missiles could hit American allies from Soviet territory and most of Alaska, but not the contiguous 48 States (of the United States). Graham Allison, the director of Harvard University’s Belfer Center for Science and International Affairs, points out, “The Soviet Union could right the nuclear imbalance by deploying new ICBMs on its own soil. But to meet the threat it faced in 1962, 1963, and 1964, it had very few options. Moving existing nuclear weapons to locations from which they could reach American targets was one.”
A second reason Soviet missiles were deployed to Cuba was because Khrushchev wanted to bring West Berlin—the American/British/French-controlled democratic zone within Communist East Germany—into the Soviet orbit. The East Germans and Soviets considered western control over a portion of Berlin a grave threat to East Germany. For this reason, among others, Khrushchev made West Berlin the central battlefield of the Cold War. Khrushchev believed that if the Americans did nothing over the missile deployments in Cuba, he could muscle the West out of Berlin using said missiles as a deterrent to western counter-measures in Berlin. If the Americans tried to bargain with the Soviets after becoming aware of the missiles, Khrushchev could demand trading the missiles for West Berlin. Since Berlin was strategically more important than Cuba, the trade would be a win for Khrushchev. President Kennedy recognized this: “The advantage is, from Khrushchev’s point of view, he takes a great chance but there are quite some rewards to it.”
Finally, Khrushchev was also reacting in part to the Jupiter intermediate-range ballistic missiles which the United States had installed in Turkey during April 1962.
From the very beginning, the Soviets' operation entailed elaborate denial and deception, known in the USSR as "Maskirovka". All of the planning and preparation for transporting and deploying the missiles were carried out in the utmost secrecy, with only a very few told the exact nature of the mission. Even the troops detailed for the mission were given misdirection, told they were headed for a cold region and outfitted with ski boots, fleece-lined parkas, and other winter equipment. The Soviet code name, Operation Anadyr, was also the name of a river flowing into the Bering Sea, the name of the capital of Chukotsky District, and a bomber base in the far eastern region. All these were meant to conceal the program from both internal and external audiences.
In early 1962, a group of Soviet military and missile construction specialists accompanied an agricultural delegation to Havana. They obtained a meeting with Cuban leader Fidel Castro. The Cuban leadership had a strong expectation that the US would invade Cuba again and they enthusiastically approved the idea of installing nuclear missiles in Cuba. However, according to another source, Fidel Castro objected to the missiles deployment that would have made him look like a Soviet puppet, but was persuaded that missiles in Cuba would be in the interests of the entire socialist camp.
Specialists in missile construction under the guise of "machine operators", "irrigation specialists" and "agricultural specialists" arrived in July. Marshal Sergei Biryuzov, chief of the Soviet Rocket Forces, led a survey team that visited Cuba. He told Khrushchev that the missiles would be concealed and camouflaged by the palm trees.
The Cuban leadership was further upset when in September the United States Congress approved US Joint Resolution 230, which expressed Congress's resolve to prevent the creation of an externally supported military establishment. On the same day, the US announced a major military exercise in the Caribbean, PHIBRIGLEX-62, which Cuba denounced as a deliberate provocation and proof that the US planned to invade Cuba.
Khrushchev and Castro agreed to place strategic nuclear missiles secretly in Cuba. Like Castro, Khrushchev felt that a US invasion of Cuba was imminent, and that to lose Cuba would do great harm to the communist cause, especially in Latin America. He said he wanted to confront the Americans "with more than words... the logical answer was missiles". The Soviets maintained their tight secrecy, writing their plans longhand, which were approved by Rodion Malinovsky on July 4 and Khrushchev on July 7.
The Soviet leadership believed, based on their perception of Kennedy's lack of confidence during the Bay of Pigs Invasion, that he would avoid confrontation and accept the missiles as a "fait accompli". On September 11, the Soviet Union publicly warned that a US attack on Cuba or on Soviet ships carrying supplies to the island would mean war. The Soviets continued their "Maskirovka" program to conceal their actions in Cuba. They repeatedly denied that the weapons being brought into Cuba were offensive in nature. On September 7, Soviet Ambassador to the United States Anatoly Dobrynin assured United States Ambassador to the United Nations Adlai Stevenson that the USSR was supplying only defensive weapons to Cuba. On September 11, the Telegrafnoe Agentstvo Sovetskogo Soyuza (Soviet News Agency TASS) announced that the Soviet Union had no need or intention to introduce offensive nuclear missiles into Cuba. On October 13, Dobrynin was questioned by former Undersecretary of State Chester Bowles about whether the Soviets plan to put offensive weapons in Cuba. He denied any such plans. And again on October 17, Soviet embassy official Georgy Bolshakov brought President Kennedy a "personal message" from Khrushchev reassuring him that "under no circumstances would surface-to-surface missiles be sent to Cuba."
As early as August 1962, the United States suspected the Soviets of building missile facilities in Cuba. During that month, its intelligence services gathered information about sightings by ground observers of Russian-built MiG-21 fighters and Il-28 light bombers. U-2 spyplanes found S-75 Dvina (NATO designation "SA-2") surface-to-air missile sites at eight different locations. CIA director John A. McCone was suspicious. Sending antiaircraft missiles into Cuba, he reasoned, “made sense only if Moscow intended to use them to shield a base for ballistic missiles aimed at the United States.” On August 10, he wrote a memo to President Kennedy in which he guessed that the Soviets were preparing to introduce ballistic missiles into Cuba. On August 31, Senator Kenneth Keating (R-New York), who probably received his information from Cuban exiles in Florida, warned on the Senate floor that the Soviet Union may be constructing a missile base in Cuba.
Air Force General Curtis LeMay presented a pre-invasion bombing plan to Kennedy in September, while spy flights and minor military harassment from US forces at Guantanamo Bay Naval Base were the subject of continual Cuban diplomatic complaints to the US government.
The first consignment of R-12 missiles arrived on the night of September 8, followed by a second on September 16. The R-12 was an intermediate-range ballistic missile, capable of carrying a thermonuclear warhead. It was a single-stage, road-transportable, surface-launched, storable liquid propellant fueled missile that could deliver a megaton-class nuclear weapon. The Soviets were building nine sites—six for R-12 medium-range missiles (NATO designation "SS-4 Sandal") with an effective range of and three for R-14 intermediate-range ballistic missiles (NATO designation "SS-5 Skean") with a maximum range of .
Cuba positioning.
On October 7, Cuban President Osvaldo Dorticós spoke at the UN General Assembly: "If ... we are attacked, we will defend ourselves. I repeat, we have sufficient means with which to defend ourselves; we have indeed our inevitable weapons, the weapons, which we would have preferred not to acquire, and which we do not wish to employ."
Missiles reported.
The missiles in Cuba allowed the Soviets to effectively target almost the entire continental United States. The planned arsenal was forty launchers. The Cuban populace readily noticed the arrival and deployment of the missiles and hundreds of reports reached Miami. US intelligence received countless reports, many of dubious quality or even laughable, and most of which could be dismissed as describing defensive missiles. Only five reports bothered the analysts. They described large trucks passing through towns at night carrying very long canvas-covered cylindrical objects that could not make turns through towns without backing up and maneuvering. Defensive missiles could make these turns. These reports could not be satisfactorily dismissed.
Corona satellite and U-2 flights find missiles.
Despite the increasing evidence of a military build-up on Cuba, no U-2 flights were made over Cuba from September 5 until October 14. The first problem that caused the pause in reconnaissance flights took place on August 30, an Air Force Strategic Air Command (SAC) U-2 flew over Sakhalin Island in the Far East by mistake. The Soviets lodged a protest and the US apologized. Nine days later, a Taiwanese-operated U-2 was lost over western China, probably to a SAM. US officials were worried that one of the Cuban or Soviet SAMs in Cuba might shoot down a CIA U-2, initiating another international incident. Therefore, the Kennedy administration decided to try the new Corona (satellite) KH series in an attempt to obtain sufficient evidence. Preparations for an emergency launch proceeded at fever pitch and led to the NRO's institution of "R7" status, that is, keeping a Corona spy satellite ready for launch on 7 days' notice in case of an emergency. At the end of September, Navy reconnaissance aircraft photographed the Soviet ship "Kasimov" with large crates on its deck the size and shape of Il-28 light bombers.
With evidence in hand from both the Corona satellite and Navy Reconnaissance aircraft, at the beginning of October the administration decided it was now worth risking U-2 flights over Cuba. They decided to transfer the Cuban U-2 reconnaissance missions to the Air Force; if another U-2 was shot down, they thought a cover story involving Air Force flights would be easier to explain than CIA flights. There was also some evidence that the Department of Defense and the Air Force lobbied to get responsibility for the Cuban flights. When the reconnaissance missions were re-authorized on October 8, weather kept the planes from flying. The US first obtained U-2 photographic evidence of the missiles on October 14, when a U-2 flight piloted by Major Richard Heyser took 928 pictures, capturing images of what turned out to be an SS-4 construction site at San Cristóbal, Pinar del Río Province, in western Cuba.
President notified.
On October 15, the CIA's National Photographic Interpretation Center reviewed the U-2 photographs and identified objects that they interpreted as medium range ballistic missiles. That evening, the CIA notified the Department of State and at 8:30 pm EDT, National Security Adviser McGeorge Bundy elected to wait until morning to tell the President. Secretary of Defense Robert McNamara was briefed at midnight. The next morning, Bundy met with Kennedy and showed him the U-2 photographs and briefed him on the CIA's analysis of the images. At 6:30 pm EDT, Kennedy convened a meeting of the nine members of the National Security Council and five other key advisers, in a group he formally named the Executive Committee of the National Security Council (EXCOMM) after the fact on October 22 by the National Security Action Memorandum 196.
Responses considered.
The Joint Chiefs of Staff unanimously agreed that a full-scale attack and invasion was the only solution. They believed that the Soviets would not attempt to stop the US from conquering Cuba. Kennedy was skeptical.
Kennedy concluded that attacking Cuba by air would signal the Soviets to presume "a clear line" to conquer Berlin. Kennedy also believed that United States' allies would think of the US as "trigger-happy cowboys" who lost Berlin because they could not peacefully resolve the Cuban situation.
The EXCOMM then discussed the effect on the strategic balance of power, both political and military. The Joint Chiefs of Staff believed that the missiles would seriously alter the military balance, but Secretary of Defense Robert McNamara disagreed. He was convinced that the missiles would not affect the strategic balance at all. An extra forty, he reasoned, would make little difference to the overall strategic balance. The US already had approximately 5,000 strategic warheads, while the Soviet Union had only 300. He concluded that the Soviets having 340 would not therefore substantially alter the strategic balance. In 1990, he reiterated that "it made "no" difference...The military balance wasn't changed. I didn't believe it then, and I don't believe it now."
The EXCOMM agreed that the missiles would affect the "political" balance. First, Kennedy had explicitly promised the American people less than a month before the crisis that "if Cuba should possess a capacity to carry out offensive actions against the United States...the United States would act." Second, US credibility among their allies, and among the American people, would be damaged if they allowed the Soviet Union to "appear" to redress the strategic balance by placing missiles in Cuba. Kennedy explained after the crisis that "it would have politically changed the balance of power. It would have appeared to, and appearances contribute to reality."
On October 18, President Kennedy met with Soviet Minister of Foreign Affairs, Andrei Gromyko, who claimed the weapons were for defensive purposes only. Not wanting to expose what he already knew, and wanting to avoid panicking the American public, the President did not reveal that he was already aware of the missile build-up.
By October 19, frequent U-2 spy flights showed four operational sites. As part of the blockade, the US military was put on high alert to enforce the blockade and to be ready to invade Cuba at a moment's notice. The 1st Armored Division was sent to Georgia, and five army divisions were alerted for maximal action. The Strategic Air Command (SAC) distributed its shorter-ranged B-47 Stratojet medium bombers to civilian airports and sent aloft its B-52 Stratofortress heavy bombers.
Operational Plans.
Two Operational Plans (OPLAN) were considered. OPLAN 316 envisioned a full invasion of Cuba by Army and Marine units supported by the Navy following Air Force and naval airstrikes. However, Army units in the United States would have had trouble fielding mechanized and logistical assets, while the US Navy could not supply sufficient amphibious shipping to transport even a modest armored contingent from the Army. OPLAN 312, primarily an Air Force and Navy carrier operation, was designed with enough flexibility to do anything from engaging individual missile sites to providing air support for OPLAN 316's ground forces.
Blockade ("Quarantine").
Kennedy met with members of EXCOMM and other top advisers throughout October 21, considering two remaining options: an air strike primarily against the Cuban missile bases, or a naval blockade of Cuba. A full-scale invasion was not the administration's first option. Robert McNamara supported the naval blockade as a strong but limited military action that left the US in control. However, the term "blockade" was problematic. According to international law a blockade is an act of war, but the Kennedy administration did not think that the USSR would be provoked to attack by a mere blockade. Additionally, legal experts at the State Department and Justice Department concluded that a declaration of war could be avoided so long as another legal justification, based on the Rio Treaty for defense of the Western Hemisphere, was obtained via a resolution by a two-thirds vote from the members or the Organization of American States (OAS).
Admiral Anderson, Chief of Naval Operations wrote a position paper that helped Kennedy to differentiate between what they termed a "quarantine" of offensive weapons and a blockade of all materials, claiming that a classic blockade was not the original intention. Since it would take place in international waters, Kennedy obtained the approval of the OAS for military action under the hemispheric defense provisions of the Rio Treaty.
On October 19, the EXCOMM formed separate working groups to examine the air strike and blockade options, and by the afternoon most support in the EXCOMM shifted to the blockade option. Reservations about the plan continued to be voiced as late as the twenty-first, however, the paramount one being that once the blockade was put into effect, the Soviets would rush to complete some of the missiles. Consequently, the United States could find itself bombing operational missiles were the blockade to fail to force Khrushchev to remove the missiles already on the island.
At 3:00 pm EDT on October 22, President Kennedy formally established the Executive Committee (EXCOMM) with National Security Action Memorandum (NSAM) 196. At 5:00 pm, he met with Congressional leaders who contentiously opposed a blockade and demanded a stronger response. In Moscow, Ambassador Kohler briefed Chairman Khrushchev on the pending blockade and Kennedy's speech to the nation. Ambassadors around the world gave advance notice to non-Eastern Bloc leaders. Before the speech, US delegations met with Canadian Prime Minister John Diefenbaker, British Prime Minister Harold Macmillan, West German Chancellor Konrad Adenauer, and French President Charles de Gaulle to brief them on the US intelligence and their proposed response. All were supportive of the US position.
On October 22 at 7:00 pm EDT, President Kennedy delivered a nation-wide televised address on all of the major networks announcing the discovery of the missiles.
During the speech a directive went out to all US forces worldwide placing them on DEFCON 3. The heavy cruiser USS "Newport News" was designated flagship for the blockade, with the USS "Leary" (DD-879) as "Newport News"' destroyer escort.
Crisis deepens.
On October 23 at 11:24 am EDT a cable drafted by George Ball to the US Ambassador in Turkey and the US Ambassador to NATO notified them that they were considering making an offer to withdraw what the U.S knew to be nearly obsolete missiles from Italy and Turkey in exchange for the Soviet withdrawal from Cuba. Turkish officials replied that they would "deeply resent" any trade for the US missile's presence in their country. Two days later, on the morning of October 25, journalist Walter Lippmann proposed the same thing in his syndicated column. Castro reaffirmed Cuba's right to self-defense and said that all of its weapons were defensive and Cuba would not allow an inspection.
International response.
Three days after Kennedy's speech, the Chinese "People's Daily" announced that "650,000,000 Chinese men and women were standing by the Cuban people". In West Germany, newspapers supported the United States' response, contrasting it with the weak American actions in the region during the preceding months. They also expressed some fear that the Soviets might retaliate in Berlin. In France on October 23, the crisis made the front page of all the daily newspapers. The next day, an editorial in "Le Monde" expressed doubt about the authenticity of the CIA's photographic evidence. Two days later, after a visit by a high-ranking CIA agent, they accepted the validity of the photographs. Also in France, in the October 29 issue of "Le Figaro", Raymond Aron wrote in support of the American response.
Soviet broadcast.
At the time, the crisis continued unabated, and on the evening of October 24, the Soviet news agency TASS broadcast a telegram from Khrushchev to President Kennedy, in which Khrushchev warned that the United States' "pirate action" would lead to war. However, this was followed at 9:24 pm by a telegram from Khrushchev to Kennedy which was received at 10:52 pm EDT, in which Khrushchev stated, "If you coolly weigh the situation which has developed, not giving way to passions, you will understand that the Soviet Union cannot fail to reject the arbitrary demands of the United States" and that the Soviet Union views the blockade as "an act of aggression" and their ships will be instructed to ignore it.
U.S. alert level raised.
The United States requested an emergency meeting of the United Nations Security Council on October 25. U.S. Ambassador to the United Nations Adlai Stevenson confronted Soviet Ambassador Valerian Zorin in an emergency meeting of the SC challenging him to admit the existence of the missiles. Ambassador Zorin refused to answer. The next day at 10:00 pm EDT, the United States raised the readiness level of SAC forces to DEFCON 2. For the only confirmed time in U.S. history, the B-52 bombers were dispersed to various locations and made ready to take off, fully equipped, on 15 minutes' notice. One-eighth of SAC's 1,436 bombers were on airborne alert, some 145 intercontinental ballistic missiles stood on ready alert, while Air Defense Command (ADC) redeployed 161 nuclear-armed interceptors to 16 dispersal fields within nine hours with one-third maintaining 15-minute alert status. Twenty-three nuclear-armed B-52 were sent to orbit points within striking distance of the Soviet Union so that the latter might observe that the U.S. was serious. Jack J. Catton later estimated that about 80% of SAC's planes were ready for launch during the crisis; David A. Burchinal recalled that, by contrast, 
"By October 22, Tactical Air Command (TAC) had 511 fighters plus supporting tankers and reconnaissance aircraft deployed to face Cuba on one-hour alert status. However, TAC and the Military Air Transport Service had problems. The concentration of aircraft in Florida strained command and support echelons; which faced critical undermanning in security, armaments, and communications; the absence of initial authorization for war-reserve stocks of conventional munitions forced TAC to scrounge; and the lack of airlift assets to support a major airborne drop necessitated the call-up of 24 Reserve squadrons."
On October 25 at 1:45 am EDT, Kennedy responded to Khrushchev's telegram, stating that the United States was forced into action after receiving repeated assurances that no offensive missiles were being placed in Cuba, and that when these assurances proved to be false, the deployment "required the responses I have announced... I hope that your government will take necessary action to permit a restoration of the earlier situation."
Blockade challenged.
At 7:15 am EDT on October 25, the USS "Essex" and USS "Gearing" attempted to intercept the "Bucharest" but failed to do so. Fairly certain the tanker did not contain any military material, they allowed it through the blockade. Later that day, at 5:43 pm, the commander of the blockade effort ordered the USS "Joseph P. Kennedy, Jr" to intercept and board the Lebanese freighter "Marucla". This took place the next day, and the "Marucla" was cleared through the blockade after its cargo was checked.
At 5:00 pm EDT on October 25, William Clements announced that the missiles in Cuba were still actively being worked on. This report was later verified by a CIA report that suggested there had been no slow-down at all. In response, Kennedy issued Security Action Memorandum 199, authorizing the loading of nuclear weapons onto aircraft under the command of SACEUR (which had the duty of carrying out first air strikes on the Soviet Union). During the day, the Soviets responded to the blockade by turning back 14 ships presumably carrying offensive weapons.
Crisis stalemated.
The next morning, October 26, Kennedy informed the EXCOMM that he believed only an invasion would remove the missiles from Cuba. However, he was persuaded to give the matter time and continue with both military and diplomatic pressure. He agreed and ordered the low-level flights over the island to be increased from two per day to once every two hours. He also ordered a crash program to institute a new civil government in Cuba if an invasion went ahead.
At this point, the crisis was ostensibly at a stalemate. The USSR had shown no indication that they would back down and had made several comments to the contrary. The US had no reason to believe otherwise and was in the early stages of preparing for an invasion, along with a nuclear strike on the Soviet Union in case it responded militarily, which was assumed.
Secret negotiations.
At 1:00 pm EDT on October 26, John A. Scali of ABC News had lunch with Aleksandr Fomin (alias of spy Alexander Feklisov) at Fomin's request. Fomin noted, "War seems about to break out" and asked Scali to use his contacts to talk to his "high-level friends" at the State Department to see if the US would be interested in a diplomatic solution. He suggested that the language of the deal would contain an assurance from the Soviet Union to remove the weapons under UN supervision and that Castro would publicly announce that he would not accept such weapons in the future, in exchange for a public statement by the US that it would never invade Cuba. The US responded by asking the Brazilian government to pass a message to Castro that the US would be "unlikely to invade" if the missiles were removed.
On October 26 at 6:00 pm EDT, the State Department started receiving a message that appeared to be written personally by Khrushchev. It was Saturday at 2:00 am in Moscow. The long letter took several minutes to arrive, and it took translators additional time to translate and transcribe it.
Robert Kennedy described the letter as "very long and emotional". Khrushchev reiterated the basic outline that had been stated to John Scali earlier in the day, "I propose: we, for our part, will declare that our ships bound for Cuba are not carrying any armaments. You will declare that the United States will not invade Cuba with its troops and will not support any other forces which might intend to invade Cuba. Then the necessity of the presence of our military specialists in Cuba will disappear." At 6:45 pm EDT, news of Fomin's offer to Scali was finally heard and was interpreted as a "set up" for the arrival of Khrushchev's letter. The letter was then considered official and accurate, although it was later learned that Fomin was almost certainly operating of his own accord without official backing. Additional study of the letter was ordered and continued into the night.
Crisis continues.
Castro, on the other hand, was convinced that an invasion of Cuba was soon at hand, and on October 26, he sent a telegram to Khrushchev that appeared to call for a pre-emptive nuclear strike on the USA. However, in a 2010 interview, Castro said of his recommendation for the Soviets to attack America "before" they made any move against Cuba: "After I've seen what I've seen, and knowing what I know now, it wasn't worth it at all." Castro also ordered all anti-aircraft weapons in Cuba to fire on any US aircraft, whereas in the past they had been ordered only to fire on groups of two or more. At 6:00 am EDT on October 27, the CIA delivered a memo reporting that three of the four missile sites at San Cristobal and the two sites at Sagua la Grande appeared to be fully operational. They also noted that the Cuban military continued to organize for action, although they were under order not to initiate action unless attacked.
At 9:00 am EDT on October 27, Radio Moscow began broadcasting a message from Khrushchev. Contrary to the letter of the night before, the message offered a new trade, that the missiles on Cuba would be removed in exchange for the removal of the Jupiter missiles from Italy and Turkey. At 10:00 am EDT, the executive committee met again to discuss the situation and came to the conclusion that the change in the message was due to internal debate between Khrushchev and other party officials in the Kremlin. McNamara noted that another tanker, the "Grozny", was about out and should be intercepted. He also noted that they had not made the USSR aware of the blockade line and suggested relaying this information to them via U Thant at the United Nations. 
While the meeting progressed, at 11:03 am EDT a new message began to arrive from Khrushchev. The message stated, in part,
The executive committee continued to meet through the day.
Throughout the crisis, Turkey had repeatedly stated that it would be upset if the Jupiter missiles were removed. Italy's Prime Minister Fanfani, who was also Foreign Minister "ad interim", offered to allow withdrawal of the missiles deployed in Apulia as a bargaining chip. He gave the message to one of his most trusted friends, Ettore Bernabei, the general manager of RAI-TV, to convey to Arthur M. Schlesinger, Jr.. Bernabei was in New York to attend an international conference on satellite TV broadcasting. Unknown to the Soviets, the U.S regarded the Jupiter missiles as obsolete and already supplanted by the Polaris nuclear ballistic submarine missiles.
On the morning of October 27, a U-2F (the third CIA U-2A, modified for air-to-air refueling) piloted by USAF Major Rudolf Anderson, departed its forward operating location at McCoy AFB, Florida. At approximately 12:00 pm EDT, the aircraft was struck by a S-75 Dvina (NATO designation "SA-2 Guideline") SAM missile launched from Cuba. The aircraft was shot down and Anderson was killed. The stress in negotiations between the USSR and the US intensified, and only much later was it learned that the decision to fire the missile was made locally by an undetermined Soviet commander acting on his own authority. Later that day, at about 3:41 pm EDT, several US Navy RF-8A Crusader aircraft on low-level photoreconnaissance missions were fired upon, and one was hit by a 37 mm shell but managed to return to base.
Drafting the response.
Emissaries sent by both Kennedy and Nikita Khrushchev agreed to meet at the Yenching Palace Chinese restaurant in the Cleveland Park neighborhood of Washington D.C. on the evening of October 27. Kennedy suggested that they take Khrushchev's offer to trade away the missiles. Unknown to most members of the EXCOMM, Robert Kennedy had been meeting with the Soviet Ambassador in Washington to discover whether these intentions were genuine. The EXCOMM was generally against the proposal because it would undermine NATO's authority, and the Turkish government had repeatedly stated it was against any such trade.
As the meeting progressed, a new plan emerged and Kennedy was slowly persuaded. The new plan called for the President to ignore the latest message and instead to return to Khrushchev's earlier one. Kennedy was initially hesitant, feeling that Khrushchev would no longer accept the deal because a new one had been offered, but Llewellyn Thompson argued that he might accept it anyway. White House Special Counsel and Adviser Ted Sorensen and Robert Kennedy left the meeting and returned 45 minutes later with a draft letter to this effect. The President made several changes, had it typed, and sent it.
After the EXCOMM meeting, a smaller meeting continued in the Oval Office. The group argued that the letter should be underscored with an oral message to Ambassador Dobrynin stating that if the missiles were not withdrawn, military action would be used to remove them. Dean Rusk added one proviso, that no part of the language of the deal would mention Turkey, but there would be an understanding that the missiles would be removed "voluntarily" in the immediate aftermath. The President agreed, and the message was sent.
At Juan Brito's request, Fomin and Scali met again. Scali asked why the two letters from Khrushchev were so different, and Fomin claimed it was because of "poor communications". Scali replied that the claim was not credible and shouted that he thought it was a "stinking double cross". He went on to claim that an invasion was only hours away, at which point Fomin stated that a response to the US message was expected from Khrushchev shortly, and he urged Scali to tell the State Department that no treachery was intended. Scali said that he did not think anyone would believe him, but he agreed to deliver the message. The two went their separate ways, and Scali immediately typed out a memo for the EXCOMM.
Within the US establishment, it was well understood that ignoring the second offer and returning to the first put Khrushchev in a terrible position. Military preparations continued, and all active duty Air Force personnel were recalled to their bases for possible action. Robert Kennedy later recalled the mood, "We had not abandoned all hope, but what hope there was now rested with Khrushchev's revising his course within the next few hours. It was a hope, not an expectation. The expectation was military confrontation by Tuesday, and possibly tomorrow...".
At 8:05 pm EDT, the letter drafted earlier in the day was delivered. The message read, "As I read your letter, the key elements of your proposals—which seem generally acceptable as I understand them—are as follows: 1) You would agree to remove these weapons systems from Cuba under appropriate United Nations observation and supervision; and undertake, with suitable safe-guards, to halt the further introduction of such weapon systems into Cuba. 2) We, on our part, would agree—upon the establishment of adequate arrangements through the United Nations, to ensure the carrying out and continuation of these commitments (a) to remove promptly the quarantine measures now in effect and (b) to give assurances against the invasion of Cuba." The letter was also released directly to the press to ensure it could not be "delayed".
With the letter delivered, a deal was on the table. However, as Robert Kennedy noted, there was little expectation it would be accepted. At 9:00 pm EDT, the EXCOMM met again to review the actions for the following day. Plans were drawn up for air strikes on the missile sites as well as other economic targets, notably petroleum storage. McNamara stated that they had to "have two things ready: a government for Cuba, because we're going to need one; and secondly, plans for how to respond to the Soviet Union in Europe, because sure as hell they're going to do something there".
At 12:12 am EDT, on October 27, the US informed its NATO allies that "the situation is growing shorter... the United States may find it necessary within a very short time in its interest and that of its fellow nations in the Western Hemisphere to take whatever military action may be necessary." To add to the concern, at 6 am the CIA reported that all missiles in Cuba were ready for action.
Later on that same day, what the White House later called "Black Saturday", the US Navy dropped a series of "signaling depth charges" (practice depth charges the size of hand grenades) on a Soviet submarine (B-59) at the blockade line, unaware that it was armed with a nuclear-tipped torpedo with orders that allowed it to be used if the submarine was "hulled" (a hole in the hull from depth charges or surface fire). The decision to launch these required agreement from all three officers on board, but one of them, Vasili Arkhipov, objected and so the launch was narrowly averted.
On the same day a US U-2 spy plane made an accidental, unauthorized ninety-minute overflight of the Soviet Union's far eastern coast. The Soviets responded by scrambling MiG fighters from Wrangel Island; in turn the Americans launched F-102 fighters armed with nuclear air-to-air missiles over the Bering Sea.
On October 27, Khrushchev also received a letter from Castro – what is now known as the Armageddon Letter (dated Oct. 26) – interpreted as urging the use of nuclear force in the event of an attack on Cuba. “I believe the imperialists’ aggressiveness is extremely dangerous and if they actually carry out the brutal act of invading Cuba in violation of international law and morality, that would be the moment to eliminate such danger forever through an act of clear legitimate defense, however harsh and terrible the solution would be,” Castro wrote.
Crisis ends.
On October 27, after much deliberation between the Soviet Union and Kennedy's cabinet, Kennedy secretly agreed to remove all missiles set in southern Italy and in Turkey, the latter on the border of the Soviet Union, in exchange for Khrushchev removing all missiles in Cuba.
At 9:00 am EDT, on October 28, a new message from Khrushchev was broadcast on Radio Moscow. Khrushchev stated that, "the Soviet government, in addition to previously issued instructions on the cessation of further work at the building sites for the weapons, has issued a new order on the dismantling of the weapons which you describe as 'offensive' and their crating and return to the Soviet Union."
Kennedy immediately responded, issuing a statement calling the letter "an important and constructive contribution to peace". He continued this with a formal letter: "I consider my letter to you of October twenty-seventh and your reply of today as firm undertakings on the part of both our governments which should be promptly carried out... The US will make a statement in the framework of the Security Council in reference to Cuba as follows: it will declare that the United States of America will respect the inviolability of Cuban borders, its sovereignty, that it take the pledge not to interfere in internal affairs, not to intrude themselves and not to permit our territory to be used as a bridgehead for the invasion of Cuba, and will restrain those who would plan to carry an aggression against Cuba, either from US territory or from the territory of other countries neighboring to Cuba."
The U.S continued the blockade, and in the following days, aerial reconnaissance proved that the Soviets were making progress in removing the missile systems. The 42 missiles and their support equipment were loaded onto eight Soviet ships. The ships left Cuba from November 5–9. The US made a final visual check as each of the ships passed the blockade line. Further diplomatic efforts were required to remove the Soviet IL-28 bombers, and they were loaded on three Soviet ships on December 5 and 6. Concurrent with the Soviet commitment on the IL-28's, the US Government announced the end of the blockade effective at 6:45 pm EDT on November 20, 1962. 
At the time when the Kennedy administration thought that the Cuban Missile Crisis was resolved, nuclear tactical rockets stayed in Cuba since they were not part of the Kennedy-Khrushchev understandings. However, the Soviets changed their minds, fearing possible future Cuban militant steps, and at November 22, 1962 the Soviet Deputy Prime Minister Anastas Mikoyan told Castro that those rockets with the nuclear warheads, were being removed too.
In his negotiations with the Soviet Ambassador Anatoly Dobrynin, US Attorney General Robert Kennedy informally proposed that the Jupiter missiles in Turkey would be removed "within a short time after this crisis was over." The last US missiles were disassembled by April 24, 1963, and were flown out of Turkey soon after.
The practical effect of this Kennedy-Khrushchev Pact was that it effectively strengthened Castro's position in Cuba, guaranteeing that the US would not invade Cuba. It is possible that Khrushchev only placed the missiles in Cuba to get Kennedy to remove the missiles from Italy and Turkey and that the Soviets had no intention of resorting to nuclear war if they were out-gunned by the Americans. Because the withdrawal of the Jupiter missiles from NATO bases in Southern Italy and Turkey was not made public at the time, Khrushchev appeared to have lost the conflict and become weakened. The perception was that Kennedy had won the contest between the superpowers and Khrushchev had been humiliated. This is not entirely the case as both Kennedy and Khrushchev took every step to avoid full conflict despite the pressures of their governments. Khrushchev held power for another two years.
Aftermath.
The compromise embarrassed Khrushchev and the Soviet Union because the withdrawal of US missiles from Italy and Turkey was a secret deal between Kennedy and Khrushchev. The Soviets were seen as retreating from circumstances that they had started. Khrushchev's fall from power two years later was in part because of the Politburo embarrassment at both Khrushchev's eventual concessions to the US and his ineptitude in precipitating the crisis in the first place. According to Dobrynin, the top Soviet leadership took the Cuban outcome as "a blow to its prestige bordering on humiliation".
Cuba perceived the outcome as a partial betrayal by the Soviets, given that decisions on how to resolve the crisis had been made exclusively by Kennedy and Khrushchev. Castro was especially upset that certain issues of interest to Cuba, such as the status of the US Naval Base in Guantánamo, were not addressed. This caused Cuban-Soviet relations to deteriorate for years to come. On the other hand, Cuba continued to be protected from invasion.
Although General Curtis LeMay told the President that he considered the resolution of the Cuban missile crisis the "greatest defeat in our history", his was a minority position. He had pressed for an immediate invasion of Cuba as soon as the crisis began, and still favored invading Cuba even after the Soviets had withdrawn their missiles. 25 years later, LeMay still believed that "We could have gotten not only the missiles out of Cuba, we could have gotten the Communists out of Cuba at that time".
After the crisis the United States and the Soviet Union created the Moscow–Washington hotline, a direct communications link between Moscow and Washington, D.C. The purpose was to have a way that the leaders of the two Cold War countries could communicate directly to solve such a crisis. The world-wide US Forces DEFCON 3 status was returned to DEFCON 4 on November 20, 1962. U-2 pilot Major Anderson's body was returned to the United States and he was buried with full military honors in South Carolina. He was the first recipient of the newly created Air Force Cross, which was awarded posthumously.
Although Anderson was the only combatant fatality during the crisis, 11 crew members of three reconnaissance Boeing RB-47 Stratojets of the 55th Strategic Reconnaissance Wing were also killed in crashes during the period between September 27 and November 11, 1962. Further, seven crew died when a MATS Boeing C-135B Stratolifter delivering ammunition to Guantanamo Bay Naval Base stalled and crashed on approach on October 23.
Critics including Seymour Melman and Seymour Hersh suggested that the Cuban missile crisis encouraged US use of military means, such as in the Vietnam War. This Soviet-American confrontation was synchronous with the Sino-Indian War, dating from the US's military blockade of Cuba; historians speculate that the Chinese attack against India for disputed land was meant to coincide with the Cuban missile crisis.
Post-Crisis Revelations.
Arthur M. Schlesinger, Jr., a historian and adviser to John F. Kennedy, told National Public Radio in an interview on October 16, 2002 that Castro did not want the missiles, but that Khrushchev had pressured Castro to accept them. Castro was not completely happy with the idea but the Cuban National Directorate of the Revolution accepted them to protect Cuba against US attack, and to aid its ally, the Soviet Union. Schlesinger believed that when the missiles were withdrawn, Castro was angrier with Khrushchev than he was with Kennedy because Khrushchev had not consulted Castro before deciding to remove them.
In early 1992, it was confirmed that Soviet forces in Cuba had, by the time the crisis broke, received tactical nuclear warheads for their artillery rockets and Il-28 bombers. Castro stated that he would have recommended their use if the US invaded despite knowing Cuba would be destroyed.
Arguably the most dangerous moment in the crisis was only recognized during the Cuban Missile Crisis Havana conference in October 2002. Attended by many of the veterans of the crisis, they all learned that on October 26, 1962 the USS "Beale" had tracked and dropped signaling depth charges (the size of hand grenades) on the B-59, a Soviet Project 641 (NATO designation "Foxtrot") submarine which, unknown to the US, was armed with a 15 kiloton nuclear torpedo. Running out of air, the Soviet submarine was surrounded by American warships and desperately needed to surface. An argument broke out among three officers on the "B-59", including submarine captain Valentin Savitsky, political officer Ivan Semonovich Maslennikov, and Deputy brigade commander Captain 2nd rank (US Navy Commander rank equivalent) Vasili Arkhipov. An exhausted Savitsky became furious and ordered that the nuclear torpedo on board be made combat ready. Accounts differ about whether Commander Arkhipov convinced Savitsky not to make the attack, or whether Savitsky himself finally concluded that the only reasonable choice left open to him was to come to the surface. During the conference Robert McNamara stated that nuclear war had come much closer than people had thought. Thomas Blanton, director of the National Security Archive, said, "A guy called Vasili Arkhipov saved the world." 
BBC journalist Joe Matthews published on October 13, 2012 the story behind the 100 tactical nuclear warheads mentioned by Graham Allison in the excerpt above. Khrushchev feared that Castro's hurt pride and widespread Cuban indignation over the concessions he had made to Kennedy might lead to a breakdown of the agreement between the Soviet Union and the United States. In order to prevent this Khrushchev decided to make Cuba a special offer. The offer was to give Cuba more than 100 tactical nuclear weapons that had been shipped to Cuba along with the long-range missiles, but which crucially had passed completely under the radar of US intelligence. Khrushchev concluded that because the Americans hadn't listed the missiles on their list of demands, the Soviet Union's interests would be well served by keeping them in Cuba. 
Anastas Mikoyan was tasked with the exercise to complete negotiations with Castro over the missile transfer deal designed to prevent a break down in the relations between Cuba and the Soviet Union. While in Havana Mikoyan witnessed the mood swings and paranoia of Castro who was convinced that Moscow had sold Cuba's defence down the river. Mikoyan came to a personal decision that under no circumstances should Castro and his military be given control of weapons with an explosive force equal to 100 Hiroshima-sized bombs. He then defused a seemingly intractable situation which risked blowing the entire crisis back up in the faces of Kennedy and Khrushchev on November 22, 1962. During a tense, four-hour meeting, Mikoyan convinced Castro that despite Moscow's best intentions, it would be in breach of an unpublished Soviet law (which didn't actually exist) to transfer the missiles permanently into Cuban hands and provide them with an independent nuclear deterrent. Finally after Mikoyan's trump card, Castro was forced to give way and - much to the relief of Khrushchev and the whole Soviet government - the tactical nuclear weapons were finally crated and returned by sea back to the Soviet Union during December 1962.

Cyprus dispute
The Cyprus dispute is the result of the ongoing conflict between the Republic of Cyprus and Turkey, over the Turkish occupied northern part of Cyprus.
Initially, with the annexation of the island by the British Empire, the "Cyprus dispute" was identified as the conflict between the people of Cyprus and the British Crown regarding the Cypriots' demand for self determination. The dispute however was finally shifted from a colonial dispute to an ethnic dispute between the Turkish and the Greek islanders. The international complications of the dispute stretch far beyond the boundaries of the island of Cyprus itself and involve the guarantor powers (Turkey, Greece, and the United Kingdom alike), along with the United States, the United Nations and the European Union. 
With Turkey's military action of 1974 (disapproved by UN Security Council Resolution 1974/360), Turkey occupied the northern part of the internationally recognised Republic of Cyprus, and later upon those territories the Turkish Cypriot community unilaterally declared independence forming the Turkish Republic of Northern Cyprus (TRNC), a sovereign entity that lacks international recognition-with the exception of Turkey with which TRNC enjoys full diplomatic relations.
After the two communities and the guarantor countries have committed themselves in finding a peaceful solution over the dispute, the United Nations have since created and maintained a buffer zone (the "Green Line") to avoid any further intercommunal tensions and hostilities. This zone separates the Greek Cypriot-controlled south from the Turkish Cypriot-controlled north.
Historical background prior to 1960.
The island of Cyprus was first inhabited in 9000 BC with the arrival of farming societies who built round houses with floors of terazzo. Cities were first built during the Bronze Age and the inhabitants had their own Eteocypriot language until around the 4th century BC. The island was part of the Hittite Empire as part of the Ugarit Kingdom during the late Bronze Age until the arrival of two waves of Greek settlement.
Cyprus experienced an uninterrupted Greek presence on the island dating from the arrival of Mycenaeans around 1100 BC, when the burials began to take the form of long "dromos". The Greek population of Cyprus survived through multiple conquerors, including Egyptian and Persian rule. In the 4th century BC, Cyprus was conquered by Alexander the Great and then ruled by the Ptolemaic Egypt until 58 BC, when it was incorporated into the Roman Empire. After an interval of Islam Khalifate (643-966), the island returned to Roman rule until the 12th century. After an occupation by the Knights Templar and the rule of Isaac Komnenos, the island in 1192 came under the rule of the Lusignan family, who established the Kingdom of Cyprus. In February 1489 it was seized by the Republic of Venice. Between September 1570 and August 1571 it was conquered by the Ottoman Empire, starting three centuries of Turkish rule over Cyprus. 
Starting in the early nineteenth century, ethnic Greeks of the island sought to bring about an end to almost 300 years of Ottoman rule and unite Cyprus with Greece. The United Kingdom took administrative control of the island in 1878, to prevent Ottoman positions from falling under Russian control following the Cyprus Convention, which led to the call for union ("enosis") to grow louder. Under the terms of the agreement reached between Britain and the Ottoman Empire, the island remained an Ottoman territory.
The Christian Greek-speaking inhabitants of the island welcomed the arrival of the British as a chance to voice their demands for union with Greece: "enosis".
When the Ottoman Empire entered World War I on the side of the Central Powers, Britain renounced the agreement and all Turkish claims over Cyprus and declared the island a British colony. In 1915, Britain offered Cyprus to Constantine I of Greece on condition that Greece join the war on the side of the British, which he declined.
1918 to 1955.
Under British rule in the early 20th century, Cyprus escaped the conflicts and atrocities that went on elsewhere between Greeks and Turks; notably during the Greco-Turkish War (1919–1922) and the 1923 Population exchange between Greece and Turkey. Turkish Cypriots consistently opposed the idea of union with Greece.
In 1925 Britain declared Cyprus to be a Crown Colony. In the years that followed, the determination for "enosis" continued. In 1931 this led to open revolution. A riot resulted in the death of six civilians, injuries to others and the burning of the British Government House in Nicosia. In the months that followed, about 2,000 people were convicted of crimes in connection with the struggle for union with Greece. Britain reacted by imposing harsh restrictions. Military reinforcements were dispatched to the island and the constitution suspended. A special "epicourical" (reserve) police force was formed consisting of only Turkish Cypriots, press restrictions instituted and political parties banned. Two bishops and eight other prominent citizens directly implicated in the conflict were exiled. Municipal elections were suspended, and until 1943 all municipal officials were appointed by the government. The governor was to be assisted by an Executive Council, and two years later an Advisory Council was established; both councils consisted only of appointees and were restricted to advising on domestic matters only. In addition, the flying of Greek or Turkish flags or the public display of portraits of Greek or Turkish heroes was forbidden.
The struggle for "enosis" was put on hold during World War II. In 1946, the British government announced plans to invite Cypriots to form a Consultative Assembly to discuss a new constitution. The British also allowed the return of the 1931 exiles. Instead of reacting positively, as expected by the British, the Greek Cypriot military hierarchy reacted angrily because there had been no mention of "enosis". The Cypriot Orthodox Church had expressed its disapproval, and Greek Cypriots declined the British invitation, stating that "enosis" was their sole political aim. The efforts by Greeks to bring about "enosis" now intensified, helped by active support of the Church of Cyprus, which was the main political voice of the Greek Cypriots at the time. However, it was not the only organisation claiming to speak for the Greek Cypriots. The Church's main opposition came from the Cypriot Communist Party (officially the Progressive Party of the Working People; "Ανορθωτικό" "Κόμμα" "Εργαζόμενου" "Λαού"; or AKEL), which also wholeheartedly supported the Greek national goal of "enosis". However the British military forces and Colonial administration in Cyprus did not see the pro-Soviet communist party as a viable partner.
By 1954 a number of Turkish mainland institutions were active in the Cyprus issue such as the National Federation of Students, the Committee for the Defence of Turkish rights in Cyprus, the Welfare Organisation of Refugees from Thrace and the Cyprus Turkish Association. Above all, the Turkish trade unions were to prepare the right climate for the main Turkish goal, the division of the island ("taksim") into Greek and Turkish parts, thus keeping the British military presence and installations on the island intact. By this time a special Turkish Cypriot paramilitary organisation Turkish Resistance Organisation (TMT) was also established which was to act as a counterbalance to the Greek Cypriot "enosis" fighting organisation of EOKA.
In 1950, Michael Mouskos, Bishop Makarios of Kition (Larnaca), was elevated to Archbishop Makarios III of Cyprus. In his inaugural speech, he vowed not to rest until union with "mother Greece" had been achieved. In Athens, "enosis" was a common topic of conversation, and a Cypriot native, Colonel George Grivas, was becoming known for his strong views on the subject. In anticipation of an armed struggle to achieve "enosis", Grivas visited Cyprus in July 1951. He discussed his ideas with Makarios but was disappointed by the archbishop's contrasting opinion as he proposed a political struggle rather than an armed revolution against the British. From the beginning, and throughout their relationship, Grivas resented having to share leadership with the archbishop. Makarios, concerned about Grivas's extremism from their very first meeting, preferred to continue diplomatic efforts, particularly efforts to get the United Nations involved. The feelings of uneasiness that arose between them never dissipated. In the end, the two became enemies. In the meantime, in August Government 1954, Greece's UN representative formally requested that self-determination for the people of Cyprus be included on the agenda of the General Assembly's next session. Turkey rejected the idea of the union of Cyprus and Greece. Turkish Cypriot community opposed Greek Cypriot "enosis" movement, as under British rule the Turkish Cypriot minority status and identity were protected. Turkish Cypriot identification with Turkey had grown stronger in response to overt Greek nationalism of Greek Cypriots, and after 1954 the Turkish government had become increasingly involved. In the late summer and early autumn of 1954, the Cyprus problem intensified. On Cyprus the colonial government threatened publishers of seditious literature with up to two years imprisonment. In December the UN General Assembly announced the decision "not to consider the problem further for the time being, because it does not appear appropriate to adopt a resolution on the question of Cyprus." Reaction to the setback at the UN was immediate and violent, resulting in the worst rioting in Cyprus since 1931.
EOKA campaign and creation of TMT, 1955–59.
In January 1955, Grivas founded the National Organisation of Cypriot Fighters ("Ethniki Organosis" "Kyprion Agoniston" – EOKA). On April 1, 1955, EOKA opened an armed campaign against British rule in a well-coordinated series of attacks on police, military, and other government installations in Nicosia, Famagusta, Larnaca, and Limassol. This resulted in the deaths of 387 British servicemen and personnel and some Greek Cypriots suspected of collaboration. As a result of this a number of Greek Cypriots began to leave the police. This however did not affect the Colonial police force as they had already created the solely Turkish Cypriot (Epicourical) reserve force to fight EOKA paramilitaries. At the same time, it led to tensions between the Greek and Turkish Cypriot communities. In 1957 the Turkish Resistance Organisation ("Türk Mukavemet" "Teşkilatı" TMT), which had already been formed to protect the Turkish Cypriots from EOKA took action. In response to the growing demand for "enosis", a number of Turkish Cypriots became convinced that the only way to protect their interests and identity of the Turkish Cypriot population in the event of "enosis" would be to divide the island - a policy known as "taksim" ("partition" in Turkish borrowed from (تقسیم)"Taqsīm" in Arabic) - into a Greek sector in the south and a Turkish sector in the north only.
By now the island was on the verge of civil war. Several attempts to present a compromise settlement had failed. Therefore, beginning in December 1958, representatives of Greece and Turkey, the so-called "mother lands" opened discussions of the Cyprus issue. Participants for the first time discussed the concept of an independent Cyprus, i.e., neither "enosis" nor "taksim". Subsequent talks always headed by the British yielded a so-called compromise agreement supporting independence, laying the foundations of the Republic of Cyprus. The scene then naturally shifted to London, where the Greek and Turkish representatives were joined by representatives of the Greek Cypriots, the Turkish Cypriots (represented by Arch. Makarios and Dr Fazil Kucuk with no significant decision making power), and the British. The Zurich-London agreements that became the basis for the Cyprus constitution of 1960 were supplemented with three treaties - the Treaty of Establishment, the Treaty of Guarantee, and the Treaty of Alliance. The general tone of the agreements was one of keeping the British sovereign bases and military and monitoring facilities intact. Some Greek Cypriots, especially members of organisations such as EOKA, expressed disappointment because "enosis" had not been attained. In a similar way some Turkish Cypriots especially members of organisations such as TMT expressed their disappointment as they had to postpone their target for "taksim", however most Cypriots that were not influenced by the three so called guarantor powers (Greece, Turkey, and Britain), welcomed the agreements and set aside their demand for "enosis" and "taksim". According to the Treaty of Establishment, Britain retained sovereignty over 256 square kilometres, which became the Dhekelia Sovereign Base Area, to the northeast of Larnaca, and the Akrotiri Sovereign Base Area to the southwest of Limassol.
Cyprus achieved independence on August 16, 1960.
Constitutional breakdown and intercommunal talks, 1960–74.
According to constitutional arrangements, Cyprus was to become an independent, non-aligned republic with a Greek Cypriot president and a Turkish Cypriot vice-president. General executive authority was vested in a council of ministers with a ratio of seven Greeks to three Turks. (The Greek Cypriots represented 78% of the population and the Turkish Cypriots 18%. The remaining 4% was made up by the three minority communities: the Latins, Maronites and Armenians.) A House of Representatives of fifty members, also with a seven-to-three ratio, were to be separately elected by communal balloting on a universal suffrage basis. In addition, separate Greek Cypriot and Turkish Cypriot Communal Chambers were provided to exercise control in matters of religion, culture, and education. According to Article 78(2) "any law imposing duties or taxes shall require a simple majority of the representatives elected by the Greek and Turkish communities respectively taking part in the vote." Legislation on other subjects was to take place by simple majority but again the President and the Vice-President had the same right of veto—absolute on foreign affairs, defence and internal security, delaying on other matters—as in the Council of Ministers. The judicial system would be headed by a Supreme Constitutional Court, composed of one Greek Cypriot and one Turkish Cypriot and presided over by a contracted judge from a neutral country. The Constitution of Cyprus, whilst establishing an Independent and sovereign Republic, was, in the words of de Smith, an authority on Constitutional Law; ""Unique in its tortuous complexity and in the multiplicity of the safeguards that it provides for the principal minority; the Constitution of Cyprus stands alone among the constitutions of the world""
Within a short period of time the first disputes started to arise between the two communities. Issues of contention included taxation and the creation of separate municipalities. Because of the legislative veto system, this resulted in a lockdown in communal and state politics in many cases.
Repeated attempts to solve the disputes failed. Eventually, on November 30, 1963, Makarios put forward to the three guarantors a thirteen-point proposal designed, in his view, to eliminate impediments to the functioning of the government. The thirteen points involved constitutional revisions, including the abandonment of the veto power by both the president and the vice president. Turkey initially rejected it (although later in future discussed the proposal). A few days later, on December 21, 1963 fighting erupted between the communities in Nicosia. In the days that followed it spread across the rest of the island. At the same time, the power-sharing government collapsed. How this happened is one of the most contentious issues in modern Cypriot history. The Greek Cypriots argue that the Turkish Cypriots withdrew in order to form their own administration. The Turkish Cypriots maintain that they were forced out. Many Turkish Cypriots chose to withdraw from the government. However, in many cases those who wished to stay in their jobs were prevented from doing so by the Greek Cypriots. Also, many of the Turkish Cypriots refused to attend because they feared for their lives after the recent violence that had erupted. There was even some pressure from the TMT as well. In any event, in the days that followed the fighting a frantic effort was made to calm tensions. In the end, on December 27, 1963, an interim peacekeeping force, the Joint Truce Force, was put together by Britain, Greece and Turkey. This held the line until a United Nations peacekeeping force, UNFICYP, was formed following United Nations Security Council Resolution 186, passed on March 4, 1964.
Peacemaking efforts, 1964–1974.
At the same time as it established a peacekeeping force, the Security Council also recommended that the Secretary-General, in consultation with the parties and the Guarantor Powers, designate a mediator to take charge of formal peacemaking efforts. U Thant, then the UN Secretary-General, appointed Sakari Tuomioja, a Finnish diplomat. While Tuomioja viewed the problem as essentially international in nature and saw "enosis" as the most logical course for a settlement, he rejected union on the grounds that it would be inappropriate for a UN official to propose a solution that would lead to the dissolution of a UN member state. The United States held a differing view. In early June, following another Turkish threat to intervene, Washington launched an independent initiative under Dean Acheson, a former Secretary of State. In July he presented a plan to unite Cyprus with Greece. In return for accepting this, Turkey would receive a sovereign military base on the island. The Turkish Cypriots would also be given minority rights, which would be overseen by a resident international commissioner. Makarios rejected the proposal, arguing that giving Turkey territory would be a limitation on "enosis" and would give Ankara too strong a say in the island’s affairs. A second version of the plan was presented that offered Turkey a 50-year lease on a base. This offer was rejected by the Greek Cypriots and by Turkey. After several further attempts to reach an agreement, the United States was eventually forced to give up its effort.
Following the sudden death of Ambassador Tuomioja in August, Galo Plaza was appointed Mediator. He viewed the problem in communal terms. In March 1965 he presented a report criticising both sides for their lack of commitment to reaching a settlement. While he understood the Greek Cypriot aspiration of "enosis", he believed that any attempt at union should be held in voluntary abeyance. Similarly, he considered that the Turkish Cypriots should refrain from demanding a federal solution to the problem. Although the Greek Cypriots eventually accepted the report, despite of its opposition to immediate "enosis", Turkey and the Turkish Cypriots rejected the plan, calling on Plaza to resign on the grounds that he had exceeded his mandate by advancing specific proposals. He was simply meant to broker an agreement. But the Greek Cypriots made it clear that if Galo Plaza resigned they would refuse to accept a replacement. U Thant was left with no choice but to abandon the mediation effort. Instead he decided to make his Good Offices available to the two sides. By resolution 186 of 4 March 1964 and a Mediator was appointed. In his Report (S/6253, A/6017, 26 March 1965), the Mediator, Dr Gala Plaza, criticised the 1960 legal framework, and proposed necessary amendments which were rejected by Turkey, a fact which resulted in serious deterioration of the situation with constant threats by Turkey against the sovereignty and territorial integrity of Cyprus, necessitating a series of UN Resolutions calling, inter alia, for respect of the sovereignty, independence and territorial integrity of Cyprus.
The Secretary-General of the United Nations in 1965, described the policy of the Turkish Cypriot leaders in this way: ""The Turkish Cypriot leaders have adhered to a rigid stand against any measures which might involve having members of the two communities live and work together, or which might place Turkish Cypriots in situations where they would have to acknowledge the authority of Government agents. Indeed, since the Turkish Cypriot leadership is committed to physical and geographical separation of the communities as a political goal, it is not likely to encourage activities by Turkish Cypriots which may be interpreted as demonstrating the merits of an alternative policy. The result has been a seemingly deliberate policy of self-segregation by the Turkish Cypriots""Report S/6426
The end of the mediation effort was effectively confirmed when, at the end of the year, Plaza resigned and was not replaced.
In March 1966, a more modest attempt at peacemaking was initiated under the auspices of Carlos Bernades, the Secretary-General’s Special Representative for Cyprus. Instead of trying to develop formal proposals for the parties to bargain over, he aimed to encourage the two sides agree to settlement through direct dialogue. However, ongoing political chaos in Greece prevented any substantive discussions from developing. The situation changed the following year. On 21 April 1967, a coup d'état in Greece brought to power a military administration. Just months later, in November 1967, Cyprus witnessed its most severe bout of intercommunal fighting since 1964. Responding to a major attack on Turkish Cypriot villages in the south of the island, which left 27 dead, Turkey bombed Greek Cypriot forces and appeared to be readying itself for an intervention. Greece was forced to capitulate. Following international intervention, Greece agreed to recall General George Grivas, the Commander of the Greek Cypriot National Guard and former EOKA leader, and reduce its forces on the island. Capitalising on the weakness of the Greek Cypriots, the Turkish Cypriots proclaimed their own provisional administration on 28 December 1967. Makarios immediately declared the new administration illegal. Nevertheless, a major change had occurred. The Archbishop, along with most other Greek Cypriots, began to accept that the Turkish Cypriots would have to have some degree of political autonomy. It was also realised that unification of Greece and Cyprus was unachievable under the prevailing circumstances.
In May 1968, intercommunal talks began between the two sides under the auspices of the Good Offices of the UN Secretary-General. Unusually, the talks were not held between President Makarios and Vice-President Kucuk. Instead they were conducted by the presidents of the communal chambers, Glafcos Clerides and Rauf Denktaş. Again, little progress was made. During the first round of talks, which lasted until August 1968, the Turkish Cypriots were prepared to make several concessions regarding constitutional matters, but Makarios refused to grant them greater autonomy in return. The second round of talks, which focused on local government, was equally unsuccessful. In December 1969 a third round of discussion started. This time they focused on constitutional issues. Yet again there was little progress and when they ended in September 1970 the Secretary-General blamed both sides for the lack of movement. A fourth and final round of intercommunal talks also focused on constitutional issues, but again failed to make much headway before they were forced to a halt in 1974.
Turkish invasion of 1974.
Timeline of the 1974 Invasion of Cyprus
After 1967, tensions between the Greek and Turkish Cypriots subsided. Instead, the main source of tension on the island came from factions within the Greek Cypriot community. Although Makarios had effectively abandoned "enosis" in favour of an ‘attainable solution’, many others continued to believe that the only legitimate political aspirations for Greek Cypriots was union with Greece. In September 1971 Grivas secretly returned to the island and formed EOKA-B, a very pro-union organisation. In early 1974 Grivas died and EOKA-B fell under the direct control of Taxiarkhos Dimitrios Ioannides, the new head of the Junta in Athens. Ioannides was determined to overthrow Makarios. Fearing the consequences of such a step, in early July 1974 Makarios wrote an open letter to the military dictatorship requesting that all Greek officers be removed from the island. On July 15, Ioannides replied through a coup of the Cyprus National Guard which resulted in Makarios being deposed.
After failing to secure British support for a joint intervention under the Treaty of Guarantee, Bülent Ecevit, the Turkish prime minister, decided to act unilaterally. On July 20 Turkey ordered a military invasion of the island (Turkish invasion of Cyprus). Within two days Turkish forces had established a narrow corridor linking the north coast with Nicosia. The intervention led to turmoil in Greece. On July 23 the military Junta collapsed.
Two days later formal peace talks were convened in Geneva between Greece, Turkey and Britain. Over the course of the following five days Turkey agreed to halt its advance on the condition that it would remain on the island until a political settlement was reached between the two sides. On August 8 another round of discussion was held in Geneva, Switzerland. Unlike before, this time the talks involved the Greek and Turkish Cypriots. During the discussions the Turkish Cypriots, supported by Turkey, insisted on some form of geographical separation between the two communities. Makarios refused to accept the demand, insisting that Cyprus must remain a unitary state. Despite efforts to break the deadlock, the two sides refused to budge. On August 14, Turkey demanded from Clerides acceptance of a proposal for a federal state, in which the Turkish Cypriot community (who, at that time, comprised about 18% of the population and owned about 10% of the land) would have received 34% of the island. Clerides asked for 36 to 48 hours to consult with the Cypriot and Greek governments, but Turkey refused to grant any consultation time, effectively ending the talks. Within hours, Turkey had resumed its second offensive. By the time a new, and permanent, ceasefire was called 36 per cent of the island was under the control of the Turkish military. The partition was marked by the United Nations Buffer Zone in Cyprus or "green line" running east to west across the island.
The effect of the division was catastrophic for all concerned. Thousands of Greek and Turkish Cypriots had been killed, wounded or missing. A further two hundred thousand Greek and Turkish Cypriots had been displaced. In addition to the entire north coast (Kerynia, Morfou) and the Karpas peninsula, the Greek Cypriots were also forced to flee the eastern port city of Famagusta. The vast majority of the Turkish occupied area was predominantly populated and owned by Greek Cypriots prior to 1974.
In the process about 160,000 - 200,000 Greek Cypriots who made up 82% of the population in the north became refugees; many of them fleeing at the word of the approaching Turkish army. Since 1974, the ceasefire line separates the two communities on the island, and is commonly referred to as the Green Line. The United Nations consented to the transfer of the remainder of the 51,000 Turkish Cypriots that were trapped in the south to settle in the north, if they wished to do so. Many of them had previously moved to the areas under UK sovereign control awaiting permission to be transferred to the areas under Turkish control.
During the operation, EOKA-B committed the massacres of Tohni and Maratha, Santalaris and Aloda.
Peace negotiations, 1974–1994.
1974 Greek Coup d'etat & Turkish Invasion.
After 1967 some hopes arose that a compromise on separate municipalities could be achieved in negotiations between Glafcos Clerides and Rauf Denktaş and certainly agreement came close, but the Makarios government could not accept de jure separateness, which would have denied the principle of the unitary, if bi-communal, state.
Inter-communal strife was also overshadowed during this period by a serious rift on the Greek side, between Makarios and the enosist National Front supported by the Greek junta. Makarios had now become an obstacle to enosis. An attempt was made on his life, and Grivas returned in 1971 to head a new organisation, EOKA-B, with Makarios, rather than the Turkish-Cypriots, in its sight.
Makarios was told from Athens to dismiss his foreign minister and to regard Athens as the National Centre. Makarios rallied supporters successfully against attempts to remove him. He was still popular in Cyprus.
Matters became worse when a new junta came to power in September 1973, and there was less relief from rightist pressure than might have been expected when Grivas died suddenly in January 1974. The pressure mounted until a peace operation in July 1974 allegedly led by a 'hammer of the Turks' Nikos Sampson, overthrew Makarios, who managed to flee the country via a British base. For Turkey this raised the spectre of Greek control of Cyprus.
Turkish Invasion.
The Turkish government therefore now demanded that Greece should dismiss Sampson, withdraw all Greek officers from the island and respect the island's independence. The Greek military government refused. For the United States, Kissinger did not seem to be greatly disturbed by the Sampson coup and looked as if he could accept enosis. Turkish Prime Minister Ecevit's assertiveness in foreign policy, reinforced by his junior coalition partner strongly inclined the Turks to intervene. The British were invited to participate in military operations, under the Treaty of Guarantee, but declined. The American envoy Joseph Sisco tried unsuccessfully to persuade the Greek military government to accept Ecevit's conditions for a Cyprus settlement, which included Turkish-Cypriot control of a coastal region in the north and negotiations for a federal solution. The Soviet Union stood aside not wanting to see enosis, which would strengthen NATO and weaken the left in Cyprus.
Turkey intervened on 20 July 1974, having the right to do so unilaterally as concerted action had not proved possible. Under the 1960 Treaty, Turkey's sole object could be to re-establish the state of affairs guaranteed by the basic articles of the 1960 Constitution. The coup d'état was said by Makarios himself to be an attempt to extend Greek dictatorship to the island.
Launched with relatively few troops, the Turkish landing had limited success at first, and resulted everywhere on the island in the occupation of Turkish-Cypriot enclaves by the Greek forces. After securing a more or less satisfactory bridgehead Turkish forces agreed to a cease-fire on 23 July 1974. The same day civilian government under Karamanlis took office in Athens, the day the Sampson coup collapsed. Glafcos Clerides became the Acting President in absence still of Makarios.
A conference of the guarantor powers, Greece, Turkey and Britain, met in Geneva on 25 July. Meanwhile Turkish troops did not refrain from extending their positions, as more Turkish-Cypriot enclaves were occupied by Greek forces. A new cease-fire line was agreed. On 30 July the powers agreed that the withdrawal of Turkish troops from the island should be linked to a `just and lasting settlement acceptable to all parties concerned'. The declaration also spoke of `two autonomous administrations -that of Greek-Cypriot community and that of the Turkish-Cypriot community'.
Division of the island.
At the second Geneva Conference on 9 August, Turkey pressed for a federal solution to the problem against stiffening Greek resistance. Whilst Turkish Cypriots wanted a bi-zonal federation, Turkey, under American advice, submitted a cantonal plan involving separation of Turkish-Cypriot areas from one another. For security reasons Turkish-Cypriots did not favour cantons. Each plan embraced about thirty-four per cent of the territory.
These plans were presented to the conference on 13 August by the Turkish Foreign Minister, Turan Güneş. Clerides wanted thirty-six to forty-eight hours to consider the plans, but Güneş demanded an immediate response. This was regarded as unreasonable by the Greeks, the British and the Americans who were in close consultation. Nevertheless, the next day, the Turkish forces extended their control to some 36 per cent of the island. they were afraid that delay would turn international opinion strongly against them if Greek spoiling tactics were given a chance and they were determined to come to the rescue of greatly threatened Turkish Cypriots whose enclaves were still occupied by Greek forces. Up to 160,000 Greek-Cypriots went south when the fighting started. Some 50,000 Turkish-Cypriots later (1975) moved north.
Turkey's international reputation suffered as a result of the precipitate move of the Turkish military to extend control to a third of the island. The British Prime Minister regarded the Turkish ultimatum as unreasonable since it was presented without allowing adequate time for study. In Greek eyes the Turkish proposals were submitted in the full awareness that the Greek side could not accept them and reflected the Turkish desire for a military base in Cyprus. The Greek side has gone some way in their proposals by recognising Turkish `groups' of villages and Turkish administrative `areas'. But they stressed that the constitutional order of Cyprus should retain its bi-communal character based on the co-existence of the Greek and Turkish communities within the framework of a sovereign, independent and integral republic. Essentially the Turkish side's proposals were for geographic consolidation and separation and for a much larger measure of autonomy for that area, or those areas, than the Greek side could envisage.
1975–1979.
On April 28, 1975, Kurt Waldheim, the UN Secretary-General, launched a new mission of Good Offices. Starting in Vienna, over the course of the following ten months Clerides and Denktaş held discussed a range of humanitarian issues relating to the events of the previous year. However, attempts to make progress on the substantive issues – such as territory and the nature of the central government – failed to produce any results. After five rounds the talks fell apart in February 1976. In January 1977, the UN managed to organise a meeting in Nicosia between Makarios and Denktaş. This led to a major breakthrough. On February 12, the two leaders signed a four point agreement confirming that a future Cyprus settlement would be based on a federation. The size of the states would be determined by economic viability and land ownership. The central government would be given powers to ensure the unity of the state. Various other issues, such as freedom of movement and freedom of settlement, would be settled through discussion. Just months later, in August 1977, Makarios died. He was replaced by Spyros Kyprianou, the foreign minister.
In May 1979, Waldheim visited Cyprus and secured a further ten-point set of proposals 1979 from the two sides. In addition to re-affirming the 1977 High Level Agreement, these also included provisions for the demilitarisation of the island and a commitment to refrain from destabilising activities and actions. Shortly afterwards a new round of discussions began in Nicosia. Again, they were short lived. For a start, the Turkish Cypriots did not want to discuss Varosha, a resort quarter of Famagusta that had been vacated by Greek-Cypriots when it was overrun by Turkish troops. This was a key issue for the Greek Cypriots. Secondly, the two sides failed to agree on the concept of ‘bicommunality’. The Turkish Cypriots believed that the Turkish Cypriot federal state would be exclusively Turkish Cypriot and the Greek Cypriot state would be exclusively Greek Cypriots. The Greek Cypriots believed that the two states should be predominantly, but not exclusively, made up of a particular community.
Turkish Cypriots' Unilateral Declaration of Independence.
In May 1983, an effort by Javier Pérez de Cuéllar, the then UN Secretary-General, foundered after the United Nations General Assembly passed a resolution calling for the withdrawal of all occupation forces from Cyprus. The Turkish Cypriots were furious at the resolution. They threatened to declare independence in retaliation. Despite this, in August, Pérez de Cuéllar gave the two sides a set of proposals for consideration that called for a rotating presidency, the establishment of a bicameral assembly along the same lines as previously suggested and 60:40 representation in the central executive. In return for increased representation in the central government, the Turkish Cypriots would surrender 8–13 per cent of the land in their possession. Both Kyprianou and Denktaş accepted the proposals. However, on 15 November 1983, the Turkish Cypriots took advantage of the post-election political instability in Turkey and unilaterally declared independence. Within days the Security Council passed a resolution, no.541 (13-1 vote: only Pakistan opposed) making it clear that it would not accept the new state and that the decision disrupted efforts to reach a settlement. Denktaş denied this. In a letter addressed to the Secretary-General informing him of the decision, he insisted that the move guaranteed that any future settlement would be truly federal in nature. Although the ‘Turkish Republic of Northern Cyprus’ (TRNC) was soon recognised by Turkey, the rest of the international community condemned the move. The Security Council passed another resolution, no.550 (13-1 vote: again only Pakistan opposed) condemning the "purported exchange of ambassadors between Turkey and the Turkish Cypriot leadership..."
In September 1984 talks resumed. After three rounds of discussions it was again agreed that Cyprus would become a bi-zonal, bi-communal, non-aligned federation. The Turkish Cypriots would retain 29 per cent for their federal state and all foreign troops would leave the island. In January 1985, the two leaders met for their first face-to-face talks since the 1979 agreement. However, while the general belief was that the meeting was being held to agree to a final settlement, Kyprianou insisted that it was a chance for further negotiations. The talks collapsed. In the aftermath, the Greek Cypriot leaders came in for heavy criticism, both at home and abroad. After that Denktaş announced that he would not make so many concessions again. Undeterred, in March 1986, de Cuéllar presented the two sides with a Draft Framework Agreement. Again, the plan envisaged the creation of an independent, non-aligned, bi-communal, bi-zonal state in Cyprus. However, the Greek Cypriots were unhappy with the proposals. They argued that the questions of removing Turkish forces from Cyprus was not addressed, nor was the repatriation of the increasing number of Turkish settlers on the island. Moreover, there were no guarantees that the full three freedoms would be respected. Finally, they saw the proposed state structure as being confederal in nature. Further efforts to produce an agreement failed as the two sides remained steadfastly attached to their positions.
The "Set of Ideas".
In August 1988, Pérez de Cuéllar called upon the two sides to meet with him in Geneva in August. There the two leaders - George Vasiliou and Rauf Denktaş - agreed to abandon the Draft Framework Agreement and return to the 1977 and 1979 High Level Agreements. However, the talks faltered when the Greek Cypriots announced their intention to apply for membership within the European Community (EC), a move strongly opposed by the Turkish Cypriots and Turkey. Nevertheless, in June 1989, de Cuellar presented the two communities with the 'Set of Ideas'. Denktaş quickly rejected them as he not only opposed the provisions, he also argued that the UN Secretary-General had no right to present formal proposals to the two sides. The two sides met again, in New York, in February 1990. However, the talks were again short lived. This time Denktaş demanded that the Greek Cypriots recognise the existence of two peoples in Cyprus and the basic right of the Turkish Cypriots to self-determination.
On 4 July 1990, Cyprus formally applied to join the EC. The Turkish Cypriots and Turkey, which had applied for membership in 1987, were outraged. Denktaş claimed that Cyprus could only join the Community at the same time as Turkey and called off all talks with UN officials. Nevertheless, in September 1990, the EC member states unanimously agreed to refer the Cypriot application to the Commission for formal consideration. In retaliation, Turkey and the TRNC signed a joint declaration abolishing passport controls and introducing a customs union just weeks later. Undeterred, Javier Pérez de Cuéllar continued his search for a solution throughout 1991. He made no progress. In his last report to the Security Council, presented in October 1991 under United Nations Security Council Resolution 716, he blamed the failure of the talks on Denktaş, noting the Turkish Cypriot leader's demand that the two communities should have equal sovereignty and a right to secession.
On 3 April 1992, Boutros Boutros-Ghali, the new UN Secretary-General, presented the Security Council with the outline plan for the creation of a bi-zonal, bi-communal federation that would prohibit any form of partition, secession or union with another state. While the Greek Cypriots accepted the Set of Ideas as a basis for negotiation, Denktaş again criticised the UN Secretary-General for exceeding his authority. When he did eventually return to the table, the Turkish Cypriot leader complained that the proposals failed to recognise his community. In November, Ghali brought the talks to a halt. He now decided to take a different approach and tried to encourage the two sides to show goodwill by accepting eight confidence building measures (CBMs). These included reducing military forces on the island, transferring Varosha to direct UN control, reducing restrictions on contacts between the two sides, undertaking an island-wide census and conducting feasibility studies regarding a solution. The Security Council endorsed the approach.
On 24 May 1993, the Secretary-General formally presented the two sides with his CBMs. Denktaş, while accepting some of the proposals, was not prepared to agree to the package as a whole. Meanwhile, on June 30, the European Commission returned its opinion on the Cypriot application for membership. While the decision provided a ringing endorsement of the case for Cypriot membership, it refrained from opening the way for immediate negotiations. The Commission stated that it felt that the issue should be reconsidered in January 1995, taking into account "the positions adopted by each party in the talks". A few months later, in December 1993, Glafcos Clerides proposed the demilitarisation of Cyprus. Denktaş dismissed the idea, but the next month he announced that he would be willing to accept the CBMs in principle. Proximity talks started soon afterwards. In March 1994, the UN presented the two sides with a draft document outlining the proposed measures in greater detail. Clerides said that he would be willing to accept the document if Denktaş did, but the Turkish Cypriot leader refused on the grounds that it would upset the balance of forces on the island. Once again, Ghali had little choice but to pin the blame for another breakdown of talks on the Turkish Cypriot side. Denktas would be willing to accept mutually agreed changes, but Clerides refused to negotiate any further changes to the March proposals. Further proposals put forward by the Secretary-General in an attempt to break the deadlock were rejected by both sides.
Deadlock and legal battles, 1994–97.
At the Corfu European Council, held on 24–25 June 1994, the EU officially confirmed that Cyprus would be included in the Union's next phase of enlargement. Two weeks later, on July 5, the European Court of Justice imposed restrictions on the export of goods from Northern Cyprus into the European Union. Soon afterwards, in December, relations between the EU and Turkey were further damaged when Greece blocked the final implementation of a customs union. As a result, talks remained completely blocked throughout 1995 and 1996. The situation took another turn for the worse at the start of 1997 when the Greek Cypriots announced that they intended to purchase the Russian-made S-300 anti-aircraft missile system. Soon afterwards, Turkey announced that it would match any military build-up. However, Turkey was now starting to come under increasing pressure from several sides. In December 1996, the European Court of Human Rights (ECHR) delivered a landmark ruling that declared that Turkey was an occupying power in Cyprus. The case - Loizidou vs Turkey - centred on Titina Loizidou, a refugee from Kyrenia, who was judged to have been unlawfully denied the control of her property by Turkey. In addition to being a major political embarrassment for Ankara, the case also had severe financial implications as the Court later ruled that Turkey should pay Mrs Loizidou US$825,000 in compensation for the loss of use of her property. Ankara rejected the ruling as politically motivated.
EU accession and the settlement process, 1997–present.
In 1997 the basic parameters of the Cyprus Dispute changed. A decision by the European Union to open up accession negotiations with the Republic of Cyprus created a new catalyst for a settlement. Among those who supported the move, the argument was made that Turkey could not have a veto on Cypriot accession and that the negotiations would encourage all sides to be more moderate. However, opponents of the move argued that the decision would remove the incentive of the Greek Cypriots to reach a settlement. They would instead wait until they became a member and then use this strength to push for a settlement on their terms. In response to the decision, Rauf Denktaş announced that he would no longer accept federation as a basis for a settlement. In the future he would only be prepared to negotiate on the basis of a confederal solution. In December 1999 tensions between Turkey and the European Union eased somewhat after the EU decided to declare Turkey a candidate for EU membership, a decision taken at the Helsinki European Council. At the same time a new round of talks started in New York. These were short lived. By the following summer they had broken down. Tensions started to rise again as a showdown between Turkey and the European Union loomed over the island's accession.
Perhaps realising the gravity of the situation, and in a move that took observers by surprise, Rauf Denktaş wrote to Glafcos Clerides on 8 November 2001 to propose a face-to-face meeting. The offer was accepted. Following several informal meetings between the two men in November and December 2001 a new peace process started under UN auspices on 14 January 2002. At the outset the stated aim of the two leaders was to try to reach an agreement by the start of June that year. However, the talks soon became deadlocked. In an attempt to break the impasse, Kofi Annan, the UN Secretary-General visited the island in May that year. Despite this no deal was reached. After a summer break Annan met with the two leaders again that autumn, first in Paris and then in New York. As a result of the continued failure to reach an agreement, the Security Council agreed that the Secretary-General should present the two sides with a blueprint settlement. This would form the basis of further negotiations. The original version of the UN peace plan was presented to the two sides by Annan on 11 November 2002. A little under a month later, and following modifications submitted by the two sides, it was revised (Annan II). It was hoped that this plan would be agreed by the two sides on the margins of the European Council, which was held in Copenhagen on December 13. However, Rauf Denktaş, who was recuperating from major heart surgery, declined to attend. The EU therefore decided to confirm that Cyprus would join the EU on 1 May 2004, along with Malta and eight other states from Central and Eastern Europe.
Although it had been expected that talks would be unable to continue, discussions resumed in early January 2003. Thereafter, a further revision (Annan III) took place in February 2003, when Annan made a second visit to the island. During his stay he also called on the two sides to meet with him again the following month in The Hague, where he would expect their answer on whether they were prepared to put the plan to a referendum. While the Greek Cypriot side, which was now led by Tassos Papadopoulos, agreed to do so, albeit reluctantly, Rauf Denktaş refused to allow a popular vote. The peace talks collapsed. A month later, on 16 April 2003, Cyprus formally signed the EU Treaty of Accession at a ceremony in Athens.
Throughout the rest of the year there was no effort to restart talks. Instead, attention turned to the Turkish Cypriot elections, which were widely expected to see a victory by moderate pro-solution parties. In the end, the assembly was evenly split. A coalition administration was formed that brought together the pro-solution CTP and the Democrat Party, which had traditionally taken the line adopted by Rauf Denktaş. This opened the way for Turkey to press for new discussions. After a meeting between Recep Tayyip Erdoğan and Kofi Annan in Switzerland, the leaders of the two sides were called to New York. There they agreed to start a new negotiation process based on two phases: phase one, which would just involve the Greek and Turkish Cypriots, being held on the island and phase two, which would also include Greece and Turkey, being held elsewhere. After a month of negotiations in Cyprus, the discussions duly moved to Burgenstock, Switzerland. The Turkish Cypriot leader Rauf Denktaş rejected the plan outright and refused to attend these talks. Instead, his son Serdar Denktaş and Mehmet Ali Talat attended in his place. There a fourth version of the plan was presented. This was short-lived. After final adjustments, a fifth and final version of the Plan was presented to the two sides on 31 March 2004.
The UN plan for settlement (Annan Plan).
Under the final proposals, the Republic of Cyprus would become the United Cyprus Republic. It would be a loose federation composed of two component states. The northern Turkish Cypriot constituent state would encompass about 28.5% of the island, the southern Greek Cypriot constituent state would be made up of the remaining 71.5%. Each part would have had its own parliament. There would also be a bicameral parliament on the federal level. In the Chamber of Deputies, the Turkish Cypriots would have 25% of the seats. (While no accurate figures are currently available, the split between the two communities at independence in 1960 was approximately 80:20 in favour of the Greek Cypriots.) The Senate would consist of equal parts of members of each ethnic group. Executive power would be vested in a presidential council. The chairmanship of this council would rotate between the communities. Each community would also have the right to veto all legislation.
One of the most controversial elements of the plan concerned property. During Turkey's military intervention/invasion in 1974, many Greek Cypriots (who owned 90% of the land and property in the north) were forced to abandon their homes. (A large number of Turkish Cypriots also left their homes.) Since then, the question of restitution of their property has been a central demand of the Greek Cypriot side. However, the Turkish Cypriots argue that the complete return of all Greek Cypriot properties to their original owners would be incompatible with the functioning of a bi-zonal, bi-communal federal settlement. To this extent, they have argued compensation should be offered. The Annan Plan attempted to bridge this divide. In certain areas, such as Morphou (Güzelyurt) and Famagusta (Gazimağusa), which would be returned to Greek Cypriot control, Greek Cypriot refugees would have received back all of their property according to a phased timetable. In other areas, such as Kyrenia (Girne) and the Karpass Peninsula, which would remain under Turkish Cypriot control, they would be given back a proportion of their land (usually one third assuming that it had not been extensively developed) and would receive compensation for the rest. All land and property (that was not used for worship) belonging to businesses and institutions, including the Church the largest property owner on the island, would have been expropriated. While many Greek Cypriots found these provisions unacceptable in themselves, many others resented the fact that the Plan envisaged all compensation claims by a particular community to be met by their own side. This was seen as unfair as Turkey would not be required to contribute any funds towards the compensation.
Apart from the property issue, there were many other parts of the plan that sparked controversy. For example, the agreement envisaged the gradual reduction in the number of Greek and Turkish troops on the island. After six years, the number of soldiers from each country would be limited to 6,000. This would fall to 600 after 19 years. Thereafter, the aim would be to try to achieve full demilitarisation, a process that many hoped would be made possible by Turkish accession to the European Union. The agreement also kept in place the Treaty of Guarantee - an integral part of the 1960 constitution that gave Britain, Greece and Turkey a right to intervene militarily in the island's affairs. Many Greek Cypriots were concerned that the continuation of the right of intervention would give Turkey too large a say in the future of the island. However, most Turkish Cypriots felt that a continued Turkish military presence was necessary to ensure their security. Another element of the plan the Greek Cypriots objected to was that it allowed many Turkish citizens who had been brought to the island to remain. (The exact number of these Turkish 'settlers' is highly disputed. Some argue that the figure is as high as 150,000 or as low as 40,000. They are seen as settlers illegally brought to the island in contravention of international law. However, while many accepted Greek Cypriot concerns on this matter, there was a widespread feeling that it would be unrealistic to forcibly remove every one of the these settlers, especially as many of them had been born and raised on the island.)
Referenda, 24 April 2004.
Under the terms of the plan, the Annan plan would only come into force if accepted by the two communities in simultaneous referendums. These were set for 24 April 2004. In the weeks that followed there was intense campaigning in both communities. However, and in spite of opposition from Rauf Denktaş, who had boycotted the talks in Switzerland, it soon became clear that the Turkish Cypriots would vote in favour of the agreement. Among Greek Cypriots opinion was heavily weighted against the plan. Tassos Papadopoulos, the president of Cyprus, in a speech delivered on 7 April called on Greek Cypriots to reject the plan. His position was supported by the centrist Diko party and the socialists of EDEK as well as other smaller parties. His major coalition partner AKEL, one of the largest parties on the island, chose to reject the plan bowing to the wishes of the majority of the party base. Support for the plan was voiced by Democratic Rally (DISY) leadership, the main right-wing party, despite opposition to the plan from the majority of party followers, and the United Democrats, a small centre-left party led by George Vasiliou, a former president. Glafcos Clerides, now retired from politics, also supported the plan. Prominent members of DISY who did not support the Annan plan split from the party and openly campaigned against it. The Greek Cypriot Church also opposed the plan in line with the views of the majority of public opinion.
The United Kingdom (a Guarantor Power) and the United States came out in favour of the plan. Turkey signalled its support for the plan. The Greek Government decided to remain neutral. However, Russia was troubled by an attempt by Britain and the US to introduce a resolution in the UN Security Council supporting the plan and used its veto to block the move. This was done as they felt that Britain and the US were trying to put unfair pressure on the Greek Cypriots.
In the 24 April referendum the Turkish Cypriots endorsed the plan by a margin of almost two to one. However, the Greek Cypriots resoundingly voted against the plan, by a margin of about three to one.
The Cyprus Dispute after the referendum.
On 1 May 2004, a week after the referendum, Cyprus joined the European Union. Under the terms of accession the whole island is considered to be a member of the European Union. However, the terms of the "acquis communautaire", the EU's body of laws, have been suspended in the Northern Cyprus.
After the referendum, in June 2004, Northern Cyprus became an "observer member" country of Organisation of Islamic Countries under the name Turkish Cypriot State. 
Despite initial hopes that a new process to modify the rejected plan would start by autumn, most of the rest of 2004 was taken up with discussions over a proposal by the European Union to open up direct trade with the Turkish Cypriots and provide €259,000,000 in funds to help them upgrade their infrastructure. This has provoked considerable debate. The Republic of Cyprus has argued that there can be no direct trade via ports and airports in Northern Cyprus as these are unrecognised. Instead, it has offered to allow Turkish Cypriots to use Greek Cypriot facilities, which are internationally recognised. This has been rejected by the Turkish Cypriots. At the same time, attention turned to the question of the start of Turkey's future membership of the European Union. At a European Council held on 17 December 2004, and despite earlier Greek Cypriot threats to impose a veto, Turkey was granted a start date for formal membership talks on condition that it signed a protocol extending the customs union to the new entrants to the EU, including Cyprus. Assuming this is done, formal membership talks would begin on 3 October 2005.
Following the defeat of the UN plan in the referendum there has been no attempt to restart negotiations between the two sides. While both sides have reaffirmed their commitment to continuing efforts to reach an agreement, the UN Secretary-General has not been willing to restart the process until he can be sure that any new negotiations will lead to a comprehensive settlement based on the plan he put forward in 2004. To this end, he has asked the Greek Cypriots to present a written list of the changes they would like to see made to the agreement. This was rejected by President Tassos Papadopoulos on the grounds that no side should be expected to present their demands in advance of negotiations. However, it appears as though the Greek Cypriots would be prepared to present their concerns orally. Another Greek Cypriot concern centres on the procedural process for new talks. Mr. Papadopoulos said that he will not accept arbitration or timetables for discussions. The UN fears that this would lead to another open-ended process that could drag on indefinitely.
In October 2012, Northern Cyprus became an "observer member" country of Economic Cooperation Organization under the name Turkish Cypriot State.
Formula One and the Cyprus Dispute.
The podium display after the 2006 Turkish Grand Prix caused a controversy, when winner Felipe Massa received the trophy from Mehmet Ali Talat, who was referred to as the "President of the Turkish Republic of Northern Cyprus." The government of the Republic of Cyprus filed an official complaint with the FIA. After investigating the incident, the FIA fined the organisers of the Grand Prix $5 million on 19 September 2006. The Turkish Motorsports Federation (TOSFED) and the organisers of the Turkish Grand Prix (MSO) agreed to pay half the fined sum pending an appeal to be heard by the FIA International Court of Appeal on November 7, 2006. TOSFED insisted the move was not planned and that Mehmet Ali Talat did fit FIA's criteria for podium presentations as a figure of world standing. Keen to repair their impartiality in international politics, FIA stood their ground forcing the appeal to be withdrawn.
2008 Elections in the Republic of Cyprus.
In the 2008 presidential elections, Papadopoulos was defeated by AKEL candidate Dimitris Christofias, who pledged to restart talks on reunification immediately. Speaking on the election result, Mehmet Ali Talat stated that "this forthcoming period will be a period during which the Cyprus problem can be solved within a reasonable space of time – despite all difficulties – provided that there is will". Christofias held his first meeting as president with the Turkish Cypriot leader on 21 March 2008 in the UN buffer zone in Nicosia. At the meeting, the two leaders agreed to launch a new round of "substantive" talks on reunification, and to reopen Ledra Street, which has been cut in two since the intercommunal violence of the 1960s and has come to symbolise the island's division. On 3 April 2008, after barriers had been removed, the Ledra Street crossing was reopened in the presence of Greek and Turkish Cypriot officials.
New negotiations.
A first meeting of the technical committees was set to take place on 18 April 2008. Talat and Christofias met socially at a cocktail party on 7 May 2008, and agreed to meet regularly to review the progress of the talks so far. A second formal summit was held on 23 May 2008 to review the progress made in the technical committees.
At a meeting on 1 July 2008, the two leaders agreed in principle on the concepts of a single citizenship and a single sovereignty, and decided to start direct reunification talks very soon; on the same date, former Australian foreign minister Alexander Downer was appointed as the new UN envoy for Cyprus. Christofias and Talat agreed to meet again on 25 July 2008 for a final review of the preparatory work before the actual negotiations would start. Christofias was expected to propose a rotating presidency for the united Cypriot state. Talat stated he expected they would set a date to start the talks in September, and reiterated that he would not agree to abolishing the guarantor roles of Turkey and Greece.
After the conclusion of negotiations, a reunification plan would be put to referendums in both communities.
In December 2008, the Athenian socialist daily newspaper "To Vima" described a "crisis" in relations between Christofias and Talat, with the Turkish Cypriots beginning to speak openly of a loose "confederation", an idea strongly opposed by South Nicosia. Tensions were further exacerbated by Turkey's harassment of Cypriot vessels engaged in oil exploration in the island's Exclusive Economic Zone, and by the Turkish Cypriot leadership's alignment with Ankara's claim that Cyprus has no continental shelf.
On 29 April 2009, Talat stated that if the Court of Appeal of England and Wales (that will put the last point in the Orams' case) makes a decision just like in the same spirit with the decision of European Court of Justice (ECJ) then the Negotiation Process in Cyprus will be damaged in such a way that it will never be repaired once more. The European Commission warned the Republic of Cyprus not to turn Orams' case legal fight to keep their holiday home into a political battle over the divided island.
On 31 January 2010, United Nations Secretary-General Ban Ki-moon arrived in Cyprus to accelerate talks aimed at reuniting the country.
The election of nationalist Derviş Eroğlu of the National Unity Party as president in Northern Cyprus on April 18 is expected to complicate reunification negotiations. Talks were resumed after the elections in late May, however, and Eroǧlu stated on 27 May 2010 he was now also in favour of a federal state, a change from his previous positions.
In early June 2010, talks reached an impasse and UN Special Advisor Alexander Downer called on the two leaders to decide whether they wanted a solution or not.
On 18 November 2010, 1st tripartite meeting (Ban, Christofias, Eroglu) occurred in New York, US without any agreement over the main issues.
On 26 January 2011, 2nd tripartite meeting (Ban, Christofias, Eroglu) occurred in Geneva, Switzerland without any agreement over the main issues.
On March 2011, United Nations Secretary-General Ban Ki-moon reported, "The negotiations cannot be an open-ended process, nor can we afford interminable talks for the sake of talks".
On 18 March 2011, Greek Cypriots and Turkish Cypriots realised 100th negotiation since April 2008 without any agreement over the main issues.
By mid-2011, there was a renewed push for an end to negotiations by the end of 2011 in order to have a united Cyprus take over the EU presidency on 1 July 2012.
On 7 July 2011, the 3rd tripartite meeting (Ban, Christofias, Eroglu) occurred in Geneva, Switzerland without any agreement over the main issues.
On 30–31 October 2011, the 4th tripartite meeting (Ban, Christofias, Eroglu) occurred in New York, US without any agreement over the main issues. Ban said that the talks are coming to an end.
On 23–24 January 2012, the 5th tripartite meeting (Ban, Christofias, Eroglu) occurred in New York, US without any agreement over the main issues. Ban said "I will be providing a report to the Security Council on the status of the negotiations at the end of February. At the end of March, I will seek a review of the process from my Special Adviser, Alexander Downer. If his report is positive, consistent with relevant Security Council resolutions and following consultations with the two sides, I intend to call a multilateral conference in late April or early May".
On 21 April 2012, United Nations Secretary-General Ban Ki-moon said "there is not enough progress on core issues of reunification talks for calling an international conference". International observers qualified the situation as the "collapse of reunification talks", "last chance for Cyprus reunification lost", "UN-led rounds of talks have failed" and the "failure of UN Cyprus campaign for reunification". On 27 April 2012, Special Advisor of the Secretary-General Alexander Downer said "If the Greek Cypriot and Turkish Cypriot Leaders cannot agree with each other on a model for a united Cyprus, then United Nations cannot make them".
At the end of September 2012, Turkish Republic of Northern Cyprus President Dervis Eroglu said that joint committees with the Greek Cypriot side had been set up to take confidence-building measures.
In 2012, the European Union(EU)-funded project "Reconciliationand Peace Economics in Cyprus" found that "There was little hope for a settlement in the island and the UN-sponsored talks again failed".
Opinion on solutions.
A number of observers increasingly suggest partition is the best solution.
An international panel of legal experts proposed the “creation of a Constitutional Convention under European Union auspices and on the basis of the 1960 Cyprus Constitution to bring together the parties directly concerned in order to reach a settlement in conformity with the Fundamental Principles.”
Class action.
Greek Cypriots, et al. v. TRNC and HSBC Bank USA is a pending class action suit by Greek Cypriots and others against the TRNC Representative Offices in the United States and HSBC Bank USA. The TRNC Representative Offices are a commercial entity because the United States does not formally recognise the "Turkish Republic of Northern Cyprus". The staff of the Representative Offices do not have diplomatic visas and only operate within the United States using business visas. Tsimpedes Law in Washington DC is suing for "the denial of access to and enjoyment of land and property held in the north". The lawsuit, originally initiated by Cypriots displaced during the Turkish invasion of Cyprus in 1974, has been joined by non-Cypriots who paid for but have never been given legal title to properties that they have purchased.
External links.
Documentaries

East Germany
The German Democratic Republic (GDR; German: "Deutsche Demokratische Republik" or "DDR"), informally known in English as East Germany, was a socialist state established by the Soviet Union in 1949 out of the Soviet zone of occupied Germany, including East Berlin of the Allied-occupied capital city. The GDR had an area of 107,771 km2 (41,610 mi2), bordering Czechoslovakia to the south, West Germany to the south and west, Poland to the east, and the Baltic Sea to the north. East Germany ceased to exist when its federal states were re-established and acceded to the Federal Republic of Germany on 3 October 1990 (see German reunification).
The GDR had a complex and controversial history. While the Western government, which acknowledged itself as the legal successor to the Third Reich, was regarded by the East as nothing other than an extension of the old Nazi regime, those who opposed the East regarded it as a puppet state for the Soviet Union. During the years of Nazi control, it was taught that Russians, along with all Slavic peoples, were ""Untermenschen"" – or ""sub-human"". Because of this, some East Germans saw the Soviet occupation of their country as shameful and regarded the new regime with contempt. The Socialist Unity Party, formed out of the merging of the Communist Party and the Social Democratic Party, was often referred to by such people as the "Russian Party". The combination of the state's perceived illegitimacy by some East Germans and post-war economic problems resulted in 2.7 million East Germans violating the GDR ban on leaving the country by going to West Germany in the 1950s. Frontier barriers were constructed to prevent further depopulation caused by emigration to West Germany, the most prominent of which being the Anti-Fascist Protection Wall – commonly known as the "Berlin Wall" – constructed in 1961, which finally closed the loop hole in the GDR border between East Berlin and West Berlin.
In 1989, a non-violent movement called for the end of German division and for the expansion of civil liberties. A border security crisis ensued resulting in many GDR citizens emigrating through Czechoslovakia and Hungary. The Soviet Union, under the reformist leadership of Mikhail Gorbachev, refused to intervene on the basis of his policy to de-escalate the Cold War and let East Germany resolve its own crisis. On 9 November, destruction of the Berlin Wall began. On 3 October 1990, the five states of the German Democratic Republic joined the Federal Republic of Germany, ending over 40 years of division and becoming a single Germany.
Naming conventions.
The official name was "Deutsche Demokratische Republik" (German Democratic Republic), usually abbreviated as "DDR". Both terms were used in East Germany with an increasing emphasis on the abbreviated name, especially since East Germany considered West Germans and West Berliners to be foreigners following the promulgation of its second constitution in 1968.
"Ostzone" (Eastern Zone) or "Soviet Zone" were two surrogate names for East Germany that were often used colloquially. The different names used to describe the German Democratic Republic reflected political positions during the Cold War conflict; for example, many Westerners doubted the political sovereignty and democratic constitution of East Germany. Surrogate name usage for East Germany could thus reveal the political leaning of a person or news source. So the media controlled by the East German government emphasised the use of the official name, DDR, while West Germans, western media and statesmen may have used other names such as Middle Germany, emphasising the location of East Germany in the centre of pre-1937 Germany.
The name Sowjetische Besatzungszone (Soviet Occupation Zone, often abbreviated to SBZ) was used by those who wanted to indicate that East Germany lacked sovereignty, whereas others used "Ostzone" or "der Osten" ("Eastern Zone" or "the East") to avoid the actual name of the state. The latter term, because it was based plainly on geographic location, was sometimes also used by East Germans. Some West German media referred to East Germany initially as the "SBZ" and later consistently named it the "so-called "GDR"" (sogenannte "DDR").
However, over time East Germany's abbreviation "DDR" became colloquial also among most West Germans and West German media. "Ostdeutschland" (an ambiguous term meaning simultaneously East or Eastern Germany) was not commonly used in East or West German common parlance to refer to the German Democratic Republic, because "Ostdeutschland" usually referred to the former eastern territories of Germany.
The term "Westdeutschland" (West Germany) when used by West Germans was almost always a reference to the geographic region of Western Germany but not to the area within the boundaries of the Federal Republic of Germany. However, this usage was not always consistent, as, for example, West Berliners frequently applied the term "Westdeutschland" to denote the Federal Republic.
History.
Explaining the internal impact of the DDR regime from the perspective of German history in the long term, historian Gerhard A. Ritter (2002) has argued that the East German state was defined by two dominant forces – Soviet Communism on the one hand, and German traditions filtered through the interwar experiences of German Communists on the other. It always was constrained by the powerful example of the increasingly prosperous West, to which East Germans compared their nation. The changes wrought by the Communists were most apparent in ending capitalism and transforming industry, agriculture, in the militarization the society, and the political thrust of the educational system and the media. On the other hand, there was relatively little change made in the historically independent domains of the sciences, the engineering professions, the Protestant churches, and in many bourgeois life styles. Social policy, says Ritter, became a critical legitimization tool in the last decades and mixed socialist and traditional elements about equally.
Origins.
At the Yalta Conference during World War II, the Allies (the U.S., Britain, and the Soviet Union) agreed on dividing a defeated Germany into occupation zones, and on dividing Berlin, the German capital, among the Allied powers as well. Initially this meant the construction of three zones of occupation, i.e., American, British, and Soviet. Later, a French zone was carved out of the American and British zones.
GDR created 1949.
The ruling Communist party, known as the "Socialist Unity Party" (SED), was formed in April 1946 from the merger between the German Communist Party (KPD) and the Social Democratic Party of Germany (SPD) by mandate of Joseph Stalin. The two former parties were notorious rivals when they were active before the Nazis consolidated all power and criminalised their agitation. The unification of the two parties was symbolic of the new friendship of German socialists in defeating their common enemy, however, Communists who made a majority had virtually total control over policy. As Walter Ulbricht noted, everything was made to look democratic while in reality Communists retained control in the background. They were totally loyal to Stalin, and realized their regime would collapse if it lost the backing of the Soviet army—as indeed happened in 1989. Historians debate whether the decision to form a separate country was initiated by Stalin or by the SED.
As West Germany was reorganized and gained independence from the occupation, the German Democratic Republic was established in East Germany in 1949. The creation of the two states made the 1945 division of Germany permanent. On 10 March 1952, (in what would become known as the "Stalin Note") Stalin put forth a proposal to reunify Germany with a policy of neutrality, with no conditions on economic policies and with guarantees for "the rights of man and basic freedoms, including freedom of speech, press, religious persuasion, political conviction, and assembly" and free activity of democratic parties and organizations. However, leadership of West Germany saw reunification as a rather abstract goal. Western powers chose to decline on this proposal, due to belief that Germany should be able to join NATO and that such a negotiation with the Soviet Union would be seen as a capitulation. Afterwards, there had been several debates about whether a real chance for reunification had been missed in 1952.
In 1949 the Soviets turned control of East Germany over to the Socialist Unity Party, headed by Wilhelm Pieck (1876–1960), who became president of the GDR and remained officially 'Number One' until his death in 1960, while most executive authority was assumed by SED General Secretary Walter Ulbricht. Socialist leader Otto Grotewohl (1894–1964) became prime minister until his death. In a major speech to an SED party conference on 28 March 1956, Grotewohl condemned abuses in the legal system. He denounced illegal arrests, called for more respect for civil rights, and even asked the parliament to develop lively debate.
West Germany saw itself as the legal successor to the Third Reich, shouldering the burdens of legal responsibility for its crimes. By contrast, East Germany renounced ties to the Nazi past, styling itself the "anti-fascist rampart" and proclaiming itself the first socialist state on German soil. It refused to admit existences of anti-semitism and refused to recognize Israel or reimburse victims of the Holocaust. The SED set a primary goal of ridding the GDR of all traces of the fascist regime, by ensuring democratic elections and the protection of individual liberties in the building up socialism.
Soviet role.
In 1955, the USSR declared the Soviet occupation zone – the historic middle portion of Germany – to be a sovereign state named the "Deutsche Demokratische Republik" (German Democratic Republic, established in 1949), while the Red Army and the Western Allies' occupation forces remained in place under the tripartite Potsdam Agreement (1945) which established the Allied Occupation of Germany.
The Communist German Democratic Republic was established in the historic "Mitteldeutschland" (Middle Germany). Former German territories east of the Oder and Neisse rivers, mainly the Prussian provinces of Pomerania, East Prussia, West Prussia, Upper Silesia, Lower Silesia, the eastern Neumark of Brandenburg, and a small piece of Saxony were thus detached from Germany. To compensate Poland for the USSR's annexation of its eastern provinces, the Allies provisionally established Poland's post-war western border at the Oder–Neisse line at the Yalta Conference (1945). As a result, most of Germany's central territories became the "Sowjetische Besatzungszone" (SBZ, Soviet Occupation Zone). All other lands east of the Oder–Neisse line were put under Polish administration, with the exception of historic northern East Prussia, which went to the USSR.
Zones of occupation.
In the Yalta and Potsdam conferences, the Allies established their joint military occupation and administration of Germany via the Allied Control Council (ACC), a four-power (US, UK, USSR, France) military government effective until the restoration of German sovereignty. In eastern Germany, the Soviet Occupation Zone (SBZ – "Sowjetische Besatzungszone") comprised the five states ("Länder") of Mecklenburg-Vorpommern, Brandenburg, Saxony, Saxony-Anhalt, and Thuringia. Disagreements over the policies to be followed in the occupied zones quickly led to a breakdown in cooperation between the four powers, and the Soviets administered their zone without regard to the policies implemented in the other zones. The Soviets withdrew from the ACC in 1948; subsequently as the other three zones were increasingly unified and granted self-government, the Soviet administration facilitated the development of a separate socialist government in its zone.
Yet, seven years after the Allies’ Potsdam Agreement to a unified Germany, the USSR via the Stalin Note (10 March 1952) proposed German reunification and superpower disengagement from Central Europe, which the three Western Allies (US, France, UK) rejected. Soviet leader Joseph Stalin, a communist proponent of reunification, was dead by March 1953. Similarly, Lavrenty Beria, the First Deputy Prime Minister of the USSR, pursued German reunification, but an internal (Party) "coup d’étât" deposed him from government in mid-1953, before he could act on the matter. His successor, Nikita Khrushchev, rejected reunification as equivalent to returning East Germany for annexation to the West; hence reunification went unconsidered until the German Democratic Republic collapsed in 1989.
East Germany and the Eastern Bloc diplomatically recognised East Berlin as the capital city of the German Democratic Republic, but the Western Allies disputed said recognition, considering the entire city of Berlin an occupied territory governed by the martial law of the Allied Control Council. According to Margarete Feinstein, East Berlin's status as the capital was largely unrecognized by the West and most Third World countries. In practice, the ACC’s authority was rendered moot by the Cold War, and the East German government ignored the legal restrictions on integration of East Berlin into the GDR.
Abetted by ACC’s weakness, Cold War political conflicts among the Allies over the status of West Berlin provoked the Berlin Blockade (24 June 1948 – 12 May 1949), in which the Soviet army stopped all Allied rail, road, and water traffic to and from West Berlin. The Allies countered the Soviets with the Berlin Airlift (1948–49) of food, fuel, and supplies to keep West Berlin alive.
Partition.
In 1946, the Communist Party of Germany ("Kommunistische Partei Deutschlands" – KPD) and the Social Democratic Party of Germany ("Sozialdemokratische Partei Deutschlands" – SPD) merged to form the Socialist Unity Party of Germany (SED – "Sozialistische Einheitspartei Deutschlands") (21 April 1945), which then won the elections of 1946, held under the oversight of the Soviet army. Being a Marxist-Leninist political party, the SED's government nationalised infrastructure and industrial plants.
In 1948, the German Economic Commission (Deutsche Wirtschaftskomission—DWK) under its chairman Heinrich Rau assumed administrative authority in the Soviet occupation zone, thus becoming the predecessor of an East German government.
On 7 October 1949, the SED established the "Deutsche Demokratische Republik" (German Democratic Republic – GDR), based on a socialist political constitution establishing its control of the anti-fascist National Front of the German Democratic Republic (NF – "Nationale Front der Deutschen Demokratischen Republik"), an omnibus alliance of every party and mass organisation in East Germany. The NF was established to stand for election to the "Volkskammer" ("People's Chamber"), the East German parliament. The first (and only) President of the German Democratic Republic was Wilhelm Pieck. However, after 1950, the true ruler of East Germany was Walter Ulbricht, the First Secretary of the SED.
On 16 June 1953, workers constructing the new "Stalinallee" boulevard in East Berlin rioted against a 10% production quota increase. Initially a labour protest, it soon included the general populace, who added their anti-Soviet discontent to the workers' civil disobedience, and on 17 June similar protests occurred throughout the GDR, with more than a million people striking in some 700 cities and towns. Fearing anti-communist counter-revolution on 18 June 1953, the government of the GDR enlisted the Soviet Occupation Forces to aid the "Volkspolizei" ("People's Police") in suppressing the rioters; some fifty people were killed and some 10,000 were jailed. (See Uprising of 1953 in East Germany.)
The German war reparations owed to the USSR impoverished the Soviet Zone of Occupation and severely weakened the East German economy. In the 1945–46 period, the Soviets confiscated and transported to the USSR approximately 33% of the industrial plant and by the early 1950s had extracted some US$10 billion in reparations in agricultural and industrial products.
The poverty of East Germany induced by reparations provoked the "Republikflucht" ("flight from the republic") to West Germany, aggravating the emigration, continual since the 1940s, from the Soviet zone of Germany to the Western Allied zones, further weakening the GDR's economy. Western economic opportunities and lack of political freedom in East Germany induced a brain drain. In response, the GDR closed the Inner German Border, and on the night of 12–13 August 1961, East German soldiers began erecting the Berlin Wall which prevented anyone from escaping.
In 1971, Soviet leader Leonid Brezhnev had Ulbricht removed; Erich Honecker replaced him. While the Ulbricht government had experimented with liberal reform, the Honecker government increased controls upon the populace of the GDR. The new government introduced a new East German Constitution which defined the German Democratic Republic as a "republic of workers and peasants" and hardly mentioned the word "German".
Initially, East Germany maintained that it was the only lawful government of Germany. However, from the 1960s onward, East Germany held itself out as a separate country from West Germany, and shared the legacy of the united German state of 1871–1945. West Germany, in contrast, claimed an exclusive mandate for all of Germany. From 1949 to the early 1970s, West Germany maintained that East Germany was an illegally constituted state. It argued that the GDR was a Soviet puppet regime and thus illegitimate. This position was shared by most of the world, until 1973. East Germany was recognized only by Communist countries and the Arab bloc, along with some "scattered sympathizers". According to the Hallstein Doctrine (1955), West Germany also did not diplomatically recognize any country – except the USSR – that recognized East German sovereignty.
But in the early 1970s, the "Ostpolitik" ("Eastern Policy") of "Change Through Rapprochement" of the pragmatic government of FRG Chancellor Willy Brandt, established normal diplomatic relations with the East Bloc states and the GDR. In the event, the Treaty of Moscow (August 1970), the Treaty of Warsaw (December 1970), the Four Power Agreement on Berlin (September 1971), the Transit Agreement (May 1972), and the Basic Treaty (December 1972) established normal relations between the Germanies, later allowing their integration to the United Nations. This also increased the number of countries recognizing East Germany to 55, including the US, UK and France, though the last three still refused to recognize East Berlin as the capital, and insisted on a specific provision in the UN resolution accepting the two Germanies into the UN to that affect.
GDR identity.
From the beginning, the newly formed GDR tried to establish its own separate identity. Because of Marx's abhorrence of Prussia, the SED repudiated continuity between Prussia and the GDR. The SED destroyed the Junker manor houses, wrecked the Berlin city palace and removed the equestrian statue of Frederick the Great from East Berlin. Instead the SED focused on the progressive heritage of German history, including Thomas Müntzer's role in the German Peasants' War and the role played by the heroes of the class struggle during Prussia's industrialization. Nevertheless, as early as 1956 East Germany's Prussian heritage asserted itself in the NVA.
As a result of the Ninth Party Congress in May 1976, East Germany after 1976–77 considered its own history as the essence of German history, in which West Germany was only an episode. It laid claim to reformers such as Karl Freiherr vom Stein, Karl August von Hardenberg, Wilhelm von Humboldt, and Gerhard von Scharnhorst.
In the early 1980s, West Germany adopted the line of "two German states in one German nation". While it respected East Germany's independence, it formally maintained that the GDR was merely a "de facto" government within a single German nation of which the FRG was the sole representative. For instance, it did not treat East Germans as foreigners.
The "Wende".
In 1989, following widespread public anger over the faking of results of local government elections that spring, many citizens applied for exit visas or left the country contrary to DDR laws. In August 1989 Hungary removed its border restrictions and unsealed its border, and more than 13,000 people left East Germany by crossing the "green" border via Czechoslovakia into Hungary and then on to Austria and West Germany. Many others demonstrated against the ruling party, especially in the city of Leipzig. Kurt Masur, the conductor of the Leipzig Gewandhaus Orchestra, led local negotiations with the government and held town meetings in the concert hall. The demonstrations eventually led Erich Honecker to resign in October, and he was replaced by a slightly more moderate communist, Egon Krenz.
On 9 November 1989, a few sections of the Berlin Wall were opened, resulting in thousands of East Germans crossing into West Berlin and West Germany for the first time. Krenz resigned a few days later, and the SED abandoned power shortly afterward. Although there were some limited attempts to create a permanent democratic East Germany, these were soon overwhelmed by calls for unification with West Germany.
East Germany held its last elections in March 1990. The winner was a coalition headed by the East German branch of West Germany's Christian Democratic Union, which advocated speedy reunification. After some negotiations (2+4 Talks) were held involving the two German states and the former Allied Powers which led to agreement on the conditions for German unification. The five original East German states that had been abolished in 1952 were recreated. On 3 October 1990, the five states officially joined the Federal Republic of Germany, while East and West Berlin united as a third city-state (in the same manner as Bremen and Hamburg). On July 1st a currency-union had preceded the political union - the "Ostmark" was abolished, the Western German "Deutsche Mark" became common currency.
The great economic and socio-political inequalities between the former Germanies required government subsidy for the full integration of East Germany to the Federal German Republic. Because of the deindustrialization taking place in he outcome of this economic reunion, the matter is disputed in political conflicts up to the present day. Most times the lack of efficiency of the East German Economy is highlighted and the de-industrialization seen as natural outcome of the "Wende". But many East German critics point out that the shock-therapy style of privatization did not leave room for east German Enterprises to adapt.
Politics.
There were four periods in East German political history. These included: 1949–61, which saw the building of socialism; 1961–1970 after the Berlin Wall closed off escape was a period of stability and consolidation; 1971–85 was termed the Honecker Era, and saw closer ties with West Germany; and 1985–89 saw the decline and extinction of East Germany.
Organization.
The ruling political party in East Germany was the "Sozialistische Einheitspartei Deutschlands" (Socialist Unity Party of Germany, SED). It was created in 1946 through the Soviet-directed merger of the Communist Party of Germany (KPD) and the Social Democratic Party of Germany (SPD) in the Soviet controlled zone.
Elections took place at the "Volkskammer" but were effectively controlled by the SED/state hierarchy, as Hans Modrow has noted. Elections were held in less-than-secret conditions, with voters given the choice of approving or rejecting "unity lists" put forward by the National Front and predetermining the distribution of seats given to the different parties and mass organisations. As was the case in most communist countries, approval rates of 90% or more were routine. 
Voting in East Germany was relatively simple. To vote yes, a voter simply took the ballot paper, which contained only one name—that of the approved candidate—and dropped it into the voting box. A voter could vote against the candidate by crossing out his or her name, but had to do so in a separate voting booth without any secrecy. The consequences for such an act of defiance were severe—loss of one's job or expulsion from school, and close surveillance by the Stasi.
The Volkskammer also included representatives from the "mass organisations" like the Free German Youth ("Freie Deutsche Jugend" or "FDJ"), or the Free German Trade Union Federation. In an attempt to include women in the political life of East Germany, there was a Democratic Women's Federation of Germany, with seats in the Volkskammer.
Important non-parliamentary mass organisations in East German society included the German Gymnastics and Sports Association ("Deutscher Turn- und Sportbund" or "DTSB"), and People's Solidarity ("Volkssolidarität", an organisation for the elderly). Another society of note was the Society for German-Soviet Friendship.
Following German reunification, the SED was renamed the "Party of Democratic Socialism" (PDS) which subsequently merged with the West German WASG to form the Left Party ("Die Linke"). The Left Party continues to be a political force in many parts of Germany, albeit drastically less powerful than the SED.
Military.
Every man served eighteen months of compulsory military service; for the medically unqualified and the conscientious objector, there were the "Baueinheiten" construction units, established in 1964 in response to political pressure by the national Protestant Church upon the GDR’s government. The armed forces of the GDR also possessed paramilitary reserve forces, such as the "Kampfgruppen der Arbeiterklasse" (Combat Groups of the Working Class), and from the Stasi, the Ministry for State Security (Mfs —"Ministerium für Staatssicherheit"), the “"Schild und Schwert der Partei"” (Shield and Sword of the Party).
Administrative districts.
Until 1952, the GDR comprised the East Berlin capital city and the five German states of Mecklenburg-Vorpommern (in 1947 renamed: Mecklenburg), Brandenburg, Saxony-Anhalt, Thuringia, Saxony, their post-war territorial demarcations approximating the pre-war German demarcations of the Middle German "Länder" (states) and "Provinzen" (provinces of Prussia). Moreover, the western parts of two provinces, Pomerania and Lower Silesia, although prevailingly annexed by Poland, remained politically integral to the GDR.
The East German Administrative Reform of 1952 disestablished the five states and established 14 "Bezirke" (districts), named per their capital cities: (i) Rostock, (ii) Neubrandenburg, (iii) Schwerin, (iv) Potsdam, (v) Frankfurt (Oder), (vi) Magdeburg, (vii) Cottbus, (viii) Halle, (ix) Leipzig, (x) Erfurt, (xi) Dresden, (xii) Karl-Marx-Stadt (Chemnitz until 1953 and again in 1990), (xiii) Gera, and (xiv) Suhl; East Berlin was denominated a "Bezirk" (district) in 1961.
The disestablished "Länder" (states), demarcated as "Bezirke" (districts), were renamed so: the northern "Land" (state) Mecklenburg was divided among the "Bezirke" Rostock, Schwerin, and Neubrandenburg; Brandenburg (containing Berlin) was divided into the Potsdam, Frankfurt (Oder), and Cottbus districts; Saxony-Anhalt was divided into the Halle and Magdeburg districts; the south-western state of Thuringia was divided into the Erfurt, Gera, and Suhl districts; and the south-eastern state of Saxony was divided among the Leipzig, Dresden, and Karl-Marx-Stadt districts.
East Berlin, the capital city of the German Democratic Republic, formed the "Bezirk" Berlin, the country’s fifteenth district, retaining special legal status until 1968, when the residents voted in approving the new (draft) constitution. Regardless of the city's four-occupying-power-status, the ACC, and diplomatic objections of the Allied governments, the GDR administered the "Bezirk" Berlin as sovereign territory.
Population.
The East German population declined by three million people throughout its forty-one year history, from 19 million in 1948 to 16 million in 1990; of the 1948 population, some 4 million were deported from the lands east of the Oder-Neisse line. This compares starkly with Poland, which increased during that time from 24 million in 1950 (a little more than East Germany) to 38 million (more than twice East Germany's population). This was primarily a result of emigration – about one quarter of East Germans left the country before the Berlin Wall was completed in 1961, and after that time, East Germany had very low birth rates, except for a recovery in the 1980s when the birth rate in East Germany was considerably higher than in West Germany, and in general the birth rate per woman was never much lower than in West Germany, except during the 1990s.
Economy.
The East German economy began poorly because of the devastation caused by the war, the loss of so many young soldiers, the disruption of business and transportation, the presence of so many refugees, and finally reparations owed to the USSR. The Red Army dismantled and transported to Russia the infrastructure and industrial plants of the Soviet Zone of Occupation. By the early 1950s, the reparations were paid in agricultural and industrial products; and Lower Silesia, with its coal mines and Szczecin, an important natural port, were given to Poland by the decision of Stalin.
The socialist centrally planned economy of the German Democratic Republic was like that of the USSR. In 1950, the GDR joined the COMECON trade bloc. In 1985, collective (state) enterprises earned 96.7% of the net national income. To ensure stable prices for goods and services, the state paid 80% of basic supply costs. The estimated 1984 per capita income was $9,800 ($21,000 in 2008 dollars). In 1976, the average annual growth of the GDP was approximately five percent. This made East German economy the richest in all of the Soviet Bloc until 1990 after the Communist collapse in the country.
Notable East German exports were photographic cameras, under the Praktica brand; automobiles under the Trabant, Wartburg, and the IFA brands; hunting rifles, sextants, and wristwatches.
Until the 1960s, East Germans endured shortages of basic foodstuffs such as sugar and coffee. East Germans with friends or relatives in the West (or any access to a hard currency) and the necessary Staatsbank foreign currency account, could afford Western products and export-quality East German products via Intershop. Consumer goods also were available, by post, from the Danish Jauerfood, and Genex companies.
The government used money and prices as political devices, providing highly subsidised prices for a wide range of basic goods and services, in what was known as "the second pay packet". The economic results were highly negative, and created an increasing differential with the prosperity in West Germany. At the production level, artificial prices made for an inefficient, backward system of semi-barter and resource-hoarding. For the consumer, it led to the substitution of GDR money with time, barter, and hard-currencies. Ironically, the socialist economy became steadily more dependent on financial infusions from hard-currency loans from West Germany. East Germans, meanwhile, came to see their soft-currency as worthless relative to the Deutsche Mark (DM).
Consumption and jobs.
In East Germany, people who were disgruntled resorted to nasty jokes at the expense of the oppressive regime; their names were recorded, and too many jokes would land a man in prison.
Throughout its history the main criterion for getting a good job was unblinking loyalty to the Communist party bosses. Even in the electronics industry, a relatively modern and competitive sector of the GDR's economy, the criteria of professionalism were secondary to political criteria in personnel recruitment and development. Dubious loyalty meant exclusion from the university and from good jobs.
With a very low birth rate and a high rate of exodus, East Germany was losing workers. The solution was to import low-skilled workers from other Communist countries. Beginning in 1963 with a series of secret international agreements, East Germany recruited workers from Poland, Hungary, Cuba, Albania, Mozambique, Angola and (North) Vietnam. They numbered more than 100,000 by 1989. Their working conditions were bleak, and although they were officially equal to their German counterparts, the foreign workers remained at the bottom of the social ladder with almost no rights.
Religion.
Religion was contested ground in the GDR, with the Communists promoting state atheism, although some people were loyal to Christian communities.
Atheism.
At the beginning, the Communist party had asserted the compatibility of Christianity and Marxism and sought Christian participation in the building of socialism. At first the question of atheism received little official attention. In the mid-1950s, as the Cold War heated up, atheism became suddenly a topic of major interest for the regime for propaganda purposes, both domestic and foreign. University chairs and departments devoted to the study of 'scientific atheism' were founded and much literature (scholarly and popular) on the subject was produced. Then this activity rather quickly subsided in the late 1960s amid perceptions that atheistic propaganda was becoming counterproductive; but official and scholarly attention to atheism was renewed beginning in 1973, though this time there was more emphasis on scholarship and the training of cadre than propaganda. Throughout, attention paid to atheism in East Germany always reflected politics and was never intended to jeopardise the cooperation that was desired from those East Germans who were religious.
Protestants.
East Germany historically was about 90% Protestant. Between 1956 and 1971 the leadership of the East German Lutheran Church changed its relations with the state from hostility to cooperation. From the founding of the GDR in 1949, the Communist Party tried to weaken the influence of the church on the rising generation. The church therefore adopted an attitude of confrontation and distance regarding the Communist authorities. Around 1956 this firm stand against the regime began to wither in favour of a more neutral stance and conditional loyalty. The regime was no longer regarded as illegitimate; instead, the church leaders started viewing the authorities as installed by God and, therefore, deserving of obedience by Christians. But on matters where the state demanded something which was not in accordance with the will of God, the church reserved its right to say no. There were both structural and intentional causes behind this development. Structural causes included the hardening of Cold War tensions in Europe in the mid-1950s, which took away the temporary character of the East German state. The loss of church members and discrimination against young Christians also made it clear to the leaders of the church that they had to come into some kind of dialogue with the authorities. The intentions behind the change of attitude varied from a traditional Lutheran acceptance of secular power to a positive attitude toward socialist ideas. There was also a will to cooperate in order to have the ability to criticise from within a position of loyalty.
Manfred Stolpe (b. 1936) became a lawyer for the Protestant church in 1959 before taking up a position at church headquarters in Berlin. In 1969 he helped found the Bund der Evangelischen Kirchen in der DDR, where he negotiated with the Communist government while at the same time working within the truly democratic system of the church's institutions. The international outlook he gained through the church's ecumenical activities helped him in his new job after winning the regional elections for the state of Brandenburg at the head of the SPD list in 1990. Despite accusations of having colluded with the Communist government, Stolpe, cleared of the charges, remained at the head of the Brandenburg government until he joined the federal government in 2002.
Catholics.
The smaller Roman Catholic Church had a fully functioning episcopal hierarchy that was in full accord with the Vatican. During the early postwar years, tensions were high. The Catholic Church as a whole and particularly the bishops were resistant to both the regime and Marxist ideology, and the state allowed the bishops to lodge protests, which they did on issues such as abortion. The bishops were, however, closely observed by the Stasi.
After 1945, the Church did fairly well in integrating Catholic exiles from lands to the east (which were given to Poland) and adjusting its institutional structures against the threats of an atheistic state. Within the Church, this meant an increasingly hierarchical structure, whereas in the area of religious education, press, and youth organisations, a system of temporary staff was developed, one that took into account the special situation of the Caritas, a charity organisation. They were hardly affected by Communist attempts to force them into line. By 1950, therefore, there existed a Catholic subsociety that was well adjusted to prevailing specific conditions and capable of maintaining Catholic identity.
With a generational change in the episcopacy taking place in the early 1980s, the state hoped for better relations with the new bishops, but the new bishops instead showed increasing independence from the state by holding unauthorised mass meetings, promoting international ties in discussions with theologians abroad, and hosting ecumenical conferences. The new bishops became less politically oriented and more involved in pastoral care and attention to spiritual concerns. The government responded by limiting international contacts for bishops.
Culture.
East Germany's culture was strongly influenced by communism and particularly Stalinism and was described by East German psychoanalyst Hans-Joachim Maaz in 1990 as having produced a "Congested Feeling" among East Germans as a result of the East German state's goal to protect people from dangers of deviant cultural influence and dangers of popular expression deviating from the state's ideals through enforcing official ideals through physical and psychological repression of these tendencies via its institutions, particularly the Stasi. Critics of the East German state have claimed that the state's commitment to communism was a hollow and cynical tool Machiavellian in nature, but this assertion has been challenged by studies that have found that the East German leadership was genuinely committed to the advance of scientific knowledge, economic development, and social progress. However, Pence and Betts argue, the majority of East Germans over time increasingly regarded the state's ideals to be hollow, though there was also a substantial number of East Germans who regarded their culture as having a healthier, more authentic mentality than that of West Germany. 
Music.
The Puhdys and Karat were some of the most popular mainstream bands, managing to hint at critical thoughts in their lyrics without being explicit. Like most mainstream acts, they appeared in popular youth magazines such as "Neues Leben" and "Magazin". Other popular rock bands were Wir, Dean Reed, City, Silly and Pankow. Most of these artists recorded on the state-owned AMIGA label.
Influences from the West were heard because West German TV and radio could be received in many parts of the East (an exception being Dresden with its geographical position in the Elbe valley, although limited reception of Western radio was still possible there). The Western influence led to the formation of more "underground" groups with a decisively western-oriented sound. A few of these bands were Die Skeptiker, Die Art and Feeling B. Additionally, hip hop culture reached the ears of the East German youth. With videos such as "Beat Street" and "Wild Style", young East Germans were able to develop a hip hop culture of their own. East Germans accepted hip hop as more than just a music form. The entire street culture surrounding rap entered the region and became an outlet for oppressed youth.
Dissident singer/songwriter Wolf Biermann, although professing to be a dedicated Communist, was not permitted to perform in public, and was deprived of his East German citizenship in 1976, while visiting West Germany. He was not allowed to return to East Germany until 1989.
Singer Nina Hagen, who is the stepdaughter of Biermann, was exiled at the same time.
Governmental support of classical music maintained some fifty symphony orchestras, such as Gewandhausorchester and Thomanerchor in Leipzig; Sächsische Staatskapelle in Dresden; and Berliner Sinfonie Orchester and Staatsoper Unter den Linden in Berlin.
The birthplace of Johann Sebastian Bach (1685–1750), Eisenach, was rendered as a museum about him, featuring more than three hundred instruments, which, in 1980, received some 70,000 visitors. In Leipzig, the Bach archive contains his compositions and correspondence and recordings of his music.
Theatre.
East German theatre was originally dominated by Bertolt Brecht, who brought back many artists out of exile and reopened the "Theater am Schiffbauerdamm" with his Berliner Ensemble. Alternatively, other influences tried to establish a "Working Class Theatre", played for the working class by the working class.
After Brecht's death, conflicts began to arise between his family (around Helene Weigel) and other artists about Brecht's heritage. Heinz Kahlau, Slatan Dudow, Erwin Geschonneck, Erwin Strittmatter, Peter Hacks, Benno Besson, Peter Palitzsch and Ekkehard Schall were considered to be among Bertolt Brecht's scholars and followers.
In the 1950s the Swiss director Benno Besson with the Deutsches Theater successfully toured Europe and Asia including Japan with "The Dragon" by Jewgenij Schwarz. In the 1960s, he became the Intendant of the Volksbühne often working with Heiner Müller.
After 1975 many artists left the GDR because of increasing censorship. A parallel theatre scene sprung up, creating theatre "outside of Berlin" in which artists played at provincial theatres. For example Peter Sodann founded the Neues Theater in Halle/Saale and Frank Castorf at the theater Anklam.
Theatre and cabaret had high status in the GDR, which allowed it to be very pro-active. This often brought it into confrontation with the state. Benno Besson once said, "In contrast to artists in the west, they took us seriously, we had a bearing."
Important theatres include: Berliner Ensemble; – Deutsches Theater; Maxim-Gorki-Theater; and Volksbühne
Cinema.
The prolific cinema of East Germany was headed by the DEFA, "Deutsche Film AG", which was subdivided in different local groups, for example "Gruppe Berlin", "Gruppe Babelsberg" or "Gruppe Johannisthal", where the local teams shot and produced films. Besides folksy movies, the movie-industry became known worldwide for its productions, especially children's movies ("Das kalte Herz", film versions of the Brothers Grimm fairy tales and modern productions such as "Das Schulgespenst").
Frank Beyer's "Jakob der Lügner" (Jacob the Liar), about the Holocaust, and "Fünf Patronenhülsen" (Five Cartridges), about resistance against fascism, became internationally famous.
Films about daily life, such as "Die Legende von Paul und Paula", by Heiner Carow, and "Solo Sunny", directed by Konrad Wolf and Wolfgang Kohlhaase, were very popular.
The film industry was remarkable for its production of "Ostern", or Western-like movies. Indians in these films often took the role of displaced people who fight for their rights, in contrast to the American westerns of the time, where Indians were often either not mentioned at all or are portrayed as the villains. Yugoslavians were often cast as the Indians because of the small number of American Indians in eastern Europe. Gojko Mitić was well known in these roles, often playing the righteous, kindhearted and charming chief ("Die Söhne der großen Bärin" directed by Josef Mach). He became an honorary Sioux chief when he visited the United States in the 1990s, and the television crew accompanying him showed the tribe one of his movies. American actor and singer Dean Reed, an expatriate who lived in East Germany, also starred in several films. These films were part of the phenomenon of Europe producing alternative films about the colonization of America.
Because of censorship a certain number of very remarkable movies were forbidden at this time and reissued after the "Wende" in 1990. Examples are "Spur der Steine" (directed by Frank Beyer) and "Der geteilte Himmel" (directed by Konrad Wolf).
Cinemas in the GDR also showed foreign films. Czechoslovak and Polish productions were more common, but certain western movies were shown, though the numbers of these were limited because it cost foreign exchange to buy the licences. Further, movies representing or glorifying capitalistic ideology were not bought. Comedies enjoyed great popularity, such as the Danish "Olsen Gang" or movies with the French comedian Louis de Funès.
Since the fall of the Berlin Wall, several movies depicting life in the GDR have been critically acclaimed. Some of the most notable were "Good Bye Lenin!" by Wolfgang Becker, "Das Leben der Anderen" (The Lives of Others) by Florian Henckel von Donnersmarck (won the Academy Award for best Film in a Foreign Language) in 2006, "Alles auf Zucker!" (Go for Zucker) by Dani Levi. Each film is heavily infused with cultural nuances unique to life in the GDR.
Sport.
East Germany was very successful in the sports of bicycling, weight-lifting, swimming, gymnastics, track and field, boxing, ice skating, and winter sports. The success is attributed to the leadership of Dr. Manfred Hoeppner which started in the late 1960s.
Another supporting reason was doping in East Germany, especially with anabolic steroids, the most detected doping substances in IOC-accredited laboratories for many years. The development and implementation of a state-supported sports doping program helped East Germany, with its small population, to become a world leader in sport during the 1970s and 1980s, winning a large number of Olympic and world gold medals and records.
Another factor for success was the furtherance-system for young people in GDR. Sport-teachers at school were encouraged to look for certain talents in children ages 6 to 10 years old. For older pupils it was possible to attend grammar-schools with a focus on sports (for example sailing, football and swimming). This policy was also used for talented pupils with regard to music or mathematics.
Sports clubs were highly subsidized, especially sports in which it was possible to get international fame. For example, the major leagues for ice hockey and basketball just included each 2 teams. Football (soccer) was the most popular sport. Club football teams such as Dynamo Dresden, 1. FC Magdeburg, FC Carl Zeiss Jena, 1. FC Lokomotive Leipzig and BFC Dynamo had successes in European competition. Many East German players such as Matthias Sammer and Ulf Kirsten became integral parts of the reunified national football team. Other sports enjoyed great popularity like figure skating, especially because of sportspeople like Katarina Witt.
The East and the West also competed via sport; GDR athletes dominated several Olympic sports. Of special interest was the only football match between the Federal Republic of Germany and the German Democratic Republic, a first-round match during the 1974 FIFA World Cup, which the East won 1–0; but West Germany, the host, went on to win the World Cup.
Television and radio.
Television and radio in East Germany were state controlled; the "Rundfunk der DDR" was the official radio broadcasting organisation from 1952 until German reunification. The organization was based in the "Funkhaus Nalepastraße" in East Berlin. "Deutscher Fernsehfunk" (DFF), from 1972–1990 known as "Fernsehen der DDR" or DDR-FS, was the state television broadcaster from 1952. Reception of Western radio (and even television) broadcasts was widespread.
Telecommunications.
By the mid-1980s, East Germany possessed a well-developed communications system. There were approximately 3.6 million telephones in usage (21.8 for every 100 inhabitants), and 16,476 Telex stations. Both of these networks were run by the Deutsche Post der DDR (East German Post Office). East Germany was assigned telephone country code 37; in 1991, several months after reunification, East German telephone exchanges were incorporated into country code 49.
An unusual feature of the telephone network was that in most cases, direct dialing for long distance calls was not possible. Although area codes were assigned to all major towns and cities, they were only used for switching international calls. Instead, each location had its own list of dialing codes with shorter codes for local calls and longer codes for long distance calls. After reunification, the existing network was largely replaced, and area codes and dialing became standardised.
In 1976 East Germany inaugurated the operation of a ground-based radio station at Fürstenwalde for the purpose of relaying and receiving communications from Soviet satellites and to serve as a participant in the international telecommunications organization established by the Soviet government, Intersputnik.
Ostalgie.
The end of the Cold War division of Germany and unification in 1990 inspired initial euphoria.
But for many East Germans, this joy quickly turned to dismay. West Germans often acted as if they had "won" and East Germans had "lost" in unification, leading many East Germans ("Ossis") to resent West Germans ("Wessis"). Barnstone finds that, "East Germans resent the wealth possessed by West Germans; West Germans see the East Germans as lazy opportunists who want something for nothing. East Germans find “Wessis” arrogant and pushy, West Germans think the “Ossis” are lazy good-for-nothings." Additionally, the dislocations, especially the closure of obsolete factories in the east, the end of Communism, the disappearance of East Germany and German unification were hardest for East Germany, where unemployment skyrocketed and many East German professionals quickly fled for better jobs in West Germany.
These and other effects of unification led many East Germans to begin to think of themselves more strongly as "East" Germans rather than as simply as "Germans". In many former GDR citizens this produced a longing for certain aspects of the former East Germany, such as full employment and other perceived benefits of the GDR state, termed "Ostalgie" (a blend of "east" and "nostalgia") and depicted in the Wolfgang Becker film "Goodbye Lenin!".
Danish historian Feiwel Kupferberg (2002) argues that the real difficulty in German reunification was the sharply different ways the West Germans and East Germans interpreted their Nazi past. The West Germans confronted the past and atoned for it, and meanwhile transformed the FRG into a prosperous, free democracy that expressed the values of both individual freedom and responsibility. By contrast, the East Germans took hold of Moscow's official interpretation that East Germany was the "victor of history" and represented the successful opposition to the Nazis. This myth, Kupferberg argues, allowed the GDR to attack the West Germans as historically complicit in the Nazi crimes because it had the same capitalist economy which had produced Hitler in the first place. East Germany was now pure, because it had rejected fascism and its twin, capitalism. This attitude, Kupferberg argues, allowed middle classes that had supported Hitler to often retain powerful roles in East Germany. Granville concludes that Kupferberg, "articulates well the thesis that the rigid communist system in the GDR inculcated passivity, helplessness, and amoral pragmatism in its citizens."
See also.
Germany
Armed Forces
Media
Transport
Other
External links.
Countries of the world Europe

Falkland Islands
The Falkland Islands ( or ; ) are an archipelago in the South Atlantic Ocean, located more than east of the coast of mainland South America. The archipelago which has an area of 4,700 square miles (12,173 km2) comprises East Falkland, West Falkland, and 776 smaller islands. Stanley, the capital and only city, is on East Falkland. The islands, a British Overseas Territory, enjoy a large degree of internal self-government with the United Kingdom guaranteeing good government and taking responsibility for their defence and foreign affairs.
Controversy exists over the Falklands' original discovery and subsequent colonisation by Europeans. At various times there have been French, British, Spanish, and Argentine settlements. Britain re-established its rule in 1833, though the islands continue to be claimed by Argentina. In 1982, following Argentina's invasion of the islands, the two-month-long undeclared Falklands War between both countries resulted in the surrender of all Argentine forces and the return of the islands to British administration.
The population, estimated at 3,140, primarily consists of native Falkland Islanders, the majority being of British descent. Other ethnicities include French, Gibraltarian, and Scandinavian. Immigration from the United Kingdom, Saint Helena, and Chile has reversed a former population decline. The predominant and official language is English. Under the British Nationality Act of 1983, Falkland Islanders are legally British citizens.
The islands lie on the boundary of the Subarctic maritime climate and Temperate maritime climate zones with both major islands having mountain ranges reaching to . The islands are home to large bird populations, although many no longer breed on the main islands due to introduced species. Major economic activities include fishing, tourism, sheep farming with an emphasis on high-quality wool exports, and oil exploration. Oil exploration, licensed by the Falkland Islands Government, remains controversial as a result of maritime disputes with Argentina.
Etymology.
The Falkland Islands took their English name from "Falkland Sound", the channel between the two main islands, which was in turn named after Anthony Cary, 5th Viscount of Falkland, by Captain John Strong, who landed on the islands in 1690. The Spanish name, "las (Islas) Malvinas", is derived from the French name, "Îles Malouines", named by Louis Antoine de Bougainville in 1764 after the first known settlers, mariners and fishermen from the Breton port of Saint-Malo in France. The ISO designation is "Falkland Islands (Malvinas)" and its ISO country code is "FK".
As a result of the sovereignty dispute, the use of many Spanish names is considered offensive in the Falkland Islands, particularly those associated with the 1982 invasion of the Falkland Islands. General Sir Jeremy Moore would not allow the use of "Islas Malvinas" in the surrender document, dismissing it as a propaganda term.
History.
Prior to the Falklands War.
Controversy exists as to who first discovered the Falkland Islands, with competing Portuguese, Spanish, and British claims in the 16th century. While Amerindians from Patagonia could have visited the Falklands, the islands were uninhabited when discovered by Europeans. The first reliable sighting is usually attributed to the Dutch explorer Sebald de Weert in 1600, who named the archipelago the Sebald Islands, a name they bore on Dutch maps into the 19th century.
In 1690, Captain John Strong of the "Welfare" en route to Puerto Deseado was driven off course and reached the Falkland Islands instead, landing at Bold Cove. Sailing between the two principal islands, he called the passage "Falkland Channel" (now Falkland Sound), after Anthony Cary, 5th Viscount of Falkland, who as Commissioner of the Admiralty had financed the expedition. The island group takes its English name from this body of water.
In 1764, French navigator and military commander Louis Antoine de Bougainville founded the first settlement on Berkeley Sound, in present-day Port Louis, East Falkland. In 1765, British captain John Byron explored and claimed Saunders Island on West Falkland, where he named the harbour Port Egmont and a settlement was constructed in 1766. Unaware of the French presence, Byron claimed the island group for King George III. Spain acquired the French colony in 1767, and placed it under a governor subordinate to the Buenos Aires colonial administration. In 1770, Spain attacked Port Egmont and expelled the British presence, bringing the two countries to the brink of war. War was avoided by a peace treaty and the British return to Port Egmont.
In 1774, economic pressures leading up to the American Revolutionary War forced Great Britain to withdraw from many overseas settlements. Upon withdrawal, the British left behind a plaque asserting Britain's continued claim. Spain maintained its governor until 1806 who, on his departure, left behind a plaque asserting Spanish claims. The remaining settlers were withdrawn in 1811.
In 1820, storm damage forced the privateer "Heroína" to take shelter in the islands. Her captain David Jewett raised the flag of the United Provinces of the River Plate and read a proclamation claiming the islands. This became public knowledge in Buenos Aires nearly a year later after the proclamation was published in the "Salem Gazette". After several failures, Luis Vernet established a settlement in 1828 with authorisation from the Republic of Buenos Aires and from Great Britain. In 1829, after asking for help from Buenos Aires, he was instead proclaimed Military and Civil Commander of the islands. Additionally, Vernet asked the British to protect his settlement if they returned.
A dispute over fishing and hunting rights resulted in a raid by the US warship USS "Lexington" in 1831. The log of the "Lexington" reports only the destruction of arms and a powder store, but Vernet made a claim for compensation from the US Government stating that the settlement was destroyed. (Compensation was rejected by the US Government of President Cleveland in 1885.) The islands were declared free from all government, the seven senior members of the settlement were arrested for piracy and taken to Montevideo, where they were released without charge on the orders of Commodore Rogers.
In November 1832, Argentina sent Commander Mestivier as an interim commander to found a penal settlement, but he was killed in a mutiny after four days. The following January, British forces returned and requested the Argentine garrison leave. Don Pinedo, captain of the ARA "Sarandi" and senior officer present, protested but ultimately complied. Vernet's settlement continued, with the Irishman William Dickson tasked with raising the British flag for passing ships. Vernet's deputy, Matthew Brisbane, returned and was encouraged by the British to continue the enterprise. The settlement continued until August 1833, when the leaders were killed in the so-called Gaucho murders. Subsequently, from 1834 the islands were governed as a British naval station until 1840 when the British Government decided to establish a permanent colony.
A new harbour was built in Stanley, and the islands became a strategic point for navigation around Cape Horn. A World War I naval battle, the Battle of the Falkland Islands, took place in December 1914, with a British victory over the smaller Imperial German Asiatic Fleet. During World War II, Stanley served as a Royal Navy station and serviced ships which took part in the 1939 Battle of the River Plate.
Sovereignty over the islands became an issue in the second half of the 20th century, when Argentina saw the creation of the UN as an opportunity to pursue its claim. Talks between British and Argentine foreign missions took place in the 1960s but failed to come to any meaningful conclusion. A major sticking point in all the negotiations was that the inhabitants preferred that the islands remain British territory.
A result of these talks was the establishment of the islands' first air link. In 1971, the Argentine state airline LADE began a service between Comodoro Rivadavia and Stanley. A temporary strip was followed by the construction of a permanent airfield and flights between Stanley and Comodoro Rivadavia continued until 1982. Further agreements gave YPF, the Argentine national oil and gas company, a monopoly over the supply of the islands' energy needs.
Falklands War and its aftermath.
On 2 April 1982, Argentina invaded the Falkland Islands and other British territories in the South Atlantic. The military junta which had ruled Argentina since 1976 sought to maintain power by diverting public attention from the nation's poor economic performance and the growing internal opposition and exploiting the long-standing feelings of the Argentines towards the islands. Several British writers hold that the United Kingdom's reduction in military capacity in the South Atlantic also encouraged the invasion.
The United Nations Security Council issued Resolution 502, calling on Argentina to withdraw forces from the islands and for both parties to seek a diplomatic solution. International reaction ranged from support for Argentina in Latin American countries (except Chile and Colombia), to opposition in the Commonwealth and Western Europe (apart from Spain). A divided United States administration, initially publicly neutral, eventually came out in support of the United Kingdom.
The British sent an expeditionary force to retake the islands, leading to the Falklands War. After short but fierce naval and air battles, the British landed at San Carlos Water on 21 May, and a land campaign followed leading to the British taking the high ground surrounding Stanley on 11 June. The Argentine forces surrendered on 14 June 1982. The war resulted in the deaths of 255 British and 649 Argentine soldiers, sailors and airmen, as well as 3 civilian Falklanders.
After the war, the British increased their military presence on the islands, constructing RAF Mount Pleasant and increasing the military garrison. Although the United Kingdom and Argentina resumed diplomatic relations in 1990, no further negotiations on sovereignty have taken place. Between 18,000 and 25,000 Argentine land mines remain from the 1982 war dispersed in a number of minefields around Stanley, Port Howard, Fox Bay and Goose Green. Information is available from the Explosive Ordnance Disposal Operation Centre in Stanley. In 2009 mine clearance began at Surf Bay, and further clearances took place at Sapper Hill, Goose Green and Fox Bay. Further clearance work was due to begin in 2011.
Sovereignty dispute.
Although the United Nations Special Committee on Decolonization includes the Falkland Islands on the United Nations list of Non-Self-Governing Territories, it has been asserted that the Falkland Islands is one of 16 territories which have too small a population "to survive as viable, fully independent state." Both the United Kingdom and the Argentine governments claim responsibility for the islands. The United Kingdom bases its claim on continuous administration of the islands since 1833 (apart from the Argentine military occupation in 1982) and the islanders’ "right to self determination, including their right to remain British if that is their wish". Argentina claims that it acquired the islands from Spain when Argentina became independent in 1816 and that the United Kingdom exceeded their authority by allegedly expelling the Argentine settlers in 1833. The islanders reject the Argentine sovereignty claim.
Before the Falklands War.
Shortly after the formation of the United Nations in 1945, Argentina asserted its right to sovereignty over the Falkland Islands and its dependencies. In 1947, the United Kingdom offered to submit the case over the Falkland Islands Dependencies to the International Court of Justice at The Hague, but Argentina refused the offer. A unilateral application by the United Kingdom in 1955 to the Court in respect of Argentine encroachment ended in deadlock when Argentina announced that it would not respect the decision of the court.
In the late 1960s, as part of the United Kingdom's decolonisation policy, secret discussions were held by the British and Argentine governments to identify a means by which the United Kingdom could cede the islands to Argentina while protecting the rights and way of life of the islanders. Details of the talks were leaked and the islanders protested against the talks having taken place. Subsequently however, economic and transport links between Argentina and the islands were established, but the political situation remained unchanged. In April 1982 Argentine military forces invaded the islands, leading to the Falklands War.
After the Falklands War.
The dispute over control of the islands has continued since the Falklands War, although diplomatic relations between Argentina and the UK were resumed in 1990. In 1994 Argentina added its claim to the islands to the Argentine constitution, stating that this claim must be pursued in a manner "respectful of the way of life of their inhabitants and according to the principles of international law". Since the war, successive Argentine governments have stated their intention to pursue their claim to the islands by peaceful means. Kirchner, campaigning for president in 2003, regarded the islands as a top priority, taking actions such as banning flights to the Falklands from Argentine airspace. In June 2003 the issue was brought before a United Nations committee, and attempts have been made to open talks with the United Kingdom to resolve the issue of the islands.
In 1998, in retaliation for the arrest in London of the former Chilean president Augusto Pinochet, the Chilean government banned flights between Punta Arenas and Stanley, thus isolating the islands from the rest of the world. Uruguay and Brazil refused to authorise direct flights between their territories and Stanley. This forced the islands' government to enter negotiations with the Argentine government and led to Argentina authorising direct flights between its territory and Stanley, on condition that Argentine citizens be allowed on the islands.
In 2007, 25 years after the war, Argentina reasserted its claim over the Falkland Islands, asking for the UK to resume talks on sovereignty. In March 2009, British Prime Minister Gordon Brown stated in a meeting with Argentine President Cristina Fernández that there would be no talks over the future sovereignty of the Falkland Islands. As far as the governments of the UK and of the Falkland Islands are concerned, there is no issue to resolve. The Falkland Islanders consider themselves as almost entirely British and maintain their allegiance to the United Kingdom.
In October 2007 a British spokeswoman confirmed that Britain intended to submit a claim to the UN to extend seabed territory around the Falklands and South Georgia, in advance of the expiry of the deadline for territorial claims following Britain's ratification of the 1982 Law of the Sea Convention. This claim would enable Britain to control activities such as fishing within the zone, in areas not conflicting with the Antarctic Treaty. Argentina has indicated it will challenge any British claim to Antarctic territory and the area around the Falkland Islands and South Georgia. Argentina made a similar claim in 2009, and the United Kingdom quickly protested against these claims.
In 2009, when delegates from the Falkland Islands were invited to the World Summit on Fishing Sustainability, the Argentine delegation protested and walked out of the conference. In February 2010, the Argentine government announced that ships traversing Argentine territorial waters en route to the Falklands, South Georgia and the South Sandwich Islands would require a permit, as part of a dispute over British oil exploration near the Falklands. The British and Falkland governments stated that Falklands-controlled waters were unaffected. On 12 June 2012, the Falkland Islands government announced it would hold a referendum on the political status of the islands in the first half of 2013.
Politics and government.
The islands are a British Overseas Territory which, under the 2009 Constitution, enjoys a large degree of internal self-government, with the United Kingdom guaranteeing good government and taking responsibility for defence and foreign affairs.
Executive authority is vested in the Queen and is exercised by the Governor on her behalf. The Governor is also responsible for the administration of South Georgia and the South Sandwich Islands, as these islands have no native inhabitants. The governor acts on the advice of the Executive Council, composed of himself as chairman, the Chief Executive, Director of Finance and three elected Legislative Assembly Members. The current Governor Nigel Haywood took office in October 2010.
The Legislative Assembly consists of the Chief Executive, Director of Finance and the eight members elected for four-year terms by universal suffrage, of whom five are from Stanley and three from Camp. There are no political parties, and no formal opposition. It is presided over by the Speaker, currently Keith Biles. The last election, the first under the 2009 constitution, took place on Thursday 5 November 2009.
Justice is administered by a resident senior magistrate and a non-resident Chief Justice of the islands who visits the islands at least once a year. The senior magistrate handles petty criminal cases, civil, commercial, admiralty and family cases and is also the island's coroner. The Chief Justice handles serious criminal cases and hears appeals. The constitution binds the judiciary to comply with decisions of the European Court of Human Rights when hearing cases related to human rights.
Freedom of expression in the Falkland Islands is guaranteed by the constitution, with the United Kingdom's superior courts explicitly empowered to hear appeals. Freedom of the press is comparable to that of the United Kingdom; which, in turn, in the view of many commentators, is significantly better than that of any other South American country.
Military.
A British military garrison is stationed on the Falkland Islands, and the islands also have a company-sized light infantry unit (FIDF) that is completely funded by the Falklands government (£400,000 in 2009). The unit is trained under a secondment arrangement with the MOD – the FIDF employed a Royal Marine WO2 as a permanent staff instructor and a major as commanding officer; the rest of the force are part-timers. It is equipped with quad bikes, inflatable boats and Land Rovers and is armed with heavy machineguns, grenade launchers and sniper rifles. In addition to defence duties, the force provides a mountain rescue service and has been trained by the Royal Navy in mounting armed deterrence against illegal fishing activity.
Education.
There are approximately 380 children between the ages of 5 and 16 on the islands (excluding families of military personnel). Their education, which follows the English system, is free and compulsory. Primary education is available at Stanley where there are boarding facilities, at RAF Mount Pleasant for children of service personnel and at a number of rural settlements where remote learning is supported by the Stanley based Camp Education Unit. The Islands' only secondary school is in Stanley and offers boarding facilities and 12 subjects to GCSE level. After 16, suitably qualified students may study at two colleges in England for their A-levels or for vocational qualifications. The government pays for older students to attend higher education, usually in the UK.
Medical care.
The Falkland Islands Government Health and Social Services Department provides medical and dental care for the islands. The King Edward VII Memorial Hospital (KEMH), completed in 1987, is Stanley's only hospital. It is run jointly by the Falkland Islands Government and the UK Ministry of Defence. Specialist medical care is provided by visiting ophthalmologists, gynaecologists, ENT surgeons, orthopaedic surgeons, oral surgeons and psychiatrists from the United Kingdom. Patients needing emergency treatment are air-lifted to the United Kingdom or to Santiago (Chile).
Geography.
The Falkland Islands are located in the South Atlantic Ocean on a projection of the Patagonian continental shelf about from the Patagonia coastline and slightly to the north of the southerly tip of Cape Horn and of its undersea extension, the Scotia Arc. In ancient geological time this shelf was part of Gondwana, which around 400 million years ago broke from what is now Africa and drifted westwards relative to Africa.
The Falklands, which have a total land area of 4,700 square miles (12,173 km2) and a coastline estimated at 800 miles (1288 km), comprise two main islands, West Falkland and East Falkland and about 776 small islands. The islands are heavily indented by sounds and fjords and have many natural harbours. The two main islands are separated by the Falkland Sound.
East Falkland, which contains the capital Stanley and the British military base at Mount Pleasant, is the more populous of the two main islands.
Both West Falkland and the northern part of East Falkland have mountain ranges that are underlaid with Palaeozoic rock, which, as a result of secondary forces associated with continental drift are at 120° to each other. The highest point of the islands is Mount Usborne, on East Falkland, while Mount Adam on West Falkland is only lower.
The southern part of East Falkland, the Lafonia Peninsula, which is connected to the rest of the island by a 4 km narrow isthmus, is dissimilar to the rest of the island. Most of Lafonia is a flat plain underlain by younger Mesozoic rock, but in the north west is Permian rock which is similar to that of parts of Ecca Pass in South Africa.
Climate.
The Falkland Islands lie on the boundary of the Subarctic maritime climate and Temperate maritime climate zones (Köppen "Cfc" and "Cfc") that is very much influenced by the proximity of the Andes, the cool South Atlantic ocean with its northerly Patagonian current and the Antarctic Peninsula land mass some to the south giving the islands a narrow annual temperature range. The January average maximum temperature is about 13°C (55°F), and the July maximum average temperature is about 4°C (39°F). The average rainfall in Stanley is , East Falkland as a whole and West Falkland as a whole with the flat areas, and in particular Lafonia being much drier than the mountainous areas. Humidity and winds are however constantly high. Snow and sleet are frequent in winter, although snowfall is rarely deep. Gales are very frequent, particularly in winter.
Weather conditions are known to be extremely changeable, with it not being unusual to face all four seasons in one afternoon. The reason for this is the many wind directions resulting in many air masses mixing at the Drake Passage, which is often an area of low pressures.
Whilst being located as far south as the U.K is north, the absence of a warming current like the Gulf Stream means temperatures are considerably colder than comparable areas in North West Europe. Weather forecasts are given by a local branch of the UK's Met Office.
Biodiversity.
Biogeographically, the Falkland Islands are classified as part of the Antarctic ecozone and Antarctic Floristic Kingdom. Strong connections exist with the flora and fauna of Patagonia in South America. The only terrestrial mammal upon the arrival of Europeans was the warrah, a kind of fox found on both major islands. It became extinct in the mid 19th century. 14 species of marine mammals frequent the surrounding waters. The elephant seal, the fur seal, and the sea lions all breed on the islands, and the largest elephant seal breeding site has over 500 animals in it. 227 bird species have been seen on the islands, over 60 of which are known to breed on the islands. There are two endemic species of bird, and 14 endemic subspecies. There are five penguin species breeding on the islands, and over 60% of the global black-browed albatross population also breed in the area.
There are no native reptiles or amphibians on the islands. Over 200 species of insects have been recorded, along with 43 spider species and 12 worm species. Only 13 terrestrial invertebrates are recognised as endemic, although information on many species is lacking and it is suspected up to two thirds of species found are actually endemic. Due to the island environment, many insect species have developed reduced or absent wings. There are around 129 freshwater invertebrates, the majority being rotifer; however, the identification of some species remains in dispute. Six species of fish are found in freshwater areas, including zebra trout and falklands minnows. Different species of krill are found in Falkland waters, with Lobster Krill inhabiting the warmer waters in the north.
There are no native tree species on the archipelago, although two species of bushes, fachine and native box are found. Other vegetation consists of grasses and ferns. Around 363 species of vascular plants, 21 species of ferns and clubmosses and 278 species of flowering plants have been recorded on the islands. Of the vascular plants, 171 are believed to be native and 13 to be endemic. Some bogs and fens exist and support some freshwater plant species, but these are not common on the islands. Tussac grass, which averages in height but can reach up to , is found within 300 m (1,000 ft) of the coast where it forms bands around larger islands. The dense canopies formed create an insulated micro-climate suitable for many birds and invertebrates. The Pale Maiden ("Sisyrinchium jubatum") is the islands' national flower.
There is little long-term data on habitat changes, so the extent of human impact is unclear. Vegetation such as tussac grass, fachine, and native box have been heavily impacted by introduced grazing animals. Many breeding birds similarly only live on offshore islands, where introduced animals such as cats and rats are not found. Virtually the entire area of the islands is used as pasture for sheep. There is also an introduced reindeer population, which was brought to the islands in 2001 for commercial purposes. Rats and Grey foxes have been introduced and are having a detrimental impact on birds that nest on the shores, as are feral cats. 22 introduced plant species are thought to provide a significant threat to local flora.
Economy.
Except for defence, the islands are self sufficient with annual exports of $125 million and imports of $90 million (2004 estimate). The Falkland Islands use the Falkland pound, which circulates interchangeably with the pound sterling and which is backed by the pound sterling on a one-for-one basis. Falkland coins are produced in the United Kingdom; coins are identical in size to the United Kingdom currency but with local designs on the reverse. The Falkland Islands also issue their own stamps. Both the coins and stamps are a source of revenue from overseas collectors.
Farmland accounts for , more than 90% of the Falklands land area. Since 1984, efforts to diversify the economy have made fishing the largest part of the economy and brought increasing income from tourism. Sheep farming was formerly the main source of income for the islands and still plays an important part with high quality wool exports going to the UK. According to the Falklands Government Statistics there are over 500,000 sheep on the islands with roughly 60% on East Falkland and 40% on West Falkland.
The government has operated a fishing zone policy since 1986 with the sale of fishing licences to foreign countries. These licences have recently raised only £12 to 15 million a year in revenue, as opposed to £20m to £25m annually during the 1990s. Locally registered fishing boats are also in operation. More than 75% of the annual catch of 200,000 tonnes (220,000 short tons) is squid.
Tourism has grown rapidly. The islands have become a regular port of call for the growing market of cruise ships with more than 36,000 visitors in 2004.
A 1995 agreement between the UK and Argentina had set the terms for exploitation of offshore resources including oil reserves as geological surveys had shown there might be up to 60 billion barrels (9.5 billion cubic metres) of oil under the seabed surrounding the islands. However, in 2007 Argentina unilaterally withdrew from the agreement; Falklands Oil and Gas Limited then signed an agreement with BHP Billiton to investigate the potential exploitation of oil reserves. Due to the difficult climatic conditions of the southern seas exploitation will be difficult, though economically viable; the continuing sovereignty dispute with Argentina is also hampering progress.
In February 2010 exploratory drilling for oil was begun by Desire Petroleum, but the results from the first test well were disappointing. Two months later, on 6 May 2010, Rockhopper Exploration announced that "it may have struck oil". Subsequent tests showed it to be a commercially viable find; an appraisal project was launched and on 14 September 2011 Rockhopper Exploration announced that plans were under way for oil production to commence in 2016, through the use of floating production storage and offloading (FPSO) technology.
Demographics.
The population of the Falkland Islands is primarily of British descent (about 70 percent of the population), mainly as a result of Scottish and Welsh immigration to the islands. In the 2006 census, some Islanders identified themselves as of French, Gibraltarian, and Scandinavian descent. Other minorities include those from Chile and Saint Helena, many of whom have become assimilated. Among the few Argentines currently residing in the islands is Maria Strange, wife of the author and historian Ian Strange.
Residents of the Falklands are often called "Kelpers" or "Islanders". The legal term for having the right of residence is "belonging to the islands". From 1 January 1983, as provided in the British Nationality (Falkland Islands) Act 1983, the islanders have been full British citizens.
A population decline leading up to the Falklands War has reversed, with the population bolstered by immigration from the British island of Saint Helena, and Chile though figures for immigration are skewed by including children born to Falkland Islander women who for medical reasons travelled abroad for their confinement as being "born abroad". Historical census figures show that the population rose from an estimate of 287 in 1851 to 2,272 in 1911. The population was 2,094 in 1921 and 2,392 in 1931, but it then declined to 1,813 in 1980. However, the population recorded in the 2001 census was higher than at any previous point in history. The population later rose to 2,955 (2006 census). The 2006 census recorded 2,115 people in Stanley and 477 in Mount Pleasant, 194 in the rest of East Falkland, 127 in West Falkland and 42 people in all the other islands. These figures exclude all military personnel and their families, but include 477 people who were present in the Falkland Islands in connection with the military garrison.
The age distribution of the islands residents is skewed towards people of working age – 65% as opposed to 21% aged below 20 and 14% aged above 60. Males outnumber females by 53% to 47% with the deviation being most prominent in the age group. In the 2006 census, 67.2% of the islanders identified themselves as being Christians, 31.5% either declined to answer or had no religious affiliation and the remaining 1.3% (39 individuals) identified themselves as adherents of other faiths. The islands have three churches, one for each of the Church of England, Roman Catholic and United Free Church communities.
Infrastructure.
Media.
The islands have two weekly newspapers – "The Penguin News", published by Mercopress and the "Teaberry Express" published by Falkland Islands News Network.
Falkland Islands technical standards for radio and television are identical to those in the United Kingdom or, in the case of Medium Wave broadcasts, the Americas. There are approximately 1000 television sets and 1000 radio receivers on the islands. Two terrestrial television channels are broadcast by the British Forces Broadcasting Service (BFBS) while KTV Ltd. relay a number of satellite services such as BBC, CNN via cable to subscribers in Stanley. Radio broadcasting is supported by seven FM radio stations and one AM radio station. The first broadcasting service, the Falkland Islands Broadcasting Service, established in 1929 used landlines connected to a speaker in people's homes. This was upgraded to wireless in 1942 and a 5 kW medium wave transmitter installed in 1954. VHF was introduced in 1999. In 2005 the service was privatised and renamed Falkland Islands Radio Service (FIRS).
Telephone.
The first telephones in the Falklands were installed by the Falkland Island Company in 1880, with lines to all settlements in Camp being installed by 1907. In 1911, Marconi built a telegraph office that permitted telegrams to be sent to Montevideo. In 1950, the fixed line telephone service to Camp was replaced by a radio service; the 2006 census showed that of the 307 2-metre radio receivers in the islands, 129 were located in Camp. In 1989, Cable and Wireless won the contract to provide the Island's national and international telephone services. In 2006, a GSM 900 mobile network was installed,
In 2006, broadband was successfully implemented in Stanley and Mount Pleasant Complex, and was rolled out across the islands in 2008/09. The International Telecommunication Union figures for 2011 identified the Falkland Islands as having the highest proportion of internet users in the world – 96.38%.
Transport.
In 1982, the Falkland Islands had no roads outside Stanley, only tracks. By 2007, the Falkland Islands had a road network of  miles (786 km) which in 2012 had been extended to  miles (862 km) linking to all occupied mainland settlements. Speed limits are 25 mph (40 km/h) in built-up areas and 40 mph (64 km/h) elsewhere. , the Falkland Islands had 67 motor vehicles per 100 people, with 4x4 vehicles accounting for 66% of the total.
The Falkland Islands have two airports with paved runways – the main international airport RAF Mount Pleasant, west of Stanley. opened in 1986 and the smaller Port Stanley Airport on the outskirts of Stanley, opened in 1979 following the 1971 Anglo-Argentine agreement regarding an air link between the countries. Mount Pleasant is used for military purposes and for heavy aircraft that require long runways, whereas Stanley is used for internal flights and smaller aircraft.
The Royal Air Force operates flights from RAF Mount Pleasant to RAF Brize Norton in Oxfordshire, England, with a refuelling stop at RAF Ascension Island. RAF flights are on TriStars although charter aircraft are often used if the TriStars are required for operational flights. Local military air support – moving of personnel, equipment and supplies around the islands is carried out under contract by British International (BRINTEL) who operate two Sikorsky S61N helicopters. The principal civilian air operator at Mount Pleasant is LAN Airlines who operate weekly flights to Santiago, Chile via Punta Arenas with an additional stop once a month at Río Gallegos, Argentina.
The main operator at Port Stanley Airport is the Falkland Islands Government Air Service (FIGAS) that operates Islander aircraft which can use the grass airstrips at most settlements. Flight schedules, which are broadcast on the radio every evening, are planned on a daily basis according to passenger needs.
Private operators from Stanley include the British Antarctic Survey who operate an air link to the Rothera Research Station on the Antarctic Peninsula and also serve other British bases in the British Antarctic Territory using a de Havilland Canada Dash 7.

Poland
Poland (), officially the Republic of Poland (; ), is a country in Central Europe, bordered by Germany to the west; the Czech Republic and Slovakia to the south; Ukraine, Belarus and Lithuania to the east; and the Baltic Sea and Kaliningrad Oblast, a Russian exclave, to the north. The total area of Poland is , making it the 69th largest country in the world and the 9th largest in Europe. Poland has a population of over 38.5 million people, which makes it the 34th most populous country in the world and the sixth most populous member of the European Union, being its most populous post-communist member. Poland is a unitary state made up of 16 voivodeships. Poland is a member of the European Union, NATO, the United Nations, the World Trade Organization, the Organisation for Economic Co-operation and Development (OECD), European Economic Area, International Energy Agency, Council of Europe, Organization for Security and Co-operation in Europe, International Atomic Energy Agency, European Space Agency, G6, Council of the Baltic Sea States, Visegrád Group, Weimar Triangle and Schengen Agreement. 
The establishment of a Polish state is often identified with the adoption of Christianity by its ruler Mieszko I in 966, over the territory similar to that of present-day Poland. The Kingdom of Poland was formed in 1025, and in 1569 it cemented a long association with the Grand Duchy of Lithuania by signing the Union of Lublin, forming the Polish–Lithuanian Commonwealth. The Commonwealth ceased to exist in 1795 as the Polish lands were partitioned among the Kingdom of Prussia, the Russian Empire, and Old Austria. Poland regained its independence as the Second Polish Republic in 1918. Two decades later, in September 1939, World War II started with the Nazi Germany and Soviet Union invasion of Poland (Molotov-Ribbentrop Pact). Over six million Polish citizens died in the war. The People's Republic was declared in 1952 although Poland was a client state of the Soviet Union from the closing days of the war. During the Revolutions of 1989, the communist state was overthrown and democratic rule was re-established in the form of the current Poland, constitutionally known as the "Third Polish Republic".
Despite the vast destruction the country experienced in World War II, Poland managed to preserve much of its cultural wealth. There are currently 14 heritage sites inscribed on the UNESCO World Heritage list in Poland. Since the end of the communist period, Poland has achieved a "very high" ranking in terms of human development.
Etymology.
The source of the name Poland and the ethnonyms for the Poles include endonyms (the way Polish people refer to themselves and their country) and exonyms (the way other peoples refer to the Poles and their country). Endonyms and most exonyms for Poles and Poland derive from the name of the West Slavic tribe of the Polans ("Polanie").
The origin of the name "Polanie" itself is uncertain. It may derive from such Polish words as "pole" (field). The early tribal inhabitants denominated it from the nature of the country. Lowlands and low hills predominate throughout the vast region from the Baltic shores to the foothills of the Carpathian Mountains. "Inter Alpes Huniae et Oceanum est Polonia, sic dicta in eorum idiomate quasi Campania" is the description by Gervase of Tilbury in his "Otia imperialia" (Recreation for the emperor, 1211). In some languages the exonyms for Poland derive from another tribal name, Lechites ("Lechici").
History.
Prehistory.
Historians have postulated that throughout Late Antiquity, many distinct ethnic groups populated the regions of what is now known as Poland. The ethnicity and linguistic affiliation of these groups have been hotly debated; the time and route of the original settlement of Slavic peoples in these regions have been the particular subjects of much controversy.
The most famous archeological find from the prehistory and protohistory of Poland is the Biskupin fortified settlement (now reconstructed as a museum), dating from the Lusatian culture of the early Iron Age, around 700 BC. Before adopting Christianity in 960 AD, the people of Poland believed in Svetovid, the Slavic god of war, fertility, and abundance. Many other Slavic nations had the same belief.
Piast dynasty.
Poland began to form into a recognizable unitary and territorial entity around the middle of the 10th century under the Piast dynasty. Poland's first historically documented ruler, Mieszko I, was baptized in 966, adopting Catholicism as the nation's new official religion, to which the bulk of the population converted in the course of the next few centuries. In 1000 Boleslaw the Brave, continuing the policy of his father held a Congress of Gniezno and created a new dioceses (Gniezno, Kraków, Kołobrzeg, Wrocław). In the 12th century, Poland fragmented into several smaller duchies when Bolesław divided the nation amongst his sons. In 1226 Konrad I of Masovia, one of the regional Piast dukes, invited the Teutonic Knights to help him fight the Baltic Prussian pagans; a decision which would ultimately lead to centuries of warfare with the Knights. In the middle of 13th century Poland was almost united by Silesian branch of Piast dynasty (Henry I the Bearded and Henry II the Pious), when the country was devastated by the Mongols and the Battle of Legnica where Duke Henry II the Pious died. In 1320, after a number of earlier unsuccessful attempts by regional rulers at uniting the Polish dukedoms, Władysław I consolidated his power, took the throne and became the first King of a reunified Poland. His son, Casimir III, is remembered as one of the greatest Polish kings, who was widely recognized as a protector of trade. He extended his kingdom to 250% of its initial size. Casimir is also known for extending royal protection to Jews and providing the original impetus for the establishment of Poland's first university.
The Golden Liberty of the nobles began to develop under Casimir's rule, when in return for their military support, the king made serious concessions to the aristocrats, finally establishing their status as superior to that of the townsmen, and aiding their rise to power. When Casimir died in 1370 he left no legitimate male heir and, considering his other male descendants either too young or unsuitable, was laid to rest as the last of the nation's Piast rulers.
Poland was also a centre of migration of peoples. The Germans settled in the towns, the Jewish community began to settle and flourish in Poland during this era (see History of the Jews in Poland); the same applies in smaller number to Armenians. The Black Death which affected most parts of Europe from 1347 to 1351 affected Poland to lesser extent.
Jagiellon dynasty.
The rule of the Jagiellon dynasty spanned the late Middle Ages and early Modern Era of Polish history. Beginning with the Lithuanian Grand Duke Jogaila (Władysław II Jagiełło), the Jagiellon dynasty (1386–1572) formed the Polish–Lithuanian union. The partnership brought vast Lithuania-controlled Rus' areas into Poland's sphere of influence and proved beneficial for the Poles and Lithuanians, who coexisted and cooperated in one of the largest political entities in Europe for the next four centuries. In the Baltic Sea region Poland's struggle with the Teutonic Knights continued and included the Battle of Grunwald (1410), where a Polish-Lithuanian army inflicted a decisive defeat on the Teutonic Knights, both countries' main adversary, allowing Poland's and Lithuania's territorial expansion into the far north region of Livonia. In 1466, after the Thirteen Years' War, King Casimir IV Jagiellon gave royal consent to the milestone Peace of Thorn, which created the future Duchy of Prussia, a Polish vassal. The Jagiellons at one point also established dynastic control over the kingdoms of Bohemia (1471 onwards) and Hungary. In the south Poland confronted the Ottoman Empire and the Crimean Tatars (by whom they were attacked on 75 separate occasions between 1474 and 1569), and in the east helped Lithuania fight the Grand Duchy of Moscow. Some historians estimate that Crimean Tatar slave-raiding cost Poland one million of its population from 1494 to 1694.
Poland was developing as a feudal state, with a predominantly agricultural economy and an increasingly powerful landed nobility. The "Nihil novi" act adopted by the Polish Sejm (parliament) in 1505, transferred most of the legislative power from the monarch to the Sejm, an event which marked the beginning of the period known as "Golden Liberty", when the state was ruled by the "free and equal" Polish nobility. Protestant Reformation movements made deep inroads into Polish Christianity, which resulted in the establishment of policies promoting religious tolerance, unique in Europe at that time. It is believed that this tolerance allowed the country to avoid the religious turmoil that spread over Europe during the late Middle Ages. The European Renaissance evoked in late Jagiellon Poland (kings Sigismund I the Old and Sigismund II Augustus) a sense of urgency in the need to promote a cultural awakening, and resultantly during this period Polish culture and the nation's economy flourished. In 1543 the Pole, Nicolaus Copernicus, an astronomer from Toruń, published his epochal works, "De revolutionibus orbium coelestium" ("On the Revolutions of the Celestial Spheres"), and thus became the first proponent of a predictive mathematical model confirming heliocentric theory which ultimately became the accepted basic model for the practice of modern astronomy. Another major figure associated with the era is classicist poet Jan Kochanowski.
Polish–Lithuanian Commonwealth.
The 1569 Union of Lublin established the Polish–Lithuanian Commonwealth, a more closely unified federal state with an elective monarchy, but which was governed largely by the nobility, through a system of local assemblies with a central parliament. The establishment of the Commonwealth coincided with a period of great stability and prosperity in Poland, with the union soon thereafter becoming a great European power and a major cultural entity, occupying approximately one million square kilometres of central Europe, as well as an agent for the of the 'Western culture' through Polonization in modern-day Ukraine, Belarus and Western Russia. Poland-Lithuania suffered from a number of dynastic crises during the reigns of the Vasa kings Sigismund III and Władysław IV and found itself engaged in a major conflicts with Russia, Sweden and the Ottoman Empire, as well as a series of minor Cossack uprisings.
From the middle of the 17th century, the nobles' democracy, suffering from internal disorder, gradually declined, thus leaving the once powerful Commonwealth extremely vulnerable to foreign intervention.
From 1648, the Cossack Khmelnytsky Uprising engulfed the south and east eventually leaving Ukraine divided, with the eastern part, lost by the Commonwealth, becoming a dependency of the Tsardom of Russia. This was soon followed by the 'Deluge', a Swedish invasion, which raged through the Polish heartlands and caused unprecedented damage to Poland's population, culture and infrastructure. Famines and epidemics followed hostilities, and the population dropped from roughly 11 to 7 million.
However, under John III Sobieski the Commonwealth's military prowess was re-established, and in 1683 Polish forces played a major part in relieving Vienna of a major Turkish siege which was being conducted by Kara Mustafa in hope of eventually marching his troops further into Europe to spread Islam.
Unfortunately, Sobieski's reign was to mark the end of the nation's golden-era, and soon, finding itself subjected to almost constant warfare and suffering enormous population losses as well as massive damage to its economy, the Commonwealth fell into decline. The government became ineffective as a result of large scale internal conflicts (e.g. Lubomirski's Rokosz against John II Casimir and rebellious confederations) and corrupted legislative processes. The nobility fell under the control of a handful of magnates, and this, compounded with two relatively weak kings of the Saxon Wettin dynasty, Augustus II and Augustus III, as well as the rise of Russia and Prussia after the Great Northern War only served to worsen the Commonwealth's plight. Despite this The Commonwealth-Saxony personal union gave rise to the emergence of the Commonwealth's first reform movement, and laid the foundations for the Polish Enlightenment.
During the later part of the 18th century, the Commonwealth made attempts to implement fundamental internal reforms; with the second half of the century bringing a much improved economy, significant population growth and far-reaching progress in the areas of education, intellectual life, art, and especially toward the end of the period, evolution of the social and political system. The most populous capital city of Warsaw replaced Gdańsk (Danzig) as the leading centre of commerce, and the role of the more prosperous townsfolk soon increased. The royal election of 1764 resulted in the elevation of Stanisław August Poniatowski, a refined and worldly aristocrat connected to a major magnate faction, to the monarchy. However, a one-time lover of Empress Catherine II of Russia, the new king spent much of his reign torn between his desire to implement reforms necessary to save his nation, and his perceived necessity to remain in a relationship with his Russian sponsor. This ultimately led to the formation of the 1768 Bar Confederation; a "szlachta" rebellion directed against Russia and the Polish king which fought to preserve Poland's independence and the "szlachta"'s traditional privileges.
Attempts at reform provoked the union's neighbours, and in 1772 the First Partition of the Commonwealth by Russia, Austria and Prussia took place; an act which the "Partition Sejm", under considerable duress, eventually "ratified" "fait accompli". Disregarding this loss, in 1773 the king established the Commission of National Education, the first government education authority in Europe.
The long-lasting Great Sejm convened by Stanisław August in 1788 successfully adopted the May 3 Constitution, the first set of modern supreme national laws in Europe. However, this document, accused by detractors of harbouring revolutionary sympathies, soon generated strong opposition from the Commonwealth's nobles and conservatives as well as from Catherine II, who, determined to prevent the rebirth of a strong Commonwealth set about planning the final dismemberment of the Polish-Lithuanian state. Russia was greatly aided in achieving its goal when the Targowica Confederation, an organisation of Polish nobles, appealed to the Empress for help, and in May 1792 Russian forces crossed the Commonwealth's frontier, thus beginning the Polish-Russian War.
The defensive war fought by the Poles and Lithuanians ended prematurely when the King, convinced of the futility of resistance, capitulated and joined the Targowica Confederation. The Confederation then took over the government; Russia and Prussia, fearing the mere existence of a Polish state, arranged for, and subsequently in 1793, executed the Second Partition of the Commonwealth, which left the country deprived of so much territory that it was practically incapable of independent existence. Eventually, in 1795, following the failed Kościuszko Uprising, the Commonwealth was partitioned one last time by all three of its more powerful neighbours, and with this, effectively ceased to exist.
The Age of Partitions.
Poles rebelled several times against the partitioners, particularly near the end of the 18th century and the beginning of the 19th century. One of the most famous and successful attempts at securing renewed Polish independence took place in 1794, during the Kościuszko Uprising, at the Racławice where Tadeusz Kosciuszko, a popular and distinguished general who had served under Washington in America, led peasants and some Polish regulars into battle against numerically superior Russian forces. In 1807, Napoleon I of France recreated a Polish state, the Duchy of Warsaw, but after the Napoleonic Wars, Poland was again divided by the victorious Allies at the Congress of Vienna of 1815. The eastern part was ruled by the Russian tsar as a Congress Kingdom which possessed a very liberal constitution. However, the tsars soon reduced Polish freedoms, and Russia annexed the country in virtually all but name. Thus in the latter half of the 19th century, only Austrian-ruled Galicia, and particularly the Free City of Kraków, created good environment for free Polish cultural life to flourish.
Throughout the period of the partitions, political and cultural repression of the Polish nation led to the organisation of a number of uprisings against the authorities of the occupying Russian, Prussian and Austrian governments. Notable amongst these are the November Uprising of 1830 and January Uprising of 1863, both of which were attempts to free Poland from the rule of tsarist Russia. The November uprising began on 29 November 1830 in Warsaw when, led by Lieutenant Piotr Wysocki, young non-commissioned officers at the Imperial Russian Army's military academy in that city revolted. They were soon joined by large segments of Polish society, and together forced Warsaw's Russian garrison to withdraw north of the city.
Over the course of the next seven months, Polish forces successfully defeated the Russian armies of Field Marshal Hans Karl von Diebitsch and a number of other Russian commanders; however, finding themselves in a position unsupported by any other foreign powers, save distant France and the newborn United States, and with Prussia and Austria refusing to allow the import of military supplies through their territories, the Poles accepted that the uprising was doomed to failure. Upon the surrender of Warsaw to General Ivan Paskievich, many Polish troops, feeling they could not go on, withdrew into Germany and there laid down their arms. Poles would have to wait another 32 years for another opportunity to free their homeland.
When in January 1863 a new Polish uprising against Russian rule began, it did so as a spontaneous protest by young Poles against conscription into the Imperial Russian Army. However, the insurrectionists, despite being joined by high-ranking Polish-Lithuanian officers and numerous politicians were still severely outnumbered and lacking in foreign support. They were forced to resort to guerrilla warfare tactics and ultimately failed to win any major military victories. Afterwards no major uprising was witnessed in the Russian controlled Congress Poland and Poles resorted instead to fostering economic and cultural self-improvement.
Despite the political unrest experienced during the partitions, Poland did benefit from large scale industrialisation and modernisation programs, instituted by the occupying powers, which helped it develop into a more economically coherent and viable entity. This was particularly true in the Greater Poland, Pomerania and Warmia annexed by Prussia (later becoming a part of the German Empire); an area which eventually, thanks largely to the Greater Poland Uprising, was reconstituted as a part of the Second Polish Republic and became one of its most productive regions.
Reconstitution of Poland.
During World War I, all the Allies agreed on the reconstitution of Poland that United States President Woodrow Wilson proclaimed in Point 13 of his Fourteen Points. A total of 2 million Polish troops fought with the armies of the three occupying powers, and 450,000 died. Shortly after the armistice with Germany in November 1918, Poland regained its independence as the Second Polish Republic ("II Rzeczpospolita Polska"). It reaffirmed its independence after a series of military conflicts, the most notable being the Polish–Soviet War (1919–1921) when Poland inflicted a crushing defeat on the Red Army at the Battle of Warsaw, an event which is considered to have ultimately halted the advance of Communism into Europe and forced Vladimir Lenin to rethink his objective of achieving global socialism. Nowadays the event is often referred to as the 'Miracle at the Vistula'.
During this period, Poland successfully managed to fuse the territories of the three former partitioning powers into a cohesive nation state. Railways were restructured to direct traffic towards Warsaw instead of the former imperial capitals, a new network of national roads was gradually built up and a major seaport was opened on the Baltic Coast, so as to allow Polish exports and imports to bypass the politically charged Free City of Danzig.
The inter-war period heralded in a new era of Polish politics. Whilst Polish political activists had faced heavy censorship in the decades up until the First World War, the country now found itself trying to establish a new political tradition. For this reason, many exiled Polish activists, such as Jan Paderewski (who would later become Prime Minister) returned home to help; a great number of them then went on to take key positions in the newly formed political and governmental structures. Tragedy struck in 1922 when Gabriel Narutowicz, inaugural holder of the Presidency, was assassinated at the Zachęta Gallery in Warsaw by painter and right-wing nationalist Eligiusz Niewiadomski.
The 1926 May Coup of Józef Piłsudski turned rule of the Second Polish Republic over to the Sanacja movement. By the 1930s Poland had become increasingly authoritarian; a number of 'undesirable' political parties, such as the Polish Communists, had been banned and following Piłsudski's death, the regime, unable to appoint a new leader, began to show its inherent internal weaknesses and unwillingness to cooperate in any way with other political parties.
World War II.
The Sanacja movement controlled Poland until the start of World War II in 1939, when Nazi Germany's Invasion of Poland (1939) on 1 September and the Soviet invasion of Poland on 17 September, which followed the breaking of the Soviet–Polish Non-Aggression Pact, occurred. Warsaw capitulated on 28 September 1939. As agreed in the Molotov–Ribbentrop Pact, Poland was split into two zones, one occupied by Nazi Germany while the Kresy, or Borderlands, fell under the control of the Soviet Union. By 1941, the Soviets had moved hundreds of thousands of Poles into labor camps scattered across the Soviet Union, and the Soviet secret police, NKVD, had executed thousands of Polish prisoners of war.
Poland made the fourth-largest troop contribution to the Allied war effort, after the Soviets, the British and the Americans. Polish troops fought under the command of both the Polish Government in Exile in the theatre of war west of Germany and under Soviet leadership in the theatre of war east of Germany. The Polish expeditionary corps, which was controlled by the exiled pre-war government based in London, played an important role in the Italian and North African Campaigns. They are particularly well remembered for their conduct at the Battle of Monte Cassino, a conflict which culminated in the raising of a Polish flag over the ruins of the mountain-top abbey by the 12th Podolian Uhlans. The Polish forces in the theatre of war east of Germany were commanded by Lieutenant General Władysław Anders who had received his command from Prime Minister of the exiled government Władysław Sikorski. On the east of Germany, the Soviet-backed Polish 1st Army distinguished itself in the battles for Berlin and Warsaw, although its actions in support of the latter have often been criticised.
Polish servicemen were also active in the theatres of naval and air warfare; during the Battle of Britain Polish squadrons such as the No. 303 "Kościuszko" fighter squadron achieved great success, and by the end of the war the exiled Polish Air Forces could claim 769 confirmed kills. Meanwhile, the Polish Navy was active in the protection of convoys in the North Sea and Atlantic Ocean.
In addition to the organised units of the 1st Army and the Forces in the Nazi-occupied Europe, the domestic underground resistance movement, the Armia Krajowa, or "Home Army", fought to free Poland from German occupation and establish an independent Polish state. The wartime resistance movement in Poland was one of the three largest resistance movements of the entire war and encompassed an unusually broad range of clandestine activities, which essentially functioned as an underground state complete with degree-awarding universities and a court system. The resistance was, however, largely loyal to the exiled government and generally resented the idea of a communist Poland; for this reason, on 1 August 1944 they initiated Operation Tempest and thus began the Warsaw Uprising. The objective of the uprising was to drive the German occupiers from the city and help with the larger fight against Germany and the Axis powers, however secondary motives for the uprising sought to see Warsaw liberated before the Soviets could reach the capital, so as to underscore Polish sovereignty by empowering the Polish Underground State before the Soviet-backed Polish Committee of National Liberation could assume control. However, a lack of available allied military aid and Stalin's reluctance to allow the 1st Army to help their fellow countrymen take the city, ultimately led to the uprising's failure and subsequent planned destruction of the city.
During the war, German forces, under direct order from Adolf Hitler, set up six major extermination camps, all of which were established on Polish territory; these included both the notorious Treblinka and Auschwitz camps. This allowed the Germans to transport the Jews living in the Third Reich outside of "German" territory, as well as to import Jews and other targeted groups from across occupied Europe to be "liquidated," or killed, in the concentration camps set up in the General Government. Among such groups were Polish intelligentsia, communists, Roma peoples and Soviet Prisoners of War. However, since millions of Jews lived in pre-war Poland, Jewish victims make up the largest percentage of all victims of the Nazis' extermination program. It is estimated that, of pre-war Poland's Jewry, approximately 90% (or about 3 million members) were killed. Throughout the occupation, many members of the Armia Krajowa, supported by the Polish government in exile, and millions of ordinary Poles — at great risk to themselves and their families — engaged in rescuing Jews from the Nazi Germans. Grouped by nationality, Poles represent the largest number of people who rescued Jews during the Holocaust. To date, 6,135 Poles have been awarded the title of "Righteous among the Nations" by the State of Israel–more than any other nation. Some estimates put the number of Poles involved in rescue efforts at up to 3 million, and credit Poles with saving up to approximately 450,000 Jews from certain death.
At the war's conclusion, Poland's territory was shifted westwards, pushing the Kresy in accordance with the Curzon Line. Meanwhile, the western border moved to the Oder-Neisse line. As a result, Poland's territory was reduced by 20%, or . The shift forced the migration of millions of people, most of whom were Poles, Germans, Ukrainians, and Jews. Of all the countries involved in the war, Poland lost the highest percentage of its citizens: over 6 million perished — nearly one-fifth of Poland's population — half of them Polish Jews. Over 90% of deaths were non-military in nature. Only in the 1970s did Poland again approach its prewar population levels.
Postwar communist Poland.
At the insistence of Joseph Stalin, the Yalta Conference sanctioned the formation of a new Polish provisional and pro-Communist coalition government in Moscow, which ignored the Polish government-in-exile based in London; a move which angered many Poles who considered it a betrayal by the Allies. In 1944, Stalin had made guarantees to Churchill and Roosevelt that he would maintain Poland's sovereignty and allow democratic elections to take place; however, upon achieving victory in 1945, the occupying Soviet authorities organised an election which constituted nothing more than a sham and was ultimately used to claim the 'legitimacy' of Soviet hegemony over Polish affairs. The Soviet Union instituted a new communist government in Poland, analogous to much of the rest of the Eastern Bloc. As elsewhere in Communist Europe the Soviet occupation of Poland met with armed resistance from the outset which continued into the fifties.
Despite widespread objections, the new Polish government accepted the Soviet annexation of the pre-war eastern regions of Poland (in particular the cities of Wilno and Lwów) and agreed to the permanent garrisoning of Red Army units on Poland's territory. Military alignment within the Warsaw Pact throughout the Cold War came about as a direct result of this change in Poland's political culture and in the European scene came to characterise the fully-fledged integration of Poland into the brotherhood of communist nations.
The People's Republic of Poland ("Polska Rzeczpospolita Ludowa") was officially proclaimed in 1952. In 1956 after the death of Bolesław Bierut, the régime of Władysław Gomułka became temporarily more liberal, freeing many people from prison and expanding some personal freedoms. A similar situation repeated itself in the 1970s under Edward Gierek, but most of the time persecution of anti-communist opposition groups persisted. Despite this, Poland was at the time considered to be one of the least repressive states of the Soviet Bloc.
Labour turmoil in 1980 led to the formation of the independent trade union "Solidarity" (""Solidarność""), which over time became a political force. Despite persecution and imposition of martial law in 1981, it eroded the dominance of the Communist Party and by 1989 had triumphed in Poland's first partially free and democratic parliamentary elections since the end of the Second World War. Lech Wałęsa, a Solidarity candidate, eventually won the presidency in 1990. The Solidarity movement heralded the collapse of communist regimes and parties across Europe.
Present-day Poland.
A shock therapy programme, initiated by Leszek Balcerowicz in the early 1990s enabled the country to transform its socialist-style planned economy into a market economy. As with all other post-communist countries, Poland suffered temporary slumps in social and economic standards, but it became the first post-communist country to reach its pre-1989 GDP levels, which it achieved by 1995 largely thanks to its booming economy.
Most visibly, there were numerous improvements in human rights, such as the freedom of speech, civil liberties (1st class) and political rights (1st class), according to Freedom House. In 1991, Poland became a member of the Visegrád Group and joined the North Atlantic Treaty Organization (NATO) alliance in 1999 along with the Czech Republic and Hungary. Poles then voted to join the European Union in a referendum in June 2003, with Poland becoming a full member on 1 May 2004. Subsequently Poland joined the Schengen Area in 2007, as a result of which, the country's borders with other member states of the European Union have been dismantled, allowing for full freedom of movement within most of the EU. In contrast to this, the section of Poland's eastern border now comprising the external EU border with Belarus, Russia and Ukraine, has become increasingly well protected, and has led in part to the coining of the phrase 'Fortress Europe', in reference to the seeming 'impossibility' of gaining entry to the EU for citizens of the former Soviet Union.
On April 10, 2010, the President of the Republic of Poland, Lech Kaczyński, along with 89 other high-ranking Polish officials died in a plane crash near Smolensk, Russia. The president's party were on their way to attend an annual service of commemoration for the victims of the Katyń massacre when the tragedy took place.
Geography.
Poland's territory extends across several geographical regions, between latitudes 49° and 55° N, and longitudes 14° and 25° E. In the north-west is the Baltic seacoast, which extends from the Bay of Pomerania to the Gulf of Gdańsk. This coast is marked by several spits, coastal lakes (former bays that have been cut off from the sea), and dunes. The largely straight coastline is indented by the Szczecin Lagoon, the Bay of Puck, and the Vistula Lagoon. The centre and parts of the north lie within the North European Plain.
Rising gently above these lowlands is a geographical region comprising the four hilly districts of moraines and moraine-dammed lakes formed during and after the Pleistocene ice age. These lake districts are the Pomeranian Lake District, the Greater Polish Lake District, the Kashubian Lake District, and the Masurian Lake District. The Masurian Lake District is the largest of the four and covers much of north-eastern Poland. The lake districts form part of the Baltic Ridge, a series of moraine belts along the southern shore of the Baltic Sea.
South of the Northern European Lowlands lie the regions of Silesia and Masovia, which are marked by broad ice-age river valleys. Farther south lies the Polish mountain region, including the Sudetes, the Cracow-Częstochowa Upland, the Świętokrzyskie Mountains, and the Carpathian Mountains, including the Beskids. The highest part of the Carpathians is the Tatra Mountains, along Poland's southern border.
Geology.
The geological structure of Poland has been shaped by the continental collision of Europe and Africa over the past 60 million years, on the one hand (and the other), by the Quaternary glaciations of northern Europe. Both processes shaped the Sudetes and the Carpathian Mountains. The moraine landscape of northern Poland contains soils made up mostly of sand or loam, while the ice age river valleys of the south often contain loess. The Cracow-Częstochowa Upland, the Pieniny, and the Western Tatras consist of limestone, while the High Tatras, the Beskids, and the Karkonosze are made up mainly of granite and basalts. The Polish Jura Chain is one of the oldest mountain ranges on earth.
Poland has 70 mountains over 2,000 metres (6,600 ft) in elevation, all in the Tatras. The Polish Tatras, which consist of the High Tatras and the Western Tatras, is the highest mountain group of Poland and of the entire Carpathian range. In the High Tatras lies Poland’s highest point, the north-western peak of Rysy, in elevation. At its foot lies the mountain lakes of Czarny Staw pod Rysami (Black Lake below Mount Rysy), and Morskie Oko (the Marine Eye).
The second highest mountain group in Poland is the Beskids, whose highest peak is Babia Góra, at . The next highest mountain groups is the Karkonosze in the Sudetes, whose highest point is Śnieżka, at ; Śnieżnik Mountains whose highest point is Śnieżnik, at .
Tourists also frequent the Bieszczady Mountains in the far southeast of Poland, whose highest point in Poland is Tarnica, with an elevation of , Gorce Mountains in Gorce National Park, whose highest point is Turbacz, with elevations , and the Pieniny in Pieniny National Park, whose highest point is Wysokie Skałki (Wysoka), with elevations . The lowest point in Poland — at below sea level — is at Raczki Elbląskie, near Elbląg in the Vistula Delta.
The only desert located in Poland stretches over the Zagłębie Dąbrowskie (the Coal Fields of Dąbrowa) region. It is called the Błędów Desert, located in the Silesian Voivodeship in southern Poland. It has a total area of . It is one of only five natural deserts in Europe. But also, it is the warmest desert that appears at this latitude. Błędów Desert was created thousands of years ago by a melting glacier. The specific geological structure has been of big importance. The average thickness of the sand layer is about , with a maximum of , which made the fast and deep drainage very easy.
The Baltic Sea activity in Słowiński National Park created sand dunes which in the course of time separated the bay from the sea. As waves and wind carry sand inland the dunes slowly move, at a speed of meters per year. Some dunes are quite high – up to . The highest peak of the park — Rowokol ( above sea level) — is also an excellent observation point.
Waters.
The longest rivers are the Vistula (), long; the Oder () which forms part of Poland’s western border, long; its tributary, the Warta, long; and the Bug, a tributary of the Vistula, long. The Vistula and the Oder flow into the Baltic Sea, as do numerous smaller rivers in Pomerania.
The Łyna and the Angrapa flow by way of the Pregolya to the Baltic, and the Czarna Hańcza flows into the Baltic through the Neman. While the great majority of Poland’s rivers drain into the Baltic Sea, Poland’s Beskids are the source of some of the upper tributaries of the Orava, which flows via the Váh and the Danube to the Black Sea. The eastern Beskids are also the source of some streams that drain through the Dniester to the Black Sea.
Poland’s rivers have been used since early times for navigation. The Vikings, for example, traveled up the Vistula and the Oder in their longships. In the Middle Ages and in early modern times, when the Polish–Lithuanian Commonwealth was the breadbasket of Europe; the shipment of grain and other agricultural products down the Vistula toward Gdańsk and onward to other parts of Europe took on great importance.
With almost ten thousand closed bodies of water covering more than each, Poland has one of the highest numbers of lakes in the world. In Europe, only Finland has a greater density of lakes. The largest lakes, covering more than , are Lake Śniardwy and Lake Mamry in Masuria, and Lake Łebsko and Lake Drawsko in Pomerania.
In addition to the lake districts in the north (in Masuria, Pomerania, Kashubia, Lubuskie, and Greater Poland), there is also a large number of mountain lakes in the Tatras, of which the Morskie Oko is the largest in area. The lake with the greatest depth—of more than —is Lake Hańcza in the Wigry Lake District, east of Masuria in Podlaskie Voivodeship.
Among the first lakes whose shores were settled are those in the Greater Polish Lake District. The stilt house settlement of Biskupin, occupied by more than one thousand residents, was founded before the 7th century BC by people of the Lusatian culture.
Lakes have always played an important role in Polish history and continue to be of great importance to today's modern Polish society. The ancestors of today’s Poles, the Polanie, built their first fortresses on islands in these lakes. The legendary Prince Popiel is supposed to have ruled from Kruszwica on Lake Gopło. The first historically documented ruler of Poland, Duke Mieszko I, had his palace on an island in the Warta River in Poznań. Nowadays the Polish lakes provide an invaluable location for the pursuit of water sports such as yachting and wind-surfing.
The Polish Baltic coast is approximately long and extends from Świnoujście on the islands of Usedom and Wolin in the west to Krynica Morska on the Vistula Spit in the east. For the most part, Poland has a smooth coastline, which has been shaped by the continual movement of sand by currents and winds. This continual erosion and deposition has formed cliffs, dunes, and spits, many of which have migrated landwards to close off former lagoons, such as Łebsko Lake in Słowiński National Park.
Prior to the end of the Second World War and subsequent change in national borders, Poland had only a very small coastline; this was situated at the end of the 'Polish Corridor', the only internationally recognised Polish territory which afforded the country access to the sea. However after World War II, the redrawing of Poland's borders and resulting 'shift' of the country's borders left it with a greatly expanded coastline, thus allowing for far greater access to the sea than was ever previously possible. The significance of this event, and importance of it to Poland's future as a major industrialised nation, was allured to by the 1945 Wedding to the Sea.
The largest spits are Hel Peninsula and the Vistula Spit. The largest Polish Baltic island is Wolin. The largest port cities are Gdynia, Gdańsk, Szczecin, and Świnoujście. The main coastal resorts are Sopot, Międzyzdroje, Kołobrzeg, Łeba, Władysławowo, and the Hel Peninsula.
Land use.
Forests cover 28.8% of Poland’s land area. More than half of the land is devoted to agriculture. While the total area under cultivation is declining, the remaining farmland is more intensively cultivated.
More than 1% of Poland’s territory, , is protected within 23 Polish national parks. Three more national parks are projected for Masuria, the Cracow-Częstochowa Upland, and the eastern Beskids. In addition, wetlands along lakes and rivers in central Poland are legally protected, as are coastal areas in the north. There are over 120 areas designated as landscape parks, along with numerous nature reserves and other protected areas.
Present day Poland is a country with great agricultural prospects; there are over two million private farms in the country, and Poland is the leading producer in Europe of potatoes and rye and is one of the world's largest producers of sugar beets and triticale. This has led Poland to be described on occasion as the future 'bread basket of the European Union'. However, despite employing around 16% of the workforce, agricultural output in Poland remains low and the industry is characterised as largely inefficient due to the large number of small, independent farms. This situation is likely to soon change for the better with the government debating agricultural reform and currently pursuing the option of auctioning off large tracts of state-owned agricultural land.
Biodiversity.
Phytogeographically, Poland belongs to the Central European province of the Circumboreal Region within the Boreal Kingdom. According to the World Wide Fund for Nature, the territory of Poland can be subdivided into three ecoregions: the Baltic mixed forests, Central European mixed forests and Carpathian montane conifer forests.
Many animals that have since died out in other parts of Europe still survive in Poland, such as the wisent in the ancient woodland of the Białowieża Forest and in Podlaskie. Other such species include the brown bear in Białowieża, in the Tatras, and in the Beskids, the gray wolf and the Eurasian Lynx in various forests, the moose in northern Poland, and the beaver in Masuria, Pomerania, and Podlaskie.
In the forests, one also encounters game animals, such as red deer, roe deer and wild boars. In eastern Poland there are a number of ancient woodlands, like Białowieża forest, that have never been cleared by people. There are also large forested areas in the mountains, Masuria, Pomerania, Lubusz Land and Lower Silesia.
Poland is the most important breeding ground for European migratory birds. Out of all of the migratory birds who come to Europe for the summer, one quarter breed in Poland, particularly in the lake districts and the wetlands along the Biebrza, the Narew, and the Warta, which are part of nature reserves or national parks.
Climate.
The climate is mostly temperate throughout the country. The climate is oceanic in the north and west and becomes gradually warmer and continental towards the south and east. Summers are generally warm, with average temperatures between and depending on a region. Winters are rather cold, with average temperatures around in the northwest and in the northeast. Precipitation falls throughout the year, although, especially in the east; winter is drier than summer.
The warmest region in Poland is Lower Silesian located in south-western Poland where temperatures in the summer average between and but can go as high as to on some days in the warmest month of July and August. The warmest cities in Poland are Tarnów, which is situated in Lesser Poland and Wrocław, which is located in Lower Silesian. The average temperatures in Wrocław are in the summer and in the winter, but Tarnów has the longest summer in all of Poland, which lasts for 115 days, from mid-May to mid-September. The coldest region of Poland is in the northeast in the Podlaskie Voivodeship near the border of Belarus. Usually the coldest city is Suwałki. The climate is affected by cold fronts which come from Scandinavia and Siberia. The average temperature in the winter in Podlaskie ranges from to .
Politics.
Poland is a democracy, with a president as a head of state, whose current constitution dates from 1997. The government structure centers on the Council of Ministers, led by a prime minister. The president appoints the cabinet according to the proposals of the prime minister, typically from the majority coalition in the Sejm. The president is elected by popular vote every five years. The president is Bronisław Komorowski. Komorowski replaced President Lech Kaczyński following the latter's death in an April 10, 2010 air crash. The prime minister, Donald Tusk, was appointed in 2007 after his Civic Platform party made significant gains in that year's parliamentary elections. In 2011, Tusk became the first Polish prime minister in history to be democratically re-elected for a consecutive term.
Polish voters elect a bicameral parliament consisting of a 460-member lower house (Sejm) and a 100-member Senate (Senat). The Sejm is elected under proportional representation according to the d'Hondt method, a method similar to that used in many parliamentary political systems. The Senat, on the other hand, is elected under the First-past-the-post voting method, with one senator being returned from each of the 100 constituencies.
With the exception of ethnic minority parties, only candidates of political parties receiving at least 5% of the total national vote can enter the Sejm. When sitting in joint session, members of the Sejm and Senat form the National Assembly (the "Zgromadzenie Narodowe"). The National Assembly is formed on three occasions: when a new President takes the oath of office; when an indictment against the President of the Republic is brought to the State Tribunal ("Trybunał Stanu"); and when a president's permanent incapacity to exercise his duties because of the state of his health is declared. To date only the first instance has occurred.
The judicial branch plays an important role in decision-making. Its major institutions include the Supreme Court of the Republic of Poland ("Sąd Najwyższy"); the Supreme Administrative Court of the Republic of Poland ("Naczelny Sąd Administracyjny"); the Constitutional Tribunal of the Republic of Poland ("Trybunał Konstytucyjny"); and the State Tribunal of the Republic of Poland ("Trybunał Stanu"). On the approval of the Senat, the Sejm also appoints the ombudsman or the Commissioner for Civil Rights Protection ("Rzecznik Praw Obywatelskich") for a five-year term. The ombudsman has the duty of guarding the observance and implementation of the rights and liberties of Polish citizens and residents, of the law and of principles of community life and social justice.
In 2011, Poles elected Anna Grodzka as the first ever transsexual MP in European history, and the second transgender MP in European history, after the Italian Vladimir Luxuria.
Law.
The Constitution of Poland is the supreme law in contemporary Poland, and the Polish legal system is based on the principle of civil rights, governed by the code of Civil Law. Historically, the most famous Polish legal act is the Constitution of May 3, 1791. Historian Norman Davies describes it as the first of its kind in Europe. The Constitution was instituted as a Government Act () and then adopted on May 3, 1791 by the Sejm of the Polish–Lithuanian Commonwealth. Primarily, it was designed to redress long-standing political defects of the federative Polish–Lithuanian Commonwealth and its Golden Liberty. Previously only the Henrican articles signed by each of Poland's elected kings could perform the function of a set of basic laws. The new Constitution introduced political equality between townspeople and the nobility ("szlachta"), and placed the peasants under the protection of the government, thus mitigating the worst abuses of serfdom. The Constitution abolished pernicious parliamentary institutions such as the "liberum veto", which at one time had placed the sejm at the mercy of any deputy who might choose, or be bribed by an interest or foreign power, to have rescinded all the legislation that had been passed by that sejm. The May 3rd Constitution sought to supplant the existing anarchy fostered by some of the country's reactionary magnates, with a more egalitarian and democratic constitutional monarchy.
Unfortunately, the adoption of such a liberal constitution was treated as a grave threat by Poland's more autocratic neighbours. In response Prussia, Austria and Russia formed an anti-Polish alliance and over the next decade collaborated with one another to partition their weaker neighbour and ultimately destroy the Polish state. In the words of two of its co-authors, Ignacy Potocki and Hugo Kołłątaj, the constitution represented "the last will and testament of the expiring Fatherland." Despite this, its text influenced many later democratic movements across the globe.
Poland's current constitution was adopted by the National Assembly of Poland on 2 April 1997, approved by a national referendum on 25 May 1997, and came into effect on 17 October 1997. It guarantees a multi-party state, the freedoms of religion, speech and assembly, and specifically casts off many Communist ideals to create a 'free market economic system'. It requires public officials to pursue ecologically sound public policy and acknowledges the inviolability of the home, the right to form trade unions, and to strike, whilst at the same time prohibiting the practices of forced medical experimentation, torture and corporal punishment.
Foreign relations.
In recent years, Poland has extended its responsibilities and position in European and international affairs, supporting and establishing friendly relations with other European nations and a large number of 'developing' countries.
In 1994, Poland became an associate member of the European Union (EU) and its defensive arm, the Western European Union (WEU), having submitted preliminary documentation for full membership in 1996, it formally joined the European Union in May 2004, along with the other members of the Visegrád group. In 1996, Poland achieved full OECD membership, and at the 1997 Madrid Summit was invited to join the North Atlantic Treaty Organisation (NATO) in the first wave of policy enlargement finally becoming a full member of NATO in March 1999.
As changes since the fall of Communism in 1989 have redrawn the map of central Europe, Poland has tried to forge strong and mutually beneficial relationships with its seven new neighbours, this has notably included signing 'friendship treaties' to replace links severed by the collapse of the Warsaw Pact. The Poles have forged special relationships with Lithuania and particularly Ukraine, with whom they will co-host the UEFA Euro 2012 football tournament, in an effort to firmly anchor these countries within the Western world and provide them with an alternative to aligning themselves with the Russian Federation respectively. Despite many positive developments in the region, Poland has found itself in a position where it must seek to defend the rights of ethnic Poles living in the former Soviet Union; this is particularly true of Belarus, where in 2005 the Lukashenko regime launched a campaign against the Polish ethnic minority.
Poland is the sixth most populous member state of the European Union and, ever since joining in 2004, has pursued policies to increase its role in European affairs. Poland has a grand total of 51 representatives in the European Parliament and in addition to this, since 14 July 2009, former Prime Minister of Poland Jerzy Buzek, has been President of the European Parliament.
Administrative divisions.
Poland's current voivodeships (provinces) are largely based on the country's historic regions, whereas those of the past two decades (to 1998) had been centred on and named for individual cities. The new units range in area from less than for Opole Voivodeship to more than for Masovian Voivodeship. Administrative authority at voivodeship level is shared between a government-appointed voivode (governor), an elected regional assembly ("sejmik") and an executive elected by that assembly.
The voivodeships are subdivided into "powiats" (often referred to in English as counties), and these are further divided into "gminas" (also known as communes or municipalities). Major cities normally have the status of both "gmina" and "powiat". Poland currently has 16 voivodeships, 379 powiats (including 65 cities with "powiat" status), and 2,478 "gminas".
Military.
The Polish armed forces are composed of four branches: Land Forces ("Wojska Lądowe"), Navy ("Marynarka Wojenna"), Air Force ("Siły Powietrzne") and Special Forces ("Wojska Specjalne"). The military is subordinate to the Minister for National Defence, however its sole commander in chief is the President of the Republic.
The Polish army currently consists of 65,000 active personnel, whilst the navy and air force respectively employ 14,300 and 26,126 servicemen and women. The Polish Navy is one of the larger navies on the Baltic Sea and is mostly involved in Baltic operations such as search and rescue provision for the section of the Baltic under Polish command, as well as hydrographic measurements and research; recently however, the Polish Navy played a more international role as part of the 2003 invasion of Iraq, providing logistical support for the United States Navy. The current position of the Polish Air Force is much the same; it has routinely taken part in Baltic Air Policing assignments, but otherwise, with the exception of a number of units serving in Afghanistan, has seen no active combat since the end of the Second World War. In 2003, the F-16C Block 52 was chosen as the new general multi-role fighter for the air force, the first deliveries taking place in November 2006; it is expected (2010) that the Polish Air Force will create three squadrons of F-16s, which will all be fully operational by 2012.
The most important mission of the armed forces is the defence of Polish territorial integrity and Polish interests abroad. Poland's national security goal is to further integrate with NATO and European defence, economic, and political institutions through the modernisation and reorganisation of its military.
Currently the armed forces is being re-organised according to NATO standards, and as of 1 January 2010, the transition to an entirely contract-based military has been completed. Previously male citizens were expected to complete a period of active service with the military; since 2007 up until the amendment of the law on conscription, the obligatory term of service was nine months.
Polish military doctrine reflects the same defensive nature as that of its NATO partners. From 1953 to 2009 Poland was a large contributor to various United Nations peacekeeping missions. The Polish Armed Forces took part in the 2003 invasion of Iraq, deploying 2,500 soldiers in the south of that country and commanding the 17-nation Multinational force in Iraq.
The military was temporarily, but severely, affected by the loss of many of its top commanders in the wake the 2010 Polish Air Force Tu-154 crash near Smolensk, Russia, which killed all 96 passengers and crew, including, amongst others, the Chief of the Polish Army's General Staff Franciszek Gągor and Polish Air Force commanding general Andrzej Błasik. They were en route from Warsaw to attend an event to mark the 70th anniversary of the Katyn massacre, whose site is commemorated approximately 19 km west of Smolensk.
Law enforcement and emergency services.
Poland has a highly developed system of law enforcement with a long history of effective policing by the State Police Service. The structure of law enforcement agencies within Poland is a multi-tier one, with the State Police providing criminal-investigative services, Municipal Police serving to maintain public order and a number of other specialised agencies, such as the Polish Border Guard, acting to fulfil their assigned missions. In addition to these state services, private security companies are also common, although they possess no powers assigned to state agencies, such as, for example, the power to make an arrest or detain a suspect.
Emergency services in Poland consist of the Emergency Medical Services, Search and Rescue units of the Polish Armed Forces and State Fire Service. Emergency medical services in Poland are, unlike other services, provided for by local and regional government.
Since joining the European Union all of Poland's emergency services have been undergoing major restructuring and have, in the process, acquired large amounts of new equipment and staff. All emergency services personnel are now uniformed and can be easily recognised thanks to a number of innovative design features, such as reflective paint and printing, present throughout their service dress and vehicle liveries. In addition to this, in an effort to comply with EU standards and safety regulations, the police and other agencies have been steadily replacing and modernising their fleets of vehicles; this has left them with thousands of new automobiles, as well as many new aircraft, boats and helicopters.
Economy.
Poland's high-income economy is considered to be one of the healthiest of the post-Communist countries and is currently one of the fastest growing within the EU. Having a strong domestic market, low private debt, flexible currency, and not being dependent on a single export sector, Poland is the only European economy to have avoided the late-2000s recession. Since the fall of the communist government, Poland has steadfastly pursued a policy of liberalising the economy and today stands out as a successful example of the transition from a centrally planned economy to a primarily market-based economy. In 2009 Poland had the highest GDP growth in the EU. As of February 2012, the Polish economy has not entered a recession in the wake of the global financial crisis.
The privatization of small and medium state-owned companies and a liberal law on establishing new firms have allowed the development of an aggressive private sector. As a consequence, consumer rights organizations have also appeared. Restructuring and privatisation of "sensitive sectors" such as coal, steel, rail transport and energy has been continuing since 1990. Between 2007 and 2010, the government plans to float twenty public companies on the Warsaw Stock Exchange, including parts of the coal industry. The biggest privatisations have been the sale of the national telecoms firm Telekomunikacja Polska to France Télécom in 2000, and an issue of 30% of the shares in Poland's largest bank, PKO Bank Polski, on the Polish stockmarket in 2004.
The Polish banking sector is the largest in central and eastern Europe as well being as the largest and the most highly developed sector of the country’s financial markets. It is regulated by the Polish Financial Supervision Authority. During the transformation to a market-oriented economy, the government privatized some banks, recapitalized the rest and introduced legal reforms that made the sector competitive. This has attracted a significant number of strategic foreign investors. Poland’s banking sector has approximately 5 domestic banks, a network of nearly 600 cooperative banks and 18 branches of foreign-owned banks. In addition, foreign investors have controlling stakes in nearly 40 commercial banks, which make up 68% of the banking capital.
Poland has a large number of private farms in its agricultural sector, with the potential to become a leading producer of food in the European Union. Structural reforms in health care, education, the pension system, and state administration have resulted in larger-than-expected fiscal pressures. Warsaw leads Central Europe in foreign investment. GDP growth had been strong and steady from 1993 to 2000 with only a short slowdown from 2001 to 2002.
The economy had growth of 3.7% annually in 2003, a rise from 1.4% annually in 2002. In 2004, GDP growth equaled 5.4%, in 2005 3.3% and in 2006 6.2%. According to Eurostat data, Polish PPS GDP per capita stood at 61% of the EU average in 2009.
Although the Polish economy is currently undergoing economic development, there are many challenges ahead. The most notable task on the horizon is the preparation of the economy (through continuing deep structural reforms) to allow Poland to meet the strict economic criteria for entry into the Eurozone. According to the Polish foreign minister Radosław Sikorski the country could join the eurozone before 2016. Some businesses may already accept the euro as payment. In addition, the ability to establish and conduct business easily has been cause for economic hardship as the World Economic Forum recently ranked Poland near the bottom of OECD countries in terms of the clarity, efficiency and neutrality of its legal framework for firm to settle disputes. A report concluded that on-going foreign business disputes issues may "have damaged Poland’s reputation as an attractive location for FDI" by reinforcing the impression of "Poland’s substandard reputation for maintaining an efficient and neutral framework to settle business disputes involving multinational foreign investors." Ernst & Young's 2010 European attractiveness survey reported that Poland saw a 52% decrease in FDI job creation and a 42% decrease in number of FDI projects since 2008.
Average salaries in the enterprise sector in December 2010 were 3,848 PLN (1,012 euro or 1,374 US dollars) and growing sharply. Salaries vary between the regions: the median wage in the capital city Warsaw was 4,603 PLN (1,177 euro or 1,680 US dollars) while in Kielce it was only 3,083 PLN (788 euro or 1125 US dollars). Differences in salaries in various districts of Poland is even higher and range from 2,020 PLN (517 euro or 737 US dollars) in Kępno County, which is located in Greater Poland Voivodeship to 5,616 (1,436 euro or 2,050 US dollars) in Lubin County, which lies in Lower Silesian Voivodeship.
According to a Credit Suisse report, Poles are the second wealthiest (after Czechs) of the Central European peoples. This makes Poland an attractive destination for many guest workers particularly from Ukraine, Belarus, Russia and Vietnam. Even though Poland is rather an ethnically homogeneous country, the number of foreigners is growing every year.
Since the United Kingdom, Ireland and some other European countries opened their job markets for Poles, many workers, especially from rural regions, have left the country to seek a better wages abroad. However, there is a rapid growth of the salaries, booming economy, strong value of Polish currency, and quickly decreasing unemployment (from 14.2% in May 2006 to 6.7% in August 2008).
Commodities produced in Poland include: electronics, cars (Arrinera, Leopard), buses (Autosan, Solaris, Solbus), helicopters (PZL Świdnik), transport equipment, locomotives, planes (PZL Mielec), ships, military engineering (including tanks, SPAAG systems), medicines (Polpharma, Polfa), food, clothes, glass, pottery (Bolesławiec), chemical products and others.
Corporations.
Poland is recognised as a regional economic power within Central Europe, possessing nearly 40 percent of the 500 biggest companies in the region (by revenues). Poland was the only member of the EU to avoid the recession of the late 2000s, a testament to the Polish economy's stability. The country's most competitive firms are components of the WIG20 which is traded on the Warsaw Stock Exchange.
Well known Polish brands include, amongst others, PKO BP, PKN Orlen, PGE, PZU, PGNiG, Tauron Group, Lotos Group, KGHM Polska Miedź, Telekomunikacja Polska, Plus, Play, PLL LOT, Poczta Polska, PKP, Biedronka, BRE Bank, Getin Holding and TVP.
Poland is recognised as having an economy with significant development potential, overtaking the Netherlands in mid-2010 to become Europe's sixth largest economy. Foreign Direct Investment in Poland has remained strong ever since the country's re-democratisation following the Round Table Agreement in 1989. Despite this, problems do exist, and further progress in achieving success depends largely on the government's privatisation of Poland's remaining state industries and continuing development and modernisation of the economy.
Tourism.
Poland is a major part of the global tourism market and is currently experiencing an upward trend in its number of visitors; this began shortly after joining the European Union. Tourism in Poland contributes to the country's overall economy and makes up a relatively large proportion of the country's service market. 
The most attractive urban destinations for tourists are Kraków, Wrocław, Gdańsk, Warsaw, Poznań, Lublin and Toruń; in addition to these the historic site of the Auschwitz German concentration camp near Oświęcim is a noteworthy place of pilgrimage and a now constitutes a major monument to the prevention of war and suffering in Southern Poland. 
Popular areas of natural beauty include northeast Poland's Masurian Lake District and Białowieża Forest, in southern Karkonosze, Table Mountains, Tatra Mountains and Bieszczady Mountains. 
Poland's main tourist offerings are thought to be based around city-sightseeing and extra-urban historical monuments, business trips, qualified tourism, agrotourism, mountain hiking and climbing among others.
Poland was the 17th most visited country by foreign tourists in 2008.
Energy.
The electricity generation sector in Poland is still largely fossil-fuel based. Many power plants nationwide use Poland's position as a major European exporter of coal to their advantage by continuing to use coal as the primary raw material in production of their energy; in 2007, hard bituminous coal contributed 48% of energy generation, brown coal and gas 12% each and oil 23%. Currently the three largest Polish coal mining firms ("Weglokoks, Kompania Węglowa and JSW") extract around 100 million tonnes of coal annually; all three of these companies are key constituents of the Warsaw Stock Exchange's lead economic indexes.
Renewable forms of energy currently only account for a small proportion of Poland's full energy generation capacity. However, the national government has set targets for the development of renewable energy sources in Poland which should see the portion of power produced by renewable resources climb to 7.5% by 2010 and 15% by 2020. This is to be achieved mainly through the construction of wind farms and a number of hydroelectric stations.
Poland is thought to have around 164,800,000,000 m³ of proven natural gas reserves and around 96,380,000 barrels of proven oil reserves. These reserves are currently attended to and exploited by energy supply companies such as PKN Orlen ("the only Polish company listed in the Fortune Global 500"). However, due to the small amounts of fossil fuels naturally occurring in Poland not being enough to satisfy the full energy consumption needs of the population and thus need to buy from abroad, the country is considered to be a net importer of oil and natural gas.
Transport.
Today transport in Poland is provided by means of rail, road, shipping and air travel. Positioned in Central Europe and with an eastern border compromising the largest external border of the Schengen Area with the rest of East-Central Europe, Poland has long been, and remains a key country through which imports to and exports from the European Union pass.
Since joining the EU in 2004, Poland has invested large amounts of money into the modernisation of its transport networks. The country now has a developing expressways network composed of motorways such as the A4 and express roads such as the S7. In addition to these newly built roads, many local and regional roads are being rebuilt as part of a national programme to rebuild all roads in Poland.
Again, with regard to railways, much the same situation is taking place. The Polish authorities have begun a program by which they hope to increase operating speeds across the entire Polish rail network; this is particularly true of a number of national trunk routes which are expected to soon receive new rolling stock capable of speeds over 200 km/h. Finally, there is a plan to introduce high speed rail to Poland from around 2014. The Polish government recently revealed that it intends to connect all major cities to a future high-speed rail network by 2020. Most intercity rail operations in Poland are operated by PKP Intercity whilst regional trains are run by a number of operators, the largest of which is Przewozy Regionalne.
The air and maritime transport markets in Poland are largely well developed. Poland has a number of international airports; the largest of which is Warsaw Chopin Airport, the primary global hub for LOT Polish Airlines, which is the largest airline of Central and Eastern Europe and one of the world's oldest airlines still in operation today. Seaports exist all along Poland's Baltic coast, with most freight operations using either Gdynia or Gdańsk as their base. Passenger ferries link Poland with Scandinavia all year round; these services are provided from Gdańsk by Polferries, Stena Line from Gdynia and Unity Line from the Port of Świnoujście.
Science.
According to Frost & Sullivan's Country Industry Forecast the country is becoming an interesting location for research and development investments. Multinational companies such as: ABB, Delphi, GlaxoSmithKline, Google, Hewlett–Packard, IBM, Intel, LG Electronics, Microsoft, Motorola, Siemens and Samsung have set up research and development centres in Poland. Over 40 research and development centers and 4,500 researchers make Poland the biggest research and development hub in Central and Eastern Europe. Companies chose Poland because of the availability of highly qualified labour force, presence of universities, support of authorities, and the largest market in Central Europe.
Today Poland's tertiary education institutions; traditional universities (found in its major cities), as well as technical, medical, and economic institutions, employ around 61,000 researchers and members of staff. There are around 300 research and development institutes, with about 10,000 researchers. In total, there are around 91,000 scientists in Poland today. However, in the 19th and 20th centuries many Polish scientists worked abroad; one of the greatest of these exiles was Maria Skłodowska-Curie, a physicist and chemist who lived much of her life in France. In the first half of the 20th century, Poland was a flourishing centre of mathematics. Outstanding Polish mathematicians formed the Lwów School of Mathematics (with Stefan Banach, Hugo Steinhaus, Stanisław Ulam) and Warsaw School of Mathematics (with Alfred Tarski, Kazimierz Kuratowski, Wacław Sierpiński). The events of World War II pushed many of them into exile. Such was the case of Benoît Mandelbrot, whose family left Poland when he was still a child. An alumnus of the Warsaw School of Mathematics was Antoni Zygmund, one of the shapers of 20th-century mathematical analysis.
According to a KPMG report 80% of Poland's current investors are content with their choice and willing to reinvest. In 2006, Intel decided to double the number of employees in its research and development centre in Gdańsk.
Communications.
The share of the telecom sector in the GDP is 4.4% (end of 2000 figure), compared to 2.5% in 1996. Nevertheless, despite high expenditures for telecom infrastructure (the coverage increased from 78 users per 1,000 inhabitants in 1989 to 282 in 2000).
The value of the telecommunication market is zl 38.2bn (2006), and it grew by 12.4% in 2007 PMR. The coverage mobile cellular is over 1000 users per 1000 people (2007). Telephones—mobile cellular: 38.7 million (Onet.pl & GUS Report, 2007), telephones—main lines in use: 12.5 million (Telecom Team Report, 2005).
With regard to internet access, the most popular ADSL services for home users in Poland are Neostrada provided by TPSA, and Net24 provided by Netia. Business users as well as some home users use Internet DSL TP also offered by TPSA. According to Eurostat, OECD and others, Internet access in Poland is amidst the most expensive in Europe. This is mostly caused by the lack of competitiveness. New operators, such as Dialog and GTS Energis are making their own provider lines and offer more attractive and cheaper service. Recently, the Polish Office of Electronical Communication passed a bill forcing the TPSA to rent 51% of their ADSL lines to other ISPs for 60% lower prices. This move will definitely affect the prices of DSL in Poland.
The public postal service in Poland is operated by Poczta Polska (The Polish Post). It was created on October 18, 1558, when king Zygmunt August established a permanent postal route from Kraków to Venice (later also to Wilno) in order to manage affairs in Italy that arose after the death of Queen Bona, his mother. Since then the service was dissolved on a number of occasions, most notably during the partitions of Poland. After regaining independence in 1918, the united territory of Poland was in need of a uniform network of communication. Thus, the interwar period saw the rapid development of the postal system as new services were introduced (e.g. money transfers, payment of pensions, delivery of magazines, air mail). Although during national uprisings and in the course of wars communication was provided mainly through field post, which was subject to military authority, postmen always took active part in the fight for independence by secretly delivering parcels and documents, or by providing vital information about the enemy. Many important events in the history of Poland involved the postal service, like the heroic Defence of the Polish Post Office in Gdańsk in 1939 and the participation of the Polish Scouts' Postal Service in the Warsaw Uprising. During the difficult times of the Second World War, the Polish Post in exile would lift up the spirits of compatriots by issuing postage stamps. Nowadays the service is a modern, functioning state-owned company which provides a number of standard and express delivery options, as well as operating the Polish postal home-delivery service. The postal service is currently expanding into the provision of logistical services.
Demographics.
Poland, with 38,116,000 inhabitants, has the eighth-largest population in Europe and the sixth-largest in the European Union. It has a population density of 122 inhabitants per square kilometer (328 per square mile).
Poland historically contained many languages, cultures and religions on its soil. The country had a particularly large Jewish population prior to World War II, when the Nazi Germany's regime led to The Holocaust. It caused Poland's Jewish population, estimated at 3 million before the war, to drop to just 300,000. The outcome of the war, particularly the shift of Poland's borders to the area between the Curzon Line and the Oder-Neisse line, coupled with post-war expulsion of minorities, significantly reduced the country's ethnic diversity. Over 7 million Germans fled or were expelled from the Polish side of the Oder-Neisse boundary.
According to the 2002 census, 36,983,700 people, or 96.74% of the population, consider themselves Polish, while 471,500 (1.23%) declared another nationality, and 774,900 (2.03%) did not declare any nationality. The largest minority nationalities and ethnic groups in Poland are Silesians (173,153 according to the census), Germans (152,897 according to the census, 92% in Opole Voivodeship and Silesian Voivodeship), Belarusians (c. 49,000), Ukrainians (c. 30,000), Lithuanians, Russians, Roma, Jews, Lemkos, Slovaks, Czechs, and Lipka Tatars. Among foreign citizens, the Vietnamese are the largest ethnic group, followed by Greeks and Armenians.
The Polish language, part of the West Slavic branch of the Slavic languages, functions as the official language of Poland. Until recent decades Russian was commonly learned as a second language but has been replaced by English and German as the most common second languages studied and spoken.
In recent years, Poland's population has decreased because of an increase in emigration and a sharp drop in the birth rate. Since Poland's accession to the European Union, a significant number of Poles have emigrated, primarily to the United Kingdom, Germany and Ireland in search of work and better work opportunities abroad. In April 2007, the Polish population of the United Kingdom had risen to approximately 300,000, and estimates place the Polish population in Ireland at 65,000. Some sources claim that the number of Polish citizens who emigrated to the UK after 2004 is as high as 2 million.
This, however, is contrasted by a recent trend that shows that more Poles are entering the country than leaving it.
Polish minorities are still present in the neighboring countries of Ukraine, Belarus, and Lithuania, as well as in other countries (see Poles for population numbers). Altogether, the number of ethnic Poles living abroad is estimated to be around 20 million. The largest number of Poles outside of Poland can be found in the United States.
Religion.
Until World War II, Poland was a religiously diverse society, in which substantial Jewish, Protestant and Christian Orthodox minorities coexisted with a Roman Catholic majority. As a result of the Holocaust and the post–World War II flight and expulsion of German and Ukrainian populations, Poland has become overwhelmingly Roman Catholic. In 2007, 88.4% of the population belonged to the Catholic Church. Though rates of religious observance are lower, at 52% to 60%, Poland remains one of the most devoutly religious countries in Europe.
From 16 October 1978 until his death on 2 April 2005 Karol Józef Wojtyła (later Pope John Paul II), a natural born Pole, reigned as Supreme Pontiff of the Roman Catholic Church and Sovereign of Vatican City. His was the second-longest documented pontificate; only Pope Pius IX served longer. He has been the only Slavic and Polish Pope to date, and was the first non-Italian Pope since Dutch Pope Adrian VI in 1522. Additionally he is credited with having played a significant role in hastening the downfall of communism in Poland and throughout Central and Eastern Europe; he is famously quoted as having, at the height of communism in 1979, told Poles "not be afraid", later praying: "Let your Spirit descend and change the image of the land... this land". He is a deeply revered figure within Polish society, and his passing in 2005 was met with large-scale outpourings of national grief.
Religious minorities include Polish Orthodox (about 506,800), various Protestants (about 150,000), Jehovah's Witnesses (126,827), Eastern Catholics, Mariavites, Polish Catholics, Jews, and Muslims (including the Tatars of Białystok). Members of Protestant churches include about 77,500 in the largest Evangelical-Augsburg Church, and a similar number in smaller Pentecostal and Evangelical churches.
Freedom of religion is now guaranteed by the 1989 statute of the Polish Constitution, enabling the emergence of additional denominations. However, because of pressure from the Polish Episcopate, the exposition of doctrine has entered the public education system as well. According to a 2007 survey, 72% of respondents were not opposed to religious instruction in public schools; alternative courses in ethics are available only in one percent of the entire public educational system.
Famous sites of Christian pilgrimage in Poland include the Monastery of Jasna Góra in the southern Polish city of Częstochowa, as well as the Family home of John Paul II in Wadowice just outside of Kraków.
Health.
Poland's healthcare system is based on an all-inclusive insurance system. State subsidised healthcare is available to all Polish citizens who are covered by this general health insurance program. However, it is not compulsory to be treated in a state-run hospital as a number of private medical complexes do exist nationwide.
All medical service providers and hospitals in Poland are subordinate to the Polish Ministry of Health, which provides oversight and scrutiny of general medical practice as well as being responsible for the day to day administration of the healthcare system. In addition to these roles, the ministry is also tasked with the maintenance of standards of hygiene and patient-care.
Hospitals in Poland are organised according to the regional administrative structure, resultantly most towns have their own hospital "(Szpital Miejski)". Larger and more specialised medical complexes tend only to be found in major cities, with some even more specialised units located only in the capital, Warsaw. However, all voivodeships have their own general hospital (most have more than one), all of which are obliged to have a trauma centre; these types of hospital, which are able to deal with almost all medical problems are called 'regional hospitals' "(Szpital Wojewódzki)". The last category of hospital in Poland is that of specialised medical centres, an example of which would be the Skłodowska-Curie Institute of Oncology, Poland's leading, and most highly specialised centre for the research and treatment of cancer.
The Polish health-care industry is currently undergoing a major transformation, with many hospitals being listed as top priorities for refurbishment. As a result of this process, many hospitals have already been thoroughly modernised throughout and are now equipped with the latest in medical hardware. The overall quality of healthcare provision nationwide, as judged by European standards, is generally regarded as being very high. This is reflected in the nation's average life expectancy, which at 71 for males and 80 for females, has shown a marked increase from 63/68 in 2003, and now corresponds with the average figures for life expectancy in the European Union.
Education.
The education of Polish society was a goal of rulers as early as the 12th century, and Poland soon became one of the most educated countries in Europe. The library catalogue of the Cathedral Chapter of Kraków dating back to 1110 shows that in the early 12th century Polish intellectuals had access to European literature. The Jagiellonian University, founded in 1364 by King Casimir III in Kraków, is one of Europe's oldest universities. In 1773 King Stanisław August Poniatowski established the Commission of National Education ("Komisja Edukacji Narodowej"), the world's first state ministry of education.
The first university in Poland, Kraków's Jagiellonian University, was established in 1364 by Casimir III the Great in Kraków. It is the oldest university in Poland. It is the second oldest university in Central Europe and one of the oldest universities in the world. Casimir III realized that the nation needed a class of educated people, especially lawyers, who could codify the country's laws and administer the courts and offices. His efforts to found an institution of higher learning in Poland were finally rewarded when Pope Urban V granted him permission to open the University of Krakow.
Since changes made in 2009 education in Poland starts at the age of five or six for the 0 class (Kindergarten) and six or seven years in the 1st class of primary school (Polish "szkoła podstawowa"). It is compulsory that children do one year of formal education before entering 1st class at no later than 7 years of age. 
At the end of 6th class when the students are 13, they take a compulsory exam that will determine to which lower secondary school ("gimnazjum, pronounced gheem-nah-sium") (Middle School/Junior High) they will be accepted. They will attend this school for three years for classes, 7, 8, and 9. They then take another compulsory exam to determine the upper secondary level school they will attend. There are several alternatives, the most common being the three years in a "liceum" or four years in a technikum. Both end with a maturity examination (matura, quite similar to French baccalauréat), and may be followed by several forms of upper education, leading to licencjat or inżynier (the Polish Bologna Process first cycle qualification), magister (second cycle qualification) and eventually doktor (third cycle qualification).
There are currently 18 fully accredited traditional universities in Poland, these are then further supplemented by 20 technical universities, nine independent medical universities and five universities for the study of economics. In addition to these institutions there are then nine agricultural academies, three pedagogical universities, a theological academy and three maritime service universities. Poland's long history of promoting the arts has led to the establishment of a number of higher educational institutes dedicated to the teaching of the arts. Amongst these are the seven higher state academies of music. All of these institutions are further supplemented by a large number of private educational institutions and the four national military academies (two for the army and one for each of the other branches of service), bringing the total number of organisations for the pursuit of higher education to well over 500, one of the largest numbers in Europe. The Programme for International Student Assessment, coordinated by the OECD, currently ranks Poland's educational system as the 23rd best in the world, being neither significantly higher nor lower than the OECD average.
Culture.
The culture of Poland is closely connected with its intricate 1000 year history Its unique character developed as a result of its geography at the confluence of European cultures. With origins in the culture of the Proto-Slavs, over time Polish culture has been profoundly influenced by its interweaving ties with the Germanic, Latinate and Byzantine worlds as well as in continual dialog with the many other ethnic groups and minorities living in Poland. The people of Poland have traditionally been seen as hospitable to artists from abroad and eager to follow cultural and artistic trends popular in other countries. In the 19th and 20th centuries the Polish focus on cultural advancement often took precedence over political and economic activity. These factors have contributed to the versatile nature of Polish art, with all its complex nuances.
Famous people.
Poland is the birthplace of many distinguished personalities (see. List of Polish people), among which are: Mikołaj Kopernik, Fryderyk Chopin, Maria Skłodowska Curie, Tadeusz Kościuszko, Kazimierz Pułaski, Józef Piłsudski and Pope John Paul II. Great Polish painter Jan Matejko devoted his monumental art to the most significant historical events on Polish lands, along with the playwright, painter and poet Stanisław Wyspiański. Stanisław Ignacy Witkiewicz (Witkacy) was an example of a Polish avant-garde philosopher and author of aesthetic theories.
Polish literature dates back to the 12th century and includes many famous poets and writers such as Jan Kochanowski, Adam Mickiewicz, Bolesław Prus, Juliusz Słowacki, Witold Gombrowicz, Stanisław Lem and, Ryszard Kapuściński. Writers Henryk Sienkiewicz, Władysław Reymont, Czesław Miłosz, Wisława Szymborska have each won the Nobel Prize in Literature. Also a renowned Polish novelist, who wrote in the English language, was Joseph Conrad.
Many world famous Polish movie directors include Academy Awards winners Roman Polański, Andrzej Wajda, Zbigniew Rybczyński, Janusz Kamiński, Krzysztof Kieślowski, Agnieszka Holland. World renowned actresses were Helena Modjeska and Pola Negri.
Poles have outstanding achievements in mountaineering in the Himalayas, especially in the winter gathering Eight-thousander. The most famous Polish climbers are Jerzy Kukuczka, Krzysztof Wielicki, Piotr Pustelnik, Andrzej Zawada and Wanda Rutkiewicz.
Society.
Poland has a great, long standing tradition of tolerance towards minorities, as well as absence of discrimination on the grounds of religion, nationality or race. This is for historical reasons and that is ethnic minorities in Poland are very few. It has a high level of gender equality, promotes disability rights movement and promotes equality. 
Poland is the first country in the world where corporal punishment was prohibited.
Poland has, throughout most of its long history, experienced only very limited immigration from abroad; this trend can largely be attributed to Poland's lack of slavery and overseas colonies as well as its lack of existence as a state during much of the 19th and early 20th centuries. Despite this, the country has for a long time been regarded as having a very tolerant society, which affords equal rights to all people no matter what their ethnic background. This can be said to stem largely from the reign of King Casimir III the Great and his acceptance for Poland's Jewish community, in a time when the most of Europe recessed antisemitic mood. The history of Jews in Poland shows peaceful co-existence of a nation and particular ethnic group.
As many as 96.7% of Polish citizens declare to be Poles, and 97.8% declare that they speak Polish at home (Census 2002). The population of Poland became one of the most ethnically homogeneous in the world as a result of the radically altered borders after World War II and the subsequent migrations. This homogeneity is a result of post World War II deportations ordered by the Soviet authorities, who wished to remove the sizeable Polish minorities from Lithuania, Belarus and Ukraine and repatriation of Ukrainians from Poland to the Soviet Union (see territorial changes of Poland and historical demography of Poland for details). Unlike in many other countries, the minority rights in Poland are guaranteed directly in the Constitution of Poland (art. 35), and today there are, amongst others, sizeable German, Ukrainian and Belarusian minorities present in the country.
After the formal collapse of Communism in 1989, Poland greatly improved its image in the world and thus has received further support from the country's recent economic success and effective entry into the structures of the European Union. Polish citizens have obtained a good reputation as workers in the united Europe, mainly due to the broad range of jobs beyond the borders of their state, since 2004. The results of an Organization for Security and Co-operation in Europe (OSCE) survey from 2004 showed that Poles work the second most hours per week of any nationality worldwide.
Poland remains one of the most peaceful countries in the world.
Music.
Artists from Poland, including famous composers like Chopin or Penderecki and traditional, regionalized folk musicians, create a lively and diverse music scene, which even recognizes its own music genres, such as poezja śpiewana and disco polo. As of 2006, Poland is one of the few countries in Europe where rock and hip hop dominate over pop music, while all kinds of alternative music genres are encouraged.
The origins of Polish music can be traced as far back as the 13th century; manuscripts have been found in Stary Sącz, containing polyphonic compositions related to the Parisian Notre Dame School. Other early compositions, such as the melody of "Bogurodzica" and "Bóg się rodzi" (a coronation polonaise for Polish kings by an unknown composer), may also date back to this period, however, the first known notable composer, Mikołaj z Radomia, was born and lived in the 15th century. During the 16th century, two main musical groups – both based in Kraków and belonging to the King and Archbishop of the Wawel – led to the rapid development of Polish music. Composers writing during this period include Wacław z Szamotuł, Mikołaj Zieleński, and Mikołaj Gomółka. Diomedes Cato, a native-born Italian who lived in Kraków from about the age of five, became one of the most famous lutenists at the court of Sigismund III, and not only imported some of the musical styles from southern Europe, but blended them with native folk music.
At the end of the 18th century, Polish classical music evolved into national forms like the polonaise. In the 19th century the most popular composers were: Józef Elsner and his pupils Fryderyk Chopin and Ignacy Dobrzyński. Important opera composers of the era were Karol Kurpiński and Stanisław Moniuszko whilst the list of famous soloists and composers included Henryk Wieniawski, Juliusz Zarębski. At the turn of the 19th and 20th centuries the most promiment composers could said to have been Władysław Zeleński and Mieczysław Karłowicz, with Karol Szymanowski gaining prominence prior to World War II. Alexandre Tansman lived in Paris but had strong connections with Poland. Henryk Górecki and Krzysztof Penderecki composed in Poland, Andrzej Panufnik emigrated.
Traditional Polish folk music has had a major effect on the works of many well-known Polish composers, and no more so than on Fryderyk Chopin, a widely recognised national hero of the arts. All of Chopin's works involve the piano and are technically demanding, emphasising nuance and expressive depth. As a great composer, Chopin invented the musical form known as the instrumental ballade and made major innovations to the piano sonata, mazurka, waltz, nocturne, polonaise, étude, impromptu and prélude, he was also the composer of a number of polonaises which borrowed heavily from traditional Polish folk music. It is largely thanks to him that the such pieces gained great popularity throughout Europe during the 19th century. Nowadays the most distinctive folk music can be heard in the towns and villages of the mountainous south, particularly in the region surrounding the winter resort town of Zakopane.
Today Poland has a very active music scene, with the jazz and metal genres being particularly popular amongst the contemporary populace. Polish jazz musicians such as Krzysztof Komeda, created a unique style, which was most famous in 1960s and 1970s and continues to be popular to this day. Since the fall of Communism, Poland has become a major venue for large-scale music festivals, chief among which are the Open'er Festival, Opole Festival and Sopot Festival.
Media.
Poland has instituted freedom of press since the fall of communism, a system under which the media was heavily politically controlled and censored. However, public TV and radio are still regulated by the government, this is exercised through an agency called "Krajowa Rada Radiofonii i Telewizji" ("The National Radio and Television Committee"), which is similar to television regulatory commissions in other developed nations.
Poland has a number of major media outlets, chief amongst which are the national television channels. TVP is Poland's public broadcasting corporation; about a third of its income comes from a broadcast receiver licence, while the rest is made through revenue from commercials and sponsorships. State television operates two mainstream channels, TVP 1 and TVP 2, as well as regional programs (TVP Info) for each of the country's 16 voivodeships. In addition to these general channels, TVP runs a number of genre-specific programmes such as TVP Sport, TVP Historia, TVP Kultura and TVP Seriale; there are currently plans to run channels dedicated to the coverage of political affairs (TVP Parlament) and entertainment (TVP Rozrywka).
Poland has a number of internationally broadcast and 24 hour news channels, chief amongst which are Polsat News, TVN 24, and TV Polonia, the latter is a state-run channel dedicated to the transmission of Polish language television for the Polish diaspora abroad. There are a number of major private television outlets such as Polsat and the TVN network.
Poland has a highly developed printed news industry, with daily newspapers like Gazeta Wyborcza "(The Electoral Gazette)", Rzeczpospolita "(The Republic)" and Gazeta Polska Codziennie providing more traditional, intellectually stimulating reporting and tabloids such as Fakt providing more sensationalist writing which is less current affairs orientated. Rzeczpospolita is one of the nation's oldest publications still in operation today, founded in 1920, it has become a stalwart bastion of Polish reporting and in 2006 won a prestigious award for being, along with the Guardian (a British daily), the best designed newspaper in the world. 
Major media outlets are experiencing an ongoing restructuring which is seeing many of them amalgamated into major media groups; a prime example of which is the German Axel Springer AG Publishing conglomerate's purchase of Fakt. International cooperation is also a growing trend within Polish media; TVP recently began cooperating with the French-German TV network ARTE.
Literature.
Polish literature has a long and complicated history. During the Middle Ages most Polish authors and academics (Jan Długosz) wrote only in Latin, as at the time, this was the 'academic' language which linked Europe together; Jan Kochanowski broke this trend and became the first author to write the majority of his works in the Polish language. A number of Polish authors have won great renown in the past few centuries, however, this largely stems from the initial success of the works of Adam Mickiewicz, who wrote the first Polish epic, Pan Tadeusz, in 1834.
Influential authors of the late 19th and 20th centuries include Henryk Sienkiewicz, Władysław Reymont, Witold Gombrowicz and Czesław Miłosz. To date four Polish authors have won the Nobel Prize in Literature, with Władysław Reymont being one of only nine writers to receive the prestigious award for one particular, outstanding literary work "(awarded for the great national epic, 'The Peasants' in 1924)" rather than their career as a whole. Ferdynand Antoni Ossendowski was an internationally popular writer.
With regard to poetry, Poland has a long and distinguished history of producing world-class poets. Chief among these are the 'three bards' (trzej wieszcze), Mickiewicz, Krasiński and Słowacki; the three national poets of Polish Romantic literature. Incidentally, the Polish word "Wieszcz" means 'prophet' or 'soothsayer', a fitting reference for the three, as the bards were thought to not only voice Polish national sentiments but to frequently foresee the nation's future.
Today the traditions of Polish literature and poetry are being carried forward by a new generation of writers. Included within this group is Wisława Szymborska, a best-selling author and recipient of the 1996 Nobel Prize in Literature.
Architecture.
Polish cities and towns reflect the whole spectrum of European styles. Romanesque architecture is represented by St. Andrew's Church in Kraków, and characteristic for Poland Brick Gothic by St. Mary's Church in Gdańsk. Richly decorated attics and arcade loggias are the common elements of the Polish Renaissance architecture, like in City Hall in Poznań. For some time the late renaissance, so called mannerism, most notably in Bishop’s Palace in Kielce, coexisted with the early baroque like in Church of SS. Peter and Paul in Kraków.
History has not been kind to Poland's architectural monuments. Nonetheless, a number of ancient structures had survived: castles, churches, and stately buildings, often unique in the regional or European context. Some of them have been painstakingly restored, like Wawel Castle, or completely reconstructed after being destroyed in the Second World War, including the Old Town and Royal Castle in Warsaw and the Old Town of Gdańsk. The architecture of Gdańsk is mostly of the Hanseatic variety, a Gothic style common amongst the former trading cities along the Baltic sea and in the northern part of Central Europe. The architectural style of Wrocław is mainly representative of German architecture, since it was for centuries located within the German states. The centre of Kazimierz Dolny on the Vistula is a good example of a well-preserved medieval town. Poland's ancient capital, Kraków, ranks among the best-preserved Gothic and Renaissance urban complexes in Europe. Meanwhile, the legacy of the Kresy Marchlands of Poland's eastern regions, where Wilno and Lwów (now "Vilnius" and "Lviv") were recognised as two major centres for the arts, played a special role in the development of Polish architecture, with Catholic church architecture deserving special note.
The second half of the 17th century is marked by baroque architecture. Side towers, visible in Branicki Palace in Białystok are typical for Polish baroque. The classical Silesian baroque is represented by the University in Wrocław. Profuse decorations of Branicki Palace in Warsaw are characteristic of rococo style. The centre of Polish classicism was Warsaw under the rule of the last Polish king Stanisław August Poniatowski. The Palace on the Water is the most notable example of Polish neoclassical architecture. Lublin Castle represents the Gothic Revival style in architecture, while the Izrael Poznański Palace in Łódź is an example of eclecticism.
Cuisine.
Polish cuisine has influenced the cuisines of its surrounding countries. For centuries the Polish kitchen has been the arena for competing with France and Italy. It is rich in meat, especially pork, chicken and beef, winter vegetables (cabbage in the dish bigos) and spices. Pasta is also featured in many Polish dishes, most notably are pierogi. Polish national cuisine shares some similarities with other European traditions. Generally speaking, Polish cuisine is hearty. The preparation of traditional cuisine generally is time intensive and Poles allow themselves a generous amount of time to prepare and enjoy their festive meals, with some meals (like Christmas Eve or Easter breakfast) taking a number of days to prepare in their entirety. It is worth noting that most regions of Poland have their own local gastronomic traditions and distinctive flavours.
Notable foods in Polish cuisine include: soups – rosół, barszcz, żurek, krupnik, kapuśniak, zupa pomidorowa, zupa ogórkowa, zupa grzybowa, flaczki (tripe soup); pierogi, kiełbasa, gołąbki, oscypek, kotlet schabowy, kotlet mielony, bigos, various potato dishes, kanapka, zapiekanka, and many more. Traditional Polish desserts include pączki, faworki, gingerbread, babka and others.
Characteristic dishes are soured milk, buttermilk, kefir, gherkin, pickled cucumber, sauerkraut.
Sports.
Many sports are popular in Poland. Football (soccer) is the country's most popular sport, with a rich history of international competition. Track and field, basketball, boxing, ski jumping, fencing, handball, ice hockey, swimming, volleyball, and weightlifting are other popular sports. The golden era of football in Poland occurred throughout the 1970s and went on until the early 1980s when the Polish national football team achieved their best results in any FIFA World Cup competitions finishing 3rd place in the 1974 and 1982 editions. The team won a gold medal in football at the 1972 Summer Olympics and also won two silver medals in 1976 and 1992. Poland, along with Ukraine, hosted the UEFA European Football Championship in 2012.
The Polish men's national volleyball team is ranked 5th in the world and the women's volleyball team is ranked 10th. Mariusz Pudzianowski is a highly successful strongman competitor and has won more World's Strongest Man titles than any other competitor in the world, winning the event in 2008 for the fifth time. The first Polish Formula One driver, Robert Kubica, has brought awareness of Formula One Racing to Poland. Poland has made a distinctive mark in motorcycle speedway racing thanks to Tomasz Gollob, a highly successful Polish rider. The national speedway team of Poland is one of the major teams in international speedway and is very successful in various competitions.
The Polish mountains are an ideal venue for hiking, skiing and mountain biking and attract millions of tourists every year from all over the world. Baltic beaches and resorts are popular locations for fishing, canoeing, kayaking and a broad-range of other water-themed sports.
International rankings.
The following are links to international rankings of Poland.
Notes.
a Numerous sources state that Polish Army was the Allies' fourth biggest fighting contingent. Steven J. Zaloga and Richard Hook write that "by the war's end the Polish Army was the fourth largest contingent of the Allied coalition after the armed forces of the Soviet Union, the United States and the United Kingdom." Jerzy Jan Lerski writes "All in all, the Polish units, although divided and controlled by different political orientation, constituted the fourth largest Allied force, after the America, British and Soviet Armies." M. K. Dziewanowski has noted that "if Polish forces fighting in the east and west were added to the resistance fighters, Poland had the fourth largest Allied army in the war (after the USSR, the U.S. and Britain)".
The claim of the fourth biggest Ally needs to be reconsidered, however. Throughout the war, Poland's position varied from the 2nd biggest Ally (after the fall of France, when Polish army outnumbered the French) to perhaps the 5th at the end of it (after the USA, Soviet Union, China and Britain). Please, see the analysis in Polish contribution to World War II.
b Sources vary with regards to what was the largest resistance movement during World War II. The confusion often stems from the fact that as war progressed, some resistance movements grew larger – and other diminished. Polish territories were mostly freed from Nazi German control in the years 1944–1945, eliminating the need for their respective (anti-Nazi) partisan forces (in Poland (although the cursed soldiers continued to fight against the Soviets). Several sources note that Polish Armia Krajowa was the largest resistance movement in Nazi-occupied Europe. Norman Davies wrote: "Armia Krajowa (Home Army), the AK, which could fairly claim to be the largest of European resistance"; Gregor Dallas wrote "Home Army (Armia Krajowa or AK) in late 1943 numbered around 400000, making it the largest resistance organization in Europe"; Mark Wyman wrote "Armia Krajowa was considered the largest underground resistance unit in wartime Europe". Certainly, Polish resistance was the largest resistance till German invasion of Yugoslavia and invasion of the Soviet Union in 1941. After that point, the numbers of Soviet partisans and Yugoslav partisans begun growing rapidly. The numbers of Soviet partisans quickly caught up and were very similar to that of the Polish resistance. The numbers of Tito's Yugoslav partisans were roughly similar to those of the Polish and Soviet partisans in the first years of the war (1941–1942), but grew rapidly in the latter years, outnumbering the Polish and Soviet partisans by 2:1 or more (estimates give Yugoslavian forces about 800,000 in 1945, to Polish and Soviet forces of 400,000 in 1944).

Political radicalism
The term political radicalism (or simply, in political science, radicalism) denotes political principles focused on altering social structures through revolutionary means and changing value systems in fundamental ways. Derived from the Latin "radix" (root), the denotation of radical has changed since its eighteenth-century coinage to comprehend the entire political spectrum—yet retains the “change at the root” connotation fundamental to revolutionary societal change. Historically, radicalism has referred exclusively to the "radical left", under the single category of far-left politics, rarely incorporating far-right politics though these may have revolutionary elements; the prominent exception is in the United States where some consider radicalism to include both political extremes of the radical left and the "radical right". In traditional labels of the spectrum of political thought, the opposite of radical on the "right" of the political spectrum is termed reactionary.
The nineteenth-century "Cyclopaedia of Political Science" (1881, 1889) reports that "radicalism is characterized less by its principles than by the manner of their application". Conservatives often used the term "radical" pejoratively, whereas contemporary left radicals used the term "conservative" derogatorily; thus contemporary denotations of "radical", "radicalism", and "political radicalism" comprehend far left, radical left, and far right (radical right).
The "Encyclopædia Britannica" records the first political usage of "radical" as ascribed to the British Whig Party parliamentarian Charles James Fox, who, in 1797, proposed a “radical reform” of the electoral system franchise to provide universal manhood suffrage, thereby, idiomatically establishing "radical" to denote supporters of the reformation of the British Parliament. Throughout the nineteenth century, the term was combined with political notions and doctrines, thus working class radicalism, middle class-, philosophic-, democratic- bourgeois-, Tory-, and plebeian radicalism. In the event, politically-influential radical leaders give rise to their own trend of political radicalism, e.g. Spencean radicalism and Carlilean radicalism. Philosophically, the French political scientist Jean-Jacques Rousseau (1712–78), is the principal theoretician proposing "political radicalism" as feasible in republican political philosophy, "viz" the French Revolution (1789–99), and other modern revolutions—the antithesis to the liberalism of John Locke.

Prohibition
Prohibition of alcohol, often referred to simply as prohibition, is the legal act of prohibiting the manufacture, transportation and sale of alcohol and alcoholic beverages. The term can also apply to the periods in the histories of the countries during which the prohibition of alcohol was enforced. Use of the term as applicable to a historical period is typically applied to countries of European culture. 
History.
The earliest records of prohibition of alcohol date back to the Xia Dynasty (ca. 2070 BC–ca. 1600 BC) in China. Yu the Great, the first ruler of the Xia Dynasty, prohibited alcohol throughout the kingdom. It was legalized again after his death, during the reign of his son Qi.
In the early twentieth century, much of the impetus for the prohibition movement in the Nordic countries and North America came from moralistic convictions of pietistic Protestants. Prohibition movements in the West coincided with the advent of women's suffrage, with newly empowered women as part of the political process strongly supporting policies that curbed alcohol consumption.
After several years, prohibition became a failure in North America and elsewhere, as bootlegging (rum-running) became widespread and organized crime took control of the distribution of alcohol. Distilleries and breweries in Canada, Mexico and the Caribbean flourished as their products were either consumed by visiting Americans or illegally exported to the United States. Chicago became notorious as a haven for prohibition dodgers during the time known as the Roaring Twenties. Prohibition generally came to an end in the late 1920s or early 1930s in most of North America and Europe, although a few locations continued prohibition for many more years.
Australasia.
Australia.
The Australian Capital Territory was the first jurisdiction in Australia to enable prohibition laws. In 1910 King O'Malley, the then Minister of Home Affairs, shepherded the laws through parliament to address unruly behaviour. Seventeen years later the Federal Parliament repealed the laws.
In Melbourne, Victoria in the late 1920s, the temperance movement drove suburban councils to hold polls and the residents of some of these municipalities voted for the creation of a dry area. This prohibited the granting of a liquor license without a formal vote of approval by local residents. These areas continue to this day in the suburbs of Camberwell and Box Hill. Polls have been held since, however the majority of voters continue to support the restrictions on liquor licenses.
More recently alcohol has been prohibited in many remote indigenous communities. Penalties for transporting alcohol into these "dry" communities are severe and can result in confiscation of any vehicles involved; in dry areas within the Northern Territory, all vehicles used to transport alcohol are seized.
Because alcohol consumption has been linked to violent behaviour in some individuals, some communities sought a safer alternative in substances such as kava, especially in the Northern Territory. Over-indulgence in kava causes sleepiness, rather than the violence that can result from over-indulgence in alcohol. These and other measures to counter alcohol abuse met with variable success. Some communities saw decreased social problems and others did not. The ANCD study notes that, to be effective, programs must address "...the underlying structural determinants that have a significant impact on alcohol and drug misuse." ("Op. cit.", p. 26) The Federal government banned kava imports into the Northern Territory in 2007.
New Zealand.
In New Zealand, prohibition was a moralistic reform movement begun in the mid-1880s by the Protestant evangelical and Nonconformist churches and the Woman's Christian Temperance Union and after 1890 by the Prohibition League. It never achieved its goal of national prohibition. It was a middle-class movement which accepted the existing economic and social order; the effort to legislate morality assumed that individual redemption was all that was needed to carry the colony forward from a pioneering society to a more mature one. However, both the Church of England and the largely Irish Catholic Church rejected prohibition as an intrusion of government into the church's domain, while the growing labor movement saw capitalism rather than alcohol as the enemy.
Reformers hoped that the women's vote, in which New Zealand was a pioneer, would swing the balance, but the women were not as well organized as in other countries. Prohibition had a majority in a national referendum in 1911, but needed a 60% vote to pass. The movement kept trying in the 1920s, losing three more referenda by close votes; it managed to keep in place a 6pm closing hour for pubs and Sunday closing. The Depression and war years effectively ended the movement.
North America.
United States.
Prohibition in the United States focused on the manufacture and sale of alcohol. Drinking itself was never illegal, and there were exceptions for medicinal and religious uses.
Prohibition was a major reform movement from the 1840s into the 1920s, and was sponsored by evangelical Protestant churches, especially the Methodists, Baptists, Presbyterians, Disciples and Congregationalists. Kansas and Maine were early adopters. The Women's Christian Temperance Union, founded in 1874, and the Prohibition Party were major players until the early 20th century, when the movement was taken over by the Anti-Saloon League. By using pressure politics on legislators, the Anti-Saloon League achieved the goal of nationwide prohibition during World War I, emphasizing the need to destroy the political corruption of the saloons, the political power of the German-based brewing industry, and the need to reduce domestic violence in the home.
Prohibition was instituted with ratification of the Eighteenth Amendment to the United States Constitution on January 16, 1919, which prohibited the "...manufacture, sale, or transportation of intoxicating liquors within, the importation thereof into, or the exportation thereof from the United States..." Congress passed the "Volstead Act" on October 28, 1919, to enforce the law, but most large cities were uninterested in enforcing the legislation, leaving an understaffed federal service to go after bootleggers. Although alcohol consumption did decline as a whole, there was a rise in alcohol consumption in many cities along with significant increases in organized crime related to its production and distribution.
The sale of alcohol was illegal, but alcoholic drinks were still widely available. People also kept private bars to serve their guests. Large quantities of alcohol were smuggled in from Canada, overland, by sea along both ocean coasts, and via the Great Lakes. The government cracked down on alcohol consumption on land within the U.S. It was a different story on the water where vessels outside the 3 mile limit were exempt. Legal and illegal home brewing was popular during Prohibition. "Malt and hop" stores popped up across the country and some former breweries turned to selling malt extract syrup, ostensibly for baking and "beverage" purposes.
Prohibition became increasingly unpopular during the Great Depression. The repeal movement was started by a wealthy Republican, Pauline Sabin, who said that prohibition should be repealed because it made the US a nation of hypocrites and undermined its respect for the rule of law. Her fellow Republicans were put in office by the "drys" and, even though they eagerly partook in consumption of alcoholic beverages at her parties, in public they presented themselves as opposing the repeal of prohibition, lest they be thrown out of office by the dry voting blocks. This hypocrisy and the fact that women led the prohibition movement convinced her to start the organization that eventually led to the repeal of prohibition.
When her fellow Republicans would not support her efforts, she went to the Democrats, who changed from drys led by conservative Democrats and Catholics to supporting repeal led by liberal politicians such as La Guardia and Franklin Roosevelt. She, and they, emphasized that repeal would generate enormous sums of much needed tax revenue, and weaken the base of organized crime. The Repeal of Prohibition in the United States was accomplished with the passage of the Twenty-first Amendment to the United States Constitution on December 5, 1933. By its terms, states were allowed to set their own laws for the control of alcohol. The organized Prohibition movement was dead nationwide, but survived for a while in a few southern and border states.
Al Capone.
Al Capone was the most notorious gangster of his generation. Born in 1899, Capone settled in Chicago to take over Johnny Torrio’s business dealing with outlawed liquor. Within 3 years, Capone had nearly 700 men at his disposal. As the profits came in, Capone acquired finesse- particularly finesse in the management of politics and politicians. By the middle of the decade, he had gained complete control of the suburb Cicero, and had installed his own Mayor in office. Capone’s rise to fame did not come without bloodshed. Rival gangs, such as the Gennas and the Aiellos, started wars with Capone, eventually leading to an epidemic of killings of epic proportions. In 1927, Capone and his gang were pulling in approximately $60 million per year- most of it from beer. Capone did not only control the sale of liquor to over 10,000 speakeasies, but he also controlled the supply: from Canada to Florida. Capone was imprisoned for tax violations and eventually died on January 25, 1947, due to a heart attack and pneumonia. 
Latin America.
Mexico.
Zapatista Communities will often ban alcohol as part of a collective decision. This has been used by many villages as a way to decrease domestic violence and has generally been favored by women. However, this is not recognized by federal Mexican law as the Zapatista movement is strongly opposed by the federal government.
The sale and purchase of alcohol is prohibited on and the night before certain national holidays, such as "Natalicio de Benito Juárez" (birthdate of Benito Juárez) and "Día de la Revolución", which are meant to be dry nationally. The same "dry law" applies to the days before presidential elections every six years.
Europe.
Czech Republic.
On 14 September, 2012, the government of the Czech Republic banned all sales of liquor with more than 20% alcohol. From this date on it is illegal to sell (and/or offer for sale) such alcoholic beverages in shops, supermarkets, bars, restaurants, gas stations, e-shops etc. This measure was taken in response to the wave of methanol poisoning cases resulting in the deaths of 18 people in the Czech Republic. Since the beginning of the "methanol affair" the total number of deaths has increased to 25. The ban remains until further notice, though restrictions were eased towards the end of September.
Nordic countries.
The Nordic countries, with the exception of Denmark, have had a strong temperance movement since the late 1800s, closely linked to the Christian revival movement of the late 19th century, but also to several worker organisations. As an example, in 1910 the temperance organisations in Sweden had some 330,000 members, which was 6% of a population of 5.5 million. Naturally, this heavily influenced the decisions of Nordic politicians in the early 20th century.
Already in 1907, the Faroe Islands passed a law prohibiting all sale of alcohol, which was in force until 1992. However, very restricted private importation from Denmark was allowed from 1928.
In 1914, Sweden put in place a rationing system, the Bratt System, in force until 1955. However a referendum in 1922 rejected an attempt to enforce total prohibition. 
In 1915, Iceland instituted total prohibition. The ban for wine and spirits was lifted in 1935, but beer remained prohibited until 1989.
In 1916, Norway prohibited distilled beverages, and in 1917 the prohibition was extended to also include fortified wine and beer. The wine and beer ban was lifted in 1923, and in 1927 the ban of distilled beverages was also lifted.
In 1919, Finland enacted prohibition, as one of the first acts after independence from the Russian Empire. Four previous attempts to institute prohibition in the early 20th century had failed due to opposition from the tsar. After a development similar to the one in the United States during its prohibition, with large-scale smuggling and increasing violence and crime rates, public opinion turned against the prohibition, and after a national referendum where 70% voted for a repeal of the law, prohibition was ended in early 1932.
Today, all Nordic countries (with the exception of Denmark) continue to have strict controls on the sale of alcohol which is highly taxed (dutied) to the public. There are government monopolies in place for selling spirits, wine and stronger beers in Norway (Vinmonopolet), Sweden (Systembolaget), Iceland (Vínbúðin), the Faroe Islands (Rúsdrekkasøla landsins) and Finland (Alko). Bars and restaurants may, however, import alcoholic beverages directly or through other companies.
Soviet Union.
In the Russian Empire, a limited version of a Dry Law was introduced in 1914. It continued through the turmoil of the Russian Revolution of 1917 and the Russian Civil War into the period of Soviet Russia and the Soviet Union until 1925.
United Kingdom.
Although the sale or consumption of commercial alcohol has never been prohibited by law, historically various groups in the UK have campaigned for the prohibition of alcohol, including the Society of Friends (Quakers), The Methodist Church and other non-conformist Christians, as well as temperance movements such as Band of Hope and temperance Chartist movements of the 19th century. 
In 1853, inspired by the Maine law in the USA, the United Kingdom Alliance led by John Bartholomew Gough was formed aimed at promoting a similar law prohibiting the sale of alcohol in the UK. This hard-line group of prohibitionists was opposed by other temperance organisations who preferred moral persuasion to a legal ban. This division in the ranks limited the effectiveness of the temperance movement as a whole. The impotence of legislation in this field was demonstrated when the Sale of Beer Act 1854 which restricted Sunday opening hours had to be repealed, following widespread rioting. In 1859 a prototype prohibition bill was overwhelmingly defeated in the House of Commons.
Asia.
Bangladesh.
In Bangladesh, foreign passport holders of non-Muslim nations can drink in some licenced restaurants and bars (and expatriate clubs) and can purchase imported alcohol from 'diplomatic bonded warehouses' at a hefty rate of sales duty (Approx 300%). Holders of diplomatic passports and some other specially privileged persons (such as U.N. employees) have 'passbooks' which entitle them to buy imported alcohol from the same 'bonded warehouses' duty free. Often duty free and duty paid prices are shown alongside one another. Bangladesh nationals of any religion may purchase alcohol from special outlets with a medical certificate. Illegal homemade liquor (known as 'Mod' or 'Bangla') is widely consumed in rural areas. The (mostly Christian) Garo tribal folk also brew a strong rice beer called 'Choo'. Christians are permitted to use wine for Holy Communion.
Brunei.
In Brunei, alcohol consumption in public is banned and there is no sale of alcohol. Non-Muslims are allowed to purchase a limited amount of alcohol from their point of embarkation overseas for their own private consumption. Non-Muslims over 17 years of age may be allowed to bring in not more than two bottles of liquor (about two quarts) and twelve cans of beer per person into the country.
India.
In some states of India alcoholic drinks are banned, for example the states of Gujarat, Nagaland and Mizoram. Certain national holidays such as Independence Day and "Gandhi Jayanti" (birthdate of Mahatma Gandhi) are meant to be "dry days" nationally. The state of Andhra Pradesh had imposed Prohibition under the Chief Ministership of N. T. Rama Rao but this was thereafter lifted. Dry days are also observed on voting days. Prohibition was also observed from 1996 to 1998 in Haryana. Prohibition has become controversial in Gujarat following a July 2009 episode in which widespread poisoning resulted from alcohol that had been sold illegally. All of the Indian states observe dry days on major religious festivals/occasions depending on the popularity of the festival in that region. These dry days are observed to maintain peace and order during the festival days.
Maldives.
The Maldives ban the import of alcohol, x-raying all baggage on arrival. Alcoholic beverages are available only to foreign tourists on resort islands and may not be taken off the resort.
Pakistan.
Pakistan allowed the free sale and consumption of alcohol for three decades from 1947, but restrictions were introduced by Zulfikar Ali Bhutto just weeks before he was removed as prime minister in 1977. Since then, only members of non-Muslim minorities such as Hindus, Christians and Zoroastrians are allowed to apply for permits for alcohol. The monthly quota depends on their income but is usually about five bottles of liquor or 100 bottles of beer. In a country of 180 million, only about 60 outlets are allowed to sell alcohol and there used to be only one legal brewery, Murree Brewery in Rawalpindi, Now there are more. Enforced by the country's Islamic Ideology Council, the ban is strictly policed. However, members of religious minorities often sell their liquor permits to Muslims and a black market trade in alcohol continues.
Middle East.
Numerous countries in the Middle East including Iran, Yemen, Libya, Saudi Arabia and Kuwait ban alcohol.
Elections.
In many countries in Latin America, the Philippines, and several US states, the sale but not the consumption of alcohol is prohibited before and during elections.

Prussia
Prussia (; Latin: "Borussia", "Prutenia"; ; ; ; Old Prussian: "Prūsa"; ; ) was a German kingdom and historic state originating out of the Duchy of Prussia and the Margraviate of Brandenburg. For centuries, the House of Hohenzollern ruled Prussia, successfully expanding its size by way of an unusually well-organized and effective army. Prussia shaped the history of Germany, with its capital in Berlin after 1451. By 1871, the smaller German city states were merged with Prussia, resulting in the creation of the German Empire. In November 1918 the royalty abdicated and the nobility lost most of its political power. Prussia was effectively abolished in 1932, and officially abolished in 1947.
The name "Prussia" derives from the Old Prussians. In the 13th century, "Old Prussia" was conquered by German crusaders, the Teutonic Knights. In 1308 Teutonic Knights conquered the formerly Polish region of Pomerelia with Gdańsk (Danzig). Their monastic state was mostly Germanized through immigration from central and western Germany and in the south it was Polonized by settlers from Masovia. After the Second Peace of Thorn of 1466, Prussia was split into the western Royal Prussia, a province of Poland, and the eastern part, since 1525 called Duchy of Prussia, a fief of the Crown of Poland up to 1657. The union of Brandenburg and the Duchy of Prussia in 1618 led to the proclamation of the Kingdom of Prussia in 1701.
Prussia achieved its greatest importance in the 18th and 19th centuries. During the 18th century, it became a great European power under the reign of Frederick the Great (1740–1786). During the 19th century, Chancellor Otto von Bismarck united the German principalities into a "Lesser Germany" which would exclude the Austrian Empire.
After 1810 Prussia dominated Germany politically, economically, and in population, and was the core of the unified North German Confederation formed in 1867, which became part of the German Empire or "Deutsches Reich" in 1871.
The term "Prussian" has often been used, especially outside of Germany, to emphasize the professionalism, aggressiveness, militarism, and conservatism of the Junker class of landed aristocrats in the East who dominated Prussia into the 20th century.
Symbols.
The main coat of arms of Prussia, as well as the flag of Prussia, depicted a black eagle on a white background.
The black and white national colours were already used by the Teutonic Knights and by the Hohenzollern dynasty. The Teutonic Order wore a white coat embroidered with a black cross with gold insert and black imperial eagle. The combination of the black and white colours with the white and red Hanseatic colours of the free cities Bremen, Hamburg, and Lübeck as well as of Brandenburg resulted in the black-white-red commercial flag of the North German Confederation, which became the flag of the German Empire in 1871.
"Suum cuique" ("to each, his own"), the motto of the Order of the Black Eagle created by King Frederick I in 1701, was often associated with the whole of Prussia. The Iron Cross, a military decoration created by King Frederick William III in 1813, was also commonly associated with the country. The region, originally populated by Baltic Old Prussians who were Christianised, became a favoured location for immigration by (later mainly Protestant) Germans ("see Ostsiedlung"), as well as Poles and Lithuanians along the border regions.
Before its abolition, the territory of the Kingdom of Prussia included the provinces of West Prussia, East Prussia, Brandenburg, Saxony (including most of the present-day state of Saxony-Anhalt and parts of the state of Thuringia in Germany), Pomerania, Rhineland, Westphalia, Silesia (without Austrian Silesia), Lusatia, Schleswig-Holstein, Hanover, Hesse-Nassau, and a small detached area in the south called Hohenzollern, the ancestral home of the Prussian ruling family. The land that Teutonic Prussia occupied was flat and covered with rich soil. The land was perfectly suited to the large-scale raising of wheat. The rise of early Prussia was based on the raising and selling of wheat. Teutonic Prussia became known as the "bread basket of Western Europe" (in German, "Kornkammer", or granary). The port cities of Stettin (Szczecin) in Pomerania, Danzig (Gdansk) in Prussia, Riga in Livonia, Koenigsberg (Kaliningrad) and Memel (Klaipėda) rose on the back of this wheat production. Wheat production and trade brought Prussia into close relationship with the Hanseatic League during the period of time from 1356 (official founding of the Hanseatic League) until the decline of the League in about 1500.
The expansion of Prussia based on its connection with the Hanseatic League cut both Poland and Lithuania off from the coast of the Baltic Sea and trade abroad. This meant that Poland and Lithuania would be traditional enemies of Prussia—which was still called the Teutonic Knights.
In 1871, Prussia's population numbered 24.69 million, accounting for 60% of the German Empire's population. In 1910, the population had increased to 40.17 million (62% of the Empire's population). In 1914, Prussia had an area of 354,490 km². In May 1939 Prussia had an area of 297,007 km² and a population of 41,915,040 inhabitants. The Principality of Neuenburg, now the Canton of Neuchâtel in Switzerland, was a part of the Prussian kingdom from 1707 to 1848.
Although Prussia was dominated by Protestant Germans (Lutherans along with some Reformed), it contained millions of Catholics in the west and in Poland. East Prussia's southern region of Masuria was mostly made up of Germanised Protestant Masurs. There were numerous Catholic populations in the Rhineland and parts of Westphalia. In addition, West Prussia, Warmia, Silesia, and the Province of Posen had predominantly Catholic populations.
In 1871, approximately 2.4 million Poles lived in Prussia, constituting the largest minority. Other minorities were Jews, Danes, Frisians, Kashubians (72,500 in 1905), Masurians (248,000 in 1905), Lithuanians (101,500 in 1905), Walloons, Czechs and Sorbs.
The area of Greater Poland, where the Polish nation had originated, became the Province of Posen after the Partitions of Poland. Poles in this Polish-majority province (62% Polish, 38% German) resisted German rule. Also, the southeast portion of Silesia (Upper Silesia) had a Polish majority. But Catholics, ethnic Poles and other Slavs, and Jews did not have equal status with Protestants
As a result of the Treaty of Versailles in 1919 the Second Polish Republic was granted not only these two areas, but also areas with a German majority in the Province of West Prussia. After World War II, East Prussia, Silesia, most of Pomerania, and the eastern part of Brandenburg were annexed by either the Soviet Union or Poland.
Early history.
In 1211 Andrew II of Hungary granted Burzenland in Transylvania as a fiefdom to the Teutonic Knights. In 1225, Andrew II expelled the Teutonic Knights from Transylvania, and they had to transfer to the Baltic Sea. Konrad I, the Polish Duke of Masovia, unsuccessfully attempted to conquer pagan Prussia in crusades in 1219 and 1222.
In 1226 Duke Konrad invited the Teutonic Knights, a German military order of crusading knights, headquartered in the Kingdom of Jerusalem at Acre, to conquer the Baltic Prussian tribes on his borders.
During 60 years of struggles against the Old Prussians, the order created an independent state which came to control Prūsa. After the Livonian Brothers of the Sword joined the Teutonic Order in 1237 they also controlled Livonia (now Latvia and Estonia). Around 1252 they finished the conquest of the northernmost Prussian tribe of the Skalvians as well as the western Baltic Curonians and erected the Memel Castle, which developed into the major port city of Memel (Klaipėda). The final border between Prussia and the adjoining Grand Duchy of Lithuania was determined in the Treaty of Melno in 1422.
The Hanseatic League was officially formed in 1356 as a group of trading cities in northern Europe which came to have a monopoly on all trade leaving the interior of Europe and Scandinavia and on all sailing trade in the Baltic Sea for foreign countries. The businessmen of the interior Sweden, Denmark and Poland came to feel oppressed by the Hanseatic League.
In the course of the Ostsiedlung process, settlers were invited in, a majority of them Germans. This brought about changes in the ethnic composition as well as in language, culture and law. Low German became the dominant language.
The Knights were subordinate to the pope and the emperor. Their initially close relationship with the Polish Crown deteriorated after they conquered Polish-controlled Pomerelia and Danzig (Gdańsk) in 1308. Eventually Poland and Lithuania, allied through the Union of Krewo (1385), defeated the Knights in the Battle of Grunwald (Tannenberg) in 1410.
The Thirteen Years' War (1454–1466) began when the Prussian Confederation, a coalition of Hanseatic cities of western Prussia, rebelled against the Order and requested help from the Polish king. The Teutonic Knights were forced to acknowledge the sovereignty of and to pay tribute to King Casimir IV Jagiellon of Poland in the Second Peace of Thorn (1466), losing western Prussia (Royal Prussia) to Poland in the process. Pursuant to the Second Peace of Thorn, two Prussian states were established
In 1525, Grand Master Albert of Brandenburg-Ansbach, a member of a cadet branch of the House of Hohenzollern, became a Lutheran Protestant and secularised the Order's remaining Prussian territories into the Duchy of Prussia. This was the area east of the mouth of the Vistula River, later sometimes called "Prussia proper". For the first time, these lands came into the hands of a branch of the Hohenzollern family. (The Hohenzollern dynasty had ruled the Margraviate of Brandenburg to the west, a German state centered on Berlin, since the 15th century.) Furthermore, with his renunciation of the Order, Albert could now marry and produce legitimate heirs.
Brandenburg-Prussia.
Brandenburg and Prussia were unified two generations later. Anna, granddaughter of Albert I and daughter of Duke Albert Frederick (reigned 1568–1618), married her cousin Elector John Sigismund of Brandenburg. Upon the death of Albert Frederick in 1618, who died without male heirs, John Sigismund was granted the right of succession to the Duchy of Prussia, which was still a Polish fief. From this time the Duchy of Prussia was in personal union with the Margraviate of Brandenburg. The resulting state, known as Brandenburg-Prussia, consisted of geographically disconnected territories in Prussia, Brandenburg, and the Rhineland lands of Cleves and Mark.
During the Thirty Years' War, the disconnected Hohenzollern lands were repeatedly marched across by various armies, especially the occupying Swedes. The ineffective and militarily weak Margrave George William (1619–1640) fled from Berlin to Königsberg, the historic capital of the Duchy of Prussia, in 1637. His successor, Frederick William I (1640–1688), reformed the army to defend the lands.
Frederick William I went to Warsaw in 1641 to render homage to King Władysław IV Vasa of Poland for the Duchy of Prussia, which was still held in fief from the Polish crown. In the first phase of the Second Northern War (1654–1660), he took the duchy as a fief from the Swedish king who later granted him full sovereignty in the Treaty of Labiau. In 1657, this grant was renewed by the Polish king in the treaties of Wehlau and Bromberg. With Prussia, the Brandenburg Hohenzollern dynasty now held a territory free of any feudal obligations, which constituted the basis for their later elevation to kings.
Frederick William I became known as the "Great Elector" for his achievements in organizing the electorate, which he accomplished by establishing an absolute monarchy (see absolutism) in Brandenburg-Prussia. Above all, he emphasized the importance of a powerful military to protect the state's disconnected territories, while the Edict of Potsdam opened Brandenburg-Prussia for immigration of Protestant refugees, and he established a bureaucracy to carry out state business efficiently.
Kingdom of Prussia.
On 18 January 1701, Frederick William's son, Elector Frederick III, upgraded Prussia from a duchy to a kingdom and crowned himself King Frederick I. To avoid offending Poland, where a part of the old Prussia lay, Leopold I, emperor of the Holy Roman Empire where most of the lands of Prussia lay, allowed Frederick only to title himself "King "in" Prussia", not "King "of" Prussia".
The state of Brandenburg-Prussia became commonly known as "Prussia", although most of its territory, in Brandenburg, Pomerania, and western Germany, lay outside of Prussia proper. The Prussian state grew in splendour during the reign of Frederick I, who sponsored the arts at the expense of the treasury.
Frederick I was succeeded by his son, Frederick William I (1713–1740) the austere "Soldier King", who did not care for the arts but was thrifty and practical. He is considered the creator of the vaunted Prussian bureaucracy and the professionalized standing army, which he developed into one of the most powerful in Europe, although his troops only briefly saw action during the Great Northern War. In view of the size of the army in relation to the total population, Mirabeau said later: "Prussia, is not a state with an army, but an army with a state." Also, Frederick William settled more than 20,000 Protestant refugees from Salzburg in thinly populated eastern Prussia, which was eventually extended to the west bank of the Memel river, and other regions. In the treaty of Stockholm (1720), he acquired half of Swedish Pomerania.
The king died in 1740 and was succeeded by his son, Frederick II, whose accomplishments led to his reputation as "Frederick the Great". As crown prince, Frederick had focused, primarily, on philosophy and the arts. He was an accomplished flute player. In 1740, Prussian troops crossed over the undefended border of Silesia and occupied Schweidnitz. Silesia was the richest province of Habsburg Austria. It signalled the beginning of three Silesian Wars (1740–1763). The First Silesian War (1740–1742) and the Second Silesian War (1744–1745) have, historically, been grouped together with the general European war called the War of Austrian Succession (1740–1748). Holy Roman Emperor Charles VI had died on October 20, 1740. He was succeeded to the throne by his daughter, Maria Theresa.
By defeating the Austrian Army at the Battle of Mollwitz on April 10, 1741, Frederick succeeded in conquering Lower Silesia (the northwestern half of Silesia). In the next year, 1742, he conquered Upper Silesia (the southeastern half). Furthermore, in the third Silesian War (usually grouped with the Seven Years War) Frederick won a victory over Austria at the Battle of Lobositz on October 1, 1756. On November 3, 1760 Frederick won another battle—the decisive battle—the Battle of Torgau. With this victory and the overall victory in the Seven Years War, Frederick, allied with Great Britain, Hanover, and Hesse-Kassel, was able to hold the whole of Silesia against a coalition of Saxony, Austria, France, and Russia. Voltaire, a close friend of the king, once described Frederick the Great's Prussia by saying "...it was Sparta in the morning, Athens in the afternoon." From these wars onwards the Austria–Prussia rivalry dominated German politics until 1866.
Silesia, full of rich soils and prosperous manufacturing towns, became a vital region to Prussia, greatly increasing the nation's area, population, and wealth. Success on the battleground against Austria and other powers proved Prussia's status as one of the great powers of Europe. The Silesian Wars began more than a century of rivalry and conflict between Prussia and Austria as the two most powerful states operating within the Holy Roman Empire (although, ironically, both had extensive territory outside the empire). In 1744 the County of East Frisia fell to Prussia following the extinction of its ruling Cirksena dynasty.
In the last 23 years of his reign until 1786, Frederick II, who understood himself as the "first servant of the state", promoted the development of Prussian areas such as the Oderbruch. At the same time he built up Prussia's military power and participated in the First Partition of Poland with Austria and Russia (1772), an act that geographically connected the Brandenburg territories with those of Prussia proper. During this period, he also opened Prussia's borders to immigrants fleeing from religious persecution in other parts of Europe, such as the Huguenots. Prussia became a safe haven in much the same way that the United States welcomed immigrants seeking freedom in the 19th century.
Frederick the Great, the first "King "of" Prussia", practised enlightened absolutism. He introduced a general civil code, abolished torture, and established the principle that the Crown would not interfere in matters of justice. He also promoted an advanced secondary education, the forerunner of today's German gymnasium (grammar school) system, which prepares the brightest students for university studies. The Prussian education system was emulated in various countries, including the United States.
Napoleonic Wars.
During the reign of King Frederick William II (1786–1797), Prussia annexed additional Polish territory through further Partitions of Poland. His successor, Frederick William III (1797–1840), announced the union of the Prussian Lutheran and Reformed churches into one church.
Prussia took a leading part in the French Revolutionary Wars, but remained quiet for more than a decade due to the Peace of Basel of 1795, only to go once more to war with France in 1806 as negotiations with that country over the allocation of the spheres of influence in Germany failed. Prussia suffered a devastating defeat against Napoleon Bonaparte's troops in the Battle of Jena-Auerstedt, leading Frederick William III and his family to flee temporarily to Memel. Under the Treaties of Tilsit in 1807, the state lost about one third of its area, including the areas gained from the second and third Partitions of Poland, which now fell to the Duchy of Warsaw. Beyond that, the king was obliged to pay a large indemnity, to cap his army at 42,000 men, and to allow French troops to be garrisoned throughout Prussia, effectively making the Kingdom a French satellite.
In response to this defeat, reformers such as Stein and Hardenberg set about modernising the Prussian state. Among their reforms were the liberation of peasants from serfdom, the Emancipation of Jews and making full citizens of them. The school system was rearranged, and in 1818 free trade was introduced. The process of army reform ended in 1813 with the introduction of compulsory military service.
After the defeat of Napoleon in Russia, Prussia quit its alliance with France and took part in the Sixth Coalition during the "Wars of Liberation" ("Befreiungskriege") against the French occupation. Prussian troops under Marshal Gebhard Leberecht von Blücher contributed crucially in the Battle of Waterloo of 1815 to the final victory over Napoleon. Prussia's reward in 1815 at the Congress of Vienna was the recovery of her lost territories, as well as the whole of the Rhineland, Westphalia, and some other territories. These western lands were to be of vital importance because they included the Ruhr Area, the centre of Germany's fledgling industrialisation, especially in the arms industry. These territorial gains also meant the doubling of Prussia's population. In exchange, Prussia withdrew from areas of central Poland to allow the creation of Congress Poland under Russian sovereignty.
Prussia emerged from the Napoleonic Wars as the dominant power in Germany, overshadowing long-time rival Austria, which had abdicated the imperial crown in 1806. In 1815 Prussia became part of the German Confederation.
The first half of the 19th century saw a prolonged struggle in Germany between liberals, who wanted a united, federal Germany under a democratic constitution, and conservatives, who wanted to maintain Germany as a patchwork of independent, monarchical states, with Prussia and Austria competing for influence. One small movement that signaled a desire for German unification in this period was the Burschenschaft student movement, by students who encouraged the use of the black-red-gold flag, discussions of a unified German nation, and a progressive, liberal political system. Because of Prussia's size and economic importance, smaller states began to join its free trade area in the 1820s. Prussia benefited greatly from the creation in 1834 of the German Customs Union (Zollverein), which included most German states but excluded Austria.
In 1848 the liberals saw an opportunity when revolutions broke out across Europe. Alarmed, King Frederick William IV agreed to convene a National Assembly and grant a constitution. When the Frankfurt Parliament offered Frederick William the crown of a united Germany, he refused on the grounds that he would not accept a crown from a revolutionary assembly without the sanction of Germany's other monarchs.
The Frankfurt Parliament was forced to dissolve in 1849, and Frederick William issued Prussia's first constitution by his own authority in 1850. This conservative document provided for a two-house parliament. The lower house, or "Landtag" was elected by all taxpayers, who were divided into three classes whose votes were weighted according to the amount of taxes paid. Women and those who paid no taxes had no vote. This allowed just over one-third of the voters to choose 85% of the legislature, all but assuring dominance by the more well-to-do men of the population. The upper house, which was later renamed the "Herrenhaus" ("House of Lords"), was appointed by the king. He retained full executive authority and ministers were responsible only to him. As a result, the grip of the landowning classes, the Junkers, remained unbroken, especially in the eastern provinces.
Wars of unification.
In 1862 King Wilhelm I appointed Otto von Bismarck as Prime Minister of Prussia. Bismarck was determined to defeat both the liberals and conservatives and increase Prussian supremacy and influence among the German states. There has been much debate as to whether Bismarck actually planned to create a united Germany when he set out on this journey, or whether he simply took advantage of the circumstances that fell into place. Certainly his memoirs paint a rosy picture of an idealist, but these were written with the benefit of hindsight. What is clear is that Bismarck curried support from large sections of the people by promising to lead the fight for greater German unification. He eventually guided Prussia through three wars which together brought William the position of German Emperor.
Schleswig Wars.
The Kingdom of Denmark was at the time in personal union with the Duchies of Schleswig and Holstein, both of which had close ties with each other, although only Holstein was part of the German Confederation. When the Danish government tried to integrate Schleswig, but not Holstein, into the Danish state, Prussia led the German Confederation against Denmark in the First War of Schleswig (1848–1851). Because Russia supported Austria, Prussia also conceded predominance in the German Confederation to Austria in the Punctation of Olmütz in 1850.
In 1863, Denmark introduced a shared constitution for Denmark and Schleswig. This led to conflict with the German Confederation, which authorized the occupation of Holstein by the Confederation, from which Danish forces withdrew. In 1864, Prussian and Austrian forces crossed the border between Holstein and Schleswig initiating the Second War of Schleswig. The Austro-Prussian forces defeated the Danes, who surrendered both territories. In the resulting Gastein Convention of 1865 Prussia took over the administration of Schleswig while Austria assumed that of Holstein.
Austro-Prussian War.
Bismarck realized that the dual administration of Schleswig and Holstein was only a temporary solution, and tensions rose between Prussia and Austria. The struggle for supremacy in Germany then led to the Austro-Prussian War (1866), triggered by the dispute over Schleswig and Holstein.
On the Austrian side stood the south German states (including Bavaria and Württemberg), some central German states (including Saxony), and Hanover in the north. On the side of Prussia were Italy, most north German states, and some smaller central German states. Eventually, the better-armed Prussian troops won the crucial victory at the Battle of Königgrätz under Helmuth von Moltke the Elder. The century-long struggle between Berlin and Vienna for dominance of Germany was now over. As a side show in this war, Prussia defeated Hanover in the Battle of Langensalza. While Hanover hoped in vain for help from Britain (as they had previously been in personal union), Britain stayed out of a confrontation with a continental superpower and Prussia satisfied its desire for merging the once separate territories and gaining strong economic and strategic power, particularly from the full access to the resources of the Ruhr.
Bismarck desired Austria as an ally in the future, and so he declined to annex any Austrian territory. But in the Peace of Prague in 1866, Prussia annexed four of Austria's allies in northern and central Germany—Hanover, Hesse-Kassel (or Hesse-Cassel), Nassau and Frankfurt. Prussia also won full control of Schleswig-Holstein. As a result of these territorial gains, Prussia now stretched uninterrupted across the northern two-thirds of Germany and contained two-thirds of Germany's population. The German Confederation was dissolved, and Prussia impelled the 21 states north of the Main River into forming the North German Confederation.
Prussia was the dominant state in the new confederation, as the kingdom comprised almost four-fifths of the new state's territory and population. Prussia's near-total control over the confederation was secured in the constitution drafted for it by Bismarck in 1867. Executive power was held by a president, assisted by a chancellor responsible only to him. The presidency was a hereditary office of the Hohenzollern rulers of Prussia. There was also a two-house parliament. The lower house, or "Reichstag" (Diet), was elected by universal male suffrage. The upper house, or "Bundesrat" (Federal Council) was appointed by the state governments. The Bundesrat was, in practice, the stronger chamber. Prussia had 17 of 43 votes, and could easily control proceedings through alliances with the other states.
As a result of the peace negotiations, the states south of the Main remained theoretically independent, but received the (compulsory) protection of Prussia. Additionally, mutual defense treaties were concluded. However, the existence of these treaties was kept secret until Bismarck made them public in 1867, when France tried to acquire Luxembourg.
Franco-Prussian War.
The controversy with the Second French Empire over the candidacy of a Hohenzollern to the Spanish throne was escalated both by France and Bismarck. With his Ems Dispatch, Bismarck took advantage of an incident in which the French ambassador had approached William. The government of Napoleon III, expecting another civil war among the German states, declared war against Prussia, continuing Franco-German enmity. Honouring their treaties, however, the German states joined forces and quickly defeated France in the Franco-Prussian War in 1870. Following victory under Bismarck's and Prussia's leadership, Baden, Württemberg, and Bavaria — which had remained outside the North German Confederation — accepted incorporation into a united German Empire.
The empire was a "Lesser German" solution (in German, "kleindeutsche Lösung") to the question of uniting all German-speaking peoples into one state, because it excluded Austria, which remained connected to Hungary and whose territories included non-German populations. On 18 January 1871 (the 170th anniversary of the coronation of King Frederick I), William was proclaimed "German Emperor" (not "Emperor of Germany") in the Hall of Mirrors at Versailles outside Paris, while the French capital was still under siege.
German Empire.
The two decades after the unification of Germany were the peak of Prussia's fortunes, but the seeds for potential strife were built into the Prusso-German political system.
The constitution of the German Empire was a slightly amended version of the North German Confederation's constitution. Officially, the German Empire was a federal state. In practice, Prussia's relationship with the rest of the empire was somewhat confusing. The Hohenzollern kingdom included three-fifths of the German territory and two-thirds of its population. The Imperial German Army was, in practice, an enlarged Prussian army, although the other kingdoms (Bavaria, Saxony, and Württemberg) retained their own armies. The imperial crown was a hereditary office of the House of Hohenzollern, the royal house of Prussia. The prime minister of Prussia was, except for two brief periods (January–November 1873 and 1892–94), also imperial chancellor. But the empire itself had no right to collect taxes directly from its subjects; the only incomes fully under federal control were the customs duties, common excise duties, and the revenue from postal and telegraph services. While all men above age 25 were eligible to vote in imperial elections, Prussia retained its restrictive three-class voting system. This effectively required the king/emperor and prime minister/chancellor to seek majorities from legislatures elected by two different franchises. In both the kingdom and the empire, the original constituencies were never redrawn to reflect changes in population, meaning that rural areas were grossly overrepresented by the turn of the 20th century.
As a result, Prussia and the German Empire were something of a paradox. Bismarck knew that his new German Reich was now a colossus out of all proportion to the rest of the continent. With this in mind, he declared Germany a satisfied power, using his talents to preserve peace, for example at the Congress of Berlin. Bismarck had barely any success in some of his domestic policies, such as the anti-Catholic "Kulturkampf", but he also had mixed success on ones like Germanization or expulsion of Poles of foreign nationality (Russian or Austro-Hungarian).
Frederick III was emperor for just 99 days in 1888 upon the death of his father, dying from cancer. At age 29, William became Emperor William II after a difficult youth and conflicts with his British mother Victoria, Princess Royal. He turned out to be a man of limited experience, narrow and reactionary views, poor judgment, and occasional bad temper, which alienated former friends and allies.
Railways.
Prussia nationalized its railways in the 1880s in an effort both to lower rates on freight service and to equalize those rates among shippers. Instead of lowering rates as far as possible, the government ran the railways as a profitmaking endeavor, and the railway profits became a major source of revenue for the state. The nationalization of the railways slowed the economic development of Prussia because the state favored the relatively backward agricultural areas in its railway building. Moreover, the railway surpluses substituted for the development of an adequate tax system.
The Free State of Prussia in the Weimar Republic.
Because of the German Revolution of 1918, William II abdicated as German Emperor and King of Prussia. Prussia was proclaimed a "Free State" (i.e. a republic, German: "Freistaat") within the new Weimar Republic and in 1920 received a democratic constitution.
Almost all of Germany's territorial losses, specified in the Treaty of Versailles, were areas that had been part of Prussia: Eupen and Malmedy to Belgium; North Schleswig to Denmark; the Memel Territory to Lithuania; the Hultschin area to Czechoslovakia. Many of the areas which Prussia had annexed in the partitions of Poland, such as the Provinces of Posen and West Prussia, as well as eastern Upper Silesia, went to the Second Polish Republic. Danzig became the Free City of Danzig under the administration of the League of Nations. Also, the Saargebiet was created mainly from formerly Prussian territories. East Prussia became an exclave, only reachable by ship (the Sea Service East Prussia) or by a railway through the Polish corridor.
The German government seriously considered breaking up Prussia into smaller states, but eventually traditionalist sentiment prevailed and Prussia became by far the largest state of the Weimar Republic, comprising 60% of its territory. With the abolition of the older Prussian franchise, it became a stronghold of the left. Its incorporation of "Red Berlin" and the industrialised Ruhr Area — both with working-class majorities — ensured left-wing dominance.
From 1919 to 1932, Prussia was governed by a coalition of the Social Democrats, Catholic Centre, and German Democrats; from 1921 to 1925, coalition governments included the German People's Party. Unlike in other states of the German Reich, majority rule by democratic parties in Prussia was never endangered. Nevertheless, in East Prussia and some industrial areas, the Nazi Party of Adolf Hitler gained more and more influence and popular support, especially from the lower middle class. Except for Catholic Upper Silesia, the Nazi Party in 1932 became the largest party in most parts of the Free State of Prussia. However, the democratic parties in coalition remained a majority, while Communists and Nazis were in the opposition.
The East Prussian Otto Braun, who was Prussian minister-president almost continuously from 1920 to 1932, is considered one of the most capable Social Democrats in history. He implemented several trend-setting reforms together with his minister of the interior, Carl Severing, which were also models for the later Federal Republic of Germany (FRG). For instance, a Prussian minister-president could be forced out of office only if there was a "positive majority" for a potential successor. This concept, known as the constructive vote of no confidence, was carried over into the Basic Law of the FRG. Most historians regard the Prussian government during this time as far more successful than that of Germany as a whole.
In contrast to its prewar authoritarianism, Prussia was a pillar of democracy in the Weimar Republic. This system was destroyed by the "Preußenschlag" ("Prussian coup") of Reich Chancellor Franz von Papen. In this coup d'état, the government of the Reich unseated the Prussian government on 20 July 1932, under the pretext that the latter had lost control of public order in Prussia (during the Bloody Sunday of Altona, Hamburg, which was still part of Prussia at that time). Papen appointed himself Reich commissioner for Prussia and took control of the government. The "Preußenschlag" made it easier, only half a year later, for Hitler to take power decisively in Germany, since he had the whole apparatus of the Prussian government, including the police, at his disposal.
The End of Prussia.
After the appointment of Hitler as the new chancellor, the Nazis used the absence of Franz von Papen as an opportunity to appoint Hermann Göring federal commissioner for the Prussian ministry of the interior. The Reichstag election of March 5, 1933 strengthened the position of the Nazi Party, although they did not achieve an absolute majority.
Because the Reichstag building had been set on fire a few weeks earlier, the new Reichstag was opened in the Garrison Church of Potsdam on March 21, 1933 in the presence of President Paul von Hindenburg. In a propaganda-filled meeting between Hitler and the Nazi Party, the "marriage of old Prussia with young Germany" was celebrated, to win over the Prussian monarchists, conservatives, and nationalists and induce them to vote for the Enabling Act of 1933.
In the centralised state created by the Nazis in the "Law on the Reconstruction of the Reich" ("Gesetz über den Neuaufbau des Reiches", 30 January 1934) and the "Law on Reich Governors" ("Reichsstatthaltergesetz", 30 January 1935) the states were dissolved, in fact if not in law. The federal state governments were now controlled by governors for the Reich who were appointed by the chancellor. Parallel to that, the organisation of the party into districts ("Gaue") gained increasing importance, as the official in charge of a "Gau" (the head of which was called a "Gauleiter") was again appointed by the chancellor who was at the same time chief of the Nazi Party.
In Prussia, this centralistic policy went even further. From 1934 almost all ministries were merged and only a few departments were able to maintain their independence. Hitler himself became formally the governor of Prussia. His functions were exercised, however, by Hermann Göring, as Prussian prime minister.
As provided for in the "Greater Hamburg Law" ("Groß-Hamburg-Gesetz"), certain exchanges of territory took place. Prussia was extended on 1 April 1937, for instance, by the incorporation of the Free and Hanseatic City of Lübeck.
The Prussian lands transferred to Poland after the Treaty of Versailles were re-annexed during World War II. However, most of this territory was not reintegrated back into Prussia but assigned to separate "Gaue" of Danzig-West Prussia and Wartheland.
With the end of Nazi rule in 1945 came the division of Germany into Zones of Occupation, and the transfer of control of everything east of the Oder-Neisse line, (including Silesia, Farther Pomerania, Eastern Brandenburg, and southern East Prussia), to Poland, with the northern third of East Prussia, including Königsberg, now Kaliningrad, going to the Soviet Union. Today the Kaliningrad Oblast is a Russian exclave between Lithuania and Poland. During the Soviet Army's takeover of eastern Germany an estimated ten million Germans fled, were expelled from (or were not able to return) to these territories as part of the Potsdam Agreement and the sanctioned German exodus from Eastern Europe.
As part of their war aims the Western allies sought the abolition of Prussia. Stalin was initially content to retain the name, Russia having a different historical view of its neighbour and sometime former ally. In Law #46 of February 25, 1947 the Allied Control Council formally proclaimed the dissolution of Prussia.
In the Soviet Zone of Occupation, which became East Germany in 1949, the former Prussian territories were reorganised into the states of Brandenburg and Saxony-Anhalt, with the remaining parts of the Province of Pomerania going to Mecklenburg-Vorpommern. These states were abolished in 1952 in favour of districts, but were recreated after the fall of the Eastern Bloc in 1990.
In the Western Zones of occupation, which became West Germany in 1949, the former Prussian territories were divided up among North Rhine-Westphalia, Lower Saxony, Hesse, Rhineland-Palatinate, and Schleswig-Holstein. Württemberg-Baden and Württemberg-Hohenzollern were later merged with Baden to create the state of Baden-Württemberg.
Administration.
Main articles: Brandenburg-Prussia, Kingdom of Prussia, Free State of Prussia (1918–1933) and Free State of Prussia (1933–1947)
In the mid-16th century, the margraves of Brandenburg had become highly dependent on the estates (counts, lords, knights and towns, no prelates due to the Protestant Reformation in 1538). The margraviate's liabilities and tax income as well as the margrave's finances were controlled by the "Kreditwerk", an institution not controlled by the elector, and the "Großer Ausschuß" ("Great Committee") of the estates. This was due to concessions made by Joachim II in 1541 in turn for financial aid by the estates, however, the "Kreditwerk" went bankrupt between 1618 and 1625. The margraves further had to yield the veto of the estates in all issues concerning the "better or worse of the country", in all legal commitments, and in all issues concerning pawn or sale of the elector's real property.
To reduce the influence of the estates, Joachim Frederick in 1604 created a council called "Geheimer Rat für die Kurmark" ("Privy Council for the Electorate"), which instead of the estates was to function as the supreme advisory council for the elector. While the council was permanently established in 1613, it failed to gain any influence until 1651 due to the Thirty Years' War.
Until after the Thirty Years' War, the territories of Brandenburg-Prussia were politically independent from each other, connected only by the common feudal superior. Frederick William, who envisioned the transformation of the personal union into a real union, started to centralize the Brandenburg-Prussian government with an attempt to establish the "Geheimer Rat" as a central authority for all territories in 1651, but this project proved to be unfeasible. Instead, the elector continued to appoint a governor ("Kurfürstlicher Rat") for each territory, who in most cases was a member of the "Geheimer Rat". The most powerful institution in the territories remained the governments of the estates ("Landständische Regierung", named "Oberratsstube" in Prussia and "Geheime Landesregierung" in Mark and Cleves), which were the highest government agencies regarding jurisdiction, finances and administration. The elector attempted to balance the estates' governments by creating "Amtskammer" chambers to administer and coordinate the elector's domains, tax income and privileges. Such chambers were introduced in Brandenburg in 1652, in Cleves and Mark in 1653, in Pomerania in 1654, in Prussia in 1661 and in Magdeburg in 1680. Also in 1680, the "Kreditwerk" came under the aegis of the elector.
Frederick William's excise tax ("Akzise"), which since 1667 replaced the property tax raised in Brandenburg for Brandenburg-Prussia's standing army with the estates' consent, was raised by the elector without consultation of the estates. The conclusion of the Second Northern War had strengthened the elector politically, enabling him to reform the constitution of Cleves and Mark in 1660 and 1661 to introduce officials loyal to him and independent of the local estates. In the Duchy of Prussia, he confirmed the traditional privileges of the estates in 1663, but the latter accepted the caveat that these privileges were not to be used to interfere with the exertion of the elector's sovereignty. As in Brandenburg, Frederick William ignored the privilege of the Prussian estates to confirm or veto taxes raised by the elector: while in 1656, an "Akzise" was raised with the estates' consent, the elector by force collected taxes not approved by the Prussian estates for the first time in 1674. Since 1704, the Prussian estates had de facto relinquished their right to approve the elector's taxes while formally still entitled to do so. In 1682, the elector introduced an "Akzise" to Pomerania and in 1688 to Magdeburg, while in Cleves and Mark an "Akzise" was introduced only between 1716 and 1720. Due to Frederick William's reforms, the state income increased threefold during his reign, and the tax burden per subject reached a level twice as high as in France.
Under the rule of Frederick III (I), the Brandenburg Prussian territories were de facto reduced to provinces of the monarchy. Frederick William's testament would have divided Brandenburg-Prussia among his sons, yet firstborn Frederick III with the emperor's backing succeeded in becoming the sole ruler based on the Treaty of Gera, which forbade a division of Hohenzollern territories. In 1689, a new central chamber for all Brandenburg-Prussian territories was created, called "Geheime Hofkammer" (since 1713: "Generalfinanzdirektorium"). This chamber functioned as a superior agency of the territories' "Amtskammer" chambers. The General War Commissariat ("Generalkriegskommissariat") emerged as a second central agency, superior to the local "Kriegskommissariat" agencies initially concerned with the administration of the army, but until 1712 transformed into an agency also concerned with general tax and police tasks.
The Kingdom of Prussia was an absolute monarchy until the Revolutions of 1848 in the German states, after which Prussia became a constitutional monarchy and Adolf Heinrich von Arnim-Boitzenburg was elected as Prussia's first prime minister. Following Prussia's first constitution, a two-house parliament was formed. The lower house, or "Landtag" was elected by all taxpayers, who were divided into three classes according to the amount of taxes paid. This allowed just over 25% of the voters to choose 85% of the legislature, all but assuring dominance by the more well-to-do elements of the population. The upper house, which was later renamed the Prussian House of Lords, was appointed by the king. He retained full executive authority and ministers were responsible only to him. As a result, the grip of the landowning classes, the Junkers, remained unbroken, especially in the eastern provinces. Prussian Secret Police, formed in response to the Revolutions of 1848 in the German states, aided the conservative government.
Unlike its authoritarian pre-war predecessor, Prussia was a promising democracy within Germany. The abolition of the aristocracy transformed Prussia into a region strongly dominated by the left wing of the political spectrum, with "Red Berlin" and the industrial centre of the Ruhr Area exerting a major influence. During this period, a coalition of centre-left parties ruled, predominantly under the leadership of East Prussian Social Democrat Otto Braun. While in office he implemented several reforms together with his Minister of the Interior, Carl Severing, which were also models for the later Federal Republic of Germany. For instance, a Prussian prime minister could only be forced out of office if there was a "positive majority" for a potential successor. This concept, known as the constructive vote of no confidence, was carried over into the Basic Law of the Federal Republic of Germany. Most historians regard the Prussian government during this time as far more successful than that of Germany as a whole.
Similar to other German states both now and at the time, executive power was continued to be vested in a Minister-President of Prussia and laws established by a Landtag elected by the people.

Puerto Rico
Puerto Rico ( or ), officially the Commonwealth of Puerto Rico (, —literally, "Associated Free State of Puerto Rico"), is an unincorporated territory of the United States, located in the northeastern Caribbean, east of the Dominican Republic and west of both the United States Virgin Islands and the British Virgin Islands.
Puerto Rico (Spanish for "rich port") comprises an archipelago that includes the main island of Puerto Rico and a number of smaller islands, the largest of which are Vieques, Culebra, and Mona. The main island of Puerto Rico is the smallest by land area of the Greater Antilles. However, it ranks third in population among that group of four islands, which also include Cuba, Hispaniola (Dominican Republic and Haiti), and Jamaica. Due to its location, Puerto Rico enjoys a tropical climate and also experiences the Atlantic hurricane season.
Originally populated for centuries by indigenous aboriginal peoples known as Taínos, the island was claimed by Christopher Columbus for Spain during his second voyage to the Americas on November 19, 1493. Under Spanish rule, the island was colonized and the indigenous population was forced into slavery and nearly wiped out due to, among other things, European infectious diseases. The remaining population was emancipated by King Charles I in 1520. Spain possessed Puerto Rico for over 400 years, despite attempts at capture of the island by the French, Dutch, and British. The Spanish Crown, in an attempt to keep Puerto Rico from gaining its independence, revived the Royal Decree of Graces of 1815. The decree was printed in three languages — Spanish, English and French — and it fostered the immigration of hundreds of non-Spanish European families.
The relationship between Puerto Rico and the United States dates back to the Spanish-American War, in which Spain, under the terms of the Treaty of Paris of 1898, ceded the island to the United States. Puerto Ricans became U.S. citizens in 1917, and the United States Congress legislates many aspects of Puerto Rican life. However, the islanders may not vote in U.S. presidential elections. Since 1947, Puerto Ricans have been able to elect their own governor. Its official languages are Spanish and English, with Spanish being the primary language. The island's current political status, including the possibility of statehood or independence, is widely debated in Puerto Rico. A referendum on statehood, independence, or continuance of the status quo will be held on November 6, 2012.
Name.
Puerto Ricans often call the island "Borinquen", from "Borikén", its indigenous Taíno name, which means "Land of the Valiant Lord". The terms "boricua" and "borincano" derive from "Borikén" and "Borinquen" respectively, and are commonly used to identify someone of Puerto Rican heritage. The island is also popularly known in Spanish as "la isla del encanto", meaning "the island of enchantment".
Columbus named the island San Juan Bautista, in honor of Saint John the Baptist. Eventually, traders and other maritime visitors came to refer to the entire island as "Puerto Rico", and "San Juan" became the name of the main trading/shipping port.
History.
Pre-Columbian era.
The ancient history of the archipelago known today as Puerto Rico before the arrival of Columbus is not well known. Unlike other larger more advanced indigenous communities in the New World (Aztec, Inca) that left behind abundant archeological and physical evidence of their societies, the indigenous population of Puerto Rico left scant records. What is known today about them comes from scarce archaeological findings and early Spanish scholarly accounts. Today, there are few and rare cave drawings, rock carvings and ancient recreational activity sites that have been identified with some degree of speculation as to who left them behind. The first comprehensive book on the history of Puerto Rico was written by Fray Íñigo Abbad y Lasierra in 1786, almost three centuries after the first Spaniards arrived on the island.
The first settlers were the Ortoiroid people, an Archaic Period culture of Amerindian hunters and fishermen. An archaeological dig in the island of Vieques in 1990 found the remains of what is believed to be an "Arcaico" (Archaic) man (named "Puerto Ferro Man") dated to around 2000 BCE. The Igneri, a tribe from the region of the Orinoco river, in northern South America, arrived between 120 and 400 CE. The Arcaicos and Igneri co-existed on the island between the 4th and 10th centuries, and perhaps clashed.
Between the 7th and 11th centuries the Taíno culture developed on the island, and by approximately 1000 CE had become dominant. At the time of Columbus' arrival, an estimated 30 to 60 thousand Taíno Amerindians, led by "cacique" (chief) Agüeybaná, inhabited the island. They called it Boriken, "the great land of the valiant and noble Lord". The natives lived in small villages led by a cacique and subsisted on hunting, fishing and gathering of indigenous cassava root and fruit. This lasted until Columbus arrived in 1493. However, Puerto Rican culture today exhibits many Taíno influences within its music and vocabulary.
Spanish colony.
When Columbus arrived in Puerto Rico during his second voyage on , 1493, the island was inhabited by the Taínos. They called it "Borikén", or "Borinquen". Columbus named the island San Juan Bautista, in honor of Saint John the Baptist. The first Spanish settlement, Caparra, was founded on August 8, 1508 by Juan Ponce de León, a lieutenant under Columbus, who later became the first governor of the island. Eventually, traders and other maritime visitors came to refer to the entire island as Puerto Rico, and San Juan became the name of the main trading/shipping port. According to the "500TH Florida Discovery Council Round Table", on March 3, 1513, Juan Ponce de Leon, organized and commenced an expedition (with a Crew of 200-including Women and Free Blacks) departing from "Punta Aguada" Puerto Rico. Puerto Rico was the historic 1st gateway to the discovery of Florida which opened the doors to the advanced settlement of the USA. They introduced Christianity, Cattle, Horses, Sheep, the Spanish language and more to the land (Florida) that later became the United States of America, 107 years before the Pilgrims landed. 
The Spaniards began to colonize the island. The indigenous population (Taínos) came to be exploited and forced into slavery. Within 50 years they were reduced to near extinction by the harsh conditions of work and by European infectious diseases to which they had no natural immunity. For example, the smallpox outbreak in 1518–1519 wiped out much of the Island's indigenous population.
In 1520, King Charles I of Spain issued a royal decree collectively emancipating the remaining Taíno population. Essentially, the Taíno presence while not completely extinct had almost vanished.
The importation of Sub-Saharan African slaves was introduced to provide the new manual work force for the Spanish colonists and merchants. Following the decline of the Taíno population, more slaves were brought to Puerto Rico; however, the number of slaves on the island paled in comparison to those in neighboring islands. African slavery was primarily restricted to coastal ports and cities, while the interior of the island continued to be essentially unexplored and undeveloped. Spanish and other European colonists were concentrated in island's seaports. Puerto Rico soon became an important stronghold and a significant port for Spanish Main colonial expansion. Various forts and walls, such as La Fortaleza, El Castillo San Felipe del Morro and El Castillo de San Cristóbal, were built to protect the strategic port of San Juan from numerous European invasion attempts. San Juan served as an important port-of-call for ships of all European nations for purposes of taking on water, food and other commercial provisions and mercantile exchange.
In 1607, Puerto Rico served as a port provisioning the English ships "Godspeed", "Susan Constant" and "Discovery", which were on their way to establish Jamestown, Virginia, the first successful English settlement in the New World. The Netherlands and England made several attempts to capture Puerto Rico but failed to wrest it from the long-term possession by Spain, which held tenaciously onto its increasingly prized island colony.
During the late 17th and early 18th centuries, Spanish colonial emphasis continued to be focussed on the more prosperous mainland North, Central, and South American colonies. This continued distraction on the part of the Spanish Crown left the island of Puerto Rico virtually unexplored, undeveloped, and (excepting coastal outposts) largely unsettled before the nineteenth century. But as independence movements in the larger Spanish colonies grew successful, Spain began to pay attention to Puerto Rico as one of its last remaining maritime colonies. Amidst the attacks, Puerto Rican culture began to flourish. In 1786, the first comprehensive history of Puerto Rico—"Historia Geográfica, Civil y Política de Puerto Rico" by Fray Iñigo Abbad y Lasierra—was published in Madrid, documenting the history of Puerto Rico from the time of Columbus' landing in 1493 until 1783. The book also presents a first-hand account of Puerto Rican identity, including music, clothing, personality and nationality.
In 1779, citizens of the still-Spanish colony of Puerto Rico fought in the American Revolutionary War under the command of Bernardo de Gálvez, named Field Marshal of the Spanish colonial army in North America. Puerto Ricans participated in the capture of Pensacola, the capital of the British colony of West Florida, and the cities of Baton Rouge, St. Louis and Mobile. The Puerto Rican troops, under the leadership of Brigadier General Ramón de Castro, helped defeat the British and Indian army of 2,500 soldiers and British warships in Pensacola.
In 1809, in a further move to secure its political bond with the island and in the midst of the European Peninsular War, the Supreme Central Junta based in Cádiz recognized Puerto Rico as an overseas province of Spain with the right to send representatives to the recently convened Spanish parliament with equal representation to Mainland Iberian, Mediterranean (Balearic Islands) and Atlantic maritime Spanish provinces (Canary Islands). The first Spanish parliamentary representative from the island of Puerto Rico, Ramon Power y Giralt, died after serving a three-year term in the Cortes. These parliamentary and constitutional reforms, which were in force from 1810 to 1814 and again from 1820 to 1823, were reversed twice afterwards when the traditional monarchy was restored by Ferdinand VII. Nineteenth-century immigration and commercial trade reforms further augmented the island's European population and economy, and expanded Spanish cultural and social imprint on the local character of the island.
Minor slave revolts had occurred in the island during this period; however, the revolt planned and organized by Marcos Xiorro in 1821, was the most important. Even though the conspiracy was unsuccessful, Xiorro achieved legendary status and is part of Puerto Rico's folklore.
In the early 19th century, Puerto Rico had an Independence movement which, due to the harsh persecution by the Spanish authorities, met in the island of St. Thomas. The movement was largely inspired by the ideals of Simón Bolívar of establishing a United Provinces of New Granada which included Puerto Rico and Cuba. Among the influential members of this movement was Brigadier General Antonio Valero de Bernabe, a Puerto Rican military leader known in Latin America as the "Liberator from Puerto Rico" who fought alongside Bolivar and María de las Mercedes Barbudo, a businesswoman also known as the "first Puerto Rican female freedom fighter". The movement was discovered and Governor Miguel de la Torre had its members imprisoned or exiled.
With the increasingly rapid growth of independent former Spanish colonies in the South and Central American states in the first part of the century, Puerto Rico and Cuba continued to grow in strategic importance to the Spanish Crown. In a very deliberate move to increase its hold on its last two new world colonies, the Spanish Crown revived the Royal Decree of Graces of 1815. This time the decree was printed in three languages: Spanish, English and French. Its primary intent was to attract Europeans of who were not of Spanish origin, with the hope that the independence movements would lose their popularity and strength with increase of new loyalist settlers with strong sympathies to Spain. As a consequence, hundreds of families, mainly from Corsica, France, Germany, Ireland, Italy and Scotland, immigrated to the island. 
In 1858, Samuel Morse introduced wired communication to Latin America when he established a telegraph system in Puerto Rico. Morse's oldest daughter, Susan Walker Morse (1821–1885), would often visit her uncle Charles Pickering Walker, who owned the Hacienda Concordia in the town of Guayama. Morse often spent winters at the Hacienda with his daughter and son-in-law, who lived and owned the Habienda Henriqueta, and he set a two-mile telegraph line connecting his son-in-law's hacienda to their house in Arroyo. The line was inaugurated on March 1, 1859 in a ceremony flanked by the Spanish and American flags. The first lines transmitted by Morse that day in Puerto Rico were: "Puerto Rico, beautiful jewel! When you are linked with the other jewels of the Antilles in the necklace of the world's telegraph, yours will not shine less brilliantly in the crown of your Queen!"
As an incentive to immigrate and colonize, free land was offered to those who wanted to populate the two islands on the condition that they swear their loyalty to the Spanish Crown and allegiance to the Roman Catholic Church. It was very successful and European immigration continued even after 1898. Puerto Rico today still receives Spanish and European immigration.
Poverty and political estrangement with Spain led to a small but significant uprising in 1868 known as "Grito de Lares." It began in the rural town of Lares, but was subdued when rebels moved to the neighboring town of San Sebastián. Leaders of this independence movement included Ramón Emeterio Betances, considered the "father" of the Puerto Rican independence movement, and other political figures such as Segundo Ruiz Belvis.
Leaders of "El Grito de Lares", who were in exile in New York City, joined the Puerto Rican Revolutionary Committee, founded on December 8, 1895, and continued their quest for Puerto Rican independence. In 1897, Antonio Mattei Lluberas and the local leaders of the independence movement of the town of Yauco organized another uprising, which became known as the "Intentona de Yauco". This was the first time that the current Puerto Rican flag was unfurled on Puerto Rican soil. The local conservative political factions, which believed that such an attempt would be a threat to their struggle for (colonial) autonomy, opposed such an action. Rumors of the planned event spread to the local Spanish authorities who acted swiftly and put an end to what would be the last major uprising in the island to Spanish colonial rule.
In 1897, Luis Muñoz Rivera and others persuaded the liberal Spanish government to agree to Charters of Autonomy for Cuba and Puerto Rico. In 1898, Puerto Rico's first, but short-lived, autonomous government was organized as an "overseas province" of Spain. This bilaterally agreed-upon charter maintained a governor appointed by Spain, which held the power to annul any legislative decision, and a partially elected parliamentary structure. In February, Governor-General Manuel Macías inaugurated the new government under the Autonomous Charter. General elections were held in March and the autonomous government began to function on , 1898.
United States colony.
In 1890, Captain Alfred Thayer Mahan, a member of the Navy War Board and leading U.S. strategic thinker, wrote a book titled "The Influence of Sea Power upon History" in which he argued for the creation of a large and powerful navy modeled after the British Royal Navy. Part of his strategy called for the acquisition of colonies in the Caribbean Sea which would serve as coaling and naval stations and which would serve as strategical points of defense upon the construction of a canal in the Isthmus.
This idea was not new, since William H. Seward, the former Secretary of State under the administrations of various presidents, among them Abraham Lincoln and Ulysses Grant, had stressed that a canal be built either in Honduras, Nicaragua or Panama and that the United States annex the Dominican Republic and purchase Puerto Rico and Cuba. The idea of annexing the Dominican Republic failed to receive the approval of the U.S. Senate and Spain did not accept the dollars that the U.S. offered for Puerto Rico and Cuba.
Captain Mahan made the following statement to the War Department: A. T. Mahan, "The Influence of Sea Power upon History (1660–1783)", London: Sampson Low, Marston, Seale; p. 83.
Since 1894, the Naval War College had been formulating contingency plans for a war with Spain. By 1896, the Office of Naval Intelligence had prepared a plan which included military operations in Puerto Rican waters. This prewar planning did not contemplate major territorial acquisitions. Except for one 1895 plan which recommended annexation of the island then named "Isle of Pines" (later renamed as Isla de la Juventud), a recommendation dropped in later planning, plans developed for attacks on Spanish territories were intended as support operations against Spain's forces in and around Cuba. However, Jorge Rodriguez Beruf, recognized as a foremost researcher on United States militarism in Puerto Rico, writes that not only was Puerto Rico considered valuable as a naval station, Puerto Rico and Cuba were also abundant in sugar – a valuable commercial commodity which the United States lacked.
On July 25, 1898, during the Spanish-American War, Puerto Rico was invaded by the United States with a landing at Guánica. As an outcome of the war, Spain ceded Puerto Rico, along with the Philippines and Guam, that were under Spanish sovereignty, to the U.S. under the Treaty of Paris. Spain relinquished sovereignty over Cuba, but did not cede it to the U.S.
The United States and Puerto Rico thus began a long-standing relationship. Puerto Rico began the 20th century under the military rule of the U.S. with officials, including the governor, appointed by the President of the United States. The Foraker Act of 1900 gave Puerto Rico a certain amount of civilian popular government, including a popularly elected House of Representatives, also a judicial system following the American legal system that includes both state courts and federal courts establishing a Puerto Rico Supreme Court and a United State District Court; and a non-voting member of Congress, by the title of "Resident Commissioner". In addition, this Act extended all U.S. laws "not locally inapplicable" to Puerto Rico, specifying specific exemption from U.S. Internal Revenue laws. The act empowered the civil government to legislate on "all matters of legislative character not locally inapplicable", including the power to modify and repeal any laws then in existence in Puerto Rico, though the U.S. Congress retained the power to annul acts of the Puerto Rico legislature. During an address to the Puerto Rican legislature in 1906, President Theodore Roosevelt recommended that Puerto Ricans become U.S. citizens. In 1917, Puerto Ricans were made U.S. citizens via the Jones Act. The same Act also provided for a popularly elected Senate to complete a bicameral Legislative Assembly, a bill of rights and authorized the election of a Resident Commissioner to a four-year term. As a result of their new U.S. citizenship, many Puerto Ricans were drafted into World War I and all subsequent wars with U.S. participation in which a national military draft was in effect.
Natural disasters, including a major earthquake, a tsunami and several hurricanes, and the Great Depression impoverished the island during the first few decades under U.S. rule. Some political leaders, like Pedro Albizu Campos who led the Puerto Rican Nationalist Party, demanded change. On , 1937, a march was organized in the southern city of Ponce by the Puerto Rican Nationalist Party. This march turned bloody when the Insular Police, "a force somewhat resembling the National Guard which answered to the U.S.-appointed governor", opened fire upon unarmed and defenseless cadets and bystanders alike, as reported by a U.S. Congressman Vito Marcantonio and the "Hays Commission" led by Arthur Garfield Hays. Nineteen were killed and over 200 were badly wounded, many in their backs while running away. An American Civil Liberties Union report declared it a massacre and it has since been known as the Ponce Massacre. On April 2, 1943, U.S. Senator Millard Tydings introduced a bill in Congress
calling for independence for Puerto Rico. This bill ultimately was defeated.
The internal governance changed during the latter years of the Roosevelt–Truman administrations, as a form of compromise led by Luis Muñoz Marín and others. It culminated with the appointment by President Truman in 1946 of the first Puerto Rican-born governor, Jesús T. Piñero.
Commonwealth.
In 1947, the U.S. granted Puerto Ricans the right to elect democratically their own governor. Luis Muñoz Marín was elected during the 1948 general elections, becoming the first popularly elected governor of Puerto Rico. 
A Bill was introduced before the Puerto Rican Senate which would restrain the rights of the independence and nationalist movements in the island. The Senate at the time was controlled by the PPD, and was presided over by Luis Muñoz Marín. The Bill, also known as the Gag Law ("Ley de la Mordaza" in Spanish) was approved by the legislature on May 21, 1948. It made it illegal to display a Puerto Rican flag, to sing a patriotic tune, to talk of independence, or to fight for the liberation of the island. The Bill, which resembled the anti-communist Smith Law passed in the United States, was signed and made into law on June 10, 1948, by the U.S. appointed governor of Puerto Rico, Jesús T. Piñero, and became known as "Law 53" ("Ley 53" in Spanish). In accordance to the new law, it would be a crime to print, publish, sell, exhibit, organize or help anyone organize any society, group or assembly of people whose intentions are to paralyze or destroy the insular government. Anyone accused and found guilty of disobeying the law could be sentenced to ten years of prison, be fined $10,000 dollars (US), or both. According to Dr. Leopoldo Figueroa, a member of the Puerto Rico House of Representatives, the law was repressive, and was in violation of the First Amendment of the US Constitution, which guarantees Freedom of Speech. He pointed out that the law as such was a violation of the civil rights of the people of Puerto Rico. The infamous law was repealed in 1957.
In 1950, the U.S. Congress approved Public Law 600 (P.L. 81-600), which allowed for a democratic referendum in Puerto Rico to determine whether Puerto Ricans desired to draft their own local constitution. This act was meant to be adopted in the "nature of a compact". It required congressional approval of the Puerto Rico Constitution before it could go into effect, and repealed certain sections of the Organic Act of 1917. The sections of this statute left in force were then entitled the "Puerto Rican Federal Relations Act". Then U.S. Secretary of the Interior Oscar L. Chapman, under whose Department resided responsibility of Puerto Rican affairs, clarified the new commonwealth status in this manner, "The bill (to permit Puerto Rico to write its own constitution) merely authorizes the people of Puerto Rico to adopt their own constitution and to organize a local government...The bill under consideration would not change Puerto Rico's political, social, and economic relationship to the United States."
On October 30, 1950, Pedro Albizu Campos and other nationalists led a 3-day revolt against the United States in various cities and towns of Puerto Rico in what is known as the Puerto Rican Nationalist Party Revolts of the 1950s. The most notable occurred in Jayuya and Utuado. In the Jayuya revolt, known as the Jayuya Uprising, the United States declared martial law, and attacked Jayuya with infantry, artillery and bombers. The Utuado Uprising culminated in what is known as the Utuado massacre. On , 1950, Puerto Rican nationalists Griselio Torresola and Oscar Collazo attempted to assassinate President Harry S Truman. Torresola was killed during the attack, but Collazo was captured. Collazo served 29 years in a federal prison, being released in 1979. Don Pedro Albizu Campos also served many years in a federal prison in Atlanta, Georgia, for seditious conspiracy to overthrow the U.S. government in Puerto Rico.
The Constitution of Puerto Rico was approved by a Constitutional Convention on , 1952, ratified by the U.S. Congress, approved by President Truman on of that year, and proclaimed by Gov. Muñoz Marín on , 1952, on the anniversary of the , 1898, landing of U.S. troops in the Puerto Rican Campaign of the Spanish-American War, until then an annual Puerto Rico holiday. Puerto Rico adopted the name of "Estado Libre Asociado" (literally "Free Associated State", officially translated into English as Commonwealth), for its body politic. The United States Congress legislates over many fundamental aspects of Puerto Rican life, including citizenship, currency, postal service, foreign affairs, military defense, communications, labor relations, the environment, commerce, finance, health and welfare, and many others.
During the 1950s, Puerto Rico experienced rapid industrialization, due in large part to "Operación Manos a la Obra" ("Operation Bootstrap"), an offshoot of FDR's New Deal, which aimed to transform Puerto Rico's economy from agriculture-based to manufacturing-based. Presently, Puerto Rico has become a major tourist destination, as well as a global center for pharmaceutical manufacturing. Yet it still struggles to define its political status. Three plebiscites have been held in recent decades to resolve the political status, but no changes have been attained. Support for the pro-statehood party, Partido Nuevo Progresista (PNP), and the pro-commonwealth party, Partido Popular Democrático (PPD), remains about equal. The only registered pro-independence party, the Partido Independentista Puertorriqueño (PIP), usually receives 3–5% of the electoral votes.
Government and politics.
Puerto Rico has a republican form of government, subject to U.S. jurisdiction and sovereignty. Its current powers are all delegated by the United States Congress and lack full protection under the United States Constitution. Puerto Rico's head of state is the President of the United States.
The government of Puerto Rico, based on the formal republican system, is composed of three branches: executive, legislative, and judicial. The executive branch is headed by the Governor, currently Luis Fortuño. The legislative branch consists of a bicameral Legislative Assembly made up of a Senate upper chamber and a House of Representatives lower chamber. The Senate is headed by the President of the Senate, while the House of Representatives is headed by the Speaker of the House.
The judicial branch is headed by the Chief Justice of the Supreme Court of Puerto Rico. The legal system is a mix of the civil law and the common law systems. The governor and legislators are elected by popular vote every four years. Members of the Judicial branch are appointed by the governor with the "advice and consent" of the Senate.
Puerto Rico is represented in the United States Congress by a nonvoting delegate, formally called a Resident Commissioner (currently Pedro Pierluisi). Current legislation has returned the Commissioner's power to vote in the Committee of the Whole, but not on matters where the vote would represent a decisive participation. Puerto Rican elections are governed by the Federal Election Commission and the State Elections Commission of Puerto Rico. While residing in Puerto Rico, Puerto Ricans cannot vote in U.S. presidential elections, but they can vote in primaries. Puerto Ricans who become residents of a U.S. state can vote in presidential elections.
Puerto Rico is not an independent country and, as such, it hosts no embassies. It is host, however, to consulates from 41 countries, mainly from the Americas and Europe. Most consulates are located in San Juan. As an unincorporated territory of the United States, Puerto Rico does not have any first-order administrative divisions as defined by the U.S. government, but has 78 municipalities at the second level. Mona Island is not a municipality, but part of the municipality of Mayagüez.
Municipalities are subdivided into wards or barrios, and those into sectors. Each municipality has a mayor and a municipal legislature elected for a four year term. The municipality of San Juan (previously called "town"), was founded first, in 1521, San Germán in 1570, Coamo in 1579, Arecibo in 1614, Aguada in 1692 and Ponce in 1692. An increase of settlement saw the founding of 30 municipalities in the 18th century and 34 in the 19th. Six were founded in the 20th century; the last was Florida in 1971.
Since 1952 Puerto Rico has had three main political parties: the Popular Democratic Party (PPD), the New Progressive Party (PNP) and the Puerto Rican Independence Party (PIP). These three parties stood for three distinct future political status scenarios: the PPD seeks to maintain the island's "association" status with the U.S. as a commonwealth, and has won a plurality vote in referendums on the island's status held over the last six decades, the PNP seeks to have Puerto Rico become a U.S. state, and the PIP seeks the establishment of a sovereign and independent republic. 
In 2007, a fourth party, the Puerto Ricans for Puerto Rico Party (PPR), was registered. The PPR claims that it seeks to address the islands' problems from a status-neutral platform. However, it ceased to remain a registered political party when it failed to obtain the requisite number of votes in the 2008 general election. Non-registered parties include the Puerto Rican Nationalist Party, the Socialist Workers Movement, the Hostosian National Independence Movement.
Political status.
The nature of Puerto Rico's political relationship with the U.S. is the subject of ongoing debate in Puerto Rico, the United States Congress, and the United Nations. Specifically, the basic question is whether Puerto Rico should remain a U.S. territory, become a U.S. state, or become an independent country.
"Estado Libre Asociado".
In 1950, the U.S. Congress granted Puerto Ricans the right to organize a constitutional convention via a referendum that gave them the option of voting their preference, "yes" or "no", on a proposed U.S. law that would organize Puerto Rico as a "commonwealth" that would continue United States sovereignty over Puerto Rico and its people. Puerto Rico's electorate expressed its support for this measure in 1951 with a second referendum to ratify the constitution. The Constitution of Puerto Rico was formally adopted on , 1952. The Constitutional Convention specified the name by which the body politic would be known. 
 "We, the people of Puerto Rico, in order to organise ourselves politically on a fully democratic basis, ...do ordain and establish this Constitution for the commonwealth which, in the exercise of our natural rights, we now create within our union with the United States of America.
 ... We consider as determining factors in our life our citizenship of the United States of America and our aspiration continually to enrich our democratic heritage in the individual and collective enjoyment of its rights and privileges; our loyalty to the principles of the Federal Constitution;..."
While the approval of the Commonwealth constitution by the people of Puerto Rico, the U.S. Congress and the U.S. President, marked a historic change in the civil government of Puerto Rico, neither it nor the public laws approved by Congress in 1950 and 1952 revoked statutory provisions concerning the legal relationship of Puerto Rico to the United States. This relationship is based on the Territorial Clause of the U.S. Constitution. The statutory provisions that set forth the conditions of the relationship are commonly referred to as the Federal Relations Act (FRA). Inclusive by Resolution number 34, approved by the Constitutional Convention and ratified in the Referendum held on November 4, 1952, the following new sentence was added to section 3 of article VII of the commonwealth constitution: "Any amendment or revision of this constitution shall be consistent with the resolution enacted by the applicable provisions of the Constitution of the United States, with the Puerto Rican Federal Relations Act and with Public Law 600, Eighty-first Congress, adopted in the nature of a compact". The provisions of the Federal Relations Act as codified on the U.S. Code Title 48, Chapter 4 shall apply to the island of Puerto Rico and to the adjacent islands belonging to the United States and waters of those islands; and the name Puerto Rico, as used in the chapter, shall be held to include not only the island of that name, but all the adjacent islands as aforesaid. While specified subsections of the FRA were "adopted in the nature of a compact", other provisions, by comparison, are excluded from the compact reference. Matters still subject to congressional authority and established pursuant to legislation include the citizenship status of residents, tax provisions, civil rights, trade and commerce, public finance, the administration of public lands controlled by the federal government, the application of federal law over navigable waters, congressional representation, and the judicial process, among others.
In 1967, Puerto Rico's Legislative Assembly polled the political preferences of the Puerto Rican electorate by passing a plebiscite act that provided for a vote on the status of Puerto Rico. This constituted the first plebiscite by the Legislature for a choice among three status options (commonwealth, statehood, and independence). Claiming "foul play" and dubbing the process as illegitimate and contrary to norms of international law regarding decolonization procedures, the plebiscite was boycotted by the major pro-statehood and pro-independence parties of the time, the Republican Party of Puerto Rico and the Puerto Rican Independence Party, respectively. The Commonwealth option, represented by the PDP, won with a majority of 60.4% of the votes. After the plebiscite, efforts in the 1970s, 1980s, 1990s and 2000s to enact legislation to address the status issue died in U.S. Congressional committees. In subsequent plebiscites organized by Puerto Rico held in 1993 and 1998 (without any formal commitment on the part of the U.S. Government to honor the results), the current political status failed to receive majority support. In 1993, Commonwealth status won by only a plurality of votes (48.6% versus 46.3% for statehood), while the "none of the above" option, which was the Popular Democratic Party-sponsored choice, won in 1998 with 50.3% of the votes (versus 46.5% for statehood). Disputes arose as to the definition of each of the ballot alternatives, and Commonwealth advocates, among others, reportedly urged a vote for "none of the above".
Within the United States.
Constitutionally, Puerto Rico is subject to the Congress's plenary powers under the territorial clause of Article IV, sec. 3, of the U.S. Constitution. U.S. federal law applies to Puerto Rico, even though Puerto Rico is not a state of the American Union and their residents have no voting representation in the U.S. Congress. Like the States of the American Union, Puerto Rico lacks "the full sovereignty of an independent nation," for example, the power to manage its "external relations with other nations," which was retained by the Federal Government. The Supreme Court has indicated that once the Constitution has been extended to an area (by Congress or the Courts), its coverage is irrevocable. To hold that the political branches may switch the Constitution on or off at will would lead to a regime in which they, not this Court, say "what the law is.".
Puerto Ricans "were collectively made U.S. citizens" in 1917 as a result of the Jones-Shafroth Act. However, U.S. citizens residing in Puerto Rico cannot vote for the U.S. president, though both major parties, Republican and Democrat, run primary elections in Puerto Rico to send delegates to vote on a presidential candidate. Since Puerto Rico is an unincorporated territory (see above) and not a U.S. state, the United States Constitution does not fully enfranchise US citizens residing in Puerto Rico.("See also:" "Voting rights in Puerto Rico"). Despite their American citizenship, however, only the "fundamental rights" under the federal constitution apply to Puerto Ricans. Various other U.S Supreme Court decisions have been held opinions on which rights apply in Puerto Rico and which ones do not. Puerto Ricans have a long history of service in the U.S. armed forces and, since 1917, they have been included in the U.S. compulsory draft whenever it has been in effect.
Though the Commonwealth government has its own tax laws, Puerto Ricans are also required to pay most U.S. federal taxes, with the major exception being the federal personal income tax, but only under certain circumstances. In 2009, Puerto Rico paid into the US Treasury. Residents of Puerto Rico pay into Social Security, and are thus eligible for Social Security benefits upon retirement. However, they are excluded from the Supplemental Security Income (SSI), and the island actually receives a small fraction of the Medicaid funding it would receive if it were a U.S. state. Also, Medicare providers receive less-than-full state-like reimbursements for services rendered to beneficiaries in Puerto Rico, even though the latter paid fully into the system.
In 1992, President George H. W. Bush issued a memorandum to heads of executive departments and agencies establishing the current administrative relationship between the federal government and the Commonwealth of Puerto Rico. This memorandum directs all federal departments, agencies, and officials to treat Puerto Rico administratively as if it were a state, insofar as doing so would not disrupt federal programs or operations. Federal executive branch agencies have significant presence in Puerto Rico, just as in any state, including the Federal Bureau of Investigation, Federal Emergency Management Agency, Transportation Security Administration, Social Security Administration, and others. While Puerto Rico has its own Commonwealth judicial system similar to that of a U.S. state, there is also a federal district court in Puerto Rico, and Puerto Rican judges have served in that Court and in other federal courts on the mainland regardless of their residency status at the time of their appointment. Puerto Ricans are also regularly appointed to high-level federal positions, including serving as United States Ambassadors.
International status.
On November 27, 1953, shortly after the establishment of the Commonwealth, the General Assembly of the United Nations approved Resolution 748, removing Puerto Rico's classification as a non-self-governing territory under article 73(e) of the Charter from UN. But the General Assembly did not apply the full list of criteria which was enunciated in 1960 when it took favorable note of the cessation of transmission of information regarding the non-self-governing status of Puerto Rico. According to the White House Task Force on Puerto Rico's Political Status in its , 2007 report, the U.S., in its written submission to the UN in 1953, never represented that Congress could not change its relationship with Puerto Rico without the territory's consent. It stated that the U.S. Justice Department in 1959 reiterated that Congress held power over Puerto Rico pursuant to the Territorial Clause of the U.S. Constitution.
In 1993, the United States Court of Appeals for the Eleventh Circuit stated that Congress may unilaterally repeal the Puerto Rican Constitution or the Puerto Rican Federal Relations Act and replace them with any rules or regulations of its choice. In a 1996 report on a Puerto Rico status political bill, the U.S. House Committee on Resources stated, "Puerto Rico's current status does not meet the criteria for any of the options for full self-government under Resolution 1541" (the three established forms of full self-government being stated in the report as (1) national independence, (2) free association based on separate sovereignty, or (3) full integration with another nation on the basis of equality). The report concluded that Puerto Rico "... remains an unincorporated territory and does not have the status of 'free association' with the United States as that status is defined under United States law or international practice", that the establishment of local self-government with the consent of the people can be unilaterally revoked by the U.S. Congress, and that U.S. Congress can also withdraw the U.S. citizenship of Puerto Rican residents of Puerto Rico at any time, for a legitimate Federal purpose. The application of the U.S. Constitution to Puerto Rico is limited by the Insular Cases.
In 2006, 2007, 2009, 2010, and 2011 the United Nations Special Committee on Decolonization passed resolutions calling on the United States to expedite a process "that would allow Puerto Ricans to fully exercise their inalienable right to self-determination and independence", and to release all Puerto Rican political prisoners in U.S. prisons, to clean up, decontaminate and return the lands in the islands of Vieques and Culebra to the people of Puerto Rico, to perform a probe into U.S. human rights violations on the island and a probe into the killing by the FBI of pro-independence leader Filiberto Ojeda Rios.
Recent developments.
In 2005 and 2007, two reports were issued by the U.S. President's Task Force on Puerto Rico's Status. Both reports conclude that Puerto Rico continues to be a territory of U.S. under the plenary powers of the U.S. Congress. Reactions from Puerto Rico's two major political parties were mixed. The Popular Democratic Party (PPD) challenged the task force's report and committed to validating the current status in all international forums, including the United Nations. It also rejected any "colonial or territorial status" as a status option, and vowed to keep working for the enhanced Commonwealth status that was approved by the PPD in 1998, which included sovereignty, an association based on "respect and dignity between both nations", and common citizenship. The New Progressive Party or New Party for Progress (PNP) supported the White House Report's conclusions and supported bills to provide for a democratic referendum process among Puerto Rico voters.
A 2009 CRS report suggested that action might be taken in the 111th Congress.
The reports issued in 2007 and 2005 by the President's Task Force on Puerto Rico's Status may be the basis for reconsideration of the existing commonwealth status, as legislative developments during the 109th and 110th Congresses suggested. Agreement on the process to be used in considering the status proposals has been as elusive as agreement on the end result. Congress would have a determinative role in any resolution of the issue. The four options that appear to be most frequently discussed include continuation of the commonwealth, modification of the current commonwealth agreement, statehood, or independence. If independence, or separate national sovereignty, were selected, Puerto Rican officials might seek to negotiate a compact of free association with the United States.
On June 15, 2009, the United Nations Special Committee on Decolonization approved a draft resolution calling on the Government of the United States to expedite a process that would allow the Puerto Rican people to exercise fully their inalienable right to self-determination and independence.
On April 29, 2010, the U.S. House voted 223–169 to approve a measure for a federally sanctioned process for Puerto Rico's self-determination, allowing Puerto Rico to set a new referendum on whether to continue its present form of commonwealth political status or to have a different political status. If Puerto Ricans vote to continue to have their present form of political status, the Government of Puerto Rico is authorized to conduct additional plebiscites at intervals of every eight years from the date on which the results of the prior plebiscite are certified; if Puerto Ricans vote to have a different political status, a second referendum would determine whether Puerto Rico would become a U.S. state, an independent country, or a sovereign nation associated with the U.S. that would not be subject to the Territorial Clause of the United States Constitution. During the House debate, a fourth option, to retain its present form of commonwealth (status quo) political status, was added as an option in the second plebiscite.
Immediately following U.S. House passage, H.R. 2499 was sent to the U.S. Senate, where it was given two formal readings and referred to the Senate Committee on Energy and Natural Resources.
A Senate hearing was held on May 19, 2010, for the purpose of gathering testimony on the bill. Among those offering testimony were Resident Commissioner of Puerto Rico, Pedro Pierluisi; Governor of Puerto Rico, Luis Fortuño; President of the Popular Democratic Party of Puerto Rico, Héctor Ferrer; and President of the Puerto Rican Independence Party, Rubén Berríos. According to the Senate Energy & Natural Resources Committee leadership, the four options are the continuation of the current commonwealth status, subject to the territorial clause (under Article IV of the Constitution), statehood, independence, and free association. On December 22, 2010, the 111th United States Congress adjourned without any Senate vote on H.R.2499, killing the bill.
The latest Task Force report was released on March 11, 2011. The report suggests a two-plebiscite process, including a "first plebiscite that requires the people of Puerto Rico to choose whether they wish to be part of the United States (either via Statehood or Commonwealth) or wish to be independent (via Independence or Free Association). If continuing to be part of the United States were chosen in the first plebiscite, a second vote would be taken between Statehood and Commonwealth." 
The United Nations Special Committee on Decolonization passed a resolution and adopted a consensus text introduced by Cuba's delegate on June 20, 2011, calling on the United States to expedite a process "that would allow Puerto Ricans to fully exercise their inalienable right to self-determination and independence." 
In October 2011, Governor Luis Fortuño set August 12, 2012 to hold the first part of a two-step status plebiscite. If a second status vote is required, it will take place on the same day as the general election in November 6, 2012, he added. A bill was brought before the Legislative Assembly of Puerto Rico in 2011 to effect the governor's proposal. The bill passed on December 28, 2011. Rather than hold two referendums for both questions, however, one referendum posing both questions will be held on a single ballot on November 6, 2012, simultaneous with the general elections.
The first referendum will ask voters whether they want to maintain the current status under the territorial clause of the U.S. Constitution or whether they prefer a nonterritorial option. A second question on the same ballot will simultaneously give people three status options: statehood, independence or free association (this last one translated as "Estado Libre Asociado Soberano" or a state of sovereign free association) .
Both President Barack Obama and 2012 Presidential candidate Mitt Romney have promised to support Puerto Rican statehood if that option is chosen by the voters in Puerto Rico.
Geography.
Puerto Rico consists of the main island of Puerto Rico and various smaller islands, including Vieques, Culebra, Mona, Desecheo, and Caja de Muertos. Of these last five, only Culebra and Vieques are inhabited year-round. Mona is uninhabited most of the year except for employees of the Puerto Rico Department of Natural Resources. There are also many other even smaller islands including Monito and "La Isleta de San Juan" which includes Old San Juan and Puerta de Tierra and is connected to the main island by bridges.
The Commonwealth of Puerto Rico has an area of , of which is land and is water. The maximum length of the main island from east to west is , and the maximum width from north to south is . Puerto Rico is the smallest of the Greater Antilles. It is 80% of the size of Jamaica, just over 18% of the size of Hispaniola and 8% of the size of Cuba, the largest of the Greater Antilles.
Puerto Rico is mostly mountainous with large coastal areas in the north and south. The main mountain range is called "La Cordillera Central" (The Central Range). The highest elevation in Puerto Rico, Cerro de Punta , is located in this range. Another important peak is El Yunque, one of the highest in the "Sierra de Luquillo" at the El Yunque National Forest, with an elevation of .
Puerto Rico has 17 lakes, all man-made, and more than 50 rivers, most originating in the Cordillera Central. Rivers in the northern region of the island are typically longer and of higher water flow rates than those of the south, since the south receives less rain than the central and northern regions.
Puerto Rico is composed of Cretaceous to Eocene volcanic and plutonic rocks, overlain by younger Oligocene and more recent carbonates and other sedimentary rocks. Most of the caverns and karst topography on the island occurs in the northern region in the carbonates. The oldest rocks are approximately years old (Jurassic) and are located at Sierra Bermeja in the southwest part of the island. They may represent part of the oceanic crust and are believed to come from the Pacific Ocean realm.
Puerto Rico lies at the boundary between the Caribbean and North American plates and is being deformed by the tectonic stresses caused by their interaction. These stresses may cause earthquakes and tsunamis. These seismic events, along with landslides, represent some of the most dangerous geologic hazards in the island and in the northeastern Caribbean. The most recent major earthquake occurred on , 1918, and had an estimated magnitude of 7.5 on the Richter scale. It originated off the coast of Aguadilla and was accompanied by a tsunami.
The Puerto Rico Trench, the largest and deepest trench in the Atlantic, is located about north of Puerto Rico at the boundary between the Caribbean and North American plates. It is long. At its deepest point, named the Milwaukee Deep, it is almost deep, or about 5.2 miles. 
Located in the tropics, Puerto Rico has an average temperature of throughout the year, with an average minimum temperature of and maximum of . Temperatures do not change drastically throughout the seasons. The temperature in the south is usually a few degrees higher than the north and temperatures in the central interior mountains are always cooler than the rest of the island. The hurricane season spans from June to November. The all-time low in Puerto Rico has been , registered in Aibonito. The average yearly precipitation is 1687mm.
Species endemic to the archipelago are 239 plants, 16 birds and 39 amphibians/reptiles, recognized as of 1998. Most of these (234, 12 and 33 respectively) are found on the main island. The most recognizable endemic species and a symbol of Puerto Rican pride is the "Coquí", a small frog easily identified by the sound of its call, and from which it gets its name. Most "Coquí" species (13 of 17) live in the El Yunque National Forest, a tropical rainforest in the northeast of the island previously known as the Caribbean National Forest. El Yunque is home to more than 240 plants, 26 of which are endemic to the island. It is also home to 50 bird species, including the critically endangered Puerto Rican Amazon. Across the island in the southwest, the of dry land at the Guánica Commonwealth Forest Reserve contain over 600 uncommon species of plants and animals, including 48 endangered species and 16 endemic to Puerto Rico.
Administrative divisions.
As an unincorporated territory of the United States, Puerto Rico does not have any first order administrative divisions as defined by the U.S. Government, but there are 78 municipalities at the secondary level which function as counties. Municipalities are further subdivided into "barrios", and those into sectors. Each municipality has a mayor and a municipal legislature elected for four year terms.
The first municipality (previously called "town") of Puerto Rico, San Juan, was founded in 1521. In the 16th century two more municipalities were established, San Germán (1570) and Coamo (1579). Three more municipalities were established in the 17th century. These were Arecibo (1614), Aguada (1692) and Ponce (1692). The 18th and 19th century saw an increase in settlement in Puerto Rico with 30 municipalities being established in the 18th century and 34 more in the 19th century. Only six municipalities were founded in the 20th century with the last, Florida, being founded in 1971.
Economy.
In the early 20th century the greatest contributor to Puerto Rico's economy was agriculture and its main crop was sugar. In the late 1940s a series of projects codenamed Operation Bootstrap encouraged a significant shift to manufacture via tax exemptions. Manufacturing quickly replaced agriculture as the main industry of the island. Puerto Rico is classified as a "high income country" by the World Bank.
Economic conditions have improved dramatically since the Great Depression because of external investment in capital-intensive industries such as petrochemicals, pharmaceuticals and technology. Once the beneficiary of special tax treatment from the U.S. government, today local industries must compete with those in more economically depressed parts of the world where wages are not subject to U.S. minimum wage legislation. In recent years, some U.S. and foreign owned factories have moved to lower wage countries in Latin America and Asia. Puerto Rico is subject to U.S. trade laws and restrictions.
Also, starting around 1950, there was heavy migration from Puerto Rico to the Continental United States, particularly New York City, in search of better economic conditions. Puerto Rican migration to New York displayed an average yearly migration of 1,800 for the years 1930–1940, 31,000 for 1946–1950, 45,000 for 1951–1960, and a peak of 75,000 in 1953. As of 2003, the U.S. Census Bureau estimates that more people of Puerto Rican birth or ancestry live in the U.S. than in Puerto Rico.
On May 1, 2006, the Puerto Rican government faced significant shortages in cash flows, which forced the closure of the local Department of Education and 42 other government agencies. All 1,536 public schools closed, and 95,762 people were furloughed in the first-ever partial shutdown of the government in the island's history. On , 2006, the budget crisis was resolved with a new tax reform agreement so that all government employees could return to work. On , 2006, a 5.5% sales tax was implemented. Municipalities are required by law to apply a municipal sales tax of 1.5% bringing the total sales tax to 7%.
Tourism is an important component of Puerto Rican economy supplying an approximate . In 1999, an estimated tourists visited the island, most from the U.S. Nearly a third of these are cruise ship passengers. A steady increase in hotel registrations since 1998 and the construction of new hotels and new tourism projects, such as the Puerto Rico Convention Center, indicate the current strength of the tourism industry. In 2009, tourism accounted for nearly 7% of the islands' gross national product.
Puerto Ricans had median household income of $18,314 for 2009, which makes Puerto Rico's economy comparable to the independent nations of Latvia or Poland. By comparison, the poorest state of the Union, Mississippi, had median household income of $36,646 in 2009. Nevertheless, Puerto Rico's GDP per capita compares favorably to other independent Caribbean nations, and is one of the highest in North America. See List of North American countries by GDP per capita.
Puerto Rico's public debt has grown at a faster pace than the growth of its economy, reaching in 2008. In , Luis Fortuño enacted several measures aimed at eliminating the government's deficit, including laying off 12,505 government employees. Puerto Rico's unemployment rate was 15.9 percent in . Some analysts said they expect the government's layoffs to propel that rate to 17 percent.
In November 2010, Gov. Fortuño proposed a tax reform plan that would be implemented in a six-year period, retroactive to , 2010. The first phase, applicable to year 2010, reduces taxes to all individual taxpayers by 7–15%. By year 2016, average relief for individual taxpayers will represent a 50% tax cut and a 30% cut for corporate taxpayers, whose tax rate will be lowered from 41 to 30%.
Businesses and consumers in Puerto Rico are subjected to economic discrimination by many U.S. and multinational companies that limit access to products or offer them at higher prices to businesses and consumers located in Puerto Rico. For example, Apple does not include K-12 or post-secondary educational institutions in their national pricing program offering discounts to teachers and students and special pricing for institutional purchases. Likewise, Minneapolis-based Best Buy does not allow residents of Puerto Rico to purchase goods on their website, which may be purchased from the 50 states, Guam and the United States Virgin Islands, but invites potential customers to skirt their own rules: "Now you can order items online and ship them to a U.S. address* – or pick them up at a U.S. store. International orders may be shipped to street addresses in the U.S., U.S. Virgin Islands and Guam, along with AFO/FPO mailing address."
At the same time, the latest report by the President Task Force on Puerto Rico Status recognizes that the status question and the economy are intimately linked. Many participants in the forums conducted by the Task Force argued that uncertainty about status is holding Puerto Rico back in economic areas. And although there are a number of economic actions that should be taken immediately or in the short term, regardless of the ultimate outcome of the
status question, identifying the most effective means of assisting the Puerto Rican economy depends
on resolving the ultimate question of status. In short, the long-term economic well-being of Puerto Rico would be dramatically improved by an early decision on the status question.
Demographics.
The population of Puerto Rico has been shaped by Amerindian settlement, European colonization, slavery, economic migration, and Puerto Rico's status as unincorporated territory of the United States.
Population and racial makeup.
The United States Census Bureau estimates that the population of Puerto Rico was 3,706,690 on July 1, 2011, a 0.51% decrease since the 2010 United States Census. 
Racial distribution
During the 19th century hundreds of Corsican, French, Lebanese, Chinese, and Portuguese families arrived in Puerto Rico, along with large numbers of immigrants from Spain (mainly from Catalonia, Asturias, Galicia, the Balearic Islands, Andalusia, and the Canary Islands) and numerous Spanish loyalists from Spain's former colonies in South America. Other settlers included Irish, Scots, Germans, Italians and thousands others who were granted land by Spain during the "Real Cedula de Gracias de 1815" ("Royal Decree of Graces of 1815"), which allowed European Catholics to settle in the island with land allotments in the interior of the island, provided they agreed to pay taxes and continue to support the Catholic Church.
Between 1960 and 1990 the census questionnaire in Puerto Rico did not ask about race or color. However, the 2000 United States Census included a racial self-identification question in Puerto Rico. According to the census, most Puerto Ricans self-identified as White and few declared themselves to be Black or some other race. A recent study conducted in Puerto Rico suggests that around 52.6% of the population possess Amerindian mtDNA.
Immigration and emigration.
Puerto Rico has recently become the permanent home of over 100,000 legal residents who immigrated from not only the Dominican Republic, but from other Latin American countries. These include Cuba, Colombia, and Venezuela, as well as surrounding Caribbean islands, Haiti, Barbados, and the U.S. Virgin Islands among them.
Emigration is a major part of contemporary Puerto Rican history. Starting soon after World War II, poverty, cheap airfare, and promotion by the island government caused waves of Puerto Ricans to move to the United States, particularly to New York, New Jersey, Massachusetts, and Florida. This trend continued even as Puerto Rico's economy improved and its birth rate declined, and Puerto Ricans continue to follow a pattern of "circular migration".
Distribution.
The most populous city is the capital, San Juan, with approximately 395,326 people. Other major cities include Bayamón, Carolina, Ponce, and Caguas. Of the ten most populous cities on the island, eight are located within what is considered San Juan's metropolitan area, while the other two are located in the south (Ponce) and west (Mayagüez) of the island.

Languages.
The official languages are Spanish and English with Spanish being the primary language. English is taught as a second language in public and private schools from elementary levels to high school and at the university level.
Spanish.
The Spanish of Puerto Rico has evolved into having many idiosyncrasies in vocabulary and syntax that differentiate it from the Spanish spoken elsewhere. While the Spanish spoken in all Iberian, Mediterranean and Atlantic Spanish Maritime Provinces was brought to the island over the centuries, the most profound regional impact on the Spanish spoken in Puerto Rico has been from that spoken in present-day Canary Islands.
As a result of the natural inclusion of indigenous vocabulary in all New World former European colonies (English, French, Spanish, Dutch, etc.), the Spanish of Puerto Rico also includes occasional Taíno words, typically in the context of vegetation, natural phenomenon or primitive musical instruments. Similarly, African-attributed words exist in the contexts of foods, music or dances, developed in coastal towns with concentrations of descendants of former Sub-Saharan slaves.
English.
According to a study by the University of Puerto Rico, nine of every ten Puerto Ricans residing in Puerto Rico do not speak English at an advanced level. More recently, according to the "2005–2009 Population and Housing Narrative Profile for Puerto Rico", among people at least five years old living in Puerto Rico in 2005–2009, 95 percent spoke a language other than English at home. Of those speaking a language other than English at home, 100 percent spoke Spanish and less than 0.5 percent spoke some other language; 85 percent reported that they did not speak English "very well."
Religion.
The Roman Catholic Church has historically been the dominant religion in Puerto Rico. The first dioceses in the Americas, including the first diocese of Puerto Rico, were authorized by Pope Julius II in 1511. One Pope, John Paul II, visited Puerto Rico in October 1984. All municipalities in Puerto Rico have at least one Catholic church, most of which are located at the town center or ""plaza"".
Protestantism, which was suppressed under the Spanish regime, has spread under American rule, making modern Puerto Rico interconfessional. The first Protestant church, Holy Trinity Church in Ponce, was established by the Anglican diocese of Antigua in 1872. In 1872, German settlers in Ponce founded the Iglesia Santísima Trinidad, an Anglican Church, the first non-Roman Catholic Church in the entire Spanish Empire in the Americas.
There is also an Eastern Orthodox community in Puerto Rico, The Dormition of the Most Holy Theotokos/ St. Spyridon's Church is located in Trujillo Alto, and serves the small Orthodox community. The congregation represents Greeks, Russians, Serbians, Bulgarians, Americans, Moldavians, and Puerto Ricans.
In 1940, Juanita Garcia Peraza founded the Mita Congregation, the first religion of Puerto Rican origin. Taíno religious practices have been rediscovered/reinvented to a degree by a handful of advocates. Various African religious practices have been present since the arrival of African slaves. In particular, the Yoruba beliefs of Santería and/or Ifá, and the Kongo-derived Palo Mayombe find adherence among a few individuals who practice some form of African traditional religion.
In 1952, a handful of American Jews established the island's first synagogue in the former residence of William Korber, a wealthy Puerto Rican of German descent, which was designed and built by Czech architect Antonin Nechodoma. The synagogue, called Sha'are Zedeck, hired its first rabbi in 1954. Puerto Rico now is home to the largest Jewish community in the Caribbean, numbering 3,000, and is the only Caribbean island in which the Conservative, Reform and Orthodox Jewish movements all are represented.
In 2007, there were about 5,000 Muslims in Puerto Rico, representing about 0.13% of the population There were eight mosques spread throughout the island, with most Muslims living in Rio Piedras.
In 2011, there were 26,546 Jehovah's Witnesses, representing about 0.72% of the population, with 329 congregations.
The Padmasambhava Buddhist Center, whose followers practice Tibetan Buddhism, has a branch in Puerto Rico.
Iglesia Santísima Trinidad of Ponce
File:IMG 3392 - Centro Islamico de Ponce, PR.jpg|Islamic Center at Ponce
File:Shaare Zedeck.jpg|Inside Sha'are Zedeck in San Juan

Culture.
Modern Puerto Rican culture is a unique mix of cultural antecedents, including African, Taíno (Amerindians), Spanish, and more recently, North American.
From the Spanish Puerto Rico received the Spanish language, the Catholic religion and the vast majority of their cultural and moral values and traditions. The United States added English language influence, the university system and the adoption of some holidays and practices. On 1903, the University of Puerto Rico was officially founded, branching out from the "Escuela Normal Industrial", a smaller organism that was founded in Fajardo three years before.
Much of Puerto Rican culture centers on the influence of music. Like the country as a whole, Puerto Rican music has been developed by mixing other cultures with local and traditional rhythms. Early in the history of Puerto Rican music, the influences of African and Spanish traditions were most noticeable. However, the cultural movements across the Caribbean and North America have played a vital role in the more recent musical influences that have reached Puerto Rico.
The official symbols of Puerto Rico are the "Reinita mora" or Puerto Rican Spindalis (a type of bird), the "Flor de Maga" (a type of flower), and the "Ceiba" or Kapok (a type of tree). The unofficial animal and a symbol of Puerto Rican pride is the Coquí, a small frog. Other popular symbols of Puerto Rico are the "jíbaro", the "countryman", and the carite.
Sports.
Baseball was one of the first sports to gain widespread popularity in Puerto Rico. The Puerto Rico Baseball League serves as the only active professional league, operating as a winter league. No Major League Baseball franchise or affiliate plays in Puerto Rico, however, San Juan hosted the Montreal Expos for several series in 2003 and 2004 before they moved to Washington, D.C. and became the Washington Nationals. The Puerto Rico national baseball team has participated in the World Cup of Baseball winning one gold (1951), four silver and four bronze medals and the Caribbean Series, winning fourteen times. Famous Puerto Rican baseball players include Roberto Clemente and Orlando Cepeda and Roberto Alomar, enshrined in the Baseball Hall of Fame in 1973, 1999, and 2011 respectively.
Boxing, basketball, and volleyball are considered popular sports as well. Wilfredo Gómez and McWilliams Arroyo have won their respective divisions at the World Amateur Boxing Championships. Other medalists include José Pedraza, who holds a silver medal, as well as three boxers that finished in third place, José Luis Vellón, Nelson Dieppa and McJoe Arroyo. In the professional circuit, Puerto Rico has the third-most boxing world champions and its the global leader in champions per capita. These include Miguel Cotto, Félix Trinidad, Wilfred Benítez and Gómez among others. The Puerto Rico national basketball team joined the International Basketball Federation in 1957. Since then, it has won more than 30 medals in international competitions, including gold in three FIBA Americas Championships and the 1994 Goodwill Games. , 2004, became a landmark date for the team when it became the first team to defeat the United States in an Olympic tournament since the integration of National Basketball Association players. Winning the inaugural game with scores of 92–73 as part of the 2004 Summer Olympics organized in Athens, Greece. Baloncesto Superior Nacional acts as the top-level professional basketball league in Puerto Rico, and has experienced success since its beginning in 1930.
Miscellaneous practices of this sport have experienced some success, including the "Puerto Rico All Stars" team, which has won twelve world championships in unicycle basketball. Organized Streetball has gathered some exposition, with teams like "Puerto Rico Street Ball" competing against established organizations including the Capitanes de Arecibo and AND1's Mixtape Tour Team. Six years after the first visit, AND1 returned as part of their renamed Live Tour, losing to the Puerto Rico Streetballers. Consequently, practitioners of this style have earned participation in international teams, including Orlando "El Gato" Meléndez, who became the first Puerto Rican born athlete to play for the Harlem Globetrotters. Orlando Antigua, whose mother is Puerto Rican, made history in 1995, when he became the first Hispanic and the first non-black in 52 years to play for the Harlem Globetrotters.
The Puerto Rico Islanders Football Club, founded in 2003, plays in the United Soccer Leagues First Division, which constitutes the second tier of football in North America. Puerto Rico is also a member of FIFA and CONCACAF. In 2008 the archipelago's first unified league, the Puerto Rico Soccer League, was established. Secondary sports include Professional wrestling and road running. The World Wrestling Council and International Wrestling Association are the largest wrestling promotions in the main island. The World's Best 10K, held annually in San Juan, has been ranked among the 20 most competitive races globally.
Puerto Rico has representation in all international competitions including the Summer and Winter Olympics, the Pan American Games, the Caribbean World Series, and the Central American and Caribbean Games. Puerto Rican athletes have won seven medals (two silver, five bronze) in Olympic competition, the first one in 1948 by boxer Juan Evangelista Venegas. On San Juan's Hiram Bithorn Stadium hosted the opening round as well as the second round of the newly formed World Baseball Classic. The Central American and Caribbean Games were held in 1993 in Ponce and in 2010 in Mayagüez.
Education.
The first school in Puerto Rico and the first school in the United States after Puerto Rico became a US territory, was the Escuela de Gramatica (Grammer School). The school was established by Bishop Alonso Manso in 1513, in the area where the Cathedral of San Juan was to be constructed. The school was free of charge and the courses taught were Latin language, literature, history, science, art, philosophy and theology.
Education in Puerto Rico is divided in three levels—Primary (elementary school grades 1–6), Secondary (intermediate and high school grades 7–12), and Higher Level (undergraduate and graduate studies). As of 2002, the literacy rate of the Puerto Rican population was 94.1%; by gender, it was 93.9% for males and 94.4% for females. According to the 2000 Census, 60.0% of the population attained a high school degree or higher level of education, and 18.3% has a bachelor's degree or higher.
Instruction at the primary school level is compulsory between the ages of 5 and 18 and is enforced by the state. The Constitution of Puerto Rico grants the right to an education to every citizen on the island. To this end, public schools in Puerto Rico provide free and non-sectarian education at the elementary and secondary levels. At any of the three levels, students may attend either public or private schools. As of 1999, there were 1532 public schools and 569 private schools in the island.
The largest and oldest university system in Puerto Rico is the public University of Puerto Rico (UPR) with 11 campuses. The largest private university systems on the island are the Sistema Universitario Ana G. Mendez which operates the Universidad del Turabo, Metropolitan University and Universidad del Este, the multi-campus Inter American University, the Pontifical Catholic University, and the Universidad del Sagrado Corazón. Puerto Rico has four schools of Medicine and four Law Schools.
Transportation.
Cities and towns in Puerto Rico are interconnected by a system of roads, freeways, expressways, and highways maintained by the Highways and Transportation Authority under the jurisdiction of the U.S. Department of Transportation, and patrolled by the Puerto Rico Police Department. The island's metropolitan area is served by a public bus transit system and a metro system called "Tren Urbano" (in English: Urban Train). Other forms of public transportation include seaborne ferries (that serve Puerto Rico's archipelago) as well as "Carros Públicos" (private mini buses).
The island has three international airports, the Luis Muñoz Marín International Airport in Carolina, Mercedita Airport in Ponce, and the Rafael Hernández Airport in Aguadilla, and 27 local airports. The Luis Muñoz Marín International Airport is the largest aerial transportation hub in the Caribbean, and one of the largest in the world in terms of passenger and cargo movement.
Puerto Rico has 9 ports in different cities across the main island. The San Juan Port is the largest in Puerto Rico, and the busiest port in the Caribbean and the 10th busiest in the United States in terms of commercial activity and cargo movement, respectively. The second largest port is the Port of the Americas in Ponce, currently under expansion to increase cargo capacity to twenty-foot containers (TEUs) per year.

Battle of the Alamo
The Battle of the Alamo (February 23 – March 6, 1836) was a pivotal event in the Texas Revolution. Following a 13-day siege, Mexican troops under President General Antonio López de Santa Anna launched an assault on the Alamo Mission near San Antonio de Béxar (modern-day San Antonio, Texas, USA). All but two of the Texian defenders were killed. Santa Anna's perceived cruelty during the battle inspired many Texians—both Texas settlers and adventurers from the United States—to join the Texian Army. Buoyed by a desire for revenge, the Texians defeated the Mexican Army at the Battle of San Jacinto, on April 21, 1836, ending the revolution.
Several months previously, Texians had driven all Mexican troops out of Mexican Texas. Approximately 100 Texians were then garrisoned at the Alamo. The Texian force grew slightly with the arrival of reinforcements led by eventual Alamo co-commanders James Bowie and William B. Travis. On February 23, approximately 1,500 Mexican troops marched into San Antonio de Béxar as the first step in a campaign to re-take Texas. For the next 12 days the two armies engaged in several skirmishes with minimal casualties. Aware that his garrison could not withstand an attack by such a large force, Travis wrote multiple letters pleading for more men and supplies, but fewer than 100 reinforcements arrived.
In the early morning hours of March 6, the Mexican Army advanced on the Alamo. After repulsing two attacks, Texians were unable to fend off a third attack. As Mexican soldiers scaled the walls, most of the Texian soldiers withdrew into interior buildings. Defenders unable to reach these points were slain by the Mexican cavalry as they attempted to escape. Between five and seven Texians may have surrendered; if so, they were quickly executed. Most eyewitness accounts reported between 182 and 257 Texians dead, while most historians of the Alamo agree that 400–600 Mexicans were killed or wounded. Several noncombatants were sent to Gonzales to spread word of the Texian defeat. The news sparked a panic, known as "The Runaway Scrape", in which the Texian army, most settlers, and the new Republic of Texas government fled from the advancing Mexican Army.
Within Mexico, the battle has often been overshadowed by events from the Mexican–American War of 1846–48. In 19th-century Texas, the Alamo complex gradually became known as a battle site rather than a former mission. The Texas Legislature purchased the land and buildings in the early part of the 20th century and designated the Alamo chapel as an official Texas State Shrine. The Alamo is now "the most popular tourist site in Texas". The Alamo has been the subject of numerous non-fiction works beginning in 1843. Most Americans, however, are more familiar with the myths spread by many of the movie and television adaptations, including the 1950s Disney miniseries "Davy Crockett" and John Wayne's 1960 film "The Alamo".
Background.
Under President Antonio López de Santa Anna, the Mexican government began to shift away from a federalist model. The increasingly dictatorial policies, including the revocation of the Constitution of 1824 in early 1835, incited many federalists to revolt. The Mexican border region of Texas was largely populated by immigrants from the United States. These were accustomed to a federalist government and to extensive individual rights, and they were quite vocal in their displeasure at Mexico's shift towards centralism. Already leery of previous American attempts to purchase Texas, Mexican authorities blamed much of the Texian unrest on American immigrants, most of whom had made little effort to adapt to the Mexican culture.
In October, Texians engaged Mexican troops in the first official battle of the Texas Revolution. Determined to quash the rebellion, Santa Anna began assembling a large force, the Army of Operations in Texas, to restore order. Most of his soldiers were raw recruits, and a large number had been forcibly conscripted.
The Texians systematically defeated the Mexican troops already stationed in Texas. The last group of Mexican soldiers in the region—commanded by Santa Anna's brother-in-law, General Martín Perfecto de Cos—surrendered on December 9 following the siege of Béxar. By this point, the Texian Army was dominated by very recent arrivals to the region, primarily adventurers from the United States. Many Texas settlers, unprepared for a long campaign, had returned home. Angered by what he perceived to be American interference in Mexican affairs, Santa Anna a resolution classifying foreigners found fighting in Texas as pirates. The resolution effectively banned the taking of prisoners of war: in this period of time, captured pirates were executed immediately. Santa Anna reiterated this message in a strongly worded letter to United States President Andrew Jackson. This letter was not widely distributed, and it is unlikely that most of the American recruits serving in the Texian Army were aware that there would be no prisoners of war.
When Mexican troops departed San Antonio de Béxar (now San Antonio, Texas, USA) Texian soldiers established a garrison at the Alamo Mission, a former Spanish religious outpost which had been converted to a makeshift fort. Described by Santa Anna as an "irregular fortification hardly worthy of the name", the Alamo had been designed to withstand an attack by native tribes, not an artillery-equipped army. The complex sprawled across , providing almost of perimeter to defend. An interior plaza was bordered on the east by the chapel and to the south by a one-story building known as the Low Barracks. A wooden palisade stretched between these two buildings. The two-story Long Barracks extended north from the chapel. At the northern corner of the east wall stood a cattle pen and horse corral. The walls surrounding the complex were at least thick and ranged from high.
To compensate for the lack of firing ports, Texian engineer Green B. Jameson constructed catwalks to allow defenders to fire over the walls; this method, however, left the rifleman's upper body exposed. Mexican forces had left behind 19 cannons, which Jameson installed along the walls. A large 18-pounder had arrived in Texas with the New Orleans Greys. Jameson positioned this cannon in the southwest corner of the compound. He boasted to Texian Army commander Sam Houston that the Texians could "whip 10 to 1 with our artillery".
The Texian garrison was woefully under-manned and under-provisioned, with fewer than 100 soldiers remaining by January 6, 1836. Colonel James C. Neill, the acting Alamo commander, wrote to the provisional government: "If there has ever been a dollar here I have no knowledge of it". Neill requested additional troops and supplies, stressing that the garrison was likely to be unable to withstand a siege lasting longer than four days. The Texian government was in turmoil and unable to provide much assistance. Four different men claimed to have been given command over the entire army: on January 14, Neill approached one of them, Sam Houston, for assistance in gathering supplies, clothing, and ammunition.
Prelude to battle.
Houston could not spare the number of men necessary to mount a successful defense. Instead, he sent Colonel James Bowie with 30 men to remove the artillery from the Alamo and destroy the complex. Bowie was unable to transport the artillery since the Alamo garrison lacked the necessary draft animals. Neill soon persuaded Bowie that the location held strategic importance. In a letter to Governor Henry Smith, Bowie argued that "the salvation of Texas depends in great measure on keeping Béxar out of the hands of the enemy. It serves as the frontier picquet guard, and if it were in the possession of Santa Anna, there is no stronghold from which to repel him in his march toward the Sabine." The letter to Smith ended, "Colonel Neill and myself have come to the solemn resolution that we will rather die in these ditches than give it up to the enemy." Bowie also wrote to the provisional government, asking for "men, money, rifles, and cannon powder". Few reinforcements were authorized; cavalry officer William B. Travis arrived in Béxar with 30 men on February 3. Five days later, a small group of volunteers arrived, including the famous frontiersman and former U.S. Congressman Davy Crockett of Tennessee.
On February 11, Neill left the Alamo, likely to recruit additional reinforcements and gather supplies. He transferred command to Travis, the highest-ranking regular army officer in the garrison. Volunteers comprised much of the garrison, and they were unwilling to accept Travis as their leader. The men instead elected Bowie, who had a reputation as a fierce fighter, as their commander. Bowie celebrated by getting very intoxicated and creating havoc in Béxar. To mitigate the resulting ill feelings, Bowie agreed to share command with Travis.
As the Texians struggled to find men and supplies, Santa Anna continued to gather men at San Luis Potosi; by the end of 1835 his army numbered 6,019 soldiers. Rather than advance along the coast, where supplies and reinforcements could be easily delivered by sea, Santa Anna ordered his army inland to Béxar, the political center of Texas and the site of Cos's defeat. The army began its march north in late December. Officers used the long journey to train the men. Many of the new recruits did not know how to use the sights of their guns, and many refused to fire from the shoulder because of the large recoil.
Progress was slow. There were not enough mules to transport all of the supplies, and many of the teamsters, all civilians, quit when their pay was delayed. The large number of "soldaderas"–women and children who followed the army–consumed the already scarce supplies. The soldiers were soon reduced to partial rations. On February 12 they crossed the Rio Grande. Temperatures in Texas reached record lows, and by February 13 an estimated of snow had fallen. Hypothermia, dysentery, and Comanche raiding parties took a heavy toll on the Mexican soldiers.
On February 21, Santa Anna and his vanguard reached the banks of the Medina River, from Béxar. Unaware of the Mexican Army's proximity, the majority of the Alamo garrison joined Béxar residents at a . After learning of the planned celebration, Santa Anna ordered General Joaquín Ramírez y Sesma to immediately seize the unprotected Alamo, but sudden rains halted that raid.
Siege.
Investment.
In the early hours of February 23, residents began fleeing Béxar, fearing the Mexican army's imminent arrival. Although unconvinced by the reports, Travis stationed a soldier in the San Fernando church bell tower—the highest location in town—to watch for signs of an approaching force. Several hours later, Texian scouts reported seeing Mexican troops outside the town. Few arrangements had been made for a potential siege. One group of Texians scrambled to herd cattle into the Alamo, while others scrounged for food in the recently abandoned houses. Several members of the garrison who had been living in town brought their families with them when they reported to the Alamo. Among these were Almaron Dickinson, who brought his wife Susanna and their infant daughter Angelina; Bowie, who was accompanied by his deceased wife's cousins, Gertrudis Navarro and Juana Navarro Alsbury, and Alsbury's young son; and Gregorio Esparza, whose family climbed through the window of the Alamo chapel after the Mexican army arrived. Other members of the garrison failed to report for duty; most of the men working outside Béxar did not try to sneak past Mexican lines.
By late afternoon Béxar was occupied by about 1,500 Mexican troops. When the Mexican troops raised a blood-red flag signifying no quarter, Travis responded with a blast from the Alamo's largest cannon. Believing that Travis had acted hastily, Bowie sent Jameson to meet with Santa Anna. Travis was angered that Bowie had acted unilaterally and sent his own representative, Captain Albert Martin. Both emissaries met with Colonel Juan Almonte and José Bartres. According to Almonte, the Texians asked for an honorable surrender but were informed that any surrender must be unconditional. On learning this, Bowie and Travis mutually agreed to fire the cannon again.
Skirmishes.
The first night of the siege was relatively quiet. Over the next few days, Mexican soldiers established artillery batteries, initially about from the south and east walls of the Alamo. A third battery was positioned southeast of the fort. Each night the batteries inched closer to the Alamo walls. During the first week of the siege more than 200 cannonballs landed in the Alamo plaza. At first the Texians matched Mexican artillery fire, often reusing the Mexican cannonballs. On February 26 Travis ordered the artillery to conserve powder and shot.
Two notable events occurred on Wednesday, February 24. At some point that day, Bowie collapsed from illness, leaving Travis in sole command of the garrison. Late that afternoon, a Mexican scout became the first fatality of the siege. The following morning, 200–300 Mexican soldiers crossed the San Antonio River and took cover in abandoned shacks near the Alamo walls. Several Texians ventured out to burn the huts while Texians within the Alamo provided cover fire. After a two-hour skirmish the Mexican troops retreated to Béxar. Two Mexican soldiers were killed and four wounded. No Texians were injured.
A blue norther blew in on February 25, dropping the temperature to . Neither army was prepared for the cold temperatures. Texian attempts to gather firewood were thwarted by Mexican troops. On the evening of February 26 Colonel Juan Bringas engaged several Texians who were burning more huts. According to historian J.R. Edmondson, one Texian was killed.
Reinforcements.
Santa Anna posted one company east of the Alamo, on the road to Gonzales. Almonte and 800 dragoons were stationed along the road to Goliad. Throughout the siege these towns had received multiple couriers, dispatched by Travis to plead for reinforcements and supplies. The most famous of his missives, written February 24, was addressed To the People of Texas & All Americans in the World. According to historian Mary Deborah Petite, the letter is "considered by many as one of the masterpieces of American patriotism". Copies of the letter were distributed across Texas, and eventually reprinted throughout the United States and much of Europe. At the end of the first day of the siege, Santa Anna's troops were reinforced by 600 men under General Joaquin Ramirez y Sesma, bringing the Mexican army up to more than 2,000 men.
As news of the siege spread throughout Texas, potential reinforcements gathered in Gonzales. They hoped to rendezvous with Colonel James Fannin, who was expected to arrive from Goliad with his garrison. On February 26, after days of indecision, Fannin ordered 320 men, four cannon, and several supply wagons to march toward the Alamo, away. This group traveled less than before turning back. Fannin blamed the retreat on his officers; the officers and enlisted men accused Fannin of aborting the mission.
Texians gathered in Gonzales were unaware of Fannin's return to Goliad, and most continued to wait. Impatient with the delay, on February 27 Travis ordered Samuel G. Bastian to go to Gonzales "to hurry up reinforcements". According to historian Thomas Ricks Lindley, Bastian encountered the Gonzales Ranging Company led by Lieutenant George C. Kimble and Travis' courier to Gonzales, Albert Martin, who had tired of waiting for Fannin. A Mexican patrol attacked, driving off four of the men, including Bastian. In the darkness, the Texians fired on the remaining 32 men, whom they assumed were Mexican soldiers. One man was wounded, and his English curses convinced the defenders to open the gates.
On March 3, the Texians watched from the walls as approximately 1,000 Mexican troops marched into Béxar. The Mexican army celebrated loudly throughout the afternoon, both in honor of their reinforcements and at the news that troops under General José de Urrea had soundly defeated Texian Colonel Frank W. Johnson at the Battle of San Patricio on February 27. Most of the Texians in the Alamo believed that Sesma had been leading the Mexican forces during the siege, and they mistakenly attributed the celebration to the arrival of Santa Anna. The reinforcements brought the number of Mexican soldiers in Béxar to almost 3,100.
The arrival of the Mexican reinforcements prompted Travis to send three men, including Davy Crockett, to find Fannin's force, which he still believed to be en route. The scouts discovered a large group of Texians camped from the Alamo. Lindley's research indicates that up to 50 of these men had come from Goliad after Fannin's aborted rescue mission. The others had left Gonzales several days earlier. Just before daylight on March 4, part of the Texian force broke through Mexican lines and entered the Alamo. Mexican soldiers drove a second group across the prairie.
Assault preparations.
On March 4, the day after his reinforcements arrived, Santa Anna proposed an assault on the Alamo. Many of his senior officers recommended that they wait for two 12-pounder cannons anticipated to arrive on March 7. That evening, a local woman, likely Bowie's cousin-in-law Juana Navarro Alsbury, approached Santa Anna to negotiate a surrender for the Alamo defenders. According to many historians, this visit probably increased Santa Anna's impatience; as historian Timothy Todish noted, "there would have been little glory in a bloodless victory". The following morning, Santa Anna announced to his staff that the assault would take place early on March 6. Santa Anna arranged for troops from Béxar to be excused from the front lines, so that they would not be forced to fight their own families.
Legend holds that at some point on March 5, Travis gathered his men and explained that an attack was imminent, and that the Mexican Army would prevail. He supposedly drew a line in the ground and asked those willing to die for the Texian cause to cross and stand alongside him; only one man (Moses Rose) was said to have declined. Most scholars disregard this tale as there is no primary source evidence to support it (the story only surfaced decades after the battle in a third-hand account). However, Travis apparently did, at some point prior to the final assault, assemble the men for a conference to inform them of the dire situation and giving them the chance to either escape or stay and die for the cause. Susannah Dickinson recalled Travis announcing that any men who wished to escape should let it be known and step out of ranks.
The last Texian verified to have left the Alamo was James Allen, a courier who carried personal messages from Travis and several of the other men on March 5.
Final assault.
Exterior fighting.
At 10 p.m. on March 5, the Mexican artillery ceased their bombardment. As Santa Anna had anticipated, the exhausted Texians soon fell into the first uninterrupted sleep many had gotten since the siege began. Just after midnight Mexican troops began preparing for the final assault. The troops were divided into four columns, commanded by Cos, Colonel Francisco Duque, Colonel José María Romero and Colonel Juan Morales. Veterans were positioned on the outside of the columns to better control the new recruits and conscripts in the middle. As a precaution, 500 Mexican cavalry were positioned around the Alamo to prevent escape of either Texian or Mexican soldiers. Santa Anna remained in camp with the 400 reserves. Despite the bitter cold, the soldiers were ordered not to wear overcoats, which could impede their movements. Clouds concealed the moon, and thus the movements of the soldiers.
At 5:30 a.m. troops silently advanced. Cos and his men approached the northwest corner of the Alamo, while Duque led his men from the northwest toward a repaired breach in the Alamo's north wall. The column commanded by Romero marched towards the east wall, and Morales's column aimed for the low parapet by the chapel.
The three Texian sentinels stationed outside the walls were killed in their sleep, allowing Mexican soldiers to approach undetected within musket range of the walls. At this point, the silence was broken by shouts of ""¡Viva Santa Anna!"" and music from the buglers. The noise woke the Texians. Most of the noncombatants gathered in the church sacristy for safety. Travis rushed to his post yelling, "Come on boys, the Mexicans are upon us and we'll give them hell!" and, as he passed a group of Tejanos, ""¡No rendirse, muchachos!"" ("No surrender, boys").
In the initial moments of the assault Mexican troops were at a disadvantage. Their column formation allowed only the front rows of soldiers to fire safely. Unaware of the dangers, the untrained recruits in the ranks "blindly fir their guns", injuring or killing the troops in front of them. The tight concentration of troops also offered an excellent target for the Texian artillery. Lacking canister shot, Texians filled their cannon with any metal they could find, including door hinges, nails, and chopped-up horseshoes, essentially turning the cannon into giant shotguns. According to the diary of José Enrique de la Peña, "a single cannon volley did away with half the company of chasseurs from Toluca". Duque fell from his horse after suffering a wound in his thigh and was almost trampled by his own men. General Manuel Castrillón quickly assumed command of Duque's column.
Although some in the front of the Mexican ranks wavered, soldiers in the rear pushed them on. As the troops massed against the walls, Texians were forced to lean over the walls to shoot, leaving them exposed to Mexican fire. Travis became one of the first defenders to die, shot while firing his shotgun into the soldiers below him. Few of the Mexican ladders reached the walls. The few soldiers who were able to climb the ladders were quickly killed or beaten back. As the Texians discharged their previously loaded rifles, however, they found it increasingly difficult to reload while attempting to keep Mexican soldiers from scaling the walls.
Mexican soldiers withdrew and regrouped, but their second attack was repulsed. Fifteen minutes into the battle, they attacked a third time. During the third strike, Romero's column, aiming for the east wall, was exposed to cannon fire and shifted to the north, mingling with the second column. Cos's column, under fire from Texians on the west wall, also veered north. When Santa Anna saw that the bulk of his army was massed against the north wall, he feared a rout; "panicked", he sent the reserves into the same area. The Mexican soldiers closest to the north wall realized that the makeshift wall contained many gaps and toeholds. One of the first to scale the 12-foot (3.7 m) wall was General Juan Amador; at his challenge, his men began swarming up the wall. Amador opened the postern in the north wall, allowing Mexican soldiers to pour into the complex. Others climbed through gun ports in the west wall, which had few defenders. As the Texian defenders abandoned the north wall and the northern end of the west wall, Texian gunners at the south end of the mission turned their cannon toward the north and fired into the advancing Mexican soldiers. This left the south end of the mission unprotected; within minutes Mexican soldiers had climbed the walls and killed the gunners, gaining control of the Alamo's 18-pounder cannon. By this time Romero's men had taken the east wall of the compound and were pouring in through the cattle pen.
Interior fighting.
As previously planned, most of the Texians fell back to the barracks and the chapel. Holes had been carved in the walls to allow the Texians to fire. Unable to reach the barracks, Texians stationed along the west wall headed west for the San Antonio River. When the cavalry charged, the Texians took cover and began firing from a ditch. Sesma was forced to send reinforcements, and the Texians were eventually killed. Sesma reported that this skirmish involved 50 Texians, but Edmondson believes that number was inflated.
The defenders in the cattle pen retreated into the horse corral. After discharging their weapons, the small band of Texians scrambled over the low wall, circled behind the church and raced on foot for the east prairie, which appeared empty. As the Mexican cavalry advanced on the group, Almaron Dickinson and his artillery crew turned a cannon around and fired into the cavalry, probably inflicting casualties. Nevertheless, all of the escaping Texians were killed.
The last Texian group to remain in the open were Crockett and his men, defending the low wall in front of the church. Unable to reload, they used their rifles as clubs and fought with knives. After a volley of fire and a wave of Mexican bayonets, the few remaining Texians in this group fell back toward the church. The Mexican army now controlled all of the outer walls and the interior of the Alamo compound except for the church and rooms along the east and west walls. Mexican soldiers turned their attention to a Texian flag waving from the roof of one building. Four Mexicans were killed before the flag of Mexico was raised in that location.
For the next hour, the Mexican army worked to secure complete control of the Alamo. Many of the remaining defenders were ensconced in the fortified barracks rooms. In the confusion, the Texians had neglected to their cannon before retreating. Mexican soldiers turned the cannon toward the barracks. As each door was blown off Mexican soldiers would fire a volley of muskets into the dark room, then charge in for hand-to-hand combat.
Too sick to participate in the battle, Bowie likely died in bed. Eyewitnesses to the battle gave conflicting accounts of his death. Some witnesses maintained that they saw several Mexican soldiers enter Bowie's room, bayonet him, and carry him alive from the room. Others claimed that Bowie shot himself or was killed by soldiers while too weak to lift his head. According to historian Wallace Chariton, the "most popular, and probably the most accurate" version is that Bowie died on his cot, "back braced against the wall, and using his pistols and his famous knife."
The last of the Texians to die were the 11 men manning the two 12-pounder cannon in the chapel. A shot from the 18-pounder cannon destroyed the barricades at the front of the church, and Mexican soldiers entered the building after firing an initial musket volley. Dickinson's crew fired their cannon from the apse into the Mexican soldiers at the door. With no time to reload, the Texians, including Dickinson, Gregorio Esparza and James Bonham, grabbed rifles and fired before being bayoneted to death. Texian Robert Evans, the master of ordnance, had been tasked with keeping the gunpowder from falling into Mexican hands. Wounded, he crawled toward the powder magazine but was killed by a musket ball with his torch only inches from the powder. Had he succeeded, the blast would have destroyed the church and killed the women and children hiding in the sacristy.
As soldiers approached the sacristy, one of the young sons of defender Anthony Wolf stood to pull a blanket over his shoulders. In the dark, Mexican soldiers mistook him for an adult and killed him. Possibly the last Texian to die in battle was Jacob Walker, who attempted to hide behind Susannah Dickinson and was bayoneted in front of the women. Another Texian, Brigido Guerrero, also sought refuge in the sacristy. Guerrero, who had deserted from the Mexican Army in December 1835, was spared after convincing the soldiers he was a Texian prisoner.
By 6:30 a.m. the battle for the Alamo was over. Mexican soldiers inspected each corpse, bayoneting any body that moved. Even with all of the Texians dead, Mexican soldiers continued to shoot, some killing each other in the confusion. Mexican generals were unable to stop the bloodlust and appealed to Santa Anna for help. Although the general showed himself, the violence continued and the buglers were finally ordered to sound a retreat. For 15 minutes after that, soldiers continued to fire into dead bodies.
Aftermath.
Casualties.
According to many accounts of the battle, between five and seven Texians surrendered. Incensed that his orders had been ignored, Santa Anna demanded the immediate execution of the survivors. Weeks after the battle, stories circulated that Crockett was among those who surrendered. However, Ben, a former American slave who cooked for one of Santa Anna's officers, maintained that Crockett's body was found surrounded by "no less than sixteen Mexican corpses". Historians disagree on which version of Crockett's death is accurate.
Santa Anna reportedly told Captain Fernando Urizza that the battle "was but a small affair". Another officer then remarked that "with another such victory as this, we'll go to the devil". In his initial report Santa Anna claimed that 600 Texians had been killed, with only 70 Mexican soldiers killed and 300 wounded. His secretary, Ramón Martínez Caro, later repudiated the report. Other estimates of the number of Mexican soldiers killed ranged from 60–200, with an additional 250–300 wounded. Most Alamo historians place the number of Mexican casualties at 400–600 Mexicans. This would represent about one-third of the Mexican soldiers involved in the final assault, which Todish remarks is "a tremendous casualty rate by any standards". Most eyewitnesses counted between 182–257 Texians killed. Some historians believe that at least one Texian, Henry Warnell, successfully escaped from the battle. Warnell died several months later of wounds incurred either during the final battle or during his escape as a courier.
Mexican soldiers were buried in the local cemetery, Campo Santo. Shortly after the battle, Colonel José Juan Sanchez Navarro proposed that a monument should be erected to the fallen Mexican soldiers. Cos rejected the idea.
The Texian bodies were stacked and burned. The only exception was the body of Gregorio Esparza. His brother Francisco, an officer in Santa Anna's army, received permission to give Gregorio a proper burial. The ashes were left where they fell until February 1837, when Juan Seguín returned to Béxar to examine the remains. A simple coffin inscribed with the names Travis, Crockett, and Bowie was filled with ashes from the funeral pyres. According to a March 28, 1837, article in the "Telegraph and Texas Register", Seguín buried the coffin under a peach tree grove. The spot was not marked and cannot now be identified. Seguín later claimed that he had placed the coffin in front of the altar at the San Fernando Cathedral. In July 1936 a coffin was discovered buried in that location, but according to historian Wallace Chariton it is unlikely to actually contain the remains of the Alamo defenders. Fragments of uniforms were found in the coffin, and it is known that the Alamo defenders did not wear uniforms.
Texian survivors.
In an attempt to convince other slaves in Texas to support the Mexican government over the Texian rebellion, Santa Anna spared Travis's slave, Joe. The day after the battle, he interviewed each noncombatant individually. Impressed with Susanna Dickinson, Santa Anna offered to adopt her infant daughter Angelina and have the child educated in Mexico City. Dickinson refused the offer, which was not extended to Juana Navarro Alsbury for her son who was of similar age. Each woman was given a blanket and two silver pesos. Alsbury and the other "Tejano" women were allowed to return to their homes in Béxar; Dickinson, her daughter and Joe were sent to Gonzales, escorted by Ben. They were encouraged to relate the events of the battle, and to inform the remainder of the Texian forces that Santa Anna's army was unbeatable.
Impact on revolution.
During the siege, newly elected delegates from across Texas met at the Convention of 1836. On March 2, the delegates declared independence, forming the Republic of Texas. Four days later, the delegates at the convention received a dispatch Travis had written March 3 warning of his dire situation. Unaware that the Alamo had fallen, Robert Potter called for the convention to adjourn and march immediately to relieve the Alamo. Sam Houston convinced the delegates to remain in Washington-on-the-Brazos to develop a constitution. After being appointed sole commander of all Texian troops, Houston journeyed to Gonzales to take command of the 400 volunteers who were still waiting for Fannin to lead them to the Alamo.
Within hours of Houston's arrival on March 11, Andres Barcenas and Anselmo Bergaras arrived with news that the Alamo had fallen and all Texians were slain. Hoping to halt a panic, Houston arrested the men as enemy spies. They were released hours later when Susannah Dickinson and Joe reached Gonzales and confirmed the report. Realizing that the Mexican army would soon advance toward the Texian settlements, Houston advised all civilians in the area to evacuate and ordered his new army to retreat. This sparked a mass exodus, known as the Runaway Scrape, and most Texians, including members of the new government, fled east.
Despite their losses at the Alamo, the Mexican army in Texas outnumbered the Texian army by almost six to one. Santa Anna assumed that knowledge of the disparity in troop numbers and the fate of the Texian soldiers at the Alamo would quell the resistance, and that Texian soldiers would quickly leave the territory. News of the Alamo's fall had the opposite effect, and men flocked to Houston's army. The "New York Post" editorialized that "had Anna treated the vanquished with moderation and generosity, it would have been difficult if not impossible to awaken that general sympathy for the people of Texas which now impels so many adventurous and ardent spirits to throng to the aid of their brethren".
On the afternoon of April 21 the Texian army attacked Santa Anna's camp near Lynchburg Ferry. The Mexican army was taken by surprise, and the Battle of San Jacinto was essentially over after 18 minutes. During the fighting, many of the Texian soldiers repeatedly cried "Remember the Alamo!" Santa Anna was captured the following day, and reportedly told Houston: "That man may consider himself born to no common destiny who has conquered the Napoleon of the West. And now it remains for him to be generous to the vanquished." Houston replied, "You should have remembered that at the Alamo". Santa Anna was forced to order his troops out of Texas, ending Mexican control of the province and giving some legitimacy to the new republic.
Legacy.
Following the battle, Santa Anna was alternately viewed as a national hero or a pariah. Mexican perceptions of the battle often mirrored the prevailing viewpoint. Santa Anna had been disgraced following his capture at the Battle of San Jacinto, and many Mexican accounts of the battle were written by men who had been, or had become, his outspoken critics. Petite and many other historians believe that some of the stories, such as the execution of Crockett, may have been invented to further discredit Santa Anna. In Mexican history, the Texas campaign, including the Battle of the Alamo, was soon overshadowed by the Mexican–American War of 1846–48.
In San Antonio de Béxar, the largely "Tejano" population viewed the Alamo complex as more than just a battlesite; it represented decades of assistance—as a mission, a hospital, or a military post. As the English-speaking population increased, the complex became best known for the battle. Focus has centered primarily on the Texian defenders, with little emphasis given to the role of the "Tejano" soldiers who served in the Texian army or the actions of the Mexican army. In the early 20th century the Texas Legislature purchased the property and appointed the Daughters of the Republic of Texas as permanent caretakers of what is now an official state shrine. In front of the church, in the center of Alamo Plaza, stands a cenotaph, designed by Pompeo Coppini, which commemorates the Texians and "Tejanos" who died during the battle. According to Bill Groneman's "Battlefields of Texas", the Alamo has become "the most popular tourist site in Texas".
The first English-language histories of the battle were written and published by Texas Ranger and amateur historian John Henry Brown. The next major treatment of the battle was Reuben Potter's "The Fall of the Alamo", published in "The Magazine of American History" in 1878. Potter based his work on interviews with many of the Mexican survivors of the battle. The first full-length, non-fiction book covering the battle, John Myers Myers' "The Alamo", was published in 1948. In the decades since, the battle has featured prominently in many non-fiction works.
According to Todish "et al.", "there can be little doubt that most Americans have probably formed many of their opinions on what occurred at the Alamo not from books, but from the various movies made about the battle." The first film version of the battle appeared in 1911, when Gaston Méliès directed "The Immortal Alamo". The battle became more widely known after it was featured in the 1950s Disney miniseries "Davy Crockett", which was largely based on myth. Within several years, John Wayne directed and starred in one of the best-known, but questionably accurate, film versions, 1960's "The Alamo". In 2004 another film, also called "The Alamo", was released. CNN described it as possibly "the most character-driven of all the movies made on the subject". It is also considered more faithful to the actual events than other movies.
Modern popular culture.
A number of songwriters have been inspired by the Battle of the Alamo. Tennessee Ernie Ford's "The Ballad of Davy Crockett" spent 16 weeks on the country music charts, peaking at No. 4 in 1955. Marty Robbins recorded a version of the song "The Ballad of the Alamo" in 1960 which spent 13 weeks on the pop charts, peaking at No. 34. Jane Bowers' song "Remember the Alamo" has been recorded by artists including Johnny Cash and Donovan.

Black Power
Black Power is a political slogan and a name for various associated ideologies aimed at promoting the Black racial group. It is used in the movement among people of Black African descent throughout the world, though primarily by African Americans in the United States. The movement was prominent in the late 1960s and early 1970s, emphasizing racial pride and the creation of black political and cultural institutions to nurture and promote black collective interests and advance black values.
"Black Power" expresses a range of political goals, from defense against racial oppression, to the establishment of social institutions and a self-sufficient economy. The earliest known usage of the term is found in a 1954 book by Richard Wright entitled "Black Power". Although he did not "coin" the phrase, New York politician Adam Clayton Powell Jr. used the term on May 29, 1966, during a baccalaureate address at Howard University: "To demand these God-given rights is to seek black power."
Origin as a political slogan.
"This is the twenty-seventh time I have been arrested and I ain't going to jail no more! The only way we gonna stop them white men from whuppin' us is to take over. What we gonna start sayin' now is Black Power!"
Stokely Carmichael saw the concept of "Black Power" as a means of solidarity between individuals within the movement. With his conception and articulation of the word, he felt this movement was not just a movement for racial desegregation, but rather a movement to help combat America's crippling racism. He was quoted in saying: "For the last time, 'Black Power' means black people coming together to form a political force and either electing representatives or forcing their representatives to speak their needs."
A range of ideology.
Some Black Power adherents believed in Black autonomy, with a variety of tendencies such as black nationalism, and black separatism. Such positions were for the most part in direct conflict with those of leaders of the mainstream Civil Rights Movement, and thus the two movements have often been viewed as inherently antagonistic. However, certain groups and individuals participated in both civil rights and black power activism.
Not all Black Power advocates were in favor of black nationalism and black separatism. While Stokely Carmichael and SNCC were in favor of black nationalism, organizations such as the Black Panther Party for Self-Defense were not. Though they considered themselves to be at war with a power structure that was indeed all white, they were not at war with all Whites, merely the individuals in the existing power structure, who happened to be all white.
Bobby Seale, Chairman and Co-Founder of the Black Panther Party for Self-Defense, was outspoken about this. His stand was that the oppression of black people was more of a result of economic exploitation than anything innately racist. In his book "Seize the Time", he states that "In our view it is a class struggle between the massive proletarian working class and the small, minority ruling class. Working-class people of all colors must unite against the exploitative, oppressive ruling class. So let me emphasize again -- we believe our fight is a class struggle and not a race struggle."
Bayard Rustin, an elder statesman of the Civil Rights Movement, was a harsh critic of Black Power in its earliest days. Writing in 1966, shortly after the March Against Fear, Rustin said that Black Power “not only lacks any real value for the civil rights movement, but [...] its propagation is positively harmful. It diverts the movement from a meaningful debate over strategy and tactics, it isolates the Negro community, and it encourages the growth of anti-Negro forces.” He particularly criticized the Congress of Racial Equality (CORE) and SNCC for their turn toward Black Power, arguing that these two organizations once “awakened the country, but now they emerge isolated and demoralized, shouting a slogan that may afford a momentary satisfaction but that is calculated to destroy them and their movement.”
Internationalist offshoots of black power include African Internationalism, pan-Africanism, black nationalism, and black supremacy.
Background.
The movement for Black Power in the U.S. came during the Civil Rights Movement in the 1960s. Many members of SNCC, among them Stokely Carmichael (later Kwame Ture), were becoming critical of the nonviolent approach to confronting racism and inequality—articulated and practiced by Martin Luther King, Jr., the NAACP and other moderates—and rejected desegregation as a primary objective.
Douglass, Frederick. Letter to an abolitionist associate (1857). In "Organizing for Social Change: A Mandate For Activity In The 1990s". Bobo, K.; Randall, J.; and Max, S. (eds). Cabin John, Maryland: Seven Locks Press (1991).
Civil Rights leaders also believed in agitation, but most did not believe in physically violent retaliation.
During the March Against Fear, there was a division between those aligned with Martin Luther King, Jr. and those aligned with Carmichael, marked by their respective slogans, "Freedom Now" and "Black Power."
While King never endorsed the slogan, his rhetoric sometimes came close to it. In his 1967 book "Where Do We Go From Here?", King wrote that "power is not the white man's birthright; it will not be legislated for us and delivered in neat government packages."
Impact.
Although the concept remained imprecise and contested and the people, who used the slogan ranged from businesspeople who used it to push black capitalism to revolutionaries who sought an end to capitalism, the idea of Black Power exerted a significant influence. It helped organize scores of community self-help groups and institutions that did not depend on Whites. It was used to force black studies programs at colleges, to mobilize black voters to elect black candidates, and to encourage greater racial pride and self-esteem.
Impact on Black Politics.
Though the Black Power movement did not immediately remedy the political problems faced by African Americans in the 1960s and 1970s, the movement did contribute to the development of black politics both directly and indirectly. As a contemporary of and successor to the Civil Rights Movement, the Black Power movement created, what sociologist Herbert H. Haines refers to as a “positive radical flank effect” on political affairs of the 1960s. Though the nature of the relationship between the Civil Rights Movement and the Black Power movement is contested, Haines’ study of the relationship between black radicals and the mainstream civil rights movement indicates that Black Power generated a “crisis in American institutions which made the legislative agenda of ‘polite, realistic, and businesslike’ mainstream organizations” more appealing to politicians. In this way, it can be argued that the more strident and oppositional messages of the Black Power movement indirectly enhanced the bargaining position of more moderate activists.
Black Power activists approached politics with vitality, variety, wit, and creativity that shaped the way future generations approached dealing with America’s societal problems (McCartney 188). These activists capitalized on the nation’s recent awareness of the political nature of oppression, a primary focus of the Civil Rights Movement, developing numerous political action caucuses and grass roots community associations to remedy the situation 
The National Black Political Convention, held March 10–12, 1972, was a significant milestone in black politics of the Black Power era. Held in Gary, Indiana, a majority black city, the convention included a diverse group of black activists, although it completely excluded whites. The convention was criticized for its racial exclusivity by Roy Wilkins of the NAACP, a group that supported integration. The delegates created a National Black Political Agenda with stated goals including the election of a proportionate number of black representatives to Congress, community control of schools, national health insurance, etc. Though the convention did not result in any direct policy, the convention advanced goals of the Black Power movement and left participants buoyed by a spirit of possibility and themes of unity and self-determination. A concluding note to the convention, addressing its supposed idealism, read: “At every critical moment of our struggle in America we have had to press relentlessly against the limits of the ‘realistic’ to create new realities for the life of our people. This is our challenge at Gary and beyond, for a new Black politics demands new vision, new hope and new definitions of the possible. Our time has come. These things are necessary. All things are possible.” Though such political activism may not have resulted in direct policy, they provided political models for later movements, advanced a pro-black political agenda, and brought sensitive issues to the forefront of American politics. In its confrontational and often oppositional nature, the Black Power movement, started a debate within the black community and America as a nation over issues of racial progress, citizenship, and democracy, namely “the nature of American society and the place of the African American in it.”. The continued intensity of debate over these same social and political issues is a tribute to the impact of the Black Power movement in arousing the political awareness and passions of citizens.
Impact on other movements.
Though the aims of the Black Power movement were racially specific, much of the movement’s impact has been its influence on the development and strategies of later political and social movements. By igniting and sustaining debate on the nature of American society, the Black Power movement created what other multiracial and minority groups interpreted to be a viable template for the overall restructuring of society. By opening up discussion on issues of democracy and equality, the Black Power movement paved the way for a diverse plurality of social justice movements, including black feminism, environmental movements, affirmative action, and gay and lesbian rights. Central to these movements were the issues of identity politics and structural inequality, features emerging from the Black Power movement Because the Black Power movement emphasized and explored a black identity, movement activists were forced to confront issues of gender, class and as well. Many activists in the Black Power movement became active in related movements. This is seen in the case of the “second wave” of women’s right activism, a movement supported and orchestrated to a certain degree by women working from within the coalition ranks of the Black Power movement. The boundaries between social movements became increasingly unclear at the end of the 1960s and into the 1970s; where the Black Power movement ends and where these other social movements begin is often unclear. “It is pertinent to note that as the movement expanded the variables of gender, class, and only compounded issues of strategy and methodology in black protest thought.”
Impact on African-American identity.
Due to the negative and militant reputation of such auxiliaries as that of the Black Panther Party, many people felt that this movement of "insurrection" would soon serve to cause discord, and disharmony through the entire U.S. Even Stokely Carmichael stated, "When you talk of Black Power, you talk of building a movement that will smash everything Western civilization has created."
Though Black Power at the most basic level refers to a political movement, the psychological and cultural messages of the Black Power movement, though less tangible, have had perhaps a longer lasting impact on American society than concrete political changes. Indeed, “fixation on the ‘political’ hinders appreciation of the movement’s cultural manifestations and unnecessarily obscures black culture’s role in promoting the psychological well being of the Afro-American people.”. States William L. Van Deburg, author of A New Day in Babylon, “movement leaders never were as successful in winning power for the people as they were in convincing people that they had sufficient power within themselves to escape ‘the prison of self-deprecation’” Primarily, the liberation and empowerment experienced by African Americans occurred in the psychological realm. The movement uplifted the black community as a whole by cultivating feelings of racial solidarity, often in opposition to the world of white Americans, a world that had physically and psychologically oppressed Blacks for generations. Through the movement, Blacks came to understand themselves and their culture by exploring and debating the question, “who are we?” in order to establish a unified and viable identity.
Throughout the Civil Rights Movement and black history a tension has existing between those wishing to minimize and maximize racial difference. W.E.B. Du Bois and Martin Luther King Jr. often attempted to deemphasize race in their quest for equality, while those advocating for separatism and colonization emphasized an extreme and irreconcilable difference between races. The Black Power movement largely achieved an equilibrium of “balanced and humane ethnocentrism.”
The impact of the Black Power movement in generating valuable discussion about ethnic identity and black consciousness manifests itself in the relatively recent proliferation of academic fields such as American studies, Black Studies, and Africana studies in both national and international institutions. The respect and attention accorded to African Americans’ history and culture in both formal and informal settings today is largely a product of the movement for Black Power in the 1960s and 1970s.
Impact in Britain.
Black Power got a foothold in Britain when Carmichael came to London in July 1967 to attend the Dialectics of Liberation Congress. As well as his address at the Congress, he also made a speech at Speakers' Corner. At that time there was no Black Power organization in Britain although there was Michael X's Racial Adjustment Action Society.
However this was more influenced by the visit of Malcolm X in that year. Michael X also adopted Islam at this stage, whereas Black Power was not organised around any religious confession.
Black is beautiful.
The cultivation of pride in the African-American race was often summarized in the phrase "Black is Beautiful". The phrase is rooted in its historical context, yet the relationship to it has changed in contemporary times. “I don’t think it’s ‘Black is beautiful’ anymore. It’s ‘I am beautiful and I’m black.’ It’s not the symbolic thing, the afro, power sign… That phase is over and it succeeded. My children feel better about themselves and they know that they’re black,” stated a respondent in Bob Blauner’s longitudinal oral history of U.S. race relations in 1986. The outward manifestations of an appreciation and celebration of blackness abound: black dolls, natural hair, black Santas, models and celebrities that were once rare and symbolic have become commonplace.
The "Black is beautiful" cultural movement aimed to dispel the notion that black people's natural features such as skin color, facial features and hair are inherently ugly. John Sweat Rock was the first to coin the phrase "Black is Beautiful", in the slavery era. The movement asked that men and women stop straightening their hair and attempting to lighten or bleach their skin. The prevailing idea in American culture was that black features are less attractive or desirable than white features. The movement is largely responsible for the popularity of the Afro. Most importantly, it gave a generation of African Americans the courage to feel good about who they are and how they look.
Impact on arts and culture.
The Black Power movement produced artistic and cultural products that both embodied and generated pride in “blackness” and further defined an African-American identity that remains contemporary. Black Power is often seen as a cultural revolution as much as a political revolution, with the goal of celebrating and emphasizing the distinctive group culture of African Americans to an American society that had previously been dominated by white artistic and cultural expressions. Black power utilized all available forms of folk, literary, and dramatic expression based in a common ancestral past to promote a message of self-actualization and cultural self-definition. The emphasis on a distinctive black culture during the Black Power movement publicized and legitimized a culture gap between Blacks and Whites that had previously been ignored and denigrated. More generally, in recognizing the legitimacy of another culture and challenging the idea of white cultural superiority, the Black Power movement paved the way for the celebration of multiculturalism in America today.
The cultural concept of “soul” was fundamental to the image of African-American culture embodied by the Black Power movement. Soul, a type of “in-group cultural cachet,” was closely tied to black America’s need for individual and group self-identification. A central expression of the “soulfulness” of the Black Power generation was a cultivation of aloofness and detachment, the creation of an “aura or emotional invulnerability,” a persona that challenged their position of relative powerlessness in greater society. The nonverbal expressions of this attitude, including everything from posture to handshakes, were developed as a counterpoint to the rigid, “up-tight” mannerisms of white people. Though the iconic symbol of black power, the arms raised with biceps flexed and clenched fists, is temporally specific, variants of the multitude of handshakes, or “giving and getting skin,” in the 1960s and 1970s as a mark of communal solidarity continue to exist as a part of black culture. Clothing style also became an expression of Black Power in the 1960s and 1970s. Though many of the popular trends of the movement remained confined to the decade, the movement redefined standards of beauty that were historically influenced by Whites and instead celebrated a natural “blackness.” As Stokely Carmichael said in 1966, “We have to stop being ashamed of being black. A broad nose, thick lip and nappy hair is us and we are going to call that beautiful whether they like it or not.” “Natural” hair styles, such as the Afro, became a socially acceptable tribute to group unity and a highly visible celebration of black heritage. Though the same social messages may no longer consciously influence individual hair or clothing styles in today’s society, the Black Power movement was influential in diversifying standards of beauty and aesthetic choices. The Black Power movement raised the idea of a black aesthetic that revealed the worth and beauty of all black people.
In developing a powerful identity from the most elemental aspects of African-American folk life, the Black Power movement generated attention to the concept of “soul food,” a fresh, authentic, and natural style of cooking that originated in Africa. The flavor and solid nourishment of the food was credited with sustaining African Americans through centuries of oppression in America and became an important aid in nurturing contemporary racial pride. Black Power advocates used the concept of “soul food” to further distinguish between white and black culture; though the basic elements of soul food were not specific to African-American food, Blacks believed in the distinctive quality, if not superiority, of foods prepared by Blacks. No longer racially specific, traditional “soul foods” such as yams, collard greens, and deep-fried chicken continue to hold a place in contemporary culinary life.
Black Arts Movement.
The Black Arts Movement or BAM, founded in Harlem by writer and activist Amiri Baraka (born Everett LeRoy Jones), can be seen as the artistic branch of the Black Power movement. This movement inspired black people to establish ownership of publishing houses, magazines, journals and art institutions. Other well-known writers who were involved with this movement included Nikki Giovanni; Don L. Lee, later known as Haki Madhubuti; Sonia Sanchez; Maya Angelou; Dudley Randall; Sterling Plumpp; Larry Neal; Ted Joans; Ahmos Zu-Bolton; and Etheridge Knight. Several black-owned publishing houses and publications sprang from the BAM, including Madhubuti's Third World Press, Broadside Press, Zu-Bolton's Energy Black South Press, and the periodicals "Callaloo" and "Yardbird Reader". Although not strictly involved with the Movement, other notable African-American writers such as novelists Ishmael Reed and Toni Morrison and poet Gwendolyn Brooks can be considered to share some of its artistic and thematic concerns.
BAM sought “to link, in a highly conscious manner, art and politics in order to assist in the liberation of black people”, and produced an increase in the quantity and visibility of African-American artistic production. Though many elements of the Black Arts movement are separate from the Black Power movement, many goals, themes, and activists overlapped. Literature, drama, and music of Blacks “served as an oppositional and defensive mechanism through which creative artists could confirm their identity while articulating their own unique impressions of social reality.” In addition to acting as highly visible and unifying representations of “blackness,” the artistic products of the Black Power movement also utilized themes of black empowerment and liberation. For instance, black recording artists not only transmitted messages of racial unity through their music, they also became significant role models for a younger generation of African Americans. Updated protest songs not only bemoaned oppression and societal wrongs, but utilized adversity as a reference point and tool to lead others to activism. Some Black Power era artists conducted brief mini-courses in the techniques of empowerment. In the tradition of cultural nationalists, these artists taught that in order to alter social conditions, Blacks first had to change the way they viewed themselves; they had to break free of white norms and strive to be more natural, a common theme of African-American art and music. Musicians such as the Temptations sang lyrics such as “I have one single desire, just like you / So move over, son, ‘cause I’m comin’ through” in their song “Message From a Black Man,” they expressed the revolutionary sentiments of the Black Power movement.
Black Arts Movement
By breaking into a field typically reserved for white Americans, artists of the Black Power era expanded opportunities for current African Americans. “Today’s writers and performers,” writes William L. Van Deburg, “recognize that they owe a great deal to Black Power’s explosion of cultural orthodoxy”.

Bloody Sunday (1972)
Bloody Sunday ()—sometimes called the Bogside Massacre—was an incident on 30 January 1972 in the Bogside area of Derry, Northern Ireland, in which 26 unarmed civil-rights protesters and bystanders were shot by soldiers of the British Army. Thirteen males, seven of whom were teenagers, died immediately or soon after, while the death of another man four-and-a-half months later was attributed to the injuries he received on that day. Two protesters were also injured when they were run down by army vehicles. Five of those wounded were shot in the back. The incident occurred during a Northern Ireland Civil Rights Association march; the soldiers involved were members of the First Battalion of the Parachute Regiment (1 Para). 
Two investigations have been held by the British government. The Widgery Tribunal, held in the immediate aftermath of the event, largely cleared the soldiers and British authorities of blame—Widgery described the soldiers' shooting as "bordering on the reckless"—but was criticised as a "whitewash", including by Jonathan Powell. The Saville Inquiry, chaired by Lord Saville of Newdigate, was established in 1998 to reinvestigate the events. Following a 12-year inquiry, Saville's report was made public on 15 June 2010, and contained findings of fault that could re-open the controversy, and potentially lead to criminal investigations for some soldiers involved in the killings. The report found that all of those shot were unarmed, and that the killings were both "unjustified and unjustifiable." On the publication of the Saville report the British prime minister, David Cameron, made a formal apology on behalf of the United Kingdom.
The Provisional Irish Republican Army's (IRA) campaign against the partition of Ireland had begun in the two years prior to Bloody Sunday, but public perceptions of the day boosted the status of, and recruitment into, the organisation enormously. Bloody Sunday remains among the most significant events in the Troubles of Northern Ireland, chiefly because those who died were shot by the British army rather than paramilitaries, in full view of the public and the press.
Background.
In the late 1960s discrimination against the Catholic minority in electoral boundaries, voting rights, and the allocation of public housing led organisations such as Northern Ireland Civil Rights Association (NICRA) to mount a non-violent campaign for change. Following attacks on civil rights marchers by Protestant loyalists, as well as members of the Royal Ulster Constabulary (RUC), anger and violence mounted. In 1969 the Battle of the Bogside broke out in the aftermath of disturbances following an Apprentice Boys of Derry march. The residents of the nationalist Bogside erected barricades around the area to resist police incursions, and, after three days of rioting when the RUC had proved unable to restore order, the government of Northern Ireland requested the deployment of the British Army.
While initially welcomed by the Catholics as a neutral force compared to the RUC, relations between the nationalists and the Army soon deteriorated. On 8 July 1971 two rioters, Seamus Cusack and Desmond Beattie, were shot dead in the Bogside by soldiers in disputed circumstances. Soldiers claimed the pair were armed, which was denied by local people, and moderate nationalists including John Hume and Gerry Fitt walked out of the Parliament of Northern Ireland in protest. A British Army memorandum states that as a result of this the situation "changed overnight", with the Provisional IRA's campaign in the city beginning at that time after previously being regarded as "quiescent".
In response to escalating levels of violence across Northern Ireland, internment without trial was introduced on 9 August 1971. In a "quid pro quo" gesture to nationalists, all marches and parades were banned, including the flashpoint march by the Apprentice Boys of Derry which was due to take place on 12 August. There was disorder across Northern Ireland following the introduction of internment, with 21 people being killed in three days of rioting. On 10 August Bombardier Paul Challenor became the first soldier to be killed by the Provisional IRA in Derry, when he was shot by a sniper on the Creggan estate. A further six soldiers had been killed in Derry by mid-December 1971. 1,932 rounds were fired at the British Army, who also faced 211 explosions and 180 nail bombs and who fired 364 rounds in return.
Provisional IRA activity also increased across Northern Ireland with thirty British soldiers being killed in the remaining months of 1971, in contrast to the ten soldiers killed during the pre-internment period of the year. Both the Official IRA and Provisional IRA had established "no-go" areas for the British Army and RUC in Derry through the use of barricades. By the end of 1971, 29 barricades were in place to prevent access to what was known as Free Derry, 16 of them impassable even to the British Army's one-ton armoured vehicles. IRA members openly mounted roadblocks in front of the media, and daily clashes took place between nationalist youths and the British Army at a spot known as "aggro corner". Due to rioting and damage to shops caused by incendiary devices, an estimated total of worth of damage had been done to local businesses.
In January 1972 the NICRA intended, despite the ban, to organise a march in Derry to protest against internment. The authorities who knew of the proposed march decided to allow it to proceed in the nationalist areas of the city, but to stop it from reaching Guildhall Square, as planned by the organizers. Major General Robert Ford, then Commander of Land Forces in Northern Ireland, ordered that 1st Battalion, The Parachute Regiment (1 PARA) should travel to Derry to be used to arrest possible rioters during the march. 1 PARA arrived in Derry on the morning of Sunday 30 January 1972 and took up positions in the city.
Events of the day.
Many details of the day's events are in dispute, with no agreement even on the number of marchers present that day. The organisers, "Insight", claimed that there were 30,000 marchers; Lord Widgery, in his now discredited tribunal, said that there were only 3,000 to 5,000. In "The Road To Bloody Sunday", local GP Dr. Raymond McClean estimated the crowd as 15,000, which is the figure that was used by Bernadette Devlin McAliskey in Parliament.
Numerous books and articles have been written and documentary films have been made on the subject.
Narrative of events.
The people planned on marching to the Guildhall, but because of army barricades designed to reroute the march it was redirected to Free Derry Corner. A group of teenagers broke off from the march and persisted in pushing the barricade and marching on the Guildhall. They attacked the British army barricade with stones. At this point, a water cannon, tear gas and rubber bullets were used to disperse the rioters. Such confrontations between soldiers and youths were common, though observers reported that the rioting was not intense. Two civilians, Damien Donaghy and John Johnston were shot and wounded by soldiers on William Street who claimed the former was carrying a black cylindrical object.
At a certain point, reports of an IRA sniper operating in the area were allegedly given to the Army command centre. At Brigade gave the British Parachute Regiment permission to go in to the Bogside. The order to fire live rounds was given, and one young man was shot and killed when he ran down Chamberlain Street away from the advancing troops. This first fatality, Jackie Duddy, was among a crowd who were running away. He was running alongside a priest, Father Edward Daly, when he was shot in the back. Continuing violence by British troops escalated, and eventually the order was given to mobilise the troops in an arrest operation, chasing the tail of the main group of marchers to the edge of the field by Free Derry Corner.
Despite a cease-fire order from the army HQ, over 100 rounds were fired directly into the fleeing crowds by troops under the command of Major Ted Loden. Twelve more were killed, many of them as they attempted to aid the fallen. Fourteen others were wounded, 12 by shots from the soldiers and two knocked down by armoured personnel carriers.
Perspectives and analyses on the day.
Thirteen people were shot and killed, with another man later dying of his wounds. The official army position, backed by the British Home Secretary the next day in the House of Commons, was that the paratroopers had reacted to gun and nail bomb attacks from suspected IRA members. All eyewitnesses (apart from the soldiers), including marchers, local residents, and British and Irish journalists present, maintain that soldiers fired into an unarmed crowd, or were aiming at fleeing people and those tending the wounded, whereas the soldiers themselves were not fired upon. No British soldier was wounded by gunfire or reported any injuries, nor were any bullets or nail bombs recovered to back up their claims.
In the events that followed, irate crowds burned down the British embassy on Merrion Square in Dublin. Anglo-Irish relations hit one of their lowest ebbs, with the Irish Minister for Foreign Affairs, Patrick Hillery, going specially to the United Nations in New York to demand UN involvement in the Northern Ireland "Troubles".
Although there were many IRA men—both Official and Provisional—present at the protest, it is claimed they were all unarmed, apparently because it was anticipated that the paratroopers would attempt to "draw them out". March organiser and MP Ivan Cooper had been promised beforehand that no armed IRA men would be near the march. One paratrooper who gave evidence at the Tribunal testified that they were told by an officer to expect a gunfight and "We want some kills". In the event, one man was witnessed by Father Edward Daly and others haphazardly firing a revolver in the direction of the paratroopers. Later identified as a member of the Official IRA, this man was also photographed in the act of drawing his weapon, but was apparently not seen or targeted by the soldiers. Various other claims have been made to the Saville Inquiry about gunmen on the day.
The city's coroner, retired British Army Major Hubert O'Neill, issued a statement on 21 August 1973, at the completion of the inquest into the people killed. He declared: 
Following the events of Bloody Sunday Bernadette Devlin, an Independent Socialist nationalist MP from Northern Ireland, expressed anger at what she perceived as government attempts to stifle accounts being reported about the day. Having witnessed the events firsthand, she was later infuriated that she was consistently denied the chance to speak in Parliament about the day, although parliamentary convention decreed that any MP witnessing an incident under discussion would be granted an opportunity to speak about it in the House.
Devlin punched Reginald Maudling, the Secretary of State for the Home Department in the Conservative government, when he made a statement to Parliament on the events of Bloody Sunday stating that the British Army had fired only in self-defence.
She was temporarily suspended from Parliament as a result of the incident.
In January 1997, the United Kingdom television station Channel 4 carried a news report that suggested that members of the Royal Anglian Regiment had also opened fire on the protesters and could have been responsible for three of the fourteen deaths.
On 29 May 2007 it was reported that General Sir Mike Jackson, second-in-command of 1 Para on Bloody Sunday, said: "I have no doubt that innocent people were shot". This was in sharp contrast to his insistence, for more than 30 years, that those killed on the day had not been innocent.
The Saville Inquiry.
Although British Prime Minister John Major rejected John Hume's requests for a public inquiry into the killings, his successor, Tony Blair, decided to start one. A second commission of inquiry, chaired by Lord Saville, was established in January 1998 to re-examine Bloody Sunday. The other judges were John Toohey QC, a former Justice of the High Court of Australia who had worked on Aboriginal issues (he replaced New Zealander Sir Edward Somers QC, who retired from the Inquiry in 2000 for personal reasons), and Mr Justice William Hoyt QC, former Chief Justice of New Brunswick and a member of the Canadian Judicial Council. The hearings were concluded in November 2004, and the report was published 15 June 2010. The Saville Inquiry was a more comprehensive study than the Widgery Tribunal, interviewing a wide range of witnesses, including local residents, soldiers, journalists and politicians. Lord Saville declined to comment on the Widgery report and made the point that the Saville Inquiry was a judicial inquiry into Bloody Sunday, not the Widgery Tribunal.
Evidence given by Martin McGuinness, a senior member of Sinn Féin and now the deputy First Minister of Northern Ireland, to the inquiry stated that he was second-in-command of the Derry City brigade of the Provisional IRA and was present at the march. He did not answer questions about where he had been staying because he said it would compromise the safety of the individuals involved.
A claim was made at the Saville Inquiry that McGuinness was responsible for supplying detonators for nail bombs on Bloody Sunday. Paddy Ward claimed he was the leader of the Fianna Éireann, the youth wing of the IRA in January 1972. He claimed McGuinness, the second-in-command of the IRA in the city at the time, and another anonymous IRA member gave him bomb parts on the morning of 30 January, the date planned for the civil rights march. He said his organisation intended to attack city-centre premises in Derry on the day when civilians were shot dead by British soldiers. In response McGuinness rejected the claims as "fantasy", while Gerry O'Hara, a Sinn Féin councillor in Derry stated that he and not Ward was the Fianna leader at the time.
Many observers allege that the Ministry of Defence acted in a way to impede the inquiry. Over 1,000 army photographs and original army helicopter video footage were never made available. Additionally, guns used on the day by the soldiers that could have been evidence in the inquiry were lost by the MoD. The MoD claimed that all the guns had been destroyed, but some were subsequently recovered in various locations (such as Sierra Leone and Beirut) despite the obstruction.
By the time the inquiry had retired to write up its findings, it had interviewed over 900 witnesses, over seven years, making it the biggest investigation in British legal history. The cost of this process has drawn criticism; as of the publication of the Saville Report being .
The inquiry was expected to report in late 2009 but was delayed until after the general election on 6 May 2010.
The report of the inquiry was published on 15 June 2010. The report concluded, "The firing by soldiers of 1 PARA on Bloody Sunday caused the deaths of 13 people and injury to a similar number, none of whom was posing a threat of causing death or serious injury." Saville stated that British paratroopers "lost control", fatally shooting fleeing civilians and those who tried to aid the civilians who had been shot by the British soldiers. The report stated that British soldiers had concocted lies in their attempt to hide their acts. Saville stated that the civilians had not been warned by the British soldiers that they intended to shoot. The report states, contrary to the previously established belief, that no stones and no petrol bombs were thrown by civilians before British soldiers shot at them, and that the civilians were not posing any threat.
The report concluded that an Official IRA sniper fired on British soldiers, albeit on the balance of evidence his shot was fired after the Army shots that wounded Damien Donaghey and John Johnston. The Inquiry rejected the sniper's account that this shot had been made in reprisal, stating the view that he and another Official IRA member had already been in position, and the shot had probably been fired simply because the opportunity had presented itself. Ultimately, the Saville Inquiry was inconclusive on Martin McGuinness's role due to a lack of certainty over his movements, concluding that while he was "engaged in paramilitary activity" during Bloody Sunday, and had probably been armed with a Thompson submachine gun, there was insufficient evidence to make any finding other than they were "sure that he did not engage in any activity that provided any of the soldiers with any justification for opening fire".
Impact on Northern Ireland divisions.
Harold Wilson, then the Leader of the Opposition in the Commons, reiterated his belief that a united Ireland was the only possible solution to Northern Ireland's Troubles. William Craig, then Stormont Home Affairs Minister, suggested that the west bank of Derry should be ceded to the Republic of Ireland.
When it was deployed on duty in Northern Ireland, the British Army was welcomed by Roman Catholics as a neutral force there to protect them from Protestant mobs, the Royal Ulster Constabulary (RUC) and the B-Specials. After Bloody Sunday many Catholics turned on the British army, seeing it no longer as their protector but as their enemy. Young nationalists became increasingly attracted to violent republican groups. With the Official IRA and Official Sinn Féin having moved away from mainstream Irish republicanism towards Marxism, the Provisional IRA began to win the support of newly radicalised, disaffected young people.
In the following twenty years, the Provisional Irish Republican Army and other smaller republican groups such as the Irish National Liberation Army (INLA) mounted an armed campaign against the British, by which they meant the RUC, the British Army, the Ulster Defence Regiment (UDR) of the British Army (and, according to their critics, the Protestant and unionist establishment). With rival paramilitary organisations appearing in both the nationalist/republican and Irish unionist/Ulster loyalist communities (the Ulster Defence Association, Ulster Volunteer Force (UVF), etc. on the loyalist side), the Troubles cost the lives of thousands of people. Incidents included the killing of three members of a pop band, the Miami Showband, by a gang including members of the UVF who were also members of the local army regiment, the UDR, and in uniform at the time, and the killing by the Provisionals of eighteen members of the Parachute Regiment in the Warrenpoint Ambush-seen by some as revenge for Bloody Sunday.
With the official cessation of violence by some of the major paramilitary organisations and the creation of the power-sharing executive at Stormont in Belfast under the 1998 Good Friday Agreement, the Saville Inquiry's re-examination of the events of that day is widely hoped to provide a thorough account of the events of Bloody Sunday.
In his speech to the House of Commons on the Inquiry, British Prime Minister David Cameron stated: "These are shocking conclusions to read and shocking words to have to say. But you do not defend the British Army by defending the indefensible." He acknowledged that all those who died were unarmed when they were killed by British soldiers and that a British soldier had fired the first shot at civilians. He also said that this was not a premeditated action, though "there was no point in trying to soften or equivocate" as "what happened should never, ever have happened". Cameron then apologised on behalf of the British Government by saying he was "deeply sorry".
A survey conducted by Angus Reid Public Opinion in June 2010 found that 61 per cent of Britons and 70 per cent of Northern Irish agreed with Cameron’s apology for the Bloody Sunday events.
Stephen Pollard, solicitor representing several of the soldiers, said on 15 June 2010 that Saville had cherry-picked the evidence and did not have justification for his findings.
Artistic reaction.
The incident has been commemorated by Irish band, U2, in their 1983 protest song "Sunday Bloody Sunday".
The John Lennon album "Some Time in New York City" features a song entitled "Sunday Bloody Sunday", inspired by the incident, as well as the song "The Luck of the Irish", which dealt more with the Irish conflict in general. Lennon, who was of Irish descent, also spoke at a protest in New York in support of the victims and families of Bloody Sunday.
The Roy Harper song "All Ireland" from the album "Lifemask", written in the days following the incident, is critical of the military but takes a long term view with regard to a solution. In Harper's book ("The Passions Of Great Fortune"), his comment on the song ends "..there must always be some hope that the children of 'Bloody Sunday', on both sides, can grow into some wisdom".
Paul McCartney (also of Irish descent) issued a single shortly after Bloody Sunday titled "Give Ireland Back to the Irish", expressing his views on the matter. It was one of few McCartney solo songs to be banned by the BBC.
Black Sabbath's Geezer Butler (also of Irish descent) wrote the lyrics to the Black Sabbath song "Sabbath Bloody Sabbath" on the album of the same name in 1973. Butler stated, "… the Sunday Bloody Sunday thing had just happened in Ireland, when the British troops opened fire on the Irish demonstrators... So I came up with the title ‘Sabbath Bloody Sabbath,’ and sort of put it in how the band was feeling at the time, getting away from management, mixed with the state Ireland was in."
Christy Moore's song "Minds Locked Shut" on the album "Graffiti Tongue" is all about the events of the day, and names the dead civilians.
The Celtic metal band Cruachan addressed the incident in a song "Bloody Sunday" from their 2004 album "Folk-Lore".
The events of the day have been dramatised in the two 2002 television dramas, "Bloody Sunday" (starring James Nesbitt) and "Sunday" by Jimmy McGovern.
Brian Friel's 1973 play "The Freedom of the City" deals with the incident from the viewpoint of three civilians.
Irish poet Thomas Kinsella's 1972 poem "Butcher's Dozen" is a satirical and angry response to the Widgery Tribunal and the events of Bloody Sunday.
Irish poet Seamus Heaney's "Casualty" (published in "Field Work," 1981) criticizes Britain for the death of his friend. 
Willie Doherty, a Derry-born artist, has amassed a large body of work which addresses the troubles in Northern Ireland. "30 January 1972" deals specifically with the events of Bloody Sunday.
In mid-2005, the play "", a dramatisation based on the Saville Inquiry, opened in London, and subsequently travelled to Derry and Dublin. The writer, journalist Richard Norton-Taylor, distilled four years of evidence into two hours of stage performance by Tricycle Theatre. The play received glowing reviews in all the British broadsheets, including "The Times": "The Tricycle's latest recreation of a major inquiry is its most devastating"; "The Daily Telegraph": "I can't praise this enthralling production too highly ... exceptionally gripping courtroom drama"; and "The Independent": "A necessary triumph".
The Wolfe Tones, an Irish rebel music band, wrote a song also called "Sunday Bloody Sunday" about the event.
Swedish troubadour Fred Åkerström wrote a song called "Den 30/1-72" about the incident.
In October 2010, T with the Maggies released the song "Domhnach na Fola" (Irish for "Bloody Sunday"), written by Mairéad Ní Mhaonaigh and Tríona Ní Dhomhnaill on their debut album.

Bosnia and Herzegovina
Bosnia and Herzegovina (; Bosnian and Croatian: "Bosna i Hercegovina" Serbian: "Босна и Херцеговина"), sometimes called Bosnia-Herzegovina, is a country in Southeastern Europe, on the Balkan Peninsula. Its capital and largest city is Sarajevo. Bordered by Croatia to the north, west and south, Serbia to the east, and Montenegro to the southeast, Bosnia and Herzegovina is almost landlocked, except for the of coastline on the Adriatic Sea surrounding the city of Neum. In the central and southern interior of the country the geography is mountainous, in the northwest it is moderately hilly, and the northeast is predominantly flatland. The inland is a geographically larger region and has a moderate continental climate, bookended by hot summers and cold and snowy winters. The southern tip of the country has a Mediterranean climate and plain topography.
Bosnia and Herzegovina is a region that traces permanent human settlement back to the Neolithic age, during and after which it was populated by several Illyrian and Celtic civilizations. Culturally, politically, and socially, the country has one of the richest histories in the region, having been first settled by the Slavic peoples that populate the area today from the 6th through to the 9th centuries AD. They then established the first independent banate in the region, known as the Banate of Bosnia, in the early 12th century upon the arrival and convergence of peoples that would eventually come to call themselves "Dobri Bošnjani" ("Good Bosnians"). This evolved into the Kingdom of Bosnia in the 14th century, after which it was annexed into the Ottoman Empire, under whose rule it would remain from the mid 15th to the late 19th centuries. The Ottomans brought Islam to the region, and altered much of the cultural and social outlook of the country. This was followed by annexation into the Austro-Hungarian Monarchy, which lasted up until World War I. Following the dissolution of the Socialist Federal Republic of Yugoslavia, the country proclaimed independence in 1992, which was followed by a bloody war, lasting until late 1995.
Today, the country maintains high literacy, life expectancy and education levels and is one of the most frequently-visited countries in the region. Bosnia and Herzegovina is regionally and internationally renowned for its natural beauty and cultural heritage inherited from six historical civilizations, its cuisine, winter sports, its eclectic and unique architecture and the Sarajevo Film Festival and Sarajevo Jazz Festival, both the largest and most prominent of their kind in Southeastern Europe.
The country is home to three ethnic groups or, officially, constituent peoples, a term unique for Bosnia and Herzegovina. Bosniaks are the largest group of the three, with Serbs second and Croats third. Regardless of ethnicity, a citizen of Bosnia and Herzegovina is often identified in English as a Bosnian. The terms Herzegovinian and Bosnian are maintained as a regional rather than ethnic distinction, and the region of Herzegovina has no precisely defined borders of its own. Moreover, the country was simply called "Bosnia" (without Herzegovina) until the Austro-Hungarian occupation at the end of the nineteenth century.
Bosnia and Herzegovina has a bicameral legislature and a three-member Presidency composed of a member of each major ethnic group. However, the central government's power is highly limited, as the country is largely decentralized and comprises two autonomous entities: the Federation of Bosnia and Herzegovina and Republika Srpska, with a third region, the Brčko District, governed under local government. The Federation of Bosnia and Herzegovina is itself complex and consists of 10 federal units - cantons. The country is a potential candidate for membership to the European Union and has been a candidate for NATO membership since April 2010, when it received a Membership Action Plan at the summit in Tallinn. Additionally, the country has been a member of the Council of Europe since April 2002 and a founding member of the Mediterranean Union upon its establishment in July 2008.
Etymology.
The first preserved mention of the name "Bosnia" is in "De Administrando Imperio", a politico-geographical handbook written by the Byzantine emperor Constantine VII in the mid-10th century (between 948 and 952) describing the "small country" (χωρίον in Greek) of "Bosona" (Βοσώνα). The Chronicle of the Priest of Duklja from 1172-1196 of Bar's Roman Catholic Christian Archbishop Grgur names Bosnia, and references an earlier source from the year of 753 - the De Regno Sclavorum (Of the Realm of Slavs). The name "Bosnia" probably comes from the name of the Bosna river around which it has been historically based, which was recorded in the Roman era under the name "Bossina". More direct roots of the river's names are unknown. Philologist Anton Mayer proposed a connection with the Indo-European root "*bos" or "*bogh", meaning "running water". Certain Roman sources similarly mention "Bathinus flumen" as a name of the Illyrian "Bosona", both of which would mean "running water" as well. Other theories involve the rare Latin term "Bosina", meaning boundary, and possible Slavic origins.
The origins of "Herzegovina" can be identified with more precision. During the Early Middle Ages the region was known as Hum, from the "Zachlumoi" tribe of southern Slavs which inhabited it. In the 1440s, the region was ruled by the powerful nobleman Stephen Vukčić Kosača. In a document sent to Friedrich III on January 20, 1448, Stefan Vukčić Kosača called himself "Herzog of Saint Sava, Lord of Hum and Primorje, Grand Duke of Bosnia". Herzog is the German for "duke", and so the lands he controlled later became known as "Herzegovina" ("Dukedom", from the addition of "-ovina", "land"). The region was administered by the Ottomans as the Sanjak of Herzegovina (Hersek), which was briefly elevated to the status of an Eyalet of Herzegovina in the 19th century.
On initial proclamation of independence in 1992 the country's official name was the "Republic of Bosnia and Herzegovina" but following the 1995 Dayton Agreement and the new constitution that accompanied it the name was officially changed to "Bosnia and Herzegovina".
History.
Early history.
Bosnia has been inhabited since at latest the Neolithic age. The earliest Neolithic population became known in the Antiquity as the Illyrians. Celtic migrations in the 4th century BC were also notable. Concrete historical evidence for this period is scarce, but overall it appears that the region was populated by a number of different peoples speaking distinct languages. Conflict between the Illyrians and Romans started in 229 BC, but Rome did not complete its annexation of the region until AD 9.
It was precisely in what is now Bosnia and Herzegovina that Rome fought one of the most difficult battles in its history since the Punic Wars, as described by the Roman historian Suetonius. This was the Roman campaign against the revolt of indigenous communities from Illyricum, known in history as the Great Illyrian Revolt, and also as the Pannonian revolt, or Bellum Batonianum, the latter named after two leaders of the rebellious Illyrian communities, Bato/Baton of the Daesitiates, and Bato of the Breuci.
The Great Illyrian revolt was a rising up of Illyrians against the Romans, more specifically a revolt against Tiberius' attempt to recruit them for his war against the Germans. The Illyrians put up a fierce resistance to the most powerful army on earth at the time (the Roman Army) for four years (AD 6 to AD 9), but they were finally subdued by Rome in AD 9.
The last Illyrian stronghold, of which their defence won the admiration of Roman historians, is said to have been Arduba. Bato of Daesitiates was captured and taken to Italy. It is alleged that when Tiberius asked Bato and the Daesitiates why they had rebelled, Baton was reputed to have answered: ""You Romans are to blame for this; for you send as guardians of your flocks, not dogs or shepherds, but wolves"." Bato spent the rest of his life in the Italian town of Ravenna.
In the Roman period, Latin-speaking settlers from the entire Roman Empire settled among the Illyrians, and Roman soldiers were encouraged to retire in the region.
The land was originally part of Illyria up until the Roman occupation. Following the split of the Roman Empire between 337 and 395 AD, Dalmatia and Pannonia became parts of the Western Roman Empire. Some claim that the region was conquered by the Ostrogoths in 455 AD. It subsequently changed hands between the Alans and the Huns. By the 6th century, Emperor Justinian had reconquered the area for the Byzantine Empire. The Illyrians were conquered by the Avars in the 6th century.
However, the Illyrians did not entirely vanish from Bosnia and Herzegovina with the arrival of new cultures. A large part of the remaining Illyrian culture intermingled with those of new settlers, some of it is believed to have been adopted by the latter, and some survived up to date, such as architectural remains ( e.g.Daorson in Ošanići near Stolac), certain customs and traditions (e.g.tatooing, the 'gluha kola' dances, the 'ganga' singing, zig-zag and concentric circles in traditional decorations), place names (e.g. Čapljina, from 'čaplja', a south Slavic word for 'heron', coincides with 'Ardea', a Latin word for 'heron', and 'Ardea', in turn, bears striking similarity with the name of Ardiaei, the native Illyrian people of the wider Neretva valley region, where the town of Čapljina is situated), etc.
Medieval Bosnia.
Modern knowledge of the political situation in the west Balkans into the region in the late 9th century. The Slavic tribes also brought their mythology and pagan system of beliefs, the "Rodovjerje". In particular, Perun / Перун, the highest god of the pantheon and the god of thunder and lightning is also commonly found in Bosnian toponymy, for instance in the name of "Mount Perun" ("Perunova Gora" / "Перунова Гора").
Along with the Slavic settlers, the native Illyrians were Christianized. Bosnia and Herzegovina, because of its geographic position and terrain, was probably one of the last areas to go through this process, which presumably originated from the urban centers along the Dalmatian coast. Thus, Slavic Bosnian tribes remained pagans for a longer time, and finally converted to Christianity.
The principalities of Serbia and Croatia split control of Bosnia and Herzegovina in the 9th and 10th century, but by the High Middle Ages political circumstance led to the area being contested between the Kingdom of Hungary and the Byzantine Empire. Following another shift of power between the two in the early 12th century, Bosnia found itself outside the control of both and emerged as an independent state under the rule of local "bans".
The first Bosnian monarch was Ban Borić. The second was Ban Kulin whose rule marked the start of a controversy with the Bosnian Church, because he allowed an indigenous Bogomilism sect considered heretical by the Roman Catholic Church. In response to Hungarian attempts to use church politics regarding the issue as a way to reclaim sovereignty over Bosnia, Kulin held a council of local church leaders to renounce the heresy and embraced Catholicism in 1203. Despite this, Hungarian ambitions remained unchanged long after Kulin's death in 1204, waning only after an unsuccessful invasion in 1254.
Bosnian history from then until the early 14th century was marked by a power struggle between the Šubić and Kotromanić families. This conflict came to an end in 1322, when Stephen II Kotromanić became "Ban". By the time of his death in 1353, he was successful in annexing territories to the north and west, as well as Zahumlje and parts of Dalmatia. He was succeeded by his nephew Tvrtko who, following a prolonged struggle with nobility and inter-family strife, gained full control of the country in 1367. Tvrtko crowned himself in 1377 as Stephen Tvrtko I the King of "Serbia, Bosnia, Pomorje, and the Western lands".
Based on archaeological evidence, he was crowned in Mile near Visoko in the church which was built in the time of Stephen II Kotromanić's reign, where he was also buried alongside his uncle Stjepan II. Following his death in 1391 however, Bosnia fell into a long period of decline. The Ottoman Empire had already started its conquest of Europe and posed a major threat to the Balkans throughout the first half of the 15th century. Finally, after decades of political and social instability, the Kingdom of Bosnia ceased to exist in 1463.
Ottoman Era (1463–1878).
The Ottoman conquest of Bosnia marked a new era in the country's history and introduced drastic changes in the political and cultural landscape. The Ottomans allowed for the preservation of Bosnia's identity by incorporating it as an integral province of the Ottoman Empire with its historical name and territorial integrity — a unique case among subjugated states in the Balkans.
Within Bosnia the Ottomans introduced a number of key changes in the territory's socio-political administration; including a new landholding system, a reorganization of administrative units, and a complex system of social differentiation by class and religious affiliation.
The three centuries of Ottoman rule also had a drastic impact on Bosnia's population make-up, which changed several times as a result of the empire's conquests, frequent wars with European powers, forced and economic migrations, and epidemics. A native Slavic-speaking Muslim community emerged and eventually became the largest of the ethno-religious groups due to lack of strong Christian church organizations and continuous rivalry between orthodox and catholic churches.
The Bosnian Christian communities also experienced major changes. The Bosnian Franciscans (and the Catholic population as a whole) were to a minor extent protected by official imperial decree, while the Bosnian Church disappeared altogether.
As the Ottoman Empire continued their rule in the Balkans (Rumelia), Bosnia was somewhat relieved of the pressures of being a frontier province, and experienced a period of general welfare. A number of cities, such as Sarajevo and Mostar, were established and grew into regional centers of trade and urban culture and were then visited by Ottoman traveler Evliya Çelebi in 1648. Within these cities, various Ottoman Sultans financed the construction of many works of Bosnian architecture such as the country's first library in Sarajevo, madrassas, a school of Sufi philosophy, and a clock tower ("Sahat Kula"), bridges such as the Stari Most, the Tsar's Mosque and the Gazi Husrev-beg's Mosque.
Furthermore, some Bosnians played influential roles in the Ottoman Empire's cultural and political history during this time. Bosnian recruits formed a large component of the Ottoman ranks in the battles of Mohács and Krbava field, while numerous other Bosnians rose through the ranks of the Ottoman military to occupy the highest positions of power in the Empire, including admirals such as Matrakçı Nasuh; generals such as Isa-Beg Isaković, Gazi Husrev-beg and Telli Hasan Pasha; administrators such as Ferhat-paša Sokolović and Osman Gradaščević; and Grand Viziers such as the influential Mehmed Paša Sokolović. Some Bosnians emerged as Sufi mystics, scholars such as Ali Džabič; and poets in the Turkish, Albanian, Arabic, and Persian languages.
However, by the late 17th century the Empire's military misfortunes caught up with the country, and the conclusion of the Great Turkish War with the treaty of Karlowitz in 1699 once again made Bosnia the Empire's westernmost province. The following century was marked by further military failures, numerous revolts within Bosnia, and several outbursts of plague. The Porte's false efforts at modernizing the Ottoman state were met with distrust growing to hostility in Bosnia, where local aristocrats stood to lose much through the proposed reforms.
This, combined with frustrations over political concessions to nascent Christian states in the east, culminated in a partially unsuccessful revolt by Husein Gradaščević, in 1831 after the Turkish Sultan Mahmud II slaughtered and abolished the Janissary. Related rebellions would be extinguished by 1850, but the situation continued to deteriorate. Later agrarian unrest eventually sparked the Herzegovinian rebellion, a widespread peasant uprising, in 1875. The conflict rapidly spread and came to involve several Balkan states and Great Powers, a situation which eventually led to the Congress of Berlin and the Treaty of Berlin in 1878.
Austro-Hungarian rule (1878–1918).
At the Congress of Berlin in 1878, the Austro-Hungarian Foreign Minister Gyula Andrássy obtained the occupation and administration of Bosnia and Herzegovina, and he also obtained the right to station garrisons in the Sanjak of Novi Pazar, which remained under Ottoman administration. The Sanjak preserved the separation of Serbia and Montenegro, and the Austro-Hungarian garrisons there would open the way for a dash to Salonika that "would bring the western half of the Balkans under permanent Austrian influence." "High military authorities desired [an... immediate major expedition with Salonika as its objective."
On 28 September 1878 the Finance Minister, Koloman von Zell, threatened to resign if the army, backed by the Archduke Albert, were allowed to advance to Salonika. In the session of the Hungarian Parliament of 5 November 1878 the Opposition proposed that the Foreign Minister should be impeached for violating the constitution with his policy during the Near East Crisis and by the occupation of Bosnia-Herzegovina. The motion lost 179 to 95. The gravest accusations were raised by the opposition rank and file against Andrassy.
Although an Austro-Hungarian side quickly came to an agreement with Bosnians, tensions remained in certain parts of the country (particularly the south) and a mass emigration of predominantly Slavic dissidents occurred. However, a state of relative stability was reached soon enough and Austro-Hungarian authorities were able to embark on a number of social and administrative reforms which intended to make Bosnia and Herzegovina into a "model colony".
With the aim of establishing the province as a stable political model that would help dissipate rising South Slav nationalism, Habsburg rule did much to codify laws, to introduce new political practices, and to provide for modernisation. The Austro-Hungarian Empire built the three Roman Catholic churches in Sarajevo and these three churches are among only 20 Catholic churches in the state of Bosnia.
Within three years of formal occupation of Bosnia Herzegovina, Austria-Hungary, in 1881, obtained German, and more importantly, Russian, approval for the annexation of these provinces, at a time which suited Vienna. This mandate was formally ratified by the Dreikaiserbund (Three Emperor's Treaty) on June 18 of that year. Upon the accession of Czar Nicholas II, however, the Russians reneged on the agreement, asserting in 1897 the need for special scrutiny of the Bosnian Annexation issue at an unspecified future date.
External matters began to affect the Bosnian Protectorate, however, and its relationship with Austria-Hungary. A bloody coup occurred in Serbia, on June 10, 1903, which brought a radical anti-Austrian government into power in Belgrade. Serb attempts to foment agitation followed, advocating a unified South Slavic state, ruled from Belgrade. This gained little support amongst most of the population of Bosnia Herzegovina, and only found fertile ground with disaffected portions of the Orthodox minority. Also, the revolt in the Ottoman Empire in 1908, raised concerns that the Istanbul government might seek the outright return of Bosnia Herzegovina. These factors caused the Austrian-Hungarian government to seek a permanent resolution of the Bosnian question, sooner, rather than later.
On July 2, 1908, in response to the pressing of the Austrian-Hungarian claim, the Russian Imperial Foreign Minister Alexander Izvolsky offered to support the Bosnian Annexation in return for Vienna's support for Russia's bid for naval access through the Dardanelles Straits into the Mediterranean. With the Russians being, at least, provisionally willing to keep their word over Bosnia Herzegovina for the first time in 11 years, Austria-Hungary waited and then published the annexation proclamation on October 6, 1908. The international furor over the annexation announcement caused Izvolsky to drop the Dardanelles Straits question, altogether, in an effort to obtain a European conference over the Bosnian Annexation. This conference never materialized and without British or French support, the Russians and their client state, Serbia, were compelled to accept the Austrian-Hungarian annexation of Bosnia Herzegovina in March 1909.
Political tensions culminated on 28 June 1914, when Serb nationalist youth Gavrilo Princip, a member of the Serb movement, Young Bosnia, assassinated the heir to the Austro-Hungarian throne, Archduke Franz Ferdinand, in Sarajevo – an event that proved to be the spark that set off World War I. Although some Bosnians died serving in the armies of the various warring states, Bosnia and Herzegovina itself managed to escape the conflict relatively unscathed.
Kingdom of Yugoslavia (1918–1941).
Following the war, Bosnia and Herzegovina joined the South Slav Kingdom of Serbs, Croats and Slovenes (soon renamed Yugoslavia). Political life in Bosnia at this time was marked by two major trends: social and economic unrest over property redistribution, and formation of several political parties that frequently changed coalitions and alliances with parties in other Yugoslav regions. The dominant ideological conflict of the Yugoslav state, between Croatian regionalism and Serbian centralization, was approached differently by Bosnia's major ethnic groups and was dependent on the overall political atmosphere. The political reforms brought about in the newly established Yugoslavian kingdom saw few benefits for the Bosniaks; according to the 1910 final census of land ownership and population according to religious affiliation conducted in Austro-Hungary, Muslims (Bosniaks) owned 91.1%, Orthodox Serbians owned 6.0%, Croatian Catholics owned 2.6% and others, 0.3% of the property. Following the reforms Bosnian Muslims had a total of 1,175,305 hectares of agricultural and forest land taken away from them.
Although the initial split of the country into 33 oblasts erased the presence of traditional geographic entities from the map, the efforts of Bosnian politicians such as Mehmed Spaho ensured that the six oblasts carved up from Bosnia and Herzegovina corresponded to the six sanjaks from Ottoman times and, thus, matched the country's traditional boundary as a whole.
The establishment of the Kingdom of Yugoslavia in 1929, however, brought the redrawing of administrative regions into banates or "banovinas" that purposely avoided all historical and ethnic lines, removing any trace of a Bosnian entity. Serbo-Croat tensions over the structuring of the Yugoslav state continued, with the concept of a separate Bosnian division receiving little or no consideration.
The Cvetković-Maček Agreement that created the Croatian banate in 1939 encouraged what was essentially a partition of Bosnia between Croatia and Serbia. However the rising threat of Adolf Hitler's Nazi Germany forced Yugoslav politicians to shift their attention. Following a period that saw attempts at appeasement, the signing of the Tripartite Treaty, and a coup d'état, Yugoslavia was finally invaded by Germany on 6 April 1941.
World War II (1941–45).
Once the kingdom of Yugoslavia was conquered by Nazi forces in World War II, all of Bosnia was ceded to the Nazi puppet regime, Independent State of Croatia.
The Croat leaders embarked on a campaign of extermination of Serbs, Jews, Roma, Croats who opposed the regime, communists and large numbers of Josip Broz Tito's Partisans by setting up a number of death camps.
Many Serbs themselves took up arms and joined the Chetniks, a Serb nationalist movement that conducted operations against the Nazi forces and the partisans. The Chetniks were also known to persecute and murder non-Serbs and communist sympathizers. They committed many war crimes against Bosnian Muslims in Eastern Bosnia. On October 12, 1941 a group of 108 notable Muslim citizens of Sarajevo signed the Resolution of Sarajevo Muslims by which they condemned the persecution of Serbs organized by Ustaše, made distinction between Muslims who participated in such persecutions and whole Muslim population, presented informations about the persecutions of Muslims by Serbs and requested security for all citizens of the country, regardless of their identity. Later, many Bosnian Muslims served in the Waffen-SS units.
Starting in 1941, Yugoslav communists under the leadership of Josip Broz Tito organized their own multi-ethnic resistance group, the partisans, who fought against both Axis and Chetnik forces. On 29 November 1943 the Anti-Fascist Council of National Liberation of Yugoslavia with Tito at its helm held a founding conference in Jajce where Bosnia and Herzegovina was reestablished as a republic within the Yugoslavian federation in its Habsburg borders.
Military success eventually prompted the Allies to support the Partisans, but Tito declined their offer to help and relied on his own forces instead. All the major military offensives by the antifascist movement of Yugoslavia against Nazis and their local supporters were conducted in Bosnia-Herzegovina and its peoples bore the brunt of fighting. More than 300,000 people died in Bosnia and Herzegovina in World War II. At the end of the war the establishment of the Socialist Federal Republic of Yugoslavia, with the constitution of 1946, officially made Bosnia and Herzegovina one of six constituent republics in the new state.
Socialist Yugoslavia (1945–1992).
Because of its central geographic position within the Yugoslavian federation, post-war Bosnia was selected as a base for the development of the military defense industry. This contributed to a large concentration of arms and military personnel in Bosnia; a significant factor in the war that followed the break-up of Yugoslavia in the 1990s. However, Bosnia's existence within Yugoslavia, for the large part, was peaceful and prosperous.
Though considered a political backwater of the federation for much of the 1950s and 1960s, in the 1970s a strong Bosnian political elite arose, fueled in part by Tito's leadership in the Non-Aligned Movement and Bosnians serving in Yugoslavia's diplomatic corps.
While working within the communist system, politicians such as Džemal Bijedić, Branko Mikulić and Hamdija Pozderac reinforced and protected the sovereignty of Bosnia and Herzegovina Their efforts proved key during the turbulent period following Tito's death in 1980, and are today considered some of the early steps towards Bosnian independence. However, the republic did not escape the increasingly nationalistic climate of the time. With the fall of the Soviet Union and the start of the break-up of Yugoslavia, the old communist doctrine of tolerance began to lose its potency, creating an opportunity for nationalist elements in the society to spread their influence.
Bosnian War for independence (1992–1995).
On 18 November 1990 the first multi-party parliamentary elections were held (with a second round on 25 November), which resulted in a national assembly dominated by three ethnically based parties, which had formed a loose coalition to oust the communists from power. Croatia and Slovenia's subsequent declarations of independence and the warfare that ensued placed Bosnia and Herzegovina and its three constituent peoples in an awkward position. A significant split soon developed on the issue of whether to stay with the Yugoslav federation (overwhelmingly favored among Serbs) or seek independence (overwhelmingly favored among Bosniaks and Croats).
The Serb members of parliament, consisting mainly of the Serb Democratic Party members, abandoned the central parliament in Sarajevo, and formed the Assembly of the Serb People of Bosnia and Herzegovina on 24 October 1991, which marked the end of the tri-ethnic coalition that governed after the elections in 1990. This Assembly established the Serbian Republic of Bosnia and Herzegovina on 9 January 1992, which became Republika Srpska in August 1992.
On 18 November 1991, the party branch in Bosnia and Herzegovina of the ruling party in the Republic of Croatia, the Croatian Democratic Union (HDZ), proclaimed the existence of the Croatian Community of Herzeg-Bosnia, as a separate "political, cultural, economic and territorial whole", on the territory of Bosnia and Herzegovina, with Croat Defence Council (HVO) as its military part. The Bosnian government did not recognize it. The Constitutional Court of Bosnia and Herzegovina declared Herzeg-Bosnia illegal, first on 14 September 1992 and again on 20 January 1994.
A declaration of Bosnia and Herzegovina sovereignty on 15 October 1991 was followed by a referendum for independence from Yugoslavia on 29 February and 1 March 1992 boycotted by the great majority of the Serbs. The turnout in the independence referendum was 63.4 per cent and 99.7 per cent of voters voted for independence. Bosnia and Herzegovina declared independence on 3 March 1992. Following a tense period of escalating tensions the opening shots in the incipient Bosnian conflict were fired when Serb paramilitary forces attacked Bosnian Croat villages around Capljina on 7 March 1992 and around Bosanski Brod and Bosniak town Gorazde on 15 March. These minor attacks were followed by much more serious Serb artillery attacks on Neum on 19 March and on Bosanski Brod on 24 March. The killing of a Bosniak civilian woman (Suada Dilberović), on 5 April 1992 by a sniper, while she was demonstrating in Sarajevo against the raising of barricades by Bosnian Serbs, is widely regarded as marking the start of warfare between the three major communities.
Secret discussions between Franjo Tuđman and Slobodan Milošević on the division of Bosnia and Herzegovina between Serbia and Croatia were held as early as March 1991, known as the Karađorđevo agreement. Following the declaration of independence of the Republic of Bosnia and Herzegovina, the Serbs attacked different parts of the country. The state administration of Bosnia and Herzegovina effectively ceased to function having lost control over the entire territory. The Serbs wanted control and possession of virtually all territories in Bosnia and Herzegovina, as a top priority of their mastermind plan of a "Greater Serbia".
The Croats and their leader Tuđman also aimed at securing the remaining parts of Bosnia and Herzegovina as exclusively Croatian. The policies of the Republic of Croatia and its leader Franjo Tuđman towards Bosnia and Herzegovina were never totally transparent and always included Franjo Tuđman's ultimate aim of expanding Croatia's borders. Bosnian Muslims were an easy target, because the Bosnian government forces were poorly equipped and unprepared for the war.
International recognition of Bosnia and Herzegovina increased diplomatic pressure for the Yugoslav People's Army (JNA) to withdraw from the republic's territory which they officially did. However, in fact, the Bosnian Serb members of JNA simply changed insignia, formed the Army of Republika Srpska, and continued fighting. Armed and equipped from JNA stockpiles in Bosnia, supported by volunteers and various paramilitary forces from Serbia, and receiving extensive humanitarian, logistical and financial support from the Federal Republic of Yugoslavia, Republika Srpska's offensives in 1992 managed to place much of the country under its control.
Initially, the Serb forces attacked the non-Serb civilian population in Eastern Bosnia. Once towns and villages were securely in their hands, the Serb forces – military, police, the paramilitaries and, sometimes, even Serb villagers – applied the same pattern: Bosniak houses and apartments were systematically ransacked or burnt down, Bosniak civilians were rounded up or captured, and sometimes beaten or killed in the process. 2.2 million refugees were displaced by the end of the war (of all three nationalities).
Men and women were separated, with many of the men detained in the camps. The women and indeed some children, as young as twelve years of age, were kept in various detention centres where they had to live in intolerably unhygienic conditions, where they were mistreated in many ways including being raped repeatedly. Serb soldiers or policemen would come to these detention centres, select one or more women, take them out and rape them.
In June 1992 the focus switched to Novi Travnik and Gornji Vakuf where the Croat Defence Council (HVO) efforts to gain control were resisted. On 18 June 1992 the Bosnian Territorial Defence in Novi Travnik received an ultimatum from the HVO which included demands to abolish existing Bosnia and Herzegovina institutions, establish the authority of the Croatian Community of Herzeg-Bosnia and pledge allegiance to it, subordinate the Territorial Defense to the HVO and expel Muslim refugees, all within 24 hours. The attack was launched on June 19. The elementary school and the Post Office were attacked and damaged.
Gornji Vakuf was initially attacked by Croats on 20 June 1992, but the attack failed. The Graz agreement caused deep division inside the Croat community and strengthened the separation group, which led to the conflict with Bosniaks. One of the primary pro-union Croat leaders, Blaž Kraljević (leader of the Croatian Defence Forces (HOS) armed group) was killed by HVO soldiers in August 1992, which severely weakened the moderate group who hoped to keep the Bosnian Croat alliance alive.
The situation became more serious in October 1992 when Croat forces attacked the Bosniak population in Prozor. According to "Jadranko Prlić indictment", HVO forces cleansed most of the Muslims from the town of Prozor and several surrounding villages.
By 1993, when an armed conflict erupted between the predominantly Bosniak government in Sarajevo and the Croatian Republic of Herzeg-Bosnia, about 70% of the country was controlled by Republika Srpska. Ethnic cleansing and civil rights violations against non-Serbs were rampant in these areas. DNA teams have been used to collect evidence of the atrocities committed by Serbian forces during these campaigns. One single most prominent example is the Srebrenica Massacre, ruled genocide by the International Criminal Tribunal for the former Yugoslavia. An estimated 8,372 Bosnians were killed by the Serbian political authorities.
In March 1994, the signing of the Washington Accords between the leaders of the republican government and Herzeg-Bosnia led to the creation of a joint Bosniak-Croat Federation of Bosnia and Herzegovina, which absorbed the territory of the Croatian Republic of Herzeg-Bosnia and that held by the Army of the Republic of Bosnia and Herzegovina. The Federation soon liberated the small Autonomous Province of Western Bosnia.
A NATO bombing campaign began in August, 1995, against the Army of Republika Srpska, after the Srebrenica massacre. Meanwhile, a ground offensive by the allied forces of Croatia and Bosnia, based on the treaty in Split by Tudjman and Izetbegović, pushed the Serbs away from territories held in western Bosnia which paved the way to negotiations.
In December 1995, the signing of the Dayton Agreement in Dayton, Ohio by the presidents of Bosnia and Herzegovina (Alija Izetbegović), Croatia (Franjo Tuđman), and Serbia (Slobodan Milošević) brought a halt to the fighting, roughly establishing the basic structure of the present-day state. A NATO-led peacekeeping force was immediately dispatched to Bosnia to enforce the deal.
The number of identified victims is currently at 97,207, and the recent research estimates the total number to be less than 110,000 killed (civilians and military), and 1.8 million displaced. This is being addressed by the International Commission on Missing Persons.
According to numerous International Criminal Tribunal for the former Yugoslavia (ICTY) judgements the conflict involved Bosnia and the Federal Republic of Yugoslavia (later Serbia and Montenegro) as well as Croatia.
The Bosnian government charged Serbia of complicity in genocide in Bosnia during the war at the International Court of Justice (ICJ). The ICJ ruling of 26 February 2007 effectively determined the war's nature to be international, though exonerating Serbia of direct responsibility for the genocide committed by Serb forces of Republika Srpska. The ICJ concluded, however, that Serbia failed to prevent genocide committed by Serb forces and failed to punish those who carried out the genocide, especially general Ratko Mladić, and bring them to justice.
Ratko Mladić was arrested in a village in northern Serbia on 26 May 2011, being accused of directly orchestrating and overseeing the slaughter of 8,000 Muslim men and boys, amongst other genocide and war crime charges.
The judges ruled that the criteria for genocide with the specific intent ("dolus specialis") to destroy Bosnian Muslims were met only in Srebrenica or Eastern Bosnia in 1995.
The court concluded that the crimes committed during the 1992–1995 war, may amount to crimes against humanity according to the international law, but that these acts did not, in themselves, constitute genocide. The Court further decided that, following Montenegro's declaration of independence in June 2006, Serbia was the only respondent party in the case, but that "any responsibility for "past" events involved at the relevant time the composite State of Serbia and Montenegro".
Geography.
Bosnia is located in the western Balkans, bordering Croatia () to the north and south-west, Serbia () to the east, and Montenegro () to the southeast. It lies between latitudes 42° and 46° N, and longitudes 15° and 20° E.
The country's name comes from the two regions Bosnia and Herzegovina, which have a very vaguely defined border between them. Bosnia occupies the northern areas which are roughly four-fifths of the entire country, while Herzegovina occupies the rest in the south part of the country.
The country is mostly mountainous, encompassing the central Dinaric Alps. The northeastern parts reach into the Pannonian basin, while in the south it borders the Adriatic. Dinaric Alps generally run in east-west direction, and get higher towards the south. The highest point of the country is peak Maglić at 2,386 m, at the Montenegrin border. Major mountains include Kozara, Grmeč, Vlašić, Čvrsnica, Prenj, Romanija, Jahorina, Bjelašnica and Treskavica.
Overall, close to 50% of Bosnia and Herzegovina is forested. Most forest areas are in Central, Eastern and Western parts of Bosnia. Herzegovina has drier Mediterranean climate, with dominant karst topography. Northern Bosnia (Posavina) contains very fertile agricultural land along the river Sava and the corresponding area is heavily farmed. This farmland is a part of the Parapannonian Plain stretching into neighboring Croatia and Serbia. The country has only 20 kilometers (12 mi) of coastline, around the town of Neum in the Herzegovina-Neretva Canton. Although the city is surrounded by Croatian peninsulas, by the international law, Bosnia and Herzegovina has a right of passage to the outer sea.
The major cities are the capital Sarajevo, Banja Luka in the northwest region known as Bosanska Krajina, Bijeljina and Tuzla in the northeast, Zenica and Doboj in the central part of Bosnia and Mostar, the capital of Herzegovina.
There are seven major rivers in Bosnia and Herzegovina
Phytogeographically, Bosnia and Herzegovina belongs to the Boreal Kingdom and is shared between the Illyrian province of the Circumboreal Region and Adriatic province of the Mediterranean Region. According to the WWF, the territory of Bosnia and Herzegovina can be subdivided into three ecoregions: the Pannonian mixed forests, Dinaric Mountains mixed forests and Illyrian deciduous forests.
Government and politics.
Bosnia and Herzegovina has several levels of political structuring, according to the Dayton accord. The most important of these levels is the division of the country into two entities: Republika Srpska and the Federation of Bosnia and Herzegovina. The Federation of Bosnia and Herzegovina covers 51% of Bosnia and Herzegovina's total area, while Republika Srpska covers 49%. The entities, based largely on the territories held by the two warring sides at the time, were formally established by the Dayton peace agreement in 1995 because of the tremendous changes in Bosnia and Herzegovina's ethnic structure. Since 1996 the power of the entities relative to the State government has decreased significantly. Nonetheless, entities still have numerous powers to themselves. The Brčko District in the north of the country was created in 2000 out of land from both entities. It officially belongs to both, but is governed by neither, and functions under a decentralized system of local government. The Brčko District has been praised for maintaining a multiethnic population and a level of prosperity significantly above the national average.
The third level of Bosnia and Herzegovina's political subdivision is manifested in cantons. They are unique to the Federation of Bosnia and Herzegovina entity, which consists of ten of them. All of them have their own cantonal government, which is under the law of the Federation as a whole. Some cantons are ethnically mixed and have special laws implemented to ensure the equality of all constituent people.
The fourth level of political division in Bosnia and Herzegovina is the municipalities. The Federation of Bosnia and Herzegovina is divided in 74 municipalities, and Republika Srpska in 63. Municipalities also have their own local government, and are typically based on the most significant city or place in their territory. As such, many municipalities have a long tradition and history with their present boundaries. Some others, however, were only created following the recent war after traditional municipalities were split by the Inter-Entity Boundary Line. Each canton in the Federation of Bosnia and Herzegovina consists of several municipalities, which are divided into local communities.
Besides entities, cantons, and municipalities, Bosnia and Herzegovina also has four "official" cities. These are: Banja Luka, Mostar, Sarajevo, and East Sarajevo. The territory and government of the cities of Banja Luka and Mostar corresponds to the municipalities of the same name, while the cities of Sarajevo and East Sarajevo officially consist of several municipalities. Cities have their own city government whose power is in between that of the municipalities and cantons (or the entity, in the case of Republika Srpska).
As a result of the Dayton Accords, the civilian peace implementation is supervised by the High Representative for Bosnia and Herzegovina selected by the Peace Implementation Council. The High Representative has many governmental and legislative powers, including the dismissal of elected and non-elected officials. More recently, several central institutions have been established (such as defense ministry, security ministry, state court, indirect taxation service and so on) in the process of transferring part of the jurisdiction from the entities to the state.
The representation of the government of Bosnia and Herzegovina is by elites who represent the country's three major groups, with each having a guaranteed share of power.
The Chair of the Presidency of Bosnia and Herzegovina rotates among three members (Bosniak, Serb, Croat), each elected as the Chair for an eight-month term within their four-year term as a member. The three members of the Presidency are elected directly by the people with Federation voters voting for the Bosniak and the Croat, and the Republika Srpska voters for the Serb.
The Chair of the Council of Ministers is nominated by the Presidency and approved by the House of Representatives. He or she is then responsible for appointing a Foreign Minister, Minister of Foreign Trade, and others as appropriate.
The Parliamentary Assembly is the lawmaking body in Bosnia and Herzegovina. It consists of two houses: the House of Peoples and the House of Representatives. The House of Peoples has 15 delegates, two-thirds of which come from the Federation (5 Croat and 5 Bosniaks) and one-third from the Republika Srpska (5 Serbs). The House of Representatives is composed of 42 Members, two-thirds elected from the Federation and one-third elected from the Republika Srpska.
The Constitutional Court of Bosnia and Herzegovina is the supreme, final arbiter of legal matters. It is composed of nine members: four members are selected by the House of Representatives of the Federation, two by the Assembly of the Republika Srpska, and three by the President of the European Court of Human Rights after consultation with the Presidency.
However, the highest political authority in the country is the High Representative in Bosnia and Herzegovina, the chief executive officer for the international civilian presence in the country. Since 1995, the High Representative has been able to bypass the elected parliamentary assembly, and since 1997 has been able to remove elected officials. The methods selected by the High Representative have been criticized as undemocratic. International supervision is to end when the country is deemed politically and democratically stable and self-sustaining.
Military.
The Armed Forces of Bosnia and Herzegovina were unified into a single entity in 2005, with the merger of the Army of the Federation of Bosnia and Herzegovina and the Army of Republika Srpska, which had defended their respective regions. The Ministry of Defense had been founded in 2004.
The Bosnian military consists of the Bosnian Ground Forces and Air Force and Air Defense. The Ground Forces number 10,000 active and 5,000 reserve personnel. They are armed with a mix of American, Yugoslavian, Soviet, and European-made weaponry, vehicles, and military equipment. The Air Force and Air Defense Forces has 2,500 personnel and about 45 aircraft. All of its aircraft are utility helicopters and basic trainers. The Air Defense Forces operate MANPAD hand-held missiles, SAM missile batteries, anti-aircraft cannons, and radar. Almost all of its anti-aircraft equipment is of Soviet origin, though it also operates some U.S. and Swedish hardware.
Foreign relations.
EU integration is one of the main political objectives of Bosnia and Herzegovina, it initiated the Stabilisation and Association Process in 2007. Countries participating in the SAP have been offered the possibility to become, once they fulfill the necessary conditions, Member States of the EU. Bosnia and Herzegovina is therefore a potential candidate country for EU accession. The implementation of the Dayton Accords of 1995 has focused the efforts of policymakers in Bosnia and Herzegovina, as well as the international community, on regional stabilization in the countries-successors of the former Yugoslavia. Within Bosnia and Herzegovina, relations with its neighbors of Croatia, Serbia and Montenegro have been fairly stable since the signing of the Dayton Agreement in 1995.
On April 23, 2010, Bosnia and Herzegovina received the Membership Action Plan from NATO, which is the last step before full membership in the alliance. Full membership is expected in 2014 or 2015, depending on the progress of reforms.
Demographics.
Bosnia and Herzegovina is home to three ethnic "constituent peoples": Bosniaks, Serbs and Croats. Tensions between the three constitutional peoples remain high and often provoke political disagreements.
According to the 1991 census, Bosnia and Herzegovina had a population of 4,377,000, while the 1996 UNHCR unofficial census showed a decrease to 3,920,000. Large population migrations during the Yugoslav wars in the 1990s have caused demographic shifts in the country. No census has been taken since 1991/96, and political disagreements have made it impossible to organize one. Nevertheless, a census has been planned for 2012. As almost all of the post-war data is simply an estimate, a census would be a statistical, inclusive, and objective way to analyze the demographics of Bosnia and Herzegovina. Most sources, however, estimate the population to be about four million, representing a decrease of 500,000 since 1991. The last official estimate by BHAS (Agency for Statistics of BiH) for 2011 shows a decrease of the population to 3,840,000. Other BHAS estimation of population done on 30 June 2009 is 3,843,000.
Ethnically, according to data from 2000 cited by the CIA, Bosniak constitute 48% of the population, Serbs 37.1%, Croats 14.3%, and others 0.6%, including Jews, Roma, and Albanians. According to unofficial estimates from the Bosnian State Statistics Agency cited by the US Department of State in 2008, 45 percent of the population identify religiously as Muslim, 36 percent as Serb Orthodox, 15 percent as Roman Catholic, 1 percent as Protestant, and 3 percent other (mostly atheists, Jews, and others). Bosnian, Croatian and Serbian are official languages, but all three are mutually intelligible standards of Serbo-Croatian. 
Economy.
Bosnia faces the dual problem of rebuilding a war-torn country and introducing market reforms to its formerly centrally planned economy. One legacy of the previous era is a greatly overstaffed military industry; under former leader Josip Broz Tito, military industries were promoted in the republic, resulting in the development of a large share of Yugoslavia's defense plants but fewer commercially-viable firms.
For the most of Bosnia's history, agriculture has been based on small and inefficient privately owned farms; food has traditionally been a net import for the republic.
The war in the 1990s caused a dramatic change in the Bosnian economy. GDP fell by 75% and the destruction of physical infrastructure devastated the economy. While much of the production capacity has been restored, the Bosnian economy still faces considerable difficulties. Figures show GDP and per capita income increased 10% from 2003 to 2004; this and Bosnia's shrinking national debt being positive trends, but high unemployment and a large trade deficit remain cause for concern.
The national currency is the (Euro-pegged) Convertible Mark (KM), controlled by the currency board. Annual inflation is the lowest relative to other countries in the region at 1.9% in 2004. The international debt was $3.1 billion (2005 est) – the smallest amount of debt owed of all the former Yugoslav republics. Real GDP growth rate was 5% for 2004 according to the Bosnian Central Bank of BiH and Statistical Office of Bosnia and Herzegovina.
Bosnia and Herzegovina has one of the highest income equality rankings in the world, ranking eighth out of 193 nations.
According to Eurostat data, Bosnia and Herzegovina's PPS GDP per capita stood at 29 per cent of the EU average in 2010.
The International Monetary Fund, IMF, announced a loan to Bosnia worth $500 million to be delivered within a Stand-By arrangement which should be approved in September 2012.
From 1994 to 2008, €5.3 billion were invested in the country.
The United States Embassy in Sarajevo, Bosnia and Herzegovina produces the Country Commercial Guide – an annual report that delivers a comprehensive look at Bosnia and Herzegovina’s commercial and economic environment, using economic, political, and market analysis. It can be viewed on Embassy Sarajevo’s website.
Communications.
The Bosnian communications market was fully liberalised in January 2006. There are three landline telephone providers, although each one predominantly serves a partile services are provided by three operators, with nationwide services. Mobile data services are also available, including high-speed EDGE and 3G services.
"Oslobođenje" (Liberation), founded in 1943, is one of the country's longest running continuously circulating newspapers. There are many national publications, only some of which include the "Dnevni Avaz" (Daily Voice), founded in 1995, and "Jutarnje Novine" (Morning News) in circulation in Sarajevo. Other local periodicals include the Croatian newspaper Hrvatska riječ and the Bosnian magazine Start, as well as the weekly newspapers "Slobodna Bosna" ("Free Bosnia") and "BH Dani" ("BH Days"). "Novi Plamen", a monthly magazine, is the most left-wing publication currently. The international news station Al Jazeera maintains a sister channel that caters to the Balkan region, Al Jazeera Balkans, broadcasting out of and based in Sarajevo.
Additionally, the country is the most liberated in terms of freedom of the press in the region, ranking 43rd internationally.
Tourism.
According to an estimation of the World Tourism Organization, Bosnia and Herzegovina will have the third highest tourism growth rate in the world between 1995 and 2020.
Lonely Planet, in ranking the best cities in the world, ranked Sarajevo, the national capital and host of the 1984 Winter Olympic Games, as #43, ahead of Dubrovnik at #59, Ljubljana at #84, Bled at #90, Belgrade at #113, and Zagreb at #135. Tourism in Sarajevo is chiefly focused on historical, religious, and cultural aspects. Bosnia has also become an increasingly popular skiing and Ecotourism destination.
More recently, Sarajevo was nominated as one of the top ten cities to visit in 2010 in that same year's edition of Lonely Planet's "Best In Travel". In March 2012, Sarajevo also won travel blog Foxnomad's "Best City to Visit" competition, beating out more than one hundred cities around the entire world.
Međugorje has become one of the most popular pilgrimage sites for Christians in the world and has turned into Europe's third most important religious place, where each year more than 1 million people visit. It has been estimated that 30 million pilgrims have come to Međugorje since the reputed apparitions began in 1981.
Bosnia and Herzegovina remains arguably one of the last undiscovered natural regions of the southern area of the Alps, with vast tracks of wild and untouched nature attracting adventurers and nature lovers. National Geographic magazine named Bosnia and Herzegovina as the best mountain biking adventure destination for 2012. The central Bosnian Dinaric Alps are favored by hikers and mountaineers, containing both Mediterreanean and Alpine climates. Whitewater rafting is somewhat of a national pastime, with three rivers, including the deepest river canyon in Europe, the Tara River Canyon.
Education.
Higher education has a long and rich tradition in Bosnia and Herzegovina, the first classifiable higher-education institution having been established a school of Sufi philosophy by Gazi Husrev-beg in 1531, with numerous other religious schools following suit over time. In 1887, under the Austro-Hungarian Empire, a Sharia Law School began a five-year program. In the 1940s the University of Sarajevo became the city's first secular higher education institute. In the 1950s post-bachelaurate graduate degrees became available. Severely damaged during the war, it was recently rebuilt in partnership with more than 40 other universities. There are various other institutions of higher education, including: University "Džemal Bijedić" of Mostar, University of Banja Luka, University of Mostar, University of Tuzla, American University in Bosnia and Herzegovina and the Academy of Sciences and Arts of Bosnia and Herzegovina, which is held in high regard as one of the most prestigious creative arts academies in the region.
Primary schooling lasts for nine years. Secondary education is provided by general and technical secondary schools (typically Gymnasiums where studies typically last for four years. All forms of secondary schooling include an element of vocational training. Pupils graduating from general secondary schools obtain the Matura and can enroll in any tertiary educational institution or academy by passing a qualification examination prescribed by the governing body or institution. Students graduating technical subjects obtain a Diploma.
Culture.
Architecture.
The architecture of Bosnia and Herzegovina is largely influenced by four major periods where political and social changes influenced the creation of distinct cultural and architectural habits of the population. Each period made its influence felt and contributed to a greater diversity of cultures and architectural language in this region.
Literature.
Bosnia and Herzegovina has a rich literature, including a Nobel prize winner Ivo Andrić and poets such as Antun Branko Šimić, Aleksa Šantić, Jovan Dučić and Mak Dizdar, writers such as Meša Selimović, Semezdin Mehmedinović, Miljenko Jergović, Isak Samokovlija, Safvet beg Bašagić, Abdulah Sidran, Petar Kočić, Aleksandar Hemon, and Nedžad Ibrišimović. The National Theater was founded 1919 in Sarajevo and its first director was famous drama-play writer Branislav Nušić.
Magazines such as "Novi Plamen" or "Sarajevske biljeznice" are some of the more prominent publications covering cultural and literary themes.
Art.
The art of Bosnia and Herzegovina was always evolving and ranged from the original medieval tombstones called Stećci to paintings in Kotromanić court. However, only with the arrival of Austro-Hungarians did the painting renaissance in Bosnia really begin to flourish. The first educated artists from European academies appeared with the beginning of 20th century. Among those are: Gabrijel Jurkić, Petar Tiješić, Karlo Mijić, Špiro Bocarić, Petar Šain, Đoko Mazalić, Roman Petrović and Lazar Drljača. Later, artists such as: Ismet Mujezinović, Vojo Dimitrijević, Ivo Šeremet, and Mica Todorović amongst others came to rise. After World War II artists like: Virgilije Nevjestić, Bekir Misirlić, Ljubo Lah, Meho Sefić, Franjo Likar, Mersad Berber, Ibrahim Ljubović, Dževad Hozo, Affan Ramić, Safet Zec, Ismar Mujezinović and Mehmed Zaimović rose in popularity. In 2007, Ars Aevi, a museum of contemporary art that includes works by renowned world artists was founded in Sarajevo.
Music.
Typical Bosnian and Herzegovinian songs are "ganga, rera", and the traditional Slavic music for the folk dances such as "kolo" and from Ottoman era the most popular is sevdalinka. Pop and Rock music has a tradition here as well, with the more famous musicians including Dino Zonić, Goran Bregović, Davorin Popović, Kemal Monteno, Zdravko Čolić, Edo Maajka, Hari Varesanovic and Dino Merlin. Very popular are also the numerous Slavic Metal bands, performing an interesting combination of upbeat tempos and traditional tunes. Among them "Silent Kingdom", "Emir Hot", "D'n'K", "Toxicdeath", "Agonize" and "Irina Kapetanović", often performing with folk metal musicians from other neighbouring Slavic countries like "Stribog" (Croatia), "Svarica" (Croatia/Bosnia) and "Arkona" (Russia).
Also, it would be unfair not to mention some of the talented composers such as Đorđe Novković, Esad Arnautalić, Kornelije Kovač, and many pop and rock bands, for example, Bijelo Dugme, Indexi, Plavi Orkestar, Zabranjeno Pušenje, who were among the leading ones in the former Yugoslavia. Bosnia is home to the composer Dušan Šestić, the creator of the current national anthem of Bosnia and Herzegovina and father of singer Marija Šestić, composer Saša Lošić and pianist Sasha Toperich. In the villages, especially in Herzegovina, Bosniaks, Serbs, and Croats play the ancient "Gusle". The gusle is used mainly to recite epic poems in a usually dramatic tone.
Cinema.
Bosnia has a rich cinematic and film heritage, dating back to the Kingdom of Yugoslavia; many Bosnian filmmakers have achieved international prominence and most have won international awards ranging from the Academy Awards to multiple Palme d'Ors and Golden Bears. Some notable Bosnian filmmakers, screenwriters and cinematographers are Academy Award-winner Danis Tanović (known for the Academy Award– and Golden Globe–winning 2001 film "No Man's Land"), Golden Bear-winning Jasmila Žbanić, Hajrudin Krvavac-Šiba, Mirza Idrizović, Aleksandar Jevđević, Ivica Matić, Ademir Kenović, the late Benjamin Filipović, Jasmin Dizdar, Pjer Žalica, Dino Mustafić, Srđan Vuletić, Aida Begić, among many others.
Sports.
Bosnia and Herzegovina has produced many athletes. Many of them were famous in the Yugoslav national teams before Bosnia and Herzegovina's independence.
The most important international sporting event in the history of Bosnia and Herzegovina was the hosting of the 14th Winter Olympics, held in Sarajevo from the 7th to 19 February 1984.
The Borac handball club has won seven Yugoslav Handball Championships, as well as the European Championship Cup in 1976 and the International Handball Federation Cup in 1991.
The Bosna basketball club from Sarajevo were European Champions in 1979. The Yugoslav national basketball team, which medaled in every world championship from 1963 through 1990, included Bosnian players such as Dražen Dalipagić and Mirza Delibašić. Bosnia and Herzegovina regularly qualifies for the European Championship in Basketball. Jedinstvo Aida women's basketball club, based in Tuzla, has won the 1989 European Championships in Florence.
Bosnia has produced many world-class basketball players, notably Mirza Teletović, the first Bosnian in the NBA, who has signed a three year deal with Brooklyn Nets. Among others are, Elmedin Kikanović, Nihad Đedović, Ognjen Kuzmić, Jusuf Nurkić, Nedžad Sinanović, and Nemanja Mitrović.
The Tuzla-Sinalco karate club from Tuzla has won the most Yugoslav championships, as well as four European Championships and one World Championship.
The Bosnian chess team has been Champion of Yugoslavia seven times, in addition to club ŠK Bosna Sarajevo winning four Chess Club Cup : 1994 in Lyon, 1999 in Bugojno, 2000 in Neum, and 2001 in Kallithea Elassonos. Chess grandmaster Borki Predojević has also won two European Championships: Under-12 years Litochoro (Greece) in 1999, and Under-14 years Kallithea Elassonos (Greece) in 2001, and in 2003 won World Championship Under-16 years Halkidiki (Greece). The most impressive success of Bosnian Chess was his runner-up position in Men´s Olympiads of 1994 in Moscow, featuring Grandmasters Predrag Nikolić, Ivan Sokolov, Bojan Kurajica and Emir Dizdarević.
Middle-weight boxer Marijan Beneš has won several Championships of Bosnia and Herzegovina, Yugoslav Championships and the European Championship. In 1978 he won the World Title against Elisha Obed from the Bahamas. Another middle-weight boxer, Anton Josipović won the Olympic Gold in Los Angeles, 1984. He also won Yugoslav Championship in 1982, the Championship of the Balkans in 1983, and the Belgrade Trophy in 1985.
Association football is the most popular sport in Bosnia and Herzegovina. It dates from 1903, but its popularity grew significantly after World War I. At the local level, FK Sarajevo (1967 and 1984), Željezničar (1972) have both won the Yugoslav Championship. The former Yugoslav national football team has included a number of Bosnian players, such as Josip Katalinski, Blaž Slišković, Dušan Bajević, Enver Marić, Mehmed Baždarević, Ivica Osim, Safet Sušić, Vahidin Musemić and Mirsad Fazlagić.
Today, the team of Bosnia and Herzegovina has modern footballers like Edin Džeko, Zvjezdan Misimović, Vedad Ibišević, Emir Spahić, Asmir Begović, Miralem Pjanić, Sejad Salihović, Senad Lulić and others. The independent Bosnia and Herzegovina national football team has not qualified for a European or World Championship but has played twice in the play-off stages. For all time matches: Bosnia and Herzegovina national football team results (1995-2011).
Bosnian national teams have struggled to draft the best national players. Many players born in Bosnia and Herzegovina choose to play for other countries because of their ethnic identification. For example Nikica Jelavić and Vedran Ćorluka were both born in Bosnia and Herzegovina but play for Croatia. Other internationally famous players from Bosnia and Herzegovina, who have made similar choices, are: Dejan Lovren, Mladen Petrić, Mario Stanić, Neven Subotić, Zlatan Ibrahimović (born and raised in Sweden, his mother a Croat, his father a Bosnian), Marko Marin, Boris Živković, Zlatko Junuzović, Savo Milošević, and Zdravko Kuzmanović.
Bosnia and Herzegovina was the world champion of volleyball at the 2004 Summer Paralympics and volleyball at the 2012 Summer Paralympics. Many among those on the team lost their legs in the Bosnian War.
Cuisine.
Bosnian cuisine uses many spices, in moderate quantities. Most dishes are light, as they are cooked in lots of water; the sauces are fully natural, consisting of little more than the natural juices of the vegetables in the dish. Typical ingredients include tomatoes, potatoes, onions, garlic, peppers, cucumbers, carrots, cabbage, mushrooms, spinach, zucchini, dried beans, fresh beans, plums, milk, paprika and cream called Pavlaka. Bosnian cuisine is balanced between Western and Eastern influences. As a result of the Ottoman administration for almost 500 years, Bosnian food is closely related to Turkish, Greek, and other former Ottoman and Mediterranean cuisines. However, because of years of Austrian rule, there are many influences from Central Europe. Typical meat dishes include primarily beef and lamb. Some local specialties are ćevapi, burek, dolma, sarma, pilaf, goulash, ajvar and a whole range of Eastern sweets. Local wines come from Herzegovina where the climate is suitable for growing grapes. Herzegovinian loza (similar to Italian Grappa but less sweet) is very popular. Plum ("rakija") or apple ("jabukovača") alcohol beverages are produced in the north. In the south, distilleries used to produce vast quantities of brandy and supply all of ex-Yugoslavian alcohol factories (brandy is the base of most alcoholic drinks).
Leisure activities.
Coffeehouses, where Bosnian coffee is served in džezva with rahat lokum and sugar cubes, proliferate Sarajevo and every city in the country. Coffee drinking is a favorite Bosnian pastime and part of the culture. Bosnians are believed to be some of the heaviest coffee drinkers in the world.

Chicano nationalism
Chicano nationalism is the ethnic nationalist ideology of Chicanos. While there were nationalistic aspects of the Chicano Movement of the 1960s and 1970s, the Movement tended to emphasize civil rights and political and social inclusion rather than nationalism. For this reason, Chicano nationalism is better described as an ideology than as a political movement.
Background.
Violence and discrimination against Mexican Americans continued into the 1950s and 1960s. Many organizations, businesses, and homeowners associations had official policies to exclude Mexican Americans. In many areas across the Southwest, Mexican Americans lived in separate residential areas, due to laws and real estate company policies.
This group of laws and policies, known as redlining, lasted until the 1950s, and fall under the concept of official segregation. In many other instances, it was more of a general social understanding that Mexicans should be excluded from White society. For instance, signs with the phrase "No Dogs or Mexicans" were posted in small businesses and public pools throughout the Southwest well into the 60's.
Some members of the Mexican American community began to question whether assimilation was possible or even desirable. At the same time, a sense of ethnic consciousness and unity was forming, especially among the youth, around the plight of the farmworkers. Mexican Americans, some of whom began calling themselves "Chicanos" as a symbol of ethnic pride, also began to uncover their history and critically analyze what they learned in public schools. With this new sense of identity and history, the early proponents of the Chicano movement began viewing themselves as a colonized people entitled to self-determination of their own. Some of them also embraced a form of nationalism that was based on their perception of the failure of the United States government to live up to the promises that it had made in the Treaty of Guadalupe Hidalgo.
Quote.
The concept of Chicano nationalism is perhaps best articulated in the 1968 Plan Espiritual de Aztlán, generally considered the manifesto of the Chicano Movement. It states, "El Plan Espiritual de Aztlán sets the theme that the Chicanos ("La Raza de Bronze") must use their nationalism as the key or common denominator for mass mobilization and organization. Once we are committed to the idea and philosophy of El Plan de Aztlán, we can only conclude that social, economic, cultural, and political independence is the only road to total liberation from oppression, exploitation, and racism. Our struggle then must be for the control of our barrios, campos, pueblos, lands, our economy, our culture, and our political life. El Plan commits all levels of Chicano society - the barrio, the campo, the ranchero, the writer, the teacher, the worker, the professional - to "La Causa"."
Functions and basis.
Chicano nationalism allowed Chicanos to define themselves as a group on their own terms, and was a determination on their part to mold their own destiny. It is rooted in the Aztec creation myth of Aztlán, a "northerly place". As the Aztecs are central to the conquest and history of Mexico, the use of the word took on the added dimension of the reclamation of an indigenous heritage as part of the decolonization process.
The sense of Chicano nationalism was enhanced by a geographical proximity of the United States and Mexico. Chicanos use the name Aztlán in reference to territories within the boundaries of the Mexican Cession, the land that was "granted" to Spain in 1493 by Pope Alexander VI in Bull Inter caetera, then claimed by the Mexican Empire in 1821 when Spain signed the Treaty of Córdoba at the conclusion of the Mexican War of Independence, then claimed as "territories" (as opposed to "states", often referred to as "provinces") by 1824 Constitution, and finally ceded to the United States in 1848 as an outcome of the Treaty of Guadalupe Hidalgo (although it also included Texas, which had earlier proclaimed its independence from the government in Mexico City and was independent territory.)
The commitment to a nationalist ideology allowed Chicano activists to supersede differences that threatened their unity. Mexican Americans had regional, linguistic, age, cultural, racial, and gender differences, all of which were all subsumed to a mutual dedication to the Chicano Movement.
This emphasis on cultural nationalism would persist well into the late seventies before the concept of activism ‘sin fronteras’ (without borders) and Marxist critiques of empire transformed the Chicano Left, causing them to turn their attention towards conflicts such as the Zapatista National Liberation Army’s (EZLN) revolution against neo-liberal economic doctrine in Chiapas, Mexico.

China
China (; ; see also Names of China), officially the People's Republic of China (PRC), is a country in East Asia. It is the world's most populous country, with a population of over 1.3 billion. Covering approximately 9.6 million square kilometres, the country is the world's second-largest country by land area, and the third- or fourth-largest by total area, depending on the definition of total area.
The People's Republic of China is a single-party state governed by the Communist Party of China. It exercises jurisdiction over 22 provinces, five autonomous regions, four directly controlled municipalities (Beijing, Tianjin, Shanghai, and Chongqing), and two mostly self-governing special administrative regions (Hong Kong and Macau). Its capital city is Beijing. The PRC also claims Taiwan—which is controlled by the Republic of China (ROC), a separate political entity—as its 23rd province, a claim controversial due to the complex political status of Taiwan and the unresolved Chinese Civil War. The PRC government denies the legitimacy of the ROC.
China's landscape is vast and diverse, with forest steppes and the Gobi and Taklamakan deserts occupying the arid north and northwest near Mongolia and Central Asia, and subtropical forests being prevalent in the wetter south near Southeast Asia. The terrain of western China is rugged and elevated, with the Himalaya, Karakoram, Pamir and Tian Shan mountain ranges separating China from South and Central Asia. The Yangtze and Yellow Rivers, the third- and sixth-longest in the world, have their sources in the Tibetan Plateau and continue to the densely populated eastern seaboard. China's coastline along the Pacific Ocean is long—the 11th-longest in the world—and is bounded by the Bohai, Yellow, East and South China Seas.
The nation of China has had numerous historical incarnations. The ancient Chinese civilization—one of the world's earliest—flourished in the fertile basin of the Yellow River in the North China Plain. China's political system was based on hereditary monarchies, known as dynasties, beginning with the semi-mythological Xia of the Yellow River basin (approx. 2000 BC) and ending with the fall of the Qing Dynasty in 1911. Since 221 BC, when the Qin Dynasty first conquered several states to form a Chinese empire, the country has expanded, fractured and been reformed numerous times. The Republic of China, founded in 1911 after the overthrow of the Qing dynasty, ruled the Chinese mainland until 1949. In 1945, the ROC acquired Taiwan from Japan following World War II.
In the 1946–1949 phase of the Chinese Civil War, the Chinese Communist Party defeated the nationalist Kuomintang in mainland China and established the People's Republic of China in Beijing on 1 October 1949. The Kuomintang relocated the ROC government to Taiwan, establishing its capital in Taipei. The ROC's jurisdiction is now limited to Taiwan and several outlying islands, including Penghu, Kinmen and Matsu. Since 1949, the People's Republic of China and the Republic of China (now widely known as "Taiwan") have remained in dispute over the sovereignty of China and the political status of Taiwan, mutually claiming each other's territory and competing for international diplomatic recognition. In 1971, the PRC gained admission to the United Nations and took the Chinese seat as a permanent member of the U.N. Security Council. China is also a member of numerous formal and informal multilateral organizations, including the WTO, APEC, BRICS, the Shanghai Cooperation Organisation, the BCIM and the G-20. As of August 2012, all but 23 countries have recognized the PRC as the sole legitimate government of China.
Since the introduction of economic reforms in 1978, China has become the world's fastest-growing major economy. As of 2012, it is the world's second-largest economy, after the United States, by both nominal GDP and purchasing power parity (PPP), and is also the world's largest exporter and second-largest importer of goods. On a per capita income basis, China ranked 90th by nominal GDP and 91st by GDP (PPP) in 2011, according to the IMF. China is a recognized nuclear weapons state and has the world's largest standing army, with the second-largest defense budget. In 2003, China became the third nation in the world, after the former Soviet Union and the United States, to independently launch a successful manned space mission. China has been characterized as a potential superpower by a number of academics, military analysts, and public policy and economics analysts.
Etymology.
The word "China" is derived from Persian "Cin" (چین). It is first recorded in 1516 in the journal of Portuguese explorer Duarte Barbosa."The Book of Duarte Barbosa" (chapter title "The Very Great Kingdom of China"). ISBN 8120604512. The Portuguese original is here: ("O Grande Reino da China"). The word appears in English in a translation published in 1555. The Persian word is, in turn, derived from the Sanskrit word "Cīna" (चीन), which was used as a name for China as early as AD 150. There are various scholarly theories regarding the origin of this word. The traditional theory, proposed in the 17th century by Martino Martini, is that "China" is derived from "Qin" (), the westernmost of the Chinese kingdoms during the Zhou Dynasty, or from the succeeding Qin Dynasty (221–206 BC). The word "Cīna" is used in two Hindu scriptures – the "Mahābhārata" of the 5th century BC and the "Laws of Manu" of the 2nd century BC – to refer to a country located in the Tibetan-Burman borderlands east of India.
In China, common names for the country include "Zhōngguó" () and "Zhōnghuá" (), although the country's official name has been changed numerous times by successive dynasties and modern governments. The term "Zhongguo" appeared in various ancient texts, such as the "Classic of History" of the 6th century BC, and in pre-imperial times it was often used as a cultural concept to distinguish the "Huaxia" from the barbarians. The term, which can be either singular or plural, referred to the group of states in the central plain. It was only in the nineteenth century that the term emerged as the formal name of the country. The Chinese were not unique in regarding their country as "central", since other civilizations had the same view.
History.
Prehistory.
Archaeological evidence suggests that early hominids inhabited China between 250,000 and 2.24 million years ago. A cave in Zhoukoudian (near present-day Beijing) exhibits fossils dated at between 300,000 and 780,000 BC. The fossils are of Peking Man, an example of "Homo erectus" who used fire. There are also remains of "Homo sapiens" dating back to 18,000–11,000 BC found at the Peking Man site.
Early dynastic rule.
Chinese tradition names the first imperial dynasty Xia, but it was considered mythical until scientific excavations found early Bronze Age sites at Erlitou in Henan Province in 1959. Archaeologists have since uncovered urban sites, bronze implements, and tombs in locations cited as Xia's in ancient historical texts, but it is impossible to verify that these remains are of the Xia without written records from the period.
The first Chinese dynasty that left historical records, the loosely feudal Shang (Yin), settled along the Yellow River in eastern China from the 17th to the 11th century BC. The oracle bone script of the Shang Dynasty represents the oldest form of Chinese writing yet found, and the direct ancestor of the modern Chinese characters used throughout East Asia. The Shang were invaded from the west by the Zhou, who ruled from the 12th to the 5th century BC, until their centralized authority was slowly eroded by feudal warlords. Many independent states eventually emerged out of the weakened Zhou state, and continually waged war with each other in the Spring and Autumn Period, only occasionally deferring to the Zhou king. By the time of the Warring States Period in the 5th–3rd centuries BC, there were seven powerful sovereign states, each with its own king, ministry and army.
Imperial China.
The first unified Chinese state was established by Qin Shi Huang of the Qin state in 221 BC. Qin Shi Huang proclaimed himself the "First Emperor" (始皇帝), and imposed many reforms throughout China, notably the forced standardization of the Chinese language, measurements, length of cart axles, and currency. The Qin Dynasty lasted only fifteen years, falling soon after Qin Shi Huang's death, as its harsh legalist and authoritarian policies led to widespread rebellion.
The subsequent Han Dynasty ruled China between 206 BC and 220 AD, and created a lasting Han cultural identity among its populace that has endured to the present day. The Han Dynasty expanded the empire's territory considerably with military campaigns reaching Korea, Vietnam, Mongolia and Central Asia, and also helped establish the Silk Road in Central Asia. China was for a large part of the last two millennia the world's largest economy. However, in the later part of the Qing Dynasty, China's economic development began to slow and Europe's rapid development in the Industrial Revolution enabled it to surpass China.
After the collapse of Han, another period of disunion followed, including the highly chivalric period of the Three Kingdoms. Independent Chinese states of this period such as Wu opened diplomatic relations with Japan, introducing the Chinese writing system there. In 580 AD, China was reunited under the Sui. However, the Sui Dynasty declined following its defeat in the Goguryeo–Sui War (598–614).
Under the succeeding Tang and Song dynasties, Chinese technology and culture entered a golden age. The Tang Empire was at its height of power until the middle of the 8th century, when the An Shi Rebellion destroyed the prosperity of the empire. The Song Dynasty was the first government in world history to issue paper money and the first Chinese polity to establish a permanent standing navy. Between the 10th and 11th centuries, the population of China doubled in size. This growth came about through expanded rice cultivation in central and southern China, and the production of abundant food surpluses.
Within its borders, the Northern Song Dynasty had a population of some 100 million people. The Song Dynasty was a culturally rich period for philosophy and the arts. Landscape art and portrait painting were brought to new levels of maturity and complexity after the Tang Dynasty, and social elites gathered to view art, share their own, and trade precious artworks. Philosophers such as Cheng Yi and Chu Hsi reinvigorated Confucianism with new commentary, infused Buddhist ideals, and emphasized a new organization of classic texts that brought about the core doctrine of Neo-Confucianism.
In 1271, the Mongol leader and fifth Khagan of the Mongol Empire Kublai Khan established the Yuan Dynasty, with the last remnant of the Song Dynasty falling to the Yuan in 1279. Before the Mongol invasion, Chinese dynasties reportedly had approximately 120 million inhabitants; after the conquest was completed in 1279, the 1300 census reported roughly 60 million people.
Late dynastic rule.
A peasant named Zhu Yuanzhang overthrew the Yuan Dynasty in 1368 and founded the Ming Dynasty.
Under the Ming Dynasty, China enjoyed another golden age, developing one of the strongest navies in the world and a rich and prosperous economy amid a flourishing of art and culture. It was during this period that Zheng He led explorations throughout the world, reaching as far as Africa. In the early years of the Ming Dynasty, China's capital was moved from Nanjing to Beijing.
During the Ming Dynasty, thinkers such as Wang Yangming further critiqued and expanded Neo-Confucianism with concepts of individualism and innate morality that would have tremendous impact on later Japanese thought. Chosun Korea also became a nominal vassal state of Ming China, and adopted much of its Neo-Confucian bureaucratic structure.
In 1644, Beijing was sacked by a coalition of rebel forces led by Li Zicheng, a minor Ming official who led the peasant revolt. The last Ming Chongzhen Emperor committed suicide when the city fell. The Manchu Qing Dynasty then allied with Ming Dynasty general Wu Sangui and overthrew Li's short-lived Shun Dynasty, and subsequently seized control of Beijing, which became the new capital of the Qing Dynasty. In total, the Manchu conquest of China cost as many as 25 million lives.
The Qing Dynasty, which lasted until 1912, was the last imperial dynasty of China. In the 19th century, the Qing Dynasty adopted a defensive posture towards European imperialism, even though it engaged in an imperialistic expansion of its own into Central Asia. At this time, China awoke to the significance of the rest of the world, the West in particular. As China opened up to foreign trade and missionary activity, opium produced by British India was forced onto Qing China. Two Opium Wars with Britain weakened the Emperor's control. Western imperialism proved to be disastrous for China: Ainslie Thomas Embree, Carol Gluck (1997). "Asia in Western and World History: A Guide for Teaching". M.E. Sharpe. p.597. ISBN 1563242656.
The weakening of the Qing regime, and the apparent humiliation of the unequal treaties in the eyes of the Chinese people, led to increasing domestic disorder. In late 1850, southern China erupted in the Taiping Rebellion, a violent civil war which lasted until 1864. The rebellion was led by Hong Xiuquan, who was partly influenced by an idiosyncratic interpretation of Christianity. Hong believed himself to be the son of God and the younger brother of Jesus. Although the Qing forces were eventually victorious, the civil war was one of the bloodiest in human history, costing at least 20 million lives (more than the total number of fatalities in World War I), with some estimates of up to 40 million. Other costly rebellions followed the Taiping Rebellion, such as the Punti-Hakka Clan Wars (1855–67), Nien Rebellion (1851–1868), Miao Rebellion (1854–73), Panthay Rebellion (1856–1873) and the Dungan revolt (1862–1877).
These rebellions each resulted in an estimated loss of several million lives, and had a devastating impact on the fragile economy. The flow of British opium hastened the empire's decline. In the 19th century, the age of colonialism was at its height and the great Chinese Diaspora began; today, about 35 million overseas Chinese live in Southeast Asia. Emigration rates were strengthened by domestic catastrophes such as the Northern Chinese Famine of 1876–1879, which claimed between 9 and 13 million lives in northern China. From 108 BC to 1911 AD, China experienced 1,828 famines, or one per year, somewhere in the empire.
While China was wracked by continuous war, Meiji Japan succeeded in rapidly modernizing its military, and set its sights on the conquest of Korea and Manchuria. At the request of the Korean emperor, the Qing government sent troops to aid in suppressing the Tonghak Rebellion in 1894. However, Japan also sent troops to Korea, leading to the First Sino-Japanese War, which resulted in Qing China's loss of influence in the Korean Peninsula as well as the cession of Taiwan (including the Pescadores) to Japan.
Following this series of defeats, a reform plan for the empire to become a modern Meiji-style constitutional monarchy was drafted by the Guangxu Emperor in 1898, but was opposed and stopped by the Empress Dowager Cixi, who placed Emperor Guangxu under house arrest in a coup d'état. The ill-fated Boxer Rebellion of 1898–1901, in which westerners in Beijing were targeted "en masse", resulted in as many as 115,000 deaths.
By the early 20th century, mass civil disorder had begun, and calls for reform and revolution were heard across the country. The 38-year-old Emperor Guangxu died under house arrest on 14 November 1908, suspiciously just a day before Cixi's own death. With the throne empty, he was succeeded by Cixi's handpicked heir, his two-year-old nephew Puyi, who became the Xuantong Emperor. Guangxu's consort became the Empress Dowager Longyu. In another coup d'état in 1912, Yuan Shikai overthrew Puyi, and forced Longyu to sign the abdication decree as regent, ending over two thousand years of imperial rule in China. Longyu died, childless, in 1913.
Republic of China (1912–1949).
On 1 January 1912, the Republic of China was established, heralding the end of Imperial China. Sun Yat-sen of the Kuomintang (the KMT or Nationalist Party) was proclaimed provisional president of the republic. However, the presidency was later given to Yuan Shikai, a former Qing general, who had ensured the defection of the entire Beiyang Army from the Qing Empire to the revolution. In 1915, Yuan proclaimed himself Emperor of China, but was forced to abdicate and reestablish the republic in the face of popular condemnation, not only from the general population but also from among his own Beiyang Army and its commanders.
After Yuan Shikai's death in 1916, China was politically fragmented, with an internationally recognized but virtually powerless national government seated in Beijing. Regional warlords exercised actual control over their respective territories. In the late 1920s, the nationalist Kuomintang, under Chiang Kai-shek, was able to reunify the country under its own control with a series of deft military and political maneuverings, known collectively as the Northern Expedition. The Kuomintang moved the nation's capital to Nanjing and implemented "political tutelage", an intermediate stage of political development outlined in Sun Yat-sen's San-min program for transforming China into a modern democratic state. Effectively, political tutelage meant one-party rule by the Kuomintang, but the party was politically divided into competing cliques. This political division made it difficult for Chiang to battle the Communists, which the Kuomintang had been warring against since 1927 in the Chinese Civil War. This war continued successfully for the Kuomintang, especially after the Communists retreated in the Long March, until the Xi'an Incident and Japanese aggression forced Chiang to confront Imperial Japan.
The Second Sino-Japanese War (1937–1945), a part of World War II, forced an uneasy alliance between the Kuomintang and the Communists. The Japanese "three-all policy" in northern China—""kill all, burn all and destroy all""—led to numerous war atrocities being committed against the civilian population; in all, as many as 20 million Chinese civilians were killed. An estimated 200,000 Chinese were massacred in the city of Nanjing alone during the Japanese occupation. Japan unconditionally surrendered to China in 1945. Taiwan, including the Pescadores, was put under the administrative control of the Republic of China, which immediately claimed sovereignty. China emerged victorious but war-ravaged and financially drained. The continued distrust between the Kuomintang and the Communists led to the resumption of civil war. In 1947, constitutional rule was established, but because of the ongoing unrest many provisions of the ROC constitution were never implemented in mainland China.
People's Republic of China (1949–present).
Major combat in the Chinese Civil War ended in 1949 with the Communist Party in control of mainland China, and the Kuomintang retreating offshore, reducing the ROC's territory to only Taiwan, Hainan, and their surrounding islands. On 1 October 1949, Mao Zedong proclaimed the People's Republic of China, which was commonly known in the West as "Communist China" or "Red China" during the Cold War. In 1950, the People's Liberation Army succeeded in capturing Hainan from the ROC, occupying Tibet, and defeating the majority of the remaining Kuomintang forces in Yunnan and Xinjiang provinces, though some Kuomintang holdouts survived until much later. 
After Mao's death in 1976 and the arrest of the Gang of Four, who were blamed for the excesses of the Cultural Revolution, Deng Xiaoping quickly wrested power from Mao's anointed successor Hua Guofeng. Although he never became the head of the party or state himself, Deng was in fact the Paramount Leader of China at that time, his influence within the Party led the country to significant economic reforms. The Communist Party subsequently loosened governmental control over citizens' personal lives and the communes were disbanded with many peasants receiving multiple land leases, which greatly increased incentives and agricultural production. This turn of events marked China's transition from a planned economy to a mixed economy with an increasingly open market environment, a system termed by some "market socialism"; the Communist Party of China officially describes it as "socialism with Chinese characteristics". China adopted its current constitution on 4 December 1982.
The death of pro-reform official Hu Yaobang helped to spark the Tiananmen Square protests of 1989, during which students and others campaigned for several months, speaking out against corruption and in favour of greater political reform, including democratic rights and freedom of speech. However, they were eventually put down on 4 June when PLA troops and vehicles entered and forcibly cleared the square, resulting in numerous casualties. This event was widely reported and brought worldwide condemnation and sanctions against the government. The "Tank Man" incident in particular became famous.
President Jiang Zemin and Premier Zhu Rongji, both former mayors of Shanghai, led the nation in the 1990s. Under Jiang and Zhu's ten years of administration, China's economic performance pulled an estimated 150 million peasants out of poverty and sustained an average annual gross domestic product growth rate of 11.2%. The country formally joined the World Trade Organization in 2001.
Although rapid economic growth has made the Chinese economy the world's second-largest, this growth has also severely impacted the country's resources and environment. Another concern is that the benefits of economic development has not been distributed evenly, resulting in a wide development gap between urban and rural areas. As a result, under President Hu Jintao and Premier Wen Jiabao, the Chinese government initiated policies to address these issues of equitable distribution of resources, though the outcome remains to be seen. More than 40 million farmers have been displaced from their land, usually for economic development, contributing to the 87,000 demonstrations and riots across China in 2005. Living standards have improved significantly but political controls remain tight. In addition, preparations for a major Communist Party leadership change in late 2012 were marked by factional disputes and political scandals, such as the fall from power of Chongqing official Bo Xilai.
Geography.
Political geography.
The People's Republic of China is the second-largest country in the world by land area after Russia and is either the third- or fourth-largest by total area, after Russia, Canada and, depending on the definition of total area, the United States. China's total area is generally stated as being approximately . Specific area figures range from according to the "Encyclopædia Britannica", according to the UN Demographic Yearbook, to according to the CIA World Factbook, and including Aksai Chin and the Trans-Karakoram Tract, which are controlled by China and claimed by India. None of these figures include the of territory ceded to China by Tajikistan following the ratification of a Sino-Tajik border agreement in January 2011.
According to the "Encyclopædia Britannica", the total area of the United States, at , is slightly smaller than that of China. Meanwhile, the CIA World Factbook states that China's total area was greater than that of the United States until the coastal waters of the Great Lakes was added to the United States' total area in 1996.
China has the longest combined land border in the world, measuring from the mouth of the Yalu River to the Gulf of Tonkin. China borders 14 nations, more than any other country except Russia, which also borders 14. China extends across much of East Asia, bordering Vietnam, Laos, and Burma in Southeast Asia; India, Bhutan, Nepal and Pakistan in South Asia; Afghanistan, Tajikistan, Kyrgyzstan and Kazakhstan in Central Asia; a small section of Russian Altai and Mongolia in Inner Asia; and the Russian Far East and North Korea in Northeast Asia.
Additionally, China shares maritime boundaries with South Korea, Japan, Vietnam and the Philippines. The PRC and the Republic of China (Taiwan) make mutual claims over each other's territory and the frontier between areas under their respective control is closest near the islands of Kinmen and Matsu, off the Fujian coast, but otherwise run through the Taiwan Strait. The PRC and ROC assert identical claims over the entirety of the Spratly Islands in the South China Sea, and the southern-most extent of these claims reach "Zengmu Ansha" (James Shoal), which would form a maritime frontier with Malaysia.
Landscape and climate.
The territory of China lies between latitudes 18° and 54° N, and longitudes 73° and 135° E. China's landscapes vary significantly across its vast width. In the east, along the shores of the Yellow Sea and the East China Sea, there are extensive and densely populated alluvial plains, while on the edges of the Inner Mongolian plateau in the north, broad grasslands predominate. Southern China is dominated by hills and low mountain ranges, while the central-east hosts the deltas of China's two major rivers, the Yellow River and the Yangtze River. Other major rivers include the Xi, Mekong, Brahmaputra and Amur. To the west, major mountain ranges, most notably the Himalayas, and high plateaus feature among the more arid landscapes of the north, such as the Taklamakan and the Gobi Desert. The world's highest point, Mt. Everest (8848m), lies on the Sino-Nepalese border. The country's lowest point, and the world's fourth-lowest, is the dried lake bed of Ayding Lake (−154m) in the Turpan Depression.
A major environmental issue in China is the continued expansion of its deserts, particularly the Gobi Desert, which is currently the world's fifth-largest desert. Although barrier tree lines planted since the 1970s have reduced the frequency of sandstorms, prolonged drought and poor agricultural practices have resulted in dust storms plaguing northern China each spring, which then spread to other parts of East Asia, including Korea and Japan. According to China's environmental watchdog, Sepa, China is losing a million acres (4,000 km²) per year to desertification. Water quality, erosion, and pollution control have become important issues in China's relations with other countries. Melting glaciers in the Himalayas could potentially lead to water shortages for hundreds of millions of people.
China's climate is mainly dominated by dry seasons and wet monsoons, which lead to pronounced temperature differences between winter and summer. In the winter, northern winds coming from high-latitude areas are cold and dry; in summer, southern winds from coastal areas at lower latitudes are warm and moist. The climate in China differs from region to region because of the country's highly complex topography.
Biodiversity.
China is one of 17 megadiverse countries, lying in two of the world's major ecozones: the Palearctic and the Indomalaya. In the Palearctic zone, mammals such as the horse, camel, tapir, and jerboa can be found. Among the species found in the Indomalaya region are the Leopard Cat, bamboo rat, treeshrew, and various monkey and ape species. Some overlap exists between the two regions due to natural dispersal and migration; deer, antelope, bears, wolves, pigs, and numerous rodent species can all be found in China's diverse climatic and geological environments. The giant panda, an emblem of modern China, is found only in a limited area along the Yangtze River. Illegal trading in endangered species is rife in China, although there are now laws to prohibit such activities.
China also hosts a variety of forest types. Cold coniferous forests predominate in the north of the country, supporting animal species such as moose and the Asian black bear, along with over 120 bird species. Moist conifer forests can have thickets of bamboo as an understorey, replaced by rhododendrons in higher montane stands of juniper and yew. Subtropical forests, which dominate central and southern China, support as many as 146,000 species of flora. Tropical and seasonal rainforests, though confined to Yunnan and Hainan Island, contain a quarter of all the plant and animal species found in China.
Environmental issues.
In recent decades, China has suffered from severe environmental deterioration and pollution. While regulations such as the 1979 Environmental Protection Law are fairly stringent, they are poorly enforced, as they are frequently disregarded by local communities and government officials in favour of rapid economic development. As a result, public protests and riots over environmental issues have become increasingly common.
Environmental campaigners such as Ma Jun have warned of the danger that water pollution poses to Chinese society. According to the Chinese Ministry of Water Resources, roughly 300 million Chinese do not have access to safe drinking water, and 40% of China’s rivers have been polluted by industrial and agricultural waste as of late 2011. This crisis is compounded by the perennial problem of water shortages, with 400 out of 600 surveyed Chinese cities reportedly short of drinking water. Additionally, numerous major Chinese coastal cities, including Shanghai, are deemed to be highly vulnerable to large-scale flooding.
However, China is the world's leading investor in renewable energy technologies, with $34.6 billion invested in 2009 alone. China produces more wind turbines and solar panels than any other country, and renewable energy projects, such as solar water heating, are widely pursued at the local level. By 2009, over 17% of China's energy was derived from renewable sources – most notably hydroelectric power plants, of which China has a total installed capacity of 197 GW.
In 2011, the Chinese government announced plans to invest four trillion yuan (US$618.55 billion) in water infrastructure projects over a ten-year period, and to complete construction of a flood prevention and anti-drought system by 2020.
Politics.
The People's Republic of China, along with Vietnam, Laos, and Cuba, is one of the four remaining official communist states in the world. However, in practice, China's political structure cannot be characterized so simply. The Chinese government has been variously described as communist and socialist, but also as authoritarian, with heavy restrictions remaining in many areas, most notably on the Internet, the press, freedom of assembly, reproductive rights, and freedom of religion. Its current political/economic system has been termed by its leaders as "socialism with Chinese characteristics".
Compared to its closed-door policies until the mid-1970s, the liberalization of China has resulted in the administrative climate being less restrictive than before. China nominally supports the Leninist principle of "democratic centralism", but Chinese politics are far different from the liberal democracy or social democracy espoused in most European and North American countries, and the National People's Congress has been described as a "rubber stamp" body. China's incumbent President is Hu Jintao, who is also the General Secretary of the Communist Party of China, and its Premier is Wen Jiabao, who is also a senior member of the CPC Politburo Standing Committee.
The country is ruled by the Communist Party of China (CPC), whose power is enshrined in China's constitution. The Chinese electoral system is hierarchical, whereby local People's Congresses are directly elected, and all higher levels of People's Congresses up to the National People's Congress (NPC) are indirectly elected by the People's Congress of the level immediately below. The political system is partly decentralized, with limited democratic processes internal to the party and at local village levels, although these experiments have been marred by corruption. There are other political parties in China, referred to in China as democratic parties, which participate in the National People's Congress and the Chinese People's Political Consultative Conference (CPPCC).
There have been some moves toward political liberalization, in that open contested elections are now held at the village and town levels, and that legislatures have shown some assertiveness from time to time. However, the Party retains effective control over government appointments: in the absence of meaningful opposition, the CPC wins by default most of the time. Political concerns in China include lessening the growing gap between rich and poor and fighting corruption within the government leadership.
The level of support to the government action and the management of the nation is among the highest in the world, with 86% of people who express satisfaction with the way things are going in their country and with their nation's economy according to a 2008 Pew Research Center survey.
Administrative divisions.
The People's Republic of China has administrative control over 22 provinces, and considers Taiwan to be its 23rd province, although Taiwan is currently governed by the Republic of China, which disputes the PRC's claim. China also has five subdivisions officially termed autonomous regions, each with a designated minority group; four municipalities; and two Special Administrative Regions (SARs), which enjoy a degree of political autonomy. These 22 provinces, five autonomous regions, and four municipalities can be collectively referred to as "mainland China", a term which usually excludes the SARs of Hong Kong and Macau. None of these divisions are recognized by the ROC government, which claims the entirety of PRC territory. 
Foreign relations.
China has diplomatic relations with 171 countries and maintains embassies in 162. Its legitimacy is disputed by the Republic of China and a few other countries; it is thus the largest and most populous state with limited recognition. Sweden was the first western country to establish diplomatic relations with the PRC on 9 May 1950. In 1971, the PRC replaced the Republic of China as the sole representative of China in the United Nations and as one of the five permanent members of the United Nations Security Council. China was also a former member and leader of the Non-Aligned Movement, and still considers itself an advocate for developing countries.
Under its interpretation of the One-China policy, China has made it a precondition to establishing diplomatic relations that the other country acknowledges its claim to Taiwan and severs official ties with the government of the Republic of China. Chinese officials have protested on numerous occasions when foreign countries have made diplomatic overtures to Taiwan, especially in the matter of armament sales. Political meetings between foreign government officials and the 14th Dalai Lama are also opposed by China, as it considers Tibet to be formally part of China.
Much of China's current foreign policy is reportedly based on Zhou Enlai's Five Principles of Peaceful Coexistence—non-interference in other states' affairs, non-aggression, peaceful coexistence, equality and mutual benefits. China's foreign policy is also driven by the concept of "harmony without uniformity", which encourages diplomatic relations between states despite ideological differences. This policy has led China to support states that are regarded as dangerous or repressive by Western nations, such as Zimbabwe, North Korea, and Iran. Conflicts with foreign countries have occurred at times in China's recent history, particularly with the United States; for example, the US bombing of the Chinese embassy in Belgrade during the Kosovo conflict in May 1999 and the US-China spy plane incident in April 2001. China's foreign relations with many Western nations suffered for a time following the military crackdown on the Tiananmen Square protests of 1989, although in recent years China has improved its diplomatic links with the West. China furthermore has an increasingly close economic relationship with Russia, and the two states often vote in unison in the UN Security Council.
Trade relations.
In recent decades, China has played an increasing role in calling for free trade areas and security pacts amongst its Asia-Pacific neighbors. In 2004, China proposed an entirely new East Asia Summit (EAS) framework as a forum for regional security issues, pointedly excluding the United States. The EAS, which includes ASEAN Plus Three, India, Australia and New Zealand, held its inaugural summit in 2005. China is also a founding member of the Shanghai Cooperation Organisation (SCO), along with Russia and the Central Asian republics.
In 2000, the United States Congress approved "permanent normal trade relations" (PNTR) with China, allowing Chinese exports in at the same low tariffs as goods from most other countries. Both Bill Clinton and George W. Bush asserted that free trade would gradually open China to democratic reform. Bush was furthermore an advocate of China's entry into the World Trade Organization (WTO). China has a significant trade surplus with the United States, its most important export market. In the early 2010s, U.S. politicians argued that the Chinese yuan was significantly undervalued, giving China an unfair trade advantage.
Sinophobic attitudes often target Chinese minorities and nationals living outside of China. Sometimes, such anti-Chinese attitudes turn violent, as occurred during the 13 May Incident in Malaysia in 1969 and the Jakarta riots of May 1998 in Indonesia, in which more than 2,000 people died. In recent years, a number of anti-Chinese riots and incidents have also occurred in Africa and Oceania. Anti-Chinese sentiment is often rooted in socio-economics.
Territorial disputes.
In addition to claiming all of Taiwan, China has been involved in a number of other international territorial disputes. Since the 1990s, China has been entering negotiations to resolve its disputed land borders. China's only remaining land border disputes are a disputed border with India and an undefined border with Bhutan. China is additionally involved in more minor multilateral disputes over the ownership of several small islands in the East and South China Seas.
Relations with the developing world.
China has strong political and economic links with numerous nations in the developing world. Most notably, it has followed a policy of engaging with African nations for trade and bilateral co-operation. Xinhua, China's official news agency, stated in 2008 that there were no less than 750,000 Chinese nationals working or living in Africa. China has furthermore strengthened its ties with major South American economies, becoming the largest trading partner of Brazil and building strategic links with Argentina. Along with Brazil, Russia, India and South Africa, China is a member of the BRICS group of emerging major economies, and hosted the group's third official summit at Sanya in Hainan Province in April 2011.
Emerging superpower status.
China is regularly hailed as a potential new superpower, with certain commentators citing its rapid economic progress, growing military might, very large population, and increasing international influence as signs that it will play a prominent global role in the 21st century. Others, however, warn that economic bubbles and demographic imbalances could slow or even halt China's growth as the century progresses.
Some authors also question the definition of "superpower", arguing that China's huge economy alone would not qualify it as a superpower, and noting that it lacks the military and cultural influence of the United States.
Sociopolitical issues and reform.
The Chinese democracy movement, social activists, and some members of the Communist Party of China have all identified the need for social and political reform. While economic and social controls have been greatly relaxed in China since the 1970s, political freedom is still tightly restricted. The Constitution of the People's Republic of China states that the "fundamental rights" of citizens include freedom of speech, freedom of the press, the right to a fair trial, freedom of religion, universal suffrage, and property rights. However, in practice, these provisions do not afford significant protection against criminal prosecution by the state.
As the Chinese economy expanded following Deng Xiaoping's 1978 reforms, tens of millions of rural Chinese moved to the cities only to find themselves treated as second-class citizens by China's "hukou" household registration system, which controls access to state benefits. Property rights are often poorly protected, and eminent domain land seizures have had a disproportionate effect on poorer peasants. In 2003, the average Chinese farmer paid three times more taxes than the average urban dweller, despite having one-sixth of the annual income. However, a number of rural taxes have since been reduced or abolished, and additional social services provided to rural dwellers.
Censorship of political speech and information, most notably on the Internet, is openly and routinely used in China to silence criticism of the government and the ruling Communist Party. In 2005, Reporters Without Borders ranked China 159th out of 167 states in its Annual World Press Freedom Index, indicating a very low level of perceived press freedom. The government has suppressed demonstrations by organizations that it considers a potential threat to "social stability", as was the case with the Tiananmen Square protests of 1989. The Communist Party has had mixed success in controlling information: a powerful and pervasive media control system faces equally strong market forces, an increasingly educated citizenry, and technological and cultural changes that are making China more open to the wider world, especially on environmental issues. However, attempts are still made by the Chinese government to control public access to outside information, with online searches for politically sensitive material being blocked by the so-called Great Firewall. Internet censorship in China is amongst the most stringent in the world.
A number of foreign governments and NGOs routinely criticize China's human rights record, alleging widespread civil rights violations, including systematic use of lengthy detention without trial, forced confessions, torture, mistreatment of prisoners, and restrictions of freedom of speech, assembly, association, religion, the press, and labor rights. China executes more people than any other country, nearly 30 times more per-capita than the United States. This high execution rate is partly due to the fact that numerous white-collar crimes, such as fraud, are punishable by death in China. However, in the early 2010s, China began restricting the application of capital punishment for some such crimes. The Chinese government has been criticized for China's lack of religious freedom, including policies targeting Christians, Tibetan Buddhists, and Falun Gong members.
The Chinese government has responded to foreign criticism by arguing that the notion of human rights should take into account a country's present level of economic development, and focus more on the people's rights to subsistence and development in poorer countries. The rise in the standard of living, literacy, and life expectancy for the average Chinese since the 1970s is seen by the government as tangible progress made in human rights. Improvements in workplace safety, and efforts to combat natural disasters such as the perennial Yangtze River floods, are also portrayed in China as progress in human rights for a still largely poor country.
Some Chinese politicians have spoken out in favor of reforms, while others remain more conservative. In 2010, Premier Wen Jiabao stated that China needs "to gradually improve the democratic election system so that state power will truly belong to the people and state power will be used to serve the people." Despite his status, Wen's comments were later censored by the government. Although the Chinese government is increasingly tolerant of NGOs which offer practical, efficient solutions to social problems, such "third sector" activity remains heavily regulated.
As the social, cultural and political consequences of economic growth and reform become increasingly manifest, tensions between the conservatives and reformists in the Communist Party are sharpening. Zhou Tianyong, the vice director of research of the Central Party School, argues that gradual political reform as well as repression of those pushing for overly rapid change over the next thirty years will be essential if China is to avoid an overly turbulent transition to a democratic, middle-class-dominated polity.
Military.
With 2.3 million active troops, the People's Liberation Army (PLA) is the largest standing military force in the world, commanded by the Central Military Commission (CMC). The PLA consists of the People's Liberation Army Ground Force (PLAGF), the People's Liberation Army Navy (PLAN), the People's Liberation Army Air Force (PLAAF), and a strategic nuclear force, the Second Artillery Corps. According to SIPRI, China's military expenditure in 2011 totalled US$129.2 billion (923 billion yuan), constituting the world's second-largest military budget. However, other nations, such as the United States, have claimed that China does not report its real level of military spending, which is allegedly much higher than the official budget. A 2007 report by the US Secretary of Defense noted that "China's actions in certain areas increasingly appear inconsistent with its declaratory policies". For its part, China claims it maintains an army purely for defensive purposes.
As a recognised nuclear weapons state, China is considered both a major regional military power and a potential military superpower. As of August 2011, China's Second Artillery Corps is believed to maintain at least 195 nuclear missiles, including 75 ICBMs. Nonetheless, China is the only member of the UN Security Council to have relatively limited power projection capabilities. To offset this, it has begun developing power projection assets, such as aircraft carriers, and has established a network of foreign military relationships that has been compared to a string of pearls.
China has made significant progress in modernizing its military since the early 2000s. It has purchased advanced Russian fighter jets, such as the Sukhoi Su-30, and has also produced its own modern fighters, most notably the Chengdu J-10 and the Shenyang J-11, J-15 and J-16. China is furthermore engaged in developing an indigenous stealth aircraft, the Chengdu J-20. China's ground forces have also undergone significant modernisations, replacing its ageing Soviet-derived tank inventory with numerous variants of the modern Type 99 tank, and upgrading its battlefield C3I and C4I systems to enhance its network-centric warfare capabilities. 
China has acquired the Russian S-300 and S-400 surface-to-air missile systems, and has constructed indigenous air defense missiles such as the HQ-9. A number of other indigenous missile technologies have also been developed – in 2007, China conducted a successful test of an anti-satellite missile, and the country now possesses numerous cruise missiles, including the CJ-10 and DH-10 land-attack warheads. In 2011, the Pentagon reported that China was believed to be testing the JL-2 missile, a submarine-launched nuclear ICBM with multiple-warhead delivery capabilities.
In recent years, much attention has been focused on enhancing the blue-water capabilities of the People's Liberation Army Navy. In September 2012, China's first aircraft carrier, the refurbished Soviet vessel "Liaoning", entered service. China furthermore maintains a substantial fleet of submarines, including several nuclear-powered attack and ballistic missile submarines. On 13 March 2011, the PLAN missile frigate "Xuzhou" was spotted off the coast of Libya, marking the first time in history a Chinese warship sailed into the Mediterranean. The ship's entrance into the Mediterranean was officially part of a humanitarian mission to rescue Chinese nationals from the Libyan civil war, though analysts such as Fareed Zakaria viewed the mission as also being an attempt to increase China's global military presence.
Economy.
As of 2012, China has the world's second-largest economy in terms of nominal GDP, totalling approximately US$7.298 trillion according to the International Monetary Fund (IMF). However, China's 2011 nominal GDP per capita of US$5,184 puts it behind around ninety countries (out of 183 countries on the IMF list) in global GDP per capita rankings. If PPP is taken into account in total GDP figures, China is again second only to the United States—in 2011, its PPP GDP reached $11.299 trillion, corresponding to $8,382 per capita. In 2009, China's primary, secondary, and tertiary industries contributed 10.6%, 46.8%, and 42.6% respectively to its total GDP.
From its founding in 1949 until late 1978, the People's Republic of China was a Soviet-style centrally planned economy, without private businesses or capitalism. To propel the country towards a modern, industrialized communist society, Mao Zedong instituted the Great Leap Forward in the early 1960s, although this had decidedly mixed economic results. Following Mao's death in 1976 and the consequent end of the Cultural Revolution, Deng Xiaoping and the new Chinese leadership began to reform the economy and move towards a more market-oriented mixed economy under one-party rule. Agricultural collectivization was dismantled and farmlands were privatized to increase productivity. Modern-day China is mainly characterized as having a market economy based on private property ownership, and is one of the leading examples of state capitalism.
Under the post-Mao market reforms, a wide variety of small-scale private enterprises were encouraged, while the government relaxed price controls and promoted foreign investment. Foreign trade was focused upon as a major vehicle of growth, leading to the creation of Special Economic Zones (SEZs), first in Shenzhen and then in other Chinese cities. Inefficient state-owned enterprises (SOEs) were restructured by introducing western-style management systems, with unprofitable ones being closed outright, resulting in massive job losses. By the latter part of 2010, China was reversing some of its economic liberalization initiatives, with state-owned companies buying up independent businesses in the steel, auto and energy industries.
Since economic liberalization began in 1978, China's investment- and export-led economy has grown almost a hundredfold and is the fastest-growing major economy in the world. According to the IMF, China's annual average GDP growth between 2001 and 2010 was 10.5%, and the Chinese economy is predicted to grow at an average annual rate of 9.5% between 2011 and 2015. Between 2007 and 2011, China's economic growth rate was equivalent to all of the G7 countries' growth combined. According to the Global Growth Generators index announced by Citigroup in February 2011, China has a very high 3G growth rating.
China is the third-most-visited country in the world, with 55.7 million inbound international visitors in 2010. It also experiences an enormous volume of domestic tourism; an estimated 740 million Chinese holidaymakers travelled within the country in October 2012 alone. China is a member of the WTO and is the world's second-largest trading power behind the US, with a total international trade value of US$3.64 trillion in 2011. Its foreign exchange reserves reached US$2.85 trillion by the end of 2010, an increase of 18.7% over the previous year, making its reserves by far the world's largest. China owns an estimated $1.6 trillion of US securities. China, holding US$1.16 trillion in US Treasury bonds, is the largest foreign holder of US public debt. China is the world's third-largest recipient of inward foreign direct investment (FDI), attracting $115 billion in 2011 alone, marking a 9% increase over 2010. China also increasingly invests abroad, with a total outward FDI of $68 billion in 2010.
China's success has been primarily due to manufacturing as a low-cost producer. This is attributed to a combination of cheap labor, good infrastructure, relatively high productivity, favorable government policy, and a possibly undervalued exchange rate. The latter has been sometimes blamed for China's huge trade surplus (US$262.7 billion in 2007) and has become a major source of dispute between China and its major trading partners—the US, EU, and Japan—despite the yuan having been de-pegged and having risen in value by 20% against the US dollar since 2005. China is moreover widely criticised for manufacturing large quantities of counterfeit goods—in 2005, the Asia Business Council alleged that the counterfeiting industry accounted for 8% of China's GDP at the time.
The state still dominates in strategic "pillar" industries (such as energy and heavy industries), but private enterprise (composed of around 30 million private businesses) has expanded enormously; in 2005, it accounted for anywhere between 33% to 70% of national GDP, while the OECD estimate for that year was over 50% of China's national output, up from 1% in 1978. The Shanghai Stock Exchange has raised record amounts of IPOs, and its benchmark Shanghai Composite index has doubled since 2005. SSE's market capitalization reached US$3 trillion in 2007, making it the world's fifth-largest stock exchange.
China now ranks 29th in the Global Competitiveness Index, although it is only ranked 135th among the 179 countries measured in the Index of Economic Freedom. In 2011, 61 Chinese companies were listed in the Fortune Global 500. Measured by total revenues, three of the world's top ten most valuable companies are Chinese, including fifth-ranked Sinopec Group, sixth-ranked China National Petroleum and seventh-ranked State Grid (the world's largest electric utilities company).
China's middle-class population (defined as those with annual income of at least US$17,000) has reached more than 100 million as of 2011, while the number of super-rich individuals worth more than 10 million yuan (US$1.5 million) is estimated to be 825,000, according to Hurun Report. Based on the Hurun rich list, the number of US dollar billionaires in China doubled from 130 in 2009 to 271 in 2010, giving China the world's second-highest number of billionaires. China's retail market was worth RMB 8.9 trillion (US$1.302 trillion) in 2007, and is growing at 16.8% annually. China is also now the world's second-largest consumer of luxury goods behind Japan, with 27.5% of the global share.
In recent years, China's rapid economic growth has contributed to severe consumer inflation, causing the prices of basic goods to rise steeply. Food prices in China increased by over 21% in the first four months of 2008 alone. To curb inflation and moderate rising property prices, the Chinese government has instituted a number of fiscal regulations and amendments, raising interest rates and imposing limits on bank loans. In September 2011, consumer prices rose by 6.1% compared to a year earlier, marking a reduction in inflation from the peak of 6.5% in July 2011. A side-effect of increased economic regulation was a slowdown in overall growth – China's quarterly GDP growth fell to 9.1% in October 2011, down from 9.5% in the previous quarter, and sank to 8.1% in April 2012. By October 2012, amid a manufacturing slowdown and increasing turmoil in global markets, China's quarterly GDP growth rate had fallen to 7.4%.
The Chinese economy is highly energy-intensive and inefficient—on average, industrial processes in China between 20% and 100% more energy than similar ones in OECD countries. China became the world's largest energy consumer in 2010, but still relies on coal to supply about 70% of its energy needs. Coupled with lax environmental regulations, this has led to massive water and air pollution, leaving China with 20 of the world's 30 most polluted cities. Consequently, the government has promised to use more renewable energy, planning to make renewables constitute 30% of China's total energy production by 2050. In 2010, China became the largest wind energy provider in the world, with a total installed wind power capacity of 41.8 GW. In January 2011, Russia began scheduled oil shipments to China, pumping 300,000 barrels of oil per day via the Eastern Siberia – Pacific Ocean oil pipeline.
Science and technology.
China was a world leader in science and technology until the Ming Dynasty. Ancient Chinese discoveries and inventions, such as papermaking, printing, the compass, and gunpowder (the Four Great Inventions), contributed to the economic development of Asia and Europe. However, Chinese scientific activity entered a prolonged decline in the fourteenth century. Unlike European scientists, medieval Chinese thinkers did not attempt to reduce observations of nature to mathematical laws, and they did not form a scholarly community offering peer review and progressive research. There was an increasing concentration on literature, the arts, and public administration, while science and technology were seen as trivial or restricted to limited practical applications. The causes of this Great Divergence continue to be debated.
After repeated military defeats by Western nations in the 19th century, Chinese reformers began promoting modern science and technology as part of the Self-Strengthening Movement. After the Communist victory in the Chinese Civil War in 1949, efforts were made to organize science and technology based on the model of the Soviet Union. However, Mao Zedong's Cultural Revolution of 1966–76 had a catastrophic effect on Chinese research, as academics were persecuted and the training of scientists and engineers was severely curtailed for nearly a decade. After Mao's death in 1976, science and technology was established as one of the Four Modernizations, and the Soviet-inspired academic system was gradually reformed.
Since the end of the Cultural Revolution, China has become one of the world's leading technological powers, spending over US$100 billion on scientific research and development in 2011 alone. Science and technology are seen as vital for achieving economic and political goals, and are held as a source of national pride to a degree sometimes described as "techno-nationalism". Almost all of the members of the Politburo Standing Committee of the Communist Party of China have engineering degrees.
China is rapidly developing its education system with an emphasis on science, mathematics and engineering; in 2009, it produced over 10,000 Ph.D. engineering graduates, and as many as 500,000 BSc graduates, more than any other country. China is also the world's second-largest publisher of scientific papers, producing 121,500 in 2010 alone, including 5,200 in leading international scientific journals. Chinese technology companies such as Huawei and Lenovo have become world leaders in telecommunications and personal computing.
The Chinese space program is one of the world's most active, and is a major source of national pride. In 1970, China launched its first satellite, Dong Fang Hong I. In 2003, China became the third country to independently send humans into space, with Yang Liwei's spaceflight aboard Shenzhou 5; as of September 2012, eight Chinese nationals have journeyed into space. In 2008, China conducted its first spacewalk with the Shenzhou 7 mission. In 2011, China's first space station module, Tiangong-1, was launched, marking the first step in a project to assemble a large manned station by 2020. The Chinese Lunar Exploration Program includes a planned lunar rover launch in 2013, and possibly a manned lunar landing in 2025. Experience gained from the lunar program may be used for future programs such as the exploration of Mars and Venus. However, some foreign analysts have accused China of covertly using its civilian space missions for military purposes, such as the launch of surveillance satellites.
Infrastructure.
Communications.
China currently has the largest number of active cellphones of any country in the world, with over 1 billion users as of May 2012. It also has the world's largest number of internet and broadband users. By December 2010, China had around 457 million internet users, an increase of 19% over the previous year, and by the end of 2011 the number of internet users had exceeded 500 million. According to the China Internet Network Information Center (CNNIC), China's average internet connection speed in 2011 was 100.9 kbit/s, less than half of the global average of 212.5 kbit/s.
China Telecom and China Unicom, the country's two largest broadband providers, accounted for 20% of global broadband subscribers, whereas the world's ten largest broadband service providers combined accounted for 39% of the world's broadband customers. China Telecom alone serves 55 million broadband subscribers, while China Unicom serves more than 40 million. The massive rise in internet use in China continues to fuel rapid broadband growth, whereas the world's other major broadband ISPs operate in the mature markets of the developed world, with high levels of broadband penetration and rapidly slowing subscriber growth. Several Chinese telecommunications companies, most notably Huawei and ZTE, have become highly profitable in overseas markets, but have also been accused of spying for the Chinese military.
Transport.
Transportation in mainland China has undergone intense state-led development since the late 1990s. The national road network has been significantly expanded through the creation of a network of expressways, known as the National Trunk Highway System (NTHS). By the end of 2011, China's expressways had reached a total length of , second only to the network of the United States. Private car ownership is growing rapidly in China, which surpassed the United States as the world's largest automobile market in 2009, with total car sales of over 13.6 million. Analysts predict that annual car sales in China may rise as high as 40 million by 2020. A side-effect of the rapid growth of China's road network has been a significant rise in traffic accidents, mostly caused by poorly enforced traffic laws—in 2011 alone, around 62,000 Chinese died in road accidents.
China also possesses the world's longest high-speed rail network, with over of service routes. Of these, serve trains with top speeds of . In 2011, China produced its first high-speed trains built entirely without foreign assistance. China intends to operate approximately of high-speed rail lines by 2020.
As of 2012, China is the world's largest constructor of new airports, and the Chinese government has begun a US$250 billion five-year project to expand and modernize domestic air travel. However, long-distance transportation remains dominated by railways and charter bus systems. Railways are the vital carrier in China; they are monopolized by the state, and divided into various railway bureaux in different regions. Due to huge demand, the system is regularly subject to overcrowding, particularly during holiday seasons, such as "Chunyun" during the Chinese New Year. The Chinese rail network carried an estimated 1.68 billion total passengers in 2010 alone. In urban areas, bicycles remain an extremely common mode of transport, despite the increasing prevalence of automobiles – as of 2012, there are approximately 470 million bicycles in China.
Rapid transit systems are also rapidly developing in China's major cities, in the form of networks of underground or light rail systems. Hong Kong has one of the most developed public transport systems in the world, while Shanghai has a high-speed maglev rail line connecting the city to its main international airport, Pudong International Airport. China is additionally developing its own satellite navigation system, dubbed Beidou, which began offering commercial navigation services in mainland China in 2011, and is planned to offer global coverage by 2020.
Demographics.
As of July 2010, the People's Republic of China has an estimated total population of 1,338,612,968. About 21% of the population (145,461,833 males; 128,445,739 females) are 14 years old or younger, 71% (482,439,115 males; 455,960,489 females) are between 15 and 64 years old, and 8% (48,562,635 males; 53,103,902 females) are over 65 years old. The population growth rate for 2006 was 0.6%.
By end of 2010, the proportion of mainland Chinese people aged 14 or younger was 16.60%, while the number aged 60 or older grew to 13.26%, giving a total proportion of 29.86% dependents. The proportion of the population of workable age was thus around 70%.
Although a middle-income country by Western standards, China's rapid growth has pulled hundreds of millions of its people out of poverty since 1978. Today, about 10% of the Chinese population lives below the poverty line of US$1 per day, down from 64% in 1978. Urban unemployment in China reportedly declined to 4% by the end of 2007, although true overall unemployment may be as high as 10%.
With a population of over 1.3 billion and dwindling natural resources, China is very concerned about its population growth and has attempted, with mixed results, to implement a strict family planning policy, known as the "one-child policy." The government's goal is one child per family, with exceptions for ethnic minorities and a degree of flexibility in rural areas. It is hoped that population growth in China will stabilize in the early decades of the 21st century, though some projections estimate a population of anywhere between 1.4 billion and 1.6 billion by 2025. China's family planning minister has indicated that the one-child policy will be maintained until at least 2020.
The one-child policy is resisted, particularly in rural areas, because of the need for agricultural labour and a traditional preference for boys (who can later serve as male heirs). Families who breach the policy often lie during the census.
The decreasing reliability of China population statistics since family planning began in the late 1970s has made evaluating the effectiveness of the policy difficult. Data from the 2010 census implies that the total fertility rate may now be around 1.4. The government is particularly concerned with the large imbalance in the sex ratio at birth, apparently the result of a combination of traditional preference for boys and family planning pressure, which led to a ban on using ultrasound devices for non-emergency applications, in an attempt to prevent sex-selective abortion.
According to the 2010 census, there were 118.06 boys born for every 100 girls, which is 0.53 points lower than the ratio obtained from a population sample survey carried out in 2005. However, the gender ratio of 118.06 is still beyond the normal range of around 105 percent, and experts warn of increased social instability should this trend continue. For the population born between the years 1900 and 2000, it is estimated that there could be 35.59 million fewer females than males. Other demographers argue that perceived gender imbalances may arise from the underreporting of female births. A recent study suggests that as many as three million Chinese babies are hidden by their parents every year. According to the 2010 census, males accounted for 51.27 percent of the total population, while females made up 48.73 percent of the total.
Ethnic groups.
China officially recognizes 56 distinct ethnic groups, the largest of
which are the Han Chinese, who constitute about 91.51% of the total
population. The Han Chinese—the world's largest single ethnic group—outnumber other ethnic groups in every province, municipality and autonomous region except Tibet and Xinjiang, and are descended from ancient Huaxia tribes living along the Yellow River.
Ethnic minorities account for about 8.49% of the population of China, according to
the 2010 census. Compared with the 2000 population census, the Han population increased by 66,537,177 persons, or 5.74%, while the population of the 55 national
minorities combined increased by 7,362,627 persons, or 6.92%.
The 2010 census recorded a total of 593,832 foreign citizens living in China. The largest such groups were from South Korea (120,750), the
United States (71,493) and Japan (66,159).
Languages.
The languages most spoken in China belong to the Sino-Tibetan language family. There are also several major linguistic groups within the Chinese language itself. The most spoken varieties are Mandarin (natively spoken by over 70% of the population), Wu (includes Shanghainese), Yue (includes Cantonese and Taishanese), Min (includes Hokkien and Teochew), Xiang, Gan, and Hakka. Non-Sinitic languages spoken widely by ethnic minorities include Zhuang, Mongolian, Tibetan, Uyghur, Hmong and Korean. Standard Mandarin, a variety of Mandarin based on the Beijing dialect, is the official national language of China and is used as a lingua franca between people of different linguistic backgrounds.
Classical Chinese was the written standard in China for thousands of years, and allowed for written communication between speakers of various unintelligible languages and dialects in China. Written vernacular Chinese, or "baihua", is the written standard, based on the Mandarin dialect and first popularized in Ming Dynasty novels. It was adopted, with significant modifications, during the early 20th century as the national standard. Classical Chinese is still part of the high school curriculum, and is thus intelligible to some degree to many Chinese. Since their promulgation by the government in 1956, Simplified Chinese characters have become the official standardized written script used to write the Chinese language within mainland China, supplanting the use of the earlier Traditional Chinese characters.
Urbanization.
Since 2000, China's cities have expanded at an average rate of 10% annually. It is estimated that China will add 400 million people to its urban population by 2025. The country's urbanization rate increased from 17.4% to 46.8% between 1978 and 2009, a scale unprecedented in human history. Between 150 and 200 million migrant workers work part-time in the major cities, returning home to the countryside periodically with their earnings.
Today, the People's Republic of China has dozens of cities with one million or more long-term residents, including the three global cities of Beijing, Hong Kong, and Shanghai. The figures in the table below are from the 2008 census, and are only estimates of the urban populations within administrative city limits; a different ranking exists when considering the total municipal populations (which includes suburban and rural populations). The large "floating populations" of migrant workers make conducting censuses in urban areas difficult; the figures below do not include the floating population, only long-term residents.
Education.
In 1986, China set the long-term goal of providing compulsory nine-year basic education to every child. As of 2007, there were 396,567 primary schools, 94,116 secondary schools, and 2,236 higher education institutions in China. In February 2006, the government advanced its basic education goal by pledging to provide completely free nine-year education, including textbooks and fees. Free compulsory education in China consists of elementary school and middle school, which lasts for 9 years (ages 6–15); almost all children in urban areas continue with three years of high school.
, 93.3% of the population over age 15 are literate, compared to only 20% in 1950. In 2000, China's literacy rate among 15-to-24-year-olds was 98.9% (99.2% for males and 98.5% for females). In March 2007, the Chinese government declared education a national "strategic priority"; the central budget for national scholarships was tripled between 2007 and 2009, and 223.5 billion yuan (US$28.65 billion) of extra state funding was allocated between 2007 and 2012 to improve compulsory education in rural areas.
In 2009, Chinese students from Shanghai achieved the world's best results in mathematics, science and literacy, as tested by the Programme for International Student Assessment (PISA), a worldwide evaluation of 15-year-old school pupils' scholastic performance.
Health.
The Ministry of Health, together with its counterparts in the provincial health bureaux, oversees the health needs of the Chinese population. An emphasis on public health and preventive medicine has characterized Chinese health policy since the early 1950s. At that time, the Communist Party started the Patriotic Health Campaign, which was aimed at improving sanitation and hygiene, as well as treating and preventing several diseases. Diseases such as cholera, typhoid and scarlet fever, which were previously rife in China, were nearly eradicated by the campaign. After Deng Xiaoping began instituting economic reforms in 1978, the health of the Chinese public improved rapidly due to better nutrition, although many of the free public health services provided in the countryside disappeared along with the People's Communes. Healthcare in China became mostly privatised, and experienced a significant rise in quality. The national life expectancy at birth rose from about 35 years in 1949 to 73.18 years in 2008, and infant mortality decreased from 300 per thousand in the 1950s to around 23 per thousand in 2006. Malnutrition stood at 12% of the population, according to United Nations FAO sources. In 2009, the government began a large-scale healthcare provision initiative worth US$124 billion, which is expected to eventually cover 90% of China's population.
As of 2012, China's national average life expectancy at birth is 74.8 years, and its infant mortality rate is 15.6 per thousand births. Despite significant improvements in health and the construction of advanced medical facilities, China has several emerging public health problems, such as respiratory illnesses caused by widespread air pollution and hundreds of millions of cigarette smokers, a possible future HIV/AIDS epidemic, and an increase in obesity among urban youths. China's large population and densely populated cities have led to serious disease outbreaks in recent years, such as the 2003 outbreak of SARS, although this has since been largely contained.
Estimates of excess deaths in China from environmental pollution (apart from smoking) are placed at 760,000 people per annum from air and water pollution (including indoor air pollution). In 2007, China overtook the United States as the world's biggest producer of carbon dioxide. Some 90% of China's cities suffer from some degree of water pollution, and nearly 500 million people lacked access to safe drinking water in 2005. Reports by the World Bank and the "New York Times" have claimed industrial pollution, particularly of the air, to be a significant health hazard in China.
Religion.
Freedom of religion is guaranteed by China's constitution, although religious organizations which lack official approval can be subject to state persecution. An accurate number of religious adherents is hard to obtain because of a lack of official data, but there is a general consensus that religious belief has been enjoying a resurgence in China since the late 1980s. A 1998 survey by Adherents.com found that 59% (over 700 million) of the population was non-religious. A later survey, conducted in 2007, found that there were 300 million religious believers in China, constituting 23% of the population, as distinct from the official figure of 100 million.
Despite the surveys' varying results, most agree that China's traditional religions—Buddhism, Taoism, and Chinese folk religions—are the dominant faiths. According to various sources, Buddhism in China accounts for between 660 million (~50% of the population) and over 1 billion (~80%), while Taoists number as many as 400 million (~30%). However, because of the fact that one person may subscribe to two or more of these traditional beliefs simultaneously, and the difficulty in clearly differentiating Buddhism, Taoism, and Chinese folk religions, there is likely a strong degree of overlap in the number of adherents of these religions. In addition, some who subscribe to Buddhism and Taoism follow their philosophies in principle but stop short of believing in any kind of deity or divinity.
Most Chinese Buddhists are merely nominal adherents, because only a small proportion of the population (around 8% or 100 million) may have taken the formal step of going for refuge. Even then, it is still difficult to estimate accurately the number of Buddhists, because they do not have congregational memberships and often do not participate in public ceremonies. Mahayana Buddhism ("Dacheng") and its subsets Pure Land (Amidism), Tiantai and Chán (better known in English by its Japanese pronunciation Zen) are the most widely practiced denominations of Buddhism. Other forms, such as Theravada and Tibetan Buddhism, are practiced largely by ethnic minorities along the geographic fringes of the Chinese mainland.
Christianity was first introduced to China during the Tang Dynasty, with the arrival of Nestorian Christianity in 635 AD. This was followed by Franciscan missionaries in the 13th century, Jesuits in the 16th century, and finally Protestants in the 19th century. Of China's minority religions, Christianity is one of the fastest-growing. The total number of Christians is difficult to determine, as many belong to unauthorized house churches, but estimates of their number have ranged from 40 million (3% of the total population) to 54 million (4%) to as many as 130 million (10%). Official government statistics put the number of Christians at 25 million, but these count only members of officially sanctioned church bodies. China is believed to now have the world's second-largest evangelical Christian population—behind the United States—and is also experiencing a surge in mainstream Christian publishing. In 2011, it was reported that more people attended Sunday church services in China than in all of Europe combined.
Islam in China dates to a mission in 651, only 18 years after the death of the Prophet Muhammad. Muslims initially came to China for trade, becoming prominent in the trading ports of the Song Dynasty. Later, Muslims such as Zheng He, Lan Yu and Yeheidie'erding became influential in government circles, and Nanjing became an important center of Islamic study. Accurate statistics on China's Muslim population are hard to find; most estimates give a figure of between 20 and 30 million Muslims (1.5% to 2% of the total population).
China also has numerous minority religions, including Hinduism, Dongbaism, Bön, and a number of more modern religions and sects (particularly Xiantianism). In July 1999, the Falun Gong spiritual practice was officially banned by the authorities, and many international organizations have criticized the government's recent treatment of Falun Gong."The US State Department, US Congress, the United Nations and human rights groups such as Amnesty say persecution of Falun Gong practitioners in China is a continuing abuse of human rights." There are no reliable estimates of the number of Falun Gong practitioners in China, although informal estimates have given figures as high as 70 million.
Culture.
Since ancient times, Chinese culture has been heavily influenced by Confucianism and conservative philosophies. For much of the country's dynastic era, opportunities for social advancement could be provided by high performance in the prestigious Imperial examinations, which were instituted in 605 AD to help the Emperor select skilful bureaucrats. The literary emphasis of the exams affected the general perception of cultural refinement in China, such as the belief that calligraphy and literati painting were higher forms of art than dancing or drama. Chinese culture has long emphasized a sense of deep history and a largely inward-looking national perspective.
A number of more authoritarian and rational strains of thought were also influential, with Legalism being a prominent example. There was often conflict between the philosophies – for instance, the individualistic Song Dynasty neo-Confucians believed that Legalism departed from the original spirit of Confucianism. Examinations and a culture of merit remain greatly valued in China today. In recent years, a number of New Confucians have claimed that modern democratic ideals and human rights are compatible with traditional Confucian values.
The first leaders of the People's Republic of China were born into the traditional imperial order, but were influenced by the May Fourth Movement and reformist ideals. They sought to change some traditional aspects of Chinese culture, such as rural land tenure, sexism, and the Confucian system of education, while preserving others, such as the family structure and culture of obedience to the state.
Some observers see the period following the establishment of the PRC in 1949 as a continuation of traditional Chinese dynastic history, while others claim that the Communist Party's rule has damaged the foundations of Chinese culture, especially through political movements such as the Cultural Revolution of the 1960s, where many aspects of traditional culture were destroyed, having been denounced as 'regressive and harmful' or 'vestiges of feudalism'. Many important aspects of traditional Chinese morals and culture, such as Confucianism, Chinese art, literature, and performing arts like Peking opera, were altered to conform to government policies and propaganda at the time.
Today, the Chinese government has accepted numerous elements of traditional Chinese culture as being integral to Chinese society. With the rise of Chinese nationalism and the end of the Cultural Revolution, various forms of traditional Chinese art, literature, music, film, fashion and architecture have seen a vigorous revival, and folk and variety art in particular have sparked interest nationally and even worldwide.
Prior to the beginning of maritime Sino-European trade in the 16th century, medieval China and the European West were linked by the Silk Road, which was a key route of cultural as well as economic exchange. Artifacts from the history of the Road, as well as from the natural history of the Gobi desert, are displayed in the Silk Route Museum in Jiuquan.
Cuisine.
Chinese cuisine is highly diverse, drawing on several millennia of culinary history. The dynastic emperors of ancient China were known to host banquets with over 100 dishes served at a time, employing countless imperial kitchen staff and concubines to prepare the food. Such royal dishes gradually became a part of wider Chinese culture. China's staple food is rice, but the country is also well known for its meat dishes. Spices are endemic to Chinese cuisine.
Numerous foreign offshoots of Chinese food, such as Hong Kong cuisine and American Chinese food, have emerged in the various nations which play host to the Chinese diaspora.
Sports.
China has one of the oldest sporting cultures in the world. There is evidence that a form of association football was played in China around 1000 AD. Today, some of the most popular sports in the country include martial arts, basketball, football, table tennis, badminton, swimming and snooker. Board games such as go (known as "weiqi" in China), xiangqi, and more recently chess, are also played at a professional level.
Physical fitness is widely emphasized in Chinese culture. Morning exercises are a common activity, with elderly citizens encouraged to practice qigong and t'ai chi ch'uan. Young people in China are also keen on basketball, especially in urban centers with limited space and grass areas. The American National Basketball Association has a huge following among Chinese youths, with ethnic Chinese players such as Yao Ming being held in high esteem. Commercial gyms and fitness clubs are rapidly gaining popularity in China, with over 3,000 such establishments serving around 3 million active subscribers in China's major cities in 2010. In addition, China is home to a huge number of cyclists, with an estimated 470 million bicycles as of 2012.
Many more traditional sports are also played in China. Dragon boat racing occurs during the annual nationwide Dragon Boat Festival, and has since gained popularity abroad. In Inner Mongolia, sports such as Mongolian-style wrestling and horse racing are popular. In Tibet, archery and equestrianism are a part of traditional festivals.
China has participated in the Olympic Games since 1932, although it has only participated as the PRC since 1952. China hosted the 2008 Summer Olympics in Beijing, where its athletes received 51 gold medals – the highest number of gold medals of any participating nation that year. China also won the most medals of any nation at the 2012 Summer Paralympics, with 231 overall, including 95 gold medals. China will host the 2013 East Asian Games in Tianjin and the 2014 Youth Olympic Games in Nanjing.

Coandă-1910
The Coandă-1910, designed by Romanian inventor Henri Coandă, was the first full-size attempt at a jet aircraft. Built as a sesquiplane, it featured an experimental aircraft engine which Coandă called the "turbo-propulseur," a centrifugal compressor propulsion system with a multi-bladed rotary fan situated in a duct and driven by a conventional piston engine. The unusual aircraft attracted attention at the Second International Aeronautical Exhibition in Paris in October 1910, being the only exhibit without a propeller, but the aircraft was not displayed afterward and it fell from public awareness. Coandă used a similar turbo-propulseur to drive a snow sled, but he did not develop it further for aircraft.
Decades later, after the practical demonstration of motorjets and turbojets, Coandă began to tell various conflicting stories about how his early experiments were precursors to the jet, even that his turbo-propulseur was the first motorjet engine complete with fuel combustion in the air stream. He also said that he had made a single brief flight in December 1910, crashing just after take-off, the aircraft destroyed by fire. Two aviation historians countered Coandă's version of events, saying there was no proof that the engine had combustion in the air stream, and no proof that the aircraft ever flew. In 1965, Coandă brought drawings forward to prove his claim of combustion ducting but these were shown to be recently reworked, differing substantially from the originals. Many aviation historians were dismissive, saying that Coandă's turbo-propulseur design involved a weak stream of "plain air", not a powerful jet of air expanding from fuel combustion.
In 2010, based on the notion that Coandă invented the first jet, the centennial of the jet aircraft was celebrated in Romania. A special coin and stamp were issued, and construction began on a working replica of the aircraft. At the European Parliament, an exhibition commemorated the building and testing of the Coandă-1910.
Early developments.
Coandă was interested in achieving reactive propelled flight as early as 1905, conducting tests of rockets attached to model aircraft, the tests held in Bucharest at the Romanian Army arsenal. In secret, at Spandau in Germany, Coandă successfully tested a flying machine equipped with a single tractor propeller, and two counter-rotating propellers providing lift, powered by a 50-horsepower (37 kW) Antoinette engine. Positioned along the fuselage centreline, the smaller rear lift propeller was mounted vertically, while the larger front one was inclined slightly forwards at 17 degrees to the vertical. According to later claims, Coandă tested the aircraft at Cassel, witnessed by the Chancellor of the German Empire Bernhard von Bülow. It was around this time that Coandă's interest in jet propulsion began, and according to him the aircraft and a jet-propelled model were displayed in December 1907 at the "Sporthalle" (indoor sports arena) in Berlin.
Coandă continued his studies at Liege, Belgium, where together with his room-mate and friend Giovanni Battista Caproni, he built the Coandă-Caproni box glider, based on the plans of gliders designed by Otto Lilienthal and Octave Chanute which he previously studied at Charlottenburg and Spandau. In 1909 he was employed as technical director of the Liège-Spa Aeroclub, and at the end of that year, with the help of car manufacturer Joachim he built the Coandă-Joachim glider. Caproni was present when the glider was flown at Spa-Malchamps, Belgium.
1910s.
With the opening of the "École supérieure d'aéronautique et de constructions mécaniques" on 15 November 1909, Coandă moved to Paris. As a continuation of his Belgian experiments, and especially looking for a way to test wing airfoils at higher speeds, he contacted Ernest Archdeacon, the co-founder of "L'Aero-Club de France", who in turn directed Coandă to Gustav Eiffel and Paul Painlevé. With their assistance, he gained approval to test different wing configurations and air resistance on a platform built by Eiffel at the front of a locomotive on the North of France railway. In March, he started flying lessons at Reims in a René Hanriot monoplane.
In an "atelier" (work room) in the courtyard of his house, he started to build his slender sesquiplane and the unusual powerplant, helped by his schoolfriend Cammarotta-Adorno. There, he tested the thrust of the powerplant on a dynamometer, tests which are described in detail in the April 1910 edition of "La Technique Aéronautique" magazine. He filed for several patents for the mechanism and aircraft on 30 May 1910, with later additions to the existing patents.
Coandă exhibited the aircraft 15 October – 2 November 1910 at the Second International Aeronautical Exhibition, an annual event commonly referred to in aviation magazines as the Paris salon, or Paris flight salon. Together with Henri Fabre's "Hydravion", the first floatplane, Coandă's aircraft and devices used for aerodynamic experiments were placed "in solitary state" in an upstairs gallery, separated from the more usual types of aircraft on the main exhibit floor.
The aircraft construction was a novelty for the time. In contrast to the monoplane described in the July 1910 patent application, the exhibit was a sesquiplane, which complicated the construction, but in return solved lateral stability control issues. The cantilevered wings were held in place at three points by tubular steel struts without any bracing from flying wires. According to Coandă's description the wings were built with metal spars, but existing photographs of the construction show a completely wooden internal structure. The trailing edges of the upper wing could be twisted separately or together for lateral control or braking during landing, and were controlled by pedals in the two-seat open cockpit. The fuselage, painted reddish-brown and highly polished, was described by "The Technical World" magazine as having a framework of steel; though the construction photographs indicate that it had a wooden framework. This was triangular in cross-section with convex ribs, strengthened with a covering of heat-shaped moulded plywood and having strips of steel placed over the ribs. Tubular radiators for engine cooling were located on either side of the cockpit. The vertical struts from the wings were secured to the fuselage with steel collars fixed with screws. The fuselage terminated in a cruciform empennage with control surfaces at 45° angles to vertical and horizontal. Four triangular surfaces at the rear of the tail were controlled using a pair of large Antoinette VII-style steering wheels mounted outside of the cockpit, one on each side, and were used for pitch and direction control. It was an early instance of what is now known as ruddervators. Forward of the tail was a small horizontal stabiliser. The fuel tank was located in the fuselage between the engine and the cockpit.
A remarkable feature of the aircraft was its powerplant. Instead of a propeller, a 50 hp (37 kW) in-line water-cooled reciprocating internal combustion engine built by Pierre Clerget at a Clément-Bayard workshop with funding from "L'Aero-Club de France", placed in the forward section of the fuselage, drove a rotary compressor through a 1:4 gearbox (1,000 rpm on the Clerget turned the compressor at 4,000 rpm) which drew air in from the front and expelled it rearward under compression and with added heat. The compressor, with a diameter of 50 centimetres (20 in), was located within a cowling at the front of the fuselage. According to later Coandă descriptions, cast aluminium components were also made by Clerget to create a powerplant with a weight of 2.8 pounds (1.3 kg) per horsepower (equivalent to a power-to-weight ratio of 0.36 hp/lb), a considerable achievement at the time.
Coandă's 1910s-era patents describe the inline piston engine's exhaust gases as being routed through heating channels or heat exchangers in contact with the central air flow, then sucked into the compressor inlet to reduce back-pressure on the engine while adding more heat and mass to the air flow. The turbo-propulseur was claimed to be capable of generating 220 Kilogram-force (2,157 N; 485 lbf) of thrust. The powerplant was referred to in reports at the time by different terms: a turbine without propellers, turbo-propulseur, ducted fan or a suction turbine.
Aviation reporters from "The Aero" and "La Technique Aeronautique" were doubtful that the powerplant could provide sufficient thrust. The engine was noted in "The Aero", reprinted in "Aircraft", as being "of remarkably small proportions in relation to the size of the machine." The writer said the turbo-propulseur was "claimed to give an enormous wind velocity", but the intake area seemed too small to produce the stated thrust, and that "it also appears as if enormous power would be necessary to drive it", more than supplied by the Clerget.
The Coandă-1910 was reportedly sold to Charles Weymann in October 1910. A daily newspaper from Bucharest wrote in 1910 that the aircraft was constructed in Clerget's workshops and that it "will fly in 6–7 weeks near Paris, piloted by Weymann, one of the pilots celebrated at the Rennes aviation meeting." Another Bucharest newspaper listed the aircraft in November as "sold twice-over". It may be that Weymann expressed his willingness to buy the aircraft once tests had been carried out.
At the exhibition, reaction among observers was mixed. Some doubted the aircraft would fly, and focused on more likely machines such as the Sloan, the Voisin, or the Louis Paulhan construction of a Henri Fabre machine. Others gave special notice to the Coandă-1910, calling it original and ingenious. The reporter from "La Technique Aeronautique" wrote, "In the absence of definitive trials, permitting the precise yield of this machine, it is without doubt premature to say it will supersede the propeller ... the tentative is interesting and we watch it closely." The official exhibition report ignored the turbo-propulseur engine and instead described Coandă's novel wing design, and the unusual empennage. On 15 November 1910, "L'Aérophile" wrote that if the machine were ever to develop as the inventor hoped, it would be "a beautiful dream".
After the exhibition the aircraft was moved to a Clément-Bayard workshop at Issy-les-Moulineaux for further testing. This work is reflected by additions to the powerplant-related patents of 3 December. A group of modern-day Romanian investigators led by Dan Antoniu, having examined photographs from 1910, concluded that the rotary compressor featured at the exhibition was a hybrid between the one described in the initial 30 May 1910 patent and the one shown in a later patent application. They felt that the exhibition machine had a simpler director system, a different rotor with a smaller intake cone, and that the exhaust gas heat transfer system had not been implemented. According to Gérard Hartmann in his "Dossiers historiques et techniques aéronautique française", the propulsion system generated only 17 kg of thrust, and to generate enough thrust for the aircraft to take off (estimated by Coandă at 24 kg) Coandă would have had to spin the "turbine" (the rotary compressor) at a speed of 7,000 rpm with the risk of it exploding. This was not tried, but Hartmann concluded that the experiment proved that the solution worked perfectly.
Henri Mirguet writing for "L'Aérophile" magazine in January 1912, recalled the previous exhibition's machine as the "chief attraction" of the 1910 salon. He wrote that Coandă answered his "pressing—and indiscreet—questions" about the turbo-propulseur-powered aircraft at that earlier exhibit, telling him that the machine had attained a speed of 112 kilometres per hour (70 mph) during several "flight tests", an improbable answer about which Mirguet "reserved judgment", waiting for confirmation that never materialised.
Related developments.
The additional turbo-propulseur patent application 13.502, dated 3 December 1910, was implemented on a double-seat motorised sled commissioned by Cyril Vladimirovich, Grand Duke of Russia. With the help of Despujols, a boat maker, and the motor manufacturer Gregoire, Coandă supervised the building of a motor sled, powered by a 30 hp (22 kW) Gregoire engine driving the turbo-propulseur. The sled was blessed by Russian Orthodox priests at the Despujols plant near Paris on 2 December 1910. Starting the next day, it was exhibited for two weeks at the 12th Automobile Salon of France, alongside Gregoire-powered automobiles on the Gregoire stand. A number of automobile and general interest magazines published photographs or sketches of the sled. This was the second time in the autumn of 1910 that a version of Coandă's turbo-propulseur design was shown at the Grand Palais of Paris. One of the periodicals reported an expected speed of , but no account exists of the sled being tested.
Coandă continued to work on the Coandă-1910 project at the beginning of 1911, aiming to improve stability, increase the power of the turbo-propulseur, and to implement airfoil improvements. Coandă applied for new patents for aerodynamic investigations and improvements of the Coandă-1910.
Coandă described a different, more sturdy system for the attachment of the wings, which also enabled changes in the angle of attack and the centre of gravity. He aimed to obtain more power from the propulsion system, and design drawings show the arrangement of two air-cooled rotary engines on the sides of the fuselage. The placement of the engines indicates that Coandă did not intend to inject fuel into the jet stream and ignite it, as the cooling of the engines would have been compromised. The patent was annotated with an additional claim on 19 July 1911 which brought significant changes, for instance retractable landing gear with dampers inside aerodynamic fairings with skids. The horizontal stabiliser was removed, a supporting surface was provided for each engine, and their accessories were covered to improve aerodynamics. Though Coandă continued to study rotary propulsion mechanisms, Antoniu believes that Coandă never implemented a practical solution because of the lack of funds.
In May 1911 Coandă filed English-language patents on the turbo-propulseur design in the United Kingdom and the United States, as well as a second French-language patent filed in Switzerland,US Patent 1104963 "Propeller". Filing date: 29 May 1911. Issue date: July 1914.Swiss patent CH58232(A), filed 26 May 1911, published 1 March 1913. and he described it for the 1911 publication of "L'Annuaire de l'Air".
The very expensive project of 1910, costing Coandă about one million francs, left him with limited funds. The possibility of a new contract with the French government lead Coandă to build the Coandă-1911. He wished to win an army-organised competition at Reims in October, one that required two engines in each aircraft as a fail-safe strategy. At the third aviation salon in Paris 1911, Coandă displayed a scale model of the aircraft which used two Gnome rotary engines mounted back to back, connected by a bevel gear to one propeller. The strange combination of two engines connected to one propeller was intended to drive a new turbine, but Coandă was unable to fund one and was forced to use a two-bladed propeller. During trials the assembly did not provide enough traction and a four-bladed propeller was ordered. The mounting support of the engines, initially intended for a jet propulsion version was not adequate for the new configuration, so the forward chassis had to be modified.
Henri Mirguet writing for "L'Aérophile" magazine in January 1912 said that the new 1911 aircraft retained the fuselage, the frame and the wing of Coandă's 1910 design, but did not keep the turbo-propulseur or "the wooden wingloading surface including the forward longitudinal ribs". The aircraft was flown on 21 October 1911, but with modest results as the latest modifications, especially those related to the powerplant, did not compensate for the increased total weight of the aircraft. At the military contest, it did not meet the requirements for independent operation of each engine.
Following the 1911 exhibition, at the personal request of Sir George White, Coandă moved to the United Kingdom to take a position as chief engineer or chief designer at British and Colonial Aeroplane Company for a few years. In the next four decades, Coandă worked on a great variety of inventions. During World War II he revived his earlier turbo-propulseur engine: he was contracted by the German Army in late 1942 to develop an air propulsion system for military ambulance snow sleds much like the one made for the Russian Grand Duke. The German contract concluded after one year, yielding no plans for production. Though Coandă had experimented with a variety of nozzles, and said that he had achieved a degree of success, no turbojet-engine-style fuel injection or combustion in the air stream was attempted.
Coandă and his 1910 aircraft were absent from much of aviation literature of the day. None of the annual issues of "Jane's All the World's Aircraft" ever mentioned the Coandă-1910 or its turbo-propulseur powerplant. As well, the Soviet engineer Nikolai Rynin did not mention Coandă at all in his exhaustive nine-volume encyclopedia on jet and rocket engines, written in the late 1920s and early '30s.
Later claims.
At the beginning of the jet age, when the potential of reactive engines was recognised, a number of histories of the jet engine were written. A once-classified Guggenheim Aeronautical Laboratory and Jet Propulsion Laboratory study completed in 1946 described the Coandă-1910 as "probably not flown" but featuring "a mechanical jet propulsion device with a centrifugal blower", one in which heat from the Clerget piston engine "furnished auxiliary jet propulsion." In the editorial lead to their 1946 article on Coandă's "Augmented Flow", "Flight" terms it, "scarcely a jet". In the same year Geoffrey G. Smith chronicled technological development in his book "Gas Turbines and Jet Propulsion for Aircraft", but did not mention Coandă.
In 1950's "l'aviation d'Ader et des temps héroiques", the authors assert that Coandă flew the first jet aircraft at Issy-les-moulineaux for 30 metres (100 ft), ending with a crash. In 1953, "Flight"s treatment of aircraft in the 50 years since the Wright brothers' flight included the Coandă-1910 "ducted fan" and said of Coanda that he "believes that he 'took off for a few feet, then came down hurriedly and broke two teeth, quoting J.W. Adderley's 1952 letter to the editor of "Flight", after Adderley's discussion with Coandă in Paris at the end of World War II. Adderley said he "can definitely confirm that the power unit was of the ducted-fan type, similar in basic principles to the Caproni-Campini aircraft of the 1930s."
In the early 1950s, Coandă began to say that he had flown his 1910 aircraft himself, and that the 1910 powerplant was the first motorjet, using fuel injection and combustion to create its thrust. In 1955 and 1956, a number of aviation articles presented the Coandă version of 1910 events. He said he took off and crashed in December 1910 in the presence of aircraft makers Louis Charles Breguet and Gabriel Voisin. Coandă himself spoke on the subject, notably before the Wings Club at New York's Biltmore Hotel on 18 January 1956 where he said "I intended to inject fuel into the air stream which would be ignited by the exhaust gases also channeled through the same circular vent", implying that he never finished the powerplant. Martin Caidin wrote "The Coanda Story" for the May 1956 issue of "Flying", based on a personal interview. For his article "He Flew In 1910", René Aubrey interviewed Coandă and wrote a contradictory story in the September 1956 "Royal Air Force Flying Review", saying that Coandă had flown his unusual aircraft on 16 December 1910, that fuel was certainly injected, and that it was "the first jet flight in the world". In Aubrey's relation of the interview, the aircraft stalled after take-off, throwing Coandă clear, and "gently collapsed to the ground" where it burned. Aubrey wrote that the aircraft engine was "designed by a friend to Coandă's specification", and that its burning exhaust was "directed below and to each side of the fuselage, which was protected by asbestos in vulnerable places."
A collection of aviation stories was published in 1957 by Major Victor Houart, a friend of Coandă's, who wrote that he was an eyewitness the day Coandă flew and crashed. One chapter of the book describes how Houart, together with a group of French dragoons, watched as Coandă taxied twice around the airfield, lifted off to avoid the ruins of an old fortification wall, started flames from the engine by applying too much power, and was thrown from the aircraft the moment it hit the wall, with Coandă "not badly hurt". Houart's version put the fuel tank in the overhead wing, which was metal. In further statements, Coandă said that his 1910 aircraft had movable leading edge slots, retractable landing gear and a fuel supply which was held in the overhead wing to reduce fuselage profile and thus drag. In 1965, Coandă presented a set of drawings, photographs and specifications of the 1910 aircraft to the National Air and Space Museum (NASM), prepared by Huyck Corporation and received by Director S. Paul Johnston and early aviation curator Louis Casey.
Rocket engineer G. Harry Stine worked alongside Coandă from 1961 to 1965 at Huyck Corporation, and interviewed him in 1962. In 1967, the magazine "Flying" printed an account written by Stine, which described the landing gear as retracting into the lower wing, with the fuel tank hidden in the upper wing. Stine wrote that Coandă flew on 10 December 1910, and described the heat from the "two jet exhausts" as being "too much for me" after the powerplant was mounted in the aircraft. In the 1980s after Coandă's death, Stine wrote a magazine article and a book mentioning the 1910 aircraft, including new details such as the name of master mechanic Pierre Clerget as the friend who helped build the turbo-propulseur. Stine's recounting of the 10 December flight included the group of eyewitness French dragoons, asbestos heat shields and metal deflector plates aft of the engine, intended taxiing with unintentional flight, a steep climb with a stall, Coandă thrown clear, and the aircraft crashing to the ground, burning. Stine gave his assessment that "Coanda's turbopropulseur had elements of a true jet", but that the patent application had no indication of the "critical stage—injection of fuel into the compressed air". He wrote that "although there were several jet-propelled aircraft in existence at an early time—the 1910 Coanda Jet and the 1938 Caproni Campini N.1—the first pure jet aircraft flight was made in Germany in 1938".
In 1965, Historian Emeritus Paul E. Garber of the NASM interviewed Coandă, who related that the December 1910 flight was no accident, that he had seated himself in the cockpit intending to test five factors: aircraft structure, the engine, the wing lift, the balance of controls, and the aerodynamics. He said that the heat from the engine was "fantastic", but that he placed mica sheets and deflecting plates to direct the jet blast away from the wooden fuselage. Garber wrote that as Coandă's aircraft began to move forward and rise from the ground, "the exhaust flame, instead of fanning outward, curved inward and ignited the aircraft." In this interview, Coandă said that he brought the aircraft back to earth under control, but the landing was "abrupt" and he was thrown clear of the airframe which was consumed completely by flame, the engine reduced to "a few handfuls of white powder."
Rebuttals.
In 1960, Charles Harvard Gibbs-Smith, aviation historian at the Science Museum in London, reacted to the mid-1950s assertion that Coandă built and flew the first jet engine aircraft. Gibbs-Smith wrote that "there has recently arisen some controversy about this machine, designed by the Rumanian-born and French-domiciled Henri Coanda, which was exhibited at the Paris salon in October 1910. Until recently it has been accepted as an all-wood sesquiplane, with cantilever wings, powered by a 50 hp Clerget engine driving a 'turbo-propulseur' in the form of a large but simple ducted air fan. This fan was fitted right across the machine's nose and the cowling covered the nose and part of the engine: the resulting 'jet' of plain air was to propel the aeroplane." He wrote that "no claims that it flew, or was even tested, were made at the time", and that the story of it flying suddenly appeared in the 1950s—the aircraft was thus "disinterred from its obscurity." He wrote that the airfield at Issy-les-Moulineaux, a former military exercise ground where the test supposedly took place, was under the constant observation of the French Army who owned it, and under observation by French aviation reporters and photographers, and by aviation experts from other countries. He said that the airfield was the "most famous, most used, most observed, and most reported-on 'airfield' in Paris", and that all events, let alone an exciting crash and destruction by fire, would have been carried in local papers, and described in military reports, but no contemporary accounts exist of the Coandă-1910 being tested, flown or destroyed. Gibbs-Smith countered the Coandă assertions point by point, saying that the aircraft did not have a retractable undercarriage, did not have leading or trailing edge wing slots, did not have a fuel tank overhead in the wing, and did not have fuel injected into any turbine. Gibbs-Smith pointed out that the pilot would have been killed by the heat if any combustion had been initiated in the engine's air stream.
In 2010, Antoniu wrote that he thought Gibbs-Smith speculated on the basis of the evidence of absence that the aircraft was never tested or flown, but that Gibbs-Smith did not find any concrete evidence to support his position. Similarly, Antoniu was unable to find concrete proof of a test flight. Antoniu also wrote that Gibbs-Smith did not check the French patents claimed by Coandă in 1910 and 1911, describing the retractable gear, leading edge wing slot and upper wing fuel tank, and that he did not see photographs from private collections demonstrating aspects about which he wrote.
In 1980, NASM historian Frank H. Winter examined the 1965 drawings and specifications Coandă prepared while at Huyck Corporation, and wrote an article about Coandă's claim: "There is a wholly new description of the inner workings of the machine that does not occur in any of the accounts given the 1910s and which defies all of the patent specifications." He said Coandă told various conflicting stories about his claimed 1910 flight, and that Coandă produced a set of altered drawings as proof of his claims: 
In his article, Winter wondered why Coandă did not add the novel feature of fuel injection and air stream combustion to his May 1911 patent applications if that feature had been present during his supposed flying experience five months earlier. Rather, Winter noted that the August 1910 patent filings in French were essentially the same as the May 1911 ones in English, and that all the descriptions were applicable to air "or water" flowing through the device, meaning that the patents could not possibly include fuel combustion in the jet stream. He also noted that no mention was made in the early patents of asbestos or mica heat shields, or of any fuel injection or combustion.
While looking through aviation periodicals and Paris newspapers reporting for the month of December, 1910, Winter found that there was a spell of bad weather at Issy during which no flying took place. This situation occurred mid-month, the period covering the conflicting dates (10 and 16 December) that Coandă said his aircraft was tested, flown and crashed. In their regular "Foreign Aviation News" column, "Flight" magazine reported that the "blank period" of inclement weather at Issy ended on the 19th when Guillaume Busson tested a monoplane made by Armand Deperdussin. Other aircraft tests and piloting activities were listed, with no mention of Coandă or his machine.
Winter found that Camille (or Cosimo) Canovetti, an Italian civil and aviation engineer, had been working on a turbo-propulseur-style aviation engine before Coandă, and had attempted to show an aircraft with such an engine at the Aviation Exposition in Milan in 1909. Canovetti took out patents on his machine in 1909, and more in 1910. Canovetti wrote in 1911 that the 1910 appearance of the Coandă engine "called general attention" to designs like his.
After Coandă's death.
Modern reference books about aviation history represent the Coandă-1910 in various ways, though many do not mention the machine or the inventor at all. Others acknowledge Coandă as the discoverer of the Coandă effect but give Hans von Ohain the honour of designing the first jet engine to power an aircraft in manned flight, and Frank Whittle the honour of completing and patenting the first jet engine capable of such flight. In their 1994 book "American Aviation", authors Joe Christy and LeRoy Cook state that Coandă's 1910 aircraft was the first jet.
Aviation author Bill Gunston changed his mind two years after publishing a 1993 book in which he gave Coandă credit for the first jet engine. Gunston's 1995 description began: "Romanian Henri Coanda built a biplane with a Clerget inline piston engine which, instead of turning a propeller, drove a centrifugal compressor blowing air to the rear. The thrust was said to be 220 kilograms [490 lb], a figure the author disbelieves. On 10 December 1910 the aircraft thus powered inadvertently became airborne, crashed and burned. Often called 'a turbine aeroplane', this was of no more significance than the Campini aircraft mentioned later, and Coanda wisely decided to switch to a propeller." In his publication of 1998 – "World Encyclopedia of Aero Engines: All major aircraft power plants, from the Wright brothers to the present day" – Gunston did not include Coanda; nor did he include Coanda in 2005's "Jane's Aero-Engines" or 2006's "World Encyclopedia of Aero Engines".
Walter J. Boyne, director of the National Air and Space Museum and a prolific aviation author (more than 40 non-fiction books and 1,000 magazine articles) mentions Coandă in passing a few times in his works. Boyne discusses Coandă briefly in one of his books, "The Leading Edge": "Professor Henri Coanda, whose scientific work was impeccable, designed and built a jet aircraft in 1910; it, like Martin's Kitten, was superbly built and technically advanced—and could not fly." In a later magazine article sidebar, Boyne described more details: "Romanian inventor Henri Coanda attempted to fly a primitive jet aircraft in 1910, using a four-cylinder internal combustion engine to drive a compressor at 4,000 revolutions per minute. It was equipped with what today might be called an afterburner, producing an estimated 500 pounds [230 kg] of thrust. Countless loyal Coanda fans insist that the airplane flew. Others say it merely crashed."
In 1980 and 1993, "Jane's Encyclopedia of Aviation" included an entry on the 1910 aircraft, calling it the "Coanda turbine" and describing it as "the world's first jet-propelled aircraft to fly". In 2003, Winter co-authored a book with fellow NASM curator F. Robert van der Linden: "100 Years of Flight: A Chronicle of Aerospace History, 1903–2003". In the book the Coandă-1910 is described as an unsuccessful ducted fan aircraft lacking documentation to substantiate any flight test.
Citing Carl A. Brown's 1985 "A History of Aviation", Tim Brady, the Dean of Aviation at Embry–Riddle Aeronautical University, wrote in 2000: "the development of the jet is, broadly, the story of three men: Henri Coanda, Sir Frank Whittle, and Pabst von Ohain..." His description of Coandă's disputed test flight agreed that fuel injection and combustion had been initiated in the rotary compressor's vent, with the novel detail that the aircraft "flew for about a thousand feet before crashing into a wall." In 1990 at the 24th Symposium of the International Academy of Astronautics, one of the papers presented included this sentence: "It is to Henri Coanda (1886–1972), a world famous inventor and pioneer of jet flight, that space engineering owes—beside one of the first model planes provided with a rocket engine (1905)—the construction and engine experiment of the first jet aircraft, the 'Coanda-1910'." In 2007 in his popular book "Extreme Aircraft", Ron Miller wrote that the powerplant in the Coandă-1910 was one of the "earliest attempts" at a jet engine, but was unsuccessful—it was "incapable of actual flight", unlike the engines designed by Whittle and Ohain. The question of the Coandă-1910 being the first jet aircraft does not appear to be resolved, supporting Stine's view: "Whether Henri Coanda built the first true jet will probably be argued interminably."
In the 2000s, Dan Antoniu and other Romanian aviation experts investigated existing photographs of the Coandă-1910, leading them to believe that the aircraft presented at the exhibition was not finished, that it was exhibited with many improvisations. Antoniu published "Henri Coandă and his technical work during 1906–1918", a 2010 book in which he said that the unfinished state of the aircraft led to Coandă filing several extra patents and starting a new series of studies with the aim of making the machine airworthy. For instance, Antoniu wrote that the exhaust pipes of the Clergét engine appeared free; there were no devices to redirect exhaust gases to the turbine as described in the patent, and there were no heat shields for crew protection. As well, the central attachment of the tubular struts holding the wings to the fuselage, with mere collars secured with screws, was judged by Antoniu as appearing potentially unsafe during take-off or landing because of the "considerable loads on the struts". The X-shaped empennage was covered at high angles by the horizontal stabiliser making it unusable, and any high-speed taxi would put the machine in danger of a nose-over.
Memorials and models.
A full-size replica of the Coandă-1910 was built in 2001; it is displayed in Bucharest at the National Military Museum. A scale model is displayed in the French Air and Space Museum at Paris – Le Bourget Airport. At the site of the historic Issy-les-Moulineaux airfield, a large plaque lists the three pioneers of flight most closely associated with the airfield: Louis Blériot, Alberto Santos-Dumont and Henri Farman. Later, a plaque honouring Coandă and Romanian aviation engineer Traian Vuia was placed on a nearby building under the auspices of the mayor of Issy-les-Moulineaux, "L'Aéroclub de France", and the Romanian Association for Aviation History.
Construction on a full-sized functional replica of the plane began in March 2010 at Craiova, Romania, by a team of engineers and former test pilots from I.R.Av. Craiova. The replica is based on plans that Coandă reworked in 1965 because the 1910 plans were lost. It uses metal for the fuselage rather than wood, and its intended engine is a true jet, the Motorlet M-701, made for the 1960s-era Aero L-29 Delfín military trainer.
In October 2010 the National Bank of Romania issued a commemorative silver coin for the centennial of the building of the first jet aircraft. The 10-leu piece is intended for coin collectors, with the official purchase price set at 220 leu. It represents the aircraft on the obverse side and a portrait of Coandă on the reverse, including Romanian words which translate to "first jet aircraft". The same month the philatelic section of the Romanian Post, "Romfilatelia", produced a limited edition philatelic folder and a stamp commemorating the centennial of jet aircraft. The stamp presents a modern internal schema of the Coandă-1910, a drawing of the injectors and burners, and a quote from Gustave Eiffel: "This boy was born 30 if not 50 years too early". At the European Parliament in December, president Jerzy Buzek opened a centennial exhibition celebrating the building and testing of the Coandă-1910.

Communism
Communism (from Latin "communis" - common, universal) is a revolutionary socialist movement to create a classless, moneyless, and stateless social order structured upon common ownership of the means of production, as well as a social, political and economic ideology that aims at the establishment of this social order. This movement, in its Marxist–Leninist interpretations, significantly influenced the history of the 20th century, which saw intense rivalry between the "socialist world" (socialist states ruled by communist parties) and the "western world" (countries with capitalist economies).
Marxist theory holds that pure communism or full communism is a specific stage of historical development that inevitably emerges from the development of the productive forces that leads to a superabundance of material wealth, allowing for distribution based on need and social relations based on freely associated individuals. The exact definition of communism varies, and it is often mistakenly, in general political discourse, used interchangeably with socialism; however, Marxist theory contends that socialism is just a transitional stage on the road to communism. Leninism adds to Marxism the notion of a vanguard party to lead the proletarian revolution and to secure all political power after the revolution for the working class, for the development of universal class consciousness and worker participation, in a transitional stage between capitalism and socialism.
Council communists and non-Marxist libertarian communists and anarcho-communists oppose the ideas of a vanguard party and a transition stage, and advocate for the construction of full communism to begin immediately upon the abolition of capitalism. There is a very wide range of theories amongst those particular communists in regards to how to build the types of institutions that would replace the various economic engines (such as food distribution, education, and hospitals) as they exist under capitalist systems—or even whether to do so at all. Some of these communists have specific plans for the types of administrative bodies that would replace the current ones, while always qualifying that these bodies would be decentralised and worker-owned, just as they currently are within the activist movements themselves. Others have no concrete set of post-revolutionary blueprints at all, claiming instead that they simply trust that the world's workers and poor will figure out proper modes of distribution and wide-scale production, and also coordination, entirely on their own, without the need for any structured "replacements" for capitalist state-based control.
In the modern lexicon of what many sociologists and political commentators refer to as the "political mainstream", communism is often used to refer to the policies of communist states, i.e., the ones totally controlled by communist parties, regardless of the practical content of the actual economic system they may preside over. Examples of this include the policies of the Socialist Republic of Vietnam where the economic system incorporates "doi moi", the People's Republic of China (PRC) where the economic system incorporates "socialist market economy", and the economic system of the Soviet Union which was described as "state capitalist" by non-Leninist socialists and later by communists who increasingly opposed the post-Stalin era Soviet model as it progressed over the course of the 20th century (e.g., Maoists, Trotskyists and libertarian communists)—and even at one point by Vladimir Lenin himself.
Etymology and terminology.
"Communism" comes from the Latin word "communis", which means "shared" or "belong to all".
In the schema of historical materialism, communism is the idea of a free society with no division or alienation, where the people are free from oppression and scarcity. A communist society would have no governments, countries, or class divisions. In Marxist theory, the dictatorship of the proletariat is the intermediate system between capitalism and communism, when the government is in the process of changing the means of ownership from privatism to collective ownership. In political science, the term "communism" is sometimes used to refer to communist states, a form of government in which the state operates under a one-party system and declares allegiance to Marxism-Leninism or a derivative thereof.
In modern usage, the word "communism" is still often used to refer to the policies of self-declared socialist governments comprising one-party states which were single legal political party systems operating under centrally planned economies and a state ownership of the means of production, with the state, in turn, claiming that it represented the interests of the working classes. A significant sector of the modern communist movement alleges that these states never made an attempt to transition to a communist society, while others even argue that they never achieved a legitimate socialism. Most of these governments based their ideology on Marxism-Leninism, but they did not call the system they had set up "communism", nor did they even necessarily claim at all times that the ideology was the sole driving force behind their policies: Mao Zedong, for example, pursued New Democracy, and Vladimir Lenin in the early 1920s enacted war communism; later, the Vietnamese enacted doi moi, and the Chinese switched to socialism with Chinese characteristics. The governments labeled by other governments as "communist" generally claimed that they had set up a "transitional socialist" system. This system is sometimes referred to as state socialism or by other similar names.
"Pure communism" is a term sometimes used to refer to the stage in history after socialism, although just as many communists use simply the term "communism" to refer to that stage; the term is synonymous with "Full communism". The classless, stateless society that is meant to characterise this communism is one where decisions on what to produce and what policies to pursue are made in the best interests of the whole of society—a sort of 'of, by, and for the working class', rather than a rich class controlling the wealth and everyone else working for them on a wage basis. In this communism the interests of every member of society is given equal weight to the next, in the practical decision-making process in both the political and economic spheres of life. Karl Marx, as well as some other communist philosophers, deliberately never provided a detailed description as to how communism would function as a social system, nor the precise ways in which the working class could or should rise up, nor any other material specifics of exactly how to get to communism from capitalism. In the "Communist Manifesto", Marx does lay out a 10-point plan advising the redistribution of land and production to begin the transition to communism, but he ensured that even this was very general and all-encompassing. It has always been presumed that Marx intended these theories to read this way specifically so that later theorists in specific situations could adapt communism to their own localities and conditions.
Theory.
According to communist theory, the only way to abolish capitalist inequalities is to have the proletariat (working class), who collectively constitute the main producer of wealth in society, and who are perpetually exploited and marginalised by the bourgeoisie (wealthy class), to overthrow the capitalist system in a wide-ranging social revolution. The revolution, in the theory of most individuals and groups espousing communist revolution, usually involves an armed rebellion. The revolution espoused can be explained by theorists in many different ways, and usually depends on the environment in which the particular communism theory originates. For example, the Chinese Revolution involved military combat between the Chinese Red and the Chinese Nationalist Armies, while the Vietnamese Revolution was characterised by guerrilla warfare between the heavily backed Vietnam People's Army and various Western armies, culminating in the Vietnam War which ended in 1975. Meanwhile, the Cuban Revolution was essentially a coup that did not involve intensive wide-scale military conflict between Fulgencio Batista's soldiers and those of Fidel Castro and Che Guevara. In fact, Castro initially did not believe that a vanguard party was necessary in Cuba's case, a view boosted by Batista's unpopularity at the time of the actual armed conflict between the two sides. Regardless of the specific form a communist revolution takes, its aim is for the working class to replace the exploiter class as the ruling class to establish a society without class divisions, called socialism, as a prelude to attempting to achieve the final stage of communism.
History.
Early Communism.
The origins of communism are debatable, and there are various historical groups, as well as theorists, whose beliefs have been subsequently described as communist. German philosopher Karl Marx saw primitive communism as the original, hunter-gatherer state of humankind from which it arose. For Marx, only after humanity was capable of producing surplus, did private property develop. The idea of a classless society first emerged in Ancient Greece. Plato in his "The Republic" described it as a state where people shared all their property, wives, and children: "The private and individual is altogether banished from life and things which are by nature private, such as eyes and ears and hands, have become common, and in some way see and hear and act in common, and all men express praise and feel joy and sorrow on the same occasions."
In the history of Western thought, certain elements of the idea of a society based on common ownership of property can be traced back to ancient times. Examples include the Spartacus slave revolt in Rome. The 5th century Mazdak movement in what is now Iran has been described as "communistic" for challenging the enormous privileges of the noble classes and the clergy, criticizing the institution of private property and for striving for an egalitarian society.
At one time or another, various small communist communities existed, generally under the inspiration of Scripture. In the medieval Christian church, for example, some monastic communities and religious orders shared their land and other property (see "Religious" and "Christian communism"). These groups often believed that concern with private property was a distraction from religious service to God and neighbour.
Communist thought has also been traced back to the work of 16th century English writer Thomas More. In his treatise "Utopia" (1516), More portrayed a society based on common ownership of property, whose rulers administered it through the application of reason. In the 17th century, communist thought surfaced again in England, where a Puritan religious group known as the "Diggers" advocated the abolition of private ownership of land. Eduard Bernstein, in his 1895 "Cromwell and Communism" argued that several groupings in the English Civil War, especially the Diggers espoused clear communistic, agrarian ideals, and that Oliver Cromwell's attitude to these groups was at best ambivalent and often hostile. Criticism of the idea of private property continued into the Age of Enlightenment of the 18th century, through such thinkers as Jean Jacques Rousseau in France. Later, following the upheaval of the French Revolution, communism emerged as a political doctrine. François Noël Babeuf, in particular, espoused the goals of common ownership of land and total economic and political equality among citizens.
Various social reformers in the early 19th century founded communities based on common ownership. But unlike many previous communist communities, they replaced the religious emphasis with a rational and philanthropic basis. Notable among them were Robert Owen, who founded New Harmony in Indiana (1825), and Charles Fourier, whose followers organized other settlements in the United States such as Brook Farm (1841–47). Later in the 19th century, Karl Marx described these social reformers as "utopian socialists" to contrast them with his program of "scientific socialism" (a term coined by Friedrich Engels). Other writers described by Marx as "utopian socialists" included Saint-Simon.
In its modern form, communism grew out of the socialist movement of 19th century Europe. As the Industrial Revolution advanced, socialist critics blamed capitalism for the misery of the proletariat—a new class of urban factory workers who laboured under often-hazardous conditions. Foremost among these critics were Marx and his associate Friedrich Engels. In 1848, Marx and Engels offered a new definition of communism and popularized the term in their famous pamphlet "The Communist Manifesto". Engels, who lived in Manchester, observed the organization of the Chartist movement ("see History of British socialism"), while Marx departed from his university comrades to meet the proletariat in France and Germany.
Modern Communism.
In the late 19th century, Russian Marxism developed a distinct character. The first major figure of Russian Marxism was Georgi Plekhanov. Underlying the work of Plekhanov was the assumption that Russia, less urbanized and industrialized than Western Europe, had many years to go before society would be ready for proletarian revolution to occur, and a transitional period of a bourgeois democratic regime would be required to replace Tsarism with a socialist and later communist society. (EB)
In Russia, the 1917 October Revolution was the first time any party with an avowedly Marxist orientation, in this case the Bolshevik Party, seized state power. The assumption of state power by the Bolsheviks generated a great deal of practical and theoretical debate within the Marxist movement. Marx predicted that socialism and communism would be built upon foundations laid by the most advanced capitalist development. Russia, however, was one of the poorest countries in Europe with an enormous, largely illiterate peasantry and a minority of industrial workers. Marx had explicitly stated that Russia might be able to skip the stage of bourgeoisie capitalism. Other socialists also believed that a Russian revolution could be the precursor of workers' revolutions in the West.
The moderate Mensheviks opposed Lenin's Bolshevik plan for socialist revolution before capitalism was more fully developed. The Bolsheviks' successful rise to power was based upon the slogans such as "Peace, bread, and land" which tapped the massive public desire for an end to Russian involvement in the First World War, the peasants' demand for land reform, and popular support for the Soviets.
The usage of the terms "communism" and "socialism" shifted after 1917, when the Bolsheviks changed their name to "Communist Party" and installed a single party regime devoted to the implementation of socialist policies under Leninism. The Second International had dissolved in 1916 over national divisions, as the separate national parties that composed it did not maintain a unified front against the war, instead generally supporting their respective nation's role. Lenin thus created the Third International (Comintern) in 1919 and sent the Twenty-one Conditions, which included democratic centralism, to all European socialist parties willing to adhere. In France, for example, the majority of the French Section of the Workers' International (SFIO) party split in 1921 to form the French Section of the Communist International (SFIC). Henceforth, the term "Communism" was applied to the objective of the parties founded under the umbrella of the Comintern. Their program called for the uniting of workers of the world for revolution, which would be followed by the establishment of a dictatorship of the proletariat as well as the development of a socialist economy. Ultimately, if their program held, there would develop a harmonious classless society, with the withering away of the state.
During the Russian Civil War (1918–1922), the Bolsheviks nationalized all productive property and imposed a policy of war communism, which put factories and railroads under strict government control, collected and rationed food, and introduced some bourgeois management of industry. After three years of war and the 1921 Kronstadt rebellion, Lenin declared the New Economic Policy (NEP) in 1921, which was to give a "limited place for a limited time to capitalism." The NEP lasted until 1928, when Joseph Stalin achieved party leadership, and the introduction of the first Five Year Plan spelled the end of it. Following the Russian Civil War, the Bolsheviks, in 1922, formed the Union of Soviet Socialist Republics (USSR), or Soviet Union, from the former Russian Empire.
Following Lenin's democratic centralism, the communist parties were organized on a hierarchical basis, with active cells of members as the broad base; they were made up only of elite cadres approved by higher members of the party as being reliable and completely subject to party discipline. The Great Purge of 1937–1938 was Stalin's attempt to destroy any possible opposition within the Communist Party. In the Moscow Trials many old Bolsheviks who had played prominent roles during the Russian Revolution of 1917, or in Lenin's Soviet government afterwards, including Kamenev, Zinoviev, Rykov, and Bukharin, were accused, pleaded guilty, and executed.
Following World War II, Communists consolidated power in Central and Eastern Europe, and in 1949, the Communist Party of China (CPC), led by Mao Zedong, established the People's Republic of China, which would follow its own ideological path of Communist development following the Sino-Soviet split. Cuba, North Korea, Vietnam, Laos, Cambodia, Angola, and Mozambique were among the other countries in the Third World that adopted or imposed a Communist government at some point. By the early 1980s almost one-third of the world's population lived in Communist states, including the former Soviet Union and PRC.
Communist states such as the Soviet Union and PRC succeeded in becoming industrial and technological powers, challenging the capitalists' powers in the arms race and space race.
Cold War.
By virtue of the Soviet Union's victory in the Second World War in 1945, the Red Army occupied nations not only in Central and Eastern Europe, but also in East Asia; consequently, communism as a movement spread to many new countries. This expansion of communism both in Europe and Asia gave rise to a few different branches of its own, such as Maoism.
Communism had been vastly strengthened by the winning of many new nations into the sphere of Soviet influence and strength in Central and Eastern Europe. Governments modelled on Soviet Communism took power with Soviet assistance in Bulgaria, Czechoslovakia, East Germany, Poland, Hungary and Romania. A Communist government was also created under Marshal Tito in Yugoslavia, but Tito's independent policies led to the expulsion of Yugoslavia from the Cominform, which had replaced the Comintern. Titoism, a new branch in the world Communist movement, was labelled "deviationist". Albania also became an independent Communist nation after World War II.
By 1950, the Chinese Communists held all of Mainland China, thus controlling the most populous nation in the world. Other areas where rising Communist strength provoked dissension and in some cases led to actual fighting through conventional and guerrilla warfare include the Korean War, Laos, many nations of the Middle East and Africa, and notably succeeded in the case of the Vietnam War against the military power of the United States and its allies. With varying degrees of success, Communists attempted to unite with nationalist and socialist forces against what they saw as Western imperialism in these poor countries.
Red Scare.
With the exception of the contribution in World War II by the Soviet Union, China, and the Italian resistance movement, communism was seen as a rival, and a threat to western democracies and capitalism for most of the 20th century. This rivalry peaked during the Cold War, as the world's two remaining superpowers, the United States and the Soviet Union, polarized most of the world into two camps of nations. This was characterized in the West as "The Free World" vs. "Behind the Iron Curtain". It supported the spread of their respective economic and political systems (capitalism and communism) and strengthened their military powers. As a result, the camps developed new weapon systems, stockpiled nuclear weapons, and competed in space exploration.
Near the beginning of the Cold War, on February 9, 1950, Senator Joseph McCarthy from Wisconsin accused 205 Americans working in the State Department of being "card-carrying communists". The fear of communism in the U.S. spurred McCarthyism, aggressive investigations and the red-baiting, blacklisting, jailing and deportation of persons suspected of following communist or other left-wing ideologies. Many famous actors and writers were placed on a blacklist from 1950 to 1954, which meant they would not be hired and would be subject to public disdain.
After the collapse of the Soviet Union.
In 1985, Mikhail Gorbachev became leader of the Soviet Union and relaxed central control, in accordance with reform policies of glasnost (openness) and perestroika (restructuring). The Soviet Union did not intervene as Poland, East Germany, Czechoslovakia, Bulgaria, Romania, and Hungary all abandoned Communist rule by 1990. In 1991, the Soviet Union dissolved.
By the beginning of the 21st century, states controlled by communist parties under a single-party system include the People's Republic of China, Cuba, Laos, Vietnam, and North Korea. Communist parties, or their descendant parties, remain politically important in a number of other countries. President Dimitris Christofias of Cyprus is a member of the Progressive Party of Working People, but the country is not run under single-party rule. The South African Communist Party is a partner in the African National Congress-led government. In India, communists lead the governments of three states, with a combined population of more than 115 million. In Nepal, communists hold a majority in the parliament. The Communist Party of Brazil is a part of the parliamentary coalition led by the ruling democratic socialist Workers' Party and is represented in the executive cabinet of Dilma Rousseff.
The People's Republic of China has reassessed many aspects of the Maoist legacy; it, along with Laos, Vietnam, and, to a lesser degree Cuba, has reduced state control of the economy in order to stimulate growth. Chinese economic reforms started in 1978 under the leadership of Deng Xiaoping; since then, China has managed to bring down the poverty rate from 53% in the Mao era to just 6% in 2001. The People's Republic of China runs Special Economic Zones dedicated to market-oriented enterprise, free from central government control. Several other communist states have also attempted to implement market-based reforms, including Vietnam.
Theories within Marxism as to why communism in Central and Eastern Europe was not achieved after socialist revolutions pointed to such elements as the pressure of external capitalist states, the relative backwardness of the societies in which the revolutions occurred, and the emergence of a bureaucratic stratum or class that arrested or diverted the transition press in its own interests. (Scott and Marshall, 2005) Marxist critics of the Soviet Union, most notably Trotsky, referred to the Soviet system, along with other Communist states, as "degenerated" or "deformed workers' states", arguing that the Soviet system fell far short of Marx's communist ideal and he claimed the working class was politically dispossessed. The ruling stratum of the Soviet Union was held to be a bureaucratic caste, but not a new ruling class, despite their political control. Anarchists who adhere to Participatory economics claim that the Soviet Union became dominated by powerful intellectual elites who in a capitalist system crown the proletariat's labour on behalf of the bourgeoisie.
Non-Marxists, in contrast, have often applied the term to any society ruled by a communist party and to any party aspiring to create a society similar to such existing nation-states. In the social sciences, societies ruled by communist parties are distinct for their single party control and their socialist economic bases. While some social and political scientists applied the concept of "totalitarianism" to these societies, others identified possibilities for independent political activity within them, and stressed their continued evolution up to the point of the dissolution of the Soviet Union and its allies in Central Europe during the late 1980s and early 1990s.
Marxist Communism.
Variations to the communist movement have developed, each based upon the ideas of different political theorists, usually as additions or interpretations of various forms of Marxism, the collective philosophies of the German philosophers Karl Marx. Marxism-Leninism is the synthesis of Vladimir Lenin's contributions to Marxism, such as how a revolutionary party should be organised; Trotskyism is Leon Trotsky's conception of Marxism, influenced by Lenin, and meanwhile, Maoism is Mao Zedong's interpretation of Marxism to suit the conditions of China at that time, and is fairly heavy on the need for agrarian worker support as the engine for the revolution, rather than workers in the urban areas, which were still very small at that point.
Self-identified communists hold a variety of views, including Marxism-Leninism, Trotskyism, council communism, Luxemburgism, anarchist communism, Christian communism, and various currents of left communism. However, the offshoots of the Marxist-Leninist interpretations of Marxism are the best-known of these and had been a driving force in international relations during the last quarter of the 19th century and most of the 20th century up to around 1989 and what historians refer to as "the collapse of communism." However, other forms of communism worldwide continue to exist in the ideologies of various individual labor movement trade unions worldwide, particularly in Europe and the Third World, and also in communist parties that continue to espouse the ultimate need for communist revolution.
Most communists today tend to agree that the remaining communist states, such as China, Vietnam and especially North Korea (which has replaced Marxism-Leninism with Juche as its official ideology), have nothing to do with communism, whether as practised currently within leftist resistance movements and parties, or in terms of the ideologies and programmes held by those movements.
A diverse range of theories persist amongst prominent globally known people such as Slavoj Zizek, Michael Parenti, Alain Badiou and other radical left thinkers who proclaim themselves communists; they and others like them are examples of present-day well-known figures in the modern communist movement.
Marxism.
Like other socialists, Karl Marx and Friedrich Engels sought an end to capitalism and the systems which they perceived to be responsible for the exploitation of workers. Whereas earlier socialists often favored longer-term social reform, Marx and Engels believed that popular revolution was all but inevitable, and the only path to socialism and communism.
According to the Marxist argument for communism, the main characteristic of human life in class society is alienation; and communism is desirable because it entails the full realization of human freedom. Marx here follows Georg Wilhelm Friedrich Hegel in conceiving freedom not merely as an absence of restraints but as action with content. According to Marx, communism's outlook on freedom was based on an agent, obstacle, and goal. The agent is the common/working people; the obstacles are class divisions, economic inequalities, unequal life-chances, and false consciousness; and the goal is the fulfilment of human needs including satisfying work, and fair share of the product.
They believed that communism allowed people to do what they want, but also put humans in such conditions and such relations with one another that they would not wish to exploit, or have any need to. Whereas for Hegel the unfolding of this ethical life in history is mainly driven by the realm of ideas, for Marx, communism emerged from material forces, particularly the development of the means of production.
Marx's lasting vision was to add this vision to a theory of how society was moving in a law-governed way towards communism, and, with some tension, a political theory that explained why revolutionary activity was required to bring it about.
In the late 19th century, the terms "socialism" and "communism" were often used interchangeably. However, Marx and Engels argued that communism would not emerge from capitalism in a fully developed state, but would pass through a "first phase" in which most productive property was owned in common, but with some class differences remaining. The "first phase" would eventually evolve into a "higher phase" in which class differences were eliminated, and a state was no longer needed. Lenin frequently used the term "socialism" to refer to Marx and Engels' supposed "first phase" of communism and used the term "communism" interchangeably with Marx and Engels' "higher phase" of communism.
These later aspects, particularly as developed by Vladimir Lenin, provided the underpinning for the mobilizing features of 20th century communist parties.
Leninism and Marxism-Leninism.
Leninism is the political movement developed by Vladimir Lenin, which has become the foundation for the organizational structure of most major communist parties. Leninists advocate the creation of a vanguard party led by dedicated revolutionaries in order to lead the working class revolution to victory. Leninists believe that socialism will not arise spontaneously through the natural decay of capitalism and that workers are unable to organize and develop socialist consciousness without the guidance of the Vanguard party. After taking power, Vanguard parties seek to create a socialist state continually led by the Vanguard party in order to direct social development and defend against counterrevolutionary insurrection. The mode of industrial organization championed by Leninism and Marxism-Leninism is the capitalist model of scientific management pioneered by Fredrick Taylor.
Marxism-Leninism is a version of Leninism merged with classical Marxism adopted by the Soviet Union and most communist parties across the world today. It shaped the Soviet Union and influenced communist parties worldwide. It was heralded as a possibility of building communism via a massive program of industrialization and collectivisation. Despite the fall of the Soviet Union and the 'Eastern Bloc' (meaning communist countries of Eastern and Central Europe), many communist parties of the world today still lay claim to uphold the Marxist-Leninist banner. Marxism-Leninism expands on Marxist thoughts by bringing the theories to what Lenin and other Communists considered, the age of capitalist imperialism, and a renewed focus on party building, the development of a socialist state, and democratic centralism as an organisational principle.
Lenin's pamphlet "What is to be Done?" (1902), proposed that the (urban) proletariat can successfully achieve revolutionary consciousness only under the leadership of a vanguard party of professional revolutionaries—who can achieve aims only with internal democratic centralism in the party; tactical and ideological policy decisions are agreed via democracy, and every member must support and promote the agreed party policy.
The post-revolutionary Bolshevik government was hostile to nationalism, especially to Russian nationalism, the "Great Russian chauvinism", which was seen as an obstacle to establishing the dictatorship of the proletariat. However, under the regime of Joseph Stalin, after the Allied victory in the Great Patriotic War, Russian nationalism became upheld as a force in shaping both the domestic and foreign policies of the Soviet Union. 
The primary elements unique to Marxism-Leninism are: the revolutionary vanguard party, revolution as a means to overthrow capitalism, and democratic centralism.
Stalinism.
Stalinism was the political system of the Soviet Union and the countries within the Soviet sphere of influence during the leadership of Joseph Stalin. The term usually defines the style of a government rather than an ideology. The ideology was officially Marxism-Leninism theory, reflecting that Stalin himself was not a theoretician, in contrast to Marx and Lenin, and prided himself on maintaining the legacy of Lenin as a founding father for the Soviet Union and the future Socialist world. Stalinism is an interpretation of their ideas, and a certain political regime claiming to apply those ideas in ways fitting the changing needs of Soviet society, as with the transition from "socialism at a snail's pace" in the mid-twenties to the rapid industrialization of the Five-Year Plans.
The legitimacy of Stalin's claim to the role of leadership in the Soviet Union (and thus the international communist movement as a whole) is a matter of some debate. Advocates of Stalinism cite both Lenin's praising of the early works of Stalin and the economic successes of the Five-Year Plans. Opponents, however, point out that certain aspects of Stalinism (socialism in one country, "revolutionary patriotism", etc.) are not found in Leninism, and argue that some aspects are even contradictory to Marxism-Leninism. Also, in Lenin's Testament, a document written by Vladimir Lenin in the last weeks of 1922 and the first week of 1923 outlining his proposed changes to the structure of the Soviet governing bodies, Lenin suggested "that the comrades think about a way of removing Stalin from Secretary-General post and appointing another man in his stead who in all other respects differs from Comrade Stalin in having only one advantage, namely, that of being more tolerant, more loyal, more polite and more considerate to the comrades, less capricious, etc." Both sides of this debate identify as being ideologically orthodox to Leninism and criticise the other as being "revisionist."
Trotskyism.
Trotskyism is the branch of Marxism that was developed by Leon Trotsky. It supports the theory of permanent revolution and world revolution instead of the two stage theory and socialism in one country. It supported proletarian internationalism and another Communist revolution in the Soviet Union, which, under the leadership of Stalin, Trotsky claimed had become a degenerated worker's state, rather than the dictatorship of the proletariat, in which class relations had re-emerged in a new form.
Trotsky and his supporters organized into the "Left Opposition" and their platform became known as Trotskyism. Stalin eventually succeeded in gaining control of the Soviet regime and Trotskyist attempts to remove Stalin from power resulted in Trotsky's exile from the Soviet Union in 1929. During Trotsky's exile, world communism fractured into two distinct branches: Marxism-Leninism and Trotskyism. Trotsky later founded the Fourth International, a Trotskyist rival to the Comintern, in 1938.
Trotskyist ideas have continually found a modest echo among political movements in some countries in Latin America and Asia, especially in Argentina, Brazil, Bolivia and Sri Lanka. Many Trotskyist organizations are also active in more stable, developed countries in North America and Western Europe. Trotsky's politics differed sharply from those of Stalin and Mao, most importantly in declaring the need for an international proletarian revolution (rather than socialism in one country) and unwavering support for a true dictatorship of the proletariat based on democratic principles.
However, as a whole, Trotsky's theories and attitudes were never accepted in worldwide mainstream Communist circles after Trotsky's expulsion, either within or outside of the Soviet bloc. This remained the case even after the Secret Speech and subsequent events which critics claim exposed the fallibility of Stalin.
Maoism.
Maoism is the Marxist-Leninist trend of Communism associated with Mao Zedong and was mostly practiced within China. Nikita Khrushchev's reforms heightened ideological differences between China and the Soviet Union, which became increasingly apparent in the 1960s. Parties and groups that supported the Communist Party of China (CPC) in their criticism against the new Soviet leadership proclaimed themselves as 'anti-revisionist' and denounced the Communist Party of the Soviet Union and the parties aligned with it as revisionist "capitalist-roaders." The Sino-Soviet Split resulted in divisions amongst communist parties around the world. Notably, the Party of Labour of Albania sided with the People's Republic of China. Effectively, the CPC under Mao's leadership became the rallying forces of a parallel international Communist tendency.
Definitions of Maoism vary. Within the Chinese context, Maoism can refer to Mao's belief in the mobilization of the masses, particularly in large-scale political movements; it can also refer to the egalitarianism that was seen during Mao's era as opposed to the free-market ideology of Deng Xiaoping; some scholars additionally define personality cults and political sloganeering as "Maoist" practices. Contemporary Maoists in China criticize the social inequalities created by a capitalist and 'revisionist' Communist party.
Prachanda Path.
Prachanda Path refers to the ideological line of the Unified Communist Party of Nepal. This thought is an extension of Marxism, Leninism and Maoism, totally based on home-ground politics of Nepal. The doctrine came into existence after it was realized that the ideology of Marxism, Leninism and Maoism could not be practiced completely as it was done in the past. And an ideology suitable, based on the ground reality of Nepalese politics was adopted by the party.
Hoxhaism.
Another variant of anti-revisionist Marxism-Leninism appeared after the ideological row between the Communist Party of China and the Party of Labour of Albania in 1978. The Albanians rallied a new separate international tendency, which would demarcate itself by a strict defence of the legacy of Joseph Stalin and fierce criticism of virtually all other Communist groupings as revisionism. Critical of the United States, the Soviet Union, and China, Enver Hoxha declared the latter two to be social-imperialist and condemned the Soviet invasion of Czechoslovakia by withdrawing from the Warsaw Pact in response. Hoxha declared Albania to be the world's only Marxist-Leninist state after 1978. The Albanians were able to win over a large share of the Maoists, mainly in Latin America such as the Popular Liberation Army, but also had a significant international following in general. This tendency has occasionally been labelled as 'Hoxhaism' after him.
After the fall of the Communist government in Albania, the pro-Albanian parties are grouped around an international conference and the publication 'Unity and Struggle'.
Titoism.
Elements of Titoism are characterized by policies and practices based on the principle that in each country, the means of attaining ultimate communist goals must be dictated by the conditions of that particular country, rather than by a pattern set in another country. During Tito's era, this specifically meant that the communist goal should be pursued independently of (and often in opposition to) the policies of the Soviet Union. The term was originally meant as a pejorative, and was labelled by Moscow as a heresy during the period of tensions between the Soviet Union and Yugoslavia known as the "Informbiro" period from 1948 to 1955.
Unlike the rest of Central and Eastern Europe, which fell under Stalin's influence post–World War II, Yugoslavia, due to the strong leadership of Marshal Josip Broz Tito and the fact that the Yugoslav Partisans liberated Yugoslavia with only limited help from the Red Army, remained independent from Moscow. It became the only country in the Balkans to resist pressure from Moscow to join the Warsaw Pact and remained "socialist, but independent" until the collapse of Soviet socialism in the late 1980s and early 1990s. Throughout his time in office, Tito prided himself on Yugoslavia's independence from Russia, with Yugoslavia never accepting full membership of the Comecon and Tito's open rejection of many aspects of Stalinism as the most obvious manifestations of this.
Eurocommunism.
Eurocommunism was a trend in the 1970s and 1980s within various Western European communist parties to develop a theory and practice of social transformation that was more relevant in a Western European democracy and less aligned to the influence or control of the Soviet Union. Parties such as the Italian Communist Party (PCI), the French Communist Party (PCF), and the Communist Party of Spain (PCE), were politically active and electorally significant in their respective countries).
The main theoretical foundation of Eurocommunism was Antonio Gramsci's writing about Marxist theory which questioned the sectarianism of the Left and encouraged communist parties to develop social alliances to win "hegemonic" support for social reforms. Eurocommunist parties expressed their fidelity to democratic institutions more clearly than before and attempted to widen their appeal by embracing public sector middle-class workers, new social movements such as feminism and gay liberation and more publicly questioning the Soviet Union. Early inspirations can also be found in the Austromarxism and its seeking of a "third" democratic "way" to socialism.
Libertarian Marxism.
Libertarian Marxism refers to a broad scope of economic and political philosophies that emphasize the anti-authoritarian aspects of Marxism. Early currents of libertarian Marxism, known as left communism, emerged in opposition to Marxism–Leninism and its derivatives, such as Stalinism, Maoism, and Trotskyism. Libertarian Marxism is also critical of reformist positions, such as those held by social democrats. Libertarian Marxist currents often draw from Marx and Engels' later works, specifically the "Grundrisse" and "The Civil War in France"; emphasizing the Marxist belief in the ability of the working class to forge its own destiny without the need for a revolutionary party or state to mediate or aid its liberation. Along with anarchism, Libertarian Marxism is one of the main currents of libertarian socialism.
Libertarian Marxism includes such currents as Luxemburgism, council communism, left communism, "Socialisme ou Barbarie", the Johnson-Forest tendency, world socialism, Lettrism/Situationism and operaismo/autonomism, and New Left. Libertarian Marxism has often had a strong influence on both post-left and social anarchists. Notable theorists of libertarian Marxism have included Anton Pannekoek, Raya Dunayevskaya, CLR James, Antonio Negri, Cornelius Castoriadis, Maurice Brinton, Guy Debord, Daniel Guérin, Ernesto Screpanti and Raoul Vaneigem.
Council Communism.
Council communism is a far-left movement originating in Germany and the Netherlands in the 1920s. Its primary organization was the Communist Workers Party of Germany (KAPD). Council communism continues today as a theoretical and activist position within both left-wing Marxism and libertarian socialism.
The central argument of council communism, in contrast to those of social democracy and Leninist Communism, is that democratic workers' councils arising in the factories and municipalities are the natural form of working class organisation and governmental power. This view is opposed to both the reformist and the Leninist ideologies, with their stress on, respectively, parliaments and institutional government (i.e., by applying social reforms), on the one hand, and vanguard parties and participative democratic centralism on the other).
The core principle of council communism is that the government and the economy should be managed by workers' councils composed of delegates elected at workplaces and recallable at any moment. As such, council communists oppose state-run authoritarian "State socialism"/"State capitalism". They also oppose the idea of a "revolutionary party", since council communists believe that a revolution led by a party will necessarily produce a party dictatorship. Council communists support a worker's democracy, which they want to produce through a federation of workers' councils.
Left Communism.
Left communism is the range of communist viewpoints held by the communist left, which criticizes the political ideas of the Bolsheviks at certain periods, from a position that is asserted to be more authentically Marxist and proletarian than the views of Leninism held by the Communist International after its first and during its second congress.
Left Communists see themselves to the left of Leninists (whom they tend to see as 'left of capital', not socialists), anarchist communists (some of whom they consider internationalist socialists) as well as some other revolutionary socialist tendencies (for example De Leonists, who they tend to see as being internationalist socialists only in limited instances).
Although she died before left communism became a distinct tendency, Rosa Luxemburg has heavily influenced most left communists, both politically and theoretically. Proponents of left communism have included Amadeo Bordiga, Herman Gorter, Anton Pannekoek, Otto Rühle, Karl Korsch, Sylvia Pankhurst and Paul Mattick.
Prominent left communist groups existing today include the International Communist Party, the International Communist Current and the Internationalist Communist Tendency.
Situationism.
The Situationist International was a restricted group of international revolutionaries founded in 1957, and which had its peak in its influence on the unprecedented general wildcat strikes of May 1968 in France.
With their ideas rooted in Marxism and the 20th century European artistic avant-gardes, they advocated experiences of life being alternative to those admitted by the capitalist order, for the fulfillment of human primitive desires and the pursuing of a superior passional quality. For this purpose they suggested and experimented with the "construction of situations", namely the setting up of environments favorable for the fulfillment of such desires. Using methods drawn from the arts, they developed a series of experimental fields of study for the construction of such situations, like unitary urbanism and psychogeography.
They fought against the main obstacle on the fulfillment of such superior passional living, identified by them in advanced capitalism. Their theoretical work peaked on the highly influential book "The Society of the Spectacle" by Guy Debord. Debord argued in 1967 that spectacular features like mass media and advertising have a central role in an advanced capitalist society, which is to show a fake reality in order to mask the real capitalist degradation of human life. To overthrow such a system, the Situationist International supported the May 1968 revolts, and asked the workers to occupy the factories and to run them with direct democracy, through workers' councils composed by instantly revocable delegates.
After publishing in the last issue of the magazine an analysis of the May 1968 revolts, and the strategies that will need to be adopted in future revolutions, the SI was dissolved in 1972.
Autonomism.
Autonomism refers to a set of left-wing political and social movements and theories close to the socialist movement. As an identifiable theoretical system it first emerged in Italy in the 1960s from workerist ("operaismo") communism. Later, post-Marxist and anarchist tendencies became significant after influence from the Situationists, the failure of Italian far-left movements in the 1970s, and the emergence of a number of important theorists including Antonio Negri, who had contributed to the 1969 founding of "Potere Operaio", Mario Tronti, Paolo Virno, etc.
Through translations made available by Danilo Montaldi and others, the Italian autonomists drew upon previous activist research in the United States by the Johnson-Forest Tendency and in France by the group Socialisme ou Barbarie.
It influenced the German and Dutch Autonomen, the worldwide Social Centre movement, and today is influential in Italy, France, and to a lesser extent the English-speaking countries. Those who describe themselves as autonomists now vary from Marxists to post-structuralists and anarchists. The Autonomist Marxist and "Autonomen" movements provided inspiration to some on the revolutionary left in English speaking countries, particularly among anarchists, many of whom have adopted autonomist tactics. Some English-speaking anarchists even describe themselves as "Autonomists". The Italian "operaismo" movement also influenced Marxist academics such as Harry Cleaver, John Holloway, Steve Wright, and Nick Dyer-Witheford.
Non-Marxist Communism.
The dominant forms of communism are based on Marxism, but non-Marxist versions of communism (such as Christian communism and anarchist communism) also exist.
Anarchist Communism.
Anarchist communism (also known as libertarian communism) is a theory of anarchism which advocates the abolition of the state, private property, and capitalism in favour of common ownership of the means of production, direct democracy and a horizontal network of voluntary associations and workers' councils with production and consumption based on the guiding principle: "from each according to his ability, to each according to his need".
Anarcho-communism differs from marxism rejecting its view about the need for a State Socialism phase before building communism. The main anarcho-communist theorist Peter Kropotkin argued "that a revolutionary society should “transform itself immediately into a communist society,”, that is, should go immediately into what Marx had regarded as the “more advanced,” completed, phase of communism." In this way it tries to avoid the reappearence of "class divisions and the need for a state to oversee everything".
Some forms of anarchist communism such as insurrectionary anarchism are egoist and strongly influenced by radical individualism, believing that anarchist communism does not require a communitarian nature at all. Most anarcho-communists view anarcho-communism as a way of reconciling the opposition between the individual and society
To date in human history, the best known examples of an "anarchist communist" society, established around the ideas as they exist today, that received worldwide attention and knowledge in the historical canon, are the anarchist territories during the Spanish Revolution and the Free Territory during the Russian Revolution. Through the efforts and influence of the Spanish Anarchists during the Spanish Revolution within the Spanish Civil War, starting in 1936 anarchist communism existed in most of Aragon, parts of the Levante and Andalusia, as well as in the stronghold of Anarchist Catalonia before being brutally crushed by the combined forces of the authoritarian regime that won the war, Hitler, Mussolini, Spanish Communist Party repression (backed by the USSR) as well as economic and armaments blockades from the capitalist countries and the Spanish Republic itself. During the Russian Revolution, anarchists such as Nestor Makhno worked to create and defend—through the Revolutionary Insurrectionary Army of Ukraine—anarchist communism in the Free Territory of the Ukraine from 1919 before being conquered by the Bolsheviks in 1921.
Christian Communism.
Christian communism can be seen as a radical form of Christian socialism. Also, because many Christian communists have formed independent stateless communes in the past, there is a link between Christian communism and Christian anarchism. Christian communists may not agree with various parts of Marxism, but they share some of the political goals of Marxists, for example replacing capitalism with socialism, which should in turn be followed by communism at a later point in the future. However, Christian communists sometimes disagree with Marxists (and particularly with Leninists) on the way a socialist or communist society should be organized.
Criticism.
Some people have criticised socialism and by extension communism, stating that the two systems have distorted or absent price signals, slow or stagnant technological advance, reduced incentives, and reduced prosperity, as well as on the grounds of its feasibility and its social and political effects.
Part of this criticism extends to the policies adopted by one-party states ruled by communist parties (known as "communist states"). Some scholars are specially focused on their human rights records which are claimed to be responsible for famines, purges and warfare resulting in deaths far in excess of previous empires, capitalist or other regimes. However, such state regimes do not fit the definition of communism as a stateless and international workers' democracy, as repeatedly advocated by Marx and Engels, and subsequent orthodox Marxists. 
The Council of Europe in Resolution 1481 and international declarations such as the Prague Declaration on European Conscience and Communism and the Declaration on Crimes of Communism have condemned some of the actions that resulted in these deaths as crimes.
Stéphane Courtois argues that communism is responsible for the murder of almost 100 million people in the 20th century, but two of the main "Black Book"'s contributors, Nicolas Werth and Jean-Louis Margolin, disagreed and publicly disassociated themselves from Courtois's statements.
References.
Notes
Bibliography
Further reading

Confederate States of America
The Confederate States of America (also called the Confederacy and the CSA) was a government set up from 1861 to 1865 by a number of Southern slave states that had declared their secession from the United States. The Confederacy recognized, as members, 11 states that had formally declared secession, two additional states with less formal declarations, and one new territory. The Confederacy was eventually defeated in the American Civil War against the Union (the U.S.). Secessionists argued that the United States Constitution was a compact among states, an agreement which each state could abandon without consultation. The Union government rejected secession as illegal. Following the Confederate attack at Fort Sumter, the Union used military action to defeat the Confederacy. No foreign nation officially recognized the Confederacy as an independent country, but several did grant belligerent status.
The Confederate Constitution of seven state signatories — South Carolina, Mississippi, Florida, Alabama, Georgia, Louisiana and Texas — formed a "permanent federal government" in Montgomery, Alabama, in 1861. In response to a call by U. S. President Abraham Lincoln for troops from each state to recapture Sumter and other lost federal properties in the South, four additional slave-holding states — Virginia, Arkansas, Tennessee and North Carolina — declared their secession and joined the Confederacy. Missouri and Kentucky were represented by partisan factions from those states. Also aligned with the Confederacy were the Five Civilized Tribes and a new Confederate Territory of Arizona. Efforts to secede in Maryland were halted by martial law, while Delaware, though of divided loyalty, did not attempt it. A Unionist government in western parts of Virginia organized the new state of West Virginia which was admitted to the Union on June 20, 1863. The Confederate government in Richmond, Virginia had an uneasy relationship with its member states because of issues related to control of manpower, although the South mobilized nearly its entire white male population for war.
Confederate control over its claimed territory and population steadily shrank from 73% to 34% during the course of the Civil War due to the successful Union overland campaigns, their control of inland waterways into the South and the seacoast Union blockade. These created an insurmountable disadvantage in men and supplies and finance. Public support of the Jefferson Davis administration eroded over time with repeated military reverses, economic hardship and charges of autocratic government. Richmond fell after four years of Union campaigns in April 1865, and shortly afterwards, Confederate General Robert E. Lee surrendered to Union General Ulysses S. Grant, and with that the Confederacy effectively collapsed. Four years later, the Supreme Court ruled in "Texas v. White" that secession was illegal, and that the Confederacy had never legally existed.
The U.S. Congress began a decade-long process known as Reconstruction which some scholars treat as an extension of the Civil War. It lasted throughout the administrations of Lincoln, Andrew Johnson and Grant, and saw the adoption of the Thirteenth Amendment to free slaves, the Fourteenth to guarantee dual U.S. and state citizenship to all, and the Fifteenth to guarantee the right to vote in states. The war left the South economically devastated by military action, ruined infrastructure and exhausted resources. The region remained well below national levels of prosperity until after World War II.
History.
The Confederacy was formed in the Montgomery Convention February 1861 by state delegations sent from seven of the United States. Following Lincoln’s inauguration, four additional border states were represented, and subsequently two states and two territories gained seats in the Confederate Congress in accordance with their Secessionist resolves. The government existed from Spring 1861 to Spring 1865 during a Civil War initiated by Confederate firing on U.S. Fort Sumter. 
A sufficient number of whites had considered themselves more Southern than American and would fight for their state and their section to be apart from the larger nation. That sectionalism became Southern nationalism, the "Cause". For the duration of its existence, the Confederacy underwent trial by war. The Southern Cause transcended ideology of "states' rights" concerning tariff policy or internal improvements to include lifestyle, values and belief system. Its “way of life” became sacred to its adherents. Everything of the South became a moral question, commingling love of things Southern and hatred of things Yankee. Not only did national political parties split, but national churches and interstate families also divided along sectional lines as the war approached. 
In no states were the whites unanimous. There were minority views everywhere and the upland plateau regions in every state had strongholds of Unionist support, especially western Virginia and eastern Tennessee. South of the Mason–Dixon Line voter support for the three pro-Union candidates in 1860 ranged from 37% in Florida to 71% in Missouri. It was an American tragedy, the Brothers' War according to some scholars, "brother against brother, father against son, kith against kin of every degree".
Nevertheless, historians argue that several thousand large-scale planters formed what they imagined to be a landed "aristocracy". They believed in a landed aristocratic ideal, despite depending on industrialized Europe for their markets, and they acted on their belief. The Confederacy had a much larger middle class of whites of small planters, farmers, merchants and artisans, which held to a “persistent folk culture in the Old South”. Otherwise, as the historian Emory Thomas notes, there would have been Confederate armies of planter generals with no soldiers.
A revolution in disunion.
The Confederate States of America was created by secessionists in Southern slave states who refused to remain in a nation that they believed was turning them into second–class citizens. The agent of the change was seen as abolitionists and anti-slavery elements in the Republican Party who used repeated insult and injury to subject them to intolerable "humiliation and degradation". The "Black Republicans" and their allies now threatened a majority in the United States House, Senate and Presidency, and on the Supreme Court, Chief Justice Roger B. Taney was 83 and ailing.
During the campaign for president in 1860, some secessionists threatened disunion at Lincoln’s election, most notably by William L. Yancey touring the north as Stephen A. Douglas toured the South calling for Union if Lincoln were elected. But to Secessionists, the Republican intent was clear. A Lincoln victory forced them to a formidable choice even before his inauguration, "The Union without slavery, or slavery without the Union."
Causes of secession.
In what later became known as the Cornerstone Speech, C.S. Vice President Alexander Stephens declared that the "cornerstone" of the new government "restupon the great truth that the negro is not equal to the white man; that slavery—subordination to the superior race—is his natural and normal condition. This, our new government, is the first, in the history of the world, based upon this great physical, philosophical, and moral truth". In later years, however, Stephens made efforts to qualify his remarks, claiming they were extemporaneous, metaphorical, and never meant to literally reflect "the principles of the new Government on this subject."
Four of the seceding states, the Deep South states of South Carolina,
Mississippi, Georgia, and Texas, issued formal declarations of causes, each of which identified the threat to slaveholders’ rights as the cause of, or a major cause of, secession. Georgia also claimed a general Federal policy of favoring Northern over Southern economic interests. Texas mentioned slavery 21 times, but also listed the failure of the federal government to live up to its obligations, in the original annexation agreement, to protect settlers along the exposed western frontier.
Secessionists and conventions.
The Fire-Eaters, calling for immediate secession, were opposed by two elements. "Cooperationists" in the Deep South would delay secession until several states went together, maybe in a Southern Convention. Under the influence of men such as Texas Governor Sam Houston, delay had the effect of sustaining the Union. "Unionists", especially in the Border South, often former Whigs, appealed to sentimental attachment to the United States. Their favorite was John Bell of Tennessee.
Secessionists were active politically. Governor William Henry Gist of South Carolina corresponded secretly with other Deep South governors, and most governors exchanged clandestine commissioners. Charleston’s secessionist "1860 Association" published over 200,000 pamphlets to persuade the youth of the South. The top three were South Carolina’s John Townsend’s “The Doom of Slavery”, “The South Alone Should Govern the South”, and James D.B. De Bow’s “The Interest of Slavery of the Southern Non-slaveholder.
Developments in South Carolina started a chain of events. The foreman of a jury refused the legitimacy of federal courts, so Federal Judge Andrew Magrath ruled that U.S. judicial authority in South Carolina was vacated. A mass meeting in Charleston celebrating the Charleston and Savannah railroad and state cooperation led to the South Carolina legislature to call for a Secession Convention. U.S. Senator James Chesnut, Jr. resigned, and U.S. Senator James Henry Hammond followed.
Elections for Secessionist conventions were heated to “an almost raving pitch, no one dared dissent”. Even once–respected voices, including the Chief Justice of South Carolina, John Belton O’Neall, lost election to the Secession Convention on a Cooperationist ticket. Across the South mobs lynched Yankees and (in Texas) Germans suspected of loyalty to the United States. Generally, seceding conventions which followed did not call for a referendum to ratify, although Texas, Arkansas, and Tennessee did, also Virginia’s second convention. Missouri and Kentucky declared neutrality.
Inauguration and response.
The first secession state conventions from the Deep South sent representatives to meet at the Montgomery Convention in Montgomery, Alabama, on February 4, 1861. There the fundamental documents of government were promulgated, a provisional government was established, and a representative Congress met for the Confederate States of America.
The new Confederate President Jefferson Davis, a former "Cooperationist" who had insisted on delaying secession until a united South could move together, issued a call for 100,000 states' militia to defend the newborn nation. Previously John B. Floyd, U.S. Secretary of War under President James Buchanan, had moved arms south out of northern U.S. armories. To economize War Department expenditures, Floyd and Congressional elements persuaded Buchanan not to put the armaments for southern forts into place. These were now appropriated to the Confederacy along with bullion and coining dies at the U.S. mints in Charlotte, North Carolina; Dahlonega, Georgia; and New Orleans. 
The Confederate capital removed to Richmond Virginia in February 1861, and on Washington's Birthday February 22, Jefferson Davis was inaugurated as permanent president with a term of six years. Five days later, he extended the earlier martial law declared in Norfolk and Portsmouth to ten miles beyond Richmond.
In his first Inaugural Address, Abraham Lincoln tried to contain the expansion of the Confederacy. To quiet the rising calls for secession in additional slave-holding states, he assured the Border States that slavery would be preserved in the states where it existed, and he entertained a proposed Thirteenth "Corwin Amendment" under consideration to explicitly protect slavery in the Constitution.
The newly inaugurated Confederate Administration pursued a policy of national territorial integrity, continuing earlier state efforts in 1860 and early 1861 to remove U.S. government presence from within their boundaries. These efforts included taking possession of U.S. courts, custom houses, post offices, and most notably, arsenals and forts. But at the Confederate attack on Fort Sumter, Lincoln called up 75,000 of the states’ militia to muster under his command. The stated purpose was to re-occupy U.S. properties throughout the South, as the U.S. Congress had not authorized their abandonment. The resistance at Fort Sumter signaled his change of policy from that of the Buchanan Administration. Lincoln's response ignited a firestorm of emotion. The people both North and South demanded war, and young men rushed to their colors in their hundreds of thousands. Four more states (Virginia, North Carolina, Tennessee, and Arkansas) declared secessions, while Kentucky tried to remain neutral.
Secession.
Secessionists argued that the United States Constitution was a compact among states that could be abandoned at any time without consultation and that each state had a right to secede. After intense debates and statewide votes, seven Deep South cotton states passed secession ordinances by February 1861 (before Abraham Lincoln took office as president), while secession efforts failed in the other eight slave states. Delegates from those seven formed the C.S.A. in February 1861, selecting Jefferson Davis as the provisional president. Unionist talk of reunion failed and Davis began raising a 100,000 man army.
States.
Initially, secessionists hoped for a peaceful departure, including all slave-holding states in the Union. Moderates in the Confederate Constitutional Convention included a provision against importation of slaves from Africa to appeal to the Upper South. Non-slave states might join, but the radicals secured a two-thirds hurdle for them.
Kentucky declared neutrality but after Confederate troops moved in, the state government asked for Union troops to drive them out. Confederate state government relocated to accompany western Confederate armies and never controlled state population.
In Missouri, on October 31, 1861, a pro-CSA remnant of the General Assembly met and passed an ordinance of secession. The Confederate state government was unable to control very much Missouri territory. It had its capital first at Neosho, then at Cassville, before being driven out of the state. For the remainder of the war, it operated as a government in exile at Marshall, Texas.
Neither Kentucky nor Missouri were declared in rebellion in the Emancipation Proclamation. The Confederacy recognized the pro-Confederate claimants in both Kentucky and Missouri and laid claim to those states, granting them Congressional representation and adding two stars to the Confederate flag.
The order of secession resolutions and dates follow.
1. South Carolina (December 20, 1860) 
2. Mississippi (January 9, 1861) 
3. Florida (January 10) 
4. Alabama (January 11) 
5. Georgia (January 19) 
6. Louisiana (January 26) 
7. Texas (February 1; referendum the 23d) 
– Ft. Sumter and Lincoln's call up –
8. Virginia (April 17; referendum May 23, 1861) 
9. Arkansas (May 6) 
10. Tennessee (May 7; referendum June 8) 
11. North Carolina (May 20, 1861) 
In Virginia the populous counties along the Ohio and Pennsylvania borders rejected the Confederacy. Unionists held a Convention in Wheeling in June 1861, establishing a "restored government" with a rump legislature, but sentiment in the region remained deeply divided. In the 50 counties that would make up the state of West Virginia, voters from 24 counties had voted for disunion in Virginia's May 23 referendum on the ordinance of secession. In the 1860 Presidential election "Constitutional Democrat" Breckenridge had outpolled "Constitutional Unionist" Bell in the 50 counties by 1,900 votes, 44% to 42%. Regardless of scholarly disputes over election procedures and results county by county, altogether they simultaneously supplied over 20,000 soldiers to each side of the conflict. Representatives for most of the counties were seated in both state legislatures at Wheeling and at Richmond for the duration of the war.
Attempts to secede from the Confederacy by some counties in East Tennessee were checked by martial law.
Although slave-holding Delaware and Maryland did not secede, citizens from those states exhibited divided loyalties. Maryland regiments fought in Lee's Army of Northern Virginia. Delaware never produced a full regiment for the Confederacy, but neither did it emancipate slaves as did Missouri and West Virginia. District of Columbia citizens made no attempts to secede and through the war years, Lincoln-sponsored referendums approved systems of compensated emancipation and slave confiscation from "disloyal citizens".
Territories.
Citizens at Mesilla and Tucson in the southern part of New Mexico Territory formed a secession convention, which voted to join the Confederacy on March 16, 1861, and appointed Lewis Owings as the new territorial governor. They won the Battle of Mesilla and established a territorial government with Mesilla serving as its capital. The Confederacy proclaimed the Confederate Arizona Territory on February 14, 1862 north to the 34th parallel. Marcus H. MacWillie served in both Confederate Congresses as Arizona’s delegate. In 1862 the Confederate New Mexico Campaign to take the northern half of the U.S. territory failed and the Confederate territorial government in exile relocated to San Antonio, Texas.
Confederate supporters in the trans-Mississippi west also claimed portions of United States Indian Territory after the United States evacuated the federal forts and installations. Over half of the American Indian troops participating in the Civil War from the Indian Territory supported the Confederacy; troops and one general were enlisted from each tribe. On July 12, 1861, the Confederate government signed a treaty with both the Choctaw and Chickasaw Indian nations. After several battles Northern armies moved back into the territory.
Indian Territory was never formally ceded into the Confederacy by American Indian councils, but like Missouri and Kentucky, the Five Civilized Nations received representation in the Confederate Congress and their citizens were integrated into regular Confederate Army units. After 1863 the tribal governments sent representatives to the Confederate Congress: Elias Cornelius Boudinot representing the Cherokee and Samuel Benton Callahan representing the Seminole and Creek people. The Cherokee Nation, aligning with the Confederacy, alleged northern violations of the Constitution, waging war against slavery commercial and political interests, abolishing slavery in the Indian Territory, and that the North intended to seize additional Indian lands.
Capitals.
Montgomery, Alabama served as the capital of the Confederate States of America from February 4 until May 29, 1861. Six states created the Confederate States of America there on February 8, 1861. The Texas delegation was seated at the time, so it is counted in the "original seven" states of the Confederacy. But it had no roll call vote until after its referendum made secession "operative". Two sessions of the Provisional Congress were held in Montgomery, adjourning May 21. The Permanent Constitution was adopted there on March 12, 1861.
The permanent capital provided for in the Confederate Constitution called for a state cession of a ten-miles square (100 square mile) district to the central government. Atlanta, which had not yet supplanted Milledgeville, Georgia as its state capital, put in a bid noting its central location and rail connections, as did Opelika, Alabama, noting its strategically interior situation, rail connections and nearby deposits of coal and iron.
Richmond, Virginia was chosen for the interim capital. The move was used by Vice President Stephens and others to encourage other border states to follow Virginia into the Confederacy. In the political moment it was a show of “defiance and strength”. The war for southern independence was surely to be fought in Virginia, but it also had the largest Southern military-aged white population, with infrastructure, resources and supplies required to sustain a war. The Davis Administration's policy was that, “It must be held at all hazards.”
The naming of Richmond as the new capital took place on May 30, 1861, and the last two sessions of the Provisional Congress were held in the new capital. The Permanent Confederate Congress and President were elected in the states and army camps on November 6, 1861. The First Congress met in four sessions in Richmond February 18, 1862 – February 17, 1864. The Second Congress met there in two sessions, May 2, 1864 – March 18, 1865.
As war dragged on, Richmond became crowded with training and transfers, logistics and hospitals. Prices rose dramatically despite government efforts at price regulation. A movement in Congress led by Henry S. Foote of Tennessee argued to remove the Capital from Richmond. At the approach of Federal armies in early summer 1862, the government’s archives were readied for removal. As the Wilderness Campaign progressed, Congress authorized Davis to remove the executive department and call Congress to session elsewhere in 1864 and again in 1865. Shortly before the end of the war, the Confederate government evacuated Richmond, planning to relocate farther south. Little came of these plans before Lee's surrender at Appomattox Court House, Virginia on April 9, 1865.
Diplomacy.
United States, a foreign power.
During the four years of its existence under trial by war, the Confederate States of America asserted its independence and appointed dozens of diplomatic agents abroad. The United States government regarded the southern states in rebellion and so refused any formal recognition of their status.
Even before Fort Sumter, U.S. Secretary of State William H. Seward issued formal instructions to the American minister to the United Kingdom: Make “no expressions of harshness or disrespect, or even impatience concerning the seceding States, their agents, or their people, States must always continue to be, equal and honored members of this Federal Union, citizens still are and always must be our kindred and countrymen.”
If the British seemed inclined to recognize the Confederacy, or even waver in that regard, they were to receive a sharp warning, with a strong hint of war: “Britain is tolerating the application of the so-called seceding States, or wavering about it, cannot remain friends with the United States ... if they determine to recognize Confederacy, may at the same time prepare to enter into alliance with the enemies of this republic.”
The United States government never declared war on those “kindred and countrymen”, but conducted its military efforts beginning with a presidential proclamation issued April 15, 1861 calling for troops to recapture forts and suppress a rebellion. Mid-war parlays between the two sides occurred without formal political recognition, though the laws of war predominantly governed military relationships on both sides of uniformed conflict.
On the part of the Confederacy, immediately following Fort Sumter the Confederate Congress proclaimed “... war exists between the Confederate States and the Government of the United States, and the States and Territories thereof ...” A state of war was not to formally exist between the Confederacy and those states and territories in the United States allowing slavery, although Confederate Rangers were compensated for destruction they could effect there throughout the war.
Concerning the international status and nationhood of the Confederate States of America, in 1869 the United States Supreme Court in "Texas v. White" ruled Texas' declaration of secession was legally null and void. Jefferson Davis, former President of the Confederacy, and Alexander Stephens, its former Vice-President, both wrote postwar arguments in favor of secession's legality and the international legitimacy of the Government of the Confederate States of America, most notably Davis' "The Rise and Fall of the Confederate Government".
International diplomacy.
Once the war with the United States began, the Confederacy pinned its hopes for survival on military intervention by the United Kingdom and France. The Confederates who had believed that "cotton is king" – that is, Britain had to support the Confederacy to obtain cotton – proved mistaken. The British had ample stocks to last over a year, and had been developing alternative sources of cotton most notably India and Egypt. They were not about to go to war with the U.S. to acquire more cotton at the risk of losing the large quantities of food imported from the North. The Confederate government sent repeated delegations to Europe; historians give them low marks for their poor diplomacy. James M. Mason went to London and John Slidell traveled to Paris. They were unofficially interviewed, but neither secured official recognition for the Confederacy. 
In late 1861 illegal actions of the U.S. Navy in seizing a British ship outraged Britain and led to a war scare in the Trent Affair. Recognition of the Confederacy seemed at hand, but Lincoln released the two detained Confederate diplomats, tensions cooled, and the Confederacy gained no advantage.
Throughout the early years of the war, British foreign secretary Lord John Russell, Emperor Napoleon III of France, and, to a lesser extent, British Prime Minister Lord Palmerston, showed interest in recognition of the Confederacy or at least mediation of the war. But the Union victory at the Battle of Antietam, (Sharpsburg) combined with internal British abolitionist opposition, and Britain did nothing. The cost to Britain of a war with the U.S. would have been high: the immediate loss of American grain shipments, the end of exports to the U.S., the seizure of billions of pounds invested in American securities. War would have meant higher taxes, another invasion of Canada, and full-scale worldwide attacks on the British merchant fleet. While outright recognition would have meant certain war with the United States, in the summer of 1862 fears of race war as had transpired in Haiti led to the British considering intervention for humanitarian reasons. Lincoln's Emancipation Proclamation did not lead to interracial violence let alone a bloodbath, but it did give the friends of the Union strong talking points in the arguments that raged across Britain.
The British government did allow blockade runners to be built in Britain and operated by British seamen. Several European nations maintained diplomats in place who had been appointed to the U.S., but no country appointed any diplomat to the Confederacy. However, those nations did recognize the Union and Confederate sides as belligerents. In 1863, the Confederacy expelled the European diplomatic missions for advising their resident subjects to refuse to serve in the Confederate army. Both Confederate and Union agents were allowed to work openly in British territories. Some state governments in northern Mexico negotiated local agreements to cover trade on the Texas border. Pope Pius IX wrote a letter to Jefferson Davis in which he addressed Davis as the "Honorable President of the Confederate States of America." but The Holy See never released a formal statement supporting or recognizing the Confederacy.
The Confederacy was seen internationally as a serious attempt at nationhood, and European governments sent military observers to assess the ‘’de facto’’ establishment of independence. These included official and unofficial Arthur Freemantle of the British Coldstream Guards, Fitzgerald Ross of the Austrian Hussars, and Justus Scheibert of the Prussian army. European travelers visited and wrote accounts for publication. Importantly in 1862, the Frenchman Charles Girard's “Seven months in the rebel states during the North American War” testified “this government ... is no longer a trial government ... but really a normal government, the expression of popular will”.
Due in part to Lincoln’s covert support of Mexican President Benito Juarez, by late spring of 1863 France was in need of Confederate cotton and other Caribbean commerce to sustain the French conquest of Mexico, an effort to reestablish North American empire. News of Lee’s decisive victory at Chancellorsville had reached the Continent, and French Emperor Napoleon III assured Confederate diplomat John Slidell that he would make “direct proposition” to the United Kingdom for joint recognition. The Emperor made the same assurance to Members of Parliament John A. Roebuck and John A. Lindsay. Roebuck in turn publicly prepared a bill to submit to Parliament June 30 supporting joint Anglo-French recognition of the Confederacy. Preparations for Lee’s incursion into Pennsylvania were underway to influence the midterm U.S. elections. Confederate independence and nationhood was at a turning point. “Southerners had a right to be optimistic, or at least hopeful, that their revolution would prevail, or at least endure”.
The Confederacy at War.
Military Strategy.
Southern Civil War historian E. Merton Coulter noted that for those who would secure its independence, “The Confederacy was unfortunate in its failure to work out a general strategy for the whole war”. Aggressive strategy called for offensive force concentration. Defensive strategy sought dispersal to meet demands of locally minded governors. The controlling philosophy evolved into a combination “dispersal with a defensive concentration around Richmond”. The Davis administration considered the war purely defensive, a “simple demand that the people of the United States would cease to war upon us."
As the Confederate government lost control of territory in campaign after campaign, it was said that “the vast size of the Confederacy would make its conquest impossible”. The enemy would be struck down by the same elements which so often debilitated or destroyed visitors and transplants in the South. Heat exhaustion, sunstroke, endemic diseases such as malaria and typhoid would match the destructive effectiveness of the Moscow winter on the invading armies of Napoleon.
But despite the Confederacy's essentially defensive stance, in the early stages of the war there were offensive visions of seizing the Rocky Mountains or cutting the North in two by marching to Lake Erie. Then, at a time when both sides believed that one great battle would decide the conflict, the Confederate won a great victory at the "Battle of Manassas". It drove the Confederate people “insane with joy”, the public demanded a forward movement to capture Washington DC, relocate the Capital there, and admit Maryland to the Confederacy. A council of war by the victorious Confederate generals decided not to advance against larger numbers of fresh Federal troops in defensive positions. Davis did not countermand it. Following the Confederate incursion halted at the Battle of Antietam, (Sharpsburg), in October 1862 generals proposed concentrating forces from state commands to re-invade the north. Nothing came of it. Again in early 1863 at his incursion into Pennsylvania, Lee requested of Davis that Beauregard simultaneously attack Washington with troops taken from the Carolinas. But the troops there remained in place during the Gettysburg Campaign.
Without counting their enslaved men, eleven states of the Confederacy were outnumbered by the North about four to one in military population. It was overmatched far more in military equipment, ability to produce and procure it, railroads for transport, and wagons supplying the front. Big guns were out-ranged and small arms were less effective. Confederate military policy innovated to compensate. Booby-trapped land mines were laid in the path of invading armies. Harbors, inlets and inland waterways were laced with numbers of sunken “torpedo” mines and covered with mobile artillery batteries. Rangers were sent to disrupt and destroy supplies of invading armies until they were disbanded, then the “dashing cavalry”.
The Confederacy relied on external sources for war materials. The first came from trade with the enemy. “Vast amounts of war supplies” came through Kentucky, and thereafter, western armies were “to a very considerable extent” provisioned with illicit trade via Federal agents and northern private traders. But that trade was interrupted in the first year of war by Admiral Porter's river gunboats as they gained dominance along navigable rivers north-south and east-west. Overseas blockade running then came to be of “outstanding importance”. On April 17, President Davis called on privateer raiders, the “militia of the sea”, to make war on U.S. seaborne commerce. Despite noteworthy effort, over the course of the war the Confederacy was found unable to match the Union in ships and seamanship, materials and marine construction.
Perhaps the most implacable obstacle to success in the 19th century warfare of mass armies was the Confederacy's lack of manpower, sufficient numbers of disciplined, equipped troops in the field at the point of contact with the enemy. During the wintering of 1862–1863, Lee observed that none of his famous victories had resulted in the destruction of the opposing army. He lacked reserve troops to exploit an advantage on the battlefield as Napoleon had done. Lee explained, “More than once have most promising opportunities been lost for want of men to take advantage of them, and victory itself had been made to put on the appearance of defeat, because our diminished and exhausted troops have been unable to renew a successful struggle against fresh numbers of the enemy.”
Armed forces.
The military armed forces of the Confederacy comprised three branches: Army, Navy and Marine Corps.
The Confederate military leadership included many veterans from the United States Army and United States Navy who had resigned their Federal commissions and had won appointment to senior positions in the Confederate armed forces. Many had served in the Mexican-American War (including Robert E. Lee and Jefferson Davis), but some such as Leonidas Polk (who had attended West Point but did not graduate) had little or no experience.
The Confederate officer corps consisted of men from both slave-owning and non-slave-owning families. The Confederacy appointed junior and field grade officers by election from the enlisted ranks. Although no Army service academy was established for the Confederacy, some colleges (such as The Citadel and Virginia Military Institute) maintained cadet corps that trained Confederate military leadership. A naval academy was established at Drewry’s Bluff, Virginia in 1863, but no midshipmen graduated before the Confederacy's end.
The soldiers of the Confederate armed forces consisted mainly of white males aged between 16 and 28. The median year of birth was 1838, so half the soldiers were 23 or older by 1861. The Confederacy adopted conscription in 1862. Many thousands of slaves served as laborers, cooks, and pioneers. Some freed blacks and men of color served in local state militia units of the Confederacy, primarily in Louisiana and South Carolina, but their officers deployed them for "local defense, not combat." Depleted by casualties and desertions, the military suffered chronic manpower shortages. In the spring of 1865, the Confederate Congress, influenced by the public support by General Lee, approved the recruitment of black infantry units. Contrary to Lee’s and Davis’s recommendations, the Congress refused “to guarantee the freedom of black volunteers.” No more than two hundred black troops were ever raised.
Raising troops.
The immediate onset of war meant that it was fought by the "Provisional" or "Volunteer Army". State governors resisted concentrating a national effort. Several wanted a strong state army for self-defense. Others feared large “Provisional” armies answering only to Davis. When filling the Confederate government's call for 100,000 men, another 200,000 were turned away by accepting only those enlisted "for the duration" or twelve-month volunteers who brought their own arms or horses.
It was important to raise troops; it was just as important to provide capable officers to command them. With few exceptions the Confederacy secured excellent general officers. Efficiency in the lower officers was "greater than could have been reasonably expected". As with the Federals, political appointees could be indifferent. Otherwise, the officer corps was governor-appointed or elected by unit enlisted. Promotion to fill vacancies was made internally regardless of merit, even if better officers were immediately available.
Anticipating the need for more “duration” men, in January 1862 Congress provided for company level recruiters to return home for two months, but their efforts met little success on the heels of Confederate battlefield defeats in February. Congress allowed for Davis to require numbers of recruits from each governor to supply the volunteer shortfall. States responded by passing their own draft laws.
The veteran Confederate army of early 1862 was mostly twelve-month volunteers with terms about to expire. Enlisted reorganization elections disintegrated the army for two months. Officers pleaded with the ranks to re-enlist, but a majority did not. Those remaining elected majors and colonels whose performance led to officer review boards in October. The boards caused a "rapid and widespread" thinning out of 1700 incompetent officers. Troops thereafter would elect only second lieutenants.
In early 1862, the popular press suggested the Confederacy required a million men under arms. But veteran soldiers were not re-enlisting, and earlier secessionist volunteers did not reappear to serve in war. One Macon, Georgia, newspaper asked how two million brave fighting men of the South were about to be overcome by four million northerners who were said to be cowards.
Conscription.
The Confederacy passed the first American law of national conscription on April 16, 1862. The white males of the Confederate States from 18 to 35 were declared members of the Confederate army for three years, and all men then enlisted were extended to a three-year term. They would serve only in units and under officers of their state. Those under 18 and over 35 could substitute for conscripts, in September those from 35 to 45 became conscripts. The cry of “rich man’s war and a poor man’s fight” led Congress to abolish the substitute system altogether in December 1863. All principals benefiting earlier were made eligible for service. By February 1864, the age bracket was made 17 to 50, those under eighteen and over forty-five to be limited to in-state duty.
Confederate conscription was not universal; it was actually a selective service. The First Conscription Act of April 1862 exempted occupations related to transportation, communication, industry, ministers, teaching and physical fitness. The Second Conscription Act of October 1862 expanded exemptions in industry, agriculture and conscientious objection. Exemption fraud proliferated in medical examinations, army furloughs, churches, schools, apothecaries and newspapers. 
Rich men’s sons were appointed to the socially outcast “overseer” occupation, but the measure was received in the country with "universal odium”. The legislative vehicle was the controversial Twenty Negro Law that specifically exempted one white overseer or owner for every plantation with at least 20 slaves. Backpedalling six months later, Congress provided overseers under 45 could be exempted only if they held the occupation before the first Conscription Act. The number of officials under state exemptions appointed by state Governor patronage expanded significantly. By law, substitutes could not be subject to conscription, but instead of adding to Confederate manpower, unit officers in the field reported that over-50 and under-17 year old substitutes made up to 90% of the desertions.
The Conscription Act of February 1864 “radically changed the whole system” of selection. It abolished industrial exemptions, placing detail authority in President Davis. As the shame of conscription was greater than a felony conviction, the system brought in “about as many volunteers as it did conscripts.” Many men in otherwise “bombproof” positions were enlisted in one way or another, nearly 160,000 additional volunteers and conscripts in uniform. Still there was shirking. To administer the draft, a Bureau of Conscription was set up to use state officers, as state Governors would allow. It had a checkered career of “contention, opposition and futility”. Armies appointed alternative military "recruiters" to bring in the out-of-uniform 17–50 year old conscripts and deserters. Nearly 3000 officers would be tasked with the job. By fall 1864, Lee was calling for more troops. “Our ranks are constantly diminishing by battle and disease, and few recruits are received; the consequences are inevitable.” By March 1865 conscription was to be administered by generals of the state reserves calling out men over 45 and under 18 years old. All exemptions were abolished. These regiments were assigned to recruit conscripts ages 17–50, recover deserters, and repel enemy cavalry raids. The service retained men who had lost but one arm or a leg in home guards. April 1865 Lee surrendered an army of 50,000. Conscription had been a failure.
The survival of the Confederacy depended on a strong base of civilians and soldiers devoted to victory. The soldiers performed well, though increasing numbers deserted in the last year of fighting, and the Confederacy never succeeded in replacing casualties as the Union could. The civilians, although enthusiastic in 1861–62, seem to have lost faith in the future of the Confederacy by 1864, and instead looked to protect their homes and communities. As Rable explains, "This contraction of civic vision was more than a crabbed libertarianism; it represented an increasingly widespread disillusionment with the Confederate experiment."
Victories: 1861.
The American Civil War broke out in April 1861 with the Battle of Fort Sumter in Charleston. In December 1860, Federal troops had withdrawn to the island fort from others in Charleston Harbor soon after South Carolina’s declaration of secession to avoid soldier-civilian street confrontations.
In January, President James Buchanan had attempted to resupply the garrison with the "Star of the West", but Confederate artillery drove it away. In March, President Lincoln notified Governor Pickens that without Confederate resistance to resupply there would be no military reinforcement without further notice, but Lincoln prepared to force resupply if it were not allowed. Confederate President Davis in cabinet decided to capture Fort Sumter before the relief fleet arrived and on April 12, 1861, General Beauregard forced their surrender.
Following Fort Sumter, Lincoln directed states to provide 75,000 troops for three months to recapture the Charleston Harbor forts and all other federal property that had been seized without Congressional authorization. In May, Federal troops crossed into Confederate territory along the entire border from the Chesapeake Bay to New Mexico. The Confederate victory at Fort Sumter was followed by Confederate victories at the battles of Big Bethel, (Bethel Church) VA in June, First Bull Run, (First Manassas) in July and in August, Wilson’s Creek, (Oak Hills) in southwest Missouri. At all three, Confederate forces could not follow up their victory due to inadequate supply and shortages of fresh troops to exploit their successes. Following each battle, Federals maintained a military presence and their occupation of Washington DC, Fort Monroe VA and Springfield MO. Both North and South began training up armies for major fighting the next year.
Confederate commerce-raiding just south of the Chesapeake Bay was ended in August at the loss of Hatteras NC. Early November a Union expedition at sea secured Port Royal and Beaufort SC south of Charleston, seizing Confederate-burned cotton fields along with escaped and owner-abandoned "contraband" field hands. December saw the loss of Georgetown SC north of Charleston. Federals there began a war-long policy of burning grain supplies up rivers into the interior wherever they could not occupy.
Incursions: 1862.
The victories of 1861 were followed by a series of defeats east and west in early 1862. To restore the Union by military force the Federal intent was to (1) secure the Mississippi River, (2) seize or close Confederate ports and (3) march on Richmond. To secure independence, the Confederate intent was to (1) repel the invader on all fronts, costing him blood and treasure and (2) carry the war into the north by two offensives in time to impact the mid-term elections.
Much of northwestern Virginia was under Federal control.
In February and March, most of Missouri and Kentucky were Union “occupied, consolidated, and used as staging areas for advances further South”. Following the repulse of Confederate counter-attack at the Battle of Shiloh, (Pittsburg Landing) Tennessee, permanent Federal occupation expanded west, south and east. Confederate forces then repositioned south along the Mississippi River to Memphis, where at the naval Battle of Memphis its River Defense Fleet was sunk and Confederates then withdrew from northern Mississippi and northern Alabama. New Orleans was captured April 29 by a combined Army-Navy force under U.S. Admiral Farragut, and the Confederacy lost control of the mouth of the Mississippi River, conceding large agricultural resources that supported the Union’s sea-supplied logistics base.
Although Confederates had suffered major reverses everywhere but Virginia, as of the end of April the Confederacy still controlled 72% of its population. Federal forces disrupted Missouri and Arkansas; they had broken through in western Virginia, Kentucky, Tennessee and Louisiana. Along the Confederacy’s shores it had closed ports and made garrisoned lodgments on every coastal Confederate state but Alabama and Texas. Although scholars sometimes assess the Union blockade as ineffectual under international law until the last few months of the war, from the first months it disrupted Confederate privateers making it “almost impossible to bring their prizes into Confederate ports”. Nevertheless, British firms developed small fleets of blockade running companies, such as John Fraser and Company and the Ordnance Department secured its own blockade runners for dedicated munitions cargos.
The Civil War saw the advent of fleets of armored warships deployed in sustained blockades at sea. After some success against the Union blockade, in March the ironclad "CSS Virginia" was forced into port and burned by Confederates at their retreat. Despite several attempts mounted from their port cities, C.S. naval forces were unable to break the Union blockade including Commodore Josiah Tattnall’s ironclads from Savannah, in 1862 with the "CSS Atlanta". Secretary of the Navy Stephen Mallory placed his hopes in a European-built ironclad fleet, but they were never realized. On the other hand, four new English-built commerce raiders saw Confederate service, and several fast blockade runners were sold in Confederate ports, then converted into commerce-raiding cruisers, manned by their British crews.
In the east, Union forces could not close on Richmond. General McClellan landed his army on the Lower Peninsula of Virginia. Lee subsequently ended that threat from the east, then Union General John Pope attacked overland from the north only to be repulsed at Second Bull Run, (Second Manassas). Lee’s strike north was turned back at Antietam MD, then Burnside’s offensive was disastrously ended at Fredericksburg VA in December. Both armies then turned to winter quarters to recruit and train for the coming spring.
In an attempt to seize the initiative, reprovision, protect farms in mid-growing season and influence U.S. Congressional elections, two major Confederate incursions into Union territory had been launched in August and September 1862. Both Braxton Bragg's invasion of Kentucky and Lee's invasion of Maryland were decisively repulsed, leaving Confederates in control of but 63% of its population. Civil War scholar Alan Nevins argues that 1862 was the strategic high water mark of the Confederacy. The failures of the two invasions were attributed to the same irrecoverable shortcomings: lack of manpower at the front, lack of supplies including serviceable shoes, and exhaustion after long marches without adequate food.
Anaconda: 1863–1864.
The failed Middle Tennessee campaign was ended January 2, 1863 at the inconclusive Battle of Stones River, (Murfreesboro), both sides losing the largest percentage of casualties suffered during the war. It was followed by another strategic withdrawal by Confederate forces. The Confederacy won a significant victory April 1863, repulsing the Federal advance on to Richmond at Chancellorsville, but the Union consolidated positions along the Virginia coast and the Chesapeake Bay.
Without an effective answer to Federal gunboats, river transport and supply, the Confederacy lost the Mississippi River following the capture of Vicksburg, Mississippi, and Port Hudson in July, ending Southern access to the trans-Mississippi West. July brought short-lived counters, Morgan's Raid into Ohio and the New York City draft riots. Robert E. Lee’s strike into Pennsylvania was repulsed at Gettysburg, Pennsylvania despite Pickett’s famous charge and other acts of valor. Southern newspapers assessed the campaign as “The Confederates did not gain a victory, neither did the enemy.”
September and November left Confederates yielding Chattanooga, Tennessee, the gateway to the lower south. For the remainder of the war fighting was restricted inside the South, resulting in a slow but continuous loss of territory. In early 1864, the Confederacy still controlled 53% of its population, but it withdrew further to reestablish defensive positions. Union offensives continued with Sherman’s March to the Sea to take Savannah and Grant's Wilderness Campaign to encircle Richmond and besiege Lee's army at Petersburg
In April 1863, the C.S. Congress authorized a uniformed Volunteer Navy, many of whom were British. Wilmington and Charleston had more shipping while “blockaded” than before the beginning of hostilities. The Confederacy had altogether eighteen commerce destroying cruisers, which seriously disrupted Federal commerce at sea and increased shipping insurance rates 900 percent. Commodore Tattnall unsuccessfully attempted to break the Union blockade on the Savannah River GA with an ironclad again in 1863. However beginning April 1864 the ironclad CSS Albemarle engaged Union gunboats and sank or cleared them for six months on the Roanoke River NC. The Federals closed Mobile Bay by sea-based amphibious assault in August, ending Gulf coast trade east of the Mississippi River. In December, the Battle of Nashville ended Confederate operations in the western theater.
Collapse: 1865.
The first three months of 1865 saw the Federal Carolinas Campaign, devastating a wide swath of the remaining Confederate heartland. The “breadbasket of the Confederacy” in the Great Valley of Virginia was occupied by Philip Sheridan. The Union Blockade captured Fort Fisher NC, and Sherman finally took Charleston SC by land attack.
The Confederacy controlled no ports, harbors or navigable rivers. Railroads were captured or had ceased operating. Its major food producing regions had been war-ravaged or occupied. Its administration survived in only three pockets of territory holding one-third its population. Its armies were defeated or disbanding. At the February 1865 Hampton Roads Conference with Lincoln, senior Confederate officials rejected his invitation to restore the Union with compensation for emancipated slaves. The Davis policy was independence or nothing, while Lee's army was wracked by disease and desertion, barely holding the trenches defending Jefferson Davis' capital.
The Confederacy's last remaining blockade-running port, Wilmington, North Carolina, was lost. When the Union broke through Lee's lines at Petersburg, Richmond fell immediately. Lee surrendered the Army of Northern Virginia at Appomattox Court House, Virginia, on April 9, 1865. “The Surrender” marked the end of the Confederacy.
The CSS Stonewall sailed from Europe to break the Union blockade in March; on making Havana, Cuba it surrendered. Some high officials escaped to Europe, but President Davis was captured May 10; all remaining Confederate forces surrendered by June 1865. The U.S. Army took control of the Confederate areas without post-surrender insurgency or guerrilla warfare against them, but peace was subsequently marred by a great deal of local violence, feuding and revenge killings.
Historian Gary Gallagher concluded that the Confederacy capitulated in the spring of 1865 because northern armies crushed “organized southern military resistance." The Confederacy's population, soldier and civilian, had suffered material hardship and social disruption. They had expended and extracted a profusion of blood and treasure until collapse; "the end had come". Jefferson Davis' assessment in 1890 determined, “With the capture of the capital, the dispersion of the civil authorities, the surrender of the armies in the field, and the arrest of the President, the Confederate States of America disappeared ... their history henceforth became a part of the history of the United States.”
"Died of states' rights".
Historian Frank Lawrence Owsley argued that the Confederacy "died of states' rights." The central government was denied requisitioned soldiers and money by governors and state legislatures because they feared that Richmond would encroach on the rights of the states. Georgia's governor Joseph Brown warned of a secret conspiracy by Jefferson Davis to destroy states’ rights and individual liberty. The first conscription act in North America authorizing Davis to draft soldiers was said to be the "essence of military despotism."
Vice President Alexander Stephens feared losing the very form of republican government. Allowing President Davis to threaten "arbitrary arrests" to draft hundreds of governor-appointed “bomb-proof” bureaucrats conferred "more power than the English Parliament had ever bestowed on the king. History proved the dangers of such unchecked authority." Abolishing draft exemptions for newspaper editors must mean that the Confederate government intended to muzzle targeted presses such as the Raleigh NC "Standard" to control elections and to suppress the peace meetings there. Southerners should never view liberty as subordinate to independence because the cry of "independence first and liberty second" was a "fatal delusion". As Rable concludes, "For Stephens, the essence of patriotism, the heart of the Confederate cause, rested on an unyielding commitment to traditional rights” without considerations of military necessity, pragmatism or compromise.
In 1863 governor Pendleton Murrah of Texas determined that state troops were required for defense against Plains Indians and Union successes advancing from the free state of Kansas. He refused to send them East. Governor Zebulon Vance of North Carolina showed intense opposition to conscription, limiting recruitment success. Vance's faith in states' rights drove him into repeated, stubborn opposition to the Davis administration.
Despite political differences within the Confederacy, no national political parties were formed because they were seen as illegitimate. "Anti-partyism became an article of political faith." Without a two party system building alternative sets of national leaders, electoral protests tended to be narrowly state-based, “negative, carping and petty”. The 1863 mid-term elections became mere expressions of futile and frustrated dissatisfaction. According to historian David M. Potter, this lack of a functioning two-party system caused "real and direct damage" to the Confederate war effort since it prevented the formulation of any effective alternatives to the conduct of the war by the Davis administration.
"Died of Davis".
The enemies of President Davis proposed that the Confederacy “died of Davis.” He was unfavorably compared to George Washington by critics such as E. A. Pollard, editor of the "Richmond Examiner." Coulter summarizes, “The American Revolution had its Washington; the Southern Revolution had its Davis ... one succeeded and the other failed.” Besides the early honeymoon period, Davis was never popular. He unwittingly caused much internal dissention from early on. His ill health and temporary bouts of blindness disabled him for days at a time.
Coulter says Davis was heroic and his will was indomitable. But his “tenacity, determination, and will power” stirred up lasting opposition of enemies Davis could not shake. He failed to overcome “petty leaders of the states” who made the term “Confederacy” into a label for tyranny and oppression, denying the "Stars and Bars" from becoming a symbol of larger patriotic service and sacrifice. Instead of campaigning to develop nationalism and gain support for his administration, he rarely courted public opinion, assuming an aloofness, “almost like an Adams”.
Davis attended to too many details. He protected his friends after their failures were obvious. He spent too much time on military affairs versus his civil responsibilities. Coulter concludes he was not the ideal leader for the Southern Revolution, but he showed “fewer weaknesses than any other” contemporary character available for the role. Robert E. Lee’s assessment of Davis as President was, “I knew of none that could have done as well.”
Government and politics.
Constitution.
The Southern leaders met in Montgomery, Alabama, to write their constitution. Much of the Confederate States Constitution replicated the United States Constitution verbatim, but it contained several explicit protections of the institution of slavery including provisions for the recognition and protection of negro slavery in any new state admitted to the Confederacy. It maintained the existing ban on international slave-trading while protecting the existing internal trade of slaves among slaveholding states.
In certain areas, the Confederate Constitution gave greater powers to the states (or curtailed the powers of the central government more) than the U.S. Constitution of the time did, but in other areas, the states actually lost rights they had under the U.S. Constitution. Although the Confederate Constitution, like the U.S. Constitution, contained a commerce clause, the Confederate version prohibited the central government from using revenues collected in one state for funding internal improvements in another state. The Confederate Constitution's equivalent to the U.S. Constitution's general welfare clause prohibited protective tariffs (but allowed tariffs for providing domestic revenue), and spoke of "carry on the Government of the Confederate States" rather than providing for the "general welfare". State legislatures had the power to impeach officials of the Confederate government in some cases. On the other hand, the Confederate Constitution contained a Necessary and Proper Clause and a Supremacy Clause that essentially duplicated the respective clauses of the U.S. Constitution. The Confederate Constitution also incorporated each of the 12 amendments to the U.S. Constitution that had been ratified up to that point.
The Confederate Constitution did not specifically include a provision allowing states to secede; the Preamble spoke of each state "acting in its sovereign and independent character" but also of the formation of a "permanent federal government". During the debates on drafting the Confederate Constitution, one proposal would have allowed states to secede from the Confederacy. The proposal was tabled with only the South Carolina delegates voting in favor of considering the motion. The Confederate Constitution also explicitly denied States the power to bar slaveholders from other parts of the Confederacy from bringing their slaves into any state of the Confederacy or to interfere with the property rights of slave owners traveling between different parts of the Confederacy. In contrast with the language of the United States Constitution, the Confederate Constitution overtly asked God's blessing ("...invoking the favor and guidance of Almighty God...").
Executive.
The Montgomery Convention to establish the Confederacy and its executive met February 4, 1861. Each state as a sovereignty had one vote, with the same delegation size as it held in the U.S. Congress, and generally 41 to 50 members attended. Offices were “provisional”, limited to a term not to exceed one year. One name was placed in nomination for president, one for vice president. Both were elected unanimously, 6–0. 
Jefferson Davis was elected president. His U.S. Senate resignation speech greatly impressed with its clear rationale for secession and his pleading for a peaceful departure from the Union to independence. Although he had made it known that he wanted to be commander-in-chief of the Confederate armies, when elected, he assumed the office of Provisional President. Three candidates for Vice President were under consideration the night before the February 9 election. All were from Georgia, and the various delegations meeting in different places determined two would not do, so Alexander Stephens was elected unanimously Provisional Vice President, though with some privately held reservations. Stephens was inaugurated February 11, Davis February 18. 
Historian E. M. Coulter observed, “No president of the U.S. ever had a more difficult task.” Washington was inaugurated in peacetime. Lincoln inherited an established government of long standing. The creation of the Confederacy was accomplished by men who saw themselves as fundamentally conservative. Although they referred to their “Revolution”, it was in their eyes more a counter-revolution against changes away from their understanding of U.S. founding documents. In Davis’ inauguration speech, he explained the Confederacy was not a French-like revolution, but a transfer of rule. The Montgomery Convention had assumed all the laws of the United States until superseded by the Confederate Congress. 
The Permanent Constitution provided for a President of the Confederate States of America, elected to serve a six-year term but without the possibility of re-election. Unlike the Union Constitution, the Confederate Constitution gave the president the ability to subject a bill to a line item veto, a power also held by some state governors.
The Confederate Congress could overturn either the general or the line item vetoes with the same two-thirds majorities that are required in the U.S. Congress. In addition, appropriations not specifically requested by the executive branch required passage by a two-thirds vote in both houses of Congress. The only person to serve as president was Jefferson Davis, due to the Confederacy being defeated before the completion of his term.
Legislative.
The only two “formal, national, functioning, civilian administrative bodies” in the Civil War South were the Jefferson Davis administration and the Confederate Congresses. The Confederacy was begun by the Provisional Congress in Convention at Montgomery, Alabama on February 28, 1861. It had one vote per state in a unicameral assembly.
The Permanent Confederate Congress was elected and began its first session February 18, 1862. The Permanent Congress for the Confederacy followed the United States forms with a bicameral legislature. The Senate had two per state, twenty-six Senators. The House numbered 106 representatives apportioned by free and slave populations within each state. Two Congresses sat in six sessions until March 18, 1865.
The political influences of the civilian, soldier vote and appointed representatives reflected divisions of political geography of a diverse South. These in turn changed over time relative to Union occupation and disruption, the war impact on local economy, and the course of the war. Without political parties, key candidate identification related to adopting secession before or after Lincoln's call for volunteers to retake Federal property. Previous party affiliation played a part in voter selection, predominantly secessionist Democrat or unionist Whig.
The absence of political parties made individual roll call voting all the more important, as the Confederate “freedom of roll-call voting unprecedented in American legislative history. Key issues throughout the life of the Confederacy related to (1) suspension of habeas corpus, (2) military concerns such as control of state militia, conscription and exemption, (3) economic and fiscal policy including impressment of slaves, goods and scorched earth, and (4) support of the Jefferson Davis administration in its foreign affairs and negotiating peace.
Provisional Congress 
For the first year, the unicameral Provisional Confederate Congress functioned as the Confederacy's legislative branch.
President of the Provisional Congress
Presidents pro tempore of the Provisional Congress
Sessions of the Confederate Congress
Tribal Representatives to Confederate Congress
Judicial.
The Confederate Constitution outlined a judicial branch of the government, but the ongoing war and resistance from states-rights advocates, particularly on the question of whether it would have appellate jurisdiction over the state courts, prevented the creation or seating of the "Supreme Court of the Confederate States;" the state courts generally continued to operate as they had done, simply recognizing the Confederate States as the national government.
Confederate district courts were authorized by Article III, Section 1, of the Confederate Constitution, and President Davis appointed judges within the individual states of the Confederate States of America. In many cases, the same US Federal District Judges were appointed as Confederate States District Judges. Confederate district courts began reopening in the spring of 1861 handling many of the same type cases as had been done before. Prize cases, in which Union ships were captured by the Confederate Navy or raiders and sold through court proceedings, were heard until the blockade of southern ports made this impossible. After a Sequestration Act was passed by the Confederate Congress, the Confederate district courts heard many cases in which enemy aliens (typically Northern absentee landlords owning property in the South) had their property sequestered (seized) by Confederate Receivers.
When the matter came before the Confederate court, the property owner could not appear because he was unable to travel across the front lines between Union and Confederate forces. Thus, the District Attorney won the case by default, the property was typically sold, and the money used to further the Southern war effort. Eventually, because there was no Confederate Supreme Court, sharp attorneys like South Carolina's Edward McCrady began filing appeals. This prevented their clients' property from being sold until a supreme court could be constituted to hear the appeal, which never occurred. Where Federal troops gained control over parts of the Confederacy and re-established civilian government, US district courts sometimes resumed jurisdiction.
Supreme Court – not established.
District Courts – judges
Post Office.
When the Confederacy was formed and its seceding states broke from the Union, it was at once confronted with the arduous task of providing its citizens with a mail delivery system, and, in the midst of the American Civil War, the newly formed Confederacy created and established the Confederate Post Office. One of the first undertakings in establishing the Post Office was the appointment of John H. Reagan to the position of Postmaster General, by Jefferson Davis in 1861, making him the first Postmaster General of the Confederate Post Office as well as a member of Davis' presidential cabinet. Through Reagan's resourcefulness and remarkable industry, he had his department assembled, organized and in operation before the other Presidential cabinet members had their departments fully operational.
When the war began, the US Post Office still delivered mail from the seceded states for a brief period of time. Mail that was postmarked after the date of a state's admission into the Confederacy through May 31, 1861 and bearing US postage was still delivered. After this time, private express companies still managed to carry some of the mail across enemy lines. Later, mail that crossed lines had to be sent by 'Flag of Truce' and was allowed to pass at only two specific points. Mail sent from the South to the North states was received, opened and inspected at Fortress Monroe on the Virginia coast before being passed on into the U.S. mail stream. Mail sent from the North to the South passed at City Point, also in Virginia, where it was also inspected before being sent on.
With the chaos of the war, a working postal system was more important than ever for the Confederacy. The Civil War had divided family members and friends and consequently letter writing naturally increased dramatically across the entire divided nation, especially to and from the men who were away serving in an army. Mail delivery was also important for the Confederacy for a myriad of business and military reasons. Because of the Union blockade, basic supplies were always in demand and so getting mailed correspondence out of the country to suppliers was imperative to the successful operation of the Confederacy. Volumes of material have been written about the Blockade runners who evaded Union ships on blockade patrol, usually at night, and who moved cargo and mail in and out of the Confederate States throughout the course of the war. Of particular interest to students and historians of the American Civil War is "Prisoner of War mail" and "Blockade mail" as these items were often involved with a variety of military and other war time activities. The postal history of the Confederacy along with surviving Confederate mail has helped historians document the various people, places and events that were involved in the American Civil War as it unfolded.
Economy.
Political economy.
Most whites were subsistence farmers who traded their surpluses locally. The plantations of the South, with white ownership and an enslaved labor force, produced substantial wealth from cash crops. It supplied two-thirds of the world’s cotton, which was in high demand for textiles, along with tobacco, sugar, and naval stores (such as turpentine). These raw materials were exported to factories in Europe and the Northeast. Planters reinvested their profits in more slaves and fresh land, for cotton and tobacco depleted the soil. There was little manufacturing or mining; shipping was controlled by outsiders.
The plantations that employed over three million black slaves were the principal source of wealth, but they were also the source of general tension and white racial solidarity. William Freehling and Steven A. Channing have documented the race-based system of enslavement as “prone to insurrection and racial upheaval” inside the South, and by midcentury, its maintenance there was coming under increasing attacks from outside.
Slave labor was applied in industry in a limited way in the Upper South and in a few port cities. One reason for the regional lag in industrial development was “top-heavy income distribution”. Mass production requires mass markets, and slave-labor living in packed-earth cabins, using self-made tools and outfitted with one suit of work clothes each year of inferior fabric, did not generate consumer demand to sustain local manufactures of any description in the same way a mechanized family farm of free labor did in the North. The Southern economy was "pre-capitalist" in that slaves were employed in the largest revenue producing enterprises, not free labor. That labor system as practiced in the American South encompassed paternalism, whether abusive or indulgent, and that meant labor management considerations apart from productivity.
Approximately 85% of both North and South white populations lived on family farms, both regions were predominantly agricultural, and mid-century industry in both was mostly domestic. But the Southern economy was uniquely pre-capitalist in its overwhelming reliance on the agriculture of cash crops to produce wealth. Southern cities and industries grew faster than ever before, but the thrust of the rest of the country’s exponential growth elsewhere was towards urban industrial development along transportation systems of canals and railroads. The South was following the dominant currents of the American economic mainstream, but at a "great distance" as it lagged in the all-weather modes of transportation that brought cheaper, speedier freight shipment and forged new, expanding inter-regional markets.
A third count of southern pre-capitalist economy relates to the cultural setting. The South and southerners did not adopt a frenzied work ethic, nor the habits of thrift that marked the rest of the country. It had access to the tools of capitalism, but it did not adopt its culture. The Southern Cause as a national economy in the Confederacy was grounded in “slavery and race, planters and patricians, plain folk and folk culture, cotton and plantations”.
National production.
The Confederacy started its existence as an agrarian economy with exports, to a world market, of cotton, and, to a lesser extent, tobacco and sugarcane. Local food production included grains, hogs, cattle, and gardens. The cash came from exports but the Southern people spontaneously stopped exports in spring 1861 to hasten the impact of "King Cotton." When the blockade was announced, commercial shipping practically ended (the ships could not get insurance), and only a trickle of supplies came via blockade runners.
The 11 states had produced $155 million in manufactured goods in 1860, chiefly from local grist-mills, and lumber, processed tobacco, cotton goods and naval stores such as turpentine. The main industrial areas were border cities such as Baltimore, Wheeling, Louisville and St. Louis, that were never under Confederate control. 
The Confederacy adopted a tariff of 15 per cent, but imposed it on all imports from other countries, including the United States. The tariff mattered little; the Union blockade minimized commercial traffic through the Confederacy's ports, and very few people paid taxes on goods smuggled from the North. The Confederate government in its entire history collected only $3.5 million in tariff revenue. The lack of adequate financial resources led the Confederacy to finance the war through printing money, which led to high inflation.
The Confederacy underwent an economic revolution with but it was too little too late as its economy was systematically strangled by blockade and raids.
Transportation systems.
In peacetime, the extensive and connected systems of navigable rivers and coastal access allowed for cheap and easy transportation of agricultural products. The railroad system in the South had been built as a supplement to the navigable rivers to enhance the all-weather shipment of cash crops to market. They tied plantation areas to the nearest river or seaport and so made supply more dependable, lowered costs and increased profits. In the event of invasion, the vast geography of the Confederacy made logistics difficult for the Union. Wherever Union armies invaded, they assigned many of their soldiers to garrison captured areas and to protect rail lines.
At onset of the Civil War, the Southern rail network was disjointed and plagued by change in track gauge as well as lack of interchange. Locomotives and freight cars had fixed axles and could not roll on tracks of different gauges (widths). Railroads of different gauges leading to the same city required all freight to be off-loaded onto wagons to be transported to the connecting railroad station where it would await freight cars and a locomotive to proceed. These included Vicksburg, New Orleans, Montgomery, Wilmington and Richmond. In addition, most rail lines led from coastal or river ports to inland cities, with few lateral railroads. Due to this design limitation, the relatively primitive railroads of the Confederacy were unable to overcome the Union Naval Blockade of the South's crucial intra-coastal and river routes.
The Confederacy had no plan to expand, protect or encourage its railroads. Refusal to export the cotton crop in 1861 left railroads bereft of their main source of income. Many lines had to lay off employees; many critical skilled technicians and engineers were permanently lost to military service. For the early years of the war, the Confederate government had a hands-off approach to the railroads. Only in mid-1863 did the Confederate government initiate an national policy, and it was confined solely to aiding the war effort. Railroads came under the de facto control of the military. In contrast, U.S. Congress had authorized military administration of railroad and telegraph January 1862, imposed a standard gauge, and built railroads into the South using that gauge. Confederate reoccupation of territory by successful armies could not be resupplied directly by rail as they advanced. The C.S. Congress formally authorized military administration of railroads in February 1865.
In the last year before the end of the war, the Confederate railroad system stood permanently on the verge of collapse. There was no new equipment and raids on both sides systematically destroyed key bridges, as well as locomotives and freight cars. Spare parts were cannibalized; feeder lines were torn up to get replacement rails for trunk lines, and the heavy use of rolling stock wore them out.
Horses and mules.
The army was always short of horses and mules, and requisitioned them with dubious promissory notes from local farmers and breeders. Union forces paid in real money and found ready sellers in the South. Horses were needed for cavalry and artillery. Mules pulled the wagons. The supply was undermined by an unprecedented epidemic of glanders, a fatal disease that baffled veterinarians. After 1863 the policy of the Union Army was to shoot all the horses and mules it did not need to keep them out of Confederate hands. The army and farmers experienced a growing shortage of horses and mules, which hurt the economy and the Confederate war effort. The South lost half its 2.5 million horses and mules; many farmers ended the war with none left. Army horses were used up by hard work, malnourishment, disease and battle wounds; their life expectancy was about seven months.
Financial instruments.
Both the individual Confederate states and later the Confederate government printed Confederate States of America dollars as paper currency in various denominations, much of it signed by the Treasurer Edward C. Elmore. During the course of the war these severely depreciated and eventually became worthless. Many bills still exist, although in recent years copies have proliferated.
The Confederate government initially wanted to finance its war mostly through tariffs on imports, export taxes, and voluntary donations of gold. However, after the spontaneous imposition of an embargo on cotton sales to Europe in 1861, these sources of revenue dried up and the Confederacy increasingly turned to issuing debt and printing money to pay for war expenses. The Confederate States politicians were worried about angering the general population with hard taxes. A tax increase might disillusion many Southerners, so the Confederacy resorted to printing more money. As a result inflation increased and remained a problem for the southern states throughout the rest of the war.
At the time of their secession, the states (and later the Confederate government) took over the national mints in their territories: the Charlotte Mint in North Carolina, the Dahlonega Mint in Georgia, and the New Orleans Mint in Louisiana. During 1861, the first two produced small amounts of gold coinage, the latter half dollars. Since the mints used the current dies on hand, these issues remain indistinguishable from those minted by the Union.
Food shortages and riots.
By summer 1861, the Union naval blockade virtually shut down the export of cotton and the import of manufactured goods. Food that formerly came overland was cut off. In response, the governor and legislature pleaded with planters to grow less cotton and more food. Most refused, some believing that the Yankees would not or could not fight. When cotton prices soared in Europe, expectations were that Europe would soon intervene to break the blockade. Neither proved true and the myth of omnipotent "King Cotton" died hard. The Georgia legislature imposed cotton quotas, making it a crime to grow an excess. But food shortages only worsened, especially in the towns.
The overall decline in food supplies, made worse by the inadequate transportation system, led to serious shortages and high prices in urban areas. When bacon reached a dollar a pound in 1864, the poor women of Richmond, Atlanta and many other cities began to riot; they broke into shops and warehouses to seize food. The women expressed their anger at ineffective state relief efforts, speculators, and merchants and planters. As wives and widows of soldiers they were hurt by the inadequate welfare system.
Devastation by 1865.
By the end of the war deterioration of the Southern infrastructure was widespread. The number of civilian deaths is unknown. Most of the war was fought in Virginia and Tennessee, but every Southern state was affected as well as Maryland, West Virginia, Kentucky, Missouri, and Indian Territory. Texas and Florida saw the least military action. Much of the damage was caused by military action, but most was caused by lack of repairs and upkeep, and by deliberately using up resources. Historians have recently estimated how much of the devastation was caused by military action. Military operations were conducted in 56% of 645 counties in nine Confederate states (excluding Texas and Florida). These counties contained 63% of the 1860 white population and 64% of the slaves. By the time the fighting took undoubtedly some people had fled to safer areas, so the exact population exposed to war is unknown.
The eleven Confederate states in the 1860 census had 297 towns and cities with 835,000 people; of these 162 with 681,000 people were at one point occupied by Union forces. Eleven were destroyed or severely damaged by war action, including Atlanta (with an 1860 population of 9,600), Charleston, Columbia, and Richmond (with prewar populations of 40,500, 8,100, and 37,900, respectively); the eleven contained 115,900 people in the 1860 census, or 14% of the urban South. Historians have not estimated what their actual population was when Union forces arrived. The number of people (as of 1860) who lived in the destroyed towns represented just over 1% of the Confederacy's 1860 population. In addition, 45 court houses were burned (out of 830). The South's agriculture was not highly mechanized. The value of farm implements and machinery in the 1860 Census was $81 million; by 1870, there was 40% less, worth just $48 million. Many old tools had broken through heavy use; new tools were rarely available; even repairs were difficult.
The economic losses affected everyone. Banks and insurance companies were mostly bankrupt. Confederate currency and bonds were worthless. The billions of dollars invested in slaves vanished. However, most debts were left behind. Most farms were intact but most had lost their horses, mules and cattle; fences and barns were in disrepair. Paskoff shows the loss of farm infrastructure was about the same whether or not fighting took place nearby. The loss of infrastructure and productive capacity meant that rural widows throughout the region faced not only the absence of able-bodied men, but a depleted stock of material resources that they could manage and operate themselves. During four years of warfare, disruption, and blockades, the South used up about half its capital stock. The North, by contrast, absorbed its material losses so effortlessly that it appeared richer at the end of the war than at the beginning.
Impact on women and families.
About 250,000 men never came home, or 30% of all white men aged 18 to 40 in 1860. Widows who were overwhelmed often abandoned the farm and merged into the households of relatives, or even became refugees living in camps with high rates of disease and death. In the Old South, being an “old maid” was something of an embarrassment to the woman and her family. Now it became almost a norm. Some women welcomed the freedom of not having to marry. Divorce, while never fully accepted, became more common. The concept of the “New Woman” emerged—she was self-sufficient, independent, and stood in sharp contrast to the "Southern Belle" of antebellum lore.
Flags.
National flags.
Coulter, Ellis Merton. [http://books.google.com/books?id=Z2_ZM0dWVrsC&dq=Ellis+Merton+Coulter&q=stars+and+bars#v=snippet&q=stars%20and%20bars&f=false The Confederate States of America, 1861-1865 viewed June 13, 2012, published in LSU’s History of the South series, on page 118 notes that beginning in March 1861, the Stars-and-Bars was used “all over the Confederacy”.]Sansing, David. [http://mshistorynow.mdah.state.ms.us/articles/107/history-of-the-confederate-flags|A Brief History of the Confederate Flags at “Mississippi History Now” online Mississippi Historical Society. Second National Flag, “the stainless banner” references, Devereaux D. Cannon, Jr., The Flags of the Confederacy, An Illustrated History (St. Lukes Press, 1988), 22-24. Section Heading “Second and Third National Flags”. Viewed October 4, 2012.]Sansing, David, [http://mshistorynow.mdah.state.ms.us/articles/107/history-of-the-confederate-flags|A Brief History of the Confederate Flags at “Mississippi History Now” online Mississippi Historical Society. Third National Flag, “the bloodstained banner” references 19. Southern Historical Society Papers (cited hereafter as SHSP, volume number, date for the first entry, and page number), 24, 118. Section Heading “Second and Third National Flags”. Viewed October 4, 2012.] "Southern Cross"
File:Bonnieblue.svg|Bonnie Blue Flag Unofficial Southern Flag
File:Confederate Rebel Flag.svg|Confederate Flag in some army units

The first official flag of the Confederate States of America—called the "Stars and Bars" – originally had seven stars, representing the first seven states that initially formed the Confederacy. As more states seceded, more stars were added, until the total was 13 (two stars were added for the divided states of Kentucky and Missouri). However, during the First Battle of Bull Run, (First Manassas) it sometimes proved difficult to distinguish the Stars and Bars from the Union flag. To rectify the situation, a separate "Battle Flag" was designed for use by troops in the field. Also known as the "Southern Cross", many variations sprang from the original square configuration. Although it was never officially adopted by the Confederate government, the popularity of the Southern Cross among both soldiers and the civilian population was a primary reason why it was made the main color feature when a new national flag was adopted in 1863. This new standard—known as the "Stainless Banner" – consisted of a lengthened white field area with a Battle Flag canton. This flag too had its problems when used in military operations as, on a windless day, it could easily be mistaken for a flag of truce or surrender. Thus, in 1865, a modified version of the Stainless Banner was adopted. This final national flag of the Confederacy kept the Battle Flag canton, but shortened the white field and added a vertical red bar to the fly end.
Because of its depiction in the 20th-century and popular media, many people consider the rectangular battle flag with the dark blue bars as being synonymous with "the Confederate Flag". This flag, however, was never adopted as a Confederate national flag, although it was adopted by the Army of Tennessee and other units. The "Confederate Flag" has a color scheme similar to the official Battle Flag, but is rectangular, not square. (Its design and shape matches the Naval Jack, but the blue bars are darker.) The "Confederate Flag" is the most recognized symbol of the South in the United States today, and continues to be a controversial icon.
Geography.
Region and climate.
The Confederate States of America claimed a total of of coastline, thus a large part of its territory lay on the seacoast with level and often sandy or marshy ground. Most of the interior portion consisted of arable farmland, though much was also hilly and mountainous, and the far western territories were deserts. The lower reaches of the Mississippi River bisected the country, with the western half often referred to as the Trans-Mississippi. The highest point (excluding Arizona and New Mexico) was Guadalupe Peak in Texas at .
Climate
Much of the area claimed by the Confederate States of America had a humid subtropical climate with mild winters and long, hot, humid summers. The climate and terrain varied from vast swamps (such as those in Florida and Louisiana) to semi-arid steppes and arid deserts west of longitude 100 degrees west. The subtropical climate made winters mild but allowed infectious diseases to flourish. Consequently, on both sides more soldiers died from disease than were killed in combat, a fact hardly atypical of pre–World War I conflicts.
Demographics.
Population
The United States Census of 1860 gives a picture of the overall 1860 population of the areas that joined the Confederacy. Note that population-numbers exclude non-assimilated Indian tribes.
In 1860 the areas that later formed the 11 Confederate States (and including the future West Virginia) had 132,760 (1.46%) free blacks. Males made up 49.2% of the total population and females 50.8% (whites: 48.60% male, 51.40% female; slaves: 50.15% male, 49.85% female; free blacks: 47.43% male, 52.57% female).
Rural/urban configuration
The area claimed by the Confederate States of America consisted overwhelmingly of rural land. Few urban areas had populations of more than 1,000 – the typical county seat had a population of fewer than 500 people. Cities were rare. Of the twenty largest U.S. cities in the 1860 census, only New Orleans lay in Confederate territory – and the Union captured New Orleans in 1862. Only 13 Confederate-controlled cities ranked among the top 100 U.S. cities in 1860, most of them ports whose economic activities vanished or suffered severely in the Union blockade. The population of Richmond swelled after it became the Confederate capital, reaching an estimated 128,000 in 1864. Other Southern cities in the Border slave-holding states such as Baltimore MD, Washington DC, Wheeling VA/WV and Alexandria VA, Louisville KY, and St. Louis MO, never came under the control of the Confederate government.
"(See also Atlanta in the Civil War, Charleston, South Carolina, in the Civil War, Nashville in the Civil War, New Orleans in the Civil War, Wilmington, North Carolina, in the American Civil War, and Richmond in the Civil War)."
Military leaders.
Military leaders of the Confederacy (with their state or country of birth and highest rank) included: 
See also.
Confederate government
Confederacy in Latin America & abroad
Confederacy in popular culture
Confederacy at war
States below the Mason-Dixon Line 
Bibliography.
Overviews and historiography.
Overviews
Historiography
Topical history.
Social history
Intellectual history
Economic history
Political history
Foreign affairs

Constitutional law
Constitutional law is the body of law which defines the relationship of different entities within a state, namely, the executive, the legislature, and the judiciary.
Not all nation states have codified constitutions, though all such states have a "jus commune", or law of the land, that may consist of a variety of imperative and consensual rules. These may include customary law, conventions, statutory law, judge-made law or international rules and norms.
Functions of constitutions.
State and legal structure.
Constitutional laws may often be considered second order rulemaking or rules about making rules to exercise power. It governs the relationships between the judiciary, the legislature and the executive with the bodies under its authority. One of the key tasks of constitutions within this context is to indicate hierarchies and relationships of power. For example, in a unitary state, the constitution will vest ultimate authority in one central administration and legislature, and judiciary, though there is often a delegation of power or authority to local or municipal authorities. When a constitution establishes a federal state, it will identify the several levels of government coexisting with exclusive or shared areas of jurisdiction over lawmaking, application and enforcement.
Human rights.
Human rights or civil liberties form a crucial part of a country's constitution and govern the rights of the individual against the state. Most jurisdictions, like the United States and France, have a codified constitution, with a bill of rights. A recent example is the Charter of Fundamental Rights of the European Union which was intended to be included in the Treaty establishing a Constitution for Europe, that failed to be ratified. Perhaps the most important example is the Universal Declaration of Human Rights under the UN Charter. These are intended to ensure basic political, social and economic standards that a nation state, or intergovernmental body is obliged to provide to its citizens but many do include its governments.
Some countries like the United Kingdom have no entrenched document setting out fundamental rights; in those jurisdictions the constitution is composed of statute, case law and convention. A case named "Entick v. Carrington" is a constitutional principle deriving from the common law. John Entick's house was searched and ransacked by Sherriff Carrington. Carrington argued that a warrant from a Government minister, the Earl of Halifax was valid authority, even though there was no statutory provision or court order for it. The court, led by Lord Camden stated that,

Inspired by John Locke, the fundamental constitutional principle is that the individual can do anything but that which is forbidden by law, while the state may do nothing but that which is authorized by law.
The commonwealth and the civil law jurisdictions do not share the same constitutional law underpinnings.
Legislative procedure.
Another main function of constitutions may be to describe the procedure by which parliaments may legislate. For instance, special majorities may be required to alter the constitution. In bicameral legislatures, there may be a process laid out for second or third readings of bills before a new law can enter into force. Alternatively, there may further be requirements for maximum terms that a government can keep power before holding an election.
Study of constitutional law.
Constitutional law is a major focus of legal studies and research. For example, most law students in the United States are required to take a class in Constitutional Law during their first year, and several law journals are devoted to the discussion of constitutional issues.
The Rule of Law.
The doctrine of the rule of law dictates that government must be conducted according to law.
The Separation of Powers.
The Separation of Powers is often regarded as a second limb functioning alongside the Rule of Law to curb the powers of the Government. 
In most modern nation states, power is divided and vested into three branches of government: The Executive, the Legislature and the Judiciary. The first and the second are harmonized in traditional Westminster forms of government.

Crusades
The Crusades were a series of religious expeditionary wars blessed by Pope Urban II and the Catholic Church, with the stated goal of restoring Christian access to the holy places in and near Jerusalem. Jerusalem was and is a sacred city and symbol of all three major Abrahamic faiths (Judaism, Christianity and Islam). The background to the Crusades was set when the Seljuk Turks decisively defeated the Byzantine army in 1071 and cut off Christian access to Jerusalem. The Byzantine emperor, Alexis I feared that all Asia Minor would be overrun. He called on western Christian leaders and the papacy to come to the aid of Constantinople by undertaking a pilgrimage or a crusade that would free Jerusalem from Muslim rule. Another cause was the destruction of many Christian sacred sites and the persecution of Christians under the Fatimid caliph Al-Hakim.
The crusaders comprised military units of Roman Catholics from all over western Europe, and were not under unified command. The main series of Crusades, primarily against Muslims in the Levant, occurred between 1095 and 1291. Historians have given many of the earlier crusades numbers. After some early successes, the later crusades failed and the crusaders were defeated and forced to return home. Several hundred thousand soldiers became Crusaders by taking vows; the Pope granted them plenary indulgence. Their emblem was the cross — the term "crusade" is derived from the French term for taking up the cross. Many were from France and called themselves "Franks," which became the common term used by Muslims.
The term "crusade" is also used to describe religiously motivated campaigns conducted between 1100 and 1600 in territories outside the Levant usually against pagans, heretics, and peoples under the ban of excommunication for a mixture of religious, economic, and political reasons. Rivalries among both Christian and Muslim powers led also to alliances between religious factions against their opponents, such as the Christian alliance with the Islamic Sultanate of Rûm during the Fifth Crusade.
The Crusades had major political, economic, and social impact on western Europe. It resulted in a substantial weakening of the Christian Byzantine Empire, which fell several centuries later to the Muslim Turks. The Reconquista, a long period of wars in Spain and Portugal (Iberia), where Christian forces reconquered the peninsula from Muslims, is closely tied to the Crusades.
Background.
Middle Eastern situation.
In 636 CE, Muslim forces led by the Arab Rashidun Caliphs defeated the Eastern Roman/Byzantines at the Battle of Yarmouk, conquering Palestine. Jerusalem fell to Caliph Omar's forces in February 638. The Umayyad Dynasty was inaugurated by Muawiyah I, sole caliph from 661, who made his capital in Damascus. In 750 the Umayyads were overthrown by the Abbasid Dynasty of Baghdad and from 878 Palestine was ruled by semi-autonomous governors in Egypt until the Fatimids conquered it in 969. The Fatimids, whose empire stretched to Morocco and centered on Egypt, were tolerant for the times and had many trade and political relationships with the Christian states of Europe. In 1072 the Fatimids lost control of Palestine to the rapidly expanding Great Seljuq Empire. They regained control of it in 1098, but their control was shaky, with the countryside subject to raids by Bedouin nomads and Turkish mercenaries.
One factor that may have contributed to Western interest in Palestine came during the reign of the Fatimid Caliph al-Hakim bi-Amr Allah who ordered the destruction of the Church of the Holy Sepulchre. In 1039 his successor permitted the Byzantine Empire to rebuild it. Pilgrimages had been allowed by Christians to the holy sites in Palestine from soon after their conquest by the Muslims. However, under the Seljuqs pilgrimage routes were disrupted and the unsettled conditions in Palestine were not conducive to either pilgrims or merchants. The Muslims realized that much of the wealth of Jerusalem came from the pilgrims; for this reason and others, the persecution of pilgrims eventually stopped. However, the damage was already done, and the violence of the conquering Seljuk Turks became part of the concern that spread support for the Crusades across the Christian world.
Western European situation.
The western European idea of the Crusades came in response to the deterioration of the Byzantine Empire caused by a new wave of Turkish Muslim attacks. The Byzantine emperors in the east, now threatened by the Seljuks, sent emissaries to the papacy asking for aid in their struggles with the Seljuk Turks. In 1074, Emperor Michael VII sent a request for aid to Pope Gregory VII, but although Gregory appears to have considered leading an expedition to aid Michael, nothing reached the planning stage. In 1095 Emperor Alexios I Komnenos asked Pope Urban II for help against the Turks. 
The Crusades were, in part, an outlet for an intense religious piety which rose up in the late 11th century among the lay public. This was an outgrowth of the Investiture Controversy, which had started around 1075 and was still on-going during the First Crusade. The papacy began to assert its independence of secular rulers and marshalled arguments for the proper use of armed force by Christians. As both sides of the Investiture Controversy tried to marshal public opinion in their favor, people became personally engaged in a dramatic religious controversy. The result was an awakening of intense Christian piety and public interest in religious affairs, and was further strengthened by religious propaganda, which advocated "Just War" in order to retake Palestine from the Muslims. Taking part in such a justified war was seen as a form of penance, which could remit sins.
It was a hotly debated issue throughout the Crusades as what exactly "remission of sin" meant. Most believed that by retaking Jerusalem they would go straight to heaven after death. However, much controversy surrounds exactly what was promised by the popes of the time. One theory was that one had to die fighting for Jerusalem for the remission to apply, which would hew more closely to what Pope Urban II said in his speeches. This meant that if the crusaders were successful, and retook Jerusalem, the survivors would not be given remission.
Precursors.
When the First Crusade was preached in 1095, the Christian princes of northern Iberia had been fighting their way out of the mountains of Galicia and Asturias, the Basque Country and Navarre, with increasing success, for about a hundred years. The fall of Moorish Toledo to the Kingdom of León in 1085 was a major victory, but the turning points of the "Reconquista" still lay in the future. The disunity of Muslim emirs was an essential factor. Other areas were also undergoing Christian expansion against the Muslims. In Sicily, the Norman adventurer Robert Guiscard had conquered northern Sicily by 1072. The maritime state of Pisa funded its new cathedral from two raids on the Muslims - Palermo in 1063 and Mahdia in 1087. Not all these precursor conflicts were against the Muslims, as the Germans were expanding at the expense of the Slavs in Northern Europe. All of these expeditions, along with a few others, are considered precursors to the Crusades, and are often given the name of "proto-crusades".
Just war doctrine.
The papacy of Pope Gregory VII had struggled with reservations about the doctrinal validity of a holy war and the shedding of blood for the Lord and had, with difficulty, resolved the question in favour of justified violence. More importantly to the Pope, the Christians who made pilgrimages to the Holy Land were being persecuted. Saint Augustine of Hippo, Gregory's intellectual model, had justified the use of force in the service of Christ in "The City of God", and a Christian "Just War" might enhance the wider standing of an aggressively ambitious leader of Europe, as Gregory saw himself.
The northerners would be cemented to Rome, and their troublesome knights could see the only kind of action that suited them. Previous attempts by the church to stem such violence, such as the concept of the "Peace of God", were not as successful as hoped. To the south of Rome, Normans were showing how such energies might be unleashed against both Arabs (in Sicily) and Byzantines (on the mainland). A Latin hegemony in the Levant would provide leverage in resolving the Papacy's claims of supremacy over the Patriarch of Constantinople, which had resulted in the Great Schism of 1054, a rift that might yet be resolved through the force of Frankish arms.
Byzantine weakness.
The Eastern Empire and its church were officially divided from the Western church and society in 1054, with the East-West Schism, but cultural differences had long divided the two before the official break in 1054. In the Byzantine Empire, the Eastern emperor's weakness was revealed by the defeat at the Battle of Manzikert in 1071, which opened Asia Minor to the control of the Turks. The Empire was on the verge of collapse, with its treasury bankrupt, its armies poorly deployed, and its aged emperor ineffective. Although an appeal was made in 1074 to the papacy, no aid was forthcoming from Pope Gregory VII. The Eastern Empire also faced difficulties in the Danube river area, as the Petchenegs had allied with the Seljuks and threatened the Empire until 1091 when they were defeated by Emperor Alexius. Alexius still needed to rebuild his armies, and sought to increase his military forces by hiring mercenaries. The Byzantine envoys to Piacenza in March 1095 likely were more concerned to secure mercenaries for Alexius' armies and may have exaggerated the dangers facing the Eastern Empire in order to secure the needed troops.
Pope Urban II.
The immediate cause of the First Crusade was the Byzantine emperor Alexios I's appeal to Pope Urban II for mercenaries to help him resist Muslim advances into territory of the Byzantine Empire. Although attempts at reconciliation after the East–West Schism between the Catholic Church in western Europe and the Eastern Orthodox Church had failed, Alexius I hoped for a positive response from Urban II.
Pope Urban II defined and launched the crusades at the Council of Clermont in 1095. He was a reformer worried about the evils which had hindered the spiritual success of the church and its clergy and the need for a revival of religiosity. He was moved by the urgent appeal for help from Byzantine Emperor Alexius I. Urban's solution was announced on the last day of the council when the pope suddenly proclaimed the Crusade against the infidel Muslims. He called for Christian princes across Europe to launch a holy war in the Holy Land. He contrasted the sanctity of Jerusalem and the holy places with the plunder and desecration by the infidel Turks. He caused outrage by vividly describing attacks upon the Christian pilgrims. He also noted the military threat to the fellow Christians of Byzantium. He charged Christians to take up the holy cause, promising to all those who went remission of sins and to all who died in the expedition immediate entry into heaven.
Then Urban raised secular motives, talking of the feudal love of tournaments and warfare. He urged the barons to give up their fratricidal and unrighteous wars in the West for the holy war in the East. He also suggested material rewards, regarding feudal fiefdoms, land ownership, wealth, power, and prestige, all at the expense of the Arabs and Turks. He said they could be defeated very easily by the Christian forces. When he finished, his listeners chanted "Deus vult" (God wills it). This became the battle cry of the crusaders. Urban put the bishop of Le Puy in charge of encouraging prelates and priests to join the cause. Word spread rapidly that war against unbelief would be fused with the practice of pilgrimage to holy sites, and the pilgrims' reward would be great on earth, as in heaven. Immediately thousands pledged themselves to go on the first crusade. Pope Urban's speech ranks as one of the most influential speeches ever made: it launched the holy wars which occupied the minds and forces of western Europe for two hundred years.
Preaching and preparation before the First Crusade.
Urban's sermon at Clermont was the start of an eight month preaching tour that the pope undertook throughout France, urging the holy war and exhorting people to help defend the Byzantine church against the Muslims. He also sent other preachers throughout Western Europe to spread the word of the Crusade. Urban fixed a date of August 1096 for the crusaders to depart for Palestine. Urban's example inspired the preaching of Peter the Hermit, who eventually led a "People's Crusade" of perhaps as many as 20,000 people, mostly lower class, towards the Holy Land just after Easter 1096. When they reached the Byzantine Empire, Alexius urged them to wait for the western nobles, but the "army" insisted on proceeding and was ambushed outside Nicaea by the Turks, with only about 3000 people escaping the ambush. 
On a popular level, the preaching of the First Crusade unleashed a wave of impassioned, personally felt pious Christian fury that was expressed in the massacres of Jews that accompanied and preceded the movement of the crusaders through Europe, as well as the violent treatment of "schismatic" Orthodox Christians of the east.
Besides the People's Crusade, Urban's appeal gathered a large number of noblemen and other soldiers together. Among the leaders of the First Crusade were Godfrey of Bouillon, Robert Curthose - son of William the Conqueror and eldest brother of the then King of England, William II of England, Hugh of Vermandois - brother of King Philip I of France, and Stephen, Count of Blois - brother-in-law of Robert Curthose. The French king was excommunicated and thus unable to go. The German Emperor, Henry IV, was still embroiled in the Investiture Crisis and would not have supported papal initiatives. The various leaders left at different times, with Hugh of Vermandois departing first and the bulk of the army dividing into four parts which travelled separately to Constantinople. In all, the western forces may have totaled as much as 100,000 persons counting both combatants and non-combatants.
List.
A traditional numbering scheme for the crusades totals nine during the 11th to 13th centuries. This division is arbitrary and excludes many important expeditions, among them those of the 14th, 15th, and 16th centuries. The Knights Hospitaller continued to crusade in the Mediterranean Sea around Malta until their defeat by Napoleon in 1798. There were frequent "minor" Crusades throughout this period, not only in the area the crusaders called Outremer but also in the Iberian Peninsula and central Europe, against Muslims and also Christian heretics and personal enemies of the Papacy or other powerful monarchs.
First Crusade 1095–1099.
The official crusader armies set off from France and Italy on the papally ordained date of 15 August 1096. The armies journeyed eastward by land toward Constantinople, where they received a wary welcome from the Byzantine Emperor. Pledging to restore lost territories to the empire, the main army, mostly French and Norman knights under baronial leadership—Godfrey of Bouillon (1060–1100), Baldwin of Flanders, Raymond of Toulouse, Robert of Normandy, Bohemond of Taranto, marched south through Anatolia.
Campaigns.
The Crusader armies fought the Turks, at first at the lengthy Siege of Antioch that began in October 1097 and lasted until June 1098. Once inside the city, as was standard military practice when an enemy had refused to surrender, the Crusaders massacred the Muslim inhabitants and pillaged the city. However, a large Muslim relief army under Kerbogha immediately besieged the victorious Crusaders within Antioch. Bohemund of Taranto led a successful break-out and defeat of Kerbogha's army on 28 June. While Bohemond and his men retained control of Antioch, in spite of his pledge to the Byzantine emperor, most of the surviving crusader army marched south, moving from town to town along the coast, finally reaching the walls of Jerusalem on 7 June 1099 with only a fraction of their original forces.
Siege of Jerusalem.
The Jews and Muslims fought together to defend Jerusalem against the invading Franks. They were unsuccessful though and on 15 July 1099 the crusaders entered the city. They proceeded to massacre the remaining Jewish and Muslim civilians and pillaged or destroyed mosques and the city itself. One historian has written that the "isolation, alienation and fear" felt by the Franks so far from home helps to explain the atrocities they committed, including the cannibalism which was recorded after the Siege of Ma'arra in 1098. As a result of the First Crusade, several small Crusader states were created, notably the Kingdom of Jerusalem. In the Kingdom of Jerusalem at most 120,000 Franks (predominantly French-speaking Western Christians) ruled over 350,000 Muslims, Jews, and native Eastern Christians who had remained since the Arab occupation began in 638 AD.
The Crusaders also tried to gain control of the city of Tyre, but were defeated by the Muslims. The people of Tyre asked Zahir al-Din Atabek, the leader of Damascus, for help defending their city from the Franks with the promise to surrender Tyre to him. When the Franks were defeated the people of Tyre did not surrender the city but Zahir al-Din simply said, "What I have done I have done only for the sake of God and the Muslims, not out of desire for wealth and kingdom."
After gaining control of Jerusalem the Crusaders created four Crusader states: the Kingdom of Jerusalem, the County of Edessa, the Principality of Antioch and the County of Tripoli. Initially, Muslims did very little about the Crusader states due to internal conflicts.
Eventually, the Muslims began to reunite under the leadership of Imad ad-Din Zengi. He began by re-taking Edessa in 1144. It was the first city to fall to the Crusaders, and became the first to be recaptured by the Muslims. This led the Pope to call for a second Crusade.
Crusaders' perspectives.
The story of the first crusade from the crusaders' perspective recounts the struggles of the first wave of crusaders to reach the hinterlands of Byzantium, of Islamic Syria, and then of Jerusalem; of the terrible slaughters of Jewish populations committed by a second wave as it marched through the Rhineland; of finding food and facing starvation; of the "miracles" associated with the alleged finding of the Holy Lance in Antioch; of the competition between European princes for leadership; and of the eventual taking of Jerusalem itself. It was an achievement to coordinate crusaders with sharply different languages, styles of leadership, and modes of fighting. That such a band even made it to Jerusalem is remarkable, and was possible, first, because of divisions within the realm of Islam, and second, because Muslims in the various provinces misinterpreted the presence of the crusading army. They seem to have regarded the Christian forces as renegades, escapees from the poverty and oppression of the "territory of war." This interpretation led to a low estimate of the threat posed to Muslim security by an army that, despite weaknesses, was motivated by a profound religious fervor.
Scholarly debates.
According to the interpretation of historian Steven Runciman (1951), the First Crusade was like a barbarian invasion of the civilized and sophisticated Byzantine empire and ultimately brought about the ruin of Byzantine civilization. The crusade was unwittingly triggered by the Byzantine emperor, Alexius I Comnenus, when he had sent ambassadors to the pope in 1095 to ask for mercenary soldiers to enroll in his armies. The emotive appeal made in response by Pope Urban II, however, had the effect of sending thousands of Frankish knights to Constantinople under their own leaders, quite a different outcome from what Alexius had expected. There had been long-distance intellectual disputes between Byzantium and the West in the past, but since contact between the two societies was sporadic, there was little open hostility. Now that the westerners arrived in the center of the empire in large numbers, those differences became a serious matter. Especially important, Runciman argues, was tension between the Byzantine patriarch and the pope, and the more tolerant attitude of the Byzantines towards Muslim powers. Although Runciman lays some of the blame at the door of the Byzantine emperors who reigned after 1143, the sack of Constantinople by the Fourth Crusade in April 1204 was the culmination of the mounting dislike and suspicion that all western Christendom now felt towards the Byzantines.
Ever since Runciman published his interpretation in 1951, it has been under challenge by scholars. They say he was too uncritical in accepting the main Byzantine source, the narrative by Anna Comnena (the daughter of Emperor Alexius I), which presents Alexius I's actions as motivated solely by superhuman charity and places the blame entirely on the crusaders, particularly on the Norman, Bohemond of Taranto. Critics say Runciman takes at face value Anna Comnena's descriptions of some of the crusaders as uncouth louts and this is largely the basis for belief that the two peoples were mutually estranged from the start. Scholars argue that the classicising literary genre in which Comnena wrote dictated that foreign peoples be presented as 'barbarians' and that this did not necessarily mean that the entire populations of the two halves of Christendom were in a constantly increasing state of mutual antipathy.
Among recent scholars, Paul Magdalino's and Ralph-Johannes Lilie's close studies of Byzantine policies towards the crusader states of Syria show not steadily mounting tension, but periods of animosity interspersed with co-operation and alliance. Jonathan Shepard re-examines the whole question of Byzantine involvement with the genesis of the First Crusade in two influential articles. Adopting a more critical stance towards Anna Comnena, Shepard argues that there was far more to the episode than an innocent Byzantine emperor taken aback by the turn of events and that Alexius was cleverly exploiting the situation for his own ends. While Runciman denounces Bohemond, the Norman leader, as a "villain" whose greed soured relations with the Byzantines, Shepard argues that this picture depends on an uncritical reading of Anna Comnena, who glorified her own family and vilified Bohemond mercilessly. In reality in 1096-7, Alexius viewed Bohemond as a potential tool, ally and recruit, a kind of imperial agent to oversee the re-conquest of Asia Minor.
Harris (2003) rejects the "clash of civilizations" model. He argues that trouble arose because the West misunderstood Byzantine foreign policy. That policy was narrowly focused on three goals which the West did not accept: acceptance of the theory that the Roman inheritance had shifted from Rome to Constantinople (called "translatio imperii"), that the suzerainty of Byzantine emperors ought to be recognized by the West, and commitment to the security of the "Oikumene" (that is, the civilized, Christian world centered around Constantinople). Although the Byzantines employed many high-ranking Latins in their government, Harris finds repeated instances of Byzantine hostility toward Latins, based on deep-rooted and long-standing antipathy that was rooted in a conviction of Byzantine cultural and religious superiority, and perhaps heightened by a growing fear of Byzantium's military inferiority and political weakness.
Crusade of 1101.
Following this crusade there was a second, less successful wave of crusaders, in which Turks led by Kilij Arslan defeated the Crusaders in three separate battles in a well-managed response to the First Crusade. On the other side of the Mediterranean, however, the Second Crusade met with great success as a group of Northern European Crusaders stopped in Portugal, allied with the Portuguese King, Afonso I of Portugal, and retook Lisbon from the Muslims in 1147. A detachment from this group of crusaders helped Count Raymond Berenguer IV of Barcelona conquer the city of Tortosa the following year. In the Holy Land by 1150, both the kings of France and Germany had returned to their countries without any result. St. Bernard of Clairvaux, who in his preachings had encouraged the Second Crusade, was upset with the amount of misdirected violence and slaughter of the Jewish population of the Rhineland. North Germans and Danes attacked the Wends during the 1147 Wendish Crusade, which was unsuccessful as well.
Third Crusade 1187–1192.
The Muslims had long fought among themselves, but they were finally united by Saladin, who created a single powerful state. Following his victory at the Battle of Hattin he easily overwhelmed the disunited crusaders in 1187 and all of the crusader holdings except a few coastal cities. The Byzantines, fearful of the crusaders, made an alliance with Saladin.
Saladin's victories shocked Europe. On hearing news of the Siege of Jerusalem (1187), Pope Urban III died of a heart attack on 19 October 1187. On 29 October Pope Gregory VIII issued a bull "Audita tremendi", proposing the Third Crusade. To reverse this disaster Emperor Frederick I Barbarossa (r. 1152-1190) of Germany, King Philip II Augustus of France, (r. 1180-1223), and King Richard the Lion-Hearted (r. 1189-1199) of England established a crusade; the pope's role was minor. Frederick died en route and few of his men reached the Holy Land. The other two armies arrived but were beset by political quarrels. King Philip feigned illness and returned to France, there scheming to win back the duchy of Normandy from Richard's control. Richard captured the island of Cyprus from the Byzantines in 1191. Cyprus served as a Crusader base for centuries to come, and remained in European hands until 1571. After a long siege, Richard the Lionheart recaptured the city of Acre and placed the entire Muslim garrison under captivity (they were executed after a series of failed negotiations). The Crusader army headed south along the Mediterranean coast. They defeated the Muslims near Arsuf, recaptured the port city of Jaffa, and were in sight of Jerusalem. However, Richard did not believe he would be able to hold Jerusalem once it was captured, as the majority of Crusaders would then return to Europe, and the crusade ended without the taking of Jerusalem. Richard left the following year after negotiating a treaty with Saladin. The treaty allowed trade for merchants and unarmed Christian pilgrims to make pilgrimages to the Holy Land (Jerusalem), while it remained under Muslim control.
Richard the Lion-Hearted's exploits gave rise to the legends of the Lion-Hearted, and, through them, Richard acquired a greatly exaggerated posthumous prestige. More showman than statesman, a brave knight but a bad king, his stature was measured by Winston Churchill: "His life was one magnificent parade which, when ended, left only an empty plain." Richard did regain Acre and Jaffa for the Christians, but that was all. The agreement he finally reached with Saladin gave pilgrims free access to Jerusalem and little else. The city itself and the adjoining kingdom, except for some coastal cities, were still subject to the same law—that of the Koran, not the Bible.
Fourth Crusade 1202–1204.
The Fourth Crusade was initiated in 1202 by Pope Innocent III, with the intention of invading the Holy Land through Egypt. Because the Crusaders lacked the funds to pay for the fleet and provisions that they had contracted from the Venetians, Doge Enrico Dandolo enlisted the crusaders to restore the Christian city of Zara (Zadar) to obedience. At this point, they lost the support of the pope who considered them excommunicated. Because they subsequently lacked provisions and time on their vessel lease, the leaders decided to go to Constantinople, where they attempted to place a Byzantine exile on the throne. After a series of misunderstandings and outbreaks of violence, the Crusaders sacked the city in 1204, and established the so-called Latin Empire and a series of other Crusader states throughout the territories of the Greek Byzantine Empire. While deploring the means, the pope finally supported this apparent forced reunion between the Eastern and Western churches. This is often seen as the final breaking point of the Great Schism between the Eastern Orthodox Church and (Western) Roman Catholic Church.
Albigensian Crusade.
The Albigensian Crusade was launched in 1209 to eliminate the heretical Cathars of Occitania (the south of modern-day France). It was a decades-long struggle that had as much to do with the concerns of northern France to extend its control southwards as it did with heresy. In the end, both the Cathars and the independence of southern France were exterminated.
Children's Crusade.
The chronicles report a spontaneous youth movement in France and Germany in 1212 attracting large numbers of peasant teenagers and young people (few were under age 15). They were convinced they could succeed where older and more sinful crusaders had failed: the miraculous power of their faith would triumph where the force of arms had not. Many parish priests and parents encouraged such religious fervour and urged them on. The pope and bishops opposed the attempt but failed to stop it entirely. The French movement was led by Stephen, a shepherd-boy of about twelve years old from the small town of Cloyes in the Orléannais. Stephen, as befitted the leader, insisted on having a gaily decorated cart for himself, with a canopy to shade him from the sun. At his side rode boys of noble birth, each rich enough to possess a horse. No one resented the inspired prophet travelling in comfort. On the contrary, he was treated as a saint, and locks of his hair and pieces of his garments were collected as precious relics. They took the road past Tours and Lyons, making for Marseilles. It was a painful journey. The summer was unusually hot. They depended on charity for their food, and the drought left little to spare in the country, and water was scarce. Many of the children died by the wayside. Others dropped out and tried to wander home. But at last the little Crusade reached Marseilles. After a few days two merchants of Marseilles, called, according to tradition, Hugh the Iron and William the Pig, offered to put ships at their disposal and to carry them free of charge, for the glory of God, to Palestine. Stephen eagerly accepted the kindly offer. Seven vessels were hired by the merchants, and the children were taken aboard and set out to sea. Eighteen years passed before there was any further news of them.
A band of several thousand youths and young men led by a German boy called Nicholas, from a Rhineland village had gathered at Cologne and set out for Italy. About a third survived the march over the Alps and got as far as Genoa; Stephen's group from France came to Marseilles. The luckier ones eventually managed to get safely home, but many others were sold as slaves in Marseilles. Little is known of the return journey of Stephen from France or Nicolas from Germany. Many of the children, especially the girls, could not face again the ardours of the road and stayed behind in some Italian town or village. Only a few stragglers found their way back next spring to the Rhineland. Nicholas was probably not amongst them. But the angry parents whose children had perished insisted on the arrest of his father, who had, it seems, encouraged the boy out of vainglory. He was taken and hanged. The sources are scattered and unclear and historians are still not sure exactly what happened to many of the thousands of children. In more recent times it is considered doubtful that there was any such expedition.
Fifth Crusade 1217–1221.
By processions, prayers, and preaching, the Church attempted to set another crusade afoot, and the Fourth Council of the Lateran (1215) formulated a plan for the recovery of the Holy Land. In the first phase, a crusading force from Austria and Hungary joined the forces of the king of Jerusalem and the prince of Antioch to take back Jerusalem. In the second phase, crusader forces achieved a remarkable feat in the capture of Damietta in Egypt in 1219, but under the urgent insistence of the papal legate, Pelagius, they then launched a foolhardy attack on Cairo in July 1221. The crusaders were turned back after their dwindling supplies led to a forced retreat. A night-time attack by the ruler of Egypt, the powerful Ayyubid Sultan Al-Kamil, resulted in a great number of crusader losses and eventually in the surrender of the army. Al-Kamil agreed to an eight-year peace agreement with Europe.
Al-Kamil had put a bounty of a Byzantine gold piece for every Christian head brought to him during the war. During 1219, St. Francis of Assisi crossed the battle lines at Damietta in order to speak with Al-Kamil. He and his companion Illuminatus were captured and beaten and brought before the Sultan. St. Bonaventure, in his Major Life of St. Francis, says that the Sultan was impressed by Francis and spent some time with him. Francis was given safe passage and although he was offered many gifts, all he accepted was a horn for calling the faithful to prayer. This act eventually led to the establishment of the Franciscan Custody of the Holy Land.
Sixth Crusade 1228–1229.
Emperor Frederick II had repeatedly vowed a crusade but failed to live up to his words, for which he was excommunicated by Pope Gregory IX in 1228. He nonetheless set sail from Brindisi, landed in Saint-Jean d'Acre. There were no battles as Frederick made a peace treaty with Al-Kamil, the ruler of Egypt. This treaty allowed Christians to rule over most of Jerusalem and a strip of territory from Acre to Jerusalem, while the Muslims were given control of the Dome of the Rock and the Al-Aqsa Mosque. Thus he achieved unexpected success. In 1225 he married Yolanda, the young heiress to the kingdom of Jerusalem; upon her death in 1228, Frederick crowned himself king of Jerusalem. The peace lasted for about ten years. Many of the Muslims though were not happy with Al-Kamil for giving up control of Jerusalem. In 1244, following the siege of Jerusalem, the Muslims regained control of the city.
Seventh Crusade 1248–1254.
The papal interests represented by the Templars brought on a conflict with Egypt in 1243, and in the following year a Khwarezmian force summoned by the latter stormed Jerusalem. The crusaders were drawn into battle at La Forbie in Gaza. The crusader army and its Bedouin mercenaries were completely defeated within forty-eight hours by Baibars' force of Khwarezmian tribesmen. This battle is considered by many historians to have been the death knell to the Kingdom of Outremer.
Louis IX of France organized a crusade against Egypt from 1248 to 1254, leaving from the newly constructed port of Aigues-Mortes in southern France. The crusaders were decisively defeated en-route to Cairo and King Louis was captured; the Arabs demanded and received a huge ransom for the release of the hapless king.
Eighth Crusade 1270.
Ignoring his advisers, in 1270 King Louis IX again attacked the Arabs in Tunis in North Africa. He picked the hottest season of the year for campaigning and his army was devastated by disease. The king himself died, ending the last major attempt to take the Holy Land. The numbering of crusades is problematical. The Eighth Crusade is sometimes counted as the Seventh, if the Fifth and Sixth Crusades are counted as a single crusade. The Ninth Crusade is sometimes also counted as part of the Eighth.
Ninth Crusade 1271–1272.
The future Edward I of England undertook another expedition against Baibars in 1271, after having accompanied Louis on the Eighth Crusade. Louis died in Tunisia. The Ninth Crusade was deemed a failure and ended the Crusades in the Middle East.
In their later years, faced with the threat of the Egyptian Mamluks, the Crusaders' hopes rested with a Franco-Mongol alliance. The Ilkhanate's Mongols were thought to be sympathetic to Christianity, and the Frankish princes were most effective in gathering their help, engineering their invasions of the Middle East on several occasions. Although the Mongols successfully attacked as far south as Damascus on these campaigns, the ability to effectively coordinate with Crusades from the west was repeatedly frustrated most notably at the Battle of Ain Jalut in 1260. The Mamluks, led by Baibars, eventually made good their pledge to cleanse the entire Middle East of the Franks. With the fall of Antioch (1268), Tripoli (1289), and Acre (1291), those Christians unable to leave the cities were massacred or enslaved and the last traces of Christian rule in the Levant disappeared.
Aftermath.
The island of Ruad, three kilometers from the Syrian shore, was occupied for several years by the Knights Templar but was ultimately lost to the Mamluks in the Siege of Ruad on September 26, 1302. The Armenian Kingdom of Cilicia, which was not itself a crusader state, and was not Latin Christian, but was closely associated with the crusader states and was ruled by the Latin Christian Lusignan dynasty for its last 34 years, survived until 1375. Other echoes of the crusader states survived for longer, but well away from the Holy Land itself. The Knights of St John carved out a new territory based on the Aegean island of Rhodes, which they ruled until 1522. Cyprus remained under the rule of the House of Lusignan until 1474/89 (the precise date depends on how Venice's highly unusual takeover is interpreted – see Caterina Cornaro) and subsequently that of Venice until 1570. By this time the Knights of St John had moved to Malta – even further from the Holy Land – which they ruled until 1798.
Northern Crusades.
Crusades of the Teutonic Order.
A German religious and military order originally founded during the siege of Acre in the Third Crusade and modeled after the Knights Templar and Hospitalers, the Teutonic Knights moved to eastern Europe early in the 13th century. There, under their grand master, Hermann von Salza, they became powerful and prominent. 
In 1198, the Teutonic Order started the Livonian Crusade. Despite numerous setbacks and rebellions, by 1290, Livonians, Latgalians, Selonians, Estonians (including Oeselians), Curonians and Semigallians had been all gradually subjugated. Denmark and Sweden also participated in fight against Estonians.
In 1229, responding to an appeal from the Duke of Poland, they began a crusade against the pagan Slavs of Prussia. They became sovereigns over lands they conquered over the next century. In a series of campaigns, the Teutonic Knights gained control over the whole Baltic coast, founding numerous towns and fortresses and establishing Christianity. A later conflict between Teutonic Knights and Christian Poland resulted in the Battle of Grunwald. 
The Teutonic Order's attempts to conquer Orthodox Russia (particularly the Republics of Pskov and Novgorod), an enterprise endorsed by Pope Gregory IX, can also be considered as a part of the Northern Crusades. One of the major blows for the idea of the conquest of Russia was the Battle of the Ice in 1242. With or without the Pope's blessing, Sweden also undertook several crusades against Orthodox Novgorod. A later conflict between Teutonic Knights and Christian Poland resulting in the Battle of Grunwald.
Swedish Crusades.
National-romanticist Swedish and Finnish historians in the nineteenth century gave the name "crusades" to military expeditions which resulted in the Swedish conquest of Finland in the Middle Ages.
The First Swedish Crusade, considered mythical by some historians, may have taken place around 1155 AD.
There is no surviving historical record for the Second Swedish Crusade in about 1249 AD, but it is believed to have taken place, and resulted in the known conquest of southwestern Finland. The Third Swedish Crusade, against Novgorod, is documented by both parties to the conflict.
According to archaeological finds, Finland was largely Christian before these crusades; they can be seen as military expeditions for territorial gain, rather than religious reasons.
Other.
Wendish Crusade.
Contemporaneous with the Second Crusade, Saxons and Danes fought against Polabian Slavs in the 1147 Wendish Crusade.
Stedinger Crusade.
Between 1232 and 1234, there was a crusade against the Stedingers. This crusade was special, because the Stedingers were not heathens or heretics, but fellow Roman Catholics. They were free Frisian farmers who resented attempts of the count of Oldenburg and the archbishop Bremen-Hamburg to make an end to their freedoms. The archbishop excommunicated them, and Pope Gregory IX declared a crusade in 1232. The Stedingers were defeated in 1234.
Aragonese Crusade.
The Aragonese Crusade, or Crusade of Aragón, was declared by Pope Martin IV against the King of Aragón, Peter III the Great, in 1284 and 1285.
Alexandrian Crusade.
The Alexandrian Crusade of October 1365 was a minor seaborne crusade against Muslim Alexandria led by Peter I of Cyprus. His motivation was at least as commercial as religious.
Norwich Crusade.
See Norwich Crusade.
Mahdian Crusade.
The Mahdian Crusade of Summer 1390 was a French-Genoese enterprise against Muslim pirates in North Africa and their main base at Mahdia led by Louis II, Duke of Bourbon.
Crusades in the Balkans.
To counter the expanding Ottoman Empire, several crusades were launched in the 15th century.
Crusade against the Tatars.
In 1259, Mongols led by Burundai and Nogai Khan ravaged the principality of Halych-Volynia, Lithuania and Poland. After that Pope Alexander IV tried without success to create a crusade against the Blue Horde (see Mongol invasion of Poland).
In the 14th century, Khan Tokhtamysh combined the Blue and White Hordes forming the Golden Horde. It seemed that the power of the Golden Horde had begun to rise, but in 1389, Tokhtamysh made the disastrous decision of waging war on his former master, the great Tamerlane. Tamerlane's hordes rampaged through southern Russia, crippling the Golden Horde's economy and practically wiping out its defenses in those lands.
After losing the war, Tokhtamysh was then dethroned by the party of Khan Temur Kutlugh and Emir Edigu, supported by Tamerlane. When Tokhtamysh asked Vytautas the Great for assistance in retaking the Horde, the latter readily gathered a huge army which included Lithuanians, Ruthenians, Russians, Mongols, Moldavians, Poles, Romanians and Teutonic Knights.
In 1398, the huge army moved from Moldavia and conquered the southern steppe all the way to the Dnieper River and northern Crimea. Inspired by their great successes, Vytautas declared a 'Crusade against the Tatars' with Papal backing. Thus, in 1399, the army of Vytautas once again moved on the Horde. His army met the Horde's at the Vorskla River, slightly inside Lithuanian territory.
Although the Lithuanian army was well equipped with cannon, it could not resist a rear attack from Edigu's reserve units. Vytautas hardly escaped alive. Many princes of his kin—possibly as many as 20—were killed (for example, Stefan Musat, Prince of Moldavia and two of his brothers, while a fourth was badly injured ), and the victorious Tatars besieged Kiev. "And the Christian blood flowed like water, up to the Kievan walls," as one chronicler put it. Meanwhile, Temur Kutlugh died from the wounds received in the battle, and Tokhtamysh was killed by one of his own men.
Hussite Crusade.
The Hussite Crusade(s), also known as the "Hussite Wars," or the "Bohemian Wars," involved the military actions against and amongst the followers of Jan Hus in Bohemia in the period 1420 to circa 1434. The Hussite Wars were arguably the first European war in which hand-held gunpowder weapons such as muskets made a decisive contribution. The Taborite faction of the Hussite warriors were basically infantry, and their many defeats of larger armies with heavily armoured knights helped affect the infantry revolution. In the end, it was an inconclusive war.
Role of women.
Most writings stress the crusades as a masculine movement symbolic of honour and male courage. But women were also involved behind the scenes, and as direct victims.
Women at home were intricately connected with the crusade movement by aiding the recruitment of crusading men, taking on extra duties in their absence, and supporting them financially and with prayer. Their encouragement and familial ties created kinship connections which made the prospect of taking the cross more appealing for those risking their lives. Arguably the most significant role that women played in the West during the crusades was their preservation of the home. The best known example is of Adela of Blois, wife of Stephen of Blois whose correspondence with her husband while he was on Crusade and she was at home managing his fief has survived in part. It appears she was rather more keen on his crusading than he was. Men could journey to The Holy Land without having to worry about their home because regents, often wives or mothers, were in charge of their estates and families. The Church recognised that concern about their families and estates might discourage crusaders, however, so they instituted special papal protections for them as part of the crusading privilege.
Even though most women showed their support for the crusades at home, some women took the cross themselves to go on the crusade. Aristocratic women who joined the movement often found that they had new positions of authority they did not have in the West. Eleanor of Aquitaine, the wealthy queen of France and the wife of king Louis VII, took the cross from St. Bernard of Clairvaux on Easter Sunday 1145 to join her husband. Another woman who had ultimate political power in the East was Melisende of Jerusalem, who under law gained hereditary rights to the crown upon her husband's death. Like Eleanor, Melisende never led troops into battle, but she did participate in acts of political diplomacy. Less successful was her granddaughter Sibylla of Jerusalem, whose choice of husband had been a crucial political issue since her childhood. Her second marriage to Guy of Lusignan made him the king-consort on the death of Baldwin IV, with disastrous results. While most women were there to help and care for the crusading men by bringing them water or raising their spirits by offering emotional support, there were women who had specific tasks which defined their feminine characteristics like the washerwoman.
The permanent residents of the Crusader kingdoms, if born in Europe, had usually come unmarried. Very many married women from Apulia in Southern Italy, where living conditions were often harsh, encouraged young women to take ship for Palestine in the knowledge that many men there were looking for wives.
The most controversial role that women had in the crusades was of course taking an active part, which threatened their femininity. Accounts are contradictory. The accounts of women fighting come mostly from Muslim historians whose aim was to portray Christian women as barbaric and ungodly because of their acts of killing. The contrasting view from Christian accounts portray women fighting only in emergency situations for the preservation of the camps and their own lives. In these cases women are seen as more feminine while behaving like 'proper women'. Virtually all crusade writings came from men, and women would have been interpreted subjectively no matter what roles they played.
Criticism.
Elements of the Crusades were criticized by some from the time of their inception in 1095. For example, Roger Bacon felt the Crusades were not effective because, "those who survive, together with their children, are more and more embittered against the Christian faith." In spite of such criticism, the movement was widely supported in Europe long after the fall of Acre in 1291.
St. Francis of Assisi crossed enemy lines to meet the Sultan of Egypt. Hoeberichts cast doubt on the intentions most Christian historians assign to Francis.
One aspect of the crusades that shocked some easterners was the formation in the west of military religious orders. This went against canon law.
Another criticism was raised that the crusaders had sworn to uphold the emperor's claims to the holy land, but upon taking Jerusalem the crusaders established "Latin" states there.
Further criticisms have been leveled; the misdirection of the crusading movement being one. This is especially evident in the Fourth Crusade which instead of attacking Islam attacked another Christian power - the (Eastern) Roman Empire, viewed as a "change in direction," not just literally, but in the ethos behind the movement where material considerations became more pronounced.
Legacy.
Historiography.
Historians are largely agreed on the facts of the crusades and their long-term impact, but differ sharply regarding their moral interpretation and their wisdom.
Politics and culture.
The Crusades had an enormous influence on the European Middle Ages. At times, much of the continent was united under a powerful Papacy, but by the 14th century, the development of centralized bureaucracies (the foundation of the modern nation state) was well on its way in France, England, Spain, Burgundy, and Portugal, and partly because of the dominance of the church at the beginning of the crusading era.
Although Europe had been exposed to Islamic culture for centuries through contacts in Iberian Peninsula and Sicily, much knowledge in areas such as science, medicine, and architecture was transferred from the Islamic to the western world during the crusade era.
The military experiences of the crusades also had a limited degree of influence on European castle design; for example, Caernarfon Castle, in Wales, begun in 1283, directly reflects the style of fortresses Edward I had observed while fighting in the Crusades.
Crusader society in the Kingdom of Jerusalem was also characterized by a culture of innovation, including in economic and social structures, governance and taxation, social mobility, and agricultural technology.
Along with trade, new scientific discoveries and inventions made their way east or west. Arab and classical Greek advances (including the development of algebra, optics, and refinement of engineering) made their way west and sped the course of advancement in European universities that led to the Renaissance in later centuries
The invasions of German crusaders prevented formation of the large Lithuanian state incorporating all Baltic nations and tribes. Lithuania was destined to become a small country and forced to expand to the East looking for resources to combat the crusaders. The Northern Crusades caused great loss of life among the pagan Polabian Slavs, and they consequently offered little opposition to German colonization (known as Ostsiedlung) of the Elbe-Oder region and were gradually assimilated by the Germans, with the exception of Sorbs.
The First Crusade ignited a long tradition of organized violence against Jews in European culture.
The Albigensian Crusade was initiated by the Catholic Church to eliminate the Cathar heresy in Languedoc. The violence led to France's acquisition of lands with closer cultural and linguistic ties to Catalonia. The Albigensian Crusade also had a role in the creation and institutionalization of both the Dominican Order and the Medieval Inquisition.
Trade.
The need to raise, transport and supply large armies led to a flourishing of trade throughout Europe. Roads largely unused since the days of Rome saw significant increases in traffic as local merchants began to expand their horizons. This was not only because the Crusades "prepared" Europe for travel, but also because many "wanted" to travel after being reacquainted with the products of the Middle East. This also aided in the beginning of the Renaissance in Italy, as various Italian city-states from the very beginning had important and profitable trading colonies in the crusader states, both in the Holy Land and later in captured Byzantine territory.
Increased trade brought many things to Europeans that were once unknown or extremely rare and costly. These goods included a variety of spices, ivory, jade, diamonds, improved glass-manufacturing techniques, early forms of gun powder, oranges, apples, and other Asian crops, and many other products.
From a larger perspective, and certainly from that of noted naval/maritime historian Archibald Ross Lewis, the Crusades must be viewed as part of a massive macrohistorical event during which Western Europe, primarily by its ability in naval warfare, amphibious siege, and maritime trade, was able to advance in all spheres of civilization. Recovering from the Dark Ages of AD 700–1000, throughout the 11th century Western Europe began to push the boundaries of its civilization. Prior to the First Crusade the Italian city-state of Venice, along with the Byzantine Empire, had cleared the Adriatic Sea of Islamic pirates, and loosened the Islamic hold on the Mediterranean Sea (Byzantine-Muslim War of 1030–1035). The Normans, with the assistance of the Italian city-states of Genoa and Pisa, had retaken Sicily from the Muslims from 1061–1091. These conflicts prior to the First Crusade had both retaken Western European territory and weakened the Islamic hold on the Mediterranean, allowing for the rise of Western European Mediterranean trading and naval powers such as the Sicilian Normans and the Italian city-states of Venice, Genoa, and Pisa.
During the Middle Ages, the key trading region of Western Europe was the Black Sea-Mediterranean Sea-Red Sea. It was the aforementioned pre-First Crusade actions, along with the Crusades themselves, which allowed Western Europe to contest the trade of the Mediterranean Sea and Black Sea, for a period which began in the 11th century and would only be ended by the Turkish Ottoman Empire beginning in the mid-to-late 15th century. This Western European contestation of vital sea lanes allowed the economy of Western Europe to advance to previously unknown degrees, most obviously as regards the Maritime Republics of Venice, Genoa, and Pisa. Indeed, it is no coincidence that the Renaissance began in Italy, as the Maritime Republics, through their control of the Eastern Mediterranean and Black Seas, were able to return to Italy the ancient knowledge of the Greeks and Romans, as well as the products of distant East Asia.
Combined with the Mongol Empire, Western Europe traded extensively with East Asia, the security of the Mongol Empire allowing the products of Asia to be brought to such Western European controlled ports as Acre, Antioch, Kaffa (on the Black Sea) and even, for a time, Constantinople itself. The Fifth Crusade of 1217–1221 and the Seventh Crusade of 1248–1254 were largely attempts to secure Western European control of the Red Sea trade region, as both Crusades were directed against Egypt, the power base of the Ayyubid, and then Mameluke, Sultanates. It was only in the 14th century, as the stability of trade with Asia collapsed with the Mongol Empire, the Mamelukes destroyed the Middle Eastern Crusader States, and the rising Ottoman Empire impeded further Western European trade with Asia, that Western Europeans sought alternate trade routes to Asia, ultimately leading to Columbus's voyage of 1492.
Caucasus.
In the Caucasus Mountains of Georgia, in the remote highland region of Khevsureti, a tribe called the Khevsurs are thought to possibly be direct descendants of a party of crusaders who got separated from a larger army and have remained in isolation with some of the crusader culture intact. Into the 20th century, relics of armor, weaponry and chain mail were still being used and passed down in such communities. Russian serviceman and ethnographer Arnold Zisserman who spent 25 years (1842–1867) in the Caucasus, believed the exotic group of Georgian highlanders were descendants of the last Crusaders based on their customs, language, art and other evidence. American traveler Richard Halliburton saw and recorded the customs of the tribe in 1935.
Etymology and usage.
The crusades were never referred to as such by their participants. The original crusaders were known by various terms, including "fideles Sancti Petri" (the faithful of Saint Peter) or "" (knights of Christ). They saw themselves as undertaking an "iter", a journey, or a "peregrinatio", a pilgrimage, though pilgrims were usually forbidden from carrying arms.
Like pilgrims, each crusader swore a vow (a "votus"), to be fulfilled on successfully reaching Jerusalem, and they were granted a cloth cross ("crux") to be sewn into their clothes. This "taking of the cross", the "crux", eventually became associated with the entire journey; the word "crusade" (coming into English from the Medieval French "croisade" and Spanish "cruzada") developed from this.
Crusades in popular culture.
"Kingdom of Heaven" (2005) - film directed by Ridley Scott—a fictionalized account of Balian of Ibelin, a nobleman in the 13th‑century Kingdom of Jerusalem

Ukraine
Ukraine ( ; , transliterated: , ) is a country in Eastern Europe. Ukraine borders the Russian Federation to the east and northeast, Belarus to the northwest, Poland, Slovakia and Hungary to the west, Romania and Moldova to the southwest, and the Black Sea and Sea of Azov to the south and southeast, respectively. It has an area of 603,628 km², making it the second largest contiguous country on the European continent, after the Russian Federation.
According to a popular and well established theory, the medieval state of Kievan Rus was established by the Varangians in the 9th century as the first historically recorded East Slavic state which emerged as a powerful nation in the Middle Ages until it disintegrated in the 12th century. By the middle of the 14th century, Ukrainian territories were under the rule of three external powers—the Golden Horde, the Grand Duchy of Lithuania, and the Kingdom of Poland. After the Great Northern War (1700–1721) Ukraine was divided between a number of regional powers and, by the 19th century, the largest part of Ukraine was integrated into the Russian Empire with the rest under Austro-Hungarian control. A chaotic period of incessant warfare ensued, with several internationally recognized attempts at independence from 1917 to 1921, following World War I and the Russian Civil War. Ukraine emerged from its own civil war, and on December 30, 1922 Ukrainian Soviet Socialist Republic became one of the founding republics of the Soviet Union. The Ukrainian SSR's territory was enlarged westward during the civil war shortly before, and after World War II, and further south in 1954 with the Crimea transfer. In 1945, the Ukrainian SSR became one of the founding members of the United Nations.
Ukraine became independent again when the Soviet Union dissolved in 1991. This dissolution started a period of transition to a market economy, in which Ukraine was stricken with an eight-year recession. Since then, however, the economy has experienced a high increase in GDP growth. Ukraine was caught up in the worldwide economic crisis in 2008 and the economy plunged. GDP fell 20% from spring 2008 to spring 2009, then leveled off as analysts compared the magnitude of the downturn to the worst years of economic depression during the early 1990s. However, the country remains a globally important market and, as of 2011, is the world's third largest grain exporter.
Ukraine is a unitary state composed of 24 oblasts (provinces), one autonomous republic (Crimea), and two cities with special status: Kiev, its capital and largest city, and Sevastopol, which houses the Russian Black Sea Fleet under a leasing agreement. Ukraine is a republic under a semi-presidential system with separate legislative, executive, and judicial branches. Since the dissolution of the Soviet Union, Ukraine continues to maintain the second largest military in Europe, after that of Russia. The country is home to 46 million people, 77.8 percent of whom are ethnic Ukrainians, with sizable minorities of Russians (17%), Belarusians and Romanians. Ukrainian is the official language of Ukraine. Russian is also widely spoken. The dominant religion in the country is Eastern Orthodox Christianity, which has heavily influenced Ukrainian architecture, literature and music.
Etymology.
The traditional view (mostly influenced by Russian and Polish historiography) on the etymology of Ukraine is that it came from the old Slavic term "ukraina" which meant "border region" or "frontier" and thus corresponded to the Western term march. The term can be often found in Eastern Slavic chronicles from 1187 on, but for a long time it referred not solely to the border lands in present-day Ukraine. and the imperial Russian terminology).
Many contemporary Ukrainian historians translate the term "u-kraine" as "in-land", "home-land" or "our-country". This translation is in accordance with the original Ukrainian language meaning of preposition "у-" (u-) and noun "країна" (krayina). The accompanying claim that it always had a strictly separate meaning to "borderland" (ukraina vs. okraina) is considered inconsistent with a number of historical sources, often of not Ukrainian origin, while the translation as "borderland" agrees well with the traditional Russian language meaning of "у-" (u-) and "краина" (kraina).
Though the form "the Ukraine" was once the more common term in English, this is now considered inappropriate; most sources have dropped the article in favour of simply "Ukraine".
History.
Early history.
Human settlement in Ukraine and its vicinity dates back to 32,000 BCE, with evidence of the Gravettian culture in the Crimean Mountains. By 4,500 BCE, the Neolithic Cucuteni-Trypillian Culture flourished in a wide area that included parts of modern Ukraine including Trypillia and the entire Dnieper-Dniester region. During the Iron Age, the land was inhabited by Cimmerians, Scythians, and Sarmatians. Between 700 BC and 200 BC it was part of the Scythian Kingdom, or Scythia.
Later, colonies of Ancient Greece, Ancient Rome, and the Byzantine Empire, such as Tyras, Olbia, and Hermonassa, were founded, beginning in the 6th century BC, on the northeastern shore of the Black Sea, and thrived well into the 6th century AD. The Goths stayed in the area but came under the sway of the Huns from the 370s AD. In the 7th century AD, the territory of eastern Ukraine was the center of Old Great Bulgaria. At the end of the century, the majority of Bulgar tribes migrated in different directions, and the Khazars took over much of the land.
Golden Age of Kiev.
Kievan Rus' was founded by the Rus' people, Varangians who first settled around Ladoga and Novgorod, then gradually moved southward eventually reaching Kiev about 880. Kievan Rus' included the western part of modern Ukraine, Belarus, with larger part of it situated on the territory of modern Russia. According to the "Primary Chronicle" the Rus' elite initially consisted of Varangians from Scandinavia.
During the 10th and 11th centuries, it became the largest and most powerful state in Europe. In the following centuries, it laid the foundation for the national identity of Ukrainians and Russians. Kiev, the capital of modern Ukraine, became the most important city of the Rus'.
The Varangians later assimilated into the local Slavic population and became part of the Rus' first dynasty, the Rurik Dynasty. Kievan Rus' was composed of several principalities ruled by the interrelated Rurikid Princes. The seat of Kiev, the most prestigious and influential of all principalities, became the subject of many rivalries among Rurikids as the most valuable prize in their quest for power.
The Golden Age of Kievan Rus' began with the reign of Vladimir the Great (980–1015), who turned Rus' toward Byzantine Christianity. During the reign of his son, Yaroslav the Wise (1019–1054), Kievan Rus' reached the zenith of its cultural development and military power. This was followed by the state's increasing fragmentation as the relative importance of regional powers rose again. After a final resurgence under the rule of Vladimir Monomakh (1113–1125) and his son Mstislav (1125–1132), Kievan Rus' finally disintegrated into separate principalities following Mstislav's death.
In the 11th and 12th centuries, constant incursions by nomadic Turkic tribes, such as the Pechenegs and the Kipchaks, caused a massive migration of Slavic populations to the safer, heavily forested regions of the north. The 13th century Mongol invasion devastated Kievan Rus'. Kiev was totally destroyed in 1240. On today's Ukrainian territory, the state of Kievan Rus' was succeeded by the principalities of Halych and Volodymyr-Volynskyi, which were merged into the state of Galicia-Volhynia.
Foreign domination.
In the mid-14th century, Casimir III of Poland gained control of Galicia-Volhynia, while the heartland of Rus', including Kiev, became the territory of the Gediminas, of the Grand Duchy of Lithuania, after the Battle on the Irpen' River. Following the 1386 Union of Krewo, a dynastic union between Poland and Lithuania, much of what became northern Ukraine was ruled by the increasingly Slavicised local Lithuanian nobles as part of the Grand Duchy of Lithuania.
By 1569, the Union of Lublin formed the Polish–Lithuanian Commonwealth, and a significant part of Ukrainian territory was moved from Lithuanian rule to the Crown of the Kingdom of Poland, thus becoming Polish territory. Under the cultural and political pressure of Polonisation, many upper-class people of Polish Ruthenia (another term for the land of Rus) converted to Catholicism and became indistinguishable from the Polish nobility. Thus, the commoners, deprived of their native protectors among Rus nobility, turned for protection to the Cossacks, who remained fiercely Orthodox. The Cossacks tended to turn to violence against those they perceived as enemies, particularly the Polish state and its representatives.
In the mid-17th century, a Cossack military quasi-state, the Zaporozhian Host, was established by the Dnieper Cossacks and the Ruthenian peasants fleeing Polish serfdom. Poland had little real control of this land, yet they found the Cossacks to be a useful fighting force against the Turks and Tatars, and at times the two allied in military campaigns. However, the continued enserfment of peasantry by the Polish nobility, emphasized by the Commonwealth's fierce exploitation of the workforce, and most importantly, the suppression of the Orthodox Church pushed the allegiances of Cossacks away from Poland.
The Cossacks aspired to have representation in Polish Sejm, recognition of Orthodox traditions and the gradual expansion of the Cossack Registry. These were all vehemently rejected by the Polish nobility, who had power in the Sejm. The Cossacks eventually turned for protection to Orthodox Russia, a decision which would later lead towards the downfall of the Polish–Lithuanian state, and the preservation of the Orthodox Church and in Ukraine.
In 1648, Bohdan Khmelnytsky led the largest of the Cossack uprisings against the Commonwealth and the Polish king John II Casimir. Left-bank Ukraine was eventually integrated into Muscovite Russia as Rada faced the alternatives of subjection to Poland, allegiance to Turkey, or allegiance to Muscovy and chose the latter as the Cossack Hetmanate as recorded in the 1654 Treaty of Pereyaslav. There followed the Russo-Polish War which ended in 1667. After the partitions of Poland at the end of the 18th century by Prussia, Habsburg Austria, and Russia, Western Ukrainian Galicia was taken over by Austria.
The Crimean Khanate was one of the strongest powers in Eastern Europe until the 18th century; at one point it even succeeded, under the Crimean khan Devlet I Giray, to devastate Moscow. The Russian population of the borderlands suffered annual Tatar invasions and tens of thousands of soldiers were required to protect the southern boundaries. From the beginning of the 16th century until the end of 17th century the Crimean Tatar raider bands made almost annual forays into agricultural Slavic
lands searching for captives to sell as slaves. According to Orest Subtelny, "from 1450 to 1586, eighty-six Tatar raids were recorded, and from 1600 to 1647, seventy." In 1688, Tatars captured a record number of 60,000 Ukrainians. This was a heavy burden for the state, and slowed its social and economic development. Since Crimean Tatars did not permit settlement of Russians to southern regions where the soil is better and the season is long enough, Muscovy had to depend on poorer regions and labour-intensive agriculture. Poland-Lithuania, Moldavia and Wallachia were also subjected to extensive slave raiding. The Crimean Khanate was conquered by the Russian Empire in 1778, bringing an end to what remained of Mongol and Tatar rule in Europe.
The Ruin.
In 1657–1686 came "The Ruin," a devastating 30-year war amongst Russia, Poland, Turks and Cossacks for control of Ukraine, which occurred at about the same time as the Deluge of Poland. For three years, Khmelnytsky's armies controlled present-day western and central Ukraine, but, deserted by his Tatar allies, he suffered a crushing defeat at Berestechko, and turned to the Russian tsar for help.
In 1654, Khmelnytsky signed the Treaty of Pereiaslav, forming a military and political alliance with Russia that acknowledged loyalty to the Czar. The wars escalated in intensity with hundreds of thousands of deaths. Defeat came in 1686 as the "Eternal Peace" between Russia and Poland gave Kiev and the Cossack lands east of the Dnieper over to Russian rule and the Ukrainian lands west of the Dnieper to Poland.
In 1709 Cossack Hetman Ivan Mazepa (1687–1709) sided with Sweden against Russia in the Great Northern War (1700–1721). Mazepa, a member of the Cossack nobility, received an excellent education abroad and proved to be a brilliant political and military leader enjoying good relations with the Romanov dynasty. After Peter the Great became czar, Mazepa as hetman gave him more than twenty years of loyal military and diplomatic service and was well rewarded.
Eventually Peter recognized that in order to consolidate and modernize Russia's political and economic power it was necessary to do away with the hetmanate and Ukrainian and Cossack aspirations to autonomy. Mazepa accepted Polish invitations to join the Poles and Swedes against Russia. The move was disastrous for the hetmanate, Ukrainian autonomy, and Mazepa. He died in exile after fleeing from the Battle of Poltava (1709), where the Swedes and their Cossack allies suffered a catastrophic defeat at the hands of Peter's Russian forces.
The hetmanate was abolished in 1764; the Zaporizhska Sich abolished in 1775, as Russia centralized control over its lands. As part of the partitioning of Poland in 1772, 1793, and 1795, the Ukrainian lands west of the Dnieper were divided between Russia and Austria. From 1737 to 1834, expansion into the northern Black Sea littoral and the eastern Danube valley was a cornerstone of Russian foreign policy.
Lithuanians and Poles controlled vast estates in Ukraine, and were a law unto themselves. Judicial rulings from Cracow were routinely flouted, while peasants were heavily taxed and practically tied to the land as serfs. Occasionally the landowners battled each other using armies of Ukrainian peasants. The Poles and Lithuanians were Roman Catholics and tried with some success to convert the Orthodox lesser nobility. In 1596 they set up the "Greek-Catholic" or Uniate Church, under the authority of the Pope but using Eastern rituals; it dominates western Ukraine to this day. Tensions between the Uniates and the Orthodox were never resolved, and the religious differentiation left the Ukrainian Orthodox peasants leaderless, as they were reluctant to follow the Ukrainian nobles.
Cossacks led an uprising, called Koliivshchyna, starting in the Ukrainian borderlands of the Polish–Lithuanian Commonwealth in 1768. Ethnicity as one root cause of this revolt, which included Ukrainian violence that killed tens of thousands of Poles and Jews. Religious warfare also broke out between Ukrainian groups. Increasing conflict between Uniate and Orthodox parishes along the newly reinforced Polish-Russian border on the Dnepr River in the time of Catherine II set the stage for the uprising. As Uniate religious practices had become more Latinized, Orthodoxy in this region drew even closer into dependence on the Russian Orthodox Church. Confessional tensions also reflected opposing Polish and Russian political allegiances.
After the Russians annexed the Crimean Khanate in 1783, the region was settled by migrants from other parts of Ukraine. Despite the promises of Ukrainian autonomy given by the Treaty of Pereyaslav, the Ukrainian elite and the Cossacks never received the freedoms and the autonomy they were expecting from Imperial Russia. However, within the Empire, Ukrainians rose to the highest Russian state and church offices. At a later period, tsarists established a policy of Russification of Ukrainian lands, suppressing the use of the Ukrainian language in print, and in public.
19th century, World War I and revolution.
In the 19th century, Ukraine was a rural area largely ignored by Russia and Austria. With growing urbanization and modernization, and a cultural trend toward romantic nationalism, a Ukrainian intelligentsia committed to national rebirth and social justice emerged. The serf-turned-national-poet Taras Shevchenko (1814–1861) and the political theorist Mykhailo Drahomanov (1841–1895) led the growing nationalist movement.
After Ukraine and Crimea became aligned with the Russian Empire Russo-Turkish War (1768–1774), significant German immigration occurred after it was encouraged by Catherine the Great and her immediate successors. Immigration was encouraged into Ukraine and especially the Crimea by Catherine in her proclamation of open migration to the Russian Empire. Immigration was encouraged for Germans and other Europeans to thin the previously dominant Turk population and encourage more complete use of farmland.
Beginning in the 19th century, there was a continuous migration from Ukraine to settle the distant areas of the Russian Empire. According to the 1897 census, there were 223,000 ethnic Ukrainians in Siberia and 102,000 in Central Asia. Between 1896 and 1906, after the construction of the trans-Siberian railway, a total of 1.6 million Ukrainians migrated eastward.
Nationalist and socialist parties developed in the late 19th century. Austrian Galicia, which enjoyed substantial political freedom under the relatively lenient rule of the Habsburgs, became the center of the nationalist movement.
Ukrainians entered World War I on the side of both the Central Powers, under Austria, and the Triple Entente, under Russia. 3.5 million Ukrainians fought with the Imperial Russian Army, while 250,000 fought for the Austro-Hungarian Army. During the war, Austro-Hungarian authorities established the Ukrainian Legion to fight against the Russian Empire. This legion was the foundation of the Ukrainian Galician Army that fought against the Bolsheviks and Poles in the post World War I period (1919–23). Those suspected of Russophile sentiments in Austria were treated harshly. Up to 5,000 supporters of the Russian Empire from Galicia were detained and placed in Austrian internment camps in Talerhof, Styria, and in a fortress at Terezín (now in the Czech Republic).
When World War I ended, several empires collapsed; among them were the Russian and Austrian empires. The Russian Revolution of 1917 ensued, and a Ukrainian national movement for self-determination reemerged, with heavy Communist/Socialist influence. During 1917–20, several separate Ukrainian states briefly emerged: the Ukrainian People's Republic, the Hetmanate, the Directorate and the pro-Bolshevik Ukrainian Soviet Socialist Republic (or Soviet Ukraine) successively established territories in the former Russian Empire; while the West Ukrainian People's Republic and the Hutsul Republic emerged briefly in the former Austro-Hungarian territory. This led to civil war, and an anarchist movement called the Black Army led by Nestor Makhno developed in Southern Ukraine during that war.
However, Poland defeated Western Ukraine in the Polish-Ukrainian War, but failed against the Bolsheviks in an offensive against Kiev. According to the Peace of Riga concluded between the Soviets and Poland, western Ukraine was officially incorporated into Poland, who in turn recognised the Ukrainian Soviet Socialist Republic in March 1919. Ukraine became a founding member of the Union of Soviet Socialist Republics or the Soviet Union in December 1922.
Inter-war Polish Ukraine.
The war in Ukraine continued for another two years; by 1921, however, most of Ukraine had been taken over by the Soviet Union, while Galicia and Volhynia were incorporated into independent Poland.
A powerful underground Ukrainian nationalist movement rose in Poland in the 1920s and 1930s, led by the Ukrainian Military Organization and the Organization of Ukrainian Nationalists (OUN). The movement attracted a militant following among students and harassed the Polish authorities. Legal Ukrainian parties, the Ukrainian Catholic Church, an active press, and a business sector also flourished in Poland. Economic conditions improved in the 1920s, but the region suffered from the Great Depression in the 1930s.
Inter-war Soviet Ukraine.
The civil war that eventually brought the Soviet government to power devastated Ukraine. It left over 1.5 million people dead and hundreds of thousands homeless. In addition, Soviet Ukraine had to face the famine of 1921. Seeing an exhausted Ukraine, the Soviet government remained very flexible during the 1920s. Thus, under the aegis of the Ukrainization policy pursued by the national Communist leadership of Mykola Skrypnyk, Soviet leadership encouraged a national renaissance in literature and the arts. The Ukrainian culture and language enjoyed a revival, as Ukrainisation became a local implementation of the Soviet-wide policy of Korenisation (literally "indigenisation") policy. The Bolsheviks were also committed to introducing universal health care, education and social-security benefits, as well as the right to work and housing. Women's rights were greatly increased through new laws designed to wipe away centuries-old inequalities. Most of these policies were sharply reversed by the early 1930s after Joseph Stalin gradually consolidated power to become the "de facto" communist party leader.
The communists gave a privileged position to manual labor, the largest class in the cities, where Russians dominated. The typical worker was more attached to class identity than to ethnicity. Although there were incidents of ethnic friction among workers (in addition to Ukrainians and Russians there were significant numbers of Poles, Germans, Jews, and others in the Ukrainian workforce), industrial laborers had already adopted Russian culture and language to a significant extent. Workers whose ethnicity was Ukrainian were not attracted to campaigns of Ukrainianization or de-Russification in meaningful numbers, but remained loyal members of the Soviet working class. There was no significant antagonism between workers identifying themselves as Ukrainian or Russian.
Starting from the late 1920s, Ukraine was involved in the Soviet industrialisation and the republic's industrial output quadrupled during the 1930s.
The industrialisation had a heavy cost for the peasantry, demographically a backbone of the Ukrainian nation. To satisfy the state's need for increased food supplies and to finance industrialisation, Stalin instituted a program of collectivisation of agriculture as the state combined the peasants' lands and animals into collective farms and enforced the policies by the regular troops and secret police. Those who resisted were arrested and deported and the increased production quotas were placed on the peasantry. The collectivisation had a devastating effect on agricultural productivity. As the members of the collective farms were not allowed to receive any grain until sometimes unrealistic quotas were met, starvation in the Soviet Union became more common. In 1932–33, millions starved to death in a famine known as Holodomor or "Great Famine". Scholars are divided as to whether this famine fits the definition of genocide, but the Ukrainian parliament and other countries recognise it as such.
The famine claimed up to 10 million of Ukrainian lives as peasants' food stocks were forcibly removed by the Soviet government by the NKVD secret police. Some explanations for the causes for the excess deaths in rural areas of Ukraine and Kazakhstan during 1931–34 has been given by dividing the causes into three groups: objective non-policy-related factors, like the drought of 1931 and poor weather in 1932; inadvertent result of policies with other objectives, like rapid industrialization, socialization of livestock, and neglected crop rotation patterns; and deaths caused intentionally by a starvation policy. The Communist leadership perceived famine not as a humanitarian catastrophe but as a means of class struggle and used starvation as a punishment tool to force peasants into collective farms.
It was largely the same groups of individuals who were responsible for the mass killing operations during the civil war, collectivisation, and the Great Terror. These groups were associated with Efim Georgievich Evdokimov (1891–1939) and operated in Ukraine during the civil war, in the North Caucasus in the 1920s, and in the Secret Operational Division within General State Political Administration (OGPU) in 1929–31. Evdokimov transferred into Communist Party administration in 1934, when he became Party secretary for North Caucasus Krai. But he appears to have continued advising Joseph Stalin and Nikolai Yezhov on security matters, and the latter relied on Evdokimov's former colleagues to carry out the mass killing operations that are known as the Great Terror in 1937–38.
With Joseph Stalin's change of course in the late 1920s, however, Moscow's toleration of Ukrainian national identity came to an end. Systematic state terror of the 1930s destroyed Ukraine's writers, artists, and intellectuals; the Communist Party of Ukraine was purged of its "nationalist deviationists". Two waves of Stalinist political repression and persecution in the Soviet Union (1929–34 and 1936–38) resulted in the killing of some 681,692 people; this included four-fifths of the Ukrainian cultural elite and three-quarters of all the Red Army's higher-ranking officers.
World War II.
Following the Invasion of Poland in September 1939, German and Soviet troops divided the territory of Poland. Thus, Eastern Galicia and Volhynia with their Ukrainian population became reunited with the rest of Ukraine. The unification that Ukraine achieved for the first time in its history was a decisive event in the history of the nation.
In 1940, Romania ceded Bessarabia and northern Bukovina in response to Soviet demands. The Ukrainian SSR incorporated northern and southern districts of Bessarabia, northern Bukovina, and the Hertsa region. But it ceded the western part of the Moldavian Autonomous Soviet Socialist Republic to the newly created Moldavian Soviet Socialist Republic. All these territorial gains were internationally recognised by the Paris peace treaties of 1947.
German armies invaded the Soviet Union on June 22, 1941, thereby initiating four straight years of incessant total war. The Axis allies initially advanced against desperate but unsuccessful efforts of the Red Army. In the encirclement battle of Kiev, the city was acclaimed as a "Hero City", because the resistance by the Red Army and by the local population was fierce. More than 600,000 Soviet soldiers (or one-quarter of the Western Front) were killed or taken captive there.
Although the wide majority of Ukrainians fought alongside the Red Army and Soviet resistance, some elements of the Ukrainian nationalist underground created an anti-Soviet nationalist formation in Galicia, the Ukrainian Insurgent Army (1942) that at times engaged the Nazi forces and continued to fight the USSR in the years after the war. Using guerilla war tactics, the insurgents targeted for assassination and terror those who they perceived as representing, or cooperating at any level with, the Soviet state.
At the same time another nationalist movement fought alongside the Nazis. In total, the number of ethnic Ukrainians that fought in the ranks of the Soviet Army is estimated from 4.5 million to 7 million. The pro-Soviet partisan guerilla resistance in Ukraine is estimated to number at 47,800 from the start of occupation to 500,000 at its peak in 1944; with about 50 percent of them being ethnic Ukrainians. Generally, the Ukrainian Insurgent Army's figures are very undependable, ranging anywhere from 15,000 to as much as 100,000 fighters.
Initially, the Germans were even hailed as liberators by some western Ukrainians, who had only joined the Soviet Union in 1939. However, brutal German rule in the occupied territories eventually turned its supporters against the occupation. Nazi administrators of conquered Soviet territories made little attempt to exploit the population of Ukrainian territories' dissatisfaction with Stalinist political and economic policies. Instead, the Nazis preserved the collective-farm system, systematically carried out genocidal policies against Jews, deported others to work in Germany, and began a systematic depopulation of Ukraine (along with Poland) to prepare it for German colonisation, which included a food blockade on Kiev.
The vast majority of the fighting in World War II took place on the Eastern Front. It has been estimated that 93 percent of all German casualties took place on the Eastern Front. The total losses inflicted upon the Ukrainian population during the war are estimated between five and eight million, including over half a million Jews killed by the Einsatzgruppen, sometimes with the help of local collaborators. Of the estimated 8.7 million Soviet troops who fell in battle against the Nazis, 1.4 million were ethnic Ukrainians. So to this day, Victory Day is celebrated as one of ten Ukrainian national holidays.
Post–World War II.
The republic was heavily damaged by the war, and it required significant efforts to recover. More than 700 cities and towns and 28,000 villages were destroyed. The situation was worsened by a famine in 1946–47, which was caused by a drought and the wartime destruction of infrastructure. The death toll of this famine varies, with even the lowest estimate in the tens of thousands.
In 1945, the Ukrainian SSR became one of the founding members of the United Nations organization. The first Soviet computer, MESM, was built at the Kiev Institute of Electrotechnology and became operational in 1950.
Postwar ethnic cleansing occurred in the newly expanded Soviet Union. As of January 1, 1953, Ukrainians were second only to Russians among adult "special deportees", comprising 20% of the total. In addition, over 450,000 ethnic Germans from Ukraine and more than 200,000 Crimean Tatars were victims of forced deportations.
Following the death of Stalin in 1953, Nikita Khrushchev became the new leader of the USSR. Having served as First Secretary of the Communist Party of Ukrainian SSR in 1938–49, Khrushchev was intimately familiar with the republic; after taking power union-wide, he began to emphasize the friendship between the Ukrainian and Russian nations. In 1954, the 300th anniversary of the Treaty of Pereyaslav was widely celebrated, and in particular, Crimea was transferred from the Russian SFSR to the Ukrainian SSR.
By 1950, the republic had fully surpassed pre-war levels of industry and production. During the 1946–1950 five year plan, nearly 20% of the Soviet budget was invested in Soviet Ukraine, a 5% increase from prewar plans. As a result, the Ukrainian workforce rose 33.2% from 1940 to 1955 while industrial output grew 2.2 times in that same period. 
Soviet Ukraine soon became a European leader in industrial production, and an important center of the Soviet arms industry and high-tech research. Such an important role resulted in a major influence of the local elite. Many members of the Soviet leadership came from Ukraine, most notably Leonid Brezhnev, who would later oust Khrushchev and become the Soviet leader from 1964 to 1982, as well as many prominent Soviet sports players, scientists, and artists.
On April 26, 1986, a reactor in the Chernobyl Nuclear Power Plant exploded, resulting in the Chernobyl disaster, the worst nuclear reactor accident in history. This was the only accident to receive the highest possible rating of 7 by the International Nuclear Event Scale indicating a "major accident", until the Fukushima Daiichi nuclear disaster in March 2011. At the time of the accident 7 million people lived in the contaminated territories, including 2.2 million in Ukraine. After the accident, the new city of Slavutych was built outside the exclusion zone to house and support the employees of the plant, which was decommissioned in 2000. A report prepared by the International Atomic Energy Agency and World Health Organization attributed 56 direct deaths to the accident and estimated that there may have been 4,000 extra cancer deaths.
Independence.
On July 16, 1990, the new parliament adopted the Declaration of State Sovereignty of Ukraine. The declaration established the principles of the self-determination of the Ukrainian nation, its democracy, political and economic independence, and the priority of Ukrainian law on the Ukrainian territory over Soviet law. A month earlier, a similar declaration was adopted by the parliament of the Russian SFSR. This started a period of confrontation between the central Soviet, and new republican authorities. In August 1991, a conservative faction among the Communist leaders of the Soviet Union attempted a coup to remove Mikhail Gorbachev and to restore the Communist party's power. After the attempt failed, on August 24, 1991 the Ukrainian parliament adopted the Act of Independence in which the parliament declared Ukraine as an independent democratic state.
A referendum and the first presidential elections took place on December 1, 1991. That day, more than 90 percent of the Ukrainian people expressed their support for the Act of Independence, and they elected the chairman of the parliament, Leonid Kravchuk to serve as the first President of the country. At the meeting in Brest, Belarus on December 8, followed by Alma Ata meeting on December 21, the leaders of Belarus, Russia, and Ukraine, formally dissolved the Soviet Union and formed the Commonwealth of Independent States (CIS).
Although the idea of an independent Ukrainian nation had previously not existed in the 20th century in the minds of international policy makers, Ukraine was initially viewed as a republic with favorable economic conditions in comparison to the other regions of the Soviet Union. However, the country experienced deeper economic slowdown than some of the other former Soviet Republics. During the recession, Ukraine lost 60 percent of its GDP from 1991 to 1999, and suffered five-digit inflation rates. Dissatisfied with the economic conditions, as well as the amounts of crime and corruption in Ukraine, Ukrainians protested and organised strikes.
The Ukrainian economy stabilized by the end of the 1990s. A new currency, the hryvnia, was introduced in 1996. Since 2000, the country has enjoyed steady real economic growth averaging about seven percent annually. A new Constitution of Ukraine was adopted under second President Leonid Kuchma in 1996, which turned Ukraine into a semi-presidential republic and established a stable political system. Kuchma was, however, criticized by opponents for corruption, electoral fraud, discouraging free speech and concentrating too much power in his office. He also repeatedly transferred public property into the hands of loyal oligarchs.
In 2004, Viktor Yanukovych, then Prime Minister, was declared the winner of the presidential elections, which had been largely rigged, as the Supreme Court of Ukraine later ruled. The results caused a public outcry in support of the opposition candidate, Viktor Yushchenko, who challenged the outcome of the elections. This resulted in the peaceful Orange Revolution, bringing Viktor Yushchenko and Yulia Tymoshenko to power, while casting Viktor Yanukovych in opposition. Yanukovych returned to a position of power in 2006, when he became Prime Minister in the Alliance of National Unity, until snap elections in September 2007 made Tymoshenko Prime Minister again. Yanukovych was elected President in 2010.
Conflicts with Russia over the price of natural gas briefly stopped all gas supplies to Ukraine in 2006 and again in 2009, leading to gas shortages in several other European countries.
Historical maps of Ukraine.
The Ukrainian state has occupied a number of territories since its initial foundation. Most of these territories have been located within Eastern Europe, however, as depicted in the maps in the gallery below, has also at times extended well into Eurasia and South-Eastern Europe.
At times there has also been a distinct lack of a Ukrainian state, as its territories were on a number of occasions, annexed by its more powerful neighbours.
Geography.
At and with a coastline of , Ukraine is the world's 44th-largest country (after the Central African Republic, before Madagascar). It is the largest wholly European country and the second largest country in Europe (after the European part of Russia, before metropolitan France). It lies between latitudes 44° and 53° N, and longitudes 22° and 41° E.
The Ukrainian landscape consists mostly of fertile plains (or steppes) and plateaus, crossed by rivers such as the Dnieper (), Seversky Donets, Dniester and the Southern Buh as they flow south into the Black Sea and the smaller Sea of Azov. To the southwest, the delta of the Danube forms the border with Romania. Its various regions have diverse geographic features ranging from the highlands to the lowlands. The country's only mountains are the Carpathian Mountains in the west, of which the highest is the Hora Hoverla at , and the Crimean Mountains on the Crimean peninsula, in the extreme south along the coast. However Ukraine also has a number of highland regions such as the Volyn-Podillia Upland (in the west) and the Near-Dnipro Upland (on the right bank of Dnieper); to the east there are the south-western spurs of the Central Russian Uplands over which runs the border with Russia. Near the Sea of Azov can be found the Donets Ridge and the Near Azov Upland. The snow melt from the mountains feeds the rivers, and natural changes in altitude form a sudden drop in elevation and create many opportunities to form waterfalls.
Significant natural resources in Ukraine include iron ore, coal, manganese, natural gas, oil, salt, sulfur, graphite, titanium, magnesium, kaolin, nickel, mercury, timber and an abundance of arable land. Despite this, the country faces a number of major environmental issues such as inadequate supplies of potable water; air and water pollution and deforestation, as well as radiation contamination in the north-east from the 1986 accident at the Chernobyl Nuclear Power Plant. Recycling toxic household waste is still in its infancy in Ukraine.
Regionalism.
There are not only clear regional differences on questions of identity but historical cleavages remain evident at the level of individual social identification. Attitudes toward the most important political issue, relations with Russia, differed strongly between Lviv, identifying more with Ukrainian nationalism and the Ukrainian Greek Catholic Church, and Donetsk, predominantly Russian orientated and favorable to the Soviet era, while in central and southern Ukraine, as well as Kiev, such divisions were less important and there was less antipathy toward people from other regions (a poll by the Research & Branding Group held March 2010 showed that the attitude of the citizens of Donetsk to the citizens of Lviv was 79% positive and that the attitude of the citizens of Lviv to the citizens of Donetsk was 88% positive). However, all were united by an overarching Ukrainian identity based on shared economic difficulties, showing that other attitudes are determined more by culture and politics than by demographic differences. Surveys of regional identities in Ukraine have shown that the feeling of belonging to a "Soviet identity" is strongest in the Donbas (about 40%) and the Crimea (about 30%).
Biodiversity.
Ukraine is home to a very wide range of animals, fungi, micro-organisms and plants.
Animals.
Ukraine is divided into two main zoological areas. One of these areas, in the west of the country, is made up of the borderlands of Europe, where there are species typical of mixed forests, the other is located in eastern Ukraine, where steppe-dwelling species thrive. In the forested areas of the country it is not uncommon to find lynxes, wolves, wild boar and martens, as well as many other similar species; this is especially true of the Carpathian mountains, where a large number of predatory mammals make their home, as well as a contingent of brown bears. Around Ukraine's lakes and rivers beavers, otters and mink make their home, whilst within, carp, bream and catfish are the most commonly found species of fish. In the central and eastern parts of the country, rodents such as hamsters and gophers are found in large numbers.
Fungi.
More than 6600 species of fungi (including lichen-forming species) have been recorded from Ukraine., but this number is far from complete. The true total number of fungal species occurring in Ukraine, including species not yet recorded, is likely to be far higher, given the generally accepted estimate that only about 7% of all fungi worldwide have so far been discovered. Although the amount of available information is still very small, a first effort has been made to estimate the number of fungal species endemic to Ukraine, and 2217 such species have been tentatively identified.
Climate.
Ukraine has a mostly temperate continental climate, although the southern Crimean coast has a humid subtropical climate. Precipitation is disproportionately distributed; it is highest in the west and north and lowest in the east and southeast. Western Ukraine receives around of precipitation annually, while Crimea receives around . Winters vary from cool along the Black Sea to cold farther inland. Average annual temperatures range from – in the north, to – in the south.
Politics.
Ukraine is a republic under a mixed semi-parliamentary semi-presidential system with separate legislative, executive, and judicial branches.
The Constitution of Ukraine.
With the proclamation of its independence on August 24, 1991, and adoption of a constitution on June 28, 1996, Ukraine became a semi-presidential republic. However, in 2004, deputies introduced changes to the Constitution, which tipped the balance of power in favour parliament. From 2004 to 2010, the legitimacy of the 2004 Constitutional amendments had official sanction, both with the Constitutional Court of Ukraine, and most major political parties. Despite this, on September 30, 2010 the Constitutional Court ruled that the amendments were null and void, forcing a return to the terms of the 1996 Constitution and again making Ukraine's political system more presidential in character.
The ruling on the 2004 Constitutional amendments has become a major topic of political discourse. Much of the concern has been due to the fact that neither the Constitution of 1996 nor the Constitution of 2004 provides the ability to "undo the Constitution", as the decision of the Constitutional Court would have it, even though the 2004 constitution arguably has an exhaustive list of possible procedures for constitutional amendments (articles 154–159). In any case, the current Constitution can arguably be modified only by a vote in Parliament.
The President, Parliament and the Government of Ukraine.
The President is elected by popular vote for a five-year term and is the formal head of state.
Ukraine's legislative branch includes the 450-seat unicameral parliament, the Verkhovna Rada. The parliament is primarily responsible for the formation of the executive branch and the Cabinet of Ministers, which is headed by the Prime Minister. However, the President still retains the authority to nominate the Ministers of the Foreign Affairs and of Defence for parliamentary approval, as well as the power to appoint the Prosecutor General and the head of the Security Service.
Laws, acts of the parliament and the cabinet, presidential decrees, and acts of the Crimean parliament may be abrogated by the Constitutional Court, should they be found to violate the constitution. Other normative acts are subject to judicial review. The Supreme Court is the main body in the system of courts of general jurisdiction.
Local self-government is officially guaranteed. Local councils and city mayors are popularly elected and exercise control over local budgets. The heads of regional and district administrations are appointed by the President in accordance with the proposals of the Prime-Minister. This system virtually requires an agreement between the President and the Prime-Minister, and has in the past led to problems, such as when President Yushchenko used a legally controversial ways to evade the law by appointing no actual governors or the local leaders, but so called 'temporarily acting' officers, thus evading the need to seek a compromise with the Prime-Minister. This practice was very controversial and required review by the Constitutional Court.
Ukraine has a large number of political parties, many of which have tiny memberships and are unknown to the general public. Small parties often join in multi-party coalitions (electoral blocs) for the purpose of participating in parliamentary elections.
Courts and law enforcement.
The courts enjoy legal, financial and constitutional freedom guaranteed by measures adopted in Ukrainian law in 2002. Judges are largely well protected from dismissal (except in the instance of gross misconduct). Court justices are appointed by presidential decree for an initial period of five years, after which Ukraine's Supreme Council confirms their positions for life in an attempt to insulate them from politics. Although there are still problems with the performance of the system, it is considered to have been much improved since Ukraine's independence in 1991. The Supreme Court is regarded as being an independent and impartial body, and has on several occasions ruled against the Ukrainian government.
Prosecutors in Ukraine have greater powers than in most European countries, and according to the European Commission for Democracy through Law ‘the role and functions of the Prosecutor’s Office is not in accordance with Council of Europe standards". In addition to this, from 2005 until 2008 the criminal judicial system maintained a 99.5 percent conviction rate, equal to the conviction rate of the Soviet Union, with suspects often being incarcerated for long periods before trial. On March 24, 2010, President Yanukovych formed an expert group to make recommendations how to "clean up the current mess and adopt a law on court organization". One day after setting this commission Yanukovych stated "We can no longer disgrace our country with such a court system." Judicial and penal institutions play a fundamental role in protecting citizens and safeguarding the common good. The criminal judicial system and the prison system of Ukraine remain quite punitive. In contemporary Ukraine prison ministry of chaplains does not exist "de jure".
Since January 1, 2010 it is allowed to hold court proceedings in Russian on mutual consent of parties. Citizens who are unable to speak Ukrainian or Russian are allowed to use their native language or the services of a translator. Previously all court proceedings were required to be held in Ukrainian, which is the nation's only language with any truly official administrative status.
Law enforcement agencies in Ukraine are typically organised under the authority of the Ministry of Internal Affairs. They consist primarily of the national police force "(Мiлiцiя)" and various specialised units and agencies such as the State Border Guard and the Coast Guard services. In recent years the law enforcement agencies, particularly the police, have faced criticism for their heavy handling of the 2004 Orange Revolution, this criticism stems from the use by the Kuchma government's contemplated use of Berkut special operations units and internal troops in a plan to put an end to demonstrations on Kiev's Maidan Nezalezhnosti. The actions of the government saw many thousands of police officers mobilised and stationed throughout the capital, primarily to dissuade protesters from challenging the state's authority but also to provide a quick reaction force in case of need; most officers were armed and another 10,000 were held in reserve nearby. Bloodshed was only avoided when Lt. Gen. Sergei Popkov heeded his colleagues' calls to withdraw.
The Ministry of Internal Affairs is also responsible for the maintenance of the State Security Service; Ukraine's domestic intelligence agency, which has on occasion been accused of acting like a secret police force serving to protect the country's political elite from media criticism. On the other hand however, it is widely accepted that members of the service provided vital information about government plans to the leaders of the Orange Revolution in order to prevent the collapse of the movement.
Foreign relations.
In 1999–2001, Ukraine served as a non-permanent member of the UN Security Council. Historically, Soviet Ukraine joined the United Nations in 1945 as one of the original members following a Western compromise with the Soviet Union, which had asked for seats for all 15 of its union republics. Ukraine has consistently supported peaceful, negotiated settlements to disputes. It has participated in the quadripartite talks on the conflict in Moldova and promoted a peaceful resolution to conflict in the post-Soviet state of Georgia. Ukraine also has made a substantial contribution to UN peacekeeping operations since 1992.
Ukraine currently considers Euro-Atlantic integration its primary foreign policy objective, but in practice balances its relationship with the European Union and the United States with strong ties to Russia. The European Union's Partnership and Cooperation Agreement (PCA) with Ukraine went into force on March 1, 1998. The European Union (EU) has encouraged Ukraine to implement the PCA fully before discussions begin on an association agreement. The EU Common Strategy toward Ukraine, issued at the EU Summit in December 1999 in Helsinki, recognizes Ukraine's long-term aspirations but does not discuss association. On January 31, 1992, Ukraine joined the then-Conference on Security and Cooperation in Europe (now the Organization for Security and Cooperation in Europe—OSCE), and on March 10, 1992, it became a member of the North Atlantic Cooperation Council. Ukraine also has a close relationship with NATO and had previously declared interest in eventual membership, this however was removed from the government's foreign policy agenda, upon election of Viktor Yanukovych to the presidency, in 2010. It is the most active member of the Partnership for Peace (PfP). All major political parties in Ukraine support full eventual integration into the European Union. The Association Agreement with the EU was expected to be signed into effect by the end of 2011, but the process has been suspended as of 2012 due to recent political developments.
Ukraine maintains peaceful and constructive relations with all its neighbours; it has especially close ties with Russia and Poland, although relations with the former are complicated by energy dependence and payment arrears.
Administrative divisions.
The system of Ukrainian subdivisions reflects the country's status as a unitary state (as stated in the country's constitution) with unified legal and administrative regimes for each unit.
Ukraine is subdivided into twenty-four oblasts (provinces) and one autonomous republic (), Crimea. Additionally, the cities of Kiev, the capital, and Sevastopol, both have a special legal status. The 24 oblasts and Crimea are subdivided into 490 (districts), or second-level administrative units. The average area of a Ukrainian raion is ; the average population of a raion is 52,000 people.
Urban areas (cities) can either be subordinated to the state (as in the case of Kiev and Sevastopol), the oblast or administrations, depending on their population and socio-economic importance. Lower administrative units include urban-type settlements, which are similar to rural communities, but are more urbanized, including industrial enterprises, educational facilities, and transport connections, and villages.
Military.
After the dissolution of the Soviet Union, Ukraine inherited a 780,000-man military force on its territory, equipped with the third-largest nuclear weapons arsenal in the world. In May 1992, Ukraine signed the Strategic Arms Reduction Treaty (START) in which the country agreed to give up all nuclear weapons to Russia for disposal and to join the Nuclear Non-Proliferation Treaty as a non-nuclear weapon state. Ukraine ratified the treaty in 1994, and by 1996 the country became free of nuclear weapons.
Ukraine took consistent steps toward reduction of conventional weapons. It signed the Treaty on Conventional Armed Forces in Europe, which called for reduction of tanks, artillery, and armoured vehicles (army forces were reduced to 300,000). The country plans to convert the current conscript-based military into a professional volunteer military not later than in 2011.
Ukraine has been playing an increasingly larger role in peacekeeping operations. Ukrainian troops are deployed in Kosovo as part of the Ukrainian-Polish Battalion. A Ukrainian unit was deployed in Lebanon, as part of UN Interim Force enforcing the mandated ceasefire agreement. There was also a maintenance and training battalion deployed in Sierra Leone. In 2003–05, a Ukrainian unit was deployed as part of the Multinational force in Iraq under Polish command. The total Ukrainian military deployment around the world is 562 servicemen.
Military units of other states participate in multinational military exercises with Ukrainian forces in Ukraine regularly, including U.S. military forces.
Following independence, Ukraine declared itself a neutral state. The country has had a limited military partnership with Russia, other CIS countries and a partnership with NATO since 1994. In the 2000s, the government was leaning towards NATO, and a deeper cooperation with the alliance was set by the NATO-Ukraine Action Plan signed in 2002. It was later agreed that the question of joining NATO should be answered by a national referendum at some point in the future. Current President Viktor Yanukovych considers the current level of co-operation between Ukraine and NATO sufficient. Yanukovich is against Ukraine joining NATO. During the 2008 Bucharest summit NATO declared that Ukraine will become a member of NATO, whenever it wants and when it would correspond to the criteria for the accession.
Economy.
In Soviet times, the economy of Ukraine was the second largest in the Soviet Union, being an important industrial and agricultural component of the country’s planned economy. With the dissolution of the Soviet system, the country moved from a planned economy to a market economy. The transition process was difficult for the majority of the population which plunged into poverty. Ukraine’s economy contracted severely following the years after the Soviet dissolution. Day to day life for the average person living in Ukraine was a struggle. A significant number of citizens in rural Ukraine survived by growing their own food, often working two or more jobs and buying the basic necessities through the barter economy.
In 1991, the government liberalised most prices to combat widespread product shortages, and was successful in overcoming the problem. At the same time, the government continued to subsidise state-run industries and agriculture by uncovered monetary emission. The loose monetary policies of the early 1990s pushed inflation to hyperinflationary levels. For the year 1993, Ukraine holds the world record for inflation in one calendar year. Those living on fixed incomes suffered the most.
Prices stabilised only after the introduction of new currency, the hryvnia, in 1996.
The country was also slow in implementing structural reforms. Following independence, the government formed a legal framework for privatisation. However, widespread resistance to reforms within the government and from a significant part of the population soon stalled the reform efforts. A large number of state-owned enterprises were exempt from the privatisation process.
In the meantime, by 1999, the GDP had fallen to less than 40 percent of the 1991 level. It recovered considerably in the following years, but still doesn't reach historical maximum. In the early 2000s, the economy showed strong export-based growth of 5 to 10 percent, with industrial production growing more than 10 percent per year. Ukraine was hit by the economic crisis of 2008 and in November 2008, the IMF approved a stand-by loan of $16.5 billion for the country.
Ukraine’s 2010 GDP (PPP), as calculated by the CIA, is ranked 38th in the world and estimated at $305.2 billion. Its GDP per capita in 2010 according to the CIA was $6,700 (in PPP terms), ranked 107th in the world. Nominal GDP (in U.S. dollars, calculated at market exchange rate) was $136 billion, ranked 53rd in the world. By July 2008 the average nominal salary in Ukraine reached 1,930 hryvnias per month. Despite remaining lower than in neighbouring central European countries, the salary income growth in 2008 stood at 36.8 percent
According to the UNDP in 2003 4.9% of the Ukrainian population lived under 2 US dollar a day and 19.5% of the population lived below the national poverty line that same year.
Ukraine produces nearly all types of transportation vehicles and spacecraft. Antonov airplanes and KrAZ trucks are exported to many countries. The majority of Ukrainian exports are marketed to the European Union and CIS. Since independence, Ukraine has maintained its own space agency, the National Space Agency of Ukraine (NSAU). Ukraine became an active participant in scientific space exploration and remote sensing missions. Between 1991 and 2007, Ukraine has launched six self made satellites and 101 launch vehicles, and continues to design spacecraft.
The country imports most energy supplies, especially oil and natural gas, and to a large extent depends on Russia as its energy supplier. While 25 percent of the natural gas in Ukraine comes from internal sources, about 35 percent comes from Russia and the remaining 40 percent from Central Asia through transit routes that Russia controls. At the same time, 85 percent of the Russian gas is delivered to Western Europe through Ukraine.
The World Bank classifies Ukraine as a middle-income state. Significant issues include underdeveloped infrastructure and transportation, corruption and bureaucracy. In 2007 the Ukrainian stock market recorded the second highest growth in the world of 130 percent. According to the CIA, in 2006 the market capitalization of the Ukrainian stock market was $111.8 billion. Growing sectors of the Ukrainian economy include the information technology (IT) market, which topped all other Central and Eastern European countries in 2007, growing some 40 percent.
Corporations.
Ukraine has a very large heavy-industry base and is one of the largest refiners of metallurgical products in Eastern Europe. However, the country is also well known for its production of high-technological goods and transport products, such as Antonov aircraft and various private and commercial vehicles. The country’s largest and most competitive firms are components of the PFTS index which is traded on the PFTS Ukraine Stock Exchange.
Well known Ukrainian brands include, amongst others, Naftogaz Ukrainy, AvtoZAZ, PrivatBank, Roshen, Yuzhmash, Nemiroff, Motor Sich, Khortytsa, Kyivstar, and Aerosvit.
Ukraine is regarded as being a developing economy with high potential for future success, however such a development is thought to be likely only with new all-encompassing economic and legal reforms. Although Foreign Direct Investment in Ukraine has remained relatively strong ever since recession of the early 1990s, the country has had trouble maintaining stable economic growth. Issues relating to current corporate governance in Ukraine are primarily linked to the large scale monopolisation of traditional heavy industries by wealthy individuals such as Rinat Akhmetov, the enduring failure to broaden the nation’s economic base and a lack of effective legal protection for investors and their products. Despite all this, Ukraine’s economy is still expected to grow by around 3.5% in 2010.
Transportation.
Most of the Ukrainian road system has not been upgraded since the Soviet era, and is now outdated. The Ukrainian government has pledged to build some of motorways by 2012. In total, Ukrainian paved roads stretch for . The network of major routes, marked with the letter ‘M’ for ‘International’ "(Ukrainian: Міжнародний"), extends nationwide and connects all the major cities of Ukraine as well as providing cross-border routes to the country’s neighbours. Currently there are only two true motorway standard highways in Ukraine; a 175 km stretch of motorway from Kharkiv to Dnipropetrovsk, and a section of the M03 which extends from Kiev to Boryspil, where the city’s international airport is located.
Rail transport in Ukraine plays the role of connecting all major urban areas, port facilities and industrial centres with neighbouring countries. The heaviest concentration of railroad track is located in the Donbas region of Ukraine. Although the amount of freight transported by rail fell by 7.4 percent in 1995 in comparison with 1994, Ukraine is still one of the world’s highest rail users. The total amount of railroad track in Ukraine extends for , of which is electrified. Currently the state has a monopoly on the provision of passenger rail transport, and all trains, other than those with cooperation of other foreign companies on international routes, are operated by its company ‘Ukrzaliznytsia’.
The aviation section in Ukraine is developing very quickly, having recently established a visa-free program for EU nationals and citizens of a number of other Western nations, the nation’s aviation sector is handling a significantly increased number of travellers. Additionally, the granting of the Euro 2012 football tournament to Poland and Ukraine as joint hosts has prompted the government to invest huge amounts of money into transport infrastructure, and in particular airports.
Kiev Boryspil is the county's largest international airport; it has a total of three main passenger terminals and is the base for both of Ukraine's national airlines. Other large airports in the country include those in Kharkiv, Lviv and Donetsk - all of which have recently-constructed, modern terminals and aviation facilities, whilst those in Dnipropetrovsk and Odessa have plans for terminal upgrades in the near future. Ukraine has a number of airlines, the largest of which are the nation’s flag carriers, Aerosvit and UIA. Antonov Airlines, a subsidiary of the Antonov Aerospace Design Bureau is the only operator of the world’s largest fixed wing aircraft, the An-225.
Maritime transport is mainly riverine, with passenger services mainly provided on the Dnieper, Danube and Pripyat rivers, as well as a number of their tributaries. Most large cities have a river port and cater for the embarkation and disembarkation of passengers as well as the loading and unloading of freight and raw materials. International maritime travel is mainly provided through the Port of Odessa, from where ferries sail regularly to Istanbul, Varna and Haifa. The largest ferry company presently operating these routes is Ukrferry.
Energy.
Ukraine is one of Europe’s largest energy consumers; it consumes almost double the energy of Germany, per unit of GDP. A great share of energy supply in Ukraine comes from nuclear power, with the country receiving most of its nuclear fuel from Russia. The remaining oil and gas, is also imported from the former Soviet Union. Ukraine is heavily dependent on its nuclear power. The largest nuclear power plant in Europe, the Zaporizhzhia Nuclear Power Plant, is located in Ukraine.
In 2006, the government planned to build 11 new reactors by the year 2030, in effect, almost doubling the current amount of nuclear power capacity. Ukraine’s power sector is the twelfth-largest in the world in terms of installed capacity, with 54 gigawatts (GW). In 2007 47.4% of power came from coal and gas (approx 20% gas), 47.5% from nuclear (92.5 TWh) and 5% from hydro.
Currently the country has four active nuclear power stations, located in Kuznetsovsk, Enerhodar, Yuzhnoukrainsk and Netishyn. In addition to these active plants, a fifth reactor complex had been planned for the Crimea, but construction was suspended indefinitely in the wake of the Chernobyl disaster, a major nuclear incident which took place at the Chernobyl Atomic Energy Station, north of Kiev.
All of Ukraine’s RBMK reactors (the type involved in the Chernobyl disaster), were located at the Chernobyl Nuclear Power Plant. All of the reactors there have been shut down leaving only VVER reactors operating in the country, which are much safer than RBMK units. Three of these new-type reactors were built since 1991 in the independent Ukraine (with the first one in 1995), whilst the other sixteen were inherited from the Soviet Union.
The share of renewables within the total energy mix is still very small, but is growing fast. Total installed capacity of renewable energy installations more than doubled in 2011 and now stands at 397 MW. Indeed, 2011 was a breakthrough year for renewable energy development in Ukraine, especially for solar energy. First, Okhotnykovo Solar Park, one of the world’s largest, was put into operation in July. Then, six months later, Europe’s largest solar park was completed in Perovo, (Crimea). Ukrainian State Agency for Energy Efficiency and Conservation forecasts that combined installed capacity of wind and solar power plants in Ukraine could increase by another 600 MW in 2012. According to Macquarie Research, by 2016 Ukraine will construct and commission new PV facilities with a total capacity of 1.8 GW, which is almost equivalent to the capacity of two nuclear reactors.
The Economic Bank for Reconstruction and Development estimates that Ukraine has great renewable energy potential: the technical potential for wind energy is estimated at 40 TWh/year, small hydro at 8.3 TWh/year, biomass at 120 TWh/year, and solar energy at 50 TWh/year.
In March 2011, Mykyta Konstantinov, director of the strategic policy, investment and nuclear energy complex department at the Ministry of Energy and Coal Mining Industry of Ukraine, said that the installed capacity of alternative and renewable energy sources will increase to 9% (about 6 GW) of the total electricity production in the country.
Internet.
Ukraine has a large and steadily growing Internet sector, mostly uninfluenced by the global financial crisis; rapid growth is forecast for at least two more years.
Ukraine is ranked 9th in the "Top 10 Internet countries in Europe" (as of 2011) with 33.9% Internet penetration and 15.3 million users.
Tourism.
Ukraine occupies 8th place in Europe by the number of tourists visiting, according to the World Tourism Organisation rankings.
Ukraine is a destination on the crossroads between central and eastern Europe, between north and south. It has mountain ranges – the Carpathian Mountains suitable for skiing, hiking, fishing and hunting. The coastline on the Black Sea is a popular summer destination for vacationers. Ukraine has vineyards where they produce native wines, ruins of ancient castles, historical parks, Orthodox and Catholic churches as well as a few mosques and synagogues. Kiev, the country’s capital city has many unique structures such as Saint Sophia Cathedral and broad boulevards. There are other cities well-known to tourists such as the harbour town Odessa and the old city of Lviv in the west. The Crimea, a little “continent” of its own, is a popular vacation destination for tourists for swimming or sun tanning on the Black Sea with its warm climate, rugged mountains, plateaus and ancient ruins. Cities there include: Sevastopol and Yalta – location of the peace conference at the end of World War II. Visitors can also take cruise tours by ship on Dnieper River from Kiev to the Black Sea coastline. Ukrainian cuisine has a long history and offers a wide variety of original dishes.
The Seven Wonders of Ukraine are the seven historical and cultural monuments of Ukraine; the sites were chosen by the general public through an internet-based vote.
Demographics.
According to the Ukrainian Census of 2001, ethnic Ukrainians make up 77.8% of the population. Other significant ethnic groups are the Russians (17.3%), Belarusians (0.6%), Moldovans (0.5%), Crimean Tatars (0.5%), Bulgarians (0.4%), Hungarians (0.3%), Romanians (0.3%), Poles (0.3%), Jews (0.2%), Armenians (0.2%), Greeks (0.2%) and Tatars (0.2%). The industrial regions in the east and southeast are the most heavily populated, and about 67.2 percent of the population lives in urban areas.
Demographic crisis.
Ukraine has been in a demographic crisis since the 1980s because of its high death rate and a low birth rate. The population is shrinking by over 150,000 a year. The birth rate has recovered in recent years from a catastrophically low level around 2000, and is now comparable to the European average, but would need to increase by another 50% or so to stabilize the population.
In 2007, the country's population was declining at the fourth fastest rate in the world.
Life expectancy is falling. The nation suffers a high mortality rate from environmental pollution, poor diets, widespread smoking, extensive alcoholism, and deteriorating medical care.
In the years 2008 through 2010, more than 1.5 million children were born in Ukraine, compared to fewer than 1.2 million during 1999–2001 during the worst of the demographic crisis. Infant mortality rates have also dropped from 10.4 deaths to 8.9 per 1,000 children under one year of age. This is still high in comparison, however, to many other nations.
According to the United Nations, poverty and poor health care are the two biggest problems Ukrainian children face. More than 26 percent of families with one child, 42 percent of families with two children and 77 percent of families with four and more children live in poverty, according to United Nations International Children's Emergency Fund. In November 2009 Ukrainian human rights ombudsman Nina Karpacheva stated that the lives of many of Ukraine’s 8.2 million children remain tough.
Fertility and natalist policies.
The current birth rate in Ukraine, as of 2010, is 10.8 births/1,000 population, and the death rate is 15.2 deaths/1,000 population (see demographic tables)
The phenomenon of lowest-low fertility, defined as total fertility below 1.3, is emerging throughout Europe and is attributed by many to postponement of the initiation of childbearing. Ukraine, where total fertility (a very low 1.1 in 2001), was one of the world's lowest, shows that there is more than one pathway to lowest-low fertility. Although Ukraine has undergone immense political and economic transformations during 1991–2004, it has maintained a young age at first birth and nearly universal childbearing. Analysis of official national statistics and the Ukrainian Reproductive Health Survey show that fertility declined to very low levels without a transition to a later pattern of childbearing. Findings from focus group interviews suggest explanations of the early fertility pattern. These findings include the persistence of traditional norms for childbearing and the roles of men and women, concerns about medical complications and infertility at a later age, and the link between early fertility and early marriage.
To help mitigate the declining population, the government continues to increase child support payments. Thus it provides one-time payments of 12,250 Hryvnias for the first child, 25,000 Hryvnias for the second and 50,000 Hryvnias for the third and fourth, along with monthly payments of 154 Hryvnias per child. The demographic trend is showing signs of improvement, as the birth rate has been steadily growing since 2001. Net population growth over the first nine months of 2007 was registered in five provinces of the country (out of 24), and population shrinkage was showing signs of stabilising nationwide. In 2007 the highest birth rates were in the Western Oblasts. In 2008, Ukraine emerged from lowest-low fertility, and the upward trend has continued since then, except for a slight dip in 2010 due to the economic crisis of 2009 (see demographic tables).
Urbanization.
In total, Ukraine has 457 cities, 176 of them are labeled oblast-class, 279 smaller -class cities, and two special legal status cities. These are followed by 886 urban-type settlements and 28,552 villages.
Language.
According to the constitution, the state language of Ukraine is Ukrainian. Russian, which was the "de facto" official language of the Soviet Union, is widely spoken, especially in eastern and southern Ukraine. According to the 2001 census, 67.5 percent of the population declared Ukrainian as their native language and 29.6 percent declared Russian. Most native Ukrainian speakers know Russian as a second language. On July 3, 2012, the Ukrainian Parliament approved a bill that Russian and other languages spoken by at least 10 percent of their residents as official languages, although Ukrainian language is still State Language for all.
These details result in a significant difference across different survey results, as even a small restating of a question switches responses of a significant group of people. Ukrainian is mainly spoken in western and central Ukraine. In western Ukraine, Ukrainian is also the dominant language in cities (such as Lviv). In central Ukraine, Ukrainian and Russian are both equally used in cities, with Russian being more common in Kiev, while Ukrainian is the dominant language in rural communities. In eastern and southern Ukraine, Russian is primarily used in cities, and Ukrainian is used in rural areas.
For a large part of the Soviet era, the number of Ukrainian speakers declined from generation to generation, and by the mid-1980s, the usage of the Ukrainian language in public life had decreased significantly. Following independence, the government of Ukraine began restoring the image and usage of Ukrainian language through a policy of Ukrainisation. Today, all foreign films and TV programs, including Russian ones, are subbed or dubbed in Ukrainian.
According to the Constitution of the Autonomous Republic of Crimea, Ukrainian is the only state language of the republic. However, the republic's constitution specifically recognises Russian as the language of the majority of its population and guarantees its usage 'in all spheres of public life'. Similarly, the Crimean Tatar language (the language of 12 percent of population of Crimea) is guaranteed a special state protection as well as the 'languages of other ethnicities'. Russian speakers constitute an overwhelming majority of the Crimean population (77 percent), with Ukrainian speakers comprising just 10.1 percent, and Crimean Tatar speakers 11.4 percent. But in everyday life the majority of Crimean Tatars and Ukrainians in Crimea use Russian.
Religion.
The dominant religion in Ukraine is Orthodox Christianity, which is currently split between three Church bodies: the Ukrainian Orthodox Church autonomous church body under the Patriarch of Moscow, the Ukrainian Orthodox Church – Kiev Patriarchate, and the Ukrainian Autocephalous Orthodox Church.
[[File:Ukraine religion 2006 Razumkov center.svg|thumb|"What religious group do you belong to?" Sociology poll by Razumkov Centre about the religious situation in Ukraine (2006)
A distant second by the number of the followers is the Eastern Rite Ukrainian Greek Catholic Church, which practices a similar liturgical and spiritual tradition as Eastern Orthodoxy, but is in communion with the Holy See of the Roman Catholic Church and recognises the primacy of the Pope as head of the Church.
Additionally, there are 863 Latin Rite Catholic communities, and 474 clergy members serving some one million Latin Rite Catholics in Ukraine. The group forms some 2.19 percent of the population and consists mainly of ethnic Poles and Hungarians, who live predominantly in the western regions of the country.
Protestant Christians also form around 2.19 percent of the population. Protestant numbers have grown greatly since Ukrainian independence. The Evangelical Baptist Union of Ukraine is the largest group, with more than 150,000 members and about 3000 clergy. The second largest Protestant church is the Ukrainian Church of Evangelical faith (Pentecostals) with 110000 members and over 1500 local churches and over 2000 clergy, but there also exist other Pentecostal groups and unions and together all Pentecostals are over 300,000, with over 3000 local churches. Also there are many Pentecostal high education schools such as the Lviv Theological Seminary and the Kiev Bible Institute. Other groups include Calvinists, Jehovah's Witnesses, Lutherans, Methodists and Seventh-day Adventists. The Church of Jesus Christ of Latter-day Saints (Mormon) is also present.
There are an estimated 500,000 Muslims in Ukraine, and about 250,000 of them are Crimean Tatars. There are 487 registered Muslim communities, 368 of them on the Crimean peninsula. In addition, some 50,000 Muslims live in Kiev; mostly foreign-born.
The Jewish population is a tiny fraction of what it was before World War II. (In Tsarist times, Ukraine had been part of the Pale of Settlement, to which Jews were largely restricted in the Russian Empire.) The largest Jewish communities in 1926 were in Odessa, 154,000 or 36.5% of the total population; and Kiev, 140,500 or 27.3%. The 2001 census indicated that there are 103,600 Jews in Ukraine, although community leaders claimed that the population could be as large as 300,000. There are no statistics on what share of the Ukrainian Jews are observant, but Orthodox Judaism has the strongest presence in Ukraine. Smaller Reform and Conservative Jewish (Masorti) communities exist as well.
One 2006 survey put the number of non-religious in Ukraine at approximately 62.5% of the population.
Famines and migration.
The famines of the 1930s, followed by the devastation of World War II, comprised a demographic disaster. Life expectancy at birth fell to a level as low as ten years for females and seven for males in 1933 and plateaued around 25 for females and 15 for males in the period 1941–44. According to "The Oxford companion to World War II", "Over 7 million inhabitants of Ukraine, more than one-sixth of the pre-war population, were killed during the Second World War."
Significant migration took place in the first years of Ukrainian independence. More than one million people moved into Ukraine in 1991–2, mostly from the other former Soviet republics. In total, between 1991 and 2004, 2.2 million immigrated to Ukraine (among them, 2 million came from the other former Soviet Union states), and 2.5 million emigrated from Ukraine (among them, 1.9 million moved to other former Soviet Union republics). Currently, immigrants constitute an estimated 14.7% of the total population, or 6.9 million people; this is the fourth largest figure in the world. In 2006, there were an estimated 1.2 million Canadians of Ukrainian ancestry, giving Canada the world's third-largest Ukrainian population behind Ukraine itself and Russia.
Health.
Ukraine's healthcare system is state subsidised and freely available to all Ukrainian citizens and registered residents. However, it is not compulsory to be treated in a state-run hospital as a number of private medical complexes do exist nationwide. The public sector employs most healthcare professionals, with those working for private medical centres typically also retaining their state employment as they are mandated to provide care at public health facilities on a regular basis.
All the country's medical service providers and hospitals are subordinate to the Ministry of Health, which provides oversight and scrutiny of general medical practice as well as being responsible for the day to day administration of the healthcare system. Despite this standards of hygiene and patient-care have fallen.
Hospitals in Ukraine are organised along the same lines as most European nations, according to the regional administrative structure; resultantly most towns have their own hospital "(Міська Лікарня)" and many also have district hospitals "(Районна Лікарня)". Larger and more specialised medical complexes tend only to be found in major cities, with some even more specialised units located only in the capital, Kiev. However, all Oblasts have their own network of general hospitals which are able to deal with almost all medical problems and are typically equipped with major trauma centres; such hospitals are called 'regional hospitals' "(Обласна Лікарня)".
Ukraine currently faces a number of major public health issues, and is considered to be in a demographic crisis due to its high death rate and low birth rate (the current Ukrainian birth rate is 11 births/1,000 population, and the death rate is 16.3 deaths/1,000 population). A factor contributing to the relatively high death is a high mortality rate among working-age males from preventable causes such as alcohol poisoning and smoking. In 2008, the country's population was one of the fastest declining in the world at −5% growth. The UN warned that Ukraine's population could fall by as much as 10 million by 2050 if trends did not improve. In addition to this obesity, systemic high blood pressure and the HIV endemic are all major challenges facing the contemporary Ukrainian healthcare system.
As of March 2009 the Ukrainian government to reforming the health care system, by the creation of a national network of family doctors and improvements in the medical emergency services. former Prime Minister Yulia Tymoshenko put forward (in November 2009) an idea to start introducing a public healthcare system based on health insurance in the spring of 2010.
Education.
According to the Ukrainian constitution, access to free education is granted to all citizens. Complete general secondary education is compulsory in the state schools which constitute the overwhelming majority. Free higher education in state and communal educational establishments is provided on a competitive basis. There is also a small number of accredited private secondary and higher education institutions.
Because of the Soviet Union's emphasis on total access of education for all citizens, which continues today, the literacy rate is an estimated 99.4%. Since 2005, an eleven-year school program has been replaced with a twelve-year one: primary education takes four years to complete (starting at age six), middle education (secondary) takes five years to complete; upper secondary then takes three years. In the 12th grade, students take Government Tests, which are also referred to as school-leaving exams. These tests are later used for university admissions.
The first higher education institutions (HEIs) emerged in Ukraine during the late 16th and early 17th centuries. The first Ukrainian higher education institution was the Ostrozka School, or Ostrozkiy Greek-Slavic-Latin Collegium, similar to Western European higher education institutions of the time. Established in 1576 in the town of Ostrog, the Collegium was the first higher education institution in the Eastern Slavic territories. The oldest university was the Kyiv Mohyla Academy, first established in 1632 and in 1694 officially recognized by the government of Imperial Russia as a higher education institution. Among the oldest is also the Lviv University, founded in 1661. More higher education institutions were set up in the 19th century, beginning with universities in Kharkiv (1805), Kiev (1834), Odessa (1865), and Chernivtsi (1875) and a number of professional higher education institutions, e.g.: Nizhyn Historical and Philological Institute (originally established as the Gymnasium of Higher Sciences in 1805), a Veterinary Institute (1873) and a Technological Institute (1885) in Kharkiv, a Polytechnic Institute in Kiev (1898) and a Higher Mining School (1899) in Katerynoslav. Rapid growth followed in the Soviet period. By 1988 a number of higher education institutions increased to 146 with over 850,000 students. Most HEIs established after 1990 are those owned by private organizations.
The Ukrainian higher education system comprises higher educational establishments, scientific and methodological facilities under federal, municipal and self-governing bodies in charge of education. The organisation of higher education in Ukraine is built up in accordance with the structure of education of the world's higher developed countries, as is defined by UNESCO and the UN.
Nowadays higher education is either state funded or private. Students that study at state expense receive a standard scholarship if their average marks at the end-of-term exams and differentiated test is at least 4 (see the 5-point grade system below); this rule may be different in some universities. In the case of all grades being the highest (5), the scholarship is increased by 25%. For most students the level of government subsidy is not sufficient to cover their basic living expenses. Most universities provide subsidized housing for out-of-city students. Also, it is common for libraries to supply required books for all registered students. There are two degrees conferred by Ukrainian universities: the Bachelor's Degree (4 years) and the Master's Degree (5–6th year). These degrees are introduced in accordance with Bologna process, in which Ukraine is taking part. Historically, Specialist's Degree (usually 5 years) is still also granted; it was the only degree awarded by universities in the Soviet times.
Culture.
Ukrainian customs are heavily influenced by Christianity, which is the dominant religion in the country. Gender roles also tend to be more traditional, and grandparents play a greater role in raising children than in the West. The culture of Ukraine has been also influenced by its eastern and western neighbours, which is reflected in its architecture, music and art.
The Communist era had quite a strong effect on the art and writing of Ukraine. In 1932, Stalin made socialist realism state policy in the Soviet Union when he promulgated the decree "On the Reconstruction of Literary and Art Organisations". This greatly stifled creativity. During the 1980s glasnost (openness) was introduced and Soviet artists and writers again became free to express themselves as they wanted.
The tradition of the Easter egg, known as pysanky, has long roots in Ukraine. These eggs were drawn on with wax to create a pattern; then, the dye was applied to give the eggs their pleasant colours, the dye did not affect the previously wax-coated parts of the egg. After the entire egg was dyed, the wax was removed leaving only the colourful pattern. This tradition is thousands of years old, and precedes the arrival of Christianity to Ukraine. In the city of Kolomya near the foothills of the Carpathian mountains in 2000 was built the museum of Pysanka which won a nomination as the monument of modern Ukraine in 2007, part of the Seven Wonders of Ukraine action.
Literature.
The history of Ukrainian literature dates back to the 11th century, following the Christianisation of the Kievan Rus’. The writings of the time were mainly liturgical and were written in Old Church Slavonic. Historical accounts of the time were referred to as "chronicles", the most significant of which was the Primary Chronicle. Literary activity faced a sudden decline during the Mongol invasion of Rus'.
Ukrainian literature again began to develop in the 14th century, and was advanced significantly in the 16th century with the introduction of print and with the beginning of the Cossack era, under both Russian and Polish dominance. The Cossacks established an independent society and popularized a new kind of epic poems, which marked a high point of Ukrainian oral literature. These advances were then set back in the 17th and early 18th centuries, when publishing in the Ukrainian language was outlawed and prohibited. Nonetheless, by the late 18th century modern literary Ukrainian finally emerged.
The 19th century initiated a vernacular period in Ukraine, led by Ivan Kotliarevsky’s work , the first publication written in modern Ukrainian. By the 1830s, Ukrainian romanticism began to develop, and the nation’s most renowned cultural figure, romanticist poet-painter Taras Shevchenko emerged. Where Ivan Kotliarevsky is considered to be the father of literature in the Ukrainian vernacular; Shevchenko is the father of a national revival.
Then, in 1863, use of the Ukrainian language in print was effectively prohibited by the Russian Empire. This severely curtained literary activity in the area, and Ukrainian writers were forced to either publish their works in Russian or release them in Austrian controlled Galicia. The ban was never officially lifted, but it became obsolete after the revolution and the Bolsheviks’ coming to power.
Ukrainian literature continued to flourish in the early Soviet years, when nearly all literary trends were approved. These policies faced a steep decline in the 1930s, when Stalin implemented his policy of socialist realism. The doctrine did not necessarily repress the Ukrainian language, but it required writers to follow a certain style in their works. Literary activities continued to be somewhat limited under the communist party, and it was not until Ukraine gained its independence in 1991 when writers were free to express themselves as they wished.
Architecture.
Ukrainian architecture is a term that describes the motifs and styles that are found in structures built in modern Ukraine, and by Ukrainians worldwide. These include initial roots which were established in the Eastern Slavic state of Kievan Rus'. After the 12th century, the distinct architectural history continued in the principalities of Galicia-Volhynia. During the epoch of the Zaporozhian Cossacks, a new style unique to Ukraine was developed under the western influences of the Polish–Lithuanian Commonwealth. After the union with the Tsardom of Russia, architecture in Ukraine began to develop in different directions, with many structures in the larger eastern, Russian-ruled area built in the styles of Russian architecture of that period, whilst the western Galicia was developed under Austro-Hungarian architectural influences, in both cases producing fine examples. Ukrainian national motifs would finally be used during the period of the Soviet Union and in modern independent Ukraine.
The great churches of the Rus', built after the adoption of Christianity in 988, were the first examples of monumental architecture in the East Slavic lands. The architectural style of the Kievan state, which quickly established itself, was strongly influenced by the Byzantine. Early Eastern Orthodox churches were mainly made of wood, with the simplest form of church becoming known as a cell church. Major cathedrals often featured scores of small domes, which led some art historians to take this as an indication of the appearance of pre-Christian pagan Slavic temples.
Several examples of these churches survive to this day; however, during the 16th, 17th, and 18th centuries, many were externally rebuilt in the Ukrainian Baroque style (see below). Examples include the grand St. Sophia of Kiev – the year 1017 is the earliest record of foundation laid, Church of the Saviour at Berestove – built from 1113 to 1125, and St. Cyril's Church, circa 12th century. All can still be found in the Ukrainian capital. Several buildings were reconstructed during the late-19th century, including the Assumption Cathedral in Volodymyr-Volynskyi, built in 1160 and reconstructed in 1896–1900, the Paraskevi church in Chernihiv, built in 1201 with reconstruction done in the late 1940s, and the Golden gates in Kiev, built in 1037 and reconstructed in 1982. The latter's reconstruction was criticized by some art and architecture historians as a revivalist fantasy. Unfortunately little secular or vernacular architecture of Kievan Rus' has survived.
As Ukraine became increasingly integrated into the Russian Empire, Russian architects had the opportunity to realize their projects in the picturesque landscape that many Ukrainian cities and regions offered. St. Andrew's Church of Kiev (1747–1754), built by Bartolomeo Rastrelli, is a notable example of Baroque architecture, and its location on top of the Kievan mountain made it a recognizable monument of the city. An equally notable contribution of Rasetrelli was the Mariyinsky Palace, which was built to be a summer residence to Russian Empress Elizabeth. During the reign of the last Hetman of Ukraine, Kirill Razumovsky, many of the Cossack Hetmanate's towns such as Hlukhiv, Baturyn and Koselets had grandiose projects built by the appointed "architect of Little Russia," Andrey Kvasov. Russia, winning successive wars over the Ottoman Empire and its vassal Crimean Khanate, eventually annexed the whole south of Ukraine and Crimea. Renamed New Russia, these lands were to be colonized, and new cities such as the Nikolayev, Odessa, Kherson and Sevastopol were founded. These would contain notable examples of Imperial Russian architecture.
In 1934, the capital of Soviet Ukraine moved from Kharkiv to Kiev. During the preceding years, the city was seen as only a regional centre, and hence received little attention. All of that was to change, but at a great price. By this point, the first examples of Stalinist architecture were already showing, and, in light of the official policy, a new city was to be built on top of the old one. This meant that much-admired examples such as the St. Michael's Golden-Domed Monastery were destroyed. Even the St. Sophia Cathedral was under threat. Also, the Second World War contributed to the wreckage. After the war, a new project for the reconstruction of central Kiev was unveiled. This transformed the Khreshchatyk avenue into one of the most notable examples of Stalinism in Architecture. However, by 1955, the new politics of architecture once again promptly stopped the project from fully being realised.
The task for modern Ukrainian architecture is diverse application of modern aesthetics, the search for an architect's own artistic style and inclusion of the existing historico-cultural environment. An example of modern Ukrainian architecture is the reconstruction and renewal of the Maidan Nezalezhnosti in central Kiev, despite the limit set by narrow space within the plaza, the engineers were able to blend together the uneven landscape and also use underground space to set a new shopping centre.
A major project, which may take up most of the 21st century, is the construction of the Kiev City-Centre on the Rybalskyi Peninsula, which, when finished, will include a dense skyscraper park amid the picturesque landscape of the Dnieper.
Music.
Music is a major part of Ukrainian culture, with a long history and many influences. From traditional folk music, to classical and modern rock, Ukraine has produced a long list of internationally recognized musical talent including Tchaikovsky, Okean Elzy and Ruslana. Elements from traditional Ukrainian folk music made their way into Western music and even into modern jazz.
Ukraine found itself at the crossroads of Asia and Europe and this is reflected within the music in a perplexing mix of exotic melismatic singing with chordal harmony which does not always easily fit the rules of traditional Western European harmony.
The most striking general characteristic of authentic ethnic Ukrainian folk music is the wide use of minor modes or keys which incorporate augmented 2nd intervals. This is an indication that the major-minor system developed in Western European music did not become as entrenched or as sophisticated in Ukraine. However, during the Baroque period, music was an important discipline for those that had received a higher education in Ukraine. It had a place of considerable importance in the curriculum of the Kyiv-Mohyla Academy. Much of the nobility was well versed in music with many Ukrainian Cossack leaders such as (Mazepa, Paliy, Holovatyj, Sirko) being accomplished players of the kobza, bandura or torban.
In the course of the 18th century in the Russian Empire court musicians were typically trained at the music academy in Hlukhiv, and largely came from Ukraine. Notable performers of the era include Tymofiy Bilohradsky who later studied lute under Sylvius Leopold Weiss in Dresden, his daughter Yelyzaveta who was a famous operatic soprano, and Oleksiy Rozumovsky, a court bandurist and the morganatic husband of Empress Elizabeth. The first dedicated musical academy was set up in Hlukhiv, Ukraine in 1738 and students were taught to sing, play violin and bandura from manuscripts. As a result many of the earliest composers and performers within the Russian empire were ethnically Ukrainian, having been born or educated in Hlukhiv, or had been closely associated with this music school.
See: Dmytro Bortniansky, Maksym Berezovsky, Artemiy Vedel.
Ukrainian classical music falls into three distinct categories defined by whether the composer was of Ukrainian ethnicity living in Ukraine, a composer of non-Ukrainian ethnicity who was born or at some time was a citizen of Ukraine, or an ethnic Ukrainian living outside of Ukraine within the Ukrainian diaspora. The music of these three groups differs considerably, as do the audiences for whom they cater.
The first category is closely tied with the Ukrainian national school of music spearheaded by Mykola Lysenko. It includes such composers as Kyrylo Stetsenko, Mykola Leontovych, Levko Revutsky, Borys Lyatoshynsky, Mykola Vilinsky. Most of their music contains Ukrainian folk figures and are composed to Ukrainian texts. On the other hand, the second category is of particular importance and international visibility, because of the large percentage of ethnic minorities in urban Ukraine. This category includes such composers as Franz Xavier Mozart, Isaak Dunayevsky, Rheinhold Gliere, Yuliy Meitus and Sergei Prokofiev, performers Volodymyr Horovyts, David Oistrakh, Sviatoslav Richter and Isaac Stern. The music of these composers rarely contains Ukrainian folk motives and more often is written to the texts of Russian or Polish poets. Whilst the third category includes a number of prominent individuals who are often not part of the mainstream Ukrainian culture but who have made a significant impact on music in Ukraine, while living outside of its borders. These include historic individuals such as: Bortniansky, Berezovsky, Vedel, Tuptalo and Titov. It also contains "Soviet" composers such as Mykola Roslavets, Isaak Dunayevsky who were born in Ukraine but who moved to other cultural centres within the Soviet Union. In North America we have Mykola Fomenko, Yuriy Oliynyk, Zinoviy Lavryshyn and Wasyl Sydorenko.
Since the mid 1960s, Western-influenced pop music, in its various forms, that has been growing in popularity in Ukraine. One of the most important and truly original musicians to come out of Ukraine in recent years is the ultra avant-garde folk singer and harmonium player Mariana Sadovska. Ukrainian pop and folk music arose with the international popularity of groups like Vopli Vidoplyasova, Viy, and Okean Elzy.
Weaving and embroidery.
Artisan textile arts play an important role in Ukrainian culture, especially in Ukrainian wedding traditions. Ukrainian embroidery, weaving and lace-making are used in traditional folk dress and in traditional celebrations. Ukrainian embroidery varies depending on the region of origin and the designs have a long history of motifs, compositions, choice of colors and types of stitches. Use of color is very important and has roots in Ukrainian folklore. Embroidery motifs found in different parts of Ukraine are preserved in the Rushnyk Museum in Pereiaslav-Khmelnytskyi.
National dress is woven and highly decorated. Weaving with handmade looms is still practised in the village of Krupove, situated in Rivne Oblast. The village is the birthplace of two famous personalities in the scene of national crafts fabrication. Nina Myhailivna and Uliana Petrivna with international recognition. In order to preserve this traditional knowledge the village is planning to open a local weaving center, a museum and weaving school.
Sport.
Ukraine greatly benefited from the Soviet emphasis on physical education. Such policies left Ukraine with hundreds of stadia, swimming pools, gymnasia, and many other athletic facilities. The most popular sport is football. The top professional league is the Vyscha Liha ("premier league"). The two most successful teams in the Vyscha Liha are rivals FC Dynamo Kyiv and FC Shakhtar Donetsk. Although Shakhtar is the reigning champion of the Vyscha Liha, Dynamo Kyiv has been much more successful historically, winning two UEFA Cup Winners' Cups, one UEFA Super Cup, a record 13 USSR Championships and a record 12 Ukrainian Championships; while Shakhtar only won six Ukrainian championships and one and last UEFA Cup. Ukraine co-hosted UEFA Euro 2012 alongside Poland.
Sergey Bubka holds the record in the Pole vault; with a great strength, speed and gymnastic abilities, he is repeatedly voted the world's best athlete.
Many Ukrainians also played for the Soviet national football team, most notably Ihor Belanov and Oleh Blokhin, winners of the prestigious Golden Ball Award for the best football player of the year. This award was only presented to one Ukrainian after the dissolution of the Soviet Union, Andriy Shevchenko, the current captain of the Ukrainian national football team. The national team made its debut in the 2006 FIFA World Cup, and reached the quarterfinals before losing to eventual champions, Italy. Ukrainians also fared well in boxing, where the brothers Vitali and Wladimir Klitschko have held world heavyweight championships.
Ukraine made its Olympic debut at the 1994 Winter Olympics. So far, Ukraine has been much more successful in Summer Olympics (96 medals in four appearances) than in the Winter Olympics (five medals in four appearances). Ukraine is currently ranked 35th by number of gold medals won in the All-time Olympic Games medal count, with every country above it, except for Russia, having more appearances.
Cuisine.
The traditional Ukrainian diet includes chicken, pork, beef, fish and mushrooms. Ukrainians also tend to eat a lot of potatoes, grains, fresh and pickled vegetables. Popular traditional dishes include (boiled dumplings with mushrooms, potatoes, sauerkraut, cottage cheese or cherries), borscht (soup made of beets, cabbage and mushrooms or meat) and (stuffed cabbage rolls filled with rice, carrots and meat). Ukrainian specialties also include Chicken Kiev and Kiev Cake. Ukrainians drink stewed fruit, juices, milk, buttermilk (they make cottage cheese from this), mineral water, tea and coffee, beer, wine and .
Notes.
a. Among the Ukrainians that rose to the highest offices in the Russian Empire were Aleksey Razumovsky, Alexander Bezborodko, Ivan Paskevich. Among the Ukrainians who greatly influenced the Russian Orthodox Church in this period were Stephen Yavorsky, Feofan Prokopovich, Dimitry of Rostov.
b. See the Great Purge article for details.
c. Estimates on the number of deaths vary. Official Soviet data is not available because the Soviet government denied the existence of the famine. See the Holodomor article for details. Sources differ on interpreting various statements from different branches of different governments as to whether they amount to the official recognition of the Famine as Genocide by the country. For example, after the statement issued by the Latvian Sejm on March 13, 2008, the total number of countries is given as 19 (according to "Ukrainian BBC": ), 16 (according to "Korrespondent", Russian edition: ), "more than 10" (according to "Korrespondent", Ukrainian edition: ) Retrieved on 2008-01-27.
d. These figures are likely to be much higher, as they do not include Ukrainians from nations or Ukrainian Jews, but instead only ethnic Ukrainians, from the Ukrainian SSR.
e. This figure excludes POW deaths.
f. According to the official 2001 census data (by nationality; by language) about 75 percent of Kiev's population responded 'Ukrainian' to the native language (ridna mova) census question, and roughly 25 percent responded 'Russian'. On the other hand, when the question 'What language do you use in everyday life?' was asked in the 2003 sociological survey, the Kievans' answers were distributed as follows: 'mostly Russian': 52 percent, 'both Russian and Ukrainian in equal measure': 32 percent, 'mostly Ukrainian': 14 percent, 'exclusively Ukrainian': 4.3 percent.
g. Such writings were also the base for Russian and Belarusian literature.
h. Without the city of Inhulets.
i. Russia and Khazakstan are the first and second largest but both these figures include European and Asian territories. Russia is the only country possessing European territories larger than Ukraine.

United States presidential election, 2000
The United States presidential election of 2000 was a contest between Republican candidate George W. Bush, the governor of Texas and son of former president George H. W. Bush, and Democratic candidate Al Gore, the Vice President.
The incumbent President, Bill Clinton, was vacating the position after serving the maximum two terms allowed by the Twenty-second Amendment. Bush narrowly won the November 7 election, with 271 electoral votes to Gore's 266 (with one elector abstaining in the official tally).
The election was noteworthy for a controversy over the awarding of Florida's 25 electoral votes, the subsequent recount process in that state, and the unusual event of the winning candidate having received fewer popular votes than the runner-up. This marked only the fourth election in U.S. History in which the eventual winner failed to win a plurality of the popular vote (after the elections of 1824, 1876, and 1888). Later research showed that by the standards requested by the Gore campaign in their contest brief or by the partial statewide recount set by the Florida Supreme Court, Bush would have likely won the recount anyway. However, the same research indicates that had the statewide recount included all uncounted votes (overvotes as well as undervotes), as seems probable based on later statements by the judge overseeing the recount and supported by faxes made public in November, 2001, Gore would have won the election.
Democratic Party nomination.
Democratic candidates
Candidates gallery.
Al Gore of Tennessee was a consistent front-runner for the nomination. Other prominent Democrats mentioned as possible contenders included Bob Kerrey, Missouri Congressman Dick Gephardt, Minnesota Senator Paul Wellstone, and famous actor and director Warren Beatty, who declined to run. Of these, only Wellstone formed an exploratory committee.
In addition to Gore's advantage as the incumbent Vice President, Bradley was not the candidate of a major faction or coalition of blocs. Running an insurgency campaign, Bradley positioned himself as the alternative to Gore, who was a founding member of the centrist Democratic Leadership Council. While former basketball star Michael Jordan campaigned for him in the early primary states, Bradley announced his intention to campaign "in a different way" by conducting a positive campaign of "big ideas". The focus of his campaign was a plan to spend the record-breaking budget surplus on a variety of social welfare programs to help the poor and the middle-class, along with campaign finance reform and gun control.
Gore easily defeated Bradley in the primaries, largely because of support from the Democratic Party establishment and Bradley's poor showing in the Iowa caucus, where Gore successfully painted Bradley as aloof and indifferent to the plight of farmers. The closest Bradley came to a victory was his 50–46 loss to Gore in the New Hampshire primary. On March 14, Al Gore won the Democratic nomination.
None of Bradley's delegates were allowed to vote for him, so Gore won the nomination unanimously at the Democratic National Convention. Connecticut Senator Joe Lieberman was nominated for Vice President by voice vote. Lieberman became the first Jewish American ever to be chosen for this position by a major party. Gore chose Lieberman over five finalists.
Delegate totals
Republican Party nomination.
Candidates gallery.
Several Republican candidates appeared on the national scene to challenge Gore's candidacy.
George W. Bush became the early front-runner, acquiring unprecedented funding and a broad base of leadership support based on his governorship of Texas and the name recognition and connections of the Bush family. Former cabinet member George Shultz played an important early role in securing establishment Republican support for Bush. In April 1998, he invited Bush to discuss policy issues with experts including Michael Boskin, John Taylor, and Condoleezza Rice. The group, which was "looking for a candidate for 2000 with good political instincts, someone they could work with", was impressed, and Shultz encouraged him to enter the race. Several aspirants withdrew before the Iowa Caucus because they were unable to secure funding and endorsements sufficient to remain competitive with Bush. These included Elizabeth Dole, Dan Quayle, Lamar Alexander, and Robert C. Smith. Pat Buchanan dropped out to run for the Reform Party nomination. That left Bush, John McCain, Alan Keyes, Steve Forbes, Gary Bauer, and Orrin Hatch as the only candidates still in the race.
On January 24, Bush won the Iowa caucus with 41% of the vote. Forbes came in second with 30% of the vote. Keyes received 14%, Bauer 9%, McCain 5%, and Hatch 1%. Hatch dropped out. On the national stage, Bush was portrayed in the media as the establishment candidate. McCain, with the support of many moderate Republicans and Independents, portrayed himself as a crusading insurgent who focused on campaign reform.
On February 1, McCain won a 49%–30% victory over Bush in the New Hampshire primary. Gary Bauer dropped out. After coming in third in Delaware Forbes dropped out, leaving three candidates. In the South Carolina primary, Bush soundly defeated McCain. Some McCain supporters blamed it on the Bush campaign, accusing them of mudslinging and dirty tricks, such as push polling that implied that McCain's adopted Bangladeshi-born daughter was an African-American child he fathered out of wedlock. While McCain's loss in South Carolina damaged his campaign, he won both Michigan and his home state of Arizona on February 22.
On February 24, McCain criticized Bush for accepting the endorsement of Bob Jones University despite its policy banning interracial dating. On February 28, McCain also referred to Rev. Jerry Falwell and televangelist Pat Robertson as "agents of intolerance", a term he would later distance himself from during his 2008 bid for the party's nomination. He lost the state of Virginia to Bush on February 29. On Super Tuesday, March 7, Bush won New York, Ohio, Georgia, Missouri, California, Maryland, and Maine. McCain won Rhode Island, Vermont, Connecticut, and Massachusetts, but dropped out of the race. On March 10, Alan Keyes got 21% of the vote in Utah. Bush took the majority of the remaining contests and won the Republican nomination on March 14, winning his home state of Texas and his brother Jeb's home state of Florida among others. At the Republican National Convention in Philadelphia George W. Bush accepted the nomination of the Republican party.
Delegate totals
Bush asked former Secretary of Defense Dick Cheney to head up a team to help select a running mate for him, but ultimately, Bush decided that Cheney should be the vice presidential nominee. While the U.S. Constitution does not specifically disallow a president and a vice president from the same state, it does prohibit electors from casting both of his or her votes for persons from his or her own state. Accordingly, Cheney—who had been a resident of Texas for nearly 10 years—changed his voting registration back to Wyoming. Had Cheney not done this, either he or Bush would have forfeited their electoral votes from the Texas electors.
Notable endorsements.
Note: Some of the endorsers switched positions.
Association of State Green Parties nomination.
The Greens/Green Party USA, the then-recognized national party organization, later endorsed Ralph Nader for president and he appeared on the ballots of 43 states and DC.
Libertarian Party nomination.
The Libertarian Party's National Nominating Convention nominated Harry Browne of Tennessee and Art Olivier of California for Vice President. Browne was nominated on the first ballot and Olivier received the Vice Presidential nomination on the second ballot. The Libertarian Party appeared on 50 of 51 ballots.
Constitution Party nomination.
The Constitution Party nominated Howard Phillips of Virginia for a third time and Curtis Frazier of Missouri. The Constitution Party was on the ballot in 41 states.
Natural Law Party nomination.
The Natural Law Party held its national convention in Arlington, Virginia, August 31–September 2, nominating a ticket of Hagelin/Goldhaber via unanimous decision without a roll-call vote. The party was on 38 of the 51 ballots nationally.
General election campaign.
Although the campaign focused mainly on domestic issues, such as the projected budget surplus, proposed reforms of Social Security and Medicare, health care, and competing plans for tax relief, foreign policy was often an issue. Bush criticized Clinton administration policies in Somalia, where 18 Americans died in 1993 trying to sort out warring factions, and in the Balkans, where United States peacekeeping troops perform a variety of functions. "I don't think our troops ought to be used for what's called nation-building," Bush said in the second presidential debate. Bush also pledged to bridge partisan gaps in the nation's capital, claiming the atmosphere in Washington stood in the way of progress on necessary reforms. Gore, meanwhile, questioned Bush's fitness for the job, pointing to gaffes made by Bush in interviews and speeches and suggesting the Texas governor lacked the necessary experience to be president.
Bill Clinton's impeachment and the sex scandal that led up to it cast a shadow on the campaign, particularly on his vice president's run to replace him. Republicans strongly denounced the Clinton scandals, particularly Bush, who made his repeated promise to restore "honor and dignity" to the White House a centerpiece of his campaign. Gore studiously avoided the Clinton scandals, as did Lieberman, even though Lieberman had been the first Democratic senator to denounce Clinton's misbehavior. In fact, some media observers theorized that Gore actually chose Lieberman in an attempt to separate himself from Clinton's past misdeeds, and help blunt the GOP's attempts to link him to his boss. Others pointed to the passionate kiss Gore gave his wife during the Democratic Convention, as a signal that despite the allegations against Clinton, Gore himself was a faithful husband. Gore avoided appearing with Clinton, who was shunted to low visibility appearances in areas where he was popular. Experts have argued that this cost Gore votes from some of Clinton's core supporters.
Ralph Nader was the most successful of third-party candidates, drawing 2.74 percent of the popular vote. His campaign was marked by a traveling tour of large "super-rallies" held in sports arenas like Madison Square Garden, with retired talk show host Phil Donahue as master of ceremonies. After initially ignoring Nader, the Gore campaign made a pitch to (potential) Nader supporters in the final weeks of the campaign, downplaying Gore's differences with Nader on the issues and arguing that Gore's ideas were more similar to Nader's than Bush's were, and noting that Gore had a better chance of winning than Nader. On the other side, the Republican Leadership Council ran pro-Nader ads in a few states in an effort to split the liberal vote. In the aftermath of the campaign, many Gore supporters claimed that Nader acted as a spoiler in the election, that Nader votes would have been cast for Gore, and that Nader threw the election outcome to Bush. Nader dismissed such concerns, claiming his objective in the campaign was to pass the 5-percent threshold so his Green Party would be eligible for matching funds in future races.
Both vice presidential candidates Dick Cheney and Joe Lieberman campaigned aggressively in the 2000 presidential election. Both camps made numerous campaign stops nationwide, often just missing each other such as when Cheney, Hadassah Lieberman, and Tipper Gore attended Chicago's Taste of Polonia over Labor Day Weekend.
Presidential debates.
The Commission on Presidential Debates, formed by Democratic and Republican party leaders, set rules that effectively excluded all but the two major party candidates. Ralph Nader was blocked from attending a closed circuit screening of the first debate in spite of his holding a ticket. He was barred from attending an interview near the site of the third debate in spite of having a "perimeter pass". Nader later sued the CPD for its role in the former incident. A settlement was reached that included an apology to Nader.
Results.
With the exceptions of Florida and Gore's home state of Tennessee, Bush carried the Southern states by comfortable margins (including then-President Bill Clinton's home state of Arkansas) and also secured wins in Ohio, Indiana, most of the rural Midwestern farming states, most of the Rocky Mountain states, and Alaska. Gore balanced Bush by sweeping the Northeastern United States (with the sole exception of New Hampshire, which Bush won narrowly), most of the Upper Midwest, and all of the Pacific Coast states of Washington, Oregon, and California, and carried Hawaii, as well.
As the night wore on, the returns in a handful of small-to-medium sized states, including Wisconsin and Iowa, were extremely close; however it was the state of Florida that would make clear the winner of the election. As the final national results were tallied the following morning, Bush had clearly won a total of 246 electoral votes, while Gore had won 255 votes. 270 votes were needed to win. Two smaller states—New Mexico (5 electoral votes) and Oregon (7 electoral votes)—were still too close to call. It was Florida (25 electoral votes), however, that the news media focused their attention on. Mathematically, Florida's 25 electoral votes became the key to an election win for either candidate. Although both New Mexico and Oregon were declared in favor of Gore over the next few days, Florida's statewide vote took center stage because that state's winner would ultimately win the election. The outcome of the election was not known for more than a month after the balloting ended because of the extended process of counting and then recounting Florida's presidential ballots.
Florida recount.
At approximately 7:50 p.m. EST on election day, 10 minutes before the polls closed in the largely Republican Florida panhandle, which is in the Central time zone, some television news networks declared that Gore had carried Florida's 25 electoral votes. They based this prediction substantially on exit polls. However, in the actual vote tally Bush began to take a wide lead early in Florida, and by 10 p.m. EST those networks had retracted that prediction and placed Florida back into the "undecided" column. At approximately 2:30 a.m., with some 85% of the votes counted in Florida and Bush leading Gore by more than 100,000 votes, the networks declared that Bush had carried Florida and therefore had been elected President. However, most of the remaining votes to be counted in Florida were located in three heavily Democratic counties—Broward, Miami-Dade, and Palm Beach—and as their votes were reported Gore began to gain on Bush. By 4:30 a.m., after all votes were counted, Gore had narrowed Bush's margin to just over 2,000 votes, and the networks retracted their predictions that Bush had won Florida and the presidency. Gore, who had privately conceded the election to Bush, withdrew his concession. The final result in Florida was slim enough to require a mandatory recount (by machine) under state law; Bush's lead had dwindled to about 300 votes by the time it was completed later that week. A count of overseas military ballots later boosted his margin to about 900 votes.
At 4 AM EST on election night, NBC pundit Jonathan Alter predicted that Florida and the entire election would be settled in court.
Most of the post-electoral controversy revolved around Gore's request for hand recounts in four counties (Broward, Miami Dade, Palm Beach, and Volusia), as provided under Florida state law. Florida Secretary of State Katherine Harris announced she would reject any revised totals from those counties if they were not turned in by November 14, the statutory deadline for amended returns. The Florida Supreme Court extended the deadline to November 26, a decision later vacated by the U.S. Supreme Court. Miami-Dade eventually halted its recount and resubmitted its original total to the state canvassing board, while Palm Beach County failed to meet the extended deadline. On November 26, the state canvassing board certified Bush the winner of Florida's electors by 537 votes. Gore formally contested the certified results, but a state court decision overruling Gore was reversed by the Florida Supreme Court, which ordered a recount of over 70,000 ballots previously rejected by machine counters. The U.S. Supreme Court quickly halted that order the next day with the concurring opinion that a recount of votes "of questionable legality does [...] threaten irreparable harm" to Bush as "each manual recount produces a degradation of the ballots."
On December 12, the Supreme Court ruled in a 7–2 vote that the Florida Supreme Court's ruling requiring a statewide recount of ballots was unconstitutional, and in a 5–4 vote that the Florida recounts could not be completed before a December 12 "safe harbor" deadline, and should therefore cease and the previously certified total should hold.
National results.
Though Gore came in second in the electoral vote, he received 543,895 more popular votes than Bush. Gore failed to win the popular vote in his home state, Tennessee, which both he and his father had represented in the Senate, making him the first major-party presidential candidate to have lost his home state since George McGovern lost South Dakota in 1972. Bush lost in Connecticut, the state of his birth. Bush is also the first Republican in American history to win the presidency without winning Vermont or Illinois, the second Republican to win the presidency without winning California (James A. Garfield in 1880 was the first), and the only winning Republican not to receive any electoral votes from California (Garfield received one vote in 1880). 
'"Source (Electoral and Popular Vote): Federal Elections Commission Electoral and Popular Vote Summary
(a) "One faithless elector from the District of Columbia, Barbara Lett-Simmons, abstained from voting in protest of the District's lack of voting representation in the United States Congress. (D.C. has a non-voting delegate to Congress.) She had been expected to vote for Gore/Lieberman. 
(b) results were Bush 18,075 (51.6%), Gore 16,549 (47.2%), and Browne 420 (1.2%).
State results.
Data comes from http://www.fec.gov/pubrec/2000presgeresults.htm, a U.S. Government document.
Aftermath.
Post recount.
After Florida was decided and Gore conceded, Texas Governor George W. Bush became the President-elect and began forming his transition committee. In a speech on December 13, in the Texas House of Representatives chamber, Bush stated he was reaching across party lines to bridge a divided America, saying, "the President of the United States is the President of every single American, of every race, and every background."
On January 6, 2001, a joint session of Congress met to certify the electoral vote. Twenty members of the House of Representatives, most of them Democratic members of the Congressional Black Caucus, rose one-by-one to file objections to the electoral votes of Florida. However, according to an 1877 law, any such objection had to be sponsored by both a representative and a senator. No senator would co-sponsor these objections, deferring to the Supreme Court's ruling. Therefore, Gore, who presided in his capacity as President of the Senate, ruled each of these objections out of order.
Subsequently, the joint session of Congress certified the electoral votes from all 50 states and the District of Columbia. Bush took the oath of office on January 20, 2001. He would serve for the next 8 years. Meanwhile, Gore declined to run for president in 2004 and 2008.
The first independent recount was conducted by The Miami Herald and USA Today. The Commission found that under most recount scenarios, Bush would have won the election, but Gore would have won using the most generous standards.
Ultimately, a media consortium — comprising the New York Times, Washington Post, Wall Street Journal, Tribune Co. (parent of the L.A. Times), Associated Press, CNN, Palm Beach Post and St. Petersburg Times — hired the National Opinion Research Center at the University of Chicago to examine 175,010 ballots that were collected from the entire state, not just the disputed counties that were discounted; these ballots contained undervotes (votes with no choice made for president) and overvotes (votes made with more than one choice marked). Their goal was to determine the reliability and accuracy of the systems used for the voting process. The NORC concluded that if the disputes over the validity of all the ballots statewide in question had been consistently resolved and "any" uniform standard applied, the electoral result would have been reversed and Gore would have won by 107-115 votes if only two of the three coders had to agree on the ballot. When counting ballots wherein all three coders agreed, Gore would have won the most restrictive scenario by 127 votes and Bush would have won the most inclusive scenario by 110 votes.
Subsequent analyses cast further doubt on conclusions that Bush likely would have won anyway, had the U.S. Supreme Court not intervened. An analysis of the NORC data by University of Pennsylvania researcher Steven F. Freeman and journalist Joel Bleifuss concluded that a recount of all uncounted votes using any standard (inclusive, strict, statewide or county by county), Gore would have been the victor Such a statewide review including all uncounted votes was a very real possibility, as Leon County Circuit Court Judge Terry Lewis, whom the Florida Supreme Court had assigned to oversee the statewide recount, had scheduled a hearing for December 13 (mooted by the U.S. Supreme Court's final ruling on the 12th) to consider the question of including overvotes as well as undervotes, and subsequent statements by Judge Lewis and internal court documents support the liklihood of including overvotes in the recount. Florida State University professor of public policy Lance deHaven-Smith observed that, even considering only undervotes, "under any of the five most reasonable interpretations of the Florida Supreme Court ruling, Gore does, in fact, more than make up the deficit." Fairness and Accuracy in Reporting's analysis of the NORC study and media coverage of it supports these interpretations and criticizes the coverage of the study by media outlets such as the New York Times and the other media consortium members.
Voting machines.
Because the 2000 presidential election was so close in Florida, the United States government and state governments pushed for election reform to be prepared by the 2004 United States Presidential Election. Many of Florida's year 2000 election night problems stemmed from usability and ballot design factors with voting systems, including the potentially confusing "butterfly ballot". Many voters had difficulties with the paper-based punch card voting machines and were either unable to understand the required process for voting or unable to perform the process. This resulted in an unusual amount of overvote (voting for more candidates than is allowed) and undervotes (voting for fewer than the minimum candidates, including none at all). Many undervotes were potentially caused by either voter error or errors with the punch card paper ballots resulting in hanging, dimpled, or pregnant chad.
A proposed solution to these problems was the installation of modern electronic voting machines. The United States Presidential Election of 2000 spurred the debate about election and voting reform, but it did not end it.
Exit polling and declaration of vote winners.
The Voter News Service's reputation was damaged by its treatment of Florida's presidential vote in 2000. Breaking its own guidelines, VNS called the state as a win for Gore 12 minutes before polls closed in the Florida panhandle. Although most of the state is in the Eastern Time Zone, counties in the Florida panhandle, located in the Central Time Zone, had not yet closed its polls. More seriously, inconsistent polling results caused the VNS to change its call twice, first from Gore to Bush, and then to "too close to call".
Also, charges of media bias were levied against the networks by Republicans. They claimed that the networks called states more quickly for Al Gore than for George W. Bush. Congress held hearings on this matter and the networks claimed to have no intentional bias in their election night reporting. However, a study of the calls made on election night 2000 indicated that states carried by Gore were called more quickly than states won by Bush; however, notable Bush states, like New Hampshire and Florida, were very close, and close Gore states like New Mexico were called late too.
More consequences.
In the aftermath of the election, the Help America Vote Act (HAVA) was passed to help states upgrade their election technology in the hopes of preventing similar problems in future elections. Unfortunately, the electronic voting systems that many states purchased to comply with HAVA actually caused problems in the presidential election of 2004.
Many Democrats blame third party candidate Ralph Nader, claiming he split votes with Gore. Nader received 97,000 votes in Florida (for comparison, there were 111,251 overvotes). Additionally, Nader received 22,000 votes in New Hampshire, where Bush beat Gore by 7,000 votes. Either state would have won the election for Gore. Defenders of Nader, including Dan Perkins, argued that the margin in Florida was small enough that Democrats could blame any number of third-party candidates for the defeat, including Workers World Party candidate Monica Moorehead, who received 1,500 votes. But the controversy with Nader also drained energy from the Democratic party as divisive debate went on in the months leading up to the election. Nader's reputation was hurt by this perception, and may have hindered his goals as an activist. For example, "Mother Jones" wrote, "For evidence of how rank-and-file liberals have turned against Nader, one need look no further than the empire he created. Public Citizen, the organization (Nader) founded in 1971, has a new fundraising problem—its founder. After the election, contributions dropped... When people inquire about Nader's relationship to the organization, Public Citizen sends out a letter that begins with a startling new disclaimer: 'Although Ralph Nader was our founder, he has not held an official position in the organization since 1980 and does not serve on the board. Public Citizen—and the other groups that Mr. Nader founded—act independently.'"
Democratic party strategist and Democratic Leadership Council (DLC) chair Al From expressed a different view. In the January 24, 2001, issue of the DLC's "Blueprint" magazine, he wrote, "I think they're wrong on all counts. The assertion that Nader's marginal vote hurt Gore is not borne out by polling data. When exit pollers asked voters how they would have voted in a two-way race, Bush actually won by a point. That was better than he did with Nader in the race."

Ustaše
The Ustaša – Croatian Revolutionary Movement (, before 1933 it was called Ustaša – Croatian Revolutionary Organization; ; members known collectively as Ustaše, but sometimes anglicised as Ustashe, Ustashas or Ustashi) was a Croatian fascist and terrorist organization which was responsible for the deaths of hundreds of thousands of citizens of Yugoslavia, particularly Serbs, during World War II. The ideology of the movement was a blend of Nazism and Croatian nationalism. The Ustaše supported the creation of a Greater Croatia that would span to the River Drina and to the border of Belgrade. The movement emphasized the need for a racially "pure" Croatia and promoted persecution and genocide against Serbs, Jews and Romani people. Fiercely nationalistic, the Ustaše were also fanatically Catholic. In the Yugoslav political context, they identified Catholicism with Croatian nationalism.""Fiercely nationalistic, the Ustaše were also fanatically Catholic. In the Yugoslav political context, they identified Catholicism with Croatian nationalism..."" Following Croatian nationalism, they declared the Catholic and Muslim faiths as religions of the Croatian people. The Ustaše also saw the Islam of Bosniaks as a religion which "keeps true the blood of Croats."
The movement functioned as a terrorist organization before World War II, but in April 1941, they were appointed to rule a part of Axis-occupied Yugoslavia as the Independent State of Croatia (NDH), which has been described as both an Italian-German quasi-protectorate, and as a puppet state of Nazi Germany. The Ustaše were chiefly responsible for the World War II Holocaust in the NDH. Around three hundred thousand were killed by the NDH government's racial policies, which condemned all Serbs, Jews and Roma to death in the concentration camps, alongside Croat resistance members and political opponents.
When it was founded in 1930, the Ustaše was a nationalist organization that sought to create an independent Croatian state. When the Ustaše came to power in the NDH, a quasi-protectorate established by Fascist Italy and Nazi Germany during World War II, its military wings became the Army of the Independent State of Croatia and the Ustaše militia (). The NDH collaborated with the Italian and German occupation forces in Yugoslavia in fighting an increasingly unsuccessful campaign against the resistance forces, the Yugoslav Partisans, who were recognized in late November 1943 as the military of the Allied Yugoslav state. As German forces withdrew from Yugoslavia in 1944/1945, the Ustaše mostly left the country, some of them remained in SFR Yugoslavia as a resistance group known as Crusaders and large numbers of them were killed without trial by Yugoslav forces (the Partisans) after the end of the war.
Name.
The word "ustaša" (plural: "ustaše") is derived from the intransitive verb "ustati" (Croatian for "rise up").
"" () was a military rank in the Imperial Croatian Home Guard (1868–1918). The same term was the name of Croatian third-class infantry regiments () during World War One 1914–1918.
Another variation of the word "ustati" is "ustanik" (plural: "ustanici") which means an insurgent, or a rebel. The name "ustaša" did not have fascist connotations during their early years in the Kingdom of Yugoslavia as the term "ustat" was itself used in Herzegovina to denote the insurgents from the Herzegovinian rebellion of 1875.
The full original name of the organization appeared in April 1931 as the "Ustaša – Hrvatska revolucionarna organizacija" or UHRO (Ustaša – Croatian revolutionary organization), though in 1933 it was renamed the "Ustaša – Hrvatski revolucionarni pokret" (Ustaša – Croatian revolutionary movement) which it kept until World War II.
Ideology.
Ideological roots.
One of the major ideological influences of the Croatian nationalism of the Ustaše was 19th century Croatian activist Ante Starčević. Starčević was an advocate of Croatian unity and independence and was both anti-Habsburg and anti-Serbian. He envisioned the creation of a Greater Croatia that would include territories inhabited by Bosniaks, Serbs, and Slovenes, considering Bosniaks and Serbs as Croats who had been converted to Islam and Orthodox Christianity while considering the Slovenes "mountain Croats". He argued that the large Serb presence in territories claimed by a Greater Croatia was the result of recent settlement, encouraged settlement by Habsburg rulers, and influx of groups like Vlachs who took up Orthodox Christianity and identified as Serbs. Starčević declared his admiration for Bosniaks because in his view they were Croats who tactically had adopted Islam to preserve the economic and political autonomy of Bosnia and medieval Croatia under the Ottoman Empire.
The Ustaše used Starčević's theories to promote the annexation of Bosnia and Herzegovina to Croatia and recognized Croatia as having two major ethnocultural components: Catholic Croats and Muslim Croats. The Ustaše deliberately sought to represent Starčević as being connected to their views, and falsely asserted that Starčević, as a liberal, never supported human equality or women's equality while portraying him as a racist.
The Ustaše promoted the theories of Dr. Milan Šufflay who is believed to have claimed that Croatia had been "one of the strongest ramparts of Western civilization for many centuries" that he claimed had been lost with its union with Serbia in Yugoslavia in 1918. Šufflay himself had been murdered in Yugoslavia in 1931, allegedly by proponents of the regime, causing an internationally publicized affair.
The Ustaše utilized the 1935 thesis by Reverend Krunoslav Draganović, which claimed that many Roman Catholics in southern Herzegovina had been converted to Orthodox Christianity in the 16th and 17th centuries, to justify a policy of forced conversion of Orthodox Christians in the area to Roman Catholicism.
The Ustaše were heavily influenced by Italian Fascism and Nazism. Ante Pavelić's position of "Poglavnik" was based on the similar positions of "Duce" held by Benito Mussolini and "Führer" by Adolf Hitler. The Ustaše, like fascists, promoted a corporatist economy. Pavelić and the Ustaše were allowed sanctuary in Italy by Mussolini after being exiled from Yugoslavia. Pavelić had been in negotiations with Fascist Italy since 1927 that included advocating a territory-for-sovereignty swap in which he would tolerate Italy annexing its claimed territory in Dalmatia in exchange for Italy supporting the sovereignty of an independent Croatia.
However Mussolini's support of the Ustaše was based on pragmatic maximization of Italian influence in the Balkans. After 1937 with the weakening of French influence in Europe following Germany's remilitarization of the Rhineland, and with the rise of a quasi-fascist government in Yugoslavia under Milan Stojadinović, Mussolini from 1937 to 1939 abandoned support for the Ustase and sought to improve relations Yugoslavia, as he feared that continued hostility towards Yugoslavia would result in Yugoslavia joining the German sphere of influence. However the collapse of the quasi-fascist Stojadinović regime resulted in Italy restoring its support for the Ustaše and its agenda to promote an independent Croatia broken away from Yugoslavia that was in personal union with Italy. Distrust towards the Ustase grew, Mussolini's son-in-law Count and Italian foreign minister Count Galeazzo Ciano noting in his diary that "The Duce is indignant with Pavelić, because he claims that the Croats are descendants of the Goths. This will have the effect of bringing them into the German orbit."
Nazi Germany initially held no support for an independent Croatia nor the Ustaše and Hitler stressed the importance for a "strong and united Yugoslavia". Nazi officials including Hermann Göring wanted Yugoslavia to be stable and officially neutral during the war to insure that Germany could continue to securely gain Yugoslavia's raw material exports. The Nazis also grew aggravated with the Ustase, such as Reichsfuhrer SS Heinrich Himmler who was dissatisfied with the lack of full compliance by the NDH to the Nazis' agenda of extermination of the Jews, as the Ustaše permitted Jews who converted to Catholicism to be recognized "honourary Croats" and were exempted from persecution.
Political programme and main agendas.
In 1933, the Ustaše presented "The Seventeen Principles" that formed the official ideology of the movement. The Principles stated the uniqueness of the Croatian nation, promoted collective rights over individual rights, and declared that people who were not Croat by "blood" would be excluded from political life. Those peoples considered "undesirables" were subjected to mass murder. The Principles called for the creation of a new economic system that would be neither capitalist nor communist. The Principles emphasized the importance of the Roman Catholic Church and the patriarchial family as means to maintain social order and morality. (The name given by modern historian to this particular aspect of Ustaše ideology varies; "national Catholicism", "political Catholicism" and "Catholic Croatism" have been proposed among others.) In power, the Ustaše banned contraception and tightened laws against blasphemy.
The Ustase accepted that Croats were part of the Dinaric race, but rejected the concept that Croats were primarily a Slavic people and claimed that Croats were primarily the descendents of the stronger Germanic roots with the Goths than Slavic roots.
The Ustaše believed that a government must naturally be strong and authoritarian. The movement opposed parliamentary democracy for being "corrupt" and Marxism and Bolshevism for interfering in family life and the economy and for their materialism. The movement considered political institutions such as political parties and parliaments to be harmful and unnatural.
The Ustaše recognized both Roman Catholicism and Islam as the national religions of the Croatian people but initially rejected Orthodox Christianity as being incompatible with their objectives. Though the Ustase emphasized religious themes, it stressed that duty to the nation took precedence over religious custom. The Ustaše in power banned the use of the expression of "Serbian Orthodox faith" and mandated the use of the expression "Greek-Eastern faith" in its place. The Ustaše persecuted "Old Catholics" who did not recognize papal infallibility. Orthodox Christian churches were closed, destroyed, or plundered during Ustaše rule. The Ustaše altered their stance towards the Orthodox faith in August 1941 when the NDH allowed those Orthodox Serbs who held no political association with Serbia to be permitted to attain Croatian citizenship and be declared an Aryan person. On 2 July 1942 the Croatian Orthodox Church was founded, and Orthodoxy thus became one of Croatia's state religions. The Ustaše attached conditions to citizenship of people of Islamic faith, such as asserting that a Muslim who supported Yugoslavia would not be considered a Croat, nor a citizen but a "Muslim Serb" who could be denied property and imprisoned. The Ustase claimed that such "Muslim Serbs" had to earn Croat status.
The Ustaše persecuted Jews who practiced Judaism but it authorized Jewish converts to Catholicism to be recognized as Croatian citizens and be given honourary Aryan citizenship that allowed them to be reinstated in their jobs that they had lost due to their previous practice of Judaism.
In economics, the Ustaše supported the creation of a corporatist economy. The movement believed that natural rights existed to private property and ownership over small-scale means of production free from state control.
Armed struggle, revenge, and terrorism were glorified by the Ustaše.
History.
Before World War II.
In October 1928, after the assassination of leading Croatian politician Stjepan Radić, Croatian Peasant Party President in the Yugoslav Assembly by radical Montenegrin politician Puniša Račić, a youth group named the Croat Youth Movement was founded by Branimir Jelić at the University of Zagreb. A year later, Ante Pavelić was invited by the 21-year-old Jelić into the organization as a junior member. A related movement, the Domobranski Pokret, which had been the name of the legal Croatian army in Austria-Hungary, began publication of "Hrvatski Domobran", a newspaper dedicated to Croatian national matters. The Ustase sent "Hrvatski Domobran" to the United States to garner support for the Ustase from Croatian Americans. The organization around the Domobran tried to engage with and radicalize moderate Croats, using Radić’s murder to stir up emotions in the country. By 1929, however, two divergent political streams had formed within Croatia: some supported the Pavelić view that only violence could secure Croatia's national interests; however, the Croatian Peasant Party, led then by Vladko Maček, successor to Stjepan Radić, had much greater support among Croats.
Various members of the Croatian Party of Rights contributed to the writing of the "Domobran", until around Christmas 1928 when the newspaper was banned by the authorities of the Kingdom of Serbs, Croats and Slovenes. In January 1929, the King banned all national parties, and the radical wing of the Party of Rights was exiled, among them Ante Pavelić, Gustav Perčec and Branimir Jelić. This group was later joined by several other Croatian exiles.
On 20 April 1929, Pavelić and others co-signed a declaration in Sofia, Bulgaria together with members of the Macedonian National Committee, asserting that they would pursue "their legal activities for the establishment of human and national rights, political freedom and complete independence for both Croatia and Macedonia". Due to this, the Court for the Preservation of the State in Belgrade sentenced Pavelić and Perčec to death on 17 July 1929. The exiles started organizing support for their cause among the Croatian diaspora in Europe, North and South America. In January 1932, they named their revolutionary organization "Ustaša". In November 1932, ten Ustaše led by Andrija Artuković, supported by four local sympathisers, attacked a gendarme outpost at Brušani in the Lika/Velebit area. The goal of attack was to scare Yugoslav authorities. The incident has sometimes been termed the Velebit Uprising.
One of the most important actions of Ustaše was assassination of Yugoslav king Alexander I. Organizer of assassination was Eugen Dido Kvaternik while assassin was Vlado Chernozemski, member of the Internal Macedonian Revolutionary Organization (IMRO). Soon after the assassination, all organizations related to the Ustaše as well as the Hrvatski Domobran, which continued as a civil organization, were banned throughout Europe. Pavelić and Kvaternik were detained in Italy from October 1934 until the end of March 1936. After March 1937, when Italy and Yugoslavia signed a pact of friendship, Ustaše and their activities were banned.
However, not only did these events fail to destroy the Ustaša organization, but it even attracted sympathizers among the Croatian youth, especially among university students. In February 1939, two of these returnees, Mile Budak and Ivan Oršanić, became editors of the newly published magazine "Hrvatski narod" ("The Croatian nation"), which supported the Ustaše ideas of Croatian independence.
World War II.
The Axis Powers invaded Yugoslavia on 6 April 1941. Vladko Maček, the leader of the Croatian Peasant Party (HSS) which was the most influential party in Croatia at the time, rejected German offers to lead the new government. On 10 April the most senior home-based Ustaša, Slavko Kvaternik, took control of the police in Zagreb and in a radio broadcast that day proclaimed the formation of the Independent State of Croatia ("Nezavisna Država Hrvatska", NDH). The name of the state was an attempt to capitalise on the Croat struggle for independence. Maček issued a statement that day, calling on all Croatians to co-operate with the new authorities.
Meanwhile Pavelić and several hundred Ustaše left their camps in Italy for Zagreb, where Pavelić declared new government on 16 April 1941. He accorded himself the title of "Poglavnik" — a Croatian approximation to "Führer" and translating to something like "Headman" in English. Independent State of Croatia was declared on Croatian "ethnic and historical territory" what is today Republic of Croatia (without Istria), Bosnia and Herzegovina, Syrmia and Bay of Kotor. However, a few days after the declaration of independence, the Ustaše were forced to sign the Treaty of Rome where they surrendered part of Dalmatia and Krk, Rab, Korčula, Biograd, Šibenik, Split, Čiovo, Šolta, Mljet and part of Konavle and Bay of Kotor in favor of Italy. "De facto" control over this territory varied for the majority of the war, as the Partisans grew more successful, while the Germans and Italians increasingly exercised direct control over areas of interest. The Germans and the Italians split the NDH into two zones of influence, one in the southwest controlled by the Italians and the other in the northeast controlled by the Germans. As a result, the NDH has been described as 'an Italian-German Quasi-Protectorate'. In September 1943, after Italian capitulation, the NDH annexed the whole territory which was annexed by Italy according to Treaty of Rome.
Ustaše Militia.
The Army of the Independent State of Croatia was composed of enlisted men who did not participate in Ustaše activities. The fanatical Ustaše Militia, however, organised in 1941 into five (later 15) 700-man battalions, two railway security battalions, and the elite Black Legion and Poglavnik Bodyguard Battalion (later Brigade), fought with a merciless tenacity which impressed and appalled friend and foe alike.
On 27 April 1941, a newly formed unit of the Ustaše army killed members of the largely Serbian community of Gudovac, near Bjelovar. Eventually all who opposed and/or threatened the Ustaše were outlawed. The HSS was banned on 11 June 1941, in an attempt by the Ustaše to take their place as the primary representative of the Croatian peasantry. Vladko Maček was sent to the Jasenovac concentration camp, but later released to serve a house arrest sentence due to his popularity among the people. Maček was later again called upon by foreigners to take a stand and oppose the Pavelić government, but refused. In early 1941, Jews and Serbs were ordered to leave certain areas of Zagreb

War of 1812
The War of 1812 was a military conflict fought between the forces of the United States and those of the British Empire. The United States declared war in 1812 for several reasons, including trade restrictions brought about by Britain's ongoing war with France, the impressment of American merchant sailors into the Royal Navy, British support of American Indian tribes against American expansion, outrage over insults to national honour after humiliations on the high seas, and possible American desire to annex Canada. Tied down in Europe until 1814, the British at first used defensive strategy, repelling multiple American invasions of the provinces of Upper and Lower Canada. However, the Americans gained control over Lake Erie in 1813, seized parts of western Ontario, and ended the prospect of an Indian confederacy and an independent Indian state in the Midwest under British sponsorship. In the Southwest, General Andrew Jackson destroyed the military strength of the Creek nation at the Battle of Horseshoe Bend in 1814. With the defeat of Napoleon in 1814 on April 6, the British adopted a more aggressive strategy, sending in three large invasion armies. The British victory at the Battle of Bladensburg in August 1814 allowed them to capture and burn Washington, D.C. American victories in September 1814 and January 1815 repulsed all three British invasions in New York, Baltimore and New Orleans.
The war was fought in three principal theatres. Firstly, at sea, warships and privateers of both sides attacked each other's merchant ships, while the British blockaded the Atlantic coast of the U.S. and mounted large-scale raids in the later stages of the war. Secondly, both land and naval battles were fought on the American–Canadian frontier, which ran along the Great Lakes and Saint Lawrence River. Thirdly, the American South and Gulf Coast also saw major land battles in which the American forces defeated Britain's Indian allies and repulsed a British invasion force at New Orleans.
Both sides invaded each other's territory, but these invasions were unsuccessful or temporary. At the end of the war, both sides occupied parts of the other's land, but these areas were restored by the Treaty of Ghent.
In the United States, victories at the Battle of New Orleans in 1815 and in the Battle of Baltimore of 1814 (which inspired the lyrics of the United States national anthem, "The Star-Spangled Banner") produced a sense of euphoria over a "second war of independence" against Britain. Peace brought an "Era of Good Feelings" in which partisan animosity nearly vanished. Canada also emerged from the war with a heightened sense of national feeling and solidarity, having repelled multiple American invasions. Battles such as the Battle of Queenston Heights and the Battle of Crysler's Farm became iconic for English-speaking Canadians. In Canada, especially Ontario, memory of the war retains national significance, as the invasions were largely perceived by Canadians as an annexation attempt by America seeking to expand US territory. In Canada, numerous ceremonies are scheduled in 2012 to commemorate a Canadian victory. The war is scarcely remembered in Britain today; as it regarded the conflict as sideshow to the much larger Napoleonic Wars raging in Europe. As such it welcomed an era of peaceful relations and trade with the United States.
Reasons for the war.
The United States declared war on Britain for several reasons. 
Honor and the second war of independence.
As Risjord (1961) notes, an unstated but powerful motivation for the Americans was the desire to uphold national honour in the face of what they considered to be British insults (including the "Chesapeake" affair). Brands says, "The other war hawks spoke of the struggle with Britain as a second war of independence; Jackson, who still bore scars from the first war of independence held that view with special conviction. The approaching conflict was about violations of American rights, but was it also vindication of American identity."
Madison often quoted what Benjamin Franklin was noted having said following the Battle of Yorktown: "The War of Revolution is won, but the War for Independence is yet to be fought."
Trade with France.
In 1807, Britain introduced a series of trade restrictions via a series of Orders in Council to impede American trade with France, with which Britain was at war. The United States contested these restrictions as illegal under international law.
The British wanted to reduce American trade with France, regardless of its theoretical right as a neutral. As historian Reginald Horsman explains, "a large section of influential British opinion, both in the government and in the country, thought that America presented a threat to British maritime supremacy."
The American merchant marine had come close to doubling between 1802 and 1810, making it by far the largest neutral fleet. Britain was the largest trading partner, receiving 80% of U.S. cotton and 50% of other U.S. exports. The British public and press were resentful of the growing mercantile and commercial competition. The United States' view was that Britain's restrictions violated its right to trade with others.
Impressment.
During the Napoleonic Wars, the Royal Navy expanded to 175 ships of the line and 600 ships overall, requiring 140,000 sailors to man. While the Royal Navy could man its ships with volunteers in peacetime, it competed in wartime with merchant shipping and privateers for a small pool of experienced sailors and turned to impressment when it could not operate ships with volunteers alone. Britain did not recognize the right of a British subject to relinquish his status as a British subject, emigrate and transfer his national allegiance as a naturalized citizen to any other country. Thus while the United States recognized British-born sailors on American ships as Americans, Britain did not. It was estimated that there were 11,000 naturalized sailors on United States ships in 1805. Secretary of the Treasury Albert Gallatin stated that 9,000 were born in Britain. The Royal Navy went after them by intercepting and searching U.S. merchant ships for deserters. Impressment actions such as the "Leander" Affair and the "Chesapeake"–"Leopard" Affair outraged Americans, because they infringed on national sovereignty and denied America’s ability to naturalize foreigners. Moreover, a great number of British sailors serving as naturalized Americans on U.S. ships were, in fact, Irish. An investigation by Captain Isaac Chauncey in 1808 found that 58% of the sailors based in New York City were either naturalized citizens or recent immigrants, the majority of foreign sailors (134 of 150) being from Britain. Moreover, eighty of the 134 British sailors were Irish.
The United States believed that British deserters had a right to become United States citizens. Britain did not recognize naturalized United States citizenship, so in addition to recovering deserters, it considered United States citizens born British liable for impressment. Aggravating the situation was the widespread use of forged identity papers by sailors. This made it all the more difficult for the Royal Navy to distinguish Americans from non-Americans and led it to impress some Americans who had never been British. (Some gained freedom on appeal.) American anger at impressment grew when British frigates stationed themselves just outside U.S. harbours in view of U.S. shores and searched ships for contraband and impressed men in U.S. territorial waters. "Free trade and sailors' rights" was a rallying cry for the United States throughout the conflict.
British support for Indian raids.
The Northwest Territory, comprising the modern states of Ohio, Indiana, Illinois, Michigan, and Wisconsin, had been an area of dispute between the Indian Nations and the United States since the passage of the Northwest Ordinance in 1787. The British Empire had ceded the area to the United States in the Treaty of Paris in 1783. The Indian Nations followed Tenskwatawa, the Shawnee Prophet and the brother of Tecumseh. Tenskwatawa had a vision of purifying his society by expelling the "children of the Evil Spirit": the American settlers. Tenskwatawa and Tecumseh formed a confederation of numerous tribes to block American expansion. The British saw the Indian nations as valuable allies and a buffer to its Canadian colonies and provided arms. Attacks on American settlers in the Northwest further aggravated tensions between Britain and the United States. The Confederation's raids hindered American expansion into rich farmlands in the Northwest Territory.
The British had the long-standing goal of creating a large "neutral" Indian state that would cover much of Ohio, Indiana, and Michigan. They made the demand as late as the fall of 1814 at the peace conference, but lost control of western Ontario at key battles on Lake Erie, thus giving the Americans control of the proposed neutral zone.
American expansionism.
American expansion into the Northwest Territory was being obstructed by indigenous leaders like Tecumseh, who were supplied and encouraged by the British. Americans on the western frontier demanded that interference be stopped. Before 1940, some historians held that United States expansionism into Canada was also a reason for the war; however, one subsequent historian wrote, Almost all accounts of the 1811–1812 period have stressed the influence of a youthful band, denominated War Hawks, on Madison's policy. According to the standard picture, these men were a rather wild and exuberant group enraged by Britain's maritime practices, certain that the British were encouraging the Indians and convinced that Canada would be an easy conquest and a choice addition to the national domain. Like all stereotypes, there is some truth in this tableau; however, inaccuracies predominate. First, Perkins has shown that those favoring war were older than those opposed. Second, the lure of the Canadas has been played down by most recent investigators.
Some Canadian historians proposed the notion in the early 20th century, and it survives in public opinion in Ontario. According to Stagg (1981 and 1983), Madison and his advisers believed that conquest of Canada would be easy and that economic coercion would force the British to come to terms by cutting off the food supply for their West Indies colonies. Furthermore, possession of Canada would be a valuable bargaining chip. Stagg suggested that settlers demanded the seizure of Canada not because they wanted the land, but because the British were thought to be arming the Indians and thereby blocking US settlement of the West. As Horsman concluded, "The idea of conquering Canada had been present since at least 1807 as a means of forcing England to change her policy at sea. The conquest of Canada was primarily a means of waging war, not a reason for starting it." Hickey flatly stated, "The desire to annex Canada did not bring on the war." Brown (1964) concluded, "The purpose of the Canadian expedition was to serve negotiation, not to annex Canada." Burt, a Canadian scholar,but also a professor at an American university, agreed, noting that Foster—the British minister to Washington—also rejected the argument that annexation of Canada was a war goal. However, J. C. A. Stagg states that, "...had the War 1812 been a successful military venture, the Madison administration would have been reluctant to have returned occupied Canadian territory to the enemy". Other authors concur, one stating "Expansion was not the only American objective, and indeed not the immediate one. But it was an objective." Another suggests that "Americans harboured 'manifest destiny' ideas of Canadian annexation throughout the nineteenth century."} A third states that "The belief that the United States would one day annex Canada had a continuous existence from the early days of the War of Independence to the War of 1812 [and was a factor of primary importance in bringing on the war."
Upper Canada (Ontario) had mostly been settled by Revolutionary-era exiles from the United States (United Empire Loyalists) or postwar American immigrants. The Loyalists were hostile to union with the United States, while the immigrant settlers were generally uninterested in politics and remained neutral or supported the British (see Laura Secord) during the war. The Canadian colonies were thinly populated and only lightly defended by the British Army. Americans then believed that many men in Upper Canada would rise up and greet an American invading army as liberators. That did not happen. One reason American forces retreated after one successful battle inside Canada was that they could not obtain supplies from the locals. But the Americans thought that the possibility of local support suggested an easy conquest, as former President Thomas Jefferson believed: "The acquisition of Canada this year, as far as the neighborhood of Quebec, will be a mere matter of marching, and will give us the experience for the attack on Halifax, the next and final expulsion of England from the American continent."
Some British officials—and some dissident Americans—charged that the goal of the war was to annex part of Canada, but they did not specify which part. The states nearest Canada strongly opposed the war.
US political conflict.
While the British government was largely oblivious to the deteriorating North-American situation because of its involvement in a continent-wide European War, the US was in a period of significant political conflict between the Federalist Party (based mainly in the Northeast), which favoured a strong central government and closer ties to Britain, and the Democratic-Republican Party (with its greatest power base in the South and West), which favoured a weak central government, preservation of slavery, expansion into Indian land, and a stronger break with Britain. By 1812, the Federalist Party had weakened considerably, and the Democratic-Republicans, with James Madison completing his first term of office and control of Congress, was in a very strong position to pursue its more aggressive agenda against Britain and attempt to further weaken its Federalist rivals. Throughout the war, support for the US cause would be weak (or sometimes non-existent) in Federalist areas of the Northeast, though after the war, the self-destruction of the Federalists at the Hartford Convention led to broader, retroactive support from all parts of the country.
Declaration of war.
On June 1, 1812, President James Madison sent a message to the Congress recounting American grievances against Great Britain, though not specifically calling for a declaration of war. After Madison's message, the House of Representatives deliberated for four days behind closed doors before voting 79 to 49 (61% in favor) the first declaration of war, and the Senate agreed by 19 to 13 (59% in favor). The conflict began formally on June 18, 1812, when Madison signed the measure into law. This was the first time that the United States had declared war on another nation, and the Congressional vote would prove to be the closest vote to formally declare war in American history. (The Authorization for Use of Military Force Against Iraq Resolution of 1991, while not a formal declaration of war, was a closer vote.) None of the 39 Federalists in Congress voted in favor of the war; critics of war subsequently referred to it as "Mr. Madison's War".
Meanwhile in London on May 11, an assassin killed Prime Minister Spencer Perceval, which resulted in Lord Liverpool coming to power. Liverpool wanted a more practical relationship with the United States. He issued a repeal of the Orders in Council, but the United States was unaware of this, as it took three weeks for the news to cross the Atlantic. In response to the US declaration of war, Isaac Brock issued a proclamation alerting the citizenry in Upper Canada of the state of war and urging all military personnel "to be vigilant in the discharge of their duty" to prevent communication with the enemy and to arrest anyone suspected of helping the Americans.
Course of the war.
Although the outbreak of the war had been preceded by years of angry diplomatic dispute, neither side was ready for war when it came. Britain was heavily engaged in the Napoleonic Wars, most of the British Army was deployed in the Peninsular War (in Portugal and Spain), and the Royal Navy was compelled to blockade most of the coast of Europe. The number of British regular troops present in Canada in July 1812 was officially stated to be 6,034, supported by Canadian militia. Throughout the war, the British Secretary of State for War and the Colonies was the Earl of Bathurst. For the first two years of the war, he could spare few troops to reinforce North America and urged the commander-in-chief in North America (Lieutenant General Sir George Prevost) to maintain a defensive strategy. The naturally cautious Prevost followed these instructions, concentrating on defending Lower Canada at the expense of Upper Canada (which was more vulnerable to American attacks) and allowing few offensive actions.
The United States was not prepared to prosecute a war, for Madison had assumed that the state militias would easily seize Canada and that negotiations would follow. In 1812, the regular army consisted of fewer than 12,000 men. Congress authorized the expansion of the army to 35,000 men, but the service was voluntary and unpopular; it offered poor pay, and there were few trained and experienced officers, at least initially. The militia objected to serving outside their home states, were not open to discipline, and performed poorly against British forces when outside their home states. American prosecution of the war suffered from its unpopularity, especially in New England, where anti-war speakers were vocal. "Two of the Massachusetts members Congress, Seaver and Widgery, were publicly insulted and hissed on Change in Boston; while another, Charles Turner, member for the Plymouth district, and Chief-Justice of the Court of Sessions for that county, was seized by a crowd on the evening of August 3, and kicked through the town." The United States had great difficulty financing its war. It had disbanded its national bank, and private bankers in the Northeast were opposed to the war. The failure of New England to provide militia units or financial support was a serious blow. Threats of secession by New England states were loud, as evidenced by the Hartford Convention. Britain exploited these divisions, blockading only southern ports for much of the war and encouraging smuggling.
On July 12, 1812, General William Hull led an invading American force of about 1,000 untrained, poorly-equipped militia across the Detroit River and occupied the Canadian town of Sandwich (now a neighbourhood of Windsor, Ontario). By August, Hull and his troops (numbering 2,500 with the addition of 500 Canadians) retreated to Detroit, where they surrendered to a force of British regulars, Canadian militia and Native Americans, led by British Major General Isaac Brock and Shawnee leader Tecumseh. The surrender not only cost the United States the village of Detroit, but control over most of the Michigan Territory. Several months later, the U.S. launched a second invasion of Canada, this time at the Niagara peninsula. On October 13, United States forces were again defeated at the Battle of Queenston Heights, where General Brock was killed.
Military and civilian leadership remained a critical American weakness until 1814. The early disasters brought about chiefly by American unpreparedness and lack of leadership drove United States Secretary of War William Eustis from office. His successor, John Armstrong, Jr., attempted a coordinated strategy late in 1813 (with 10,000 men) aimed at the capture of Montreal, but he was thwarted by logistical difficulties, uncooperative and quarrelsome commanders and ill-trained troops. After losing several battles to inferior forces, the Americans retreated in disarray in October 1813.
A decisive use of naval power came on the Great Lakes and depended on a contest of building ships. The U.S. started a rapidly-expanded program of building warships at Sackets Harbor on Lake Ontario, where 3,000 men were recruited, many from New York City, to build 11 warships early in the war. In 1813, the Americans won control of Lake Erie in the Battle of Lake Erie and cut off British and Native American forces in the west from their supply base; they were decisively defeated by General William Henry Harrison's forces on their retreat towards Niagara at the Battle of the Thames in October 1813. Tecumseh, the leader of the tribal confederation, was killed and his Indian coalition disintegrated. While some Natives continued to fight alongside British troops, they subsequently did so only as individual tribes or groups of warriors, and where they were directly supplied and armed by British agents. The Americans controlled western Ontario, and permanently ended the threat of Indian raids based in Canada into the American Midwest, thus achieving a basic war goal. Control of Lake Ontario changed hands several times, with both sides unable and unwilling to take advantage of the temporary superiority.
At sea, the powerful Royal Navy blockaded much of the coastline, though it was allowing substantial exports from New England, which traded with Canada in defiance of American laws. The blockade devastated American agricultural exports, but it helped stimulate local factories that replaced goods previously imported. The American strategy of using small gunboats to defend ports was a fiasco, as the British raided the coast at will. The most famous episode was a series of British raids on the shores of Chesapeake Bay, including an attack on Washington that resulted in the British burning of the White House, the Capitol, the Navy Yard, and other public buildings, in the "Burning of Washington". The embarrassing Burning of Washington led to Armstrong's dismissal as US Secretary of War. The British power at sea was enough to allow the Royal Navy to levy "contributions" on bayside towns in return for not burning them to the ground. The Americans were more successful in ship-to-ship actions. They sent out several hundred privateers to attack British merchant ships; in the first four months of war they captured 219 British merchant ships. British commercial interests were damaged, especially in the West Indies.
After Napoleon abdicated on April 6, 1814, the British could send veteran armies to the United States, but by then the Americans had learned how to mobilize and fight. British General Prevost launched a major invasion of New York State with these veteran soldiers, but the American fleet under Thomas Macdonough gained control of Lake Champlain and the British lost the Battle of Plattsburgh in September 1814. Prevost, blamed for the defeat, sought a court-martial to clear his name, but he died in London awaiting it. A British invasion of Louisiana (unknowingly launched after the Treaty of Ghent was negotiated to end the war) was defeated with very heavy British losses by General Andrew Jackson at the Battle of New Orleans in January 1815. The victory made Jackson a national hero, restored the American sense of honour, and ruined the Federalist party efforts to condemn the war as a failure. With the ratification of the peace treaty in February 1815, the war ended before the U.S. new Secretary of War James Monroe could put his new offensive strategy into effect.
Once Britain and The Sixth Coalition defeated Napoleon in 1814, France and Britain became allies. Britain ended the trade restrictions and the impressment of American sailors, thus removing two more causes of the war. After two years of warfare, the major causes of the war had disappeared. Neither side had a reason to continue or a chance of gaining a decisive success that would compel their opponents to cede territory or advantageous peace terms. As a result of this stalemate, the two countries signed the Treaty of Ghent on December 24, 1814. News of the peace treaty took two months to reach the U.S., during which fighting continued. The war fostered a spirit of national unity and an "Era of Good Feelings" in the U.S., as well as in Canada. It opened a long era of peaceful relations between the United States and the British Empire.
Theatres of war.
Atlantic theatre.
Single-ship actions.
In 1812, Britain's Royal Navy was the world's largest, with over 600 cruisers in commission and some smaller vessels. Although most of these were involved in blockading the French navy and protecting British trade against (usually French) privateers, the Royal Navy nevertheless had 85 vessels in American waters, if all British Navy vessels in North American and the Caribbean are counted. However, the Royal Navy's North American squadron based in Halifax, Nova Scotia, which bore the brunt of the war, numbered one small ship of the line, seven frigates, nine smaller sloops and brigs along with five schooners. By contrast, the United States Navy comprised 8 frigates, 14 smaller sloops and brigs, and no ships of the line. Three of the American frigates were exceptionally large and powerful for their class, larger than any British frigate in North America: whereas the standard British frigate of the time was rated as a 38 gun ship, actually carrying up to 50 guns, with its main battery consisting of 18-pounder guns, the "Constitution", "President", and "United States" were rated as 44-gun ships carrying 56-60 guns with a main battery of 24-pounders.
The British strategy was to protect their own merchant shipping to and from Halifax, Nova Scotia, and the West Indies, and to enforce a blockade of major American ports to restrict American trade. Because of their numerical inferiority, the Americans aimed to cause disruption through hit-and-run tactics, such as the capture of prizes and engaging Royal Navy vessels only under favourable circumstances. Days after the formal declaration of war, however, two small squadrons sailed, including the frigate "President" and the sloop "Hornet" under Commodore John Rodgers, and the frigates "United States" and "Congress", with the brig "Argus" under Captain Stephen Decatur. These were initially concentrated as one unit under Rodgers, and it was his intention to force the Royal Navy to concentrate its own ships to prevent isolated units being captured by his powerful force. Large numbers of American merchant ships were still returning to the United States, and if the Royal Navy was concentrated, it could not watch all the ports on the American seaboard. Rodgers' strategy worked, in that the Royal Navy concentrated most of its frigates off New York Harbor under Captain Philip Broke and allowed many American ships to reach home. However, his own cruise captured only five small merchant ships, and the Americans never subsequently concentrated more than two or three ships together as a unit.
Meanwhile, the "Constitution", commanded by Captain Isaac Hull, sailed from Chesapeake Bay on July 12. On July 17, Broke's British squadron gave chase off New York, but the "Constitution" evaded her pursuers after two days. After briefly calling at Boston to replenish water, on August 19, the "Constitution" engaged the British frigate HMS "Guerriere". After a 35-minute battle, "Guerriere" had been dis-masted and captured and was later burned. The "Constitution" earned the nickname "Old Ironsides" following this battle as many of the British cannon balls were seen to bounce off her hull. Hull returned to Boston with news of this significant victory. On October 25, the "United States", commanded by Captain Decatur, captured the British frigate HMS "Macedonian", which he then carried back to port. At the close of the month, the "Constitution" sailed south, now under the command of Captain William Bainbridge. On December 29, off Bahia, Brazil, she met the British frigate HMS "Java". After a battle lasting three hours, "Java" struck her colours and was burned after being judged unsalvageable. The "Constitution", however, was relatively undamaged in the battle.
The successes gained by the three big American frigates forced Britain to construct five 40-gun, 24-pounder heavy frigates and two "spar-decked" frigates (the 60-gun HMS "Leander" and HMS "Newcastle") and to razee three old 74-gun ships of the line to convert them to heavy frigates. The Royal Navy acknowledged that there were factors other than greater size and heavier guns. The United States Navy's sloops and brigs had also won several victories over Royal Navy vessels of approximately equal strength. While the American ships had experienced and well-drilled volunteer crews, the enormous size of the overstretched Royal Navy meant that many ships were shorthanded and the average quality of crews suffered, and constant sea duties of those serving in North America interfered with their training and exercises.
The capture of the three British frigates stimulated the British to greater exertions. More vessels were deployed on the American seaboard and the blockade tightened. On June 1, 1813, off Boston Harbor, the frigate "Chesapeake", commanded by Captain James Lawrence, was captured by the British frigate HMS "Shannon" under Captain Sir Philip Broke. Lawrence was mortally wounded and famously cried out, "Don't give up the ship! Hold on, men!" Although the "Chesapeake" was only of equal strength to the average British frigate and the crew had mustered together only hours before the battle, the British press reacted with almost hysterical relief that the run of American victories had ended. Notably, this action was by ratio one of the bloodiest contests recorded during this age of sail, with more dead and wounded than HMS "Victory" suffered in four hours of combat at Trafalgar. Captain Lawrence was killed and Captain Broke was so badly wounded that he never again held a sea command.
In January 1813, the American frigate "Essex", under the command of Captain David Porter, sailed into the Pacific in an attempt to harass British shipping. Many British whaling ships carried letters of marque allowing them to prey on American whalers, and nearly destroyed the industry. The "Essex" challenged this practice. She inflicted considerable damage on British interests before she was captured off Valparaiso, Chile by the British frigate HMS "Phoebe" and the sloop HMS "Cherub" on March 28, 1814.
The British 6th-rate "Cruizer"-class brig-sloops did not fare well against the American ship-rigged sloops of war. The "Hornet" and "Wasp" constructed before the war were notably powerful vessels, and the "Frolic" class built during the war even more so (although "Frolic" was trapped and captured by a British frigate and a schooner). The British brig-rigged sloops tended to suffer fire to their rigging far worse than the American ship-rigged sloops, while the ship-rigged sloops could back their sails in action, giving them another advantage in manoeuvring.
Following their earlier losses, the British Admiralty instituted a new policy that the three American heavy frigates should not be engaged except by a ship of the line or smaller vessels in squadron strength. An example of this was the capture of the "President" by a squadron of four British frigates in January 1815. A month later, however, the "Constitution" managed to engage and capture two smaller British warships, HMS "Cyane" and HMS "Levant", sailing in company.
Blockade.
The blockade of American ports later tightened to the extent that most American merchant ships and naval vessels were confined to port. The American frigates "United States" and "Macedonian" ended the war blockaded and hulked in New London, Connecticut. Some merchant ships were based in Europe or Asia and continued operations. Others, mainly from New England, were issued licences to trade by Admiral Sir John Borlase Warren, commander in chief on the American station in 1813. This allowed Wellington's army in Spain to receive American goods and to maintain the New Englanders' opposition to the war. The blockade nevertheless resulted in American exports decreasing from $130 million in 1807 to $7 million in 1814. Most of these were food exports that had gone to Britain or British colonies, which suffered when their supplies were cut off.
The operations of American privateers (some of which belonged to the United States Navy, but most of which were private ventures) were extensive. They continued until the close of the war and were only partially affected by the strict enforcement of convoy by the Royal Navy. An example of the audacity of the American cruisers was the depredations in British home waters carried out by the American sloop "Argus", which was eventually captured off St. David's Head in Wales by the British brig HMS "Pelican" on August 14, 1813. A total of 1,554 vessels were claimed captured by all American naval and privateer vessels, 1,300 of which were captured by privateers. However, insurer Lloyd's of London reported that only 1,175 British ships were taken, 373 of which were recaptured, for a total loss of 802.
As the Royal Navy base that supervised the blockade, Halifax profited greatly during the war. From that base British privateers seized many French and American ships and sold their prizes in Halifax.
The war was the last time the British allowed privateering, since the practice was coming to be seen as politically inexpedient and of diminishing value in maintaining its naval supremacy. It was the swan song of Bermuda's privateers, who had vigorously returned to the practice after American lawsuits had put a stop to it two decades earlier. The nimble Bermuda sloops captured 298 enemy ships. British naval and privateer vessels between the Great Lakes and the West Indies captured 1,593.
Atlantic coast.
Preoccupied in their pursuit of American privateers when the war began, the British naval forces had some difficulty in blockading the entire U.S. coast. The British government, having need of American foodstuffs for its army in Spain, benefited from the willingness of the New Englanders to trade with them, so no blockade of New England was at first attempted. The Delaware River and Chesapeake Bay were declared in a state of blockade on December 26, 1812.
This was extended to the coast south of Narragansett by November 1813 and to the entire American coast on May 31, 1814. In the meantime, illicit trade was carried on by collusive captures arranged between American traders and British officers. American ships were fraudulently transferred to neutral flags. Eventually, the U.S. government was driven to issue orders to stop illicit trading; this put only a further strain on the commerce of the country. The overpowering strength of the British fleet enabled it to occupy the Chesapeake and to attack and destroy numerous docks and harbours.
The blockading fleet in the Chesapeake, based at Bermuda, received increasing numbers of enslaved Americans during 1813, welcomed by Royal Navy officers holding anti-slavery sentiments and, by British government order, treated as free on coming into British hands. In 1814, the British government changed from a policy of passively permitting reception of refugees to one of actively encouraging emigration, imperfectly implemented by Admiral Sir Alexander Cochrane's proclamation of April 2, 1814, and somewhat reminiscent of the offers of freedom during the Revolutionary War. Thousands of enslaved Americans went over to the British with their families during the two years from March 1813, and from May 1814 younger men among the volunteers were recruited into a new Corps of Colonial Marines, initially based on occupied Tangier Island, in the Chesapeake, the Corps joining Royal Marines in September 1814 to become part of the 3rd Battalion Royal and Colonial Marines. They fought for Britain throughout the Atlantic campaign, with praise from commanders, including the Battle of Bladensburg and the attacks on Washington, D.C. and Baltimore. After garrison service in the new Royal Naval Dockyard at Bermuda after the war they were settled in Trinidad in August 1816, where seven hundred of these ex-marines were granted land, organized in villages according to their military companies, in the area since known as The Company Villages. A small number of other freed Americans were recruited into the Second West India regiment. Most of those men who did not enlist were settled with their families in Nova Scotia and New Brunswick by the British, while two hundred from the Gulf of Mexico were settled in Trinidad in 1815.
Maine.
Maine, then part of Massachusetts, was a base for smuggling and illegal trade between the U.S. and the British. Until 1813 the region was generally quiet except for privateer actions near the coast. In September, 1813, there was a notable naval action when the U.S. Navy's brig "Enterprise" fought and captured the Royal Navy brig "Boxer" off Pemaquid Point.
The first British assault came in July, 1814, when Sir Thomas Masterman Hardy took Moose Island (Eastport, Maine) without a shot, with the entire American garrison of Fort Sullivan surrendering. Next, from his base in Halifax, Nova Scotia, in September 1814, Sir John Coape Sherbrooke led 3,000 British troops in the "Penobscot Expedition". In 26 days, he raided and looted Hampden, Bangor, and Machias, destroying or capturing 17 American ships. He won the Battle of Hampden (losing two killed while the Americans lost one killed). Retreating American forces were forced to destroy the frigate "Adams". The British occupied the town of Castine and most of eastern Maine for the rest of the war. The Treaty of Ghent returned this territory to the United States. The British left in April 1815, at which time they took 10,750 pounds obtained from tariff duties at Castine. This money, called the "Castine Fund", was used in the establishment of Dalhousie University, in Halifax, Nova Scotia.
Chesapeake campaign and "The Star-Spangled Banner".
The strategic location of the Chesapeake Bay near America's capital made it a prime target for the British. Starting in March 1813, a squadron under Rear Admiral George Cockburn started a blockade of the bay and raided towns along the bay from Norfolk to Havre de Grace.
On July 4, 1813, Joshua Barney, a Revolutionary War naval hero, convinced the Navy Department to build the Chesapeake Bay Flotilla, a squadron of twenty barges to defend the Chesapeake Bay. Launched in April 1814, the squadron was quickly cornered in the Patuxent River, and while successful in harassing the Royal Navy, they were powerless to stop the British campaign that ultimately led to the "Burning of Washington". This expedition, led by Cockburn and General Robert Ross, was carried out between August 19 and 29, 1814, as the result of the hardened British policy of 1814 (although British and American commissioners had convened peace negotiations at Ghent in June of that year). As part of this, Admiral Warren had been replaced as commander in chief by Admiral Alexander Cochrane, with reinforcements and orders to coerce the Americans into a favourable peace.
Governor-in-chief of British North America Sir George Prevost had written to the Admirals in Bermuda, calling for retaliation for the American sacking of York (now Toronto). A force of 2,500 soldiers under General Ross had just arrived in Bermuda aboard HMS "Royal Oak", three frigates, three sloops and ten other vessels. Released from the Peninsular War by British victory, the British intended to use them for diversionary raids along the coasts of Maryland and Virginia. In response to Prevost's request, they decided to employ this force, together with the naval and military units already on the station, to strike at Washington, D.C.
On August 24, U.S. Secretary of War John Armstrong insisted that the British would attack Baltimore rather than Washington, even when the British army was obviously on its way to the capital. The inexperienced American militia, which had congregated at Bladensburg, Maryland, to protect the capital, was routed in the Battle of Bladensburg, opening the route to Washington. While Dolley Madison saved valuables from the Presidential Mansion, President James Madison was forced to flee to Virginia.
The British commanders ate the supper that had been prepared for the President before they burned the Presidential Mansion; American morale was reduced to an all-time low. The British viewed their actions as retaliation for destructive American raids into Canada, most notably the Americans' burning of York (now Toronto) in 1813. Later that same evening, a furious storm swept into Washington, D.C., sending one or more tornadoes into the city that caused more damage but finally extinguished the fires with torrential rains. The naval yards were set afire at the direction of U.S. officials to prevent the capture of naval ships and supplies. The British left Washington, D.C. as soon as the storm subsided. Having destroyed Washington's public buildings, including the President's Mansion and the Treasury, the British army next moved to capture Baltimore, a busy port and a key base for American privateers. The subsequent Battle of Baltimore began with the British landing at North Point, where they were met by American militia. An exchange of fire began, with casualties on both sides. General Ross was killed by an American sniper as he attempted to rally his troops. The sniper himself was killed moments later, and the British withdrew. The British also attempted to attack Baltimore by sea on September 13 but were unable to reduce Fort McHenry, at the entrance to Baltimore Harbor.
The Battle of Fort McHenry was no battle at all. British guns had range on American cannon, and stood off out of U.S. range, bombarding the fort, which returned no fire. Their plan was to coordinate with a land force, but from that distance coordination proved impossible, so the British called off the attack and left. All the lights were extinguished in Baltimore the night of the attack, and the fort was bombarded for 25 hours. The only light was given off by the exploding shells over Fort McHenry, illuminating the flag that was still flying over the fort. The defence of the fort inspired the American lawyer Francis Scott Key to write a poem that would eventually supply the lyrics to "The Star-Spangled Banner".
None of the actions of the Chesapeake campaign were deemed worthy of a British army medal clasp (Fort Detroit, Chateauguay, Chrysler's Farm being the three clasps for the war), but participants in the attack in Washington were paid prize money by the War Office. In addition, prize-money arising from the booty captured by the expedition in the River Patuxent, at Fort Washington, and Alexandria, between August 22 and 29, 1814 was paid in November 1817. Three companies of Corps of Colonial Marines were among the recipients. A first-class share was worth ₤183 9s 1¾d; a sixth-class share, which was what probably an ordinary marine would receive, was worth ₤1 9s 3½d. A second and final payment came in May 1819. A first-class share was worth ₤42 13s 10¾d; a sixth-class share was worth 9s 1¾d.
Great Lakes and Western Territories.
Invasions of Upper and Lower Canada, 1812.
American leaders assumed that Canada could be easily overrun. Former President Jefferson optimistically referred to the conquest of Canada as "a matter of marching." Many Loyalist Americans had migrated to Upper Canada after the Revolutionary War. There was also significant non-Loyalist American immigration to the area due to the offer of land grants to immigrants, and the US assumed the latter would favour the American cause, but they did not. In prewar Upper Canada, General Prevost was in the unusual position of having to purchase many provisions for his troops from the American side. This peculiar trade persisted throughout the war in spite of an abortive attempt by the US government to curtail it. In Lower Canada, which was much more populous, support for Britain came from the English elite with strong loyalty to the Empire, and from the Canadien elite, who feared American conquest would destroy the old order by introducing Protestantism, Anglicization, republican democracy, and commercial capitalism; and weakening the Catholic Church. The Canadien inhabitants feared the loss of a shrinking area of good lands to potential American immigrants.
In 1812–13, British military experience prevailed over inexperienced American commanders. Geography dictated that operations would take place in the west: principally around Lake Erie, near the Niagara River between Lake Erie and Lake Ontario, and near the Saint Lawrence River area and Lake Champlain. This was the focus of the three-pronged attacks by the Americans in 1812. Although cutting the St. Lawrence River through the capture of Montreal and Quebec would have made Britain's hold in North America unsustainable, the United States began operations first in the western frontier because of the general popularity there of a war with the British, who had sold arms to the Native Americans opposing the settlers.
The British scored an important early success when their detachment at St. Joseph Island, on Lake Huron, learned of the declaration of war before the nearby American garrison at the important trading post at Mackinac Island in Michigan. A scratch force landed on the island on July 17, 1812 and mounted a gun overlooking Fort Mackinac. After the British fired one shot from their gun, the Americans, taken by surprise, surrendered. This early victory encouraged the natives, and large numbers moved to help the British at Amherstburg.
An American army under the command of William Hull invaded Canada on July 12, with his forces chiefly composed of untrained and ill-disciplined militiamen. Once on Canadian soil, Hull issued a proclamation ordering all British subjects to surrender, or "the horrors, and calamities of war will stalk before you." He also threatened to kill any British prisoner caught fighting alongside a native. The proclamation helped stiffen resistance to the American attacks. Hull's army was too weak in artillery and badly supplied to achieve its objectives, and had to fight just to maintain its own lines of communication.
The senior British officer in Upper Canada, Major General Isaac Brock, felt that he should take bold measures to calm the settler population in Canada, and to convince the aboriginals who were needed to defend the region that Britain was strong. He moved rapidly to Amherstburg near the western end of Lake Erie with reinforcements and immediately decided to attack Detroit. Hull, fearing that the British possessed superior numbers and that the Indians attached to Brock's force would commit massacres if fighting began, surrendered Detroit without a fight on August 16. Knowing of British-instigated indigenous attacks on other locations, Hull ordered the evacuation of the inhabitants of Fort Dearborn (Chicago) to Fort Wayne. After initially being granted safe passage, the inhabitants (soldiers and civilians) were attacked by Potowatomis on August 15 after travelling only in what is known as the Battle of Fort Dearborn. The fort was subsequently burned.
Brock promptly transferred himself to the eastern end of Lake Erie, where American General Stephen Van Rensselaer was attempting a second invasion. An armistice (arranged by Prevost in the hope the British renunciation of the Orders in Council to which the United States objected might lead to peace) prevented Brock from invading American territory. When the armistice ended, the Americans attempted an attack across the Niagara River on October 13, but suffered a crushing defeat at Queenston Heights. Brock was killed during the battle. While the professionalism of the American forces would improve by the war's end, British leadership suffered after Brock's death. A final attempt in 1812 by American General Henry Dearborn to advance north from Lake Champlain failed when his militia refused to advance beyond American territory.
In contrast to the American militia, the Canadian militia performed well. French Canadians, who found the anti-Catholic stance of most of the United States troublesome, and United Empire Loyalists, who had fought for the Crown during the American Revolutionary War, strongly opposed the American invasion. However, many in Upper Canada were recent settlers from the United States who had no obvious loyalties to the Crown. Nevertheless, while there were some who sympathized with the invaders, the American forces found strong opposition from men loyal to the Empire.
American Northwest, 1813.
After Hull's surrender of Detroit, General William Henry Harrison was given command of the U.S. Army of the Northwest. He set out to retake the city, which was now defended by Colonel Henry Procter in conjunction with Tecumseh. A detachment of Harrison's army was defeated at Frenchtown along the River Raisin on January 22, 1813. Procter left the prisoners with an inadequate guard, who could not prevent some of his North American aboriginal allies from attacking and killing perhaps as many as sixty Americans, many of whom were Kentucky militiamen. The incident became known as the River Raisin Massacre. The defeat ended Harrison's campaign against Detroit, and the phrase "Remember the River Raisin!" became a rallying cry for the Americans.
In May 1813, Procter and Tecumseh set siege to Fort Meigs in northern Ohio. American reinforcements arriving during the siege were defeated by the natives, but the fort held out. The Indians eventually began to disperse, forcing Procter and Tecumseh to return to Canada. A second offensive against Fort Meigs also failed in July. In an attempt to improve Indian morale, Procter and Tecumseh attempted to storm Fort Stephenson, a small American post on the Sandusky River, only to be repulsed with serious losses, marking the end of the Ohio campaign.
On Lake Erie, American commander Captain Oliver Hazard Perry fought the Battle of Lake Erie on September 10, 1813. His decisive victory ensured American control of the lake, improved American morale after a series of defeats, and compelled the British to fall back from Detroit. This paved the way for General Harrison to launch another invasion of Upper Canada, which culminated in the U.S. victory at the Battle of the Thames on October 5, 1813, in which Tecumseh was killed. Tecumseh's death effectively ended the North American indigenous alliance with the British in the Detroit region. American control of Lake Erie meant the British could no longer provide essential military supplies to their aboriginal allies, who therefore dropped out of the war. The Americans controlled the area during the conflict.
Niagara frontier, 1813.
Because of the difficulties of land communications, control of the Great Lakes and the St. Lawrence River corridor was crucial. When the war began, the British already had a small squadron of warships on Lake Ontario and had the initial advantage. To redress the situation, the Americans established a Navy yard at Sackett's Harbor, New York. Commodore Isaac Chauncey took charge of the large number of sailors and shipwrights sent there from New York; they completed the second warship built there in a mere 45 days. Ultimately, 3,000 men worked at the shipyard, building eleven warships and many smaller boats and transports. Having regained the advantage by their rapid building program, Chauncey and Dearborn attacked York (now called Toronto), the capital of Upper Canada, on April 27, 1813. The Battle of York was an American victory, marred by looting and the burning of the Parliament buildings and a library. However, Kingston was strategically more valuable to British supply and communications along the St. Lawrence. Without control of Kingston, the U.S. navy could not effectively control Lake Ontario or sever the British supply line from Lower Canada.
On May 27, 1813, an American amphibious force from Lake Ontario assaulted Fort George on the northern end of the Niagara River and captured it without serious losses. The retreating British forces were not pursued, however, until they had largely escaped and organized a counteroffensive against the advancing Americans at the Battle of Stoney Creek on June 5. On June 24, with the help of advance warning by Loyalist Laura Secord, another American force was forced to surrender by a much smaller British and native force at the Battle of Beaver Dams, marking the end of the American offensive into Upper Canada. Meanwhile, Commodore James Lucas Yeo had taken charge of the British ships on the lake and mounted a counterattack, which was nevertheless repulsed at the Battle of Sackett's Harbor. Thereafter, Chauncey and Yeo's squadrons fought two indecisive actions, neither commander seeking a fight to the finish.
Late in 1813, the Americans abandoned the Canadian territory they occupied around Fort George. They set fire to the village of Newark (now Niagara-on-the-Lake) on December 15, 1813, incensing the Canadians and politicians in control. Many of the inhabitants were left without shelter, freezing to death in the snow. This led to British retaliation following the Capture of Fort Niagara on December 18, 1813. Early the next morning on December 19, the British and their native allies stormed the neighbouring town of Lewiston, New York, torching homes and buildings and killing about a dozen civilians. As the British were chasing the surviving residents out of town, a small force of Tuscarora natives intervened and stopped the pursuit, buying enough time for the locals to escape to safer ground. It is notable in that the Tuscaroras defended the Americans against their own Iroquois brothers, the Mohawks, who sided with the British. Later, the British attacked and burned Buffalo on December 30, 1813.
In 1814, the contest for Lake Ontario turned into a building race. Eventually, by the end of the year, Yeo had constructed HMS St. Lawrence, a first-rate ship of the line of 112 guns that gave him superiority, but the Engagements on Lake Ontario were an indecisive draw.
St. Lawrence and Lower Canada, 1813.
The British were potentially most vulnerable over the stretch of the St. Lawrence where it formed the frontier between Upper Canada and the United States. During the early days of the war, there was illicit commerce across the river. Over the winter of 1812 and 1813, the Americans launched a series of raids from Ogdensburg on the American side of the river, which hampered British supply traffic up the river. On February 21, Sir George Prevost passed through Prescott on the opposite bank of the river with reinforcements for Upper Canada. When he left the next day, the reinforcements and local militia attacked. At the Battle of Ogdensburg, the Americans were forced to retire.
For the rest of the year, Ogdensburg had no American garrison, and many residents of Ogdensburg resumed visits and trade with Prescott. This British victory removed the last American regular troops from the Upper St. Lawrence frontier and helped secure British communications with Montreal. Late in 1813, after much argument, the Americans made two thrusts against Montreal. The plan eventually agreed upon was for Major General Wade Hampton to march north from Lake Champlain and join a force under General James Wilkinson that would embark in boats and sail from Sackett's Harbor on Lake Ontario and descend the St. Lawrence. Hampton was delayed by bad roads and supply problems and also had an intense dislike of Wilkinson, which limited his desire to support his plan. On October 25, his 4,000-strong force was defeated at the Chateauguay River by Charles de Salaberry's smaller force of -Canadian Voltigeurs and Mohawks. Wilkinson's force of 8,000 set out on October 17, but was also delayed by bad weather. After learning that Hampton had been checked, Wilkinson heard that a British force under Captain William Mulcaster and Lieutenant Colonel Joseph Wanton Morrison was pursuing him, and by November 10, he was forced to land near Morrisburg, about 150 kilometres (90 mi.) from Montreal. On November 11, Wilkinson's rear guard, numbering 2,500, attacked Morrison's force of 800 at Crysler's Farm and was repulsed with heavy losses. After learning that Hampton could not renew his advance, Wilkinson retreated to the U.S. and settled into winter quarters. He resigned his command after a failed attack on a British outpost at Lacolle Mills.
Niagara and Plattsburgh Campaigns, 1814.
By the middle of 1814, American generals, including Major Generals Jacob Brown and Winfield Scott, had drastically improved the fighting abilities and discipline of the army. Their renewed attack on the Niagara peninsula quickly captured Fort Erie. Winfield Scott then gained a victory over an inferior British force at the Battle of Chippawa on July 5. An attempt to advance further ended with a hard-fought but inconclusive battle at Lundy's Lane on July 25.
The outnumbered Americans withdrew but withstood a prolonged Siege of Fort Erie. The British suffered heavy casualties in a failed assault and were weakened by exposure and shortage of supplies in their siege lines. Eventually the British raised the siege, but American Major General George Izard took over command on the Niagara front and followed up only halfheartedly. The Americans lacked provisions, and eventually destroyed the fort and retreated across the Niagara.
Meanwhile, following the abdication of Napoleon, 15,000 British troops were sent to North America under four of Wellington’s ablest brigade commanders. Fewer than half were veterans of the Peninsula and the rest came from garrisons. Prevost was ordered to neutralize American power on the lakes by burning Sackets Harbor, gain naval control of Lake Erie, Lake Ontario and the Upper Lakes, and defend Lower Canada from attack. He did defend Lower Canada but otherwise failed to achieve his objectives. Given the late season he decided to invade New York State. His army outnumbered the American defenders of Plattsburgh, but he was worried about his flanks so he decided he needed naval control of Lake Champlain. On the lake, the British squadron under Captain George Downie and the Americans under Master Commandant Thomas Macdonough were more evenly matched.
On reaching Plattsburgh, Prevost delayed the assault until the arrival of Downie in the hastily completed 36-gun frigate HMS "Confiance". Prevost forced Downie into a premature attack, but then unaccountably failed to provide the promised military backing. Downie was killed and his naval force defeated at the naval Battle of Plattsburgh in Plattsburgh Bay on September 11, 1814. The Americans now had control of Lake Champlain; Theodore Roosevelt later termed it "the greatest naval battle of the war." The successful land defence was led by Alexander Macomb. To the astonishment of his senior officers, Prevost then turned back, saying it would be too hazardous to remain on enemy territory after the loss of naval supremacy. Prevost was recalled and in London, a naval court-martial decided that defeat had been caused principally by Prevost’s urging the squadron into premature action and then failing to afford the promised support from the land forces. Prevost died suddenly, just before his own court-martial was to convene. Prevost's reputation sank to a new low, as Canadians claimed that their militia under Brock did the job and he failed. Recently, however, historians have been more kindly, measuring him not against Wellington but against his American foes. They judge Prevost’s preparations for defending the Canadas with limited means to be energetic, well-conceived, and comprehensive; and against the odds, he had achieved the primary objective of preventing an American conquest.
American West, 1813–14.
The Mississippi River valley was the western frontier of the United States in 1812. The territory acquired in the Louisiana Purchase of 1803 contained almost no U.S. settlements west of the Mississippi except around Saint Louis and a few forts and trading posts. Fort Bellefontaine, an old trading post converted to a U.S. Army post in 1804, served as regional headquarters. Fort Osage, built in 1808 along the Missouri was the western-most U.S. outpost, it was abandoned at the start of the war. Fort Madison, built along the Mississippi in what is now Iowa, was also built in 1808, and had been repeatedly attacked by British-allied Sauk since its construction. In September 1813 Fort Madison was abandoned after it was attacked and besieged by natives, who had support from the British. This was one of the few battles fought west of the Mississippi. Black Hawk played a leadership role.
Little of note took place on Lake Huron in 1813, but the American victory on Lake Erie and the recapture of Detroit isolated the British there. During the ensuing winter, a Canadian party under Lieutenant Colonel Robert McDouall established a new supply line from York to Nottawasaga Bay on Georgian Bay. When he arrived at Fort Mackinac with supplies and reinforcements, he sent an expedition to recapture the trading post of Prairie du Chien in the far west. The Siege of Prairie du Chien ended in a British victory on July 20, 1814.
Earlier in July, the Americans sent a force of five vessels from Detroit to recapture Mackinac. A mixed force of regulars and volunteers from the militia landed on the island on August 4. They did not attempt to achieve surprise, and at the brief Battle of Mackinac Island, they were ambushed by natives and forced to re-embark. The Americans discovered the new base at Nottawasaga Bay, and on August 13, they destroyed its fortifications and a schooner that they found there. They then returned to Detroit, leaving two gunboats to blockade Mackinac. On September 4, these gunboats were taken unawares and captured by British boarding parties from canoes and small boats. This Engagement on Lake Huron left Mackinac under British control.
The British garrison at Prairie du Chien also fought off another attack by Major Zachary Taylor. In this distant theatre, the British retained the upper hand until the end of the war, through the allegiance of several indigenous tribes that received British gifts and arms. In 1814 U.S. troops retreating from the Battle of Credit Island on the upper Mississippi attempted to make a stand at Fort Johnson, but the fort was soon abandoned, along with most of the upper Mississippi valley.
After the U.S. was pushed out of the Upper Mississippi region, they held on to eastern Missouri and the St. Louis area. Two notable battles fought against the Sauk were the Battle of Cote Sans Dessein, in April 1815, at the mouth of the Osage River in the Missouri Territory, and the Battle of the Sink Hole, in May 1815, near Fort Cap au Gris.
At the conclusion of peace, Mackinac and other captured territory was returned to the United States. Fighting between Americans, the Sauk, and other indigenous tribes continued through 1817, well after the war ended in the east.
Southern theatre.
Creek War.
In March 1814, Jackson led a force of Tennessee militia, Choctaw, Cherokee warriors, and U.S. regulars southward to attack the Creek Indians. On March 26, Jackson and General John Coffee decisively defeated the Creek at Horseshoe Bend, killing 800 of 1,000 Creeks at a cost of 49 killed and 154 wounded out of approximately 2,000 American and Cherokee forces. Jackson pursued the surviving Creeks until they surrendered. Most historians consider the Creek War as part of the War of 1812, because the British supported them.
New Orleans.
Andrew Jackson heard reports that the British were organizing ships and armies for a large-scale invasion. The British set up a base at Pensacola, Florida in August 1814; Jackson with 4,000 men took the town in November. Unaware of the Ghent treaty, Andrew Jackson's force moved to New Orleans, Louisiana, in late 1814. Using 1,000 regulars and 3,000 to 4,000 militia, pirates and other fighters, as well as civilians and slaves sent to work on the fortifications, he built strong defences just south of the city, which was north of the Gulf. The 8,000 British regulars under General Edward Pakenham attacked on January 8, 1815. The Battle of New Orleans was an American victory, as the British suffered 2,000 casualties: 291 dead (including Pakenham and his second and third in command); 1262 wounded, and 484 captured or missing. The Americans had 71 casualties: 13 dead, 39 wounded, and 19 missing. It was hailed as a great victory across the U.S., making Jackson a national hero and eventually propelling him to the presidency.
Alabama.
James Wilkinson captured Mobile, Alabama from the Spanish in March 1813, and built fortifications.
In early 1815 the British gave up on New Orleans but moved to attack Mobile. In one of the last military actions of the war, 1,000 British troops won the Battle of Fort Bowyer on February 12, 1815. When news of peace arrived the next day, they abandoned the fort and sailed home.
Postwar fighting.
In May 1815, a band of British-allied Sauk, unaware that the war had ended months before, attacked a small band of U.S. soldiers northwest of St. Louis. Intermittent fighting, primarily with the Sauk, continued in the Missouri Territory well into 1817, although it is unknown if the Sauk were acting on their own or on behalf of British agents. Several uncontacted isolated warships continued fighting well into 1815 and were the last American forces to take offensive action against the British.
The Treaty of Ghent.
Factors leading to the peace negotiations.
By 1814, both sides had achieved their main war goals and were weary of a costly war that offered little but stalemate. They both sent delegations to a neutral site in Ghent, Belgium. The negotiations began in early August and concluded on December 24, when a final agreement was signed; both sides had to ratify it before it could take effect. Meanwhile both sides planned new invasions.
In 1814 the British began blockading New England ports, reducing American foreign trade to a trickle, but hurting British interests in the West Indies and Canada that had depended on that trade. New England was considering secession. But although American privateers found chances of success much reduced, with most British merchantmen now sailing in convoy, privateering continued to prove troublesome to the British, as shown by high insurance rates. British landowners grew weary of high taxes, and colonial interests and merchants called on the government to reopen trade with the U.S. by ending the war.
Negotiations and peace.
As the peace talks opened, the British demanded the creation of an Indian barrier state in the American Northwest Territory (the area from Ohio to Wisconsin), and they demanded that Americans not have any naval forces on the Great Lakes. The U.S. rejected the demands and there was an impasse.
The Prime Minister, Lord Liverpool, aware of growing opposition to wartime taxation and the demands of Liverpool and Bristol merchants to reopen trade with America, realized Britain had little to gain and much to lose from prolonged warfare.
On December 24, 1814 the diplomats in Ghent signed the Treaty of Ghent. The treaty was ratified by the British three days later on December 27 and arrived in Washington on February 17 where it was quickly ratified and went into effect, thus finally ending the war. The terms called for all occupied territory to be returned, the prewar boundary between Canada and the United States to be restored, and the Americans were to gain fishing rights in the Gulf of Saint Lawrence.
The treaty ignored the grievances that led to war. American complaints of Indian raids, impressment and blockades had ended when Britain's war with France ended in 1814, and were not mentioned in the treaty. Mobile and parts of western Florida were not mentioned in the treaty but remained permanently in American possession, despite objections by Spain. Thus, the war ended with no significant territorial losses for either side.
Impressment could have become an issue during Napoleon's reappearance for the Hundred Days, for which Britain remanned her fleet; however, the British did not search American ships for British sailors at Liverpool (even the American official position conceded that they had the right to do in British ports), and when William Eustis, American minister to the Netherlands, complained of the impressment of a seaman off an American ship, the captain responsible was recalled to explain his actions. After the second fall of Napoleon, impressment was largely abandoned.
Losses and compensation.
British losses in the war were about 1,600 killed in action and 3,679 wounded; 3,321 British died from disease. American losses were 2,260 killed in action and 4,505 wounded. While the number of Americans who died from disease is not known, it is estimated that about 15,000 died from all causes directly related to the war. These figures do not include deaths among Canadian militia forces or losses among native tribes.
There have been no estimates of the cost of the American war to Britain, but it did add some £25 million to the national debt. In the U.S., the cost was $105 million, about the same as the cost to Britain. The national debt rose from $45 million in 1812 to $127 million by the end of 1815, although by selling bonds and treasury notes at deep discounts—and often for irredeemable paper money due to the suspension of specie payment in 1814—the government received only $34 million worth of specie.
In addition, at least 3,000 American slaves escaped to the British because of their offer of freedom, the same as they had made in the American Revolution. Many other slaves simply escaped in the chaos of war and achieved their freedom on their own. The British settled some of the newly freed slaves in Nova Scotia. Four hundred freedmen were settled in New Brunswick. The Americans protested that Britain's failure to return the slaves violated the Treaty of Ghent. After arbitration by the Tsar of Russia the British paid $1,204,960 in damages to Washington, which reimbursed the slaveowners.
Memory and historiography.
Popular views.
During the 19th century the popular image of the war in the United States was of an American victory, and in Canada, of a Canadian victory. Each young country saw her self-perceived victory as an important foundation of her growing nationhood. The British, on the other hand, who had been preoccupied by Napoleon's challenge in Europe, paid little attention to what was to them a peripheral and secondary dispute, a distraction from the principal task at hand.
Canadian.
In British North America (which formed the Dominion of Canada in 1867), the War of 1812 was seen by Loyalists as a victory, as they had successfully defended their borders from an American takeover. The outcome gave Empire-oriented Canadians confidence and, together with the postwar "militia myth" that the civilian militia had been primarily responsible rather than the British regulars, was used to stimulate a new sense of Canadian nationalism. John Strachan, the first Anglican bishop of Toronto, created the myth, telling his flock that Upper Canada had been saved from the dangerous republicanism of the American invaders by the heroism of the local citizenry.
A long-term implication of the militia myth—which was false, but remained popular in the Canadian public at least until the First World War—was that Canada did not need a regular professional army. The U.S. Army had done poorly, on the whole, in several attempts to invade Canada, and the Canadians had shown that they would fight bravely to defend their country. But the British did not doubt that the thinly populated territory would be vulnerable in a third war. "We cannot keep Canada if the Americans declare war against us again," Admiral Sir David Milne wrote to a correspondent in 1817.
By the 21st century it was a forgotten war in Britain and Quebec, although still remembered in the rest of Canada, especially Ontario. In a 2009 poll, 37% of Canadians said the war was a Canadian victory, 9% said the U.S. won, 15% called it a draw, and 39%—mainly younger Canadians—said they knew too little to comment.
A February 2012 poll found that in a list of items that could be used to define Canadians' identity, the fact that Canada successfully repelled an American invasion in the War of 1812 places second (25%), only behind the fact that Canada has universal health care (53%).
American.
Today, American popular memory includes the British capture and the burning of Washington in August 1814, which necessitated its extensive renovation. Another memory is the successful American defence of Fort McHenry in September 1814, which inspired the lyrics of the U.S. national anthem, "The Star-Spangled Banner". The successful Captains of the U.S. Navy became popular heroes with plates with the likeness of Decatur, Steward, Hull, and others, becoming popular items. Ironically, many were made in England. The Navy became a cherished institution, lauded for the victories that it won against all odds.
The war was somewhat revitalized in the American popular consciousness as a result of the 1959 song "The Battle of New Orleans".
Historians' views.
Historians have differing and more complex interpretations. Historians agree that ending the war with neither side gaining or losing territory allowed for the peaceful settlement of boundary disputes and for the opening of a permanent era of good will and friendly relations between the U.S. and Canada. The war established distinct national identities for Canada and the United States, with a "newly significant border."
In recent decades the view of the majority of historians has been that the war ended in stalemate, with the Treaty of Ghent closing a war that had become militarily inconclusive. Neither side wanted to continue fighting since the main causes had disappeared and since there were no large lost territories for one side or the other to reclaim by force. Insofar as they see the war's untriumphant resolution as allowing two centuries of peaceful and mutually beneficial intercourse between the U.S., Britain and Canada, these historians often conclude that all three nations were the "real winners" of the War of 1812. These writers often add that the war could have been avoided in the first place by better diplomacy. It is seen as a mistake for everyone concerned because it was badly planned and marked by multiple fiascoes and failures on both sides, as shown especially by the repeated American failure to seize parts of Canada, and the failed British invasions of New Orleans and upstate New York.
However, other scholars hold that the war constituted a British victory and an American defeat. They argue that the British achieved their military objectives in 1812 (by stopping the repeated American invasions of Canada) and that Canada retained her independence of the United States. By contrast, they say, the Americans suffered a defeat when their armies failed to achieve their war goal of seizing part or all of Canada. Additionally, they argue the US lost as it failed to stop impressment, which the British refused to repeal until the end of the Napoleonic Wars, and the US actions had no effect on the orders in council, which were rescinded before the war started.
A second minority view is that both the US and Britain won the war—that is, both achieved their main objectives, while the Indians were the losing party. The British won by losing no territories and achieving their great war goal, the total defeat of Napoleon. U.S. won by (1) securing her honour and successfully resisting a powerful empire once again, thus winning a "second war of independence"; (2) ending the threat of Indian raids and the British plan for a semi-independent Indian sanctuary—thereby opening an unimpeded path for the United States' westward expansion—and (3) stopping the Royal Navy from restricting American trade and impressing American sailors.
Indians as losers.
Historians generally agree that the real losers of the War of 1812 were the Indians (called "First Nations" in Canada). American settlers into the Middle West had been repeatedly blocked and threatened by Indian raids before 1812, and that now came to an end. Throughout the war the British had played on terror of the tomahawks and scalping knives of their Indian allies; it worked especially at Hull's surrender at Detroit. By 1813 Americans had killed Tecumseh and broken his coalition of tribes. Jackson then defeated the enemy Indians in the Southwest. At the peace conference the British demanded an independent Indian state in the Midwest, but by late 1814 the British-Indian alliance had been defeated militarily and the British had to abandon the demand. The withdrawal of British protection gave the Americans a free hand, which resulted in the removal of most of the tribes to Indian Territory (present-day Oklahoma). In that sense according to historian Alan Taylor, the final victory at New Orleans had "enduring and massive consequences." It gave the Americans "continental predominence" while it left the Indians dispossessed, powerless, and vulnerable.
Long-term consequences.
Neither side lost territory in the war, nor did the treaty that ended it address the original points of contention—and yet it changed much between the United States of America and Britain.
The Rush–Bagot Treaty was a treaty between the United States and Britain enacted in 1817 that provided for the demilitarization of the Great Lakes and Lake Champlain, where many British naval arrangements and forts still remained. The treaty laid the basis for a demilitarized boundary and was indicative of improving relations between the United States and Great Britain in the period following the War of 1812. It remains in effect to this day.
The Treaty of Ghent established the "status quo ante bellum"; that is, there were no territorial losses by either side. The issue of impressment was made moot when the Royal Navy, no longer needing sailors, stopped impressment after the defeat of Napoleon. Except for occasional border disputes and the circumstances of the American Civil War, relations between the U.S. and Britain remained generally peaceful for the rest of the 19th century, and the two countries became close allies in the 20th century.
Border adjustments between the U.S. and British North America were made in the Treaty of 1818. A border dispute along the Maine–New Brunswick border was settled by the 1842 Webster–Ashburton Treaty after the bloodless Aroostook War, and the border in the Oregon Territory was settled by splitting the disputed area in half by the 1846 Oregon Treaty.
United States.
The U.S. suppressed the native American resistance on its western and southern borders. The nation also gained a psychological sense of complete independence as people celebrated their "second war of independence." Nationalism soared after the victory at the Battle of New Orleans. The opposition Federalist Party collapsed, and the Era of Good Feelings ensued.
No longer questioning the need for a strong Navy, the U.S. built three new 74-gun ships of the line and two new 44-gun frigates shortly after the end of the war. (Another frigate had been destroyed to prevent it being captured on the stocks.) In 1816, the U.S. Congress passed into law an "Act for the gradual increase of the Navy" at a cost of $1,000,000 a year for eight years, authorizing 9 ships of the line and 12 heavy frigates. The Captains and Commodores of the U.S. Navy became the heroes of their generation in the U.S. Decorated plates and pitchers of Decatur, Hull, Bainbridge, Lawrence, Perry, and Macdonough were made in Staffordshire, England, and found a ready market in the United States. Three of the war heroes used their celebrity to win national office: Andrew Jackson (elected President in 1828 and 1832), Richard Mentor Johnson (elected Vice President in 1836), and William Henry Harrison (elected President in 1840).
New England states became increasingly frustrated over how the war was being conducted and how the conflict was affecting them. They complained that the U.S. government was not investing enough in the states' defences militarily and financially, and that the states should have more control over their militia. The increased taxes, the British blockade, and the occupation of some of New England by enemy forces also agitated public opinion in the states. As a result, at the Hartford Convention (December 1814 – January 1815) Federalist delegates deprecated the war effort and sought more autonomy for the New England states. They did not call for secession but word of the angry anti-war resolutions appeared at the same time that peace was announced and the victory at New Orleans was known. The upshot was that the Federalists were permanently discredited and quickly disappeared as a major political force.
This war enabled thousands of slaves to escape to British lines or ships for freedom, despite the difficulties. The planters' complacency about slave contentment was shocked by their seeing slaves who would risk so much to be free.
British North America (Canada).
A strong hostility to republicanism and American influences permeated western Canada after the war and shaped its policies. Immigration from the U.S. was discouraged, and favour was shown the Anglican church as opposed to the more Americanized Methodist church.
The Battle of York showed the vulnerability of Upper and Lower Canada. In the 1820s, work began on La Citadelle at Quebec City as a defence against the United States. Additionally, work began on the Halifax citadel to defend the port against American attacks. From 1826 to 1832, the Rideau Canal was built to provide a secure waterway not at risk from American cannon fire. To defend the western end of the canal, the British also built Fort Henry at Kingston.
Indigenous nations.
The Native Americans allied to the British lost their cause. The British proposal to create a "neutral" Indian zone in the American West was rejected at the Ghent peace conference and never resurfaced. After 1814 the natives, who lost most of their fur gathering territory, became an undesirable burden to British policymakers who now looked to the United States for markets and raw materials. British agents in the field continued to meet regularly with their former native partners, but they did not supply arms or encouragement and there were no Indian campaigns to stop U.S. expansionism in the Midwest. Abandoned by their powerful sponsor, Great Lakes-area natives ultimately migrated or reached accommodations with the American authorities and settlers. In the Southeast, Indian resistance had been crushed by General Andrew Jackson; as President (1829–37), Jackson systematically expelled the major tribes to reservations west of the Mississippi.
Bermuda.
Bermuda had been largely left to the defences of its own militia and privateers prior to U.S. independence, but the Royal Navy had begun buying up land and operating from there in 1795, as its location was a useful substitute for the lost U.S. ports. It originally was intended to be the winter headquarters of the North American Squadron, but the war saw it rise to a new prominence. As construction work progressed through the first half of the 19th century, Bermuda became the permanent naval headquarters in Western waters, housing the Admiralty and serving as a base and dockyard. The military garrison was built up to protect the naval establishment, heavily fortifying the archipelago that came to be described as the "Gibraltar of the West." Defence infrastructure would remain the central leg of Bermuda's economy until after World War II.
Britain.
The massive ongoing conflict against the French Empire under Napoleon ensured that the War of 1812 was never seen as more than a sideshow to the main event by the British. Britain's blockade of French trade had been entirely successful and the Royal Navy was the world's dominant nautical power (and would remain so for another century). While the land campaigns had contributed to saving Canada, the Royal Navy had shut down American commerce, bottled up the U.S. Navy in port and heavily suppressed privateering. British businesses were demanding peace so that trade could resume. The peace was generally welcomed by the British though there was disquiet at the rapid growth of the U.S. However, the two nations quickly resumed trade after the end of the war and, over time, a growing friendship.

Italy
Italy ( ), officially the Italian Republic (), is a unitary parliamentary republic in Southern Europe. To the north, it borders France, Switzerland, Austria, and Slovenia along the Alps. To the south, it consists of the entirety of the Italian Peninsula, Sicily, Sardinia–the two largest islands in the Mediterranean Sea–and many other smaller islands. The independent states of San Marino and the Vatican City are enclaves within Italy, while Campione d'Italia is an Italian exclave in Switzerland. The territory of Italy covers some and is influenced by a temperate seasonal climate. With 60.8 million inhabitants, it is the fifth most populous country in Europe, and the 23rd most populous in the world.
Rome, the capital of Italy, has for centuries been a political and religious centre of Western civilisation as the capital of the Roman Empire and site of the Holy See. After the decline of the Roman Empire, Italy endured numerous invasions by foreign peoples, from Germanic tribes such as the Lombards and Ostrogoths, to the Byzantines and later, the Normans, among others. Centuries later, Italy became the birthplace of Maritime republics and the Renaissance. Through much of its post-Roman history, Italy was fragmented into numerous city and regional states (such as the Republic of Venice and the Church State), but was unified in 1861. In the late 19th century, through World War I, and to World War II, Italy possessed a colonial empire.
Modern Italy is a democratic republic. It has been ranked as the world's 24th most-developed country and its Quality-of-life Index has been ranked in the world's top ten in 2005. Italy enjoys a very high standard of living, and has a high GDP per capita. It is a founding member of what is now the European Union and part of the Eurozone. Italy is also a member of the G8, G20 and NATO. It has the world's third-largest gold reserves, eighth-largest nominal GDP, tenth highest GDP (PPP) and the sixth highest government budget in the world. It is also a member state of the Organisation for Economic Co-operation and Development, the World Trade Organization, the Council of Europe, the Western European Union and the United Nations. Italy has the world's ninth-largest defence budget and shares NATO's nuclear weapons.
Italy plays a prominent role in European and global military, cultural and diplomatic affairs. The country's European political, social and economic influence make it a major regional power. The country has a high public education level and is a highly globalised nation.
Etymology.
The assumptions on the etymology of the name "Italia" are very numerous and the corpus of the solutions proposed by historians and linguists is very wide. According to one of the more common explanations, the term "Italia", from , was borrowed through Greek from the Oscan "Víteliú", meaning "land of young cattle" ("cf." Lat "vitulus" "calf", Umb "vitlo" "calf"). The bull was a symbol of the southern Italian tribes and was often depicted goring the Roman wolf as a defiant symbol of free Italy during the Social War. Greek historian Dionysius of Halicarnassus states this account together with the legend that Italy was named after Italus, mentioned also by Aristotle and Thucydides.
The name "Italia" originally applied only to a part of what is now Southern Italy – according to Antiochus of Syracuse, the southern portion of the Bruttium peninsula (modern Calabria: province of Reggio, and part of the provinces of Catanzaro and Vibo Valentia). But by his time Oenotria and Italy had become synonymous, and the name also applied to most of Lucania as well. The Greeks gradually came to apply the name "Italia" to a larger region, but it was during the reign of Emperor Augustus (end of the first century BC) that the term was expanded to cover the entire peninsula until the Alps.
History.
Prehistory and antiquity.
Excavations throughout Italy reveal a Neanderthal presence dating back to the Paleolithic period, some 200,000 years ago, modern Humans arrived about 40,000 years ago. The Ancient peoples of pre-Roman Italy – such as the Umbrians, the Latins (from which the Romans emerged), Volsci, Samnites, the Celts and the Ligures which inhabited northern Italy, and many others – were Indo-European peoples; the main historic peoples of non-Indo-European heritage include the Etruscans, the Elymians and Sicani in Sicily and the prehistoric Sardinians.
Between the 17th and the 11th century BC Mycenaean Greeks established contacts with Italy and in the 8th and 7th centuries BC Greek colonies were established all along the coast of Sicily and the southern part of the Italian Peninsula became known as Magna Graecia. Also the Phoenicians established colonies on the coasts of Sardinia and Sicily.
Ancient Rome was at first a small agricultural community founded around the 8th century BC, that grew over the course of the centuries into a colossal empire encompassing the whole Mediterranean Sea, in which Ancient Greek and Roman cultures merged into one civilization. This civilization was so influential that its legacy is profound in the world. Ancient Rome heavily influenced and left its mark in modern government, law, politics, administration, cities, engineering, philosophy, architecture and arts, forming the ground that Western civilization is based upon. In a slow decline since the late 2nd century AD, the empire finally broke into two parts in 395 AD: the Western Roman Empire and the Eastern Roman Empire. The western part – under the pressure of the Franks, the Vandals, the Huns, the Goths and other populations from Eastern Europe – finally dissolved in 476 AD, when the last western Emperor was deposed by the Barbarian chief Odoacer.
Middle Ages.
After the fall of Rome, Italy was conquered by the Germanic Tribe of the Ostrogoths, but in the 6th century the East Roman Emperor Justinian reconquered it. The invasion of another Germanic tribe (the Lombards) late in the same century reduced the Byzantine presence to a strip of land between Ravenna and Rome plus other lands in southern Italy, breaking the unity of the peninsula until 1870.
The Lombard reign of northern and central Italy was absorbed into the Frankish Empire by Charlemagne in the late 8th century. The Frankish kings also helped the formation of the Papal States in central Italy, extending from Rome to Ravenna, although for most of the Middle Ages the Papacy effectively controlled only Latium. The existence of this theocratic state hindered for centuries the unification of the peninsula. Until the 13th century, Italian politics were dominated by the relationship between the German Holy Roman Emperors and the popes, with most of the Italian cities siding for the former ("Ghibellini") or for the latter ("Guelfi") from momentary convenience.
It was during this vacuum of authority that the Italy saw the rise of a peculiar institution, the medieval commune. In the anarchic conditions that often prevailed in medieval Italian city-states, people organised themselves to restore order and disarm the feuding elites. In the 12th century, a league of comuni, the Lombard League, defeated the German emperor Frederick Barbarossa, leading to a process granting effective independence to most of northern and central Italian cities. Despite the devastation of the numerous wars, Italy maintained, especially in the north and center, a relatively developed urban civilization.
During the same period, Italy saw the rise of numerous Maritime Republics, the most notable being Venice, Genoa, Pisa and Amalfi. Heavily involved in the Crusades, they took advantage of political and trading opportunities. Venice and Genoa soon became Europe's main gateways to trade with the East, establishing colonies as far as the Black Sea and often controlling most of the trade with the Byzantine Empire and the Islamic Mediterranean world. The county of Savoy expanded its territory into the peninsula in the late Middle Ages, while Florence developed into a highly organized commercial and financial city-state, becoming for many centuries the European capital of silk, wool, banking and jewelry.
In the south, Byzantine Sicily had become an Islamic emirate in the 9th century, thriving until the Italo-Normans conquered it in the late 11th century together with most of the Lombard and Byzantine states of southern Italy. Through a complex series of events, southern Italy developed as a unified kingdom, first under the House of Hohenstaufen, then under the Capetian House of Anjou and, from the 15th century, the house of Aragon (although Sicily was a separate Aragonese kingdom from the late 13th to the 15th century). In Sardinia, the former Byzantine provinces became independent states known as giudicati, although most of the island was under Genoese or Pisan control until the Aragonese conquered it in the 15th century.
Early Modern.
The Black Death pandemic in 1348 left its mark on Italy by killing one third of the population. However, the recovery from the disaster of the Black Death led to a resurgence of cities, trade and economy which greatly stimulated the successive phases of Humanism and Renaissance, cultural movements both born in the peninsula, and later spread in Europe.
In the 14th and 15th centuries, Northern and upper Central Italy were divided into a number of warring city-states, the rest of the peninsula being occupied by the larger Papal States and Naples. The strongest among these city-states annexed the surrounding territories giving birth to the Signorie, regional states led by merchant families which founded local dynasties. Dominated by merchant oligarchies, they enjoyed a relative freedom and nurtured academic and artistic advancement. Warfare between the states was common, invasion from outside Italy confined to intermittent sorties of Holy Roman Emperors. These wars were primarily fought by armies of mercenaries known as "condottieri", bands of soldiers drawn from around Europe, but especially Germany and Switzerland, led largely by Italian captains.
Decades of fighting eventually saw Florence, Milan and Venice emerge as the dominant players that agreed to the Peace of Lodi in 1454, which saw relative calm brought to the region for the first time in centuries. This peace would hold for the next forty years, and Venice's unquestioned hegemony over the sea also led to unprecedented peace for much of the rest of the 15th century. The Italian Renaissance peaked in the mid-16th century as foreign invasions plunged the region into the turmoil of the Italian Wars. However, the ideas and ideals of the Renaissance endured and even spread into the rest of Europe, setting off the Northern Renaissance, and the English Renaissance. In the meantime, the discovery of the Americas, the new routes to Asia discovered by the Portuguese and the rise of the Ottoman Empire—all factors which eroded the traditional Italian dominance in trade with the East – started the economic decline of the peninsula.
Following the Italian Wars (1494 to 1559), Italy saw a long period of relative peace, first under Habsburg Spain (1559 to 1713) and then under Habsburg Austria (1713 to 1796). The plague repeatedly returned to haunt Italy throughout the 14th to 17th centuries. In the first half of the 17th century, a plague claimed some 1.7 million victims, or about 14% of Italy’s population. As Spain declined in the 17th century, so did its Italian possessions in Naples, Sicily, Sardinia, and Milan. Southern Italy was impoverished, stagnant, and cut off from the mainstream of events in Europe. Despite that, Italy kept making its contribution to the European culture, giving birth to the Baroque Style.
In the 18th century, as a result of the War of Spanish Succession, Austria replaced Spain as the dominant foreign power, while the House of Savoy emerged as a major regional power expanding to Piedmont and Sardinia. In this century, the ideas of the Enlightenment influenced the Italian rulers, paving the way to reforms which started an economic recovery in northern Italy and Tuscany.
During the Napoleonic Wars, the northern and central parts of the country were invaded and later partly annexed to the Empire and partly reorganized as a new Kingdom of Italy—essentially a client state of the French Empire — while the southern half of the peninsula was administered by Joachim Murat, Napoleon's brother-in-law, who was crowned as King of Naples. The 1814 Congress of Vienna restored the situation of the late 18th century, but the ideals of the French Revolution could not be eradicated.
Italian unification and Liberal Italy.
The creation of the Kingdom of Italy was the result of efforts by Italian nationalists and monarchists loyal to the House of Savoy to establish a united state encompassing the entire Italian Peninsula. In the context of the 1848 liberal revolutions that swept through Europe, an unsuccessful war was declared on Austria. The Kingdom of Sardinia again attacked the Austrian Empire in the Second Italian War of Independence of 1859, with the aid of France, resulting in liberating Lombardy.
In 1860–61, Giuseppe Garibaldi led the drive for unification in Naples and Sicily, allowing the Sardinian government led by the Count of Cavour to declare a united Italian kingdom on 17 March 1861. In 1866, Victor Emmanuel II allied with Prussia during the Austro-Prussian War, waging the Third Italian War of Independence which allowed Italy to annex Venetia. Finally, as France during the disastrous Franco-Prussian War of 1870 abandoned its garrisons in Rome, the Savoy rushed to fill the power gap by taking over the Papal States.
The Sardinian Albertine Statute of 1848, extended to the whole Kingdom of Italy in 1861, provided for basic freedoms, but electoral laws excluded the non-propertied and uneducated classes from voting. The government of the new kingdom took place in a framework of parliamentary constitutional monarchy dominated by liberal forces. In 1913, male universal suffrage was adopted. As Northern Italy quickly industrialized, the South and rural areas of North remained underdeveloped and overpopulated, forcing millions of people to migrate abroad, while the Italian Socialist Party constantly increased in strength, challenging the traditional liberal and conservative establishment.
Starting from the last two decades of the 19th century, Italy developed into a colonial power by forcing Somalia, Eritrea and later Libya and the Dodecanese under its rule. During World War I, Italy at first stayed neutral, but in 1915 signed the secret Treaty of London, entering the Entente on the promise of receiving Trento, Trieste, Istria and Dalmatia from the Austro-Hungarian Empire—as well as parts of the Ottoman Empire. During the war, more than 650,000 Italian soldiers died, and the economy collapsed. Under the Peace Treaties of Saint-Germain, Rapallo and Rome, Italy obtained most of the promised territories, including the Hungarian harbour of Fiume, but not Dalmatia (except Zara), allowing nationalists to define the victory as "mutilated".
Fascist regime.
The turbulence that followed the devastation of World War I, inspired by the Russian Revolution, led to turmoil and anarchy. The liberal establishment, fearing a socialist revolution, started to endorse the small National Fascist Party, led by Benito Mussolini. In October 1922 the fascists attempted a coup (the "March on Rome"), supported by king Victor Emmanuel III. Over the next few years, Mussolini banned all political parties and curtailed personal liberties, thus forming a dictatorship.
In 1935, Mussolini invaded Ethiopia, resulting in an international alienation and leading to Italy's withdrawal from the League of Nations. Consequently, Italy allied with Nazi Germany and Empire of Japan and strongly supported Franco in the Spanish civil war. In 1939, Italy occupied Albania, a "de facto" protectorate for decades, and entered World War II in June 1940 on the side of the Axis powers. Mussolini, wanting a quick victory like Hitler's Blitzkriegs in Poland and France, invaded Greece in October 1940, but was forced to accept a humiliating stalemate after a few months. At the same time, after initially conquering British Somalia and parts of Egypt, the Italians saw an allied counter-attack lead to the loss of all their possessions in Africa.
Italy was then invaded by the Allies in July 1943, leading to the collapse of the Fascist regime and the fall of Mussolini. In September 1943, Italy surrendered. The country remained a battlefield for the rest of the war, as the allies were moving up from the south as the north was the base for loyalist Italian fascist and German Nazi forces, fought also by the Italian resistance movement. The hostilities ended on 2 May 1945. Nearly half a million Italians (including civilians) died in the conflict, and the Italian economy had been all but destroyed; per capita income in 1944 was at its lowest point since the beginning of the 20th century.
Italian Republic.
Italy became a republic after a referendum held on 2 June 1946, a day celebrated since as Republic Day. This was also the first time that Italian women were entitled to vote. Victor Emmanuel III's son, Umberto II, was forced to abdicate and exiled. The Republican Constitution was approved on 1 January 1948. Under the Paris Peace Treaties of 1947, most of Venezia Giulia was lost to Yugoslavia and, later, the Free Territory of Trieste was divided between the two states.
Fears in the Italian electorate of a possible Communist takeover proved crucial for the first universal suffrage electoral outcome on 18 April 1948, when the Christian Democrats, under the leadership of Alcide De Gasperi, obtained a landslide victory. Consequently, in 1949 Italy became a member of NATO. The Marshall Plan helped to revive the Italian economy which, until the late 1960s, enjoyed a period of sustained economic growth commonly called the "Economic Miracle". In 1957, Italy was a founding member of the European Economic Community (EEC), which became the European Union (EU) in 1993.
From the late 1960s until the early 1980s, the country experienced the Years of Lead, a period characterized by economic crisis (especially after the 1973 oil crisis), widespread social conflicts and terrorist massacres carried out by opposing extremist groups, with the alleged involvement of US intelligence. The Years of Lead culminated in the assassination of the Christian Democrat leader Aldo Moro in 1978 and in the Bologna railway station massacre in 1980, where 85 people died; these events had deeply affected the whole country.
In the 1980s, for the first time since 1945, two governments were led by non-Christian-Democrat premiers: one liberal (Giovanni Spadolini) and one socialist (Bettino Craxi); the Christian Democrats remained, however, the main government party. During Craxi's government, the economy recovered and Italy became the world's fifth largest industrial nation, gaining entry into the G7 Group. However, as a result of his spending policies, the Italian national debt skyrocketed during the Craxi era, soon passing 100% of the GDP.
In the early 1990s, Italy faced significant challenges, as voters – disenchanted with political paralysis, massive public debt and the extensive corruption system (known as "Tangentopoli") uncovered by the 'Clean Hands' investigation – demanded radical reforms. The scandals involved all major parties, but especially those in the government coalition: the Christian Democrats, who ruled for almost 50 years, underwent a severe crisis and eventually disbanded, splitting up into several factions. The Communists reorganized as a social-democratic force. During the 1990s and the 2000s (decade), centre-right (dominated by media magnate Silvio Berlusconi) and centre-left coalitions alternatively governed the country, which entered a prolonged period of economic stagnation.
Geography.
Italy is located in Southern Europe and comprises the boot-shaped Italian Peninsula and a number of islands including the two largest, Sicily and Sardinia. It lies between latitudes 35° and 47° N, and longitudes 6° and 19° E.
The country's total area is 301,230 km², of which 294,020 km² is land and 7,210 km² is water. Including the islands, Italy has a coastline and border of 7,600 km on the Adriatic, Ionian, Tyrrhenian seas (740 km), and borders shared with France (488 km), Austria (430 km), Slovenia (232 km) and Switzerland (740 km), ; San Marino (39 km) and Vatican City (3.2 km), both enclaves, account for the remainder.
The Apennine Mountains form the peninsula's backbone and the Alps form its northern boundary, where Italy's highest point is located on Mont Blanc (4,810 m/15,782 ft). The Po, Italy's longest river (652 km/405 mi), flows from the Alps on the western border with France and crosses the Padan plain on its way to the Adriatic Sea.
The five largest lakes are, in order of diminishing size: Garda (), Maggiore (, shared with Switzerland), Como (), Trasimeno () and Bolsena ().
The country is situated at the meeting point of the Eurasian Plate and the African Plate, leading to considerable seismic and volcanic activity. There are 14 volcanoes in Italy, four of which are active: Etna (the traditional site of Vulcan’s smithy), Stromboli, Vulcano and Vesuvius. Vesuvius is the only active volcano in mainland Europe and is most famous for the destruction of Pompeii and Herculanum. Several islands and hills have been created by volcanic activity, and there is still a large active caldera, the Campi Flegrei north-west of Naples.
Although the country comprises the Italian peninsula and most of the southern Alpine basin, some of Italy's territory extends beyond the Alpine basin and some islands are located outside the Eurasian continental shelf. These territories are the "comuni" of: Livigno, Sexten, Innichen, Toblach (in part), Chiusaforte, Tarvisio, Graun im Vinschgau (in part), which are all part of the Danube's drainage basin, while the Val di Lei constitutes part of the Rhine's basin and the islands of Lampedusa and Lampione are on the African continental shelf.
Environment.
After its quick industrial growth, Italy took a long time to confront its environmental problems. After several improvements, it now ranks 84th in the world for ecological sustainability. National parks cover about five percent of the country. In the last decade, Italy has become one of the world's leading producers of renewable energy, ranking as the world’s fourth largest holder of installed solar energy capacity and the sixth largest holder of wind power capacity in 2010. Italy is the twelfth largest carbon dioxide producer.
Extensive traffic and congestion in the largest metropolitan areas continue to cause severe environmental and health issues, even if smog levels have decreased dramatically since the 1970s and 1980s, and the presence of smog is becoming an increasingly rarer phenomenon and levels of sulphur dioxide are decreasing.
Many watercourses and coastal stretches have also been contaminated by industrial and agricultural activity, while due to rising water levels, Venice has been regularly flooded throughout recent years. Waste from industrial activity is not always disposed of by legal means and has led to permanent health effects on inhabitants of affected areas, as in the case of the Seveso disaster. The country has also operated several nuclear reactors between 1963 and 1990 but, after the Chernobyl disaster and a referendum on the issue the nuclear program was terminated, a decision that was overturned by the government in 2008, planning to build up to four nuclear power plants with French technology. This was in turn struck down by a referendum following the Fukushima nuclear accident. Deforestation, illegal building developments and poor land-management policies have led to significant erosion all over Italy's mountainous regions, leading to major ecological disasters like the 1963 Vajont Dam flood, the 1998 Sarno and 2009 Messina mudslides.
Climate.
Thanks to the great longitudinal extension of the peninsula and the mostly mountainous inetrnal conformation, the climate of Italy is highly diverse. In most of the inland northern and central regions, the climate ranges from humid subtropical to humid continental and oceanic. In particular, the climate of the Po valley geographical region is mostly continental, with harsh winters and hot summers. The coastal areas of Liguria, Tuscany and most of the South generally fit the Mediterranean climate stereotype (Köppen climate classification Csa). Conditions on peninsular coastal areas can be very different from the interior's higher ground and valleys, particularly during the winter months when the higher altitudes tend to be cold, wet, and often snowy. The coastal regions have mild winters and warm and generally dry summers, although lowland valleys can be quite hot in summer. Average winter temperatures vary from on the Alps to 
Politics.
Italy has been a unitary parliamentary republic since 2 June 1946, when the monarchy was abolished by a constitutional referendum. The President of the Italian Republic ("Presidente della Repubblica"), currently Giorgio Napolitano since 2006, is Italy's head of state. The President is elected for a single seven years mandate by the Parliament of Italy in joint session. Italy has a written democratic constitution, resulting from the work of a Constituent Assembly formed by the representatives of all the anti-fascist forces that contributed to the defeat of Nazi and Fascist forces during the Civil War.
Government.
Italy has a parliamentary government based on a proportional voting system. The parliament is perfectly bicameral: the two houses, the Chamber of Deputies (that meets in Palazzo Montecitorio) and the Senate of the Republic (that meets in Palazzo Madama), have the same powers. The Prime Minister, officially President of the Council of Ministers ("Presidente del Consiglio dei Ministri"), is Italy's head of government. The Prime Minister and the cabinet are appointed by the President of the Republic, but must pass a vote of confidence in Parliament to become in office.
While the office is similar to those in most other parliamentary systems, the Italian prime minister has less authority than some of his counterparts. The prime minister is not authorized to request the dissolution of Parliament or dismiss ministers (that are exclusive prerogatives of the President of the Republic) and must receive a vote of approval from the Council of Ministers—which holds effective executive power—to execute most political activities.
After the resignation of Silvio Berlusconi on 12 November 2011, economist Mario Monti has been appointed as a technocratic Prime Minister. The Italy's four major political parties are the People of Freedom, the Democratic Party, the Northern League and the Italy of Values. During the 2008 general elections these four parties won 590 out of 630 seats available in the Chamber of Deputies and 308 out of 315 seats available in the Senate of the Republic.
Most of the remaining seats were won by minor parties that only contest election in one part of Italy, like the South Tyrolean People's Party and the Movement for Autonomies. However, during the last 3 years, a so-called "Third Pole" emerged, merging the Christian Democrats of UDC with some dissident MPs coming from Mr. Berlusconi's cabinet.
A peculiarity of the Italian Parliament is the representation given to Italian citizens permanently living abroad: 12 Deputies and 6 Senators elected in four distinct overseas constituencies. In addition, the Italian Senate is characterized also by a small number of senators for life, appointed by the President "for outstanding patriotic merits in the social, scientific, artistic or literary field". Former Presidents of the Republic are "ex officio" life senators.
Law and criminal justice.
The Italian judicial system is based on Roman law modified by the Napoleonic code and later statutes. The Supreme Court of Cassation is the highest court in Italy for both criminal and civil appeal cases. The Constitutional Court of Italy ("Corte Costituzionale") rules on the conformity of laws with the constitution and is a post–World War II innovation. Since their appearance in the middle of the 19th century, Italian organized crime and criminal organizations have infiltrated the social and economic life of many regions in Southern Italy, the most notorious of which being the Sicilian Mafia, which would later expand into some foreign countries including the United States. The Mafia receipts may reach 9% of Italy's GDP.
A 2009 report identified 610 comuni which have a strong Mafia presence, where 13 million Italians live and 14.6% of the Italian GDP is produced. The Calabrian 'Ndrangheta, nowadays probably the most powerful crime syndicate of Italy, accounts alone for 3% of the country's GDP. However, at 0.013 per 1,000 people, Italy has only the 47th highest murder rate (in a group of 62 countries) and the 43rd highest number of rapes per 1,000 people in the world (in a group of 65 countries), relatively low figures among developed countries.
Foreign relations.
Italy is a founding member of the European Community, now the European Union (EU), and of the North Atlantic Treaty Organization (NATO). Italy was admitted to the United Nations in 1955, and it is a member and strong supporter of a wide number of international organizations, such as the Organisation for Economic Co-operation and Development (OECD), the General Agreement on Tariffs and Trade/World Trade Organization (GATT/WTO), the Organization for Security and Co-operation in Europe (OSCE), the Council of Europe, and the Central European Initiative. Its recent turns in the rotating presidency of international organisations include the Conference for Security and Co-operation in Europe (CSCE), the forerunner of the OSCE, in 1994; G8; and the EU in 2009 and from July to December 2003.
Italy strongly supports multilateral international politics, endorsing the United Nations and its international security activities. Italy deployed troops in support of UN peacekeeping missions in Somalia, Mozambique, and East Timor and provides support for NATO and UN operations in Bosnia, Kosovo and Albania. Italy deployed over 2,000 troops in Afghanistan in support of Operation Enduring Freedom (OEF) from February 2003. Italy still supports international efforts to reconstruct and stabilize Iraq, but it has withdrawn its military contingent of some 3,200 troops as of November 2006, maintaining only humanitarian operators and other civilian personnel.
In August 2006 Italy deployed about 2,450 troops in Lebanon for the United Nations' peacekeeping mission UNIFIL.
Military.
The Italian Army, Navy, Air Force and Gendarmerie collectively form the Italian armed forces, under the command of the Supreme Defence Council, presided over by the President of the Italian Republic. From 2005, military service is entirely voluntary. In 2010, the Italian military had 293,202 personnel on active duty, of which 114,778 in the national gendarmerie. Total Italian military spending in 2010 ranked tenth in the world, standing at $35.8 billion, equal to 1.7% of national GDP. As part of NATO's nuclear sharing strategy Italy also hosts 90 United States nuclear bombs, located in the Ghedi and Aviano air bases.
The Italian Army is the national ground defense force, numbering 109,703 in 2008. Its best-known combat vehicles are the Dardo infantry fighting vehicle, the Centauro tank destroyer and the Ariete tank, and among its aircraft the Mangusta attack helicopter, recently deployed in UN missions. It also has at its disposal a large number of Leopard 1 and M113 armored vehicles.
The Italian Navy in 2008 had 35,200 active personnel with 85 commissioned ships and 123 aircraft. It is now equipping itself with a bigger aircraft carrier, (the "Cavour"), new destroyers, submarines and multipurpose frigates. In modern times the Italian Navy, being a member of the NATO, has taken part in many coalition peacekeeping operations around the world.
The Italian Air Force in 2008 had a strength of 43,882 and operated 585 aircraft, including 219 combat jets and 114 helicopters. As a stopgap and as replacement for leased Tornado ADV interceptors, the AMI has leased 30 F-16A Block 15 ADF and four F-16B Block 10 Fighting Falcons, with an option for more. The coming years also will see the introduction of 121 EF2000 Eurofighter Typhoons, replacing the leased F-16 Fighting Falcons. Further updates are foreseen in the Tornado IDS/IDT and AMX fleets. A transport capability is guaranteed by a fleet of 22 C-130Js and Aeritalia G.222s of which 12 are being replaced with the newly developed G.222 variant called the C-27J Spartan.
An autonomous corps of the military, the Carabinieri are the gendarmerie and military police of Italy, policing the military and civilian population alongside Italy's other police forces. While the different branches of the Carabinieri report to separate ministries for each of their individual functions, the corps reports to the Ministry of Internal Affairs when maintaining public order and security.
Administrative divisions.
Italy is subdivided into 20 regions ("regioni", singular "regione"), five of these regions having a special autonomous status that enables them to enact legislation on some of their local matters. The country is further divided into 110 provinces ("province") and 8,100 municipalities ("comuni"). There are also 15 metropolitan cities ("città metropolitane"), established in 2009, but this administrative division is not yet operational.
Economy.
Italy has a free market economy characterized by high per capita GDP and low unemployment rates. In 2010, it was the eighth-largest economy in the world and the fourth-largest in Europe in terms of nominal GDP, and the tenth-largest economy in the world and fifth-largest in Europe in terms of PPP. It is a founding member of the G8, the Eurozone and the OECD.
After World War II, Italy was rapidly transformed from an agriculture based economy into one of the world's most industrialized nations and a leading country in world trade and exports. It is a developed country, with the world's 8th highest quality of life in 2005 and the 24th Human Development Index. In spite of the recent global economic crisis, Italian per capita GDP at purchasing power parity remains approximately equal to the EU average, while the unemployment rate (8.5%) stands as one of the EU's lowest. The country is well known for its influential and innovative business economic sector, an industrious and competitive agricultural sector (Italy is the world's largest wine producer), and for its creative and high-quality automobile, industrial, appliance and fashion design.
Italy has a smaller number of global multinational corporations than other economies of comparable size, but there is a large number of small and medium-sized enterprises, notoriously clustered in several industrial districts, which are the backbone of the Italian industry. This has produced a manufacturing sector often focused on the export of niche market and luxury products, that if on one side is less capable to compete on the quantity, on the other side is more capable of facing the competition from China and other emerging Asian economies based on lower labour costs, with higher quality products.
The country was the world's 7th largest exporter in 2009. Italy's closest trade ties are with the other countries of the European Union, with whom it conducts about 59% of its total trade. Its largest EU trade partners, in order of market share, are Germany (12.9%), France (11.4%), and Spain (7.4%). Finally, tourism is one of the fastest growing and profitable sectors of the national economy: with 43.6 million international tourist arrivals and total receipts estimated at $38.8 billion in 2010, Italy is both the fifth most visited country and highest tourism earner in the world.
Despite these important achievements, the Italian economy today suffers from many and relevant problems. After a strong GDP growth of 5–6% per year from the 1950s to the early 1970s, and a progressive slowdown in the 1980s and 1990s, the last decade's average annual growth rates poorly performed at 1.23% in comparison to an average EU annual growth rate of 2.28%. The stagnation in economic growth, and the political efforts to revive it with massive government spending from the 1980s onwards, eventually produced a severe rise in public debt. According to the EU's statistics body Eurostat, Italian public debt stood at 116% of GDP in 2010, ranking as the second biggest debt ratio after Greece (with 126.8%).
However, the biggest chunk of Italian public debt is owned by national subjects, a major difference between Italy and Greece. In addition, Italian living standards have a considerable north-south divide. The average GDP per capita in the north exceeds by far the EU average, while many regions of Southern Italy are dramatically below. Italy has often been referred the "sick man of Europe", characterised by economic stagnation, political instability and problems in pursuing reform programs.
More specifically, Italy suffers from structural weaknesses due to its geographical conformation and the lack of raw materials and energy resources: in 2006 the country imported more than 86% of its total energy consumption (99.7% of the solid fuels, 92.5% of oil, 91.2% of natural gas and 15% of electricity). The Italian economy is weakened by the lack of infrastructure development, market reforms and research investment, and also high public deficit. In the Index of Economic Freedom 2008, the country ranked 64th in the world and 29th in Europe, the lowest rating in the Eurozone. Italy still receives development assistance from the European Union every year. Between 2000 and 2006, Italy received €27.4 billion from the EU.
The country has an inefficient state bureaucracy, low property rights protection and high levels of corruption, heavy taxation and public spending that accounts for about half of the national GDP. In addition, the most recent data show that Italy's spending in R&D in 2006 was equal to 1.14% of GDP, below the EU average of 1.84% and the Lisbon Strategy target of devoting 3% of GDP to research and development activities. According to the Confesercenti, a major business association in Italy, organized crime in Italy represented the "biggest segment of the Italian economy", accounting for €90 billion in receipts and 7% of Italy's GDP.
Infrastructure.
In 2004 the transport sector in Italy generated a turnover of about 119.4 billion euros, employing 935,700 persons in 153,700 enterprises. Regarding the national road network, in 2002 there were of serviceable roads in Italy, including of motorways, state-owned but privately operated by Atlantia. In 2005, about 34,667,000 passenger cars (590 cars per 1,000 people) and 4,015,000 goods vehicles circulated on the national road network.
The national railway network, state-owned and operated by Ferrovie dello Stato, in 2003 totalled of which 69% is electrified, and on which 4,937 locomotives and railcars circulated. The national inland waterways network comprised of navigable rivers and channels in 2002. In 2004 there were approximately 30 main airports (including the two hubs of Malpensa International in Milan and Leonardo Da Vinci International in Rome) and 43 major seaports (including the seaport of Genoa, the country's largest and second largest in the Mediterranean Sea). In 2005 Italy maintained a civilian air fleet of about 389,000 units and a merchant fleet of 581 ships.
Demographics.
Italy has 60,626,442 inhabitants according to 1 January 2011 municipal records ("Anagrafe"). Its population density, at 201/km² (520/sq. mile), is higher than that of most Western European countries. However the distribution of the population is widely uneven. The most densely populated areas are the Po Valley (that accounts for almost a half of the national population) and the metropolitan areas of Rome and Naples, while vast regions such as the Alps and Apennines highlands, the plateaus of Basilicata and the island of Sardinia are very sparsely populated.
The population of Italy almost doubled during the 20th century, but the pattern of growth was extremely uneven due to large-scale internal migration from the rural South to the industrial cities of the North, a phenomenon which happened as a consequence of the Italian economic miracle of the 1950–1960s. In addition, after centuries of net emigration, from the 1980s Italy has experienced large-scale immigration for the first time in modern history. According to the Italian government, there were 4,570,317 foreign residents in Italy as of January 2011.
High fertility and birth rates persisted until the 1970s, after which they start to dramatically decline, leading to rapid population aging. At the end of the 2000s (decade), one in five Italians was over 65 years old. However, thanks mainly to the massive immigration of the last two decades, in recent years Italy experienced a significant growth in birth rates. The total fertility rate has also climbed from an all-time low of 1.18 children per woman in 1995 to 1.41 in 2008.
The TFR is expected to reach 1.6 - 1.8 in 2030
Ethnic groups.
Italy has been a country of mass emigration from the late 19th century until the 1960s. Between 1898 and 1914, the peak years of Italian diaspora, approximately 750,000 Italians emigrated each year. The diaspora concerned more than 25 million Italians and it is considered the biggest mass migration of contemporary times. As a result, today more than 4.1 million Italian-born people are living abroad, while at least 60 million people of full or part Italian ancestry live outside of Italy, most notably in South America, the United States, Australia and Northern Europe.
The postwar economic miracle, ending many decades of poverty and emigration, induced big social changes such as lower birth rates, an aging population and thus a shrinking workforce. Under these circumstances, starting from the late 1970s, Italy became to attract increasing flows of foreign immigrants. The present-day figure of about 4.6 million foreign residents, making up some 7.5% of the total population, include more than half a million children born in Italy to foreign nationals—second generation immigrants, but exclude foreign nationals who have subsequently acquired Italian nationality; this applied to 53,696 people in 2008.
The official figures also exclude illegal immigrants, whose numbers are very difficult to determine; they are estimated to be at least 670,000. Since the fall of the Berlin Wall and, more recently, the 2004 and 2007 enlargements of the European Union, the main waves of migration have originated from former socialist countries of Eastern Europe (especially Romania, Albania, Ukraine and Poland). The second most important area of immigration to Italy has always been the neighbouring North Africa (in particular, Morocco, Egypt and Tunisia), with soaring arrivals as a consequence of the Arab Spring. Furthermore, in recent years, growing migration fluxes from the Far East (notably, China and the Philippines) and Latin America (Ecuador, Peru) have been recorded.
Currently, about one million Romanians (around one tenth of them being Roma) are officially registered as living in Italy, representing thus the most important individual country of origin, followed by Albanians and Moroccans with about 500,000 people each. The number of unregistered Romanians is difficult to estimate, but the Balkan Investigative Reporting Network suggested that in 2007 that there might have been half a million or more. Overall, at the end of 2000s (decade) the foreign born population of Italy was from: Europe (54%), Africa (22%), Asia (16%), the Americas (8%) and Oceania (0.06%). The distribution of immigrants is largely uneven in Italy: 87% of immigrants live in the northern and central parts of the country (the most economically developed areas), while only 13% live in the southern half of the peninsula.
Languages.
Italy's official language is Italian. Ethnologue has estimated that there are about 55 million speakers of the language in Italy and a further 6.7 million outside of the country. However, between 120 and 150 million people use Italian as a second or cultural language, worldwide.
Italian, adopted by the state after the unification of Italy, is based on the Florentine variety of Tuscan and is somewhat intermediate between the Italo-Dalmatian languages and the Gallo-Romance languages. Its development was also influenced by the Germanic languages of the post-Roman invaders.
Italy has numerous dialects spoken all over the country and some Italians cannot speak Italian at all. However, the establishment of a national education system has led to decrease in variation in the languages spoken across the country. Standardisation was further expanded in the 1950s and 1960s thanks to economic growth and the rise of mass media and television (the state broadcaster RAI helped set a standard Italian).
Several linguistic groups are legally recognized, and a number of minority languages have co-official status alongside Italian in various parts of the country. French is co-official in the Valle d’Aosta—although in fact Franco-Provencal is more commonly spoken there. German has the same status in the province of South Tyrol as, in some parts of that province and in parts of the neighbouring Trentino, does Ladin. Slovene is officially recognised in the provinces of Trieste, Gorizia and Udine in Friuli Venezia Giulia.
In these regions official documents are bilingual (trilingual in Ladin communities), or available upon request in either Italian or the co-official language. Traffic signs are also multilingual, except in the Valle d’Aosta where – with the exception of Aosta itself which has retained its Latin form in Italian (as in English) – French toponyms are generally used, attempts to italianise them during the Fascist period having been abandoned. Education is possible in minority languages where such schools are operating.
Religion.
Roman Catholicism is by far the largest religion in the country, although Catholicism is no longer officially the state religion. The proportion of Italians that identify themselves as Roman Catholic is 87.8%, although only about one-third of these described themselves as active members (36.8%). Most Italians believe in God, or a form of a spiritual life force. According to the most recent Eurobarometer Poll 2005: 74% of Italian citizens responded that 'they believe there is a God', 16% answered that 'they believe there is some sort of spirit or life force' and 6% answered that 'they do not believe there is any sort of spirit, God, or life force'.
The Italian Catholic Church is part of the global Roman Catholic Church, under the spiritual leadership of the Pope, curia in Rome, and the Conference of Italian Bishops. In addition to Italy, two other sovereign nations are included in Italian-based dioceses, the enclaves of San Marino and Vatican City. There are 225 dioceses in the Italian Catholic Church, see further in this article and in the article List of the Roman Catholic dioceses in Italy.
Italy has a rich Catholic culture, especially as numerous Catholic saints, martyrs and popes were Italian themselves. Roman Catholicism is the largest religion and denomination in Italy, with around 87.8% of Italians considering themselves Catholic. Italy is also home to the greatest number of cardinals in the world, and is the country with the greatest number of Roman Catholic churches per capita.
Even though the main Christian denomination in Italy is Roman Catholicism, there are relevant minorities of Waldensians, Eastern Orthodox and other Christian churches. In the 20th century, Pentecostalism, non-denominational Evangelicalism, were the fastest-growing Protestant churches, as well as Jehovah's Witnesses and Mormonism. Starting from the 1980s, Immigration from Subsaharan Africa has increased the size of Baptist, Anglican, Pentecostal and Evangelical communities in Italy, while immigration from Eastern Europe has established large Eastern Orthodox communities.
At the beginning of 21st century, there were more than 700,000 Eastern Orthodox Christians in Italy, including 180,000 Greek Orthodox, 550,000 Pentecostals and Evangelists (0.8%), of whom 400,000 are members of the Assemblies of God, 235,685 Jehovah's Witnesses (0.4%), 30,000 Waldensians, 25,000 Seventh-day Adventists, 22,000 Mormons, 15,000 Baptists (plus some 5,000 Free Baptists), 7,000 Lutherans, 4,000 Methodists (affiliated with the Waldensian Church).
One of the longest-established religious faiths in Italy is Judaism, Jews having been present in Ancient Rome before the birth of Christ. Italy has seen many influential Italian-Jews, such as Shabbethai Donnolo (died 982), prime minister Luigi Luzzatti, who took office in 1910, and Ernesto Nathan, outstanding mayor of Rome from 1907 to 1913. During the Holocaust, Italy took in many Jewish refugees from Nazi Germany. However, with the creation of the Nazi-backed puppet Italian Social Republic, about 15% of Italy's Jews were killed, despite the Fascist government's refusal to deport Jews to Nazi death camps. This, together with the emigration that preceded and followed the Second World War, has left only a small community of around 45,000 Jews in Italy today.
Rising immigration has been accompanied by an increase in non-Christian faiths. In 2009, there were 1.0 million Muslims in Italy forming 1.6 percent of population, although only 50,000 hold Italian citizenship. Independent estimates put the Islamic population in Italy anywhere from 0.8 million to 1.5 million. There are more than 200,000 followers of faiths originating in the Indian subcontinent with some 70,000 Sikhs with 22 gurdwaras across the country, 70,000 Hindus, and 50,000 Buddhists. There are an estimated some 4,900 Bahá'ís in Italy in 2005.
Education.
Education in Italy is free and mandatory from ages six to sixteen, and consists five stages: kindergarten ("scuola dell'infanzia"), primary school ("scuola primaria"), lower secondary school ("scuola secondaria di primo grado"), upper secondary school ("scuola secondaria di secondo grado") and university ("università").
Italy hosts a broad variety of universities, colleges and academies. Founded in 1088, the University of Bologna is likely the oldest in the world. In 2009, the University of Bologna is, according to The Times, the only Italian college in the top 200 World Universities. Milan's Bocconi University has been ranked among the top 20 best business schools in the world by The Wall Street Journal international rankings, especially thanks to its M.B.A. program, which in 2007 placed it no. 17 in the world in terms of graduate recruitment preference by major multinational companies. Bocconi was also ranked by Forbes as the best worldwide in the specific category Value for Money. In May 2008, Bocconi overtook several traditionally top global business schools in the Financial Times Executive education ranking, reaching no. 5 in Europe and no. 15 in the world. 
Other top universities and polytechnics include the Polytechnic University of Turin, the Politecnico di Milano (which in 2011 was ranked as the 48th best technical university in the world by QS World University Rankings.), the University of Rome La Sapienza (which in 2005 was Europe's 33rd best university, and ranks amongst Europe's 50 and the world's 150 best colleges) and the University of Milan (whose research and teaching activities have developed over the years and have received important international recognitions. The University is the only Italian member of the League of European Research Universities (LERU), a prestigious group of twenty research-intensive European Universities. It also been awarded ranking positions as such: -1st in Italy and 7th in Europe (The Leiden Ranking – Universiteit Leiden).
According to National Science Indicators (1981–2002), a database produced by Research Services Group containing listings of output and citation statistics for more than 90 countries, Italy has an above-average output of scientific papers (in terms of number of papers written with at least one author being from Italy) in space science (9.75% of papers in the world being from Italy), mathematics (5.51% of papers in the world), computer science, neurosciences, and physics; the lowest, but still slightly above world-average, output in terms of number of papers produced is recorded in the social sciences, psychology and psychiatry, and economics and business.
Healthcare.
The Italian state runs a universal public healthcare system since 1978. However, healthcare is provided to all citizens and residents by a mixed public-private system. The public part is the "Servizio Sanitario Nazionale", which is organized under the Ministry of Health and administered on a devolved regional basis. Healthcare spending in Italy accounted for more than 9.0% of the national GDP in 2008, slightly above the OECD countries' average of 8.9%. However, Italy ranks as having the world's 2nd best healthcare system, and the world's 3rd best healthcare performance. Italy had the 12th highest worldwide life expectancy in 2010, while, as in many others western countries, seeing an increase in the proportion of overweight and obese people, with 34.2% of Italians self reporting as overweight and 9.8% self reporting as obese. The proportion of daily smokers was 22% in 2008. Smoking in public places including bars, restaurants, night clubs and offices has been restricted to specially ventilated rooms since 2005.
Culture.
Italy did not exist as a state until the country's unification in 1861. Due to this comparatively late unification, and the historical autonomy of the regions that comprise the Italian Peninsula, many traditions and customs that are now recognized as distinctly Italian can be identified by their regions of origin. Despite the political and social distinction of these regions, Italy's contributions to the cultural and historical heritage of Europe and the world remain immense. Italy is home to the greatest number of UNESCO World Heritage Sites (47) to date, and has rich collections of art, culture and literature from many different periods. The country has had a broad cultural influence worldwide, also because numerous Italians emigrated to other places during the Italian diaspora. Furthermore, the nation has, overall, an estimated 100,000 monuments of any sort (museums, palaces, buildings, statues, churches, art galleries, villas, fountains, historic houses and archaeological remains).
Architecture.
Italy has a very broad and diverse architectural style, which cannot be simply classified by period, but also by region, due to Italy's division into several city-states until 1861. However, this has created a highly diverse and eclectic range in architectural designs. Italy is known for its considerable architectural achievements, such as the construction of arches, domes and similar structures during ancient Rome, the founding of the Renaissance architectural movement in the late-14th to 16th century, and being the homeland of Palladianism, a style of construction which inspired movements such as that of Neoclassical architecture, and influenced the designs which noblemen built their country houses all over the world, notably in the UK, Australia and the US during the late-17th to early 20th centuries. Several of the finest works in Western architecture, such as the Colosseum, the Milan Cathedral and Florence cathedral, the Leaning Tower of Pisa and the building designs of Venice are found in Italy.
Italian architecture has also widely influenced the architecture of the world. British architect Inigo Jones, inspired by the designs of Italian buildings and cities, brought back the ideas of Italian Renaissance architecture to 17th century England, being inspired by Andrea Palladio. Additionally, Italianate architecture, popular abroad since the 19th century, was used to describe foreign architecture which was built in an Italian style, especially modelled on Renaissance architecture.
Visual art.
Over the centuries, Italian art has gone through many stylistic changes. Italian painting is traditionally characterized by a warmth of colour and light, as exemplified in the works of Caravaggio and Titian, and a preoccupation with religious figures and motifs. Italian painting enjoyed preeminence in Europe for hundreds of years, from the Romanesque and Gothic periods, and through the Renaissance and Baroque periods, the latter two of which saw fruition in Italy. Other notable artists who fall within these periods include Michelangelo, Leonardo da Vinci, Donatello, Botticelli, Fra Angelico, Tintoretto, Bernini, and Raphael.
Thereafter, Italy was to experience a continual subjection to foreign powers which caused a shift of focus to political matters, leading to its decline as the artistic authority in Europe. Not until 20th century Futurism, primarily through the works of Umberto Boccioni and Giacomo Balla, would Italy recapture any of its former prestige as a seminal place of artistic evolution. Futurism was succeeded by the metaphysical paintings of Giorgio de Chirico, who exerted a strong influence on the Surrealists and generations of artists to follow.
Literature and theatre.
The basis of the modern Italian language was established by the Florentine poet Dante Alighieri, whose greatest work, the Divine Comedy, is considered amongst the foremost literary statements produced in Europe during the Middle Ages. There is no shortage of celebrated literary figures in Italy: Giovanni Boccaccio, Giacomo Leopardi, Alessandro Manzoni, Torquato Tasso, Ludovico Ariosto, and Petrarch, whose best-known vehicle of expression, the sonnet, was invented in Italy.
Prominent philosophers include Giordano Bruno, Marsilio Ficino, Niccolò Machiavelli, and Giambattista Vico. Modern literary figures and Nobel laureates are nationalist poet Giosuè Carducci in 1906, realist writer Grazia Deledda in 1926, modern theatre author Luigi Pirandello in 1936, poets Salvatore Quasimodo in 1959 and Eugenio Montale in 1975, satirist and theatre author Dario Fo in 1997.
Italian theatre can be traced back to the Roman tradition which was heavily influenced by the Greek; as with many other literary genres, Roman dramatists tended to adapt and translate from the Greek. For example, Seneca's "Phaedra" was based on that of Euripides, and many of the comedies of Plautus were direct translations of works by Menander. During the 16th century and on into the 18th century, Commedia dell'arte was a form of improvisational theatre, and it is still performed today. Travelling troupes of players would set up an outdoor stage and provide amusement in the form of juggling, acrobatics, and, more typically, humorous plays based on a repertoire of established characters with a rough storyline, called "canovaccio".
Music.
From folk music to classical, music has always played an important role in Italian culture. Instruments associated with classical music, including the piano and violin, were invented in Italy, and many of the prevailing classical music forms, such as the symphony, concerto, and sonata, can trace their roots back to innovations of 16th and 17th century Italian music.
Italy's most famous composers include the Renaissance composers Palestrina and Monteverdi, the Baroque composers Alessandro Scarlatti, Corelli and Vivaldi, the Classical composers Paganini and Rossini, and the Romantic composers Verdi and Puccini. Modern Italian composers such as Berio and Nono proved significant in the development of experimental and electronic music. While the classical music tradition still holds strong in Italy, as evidenced by the fame of its innumerable opera houses, such as La Scala of Milan and San Carlo of Naples, and performers such as the pianist Maurizio Pollini and the late tenor Luciano Pavarotti, Italians have been no less appreciative of their thriving contemporary music scene.
Italy is widely known for being the birthplace of opera. Italian opera was believed to have been founded in the early 17th century, in Italian cities such as Mantua and Venice. Later, works and pieces composed by native Italian composers of the 19th and early 20th centuries, such as Rossini, Bellini, Donizetti, Verdi and Puccini, are amongst the most famous operas ever written and today are performed in opera houses across the world. La Scala operahouse in Milan is also renowned as one of the best in the world. Famous Italian opera singers include Enrico Caruso and Alessandro Bonci.
Introduced in the early 1920s, jazz took a particularly strong foothold in Italy, and remained popular despite the xenophobic cultural policies of the Fascist regime. Today, the most notable centers of jazz music in Italy include Milan, Rome, and Sicily. Later, Italy was at the forefront of the progressive rock movement of the 1970s, with bands like PFM and Goblin. Italy was also an important country in the development of disco and electronic music, with Italo disco, known for its futuristic sound and prominent usage of synthesizers and drum machines, being one of the earliest electronic dance genres, as well as European forms of disco music aside from Euro disco (which later went on to influence several genres such as Eurodance and Nu-disco).
Producers/songwriters such as Giorgio Moroder, who won three Academy Awards for his music, were highly influential in the development of EDM (electronic dance music). Today, Italian pop music is represented annually with the Sanremo Music Festival, which served as inspiration for the Eurovision song contest, and the Festival of Two Worlds in Spoleto. Singers such as pop diva Mina, classical crossover artist Andrea Bocelli, Grammy winner Laura Pausini, and European chart-topper Eros Ramazzotti have attained international acclaim.
Cinema.
The history of Italian cinema began a few months after the Lumière brothers began motion picture exhibitions. The first Italian film was a few seconds, showing Pope Leo XIII giving a blessing to the camera. The Italian film industry was born between 1903 and 1908 with three companies: the Società Italiana Cines, the Ambrosio Film and the Itala Film. Other companies soon followed in Milan and in Naples. In a short time these first companies reached a fair producing quality, and films were soon sold outside Italy. Cinema was later used by Benito Mussolini, who founded Rome's renowned Cinecittà studio for the production of Fascist propaganda until World War II.
After the war, Italian film was widely recognised and exported until an artistic decline around the 1980s. Notable Italian film directors from this period include Vittorio De Sica, Federico Fellini, Sergio Leone, Pier Paolo Pasolini, Luchino Visconti, Michelangelo Antonioni and Dario Argento. Movies include world cinema treasures such as "La dolce vita", "The Good, the Bad and the Ugly" and "Bicycle Thieves". The mid-1940s to the early 1950s was the heyday of neorealist films, reflecting the poor condition of post-war Italy.
As the country grew wealthier in the 1950s, a form of neorealism known as pink neorealism succeeded, and other film genres, such as sword-and-sandal followed as spaghetti westerns, were popular in the 1960s and 1970s. In recent years, the Italian scene has received only occasional international attention, with movies like "La vita è bella" directed by Roberto Benigni and "Il postino" with Massimo Troisi.
Science.
Through the centuries, Italy has given birth to some notable scientific minds. Amongst them, and perhaps the most famous polymath in history, Leonardo da Vinci made several contributions to a variety of fields including art, biology, and technology. Galileo Galilei was a physicist, mathematician, and astronomer who played a major role in the Scientific Revolution. His achievements include improvements to the telescope and consequent astronomical observations, and support for Copernicanism. The physicist Enrico Fermi, a Nobel prize laureate, was the leader of the team that built the first nuclear reactor and is also noted for his many other contributions to physics, including the co-development of the quantum theory.
A brief overview of some other notable figures includes the astronomer Giovanni Domenico Cassini, who made many important discoveries about the Solar System; the physicist Alessandro Volta, inventor of the electric battery; the mathematicians Lagrange, Fibonacci, and Gerolamo Cardano, whose Ars Magna is generally recognized as the first modern treatment on mathematics, made fundamental advances to the field.
Marcello Malpighi, a doctor and founder of microscopic anatomy; the biologist Lazzaro Spallanzani, who conducted important research in bodily functions, animal reproduction, and cellular theory; the physician, pathologist, scientist, and Nobel laureate Camillo Golgi, whose many achievements include the discovery of the Golgi complex, and his role in paving the way to the acceptance of the Neuron doctrine; and Guglielmo Marconi, who received the Nobel Prize in Physics for the invention of radio.
Sport.
Italy has a long sporting tradition. In numerous sports, both individual and team, Italy has good representation and many successes. The most popular sport is by far football. Basketball and volleyball are the next most popular/played, with Italy having a rich tradition in both. Italy's Squadra Azzurra won the 2006 FIFA World Cup, and is currently the second most successful football team in the world, after Brazil, having won four FIFA World Cups. Italy has also got strong traditions in cycling, tennis, athletics, fencing, winter sports and rugby. Italian Scuderia Ferrari is the oldest surviving team in Grand Prix racing, having competed since 1948, and statistically the most successful Formula One team in history with a record of 15 drivers' championships and 16 constructors' championships.
Fashion and design.
Italian fashion has a long tradition, and is regarded as one of the most important in the world. Milan, Florence and Rome are Italy's main fashion capitals. According to the 2009 Global Language Monitor, Milan was nominated the true fashion capital of the world, even surpassing other major capitals, such as New York, Paris, London and Tokyo, while Rome came 4th. Major Italian fashion labels, such as Gucci, Prada, Versace, Valentino, Armani, Dolce & Gabbana, Missoni, Fendi, Moschino, Max Mara and Ferragamo, to name a few, are regarded as amongst the finest fashion houses in the world. Also, the fashion magazine Vogue Italia, is considered the most important and prestigious fashion magazine in the world.
Italy is also prominent in the field of design, notably interior design, architectural design, industrial design and urban design. The country has produced some well-known furniture designers, such as Gio Ponti and Ettore Sottsass, and Italian phrases such as ""Bel Disegno"" and ""Linea Italiana"" have entered the vocabulary of furniture design. Examples of classic pieces of Italian white goods and pieces of furniture include Zanussi's washing machines and fridges, the "New Tone" sofas by Atrium, and the post-modern bookcase by Ettore Sottsass, inspired by Bob Dylan's song "Stuck Inside of Mobile with the Memphis Blues Again".
Today, Milan and Turin are the nation's leaders in architectural design and industrial design. The city of Milan hosts the FieraMilano, Europe's biggest design fair. Milan also hosts major design and architecture-related events and venues, such as the ""Fuori Salone"" and the Salone del Mobile, and has been home to the designers Bruno Munari, Lucio Fontana, Enrico Castellani and Piero Manzoni
Cuisine.
Modern Italian cuisine has developed through centuries of social and political changes, with roots as far back as the 4th century BCE. Italian cuisine in itself takes heavy influences, including Etruscan, ancient Greek, ancient Roman, Byzantine, and Jewish. Significant changes occurred with the discovery of the New World with the introduction of items such as potatoes, tomatoes, bell peppers and maize, now central to the cuisine but not introduced in quantity until the 18th century. Italian cuisine is noted for its regional diversity, abundance of difference in taste, and is known to be one of the most popular in the world, with influences abroad.
Italian cuisine is characterized by its extreme simplicity, with many dishes having only four to eight ingredients. Italian cooks rely chiefly on the quality of the ingredients rather than on elaborate preparation. Dishes and recipes are often the creation of grandmothers rather than of chefs, which makes many recipes ideally suited for home cooking.
This is one of the main reasons behind the ever increasing popularity of this cuisine, as cooking magazines in foreign countries popularize Italian recipes targeted at the home cook. Ingredients and dishes vary by region. Many dishes that were once regional, however, have proliferated with variations throughout the country.
Cheese, ham and wine are a major part of the cuisine, with many variations and Denominazione di origine controllata (DOC) (regulated appellation) laws. Coffee, specifically espresso, has become important in Italian cuisine.

Japanese American internment
Japanese-American internment was the relocation and internment by the United States government in 1942 of about 110,000 Japanese Americans and Japanese who lived along the Pacific coast of the United States to camps called "War Relocation Camps," in the wake of Imperial Japan's attack on Pearl Harbor. The internment of Japanese Americans was applied unequally throughout the United States. All who lived on the West Coast of the United States were interned, while in Hawaii, where the 150,000-plus Japanese Americans composed over one-third of the population, an estimated 1,200 to 1,800 were interned. Of those interned, 62% were American citizens.
President Franklin D. Roosevelt authorized the internment with Executive Order 9066, issued February 19, 1942, which allowed local military commanders to designate "military areas" as "exclusion zones," from which "any or all persons may be excluded." This power was used to declare that all people of Japanese ancestry were excluded from the entire Pacific coast, including all of California and much of Oregon, Washington and Arizona, except for those in internment camps. In 1944, the Supreme Court upheld the constitutionality of the exclusion orders, while noting that the provisions that singled out people of Japanese ancestry were a separate issue outside the scope of the proceedings. The United States Census Bureau assisted the internment efforts by providing confidential neighborhood information on Japanese Americans. The Bureau's role was denied for decades, but was finally proven in 2007.
In 1988, Congress passed and President Ronald Reagan signed legislation which apologized for the internment on behalf of the U.S. government. The legislation said that government actions were based on "race prejudice, war hysteria, and a failure of political leadership". The U.S. government eventually disbursed more than $1.6 billion in reparations to Japanese Americans who had been interned and their heirs.
Historical context.
In the first half of the 20th century, California experienced a wave of anti-Japanese prejudice, in part because of the concentration of new immigrants. This was distinct from the Japanese American experience in the broader United States. Over 90% of Japanese immigrants to the USA settled in California, where labor and farm competition fed into general anti-Japanese sentiment. In 1905, California's anti-miscegenation law outlawed marriages between Caucasians and "Mongolians", an umbrella term that was used to refer to the Japanese and other ethnicities of East Asian ancestry. In October 1906, the San Francisco Board of Education separated Japanese students from Caucasian students. It ordered 93 Japanese students in the district to attend a segregated school in Chinatown. Twenty-five of the students were American citizens. In 1924, the "Oriental Exclusion Law" eliminated all Japanese immigration. Japanese immigrants had already been unable to attain citizenship by naturalization.
In 1939 through 1941, the Federal Bureau of Investigation (FBI) compiled the Custodial Detention Index (CDI) on citizens, enemy aliens and foreign nationals, citing national security. On June 28, 1940, the Alien Registration Act was passed. Among many other loyalty regulations, Section 31 required the registration and fingerprinting of all aliens older than 14, and Section 35 required aliens to report any change of address within five days. In the subsequent months, nearly five million foreign nationals registered at post offices around the country.
Of 127,000 Japanese Americans living in the continental United States at the time of the Pearl Harbor attack, 112,000 resided on the West Coast. About 80,000 were "nisei" (literal translation: "second generation"; Japanese people born in the United States and holding American citizenship) and "sansei" (literal translation: "third generation"; the sons or daughters of "nisei"). The rest were "issei" (literal translation: "first generation"; immigrants born in Japan who were ineligible for U.S. citizenship).
After Pearl Harbor.
The attack on Pearl Harbor on December 7, 1941 led military and political leaders to suspect that Imperial Japan was preparing a full-scale attack on the West Coast of the United States. Japan's rapid military conquest of a large portion of Asia and the Pacific between 1936 and 1942 made its military forces seem unstoppable to some Americans. Civilian and military officials had serious concerns about the loyalty of the ethnic Japanese after the Niihau Incident which immediately followed the attack on Pearl Harbor, when a civilian Japanese national and two Hawaiian-born ethnic Japanese on the island of Ni'ihau violently freed a downed and captured Japanese naval airman, attacking their fellow Ni'ihau islanders in the process.
Several concerns over the loyalty of ethnic Japanese seemed to stem from racial prejudice rather than evidence of actual malfeasance. Major Karl Bendetsen and Lieutenant General John L. DeWitt, head of the Western Command, each questioned Japanese American loyalty. DeWitt, who administered the internment program, repeatedly told newspapers that "A Jap's a Jap" and testified to Congress,
DeWitt also sought approval to conduct search and seizure operations aimed at preventing alien Japanese from making radio transmissions to Japanese ships. The Justice Department declined, stating that there was no probable cause to support DeWitt's assertion, as the FBI concluded that there was no security threat. On January 2, the Joint Immigration Committee of the California Legislature sent a manifesto to California newspapers which attacked "the ethnic Japanese," who it alleged were "totally unassimilable." This manifesto further argued that all people of Japanese heritage were loyal subjects of the Emperor of Japan; Japanese language schools, furthermore, according to the manifesto, were bastions of racism which advanced doctrines of Japanese racial superiority.
The manifesto was backed by the Native Sons and Daughters of the Golden West and the California Department of the American Legion, which in January demanded that all Japanese with dual citizenship be placed in concentration camps. Internment was not limited to those who had been to Japan, but included a small number of German and Italian enemy aliens. By February, Earl Warren, the Attorney General of California, had begun his efforts to persuade the federal government to remove all people of Japanese heritage from the West Coast.
Those that were as little as 1/16 Japanese could be placed in internment camps. There is evidence supporting the argument that the measures were racially motivated, rather than a military necessity. For example, orphaned infants with "one drop of Japanese blood" (as explained in a letter by one official) were included in the program.
Upon the bombing of Pearl Harbor and pursuant to the Alien Enemies Act, Presidential Proclamations 2525, 2526 and 2527 were issued designating Japanese, German and Italian nationals as enemy aliens. Information from the CDI was used to locate and incarcerate foreign nationals from Japan, Germany and Italy (although Germany and Italy did not declare war on the U.S. until December 11).
Presidential Proclamation 2537 was issued on January 14, 1942, requiring aliens to report any change of address, employment or name to the FBI. Enemy aliens were not allowed to enter restricted areas. Violators of these regulations were subject to "arrest, detention and internment for the duration of the war."
Executive Order 9066 and related actions.
Executive Order 9066, signed by Franklin D. Roosevelt on February 19, 1942, allowed authorized military commanders to designate "military areas" at their discretion, "from which any or all persons may be excluded." These "exclusion zones," unlike the "alien enemy" roundups, were applicable to anyone that an authorized military commander might choose, whether citizen or non-citizen. Eventually such zones would include parts of both the East and West Coasts, totaling about 1/3 of the country by area. Unlike the subsequent detainment and internment programs that would come to be applied to large numbers of Japanese Americans, detentions and restrictions directly under this Individual Exclusion Program were placed primarily on individuals of German or Italian ancestry, including American citizens.
These edicts included persons of part-Japanese ancestry as well. Anyone with at least one-sixteenth Japanese ancestry was eligible. Korean-Americans and Taiwanese, considered to have Japanese nationality (since Korea and Taiwan were both Japanese colonies), were also included.
Non-military advocates for exclusion, removal, and detention.
Other California newspapers also embraced this view. According to a "Los Angeles Times" editorial,
State politicians joined the bandwagon that was embraced by Leland Ford of Los Angeles, who demanded that "all Japanese, whether citizens or not, be placed in concentration camps." Internment of Japanese Americans, who provided critical agricultural labor on the West Coast, created a labor shortage, which was exacerbated by the induction of many American laborers into the Armed Forces. This vacuum precipitated a mass immigration of Mexican workers into the United States to fill these jobs, largely under the banner of what became known as the Bracero Program. Many Japanese internees were even temporarily released from their camps – for instance, to harvest Western beet crops – to address this wartime labor shortage.
Statement of military necessity as justification for internment.
Niihau Incident.
The Niihau Incident occurred in December 1941, just after the Japanese attack on Pearl Harbor. It involved three Japanese Americans on the Hawaiian island of Niihau assisting a Japanese pilot who crashed there. Despite the incident, the Territorial Governor of Hawaii rejected calls for mass internment of the Japanese Americans living there.
Cryptography.
In "Magic: The Untold Story of US Intelligence and the Evacuation of Japanese Residents From the West Coast During World War II", David Lowman, a former National Security Agency (NSA) operative, argues that Magic intercepts ("Magic" was the code-name for American code-breaking efforts) posed "the frightening specter of massive espionage nets," thus justifying internment. Lowman contended that internment served to ensure the secrecy of US code-breaking efforts, because effective prosecution of Japanese Americans might necessitate disclosure of secret information. If US code-breaking technology was revealed in the context of trials of individual spies, the Japanese Imperial Navy would change its codes, thus undermining US strategic wartime advantage.
Some scholars have criticized or dismissed Lowman's reasoning that "disloyalty" among some individual Japanese Americans could legitimize "incarcerating 120,000 people, including infants, the elderly, and the mentally ill". Lowman's reading of the contents of the "Magic" cables has also been challenged, as some scholars contend that the cables demonstrate the opposite of what Lowman claims: that Japanese Americans were not heeding the overtures of Imperial Japan to spy against the United States. According to one critic, Lowman's book has long since been "refuted and discredited".
The controversial conclusions drawn by Lowman were defended by pundit Michelle Malkin in her book "In Defense of Internment; The Case for 'Racial Profiling' in World War II and the War on Terror". Malkin's defense of Japanese internment was in part the result of what she describes as the "constant alarmism from Bush-bashers who argue that every counter-terror measure in America is tantamount to the internment". The text was critical of academia's treatment of the subject, and suggested that academics critical of Japanese internment had ulterior motives. She received much criticism for her text, particularly in regards to her reading of the "Magic" cables. Daniel Pipes, also drawing on Lowman, has defended Malkin's stance, and asserted that Japanese American internment was "a good idea" which offers "lessons for today".
United States District Court opinions.
A report by General DeWitt and Colonel Bendetsen depicting racist bias against Japanese Americans was circulated and then hastily redacted in 1943–1944. The report stated flatly that, because of their race, it was impossible to determine the loyalty of Japanese Americans, thus necessitating internment. The original version was so offensive – even in the atmosphere of the wartime 1940s – that Bendetsen ordered all copies to be destroyed. 
In 1980, a copy of the original "Final Report: Japanese Evacuation from the West Coast – 1942" was found in the National Archives, along with notes showing the numerous differences between the original and redacted versions. This earlier, racist and inflammatory version, as well as the FBI and Office of Naval Intelligence (ONI) reports, led to the "coram nobis" retrials which overturned the convictions of Fred Korematsu, Gordon Hirabayashi and Minoru Yasui on all charges related to their refusal to submit to exclusion and internment. The courts found that the government had intentionally withheld these reports and other critical evidence, at trials all the way up to the Supreme Court, which would have proved that there was no military necessity for the exclusion and internment of Japanese Americans. In the words of Department of Justice officials writing during the war, the justifications were based on "willful historical inaccuracies and intentional falsehoods."
The Ringle Report.
In May 2011, U.S. Solicitor General Neal Katyal, after a year of investigation, found Charles Fahy intentionally withheld "The Ringle Report", drafted by the Office of Naval Intelligence, in order to justify the Roosevelt administration in the cases of Hirabayashi v. United States and Korematsu v. United States. The report would have undermined the administration's position of the military necessity for such action, finding most Japanese-Americans were not a national security threat, along with allegations of communication espionage being unfounded by the FBI and Federal Communications Commission.
Facilities.
While this event is most commonly called the "internment" of Japanese Americans, in fact there were several different types of camps involved. The best known facilities were the "Assembly Centers" run by the Wartime Civil Control Administration (WCCA), and the "Relocation Centers" run by the War Relocation Authority (WRA), which are generally (but unofficially) referred to as "internment camps." The Department of Justice (DOJ) operated camps officially called "Internment Camps", which were used to detain those suspected of actual crimes or "enemy sympathies." German American internment and Italian American internment camps also existed, sometimes sharing facilities with the Japanese Americans. The WCCA and WRA facilities were the largest and the most public. The WCCA Assembly Centers were temporary facilities that were first set up in horse racing tracks, fairgrounds and other large public meeting places to assemble and organize internees before they were transported to WRA Relocation Centers by truck, bus or train. The WRA Relocation Centers were camps that housed persons removed from the exclusion zone after March 1942, or until they were able to relocate elsewhere in America outside the exclusion zone.
DOJ Internment Camps.
During World War II, over 7,000 Japanese Americans and Japanese from Latin America were held in internment camps run by the Immigration and Naturalization Service, part of the Department of Justice. In this period, Latin Americans of Japanese ancestry were rounded up and transported to American internment camps run by the U.S. Justice Department. These Latin American internees were eventually, through the efforts of civil rights attorney Wayne M. Collins, offered "parole" relocation to the labor-starved farming community in Seabrook, New Jersey. Many became naturalized American citizens or Japanese Americans after the war.
There were twenty-seven U.S. Department of Justice Camps, eight of which (in Texas, Idaho, North Dakota, New Mexico, and Montana) held Japanese Americans. The camps were guarded by Border Patrol agents rather than military police and were intended for non-citizens including Buddhist ministers, Japanese language instructors, newspaper workers, and other community leaders.
In addition 2,264 persons of Japanese ancestry taken from 12 Latin American countries by the U.S. State and Justice Departments were held at the Department of Justice Camps. About two-thirds of these persons were Japanese Peruvians. There has been some speculation that the United States intended to use them in hostage exchanges with Japan, a plot in part facilitated by local prejudice against Japanese communities in various South American countries. After the war, Peru refused to accept the return of the Japanese Peruvians they had acquiesced to interning in American camps; of this group, some were transferred to Japan, some were granted American citizenship, and a small minority of about 100 managed to achieve repatriation into Peru by asserting special circumstances, such as marriage to a non-Japanese Peruvian. Three hundred of the Japanese Peruvians who fought deportation in the courts were allowed to settle in the United States, and were granted American citizenship in 1953.
WCCA Civilian Assembly Centers.
Executive Order 9066 authorized the evacuation of all persons of Japanese ancestry from the West Coast; it was signed when there was no place for the Japanese Americans to go. When voluntary evacuation proved impractical, the military took over full responsibility for the evacuation; on April 9, 1942, the Wartime Civilian Control Agency (WCCA) was established by the military to coordinate the evacuation to inland relocation centers. The relocation centers were far from ready for large influxes of people. For some, there was still contention over the location, but for most, their placement in "isolated" undeveloped areas of the country exacerbated problems of building infrastructure and housing. Since the Japanese Americans living in the restricted zone were considered too dangerous to freely conduct their daily business, the military decided it was necessary to find temporary "assembly centers" to house the evacuees until the relocation centers were completed.
WRA Relocation Centers.
The War Relocation Authority (WRA) was the U.S. civilian agency responsible for the relocation and detention. The WRA was created by President Roosevelt on March 18, 1942 with Executive Order 9102 and officially ceased to exist June 30, 1946. Milton S. Eisenhower, then an official of the Department of Agriculture, was chosen to head the WRA. Dillon S. Myer replaced Milton Eisenhower on June 17, 1942, three months after Milton took control. Myer served as Director of the WRA until the centers were closed. Within nine months, the WRA had opened ten facilities in seven states, and transferred over 100,000 people from the WCCA facilities.
The WRA camp at Tule Lake, though initially like the other camps, eventually became a detention center for people believed to pose a security risk. Tule Lake also served as a "segregation center" for individuals and families who were deemed "disloyal" and for those who were to be deported to Japan.
List of camps.
There were three types of camps. "Civilian Assembly Centers" were temporary camps, frequently located at horse tracks, where the Nisei were sent as they were removed from their communities. Eventually, most were sent to "Relocation Centers," also known as "internment camps." "Detention camps" housed Nikkei considered to be disruptive or of special interest to the government.
Citizen Isolation Centers.
The Citizen Isolation Centers were for those considered to be problem inmates.
Exclusion, removal, and detention.
Somewhere between 110,000 and 120,000 people of Japanese ancestry were subject to this mass exclusion program, of whom about two-thirds were U.S. citizens. The remaining one-third were non-citizens subject to internment under the Alien Enemies Act; many of these "resident aliens" had long been inhabitants of the United States, but had been deprived the opportunity to attain citizenship by laws that blocked Asian-born nationals from ever achieving citizenship.
Internees of Japanese descent were first sent to one of 17 temporary "Civilian Assembly Centers," where most awaited transfer to more permanent relocation centers being constructed by the newly formed War Relocation Authority (WRA). Some of those who did report to the civilian assembly centers were not sent to relocation centers, but were released under the condition that they remain outside the prohibited zone until the military orders were modified or lifted. Almost 120,000 Japanese Americans and resident Japanese aliens would eventually be removed from their homes in California, the western halves of Oregon and Washington and southern Arizona as part of the single largest forced relocation in U.S. history.
Most of these camps/residences, gardens, and stock areas were placed on Native American reservations, for which the Native Americans were formally compensated. The Native American councils disputed the amounts negotiated in absentia by US government authorities and later sued finding relief and additional compensation for some items of dispute.
Under the National Student Council Relocation Program (supported primarily by the American Friends Service Committee), students of college age were permitted to leave the camps to attend institutions willing to accept students of Japanese ancestry. Although the program initially granted leave permits to only a very small number of students, this eventually grew to 2,263 students by December 31, 1943.
Curfew and exclusion.
The exclusion from Military Area No. 1 initially occurred through a voluntary relocation policy. Under the voluntary relocation policy, the Japanese Americans were free to go anywhere outside of the exclusion zone; the arrangements and costs of relocation were borne by the individuals. The night-time curfew, initiated on March 27, 1942, was the first mass-action restricting the Japanese Americans.
Conditions in the camps.
According to a 1943 War Relocation Authority report, internees were housed in "tar paper-covered barracks of simple frame construction without plumbing or cooking facilities of any kind." The spartan facilities met international laws, but still left much to be desired. Many camps were built quickly by civilian contractors during the summer of 1942 based on designs for military barracks, making the buildings poorly equipped for cramped family living.
To describe the conditions in more detail, the Heart Mountain War Relocation Center in northwestern Wyoming was a barbed-wire-surrounded enclave with unpartitioned toilets, cots for beds, and a budget of 45 cents daily per capita for food rations. Because most internees were evacuated from their West Coast homes on short notice and not told of their assigned destinations, many failed to pack appropriate clothing for Wyoming winters which often reached temperatures below zero Fahrenheit. Many families were forced to simply take the "clothes on their backs."
Armed guards were posted at the camps, which were all in remote, desolate areas far from population centers. Internees were typically allowed to stay with their families, and were treated well unless they violated the rules. There are documented instances of guards shooting internees who reportedly attempted to walk outside the fences. One such shooting, that of James Wakasa at Topaz, led to a re-evaluation of the security measures in the camps. Some camp administrations eventually allowed relatively free movement outside the marked boundaries of the camps. Nearly a quarter of the internees left the camps to live and work elsewhere in the United States, outside the exclusion zone. Eventually, some were authorized to return to their hometowns in the exclusion zone under supervision of a sponsoring American family or agency whose loyalty had been assured.
The phrase "shikata ga nai" (loosely translated as "it cannot be helped") was commonly used to summarize the interned families' resignation to their helplessness throughout these conditions. This was even noticed by the children, as mentioned in the well-known memoir "Farewell to Manzanar."
Loyalty questions and segregation.
Some Japanese Americans did question the American government, after finding themselves in internment camps. Several pro-Japan groups formed inside the camps, particularly at the Tule Lake location. When the government passed a law that made it possible for an internee to renounce American citizenship, 5,589 internees opted to do so; 5,461 of these were at Tule Lake. Of those who renounced their citizenship, 1,327 were repatriated to Japan. Many of these individuals would later face stigmatization in the Japanese-American community, after the war, for having made that choice, although even at the time they were not certain what their futures held were they to remain American, and remain interned.
he renunciations had little to do with "loyalty" or "disloyalty" to the United States, but were instead the result of a series of complex conditions and factors that were beyond the control of those involved. Prior to discarding citizenship, most or all of the renunciants had experienced the following misfortunes: forced removal from homes; loss of jobs; government and public assumption of disloyalty to the land of their birth based on race alone; and incarceration in a "segregation center" for "disloyal" ISSEI or NISEI...
Minoru Kiyota, who was among those who renounced his citizenship and swiftly came to regret the decision, has stated that he wanted only "to express my fury toward the government of the United States," for his internment and for the mental and physical duress, as well as the intimidation, he was made to face.
Kiyota, Minoru and Keenan, Linda Klepinger. "Beyond Loyalty". 1997, page 129
Civil rights attorney Wayne M. Collins successfully challenged most of these renunciations as invalid, owing to the conditions of duress and intimidation under which the government obtained them. Many of the deportees were "Issei" (first generation Japanese immigrants) who often had difficulty with English and often did not understand the questions they were asked. Even among those "Issei" who had a clear understanding, Question 28 posed an awkward dilemma: Japanese immigrants were denied US citizenship at the time, so when asked to renounce their Japanese citizenship, answering "Yes" would have made them stateless persons.
When the government circulated a questionnaire seeking army volunteers from among the internees, 6% of military-aged male respondents volunteered to serve in the U.S. Armed Forces. Most of those who refused tempered that refusal with statements of willingness to fight if they were restored their rights as American citizens. 20,000 Japanese American men and many Japanese American women served in the U.S. Army during World War II.
The famed 442nd Regimental Combat Team, which fought in Europe, was formed from those Japanese Americans who did agree to serve. This unit was the most highly decorated US military unit of its size and duration. Most notably, the 442nd was known for saving the 141st (or the "lost battalion") from the Germans. The 1951 film "Go For Broke!" was a fairly accurate portrayal of the 442nd, and starred several of the RCT's veterans.
Other detention camps.
As early as 1939, when war broke out in Europe and while armed conflict began to rage in East Asia, the FBI and branches of the Department of Justice and the armed forces began to collect information and surveillance on influential members of the Japanese community in the United States. These data were included in the Custodial Detention index (CDI). Agents in the Department of Justice's Special Defense Unit classified the subjects into three groups: A, B and C, with A being "most dangerous," and C being "possibly dangerous."
After the Pearl Harbor attacks, Roosevelt authorized his attorney general to put into motion a plan for the arrest of individuals on the potential enemy alien lists. Armed with a blanket arrest warrant, the FBI seized these men on the eve of December 8, 1941. These men were held in municipal jails and prisons until they were moved to Department of Justice detention camps, separate from those of the Wartime Relocation Authority (WRA). These camps operated under far more stringent conditions and were subject to heightened criminal-style guard, despite the absence of criminal proceedings.
Crystal City, Texas, was one such camp where Japanese Americans, German Americans, Italian Americans, and a large number of US-seized, Axis-descended nationals from several Latin-American countries were interned.
Canadian citizens with Japanese ancestry were also interned by the Canadian government during World War II (see Japanese Canadian internment). Japanese people from various parts of Latin America, including Peru, were brought to the United States for internment or interned in their countries of residence, and there were varied restrictions placed on Japanese Brazilians.
Hawaii.
Although there was a strong push from mainland Congressmen (Hawaii was only a US territory at the time, and did not have a voting representative or senator in Congress) to remove and intern all Japanese Americans and Japanese immigrants in Hawaii, it never happened. 1,200 to 1,800 Japanese nationals and Japanese Americans from Hawaii were interned, either in five camps on the islands or in one of the mainland internment camps.
The vast majority of Japanese Americans and their immigrant parents in Hawaii were not interned because the government had already declared martial law in Hawaii and this allowed it to significantly reduce the supposed risk of espionage and sabotage by residents of Japanese ancestry. Also, Japanese Americans comprised over 35% of the territory's population, with about 150,000 inhabitants; detaining so many people would have been enormously challenging in terms of logistics. Also, the whole of Hawaiian society was dependent on their productivity. Lieutenant General Delos C. Emmons, commander of the Hawaii Department, promised the local Japanese-American community that they would be treated fairly so long as they remained loyal to the United States, and he succeeded in blocking efforts to relocate them to the outer islands or mainland by pointing out the logistical difficulties. Among the small number interned were a number of community leaders and prominent politicians, including territorial legislators Thomas Sakakihara and Sanji Abe.
There were five internment camps in Hawaii, referred to as "Hawaiian Island Detention Camps". One camp was located at Sand Island at the mouth of Honolulu Harbor. This camp was prepared in advance of the war's outbreak. All prisoners held here were "detained under military custody... because of the imposition of martial law throughout the Islands". Another Hawaiian camp was the Honouliuli Internment Camp, near Ewa, on the southwestern shore of Oahu; it was opened in 1943 to replace the Sand Island camp. One was also located on the island of Maui in the town of Haiku. In total, five internment camps operated in Hawaii.
Internment ends.
On December 18, 1944, the Supreme Court of the United States clarified the legality of the exclusion process under Order 9066 by handing down two decisions. "Korematsu v. United States", a 6–3 decision, stated that the exclusion process in general was constitutional. "Ex parte Endo" unanimously declared that loyal citizens of the United States, regardless of cultural descent, could not be detained without cause.
On January 2, 1945, the exclusion order was rescinded entirely. The internees then began to leave the camps to rebuild their lives at home, although the relocation camps remained open for residents who were not ready to make the move back. The freed internees were given $25 and a train ticket to their former homes. While the majority returned to their former lives, some of the Japanese Americans emigrated to Japan. The last internment camp was not closed until 1946; Japanese taken by the U.S. from Peru that were still being held in the camp in Santa Fe took legal action in April 1946 in an attempt to avoid deportation to Japan.
One of the WRA camps, Manzanar, was designated a National Historic Site in 1992 to "provide for the protection and interpretation of historic, cultural, and natural resources associated with the relocation of Japanese Americans during World War II" (Public Law 102-248). In 2001, the site of the Minidoka War Relocation Center in Idaho was designated the Minidoka National Historic Site.
Hardship and material loss.
Many internees lost irreplaceable personal property due to the restrictions on what could be taken into the camps. These losses were compounded by theft and destruction of items placed in governmental storage. A number of persons died or suffered for lack of medical care, and several were killed by sentries; James Wakasa, for instance, was killed at Topaz War Relocation Center, near the perimeter wire. Nikkei were prohibited from leaving the Military Zones during the last few weeks before internment, and only able to leave the camps by permission of the camp administrators.
Psychological injury was observed by Dillon S. Myer, director of the WRA camps. In June 1945, Myer described how the Japanese Americans had grown increasingly depressed, and overcome with feelings of helplessness and personal insecurity. Author Betty Furuta insists that the Japanese used gaman, loosely meaning "perseverance", to overcome hardships which was mistaken by non-Japanese as being introverted and lacking initiative.
Some Japanese-American farmers were able to find families willing to tend their farms for the duration of their internment. In other cases Japanese-American farmers had to sell their property in a matter of days, usually at great financial loss. In these cases, the land speculators who bought the land made huge profits. California's Alien Land Laws of the 1910s, which prohibited most non-citizens from owning property in that state, contributed to Japanese-American property losses. Because they were barred from owning land, many older Japanese-American farmers were tenant farmers and therefore lost their rights to those farm lands.
To compensate former internees for their property losses, the US Congress, on July 2, 1948, passed the "American Japanese Claims Act," allowing Japanese Americans to apply for compensation for property losses which occurred as "a reasonable and natural consequence of the evacuation or exclusion." By the time the Act was passed, the IRS had already destroyed most of the 1939–42 tax records of the internees, and, due to the time pressure and the strict limits on how much they could take to the assembly centers and then the internment camps, few of the internees themselves had been able to preserve detailed tax and financial records during the evacuation process. Thus, it was extremely difficult for claimants to establish that their claims were valid. Under the Act, Japanese-American families filed 26,568 claims totaling $148 million in requests; about $37 million was approved and disbursed.
Reparations and redress.
During World War II, Colorado governor Ralph Lawrence Carr was the only elected official to publicly apologize for the internment of American citizens. The act cost him reelection, but gained him the gratitude of the Japanese American community, such that a statue of him was erected in Sakura Square in Denver's Japantown.
Largely through the efforts of college President William Dennis, Earlham College instituted a program beginning in 1942 that enrolled several dozen Japanese-American students, in order to spare them from internment. While this action was controversial in Richmond, Indiana, it helped strengthen the college's ties to Japan and the Japanese-American community.
Beginning in the 1960s, a younger generation of Japanese Americans who were inspired by the Civil Rights movement began what is known as the "Redress Movement," an effort to obtain an official apology and reparations from the federal government for interning their parents and grandparents during the war, focusing not on documented property losses but on the broader injustice of the internment. The movement's first success was in 1976, when President Gerald Ford proclaimed that the internment was "wrong," and a "national mistake" which "shall never again be repeated".
The campaign for redress was launched by Japanese Americans in 1978. The Japanese American Citizens League (JACL) asked for three measures to be taken as redress: $25,000 to be awarded to each person who was detained, an apology from Congress acknowledging publicly that the U.S. government had been wrong, and the release of funds to set up an educational foundation for the children of Japanese American families.
In 1980, Congress established the Commission on Wartime Relocation and Internment of Civilians (CWRIC) to study the matter. On February 24, 1983, the commission issued a report entitled "Personal Justice Denied", condemning the internment as "unjust and motivated by racism rather than real military necessity". The Commission recommended that $20,000 in reparations be paid to those Japanese Americans who had been victims of internment.
In 1988, U.S. President Ronald Reagan signed the Civil Liberties Act of 1988, which had been sponsored by Representative Norman Mineta and Senator Alan K. Simpson – the two had met while Mineta was interned at a camp in Wyoming – which provided redress of $20,000 for each surviving detainee, totaling $1.2 billion dollars. The question of to whom reparations should be given, how much, and even whether monetary reparations were appropriate were subjects of sometimes contentious debate.
""In remembering, it is important to come to grips with the past. No nation can fully understand itself or find its place in the world if it does not look with clear eyes at all the glories and disgraces of its past. We in the United States acknowledge such an injustice in our history. The internment of Americans of Japanese ancestry was a great injustice, and it will never be repeated.""
Some Japanese and Japanese Americans who were relocated during World War II received compensation for property losses, according to a 1948 law. Congress appropriated $38 million to meet $131 million of claims from among 23,000 claimants. These payments were disbursed very slowly, the final disbursal occurring in 1965. In 1988, following lobbying efforts by Japanese Americans, $20,000 per internee was paid out to individuals who had been interned or relocated, including those who chose to return to Japan. These payments were awarded to 82,210 Japanese Americans or their heirs at a cost of $1.6 billion; the program's final disbursement occurred in 1999.
Under the 2001 budget of the United States, it was also decreed that the ten sites on which the detainee camps were set up are to be preserved as historical landmarks: “places like Manzanar, Tule Lake, Heart Mountain, Topaz, Amache, Jerome, and Rohwer will forever stand as reminders that this nation failed in its most sacred duty to protect its citizens against prejudice, greed, and political expediency”.
On January 30, 2011, California first observed an annual "Fred Korematsu Day of Civil Liberties and the Constitution", the first such commemoration for an Asian American in the U.S. On June 14, 2011, Peruvian president Alan García apologized for his country's internment of Japanese immigrants during World War II, most of whom were transferred to the United States.
Legal legacy.
Several significant legal decisions arose out of Japanese-American internment, relating to the powers of the government to detain citizens in wartime. Among the cases which reached the Supreme Court were "Yasui v. United States" (1943), "Hirabayashi v. United States" (1943), "ex parte Endo" (1944), and "Korematsu v. United States" (1944). In "Yasui" and "Hirabayashi" the court upheld the constitutionality of curfews based on Japanese ancestry; in "Korematsu" the court upheld the constitutionality of the exclusion order. In "Endo", the court accepted a petition for a writ of habeas corpus and ruled that the WRA had no authority to subject a citizen whose loyalty was acknowledged to its procedures.
Korematsu's and Hirabayashi's convictions were vacated in a series of "coram nobis" cases in the early 1980s. In the "coram nobis" cases, federal district and appellate courts ruled that newly uncovered evidence revealed an unfairness which, had it been known at the time, would likely have changed the Supreme Court's decisions in the Yasui, Hirabayashi, and Korematsu cases. These new court decisions rested on a series of documents recovered from the National Archives showing that the government had altered, suppressed and withheld important and relevant information from the Supreme Court, including the Final Report by General DeWitt justifying the internment program. The Army had destroyed documents in an effort to hide the fact that alterations had been made to the report. The "coram nobis" cases vacated the convictions of Korematsu and Hirabayashi (Yasui died before his case was heard, rendering it moot), and are regarded as one of the impetuses for the Civil Liberties Act of 1988.
The rulings of the US Supreme Court in the Korematsu and Hirabayashi cases, specifically in its expansive interpretation of government powers in wartime, have yet to be overturned. They are still the law of the land because a lower court cannot overturn a ruling by the US Supreme Court. The "coram nobis" cases totally undermined the "factual" underpinnings of the 1944 cases, leaving the original decisions without much logical basis. Nonetheless, in light of the fact that these 1944 decisions are still on the books, a number of legal scholars have expressed the opinion that the original Korematsu and Hirabayashi decisions have taken on renewed relevance in the context of the War on Terror.
Terminology debate.
There has been much discussion over what to call the locations in which internees were held. The WRA officially called them "War Relocation Centers." Manzanar, for instance, was officially known as the Manzanar War Relocation Center. Because of this, the National Park Service has chosen to use "relocation center" in referring to the camps. Some historians and scholars, as well as former internees, object to this wording, noting that the internees were literally imprisoned, such that "relocation" becomes a euphemism.
Another widely used name for the American camps is "internment camp". This phrase is also potentially misleading, as the United States Department of Justice operated separate camps that were officially called "internment camps" in which some Japanese Americans were imprisoned during World War II.
"Concentration camp" is the most controversial descriptor of the camps. This term is criticized for suggesting that the Japanese American experience was analogous to the Holocaust and the Nazi concentration camps. For this reason, National Park Service officials have attempted to avoid the term. Franklin D. Roosevelt, Dwight D. Eisenhower and Secretary of the Interior Harold L. Ickes each referred to the American camps as "concentration camps," at the time. When the nature of the Nazi concentration camps became clear to the world, and the phrase "concentration camp" came to signify a Nazi death camp, most historians turned to other terms to describe Japanese internment.
Recognizing the controversy over the terminology, in 1971, when the Manzanar Committee applied to the California Department of Parks and Recreation to have Manzanar designated as a California State Historical Landmark, it was proposed that both "relocation center" and "concentration camp" be used in the wording of the plaque for the landmark. Some Owens Valley residents vehemently opposed the use of "concentration camp," and it took a year of discussion and negotiation before both terms were accepted and included on the plaque.
Expulsions and population transfers of WWII.
The internment of Japanese Americans has sometimes been compared to the persecutions, expulsions, and dislocations of other ethnic minorities in the context of World War II, in Europe and Asia. An estimated 500,000 Volga Germans were rounded up and deported to Siberia and Kazakhstan when Germany invaded the Soviet Union, with many of them dying en route. The Volga Germans were deported prior to the Battle of Stalingrad, as they were regarded, in the "war hysteria of the moment", as a potential "Fifth Column".
In 1944, the Red Army rounded up about 500,000 Chechens and Ingushes for relocation; a third of this population perished in the first year, from starvation, cold, and disease. Other nationalities which faced ethnic cleansing for having been identified as potential collaborators with the Germans were the Balkars, Crimean Tartars, Karachi, Kalmyks, and Meskhetians.
Exhibitions and Collections.
The Smithsonian Institution’s National Museum of American History has more than 800 artifacts from its A More Perfect Union collection available online. Archival photography, publications, original manuscripts, artworks, and handmade objects comprise the collection of items related to the Japanese American experience.
On October 1, 1987, the Smithsonian Institution National Museum of American History opened an exhibition called, "A More Perfect Union: Japanese Americans and the U.S. Constitution." The exhibition examined the Constitutional process by considering the experiences of Americans of Japanese ancestry before, during, and after World War II. On view were more than 1,000 artifacts and photographs relating to the experiences of Japanese Americans during World War II. The exhibition closed on January 11, 2004. On November 8, 2011, the National Museum of American History launched an online exhibition of the same name with shared content.
References In Music.
Fort Minor's release The Rising Tied contains a track entitled Kenji, which relates the tale of a Japanese-American family's experience during the internment period. Lead singer Mike Shinoda's paternal grandparents were interned during World War II, along with his father (as an infant). Shinoda is a third generation Japanese American, and his father is Nisei.
Folk/country musician Tom Russell wrote "Manzanar", a song about the Japanese American internment, that was released on his album "Box of Visions" (1993).

Kosovo War
The Kosovo War, was an armed conflict in Kosovo, in the Federal Republic of Yugoslavia, which involved Yugoslav government forces, Albanian separatist forces (KLA), and NATO, between 1998 to 1999.
The KLA, formed in 1991, began attacking police stations and Yugoslav government offices in February 1996, which resulted in an increase in the number of Yugoslav security forces in the region. This led to an escalation into a conflict, although it was initially viewed as an insurgency. The KLA was regarded by the US as a terrorist group until 1998 when it was de-listed for classified reasons. The UK and the US then lobbied France to do the same. The US and NATO then cultivated diplomatic relationships with KLA leaders.
In 1999, the KLA was officially disbanded while some members joined the UCPMB in the Preševo Valley, and the National Liberation Army (NLA) and Albanian National Army (ANA) during the armed ethnic conflict in Macedonia. UNMIK instituted NGOs within Kosovo such as the Kosovo Protection Corps (in accordance with UNSC resolution 1244 which required the establishment of a civilian emergency protection body to replace the former KLA) and the Kosovo Police (which consisted mainly of KLA veterans).
NATO countries promoted the war in Kosovo as the first humanitarian war based on short-term military reports and casualty reports. The conflict was at the center of news headlines for months, and gained a massive amount of coverage and attention from the international community and media. The NATO bombing and surrounding events have remained controversial.
Background.
Kosovo in Tito's Yugoslavia (1945–1986).
Tensions between the Serbian and Albanian communities in Kosovo simmered throughout the 20th century and occasionally erupted into major violence, particularly during the First Balkan War, World War I, and World War II. The Socialist government of Josip Broz Tito systematically repressed nationalist manifestations throughout Yugoslavia, seeking to ensure that no republic or nationality gained dominance over the others. In particular, the power of Serbia—the largest and most populous republic—was diluted by the establishment of autonomous governments in the province of Vojvodina in the north of Serbia and Kosovo in the south. Kosovo's borders did not precisely match the areas of ethnic Albanian settlement in Yugoslavia (significant numbers of Albanians were left in the Republic of Macedonia, Montenegro, and Serbia though the majority of its inhabitants were Albanian). Kosovo's formal autonomy, established under the 1945 Yugoslav constitution, initially meant relatively little in practice. Tito's secret police cracked down hard on nationalists. In 1956, a number of Albanians were put on trial in Kosovo on charges of espionage and subversion. The threat of separatism was in fact minimal, as the few underground groups aiming for union with Albania were politically insignificant. Their long-term impact was substantial, though, as some—particularly the Revolutionary Movement for Albanian Unity, founded by Adem Demaci—were to form the political core of the Kosovo Liberation Army. Demaci himself was imprisoned in 1964 along with many of his followers. Yugoslavia underwent a period of economic and political crisis in 1969, as a massive government program of economic reform widened the gap between the rich north and poor south of the country.
Student demonstrations and riots in Belgrade in June 1968 spread to Kosovo in November the same year, but were quelled by the Yugoslav security forces. However, some of the students' demands—in particular, representative powers for Albanians in both the Serbian and Yugoslav state bodies, and better recognition of the Albanian language—were conceded by Tito. The University of Pristina was established as an independent institution in 1970, ending a long period when the institution had been run as an outpost of Belgrade University. The Albanianisation of education in Kosovo was hampered by the lack of Albanian-language educational materials in Yugoslavia, so an agreement was struck with Albania itself to supply textbooks. In 1974, Kosovo's political status was improved further when a new Yugoslav constitution granted an expanded set of political rights. Along with Vojvodina, Kosovo was declared a province and gained many of the powers of a fully-fledged republic: a seat on the federal presidency and its own assembly, police force, and national bank.
Power was still exercised by the Communist Party, but it was now devolved mainly to ethnic Albanian communists. Tito's death on May 9, 1980 ushered in a long period of political instability, worsened by growing economic crisis and nationalist unrest. The first major outbreak occurred in Kosovo's main city, Pristina, in July 1981, when Albanian students rioted over long queues in their university canteen. This seemingly trivial dispute rapidly spread throughout Kosovo and took on the character of a national revolt, with massive popular demonstrations in many Kosovo towns. The protesters demanded that Kosovo should become the seventh republic of Yugoslavia.
However, this was politically unacceptable to Serbia and the Socialist Republic of Macedonia. Some Serbs (and possibly some Albanian nationalists as well) saw the demands as being a prelude to a "Greater Albania" which could encompass parts of Montenegro, the Republic of Macedonia and Kosovo itself. The Communist Yugoslav presidency quelled the disturbances by sending in riot police and the army, and proclaiming a state of emergency, although it did not repeal the province's autonomy as some Serbian Communists demanded. The Yugoslav press reported that about 11 people had been killed (others claimed a death toll as high as 1,000) and another 4,200 were imprisoned. Kosovo's Communist Party also suffered purges, with several key figures (including its president) expelled.
Hardliners instituted a fierce crackdown on nationalism of all kinds, Albanian and Serbian alike. Kosovo endured a heavy secret police presence throughout most of the 1980s that ruthlessly suppressed any unauthorized nationalist manifestations, both Albanian and Serbian. According to a report quoted by Mark Thompson, as many as 580,000 inhabitants of Kosovo were arrested, interrogated, interned, or reprimanded. Thousands of these lost their jobs or were expelled from their educational establishments. During this time, tension between the Albanian and Serbian communities continued to escalate.
In 1969, the Serbian Orthodox Church had ordered its clergy to compile data on the ongoing problems of Serbs in Kosovo, seeking to pressure the government in Belgrade to do more to protect the Serbian faithful. In February 1982, a group of priests from Serbia proper petitioned their bishops to ask "why the Serbian Church is silent" and why it did not campaign against "the destruction, arson and sacrilege of the holy shrines of Kosovo". Such concerns did attract interest in Belgrade. Stories appeared from time to time in the Belgrade media claiming that Serbs and Montenegrins were being persecuted. There was a perception among Serbian nationalists that Serbs were being driven out of Kosovo.
In addition to all this, the worsening state of Kosovo's economy made the province a poor choice for Serbs seeking work. Albanians, as well as Serbs, tended to favor their compatriots when employing new recruits, but the number of jobs was too few for the population. Kosovo was the poorest part of Yugoslavia: the average per capita income was $795, compared with the national average of $2,635.
Riots.
In 1981, it was reported that some 4,000 Serbs moved from Kosovo to Central Serbia after the Kosovo Albanian riots in March that resulted in several Serb deaths and the desecration of Serbian Orthodox architecture and graveyards. In 1982 It was concluded that the Serbs were victims of major prejudice and harassment, several murders had been committed by ethnic Albanians, and forming of serious nationalist groups was reality. 33 nationalist formations were dismantled by the Yugoslav Police who sentenced some 280 people (800 fined, 100 under investigation) and seized arms caches and propaganda material.
In 1987 David Binder wrote a report on "The New York Times" about the rising nationalism among Albanians in Kosovo. In his report he tells about Paraćin massacre, where an ethnic Albanian soldier in the JNA killed four fellow soldiers and wounded five others.
The report quoting Federal Secretary for National Defense, Fleet Adm. Branko Mamula, shows that from 1981–1987, 216 illegal Albanian organizations with 1,435 members were discovered in the JNA. They had prepared the mass killings of officers and soldiers, poisoning food and water, sabotage, breaking in and stealing weapons and ammunition.
Kosovo and the rise of Slobodan Milošević (1986–1990).
In Kosovo, growing Albanian nationalism and separatism led to tensions between Serbs and Albanians. An increasingly poisonous atmosphere led to wild rumors being spread around and otherwise trivial incidents being blown out of proportion.
It was against this tense background that the Serbian Academy of Sciences and Arts (SANU, from its Serbian initials, САНУ) conducted a survey of Serbs who had left Kosovo in 1985 and 1986. The report concluded that a considerable part of those who had left had been under pressure by Albanians to do so.
Sixteen prominent members of the SANU began work in June 1985 on a draft document that was leaked to the public in September 1986. The SANU Memorandum, as it has become known, was hugely controversial. It focused on the political difficulties facing Serbs in Yugoslavia, pointing to Tito's deliberate hobbling of Serbia's power and the difficulties faced by Serbs outside Serbia proper.
The Memorandum paid special attention to Kosovo, arguing that the province's Serbs were being subjected to "physical, political, legal and cultural genocide" in an "open and total war" that had been ongoing since the spring of 1981. It claimed that Kosovo's status in 1986 was a worse historical defeat for the Serbs than any event since liberation from the Ottomans in 1804, thus ranking it above such catastrophes as the Nazi occupation or the First World War occupation of Serbia by the Austro-Hungarians. The Memorandum's authors claimed that 200,000 Serbs had moved out of the province over the previous twenty years and warned that there would soon be none left "unless things change radically." The remedy, according to the Memorandum, was for "genuine security and unambiguous equality for all peoples living in Kosovo and Metohija be established" and "objective and permanent conditions for the return of the expelled nation [to be created." It concluded that "Serbia must not be passive and wait and see what the others will say, as it has done so often in the past."
The SANU Memorandum met with many different reactions. The Albanians saw it as a call for Serbian supremacy at a local level. They claimed that all Serb emigrants had left Kosovo for economic reasons. Other Yugoslav nationalities, notably the Slovenes and Croats, saw a threat in the call for a more assertive Serbia. Serbs themselves were divided: many welcomed it, while the Communist old guard strongly attacked its message. One of those who denounced it was Serbian Communist Party official Slobodan Milošević.
In November 1988, Kosovo's head of the provincial committee was arrested. In March 1989, Milošević announced an "anti-bureaucratic revolution" in Kosovo and Vojvodina, curtailing their autonomy as well as imposing a curfew and a state of emergency in Kosovo due to violent demonstrations, resulting in 24 deaths (including two policemen). Milošević and his government claimed that the constitutional changes were necessary to protect Kosovo's remaining Serbs against harassment from the Albanian majority.
Constitutional amendments (1989–1996).
Events.
On 17 November 1988, Kaqusha Jashari and Azem Vllasi were forced to resign from the leadership of the League of Communists of Kosovo (LCK). In early 1989 the Serbian Assembly proposed amendments to the Constitution of Serbia which would remove the word "Socialist" from the Serbian Republic's title, establish multi-party elections, remove the independence of institutions of the autonomous provinces such as Kosovo, and rename Kosovo as the Autonomous Province of Kosovo and Metohija. In February Kosovar Albanians demonstrated in large numbers against the proposal, emboldened by striking miners. Serbs in Belgrade protested against the Kosovo Albanian's separatism. On 3 March 1989 the Presidency of Yugoslavia imposed special measures assigning responsibility for public security to the federal government. On 23 March the Assembly of Kosovo voted to accept the proposed amendments although most Albanian delegates abstained. In early 1990 Kosovar Albanians held mass demonstrations against the special measures, which were lifted on 18 April 1990 and responsibility for public security was again assigned to Serbia.
On 8 May 1989 Milošević became President of the Presidency of Serbia, which was confirmed on 6 December. On 22 January 1990 the 14 congress of the League of Communists of Yugoslavia (LCY) abolished the party's position as the only legal political party in Yugoslavia. In January 1990 the Yugoslav government announced it would press ahead with the creation of a multi-party system.
On 26 June 1990 Serbian authorities closed the Kosovo Assembly citing special circumstances. On 1 or 2 July 1990 Serbia approved the new amendments to the Constitution of Serbia in a referendum. Also on 2 July, 114 ethnic Albanian delegates of the 180 member Kosovo Assembly declared Kosovo an independent republic within Yugoslavia. On 5 July the Serbian Assembly dissolved the Kosovo Assembly. Serbia also dissolved the provincial executive council and assumed full and direct control of the province. Serbia took over management of Kosovo's principal Albanian-language media, halting Albanian-language broadcasts. On 4 September 1990 Kosovar Albanians observed a 24-hour general strike, virtually shutting down the province.
On 16 or 17 July 1990, the League of Communists of Serbia (LCS) combined with the Socialist Alliance of Working People of Serbia to become the Socialist Party of Serbia (SPS), and Milošević became its first president. On 8 August 1990 several amendments to the federal Socialist Federal Republic of Yugoslavia (SFRY) Constitution were adopted enabling the establishment of a multi-party election system.
On 7 September 1990 the Constitution of the Republic of Kosovo was promulgated by the disbanded Assembly of Kosovo. Milošević responded by ordering the arrest of the deputies of the disbanded Assembly of Kosovo. The new controversial Serbian Constitution was promulgated on 28 September 1990. Multi-party elections were held in Serbia on 9 and 26 December 1990 after which Milošević became President of Serbia. In September 1991 Kosovar Albanians held an unofficial referendum in which they voted overwhelmingly for independence. On 24 May 1992 Kosovar Albanians held unofficial elections for an assembly and president of the Republic of Kosovo.
On 5 August 1991 the Serbian Assembly suspended the Priština daily "Rilindja", following the Law on Public Information of 29 March 1991 and establishment of the "Panorama" publishing house on 6 November which incorporated "Rilindja", which was declared unconstitutional by the federal authorities. United Nations Special Rapporteur Tadeusz Mazowiecki reported on 26 February 1993 that the police had intensified their repression of the Albanian population since 1990, including depriving them of their basic rights, destroying their educations system, and large numbers of political dismissals of civil servants.
Analysis.
Crucially, as both provinces had a vote in the eight member Yugoslav Presidency, this gave Milosevic an automatic four votes when combined with Serbia and Montenegro (which was closely allied to Serbia). Slovenia, Croatia, Bosnia and Macedonia thus had to maintain an uneasy alliance to prevent Milošević from driving through constitutional changes. Serbia's political changes were ratified in a July 5, 1990 referendum across the entire republic of Serbia, including Kosovo. As a result of these measures more than 80,000 Kosovo Albanians were expelled from their state jobs in Kosovo. A new Serb curriculum was imposed in all higher education in Kosovo, a move which was rejected by Albanians who responded by creating their parallel education system.
The impact on Kosovo was drastic. The reduction of its autonomy was accompanied by the abolition of its political institutions (including the League of Communists of Kosovo); its assembly and government were formally disbanded. As most of Kosovo's industry was state-owned, the changes brought a wholesale change of corporate cadres. Technically, few were sacked outright: their companies required them to sign loyalty pledges, which most Albanians would not sign, although a few did and remained employed in Serbian state companies right up to 1999.
Albanian cultural autonomy was also drastically reduced. TV and radio broadcasts in Albanian ceased. Albanian was no longer an official language of the province. The University of Pristina, seen as a hotbed of Albanian nationalism, was purged: 800 lecturers at Pristina University were sacked and 22,500 of the 23,000 students expelled. Some 40,000 Yugoslav troops and police replaced the original Albanian-run security forces. A punitive regime was imposed that was harshly condemned as a "police state". Poverty and unemployment reached catastrophic levels, with about 80% of Kosovo's population becoming unemployed. As many as a third of adult male Albanians chose to go abroad (particularly to Germany and Switzerland) to find work.
With Kosovo's Communist Party effectively broken up by Milošević's crackdown, the dominant Albanian political party position passed to the Democratic League of Kosovo, led by the writer Ibrahim Rugova. It responded to the abolition of Kosovo's autonomy by pursuing a policy of peaceful resistance. Rugova took the very practical line that armed resistance would be futile given Serbia's military strength and would lead only to a bloodbath in the province. He called on the Albanian populace to boycott the Yugoslav and Serbian states by not participating in any elections, by ignoring the military draft (compulsory in Yugoslavia), and most important, by not paying any taxes or duties to the State. He also called for the creation of parallel Albanian schools, clinics, and hospitals. In September 1991, the shadow Kosovo Assembly organized a referendum on independence for Kosovo. Despite widespread harassment and violence by Serbian security forces, the referendum achieved a reported 90% turnout among the province's Albanians, and a 98% vote—nearly a million votes in all—which approved the creation of an independent "Republic of Kosovo". In May 1992, a second referendum elected Rugova as President of Kosovo. The Serbian government declared that both referendums were illegal, and their results null and void.
Eruption of War.
The slide to war (1996–1998).
Rugova's policy of passive resistance succeeded in keeping Kosovo quiet during the war with Slovenia, and the wars in Croatia and Bosnia during the early 1990s. However, as evidenced by the emergence of the KLA, this came at the cost of increasing frustration among Kosovo's Albanian population. In the mid-1990s, Rugova pleaded for a United Nations peacekeeping force for Kosovo. In 1997, Milošević was promoted to the presidency of the Federal Republic of Yugoslavia (comprising Serbia and Montenegro since its inception in April 1992).
Continuing Serbian repression had radicalized many Albanians, some of whom decided that only armed resistance would change the situation. On April 22, 1996, four attacks on Serbian security personnel were carried out almost simultaneously in several parts of Kosovo. A hitherto-unknown terrorist organization calling itself the "Kosovo Liberation Army" (KLA) subsequently claimed responsibility. The nature of the KLA was at first highly mysterious.
It is widely believed that the KLA received financial and material support from the Kosovo Albanian diaspora. In early 1997, Albania collapsed into chaos following the fall of President Sali Berisha. Military stockpiles were looted with impunity by criminal gangs, with much of the hardware ending up in western Kosovo and boosting the growing KLA arsenal. Bujar Bukoshi, shadow Prime Minister in exile (in Zürich, Switzerland), created a group called FARK (Armed Forces of the Republic of Kosova) which was reported to have been disbanded and absorbed by the KLA in 1998. The Yugoslav government considered the KLA to be "terrorists" and "insurgents" who indiscriminately attacked police and civilians, while most Albanians saw the KLA as "freedom fighters".
In 1998, the U.S. State Department listed the KLA as a terrorist organization, and in 1999 the Republican Policy Committee of the U.S. Senate expressed its troubles with the "effective alliance" of the Democratic Clinton administration with the KLA due to "numerous reports from reputable unofficial sources ".
In 2000, a BBC article stated that "Nato at War" shows how the United States, which had described the KLA as "terrorist", now sought to form a relationship with the group.
U.S. envoy Robert Gelbard referred to the KLA as terrorists. Responding to criticism, he later clarified to the House Committee on International Relations that "while it has committed 'terrorist acts,' it has 'not been classified legally by the U.S. Government as a terrorist organization.'" On June 1998, he held talks with two men who claimed they were political leaders.
Meanwhile, the U.S. held an "outer wall of sanctions" on Yugoslavia which had been tied to a series of issues, Kosovo being one of them. These were maintained despite the agreement at Dayton to end all sanctions. The Clinton administration claimed that Dayton bound Yugoslavia to hold discussions with Rugova over Kosovo.
The crisis escalated in December 1997 at the Peace Implementation Council meeting in Bonn, where the International Community (as defined in the Dayton Agreement) agreed to give the High Representative in Bosnia sweeping powers, including the right to dismiss elected leaders. At the same time, Western diplomats insisted that Kosovo be discussed, and that Serbia and Yugoslavia be responsive to Albanian demands there. The delegation from Serbia stormed out of the meetings in protest.
This was followed by the return of the Contact Group that oversaw the last phases of the Bosnian conflict and declarations from European powers demanding that Serbia solve the problem in Kosovo.
War begins.
KLA attacks suddenly intensified, centered on the Drenica valley area, with the compound of one Adem Jashari being a particular focal point. Days after Robert Gelbard described the KLA as a terrorist group, Serbian police responded to the KLA attacks in the Likosane area, and pursued some of the KLA to Cirez, resulting in the deaths of 16 Albanian fighters and four Serbian policemen. The first serious action of the war had begun.
Despite some accusations of summary executions and killings of civilians, condemnations from Western capitals were not as voluble as they would become later. Serb police began to pursue Jashari and his followers in the village of Donje Prekaz. A massive firefight at the Jashari compound led to the massacre of 60 Albanians, of which eighteen were women and ten were under the age of sixteen. This March 5 event provoked massive condemnation from the western capitals. Madeleine Albright stated that "this crisis is not an internal affair of the FRY".
On March 24, Serbian forces surrounded the village of Glodjane, in the Dukagjin operational zone, and attacked a rebel compound there. Despite their superior firepower, the Serbian forces failed to destroy the KLA unit which had been their objective. Although there were deaths and severe injuries on the Albanian side, the insurgency in Glodjane was far from stamped out. It was in fact to become one of the strongest centers of resistance in the upcoming war.
The KLA's first goal was thus to merge its Drenica stronghold with their stronghold in Albania proper, and this would shape the first few months of the fighting.
The Serbs also continued their efforts at diplomacy, attempting to arrange talks with Ibrahim Rugova's staff (talks which Rugova and his staff refused to attend). After several failed meetings, Ratko Marković, chairman of the Serbian delegation to the meetings, invited representatives of Kosovo minority groups to attend while maintaining his invitation to the Albanians. Serbian President Milan Milutinović attended one of the meetings, though Rugova did not. He and his staff insisted on talking to Yugoslav officials, not "Serbian" ones, and only to discuss the modalities of Kosovo independence.
A new Serbian government was also formed at this time, led by the Socialist Party of Serbia and the Serbian Radical Party. Ultra-nationalist Radical Party chairman Vojislav Šešelj became a deputy prime minister. This increased the dissatisfaction with Serbia's position among Western diplomats and spokespersons.
In early April, Serbia arranged for a referendum on the issue of foreign interference in Kosovo. Serbian voters decisively rejected foreign interference in this crisis. Meanwhile, the KLA claimed much of the area in and around Dečani and ran a territory based in the village of Glođane, encompassing its surroundings. So, on May 31, 1998, the Yugoslav army and the Serb Ministry of the Interior police began an operation to clear the border of the KLA. NATO's response to this offensive was mid-June's Operation Determined Falcon, an air show over the Yugoslav borders.
During this time, the Yugoslav President Milošević reached an arrangement with Boris Yeltsin of Russia to stop offensive operations and prepare for talks with the Albanians, who, through this whole crisis, refused to talk to the Serbian side, but not the Yugoslav. In fact, the only meeting between Milošević and Ibrahim Rugova took place on May 15 in Belgrade, two days after Richard Holbrooke announced that it would take place. One month later, Holbrooke, after a trip to Belgrade where he threatened Milošević that if he did not obey, "what's left of your country will implode", he visited the border areas affected by the fighting in early June; there he was famously photographed with the KLA. The publication of these images sent a signal to the KLA, its supporters and sympathizers, and to observers in general, that the U.S. was decisively backing the KLA and the Albanian population in Kosovo.
The Yeltsin agreement included Milošević's allowing international representatives to set up a mission in Kosovo-Metohija to monitor the situation there. This was the Kosovo Diplomatic Observer Mission (KDOM) that began operations in early July. The American government welcomed this part of the agreement, but denounced the initiative's call for a mutual cease fire. Rather, the Americans demanded that the Serbian-Yugoslavian side should cease fire "without linkage...to a cessation in terrorist activities".
All through June and into mid-July, the KLA maintained its advance. KLA surrounded Peć, Đakovica, and had set up an interim capital in the town of Mališevo (north of Orahovac). The KLA troops infiltrated Suva Reka, and the northwest of Priština. They moved on to the Belacevec coal pits and captured them in late June, threatening energy supplies in the region. Their tactics as usual focused mainly on guerilla and mountain warfare, and harassing and ambushing Serb forces and police patrols.
The tide turned in mid-July when the KLA captured Orahovac. On July 17, 1998, two close-by villages to Orahovac, Retimlije and Opteruša, were also captured. Similar, even if less systematic events took place in the town of Orahovac and the larger Serb village of Velika hoċa. The Orthodox monastery of Zociste 3 miles (5 km) from Orehovac—famous for the relics of the Saints Kosmas and Damianos and revered also by local Albanians—was robbed, its monks deported to a KLA prison camp, and, while empty, the monastery church and all its buildings were leveled to the ground by mining. This led to a series of Serb and Yugoslav offensives which would continue into the beginning of August.
A new set of KLA attacks in mid-August triggered Yugoslavian operations in south-central Kosovo south of the Priština-Peć road. This wound down with the capture of Klecka on August 23 and the discovery of a KLA-run crematorium in which some of their victims were found. The KLA began an offensive on September 1 around Prizren, causing Yugoslavian military activity there. In Metohija, around Peć, another offensive caused condemnation as international officials expressed fear that a large column of displaced people would be attacked.
In early mid-September, for the first time, some KLA activity was reported in northern Kosovo around Podujevo. Finally, in late September, a determined effort was made to clear the KLA out of the northern and central parts of Kosovo and out of the Drenica valley itself. During this time many threats were made from Western capitals but these were tempered somewhat by the elections in Bosnia, as they did not want Serbian Democrats and Radicals to win. Following the elections, however, the threats intensified once again but a galvanizing event was needed. They got it on September 28, when the mutilated corpses of a family were discovered by KDOM outside the village of Gornje Obrinje; the bloody doll from there became the rallying image for the ensuing war.
UN, NATO, and OSCE (1998–1999).
On 23 September 1998 acting under Chapter VII of the United Nations Charter the UN Security Council adopted Resolution 1199. This expressed 'grave concern' at reports reaching the Secretary General that over 230,000 persons had been displaced from their homes by 'the excessive and indiscriminate use of force by Serbian security forces and the Yugoslav Army', demanding that all parties in Kosovo and the Federal Republic of Yugoslavia (Serbia and Montenegro) cease hostilities and maintain a ceasefire. On 24 September the North Atlantic Council (NAC) of NATO issued an "activation warning" (ACTWARN) taking NATO to an increased level of military preparedness for both a limited air option and a phased air campaign in Kosovo.
The other major issue for those who saw no option but to resort to the use of force was the estimated 250,000 displaced Albanians, 30,000 of whom were out in the woods, without warm clothing or shelter, with winter fast approaching.
Meanwhile, the U.S. Ambassador to the Republic of Macedonia, Christopher Hill, was leading shuttle diplomacy between an Albanian delegation, led by Rugova, and the Yugoslav and Serbian authorities. It was these meetings which were shaping what was to be the peace plan to be discussed during a period of planned NATO occupation of Kosovo.
During a period of two weeks, threats intensified, culminating in NATO's Activation Order being given. All was ready for the bombs to fly; Richard Holbrooke went to Belgrade in the hope of reaching an agreement with Milošević.
Officially, the international community demanded an end to fighting. It specifically demanded that the Serbs end its offensives against the KLA whilst attempting to convince the KLA to drop its bid for independence. Moreover, attempts were made to persuade Milošević to permit NATO peacekeeping troops to enter Kosovo. This, they argued, would allow for the Christopher Hill peace process to proceed and yield a peace agreement.
On 13 October 1998 the North Atlantic Council issued issue activation orders (ACTORDs) for the execution of both limited air strikes and a phased air campaign in Yugoslavia which would begin in approximately 96 hours. On 15 October the NATO Kosovo Verification Mission (KVM) Agreement for a ceasefire was signed, and the deadline for withdrawal was extended to 27 October. The Serbian withdrawal commenced on or around 25 October 1998, and Operation Eagle Eye commenced on 30 October.
The KVM was a large contingent of unarmed Organization for Security and Co-operation in Europe (OSCE) peace monitors (officially known as verifiers) that moved into Kosovo. Their inadequacy was evident from the start. They were nicknamed the "clockwork oranges" in reference to their brightly coloured vehicles. Fighting resumed in December 1998 after both sides broke the ceasefire. 
The January to March 1999 phase of the war brought increasing insecurity in urban areas, including bombings and murders. Such attacks took place during the Rambouillet talks in February and as the Kosovo Verification Agreement unraveled in March. Killings on the roads continued and increased. There were military confrontations in, among other places, the Vučitrn area in February and the heretofore unaffected Kačanik area in early March.
On 15 January 1999 the Račak massacre occurred when "45 Kosovan Albanian farmers were rounded up, led up a hill and massacred". The bodies had been discovered by OSCE monitors, including Head of Mission William Walker, and foreign news correspondents. Yugoslavia denied a massacre took place. The Račak massacre was the culmination of the KLA attacks and Serbian reprisals that had continued throughout the winter of 1998–1999. The incident was immediately condemned as a massacre by the Western countries and the United Nations Security Council, and later became the basis of one of the charges of war crimes leveled against Milošević and his top officials. This massacre was the turning point of the war. NATO decided that the conflict could only be settled by introducing a military peacekeeping force under the auspices of NATO, to forcibly restrain the two sides.
Priština, the capital of Kosovo, had been subjected to heavy firefights and segregation according to OSCE reports.
The Rambouillet Conference (January–March 1999).
On 30 January 1999 NATO issued a statement announcing that the North Atlantic Council had agreed that "the NATO Secretary General may authorise air strikes against targets on FRY territory" to "compliance with the demands of the international community and [to achieve a political settlement". While this was most obviously a threat to the Milošević government, it also included a coded threat to the Albanians: any decision would depend on the "position and actions of the Kosovo Albanian leadership and all Kosovo Albanian armed elements in and around Kosovo."
Also on 30 January 1999 the Contact Group issued a set of "non-negotiable principles" which made up a package known as "Status Quo Plus"—effectively the restoration of Kosovo's pre-1990 autonomy within Serbia, plus the introduction of democracy and supervision by international organizations. It also called for a peace conference to be held in February 1999 at the Château de Rambouillet, outside Paris.
The Rambouillet talks began on February 6, 1999, with NATO Secretary General Javier Solana negotiating with both sides. They were intended to conclude by February 19. The Serbian delegation was led by then president of Serbia Milan Milutinović, while Milošević himself remained in Belgrade. This was in contrast to the 1995 Dayton conference that ended the war in Bosnia, where Milošević negotiated in person. The absence of Milošević was interpreted as a sign that the real decisions were being made back in Belgrade, a move that aroused criticism in Serbia as well as abroad; Kosovo's Serbian Orthodox bishop Artemije traveled all the way to Rambouillet to protest that the delegation was wholly unrepresentative. At this time speculation about an indictment of Milošević for war crimes was rife, so his absence may have been motivated by fear of arrest.
The first phase of negotiations was successful. In particular, a statement was issued by the Contact Group co-chairmen on February 23, 1999 that the negotiations "have led to a "consensus" on substantial autonomy for Kosovo, including on mechanisms for free and fair elections to democratic institutions, for the governance of Kosovo, for the protection of human rights and the rights of members of national communities; and for the establishment of a fair judicial system". They went on to say that "a political framework is now in place", leaving the further work of finalizing "the implementation Chapters of the Agreement, including the modalities of the "invited international" civilian and military presence in Kosovo". During the next month, however, NATO, under the influence of US diplomats Rubin and Albright, sought to impose a forced, as opposed to invited, military presence. The tilting of NATO towards the KLA organization is chronicled in the BBC Television "Moral Combat: NATO at War" program. This happened despite the fact, quoting General Klaus Naumann (Chairman of NATO Military Committee), that "Ambassador Walker stated in the NAC (North Atlantic Council) that the majority of violations was caused by the KLA".
In the end, on March 18, 1999, the Albanian, American, and British delegations signed what became known as the Rambouillet Accords while the Serbian and Russian delegations refused as it called for the complete and unrestricted movement of NATO on the whole of Serbia's territory. The accords called for NATO administration of Kosovo as an autonomous province within Yugoslavia, a force of 30,000 NATO troops to maintain order in Kosovo; an unhindered right of passage for NATO troops on Yugoslav territory, including Kosovo; and immunity for NATO and its agents to Yugoslav law. These latter provisions were much the same as had been applied to Bosnia for the SFOR (Stabilization Force) mission there. There were also many who viewed the accords as an excuse to bomb the whole of the Federal Republic of Yugoslavia.
While the accords did not fully satisfy the Albanians, they were much too radical for the Serbs, who responded by substituting a drastically revised text that even the Russians (traditional allies of the Serbs) found unacceptable. It sought to reopen the painstakingly negotiated political status of Kosovo and deleted all of the proposed implementation measures. Among many other changes in the proposed new version, it eliminated the entire chapter on humanitarian assistance and reconstruction, removed virtually all international oversight and dropped any mention of invoking "the will of the people Kosovo" in determining the final status of the province.
Two proposals were on the table on the eve of the bombing. One was the Rambouillet accord, presented to Serbia as an ultimatum. The second was Serbia’s position, formulated in its March 15 “Revised Draft Agreement” and the Serb National Assembly Resolution of March 23. A serious concern for protecting Kosovars might well have brought into consideration other options as well, including, perhaps, something like the 1992–93 proposal of the Serbian president of Yugoslavia, Dobrica Cosic, that Kosovo be partitioned, separating itself from Serbia apart from “a number of Serbian enclaves.” At the time, the proposal was rejected by Ibrahim Rugova’s Republic of Kosovo, which had declared independence and set up a parallel government; but it might have served as a basis for negotiation in the different circumstances of early 1999. 
Events proceeded rapidly after the failure at Rambouillet and the alternative Serbian proposal. The international monitors from the OSCE withdrew on 22 March, for fear of the monitors' safety ahead of the anticipated NATO bombing campaign.
On March 23, the Serbian assembly accepted the principle of autonomy for Kosovo and non-military part of the agreement. But the Serbian side had objections to the military part of the Rambouillet agreement, particularly appendix B that foresees free access to all of Serbia for NATO troops, which it characterized as "NATO occupation".
Perhaps even more striking is that the Rambouillet ultimatum, though universally described as the peace proposal, was also kept from the public, particularly the provisions that were apparently introduced in the final moments of the Paris peace talks (appendix B) in March after Serbia had expressed agreement with the main political proposals, and that virtually guaranteed rejection.
NATO bombing timeline.
On 23 March 1999 at 21:30 UTC Richard Holbrooke returned to Brussels and announced that peace talks had failed and formally handed the matter to NATO for military action. Hours before the announcement, Yugoslavia announced on national television it had declared a state of emergency citing an imminent threat of war and began a huge mobilization of troops and resources.
On 23 March 1999 at 22:17 UTC the Secretary General of NATO, Javier Solana, announced he had directed the Supreme Allied Commander Europe (SACEUR), US Army General Wesley Clark, to "initiate air operations in the Federal Republic of Yugoslavia." On 24 March at 19:00 UTC NATO started its bombing campaign against Yugoslavia.
NATO's bombing campaign lasted from March 24 to June 11, 1999, involving up to 1,000 aircraft operating mainly from bases in Italy and aircraft carriers stationed in the Adriatic. Tomahawk cruise missiles were also extensively used, fired from aircraft, ships, and submarines. All of the NATO members were involved to some degree—with the exception of Greece. Over the ten weeks of the conflict, NATO aircraft flew over 38,000 combat missions. For the German Air Force ("Luftwaffe"), it was the second time it had participated in a conflict since World War II after the Bosnian War.
The proclaimed goal of the NATO operation was summed up by its spokesman as "Serbs out, peacekeepers in, refugees back". That is, Yugoslav troops would have to leave Kosovo and be replaced by international peacekeepers to ensure that the Albanian refugees could return to their homes. The campaign was initially designed to destroy Yugoslav air defenses and high-value military targets. It did not go very well at first, with bad weather hindering many sorties early on. NATO had seriously underestimated Milošević's will to resist: few in Brussels thought that the campaign would last more than a few days, and although the initial bombardment was more than just a pin-prick, it was nowhere near the concentrated bombardments seen in Baghdad in 1991. On the ground, the ethnic cleansing campaign by the Serbians was stepped up. In actions unparalleled since World War Two, Serbian forces expelled hundreds of thousands of Kosovo Albanians from Kosovo, in miserable conditions. UNHCR representatives reported on 3 April that, "During 2 April, an estimated 45,000 Kosovars arrived at the Macedonian border with Kosovo, of whom around 25,000 in six trains carrying people who report that they were expelled from Pristina. The new arrivals were exhausted and traumatized.". On 6 April, UNHCR representatives were reporting that "at least 25,000 Kosovars arrived at the main Albanian border point at Morini between Monday and Tuesday mornings and a further 15,000 at the mountain frontier of Qafa Prushit, bringing the estimated total to 262,000 ... Virtually every Kosovar arriving at Qafa Prushit came on foot in very, very bad physical condition ... refugees interviewed said men were both being tortured and even executed in front of their families ... Serbian police stationed just opposite the Albanian border post warned journalists they would shoot if the correspondents approached. Aid officials were told to withdraw 500 metres from the crossing.". A report written for the UNHCR after the crisis concluded that 'half a million people arrived in neighbouring areas in the course of about
two weeks, and a few weeks later the total was over 850,000'. The Serbian authorities have never acknowledged these UNHCR figures. On 25 March Arkan appeared at the Hyatt hotel in Belgrade where most of Western journalists were staying and warned all of them to leave Serbia.
NATO military operations switched increasingly to attacking Yugoslav units on the ground, hitting targets as small as individual tanks and artillery pieces, as well as continuing with the strategic bombardment. This activity was, however, heavily constrained by politics, as each target needed to be approved by all nineteen member states. Montenegro was bombed on several occasions but NATO eventually desisted to prop up the precarious position of its anti-Milošević leader, Đukanović. So-called "dual-use" targets, of use to both civilians and the military, were attacked, including bridges across the Danube, factories, power stations, schools, houses, nurseries, hospitals, telecommunications facilities and, controversially, the headquarters of Yugoslavian Leftists, a political party led by Milošević's wife, and the Serbian state television broadcasting tower. Some saw these actions as violations of international law and the Geneva Conventions in particular. NATO, however, argued that these facilities were potentially useful to the Yugoslav military and that their bombing was therefore justified.
At the start of May, a NATO aircraft attacked an Albanian refugee convoy, believing it was a Yugoslav military convoy, killing around fifty people. NATO admitted its mistake five days later, but the Serbs accused NATO of deliberately attacking the refugees; however, a later report conducted by the ICTY entitled Final Report to the Prosecutor by the Committee Established to Review the NATO Bombing Campaign Against the Federal Republic of Yugoslavia opined that "civilians were not deliberately attacked in this incident" and that "neither the aircrew nor their commanders displayed the degree of recklessness in failing to take precautionary measures which would sustain criminal charges." On May 7, NATO bombs hit the Chinese Embassy in Belgrade, killing three Chinese journalists and outraging Chinese public opinion. The United States and NATO later apologized for the bombing, saying that it occurred because of an outdated map provided by the CIA although this was challenged by a joint report from "The Observer" (UK) and "Politiken" (Denmark) newspapers which claimed that NATO intentionally bombed the embassy because it was being used as a relay station for Yugoslav army radio signals. However the report by the newspaper contradicts findings in the same report by the ICTY which stated that the root of the failures in target location "appears to stem from the land navigation techniques employed by an intelligence officer." 
In another major incident at the Dubrava prison in Kosovo, the Yugoslav government attributed 85 civilian deaths to NATO bombing of the facility after NATO cited Serbian and Yugoslav military activity in the area although a Human Rights Watch reported only at least nineteen ethnic Albanian prisoners killed.
By the start of April, the conflict seemed little closer to a resolution and NATO countries began to think seriously about a ground operation—an invasion of Kosovo. This would have to be organized very quickly, as there was little time before winter would set in and much work would have to be done to improve the roads from the Greek and Albanian ports to the envisaged invasion routes through Macedonia and northeastern Albania. British Prime Minister Tony Blair was a strong advocate of ground forces, pressing for this from the United States; his strong stance caused some alarm in Washington as American forces would be making the largest contribution to any offensive. U.S. President Bill Clinton was extremely reluctant to commit American forces for a ground offensive. Instead, Clinton authorized a CIA operation to look into methods to destabilize the Serbian government without training KLA troops. At the same time, Finnish and Russian diplomatic negotiators continued to try to persuade Milošević to back down. Tony Blair would order 50,000 British soldiers to be made ready for a ground offensive: most of the available British Army. 
Milošević finally recognised that NATO was serious in its resolve to end the conflict one way or another and that Russia would not intervene to defend Serbia despite Moscow's strong anti-NATO rhetoric. Faced with little alternative, Milošević accepted the conditions offered by a Finnish–Russian mediation team and agreed to a military presence within Kosovo headed by the UN, but incorporating NATO troops.
The Norwegian special forces Hærens Jegerkommando and Forsvarets Spesialkommando cooperated with the KLA in gathering intelligence information. Preparing for the invasion on June 12, the Norwegian special forces sat together with the KLA on the Ramno mountain on the border between Macedonia and Kosovo and had an excellent scouting point for what was happening inside Kosovo. Together with British special forces, Norwegian special forces were the first to cross over the border into Kosovo. According to Keith Graves with the television network Sky News, the Norwegians were already inside Kosovo two days prior to the marching in of other forces and were among the first to enter into Pristina. The Hærens Jegerkommando's and Forsvarets Spesialkommando's job was to clear the way between the striding parties and to make local deals to implement the peace deal between the Serbians and the Kosovo Albanians.
Yugoslav army withdrawal and the entry of KFOR.
On 3 June 1999, Milošević accepted the terms of an international peace plan to end the fighting, with the Serbian parliament adopting the proposal amid contentious debate with delegates coming close to fistfights at some points. On 10 June, the North Atlantic Council ratified the agreement and suspended air operations.
On 12 June, after Milošević accepted the conditions, the NATO-led peacekeeping Kosovo Force (KFOR) began entering Kosovo. KFOR had been preparing to conduct combat operations, but in the end, its mission was only peacekeeping. It was based upon the Allied Rapid Reaction Corps headquarters commanded by then Lieutenant General Mike Jackson of the British Army. It consisted of British forces (a brigade built from 4th Armored and 5th Airborne Brigades), a French Army Brigade, a German Army brigade, which entered from the west while all the other forces advanced from the south, and Italian Army and United States Army brigades. The U.S. contribution, known as the Initial Entry Force, was led by the 1st Armored Division which was spearheaded by a platoon from the 2nd Battalion, 505th Parachute Infantry Regiment attached to the British Forces. Subordinate units included TF 1–35 Armor from Baumholder, Germany, the 2nd Battalion, 505th Parachute Infantry Regiment from Fort Bragg, North Carolina, the 26th Marine Expeditionary Unit from Camp Lejeune, North Carolina, the 1st Battalion, 26th Infantry Regiment from Schweinfurt, Germany, and Echo Troop, 4th Cavalry Regiment, also from Schweinfurt, Germany. Also attached to the U.S. force was the Greek Army's 501st Mechanized Infantry Battalion. The initial U.S. forces established their area of operation around the towns of Uroševac, the future Camp Bondsteel, and Gnjilane, at Camp Monteith, and spent four months—the start of a stay which continues to date—establishing order in the southeast sector of Kosovo.
During the initial incursion, the U.S. soldiers were greeted by Albanians cheering and throwing flowers as U.S. soldiers and KFOR rolled through their villages. Although no resistance was met, three U.S. soldiers from the Initial Entry Force lost their lives in accidents.
On 1 October 1999, approximately 150 paratroopers from Alpha Company, 1/508th Airborne Battalion Combat Team from Vicenza, Italy parachuted into Ferizaj, Kosovo as part of Operation Rapid Guardian. The purpose of the mission was primarily to warn then Serbian President Slobodan Milošević of NATO resolve and of its rapid military capability. One U.S. soldier, Army Ranger Sgt. Jason Neil Pringle, was killed during operations after his parachute failed to deploy. The paratroopers of the 1/508th then joined paratroopers of the 82nd Airborne and K.F.O.R. in patrolling various areas of Kosovo, without incident, through 3 October 1999. 
Following the military campaign, the involvement of Russian peacekeepers proved to be tense and challenging to the NATO Kosovo force. The Russians expected to have an independent sector of Kosovo, only to be unhappily surprised with the prospect of operating under NATO command. Without prior communication or coordination with NATO, Russian peacekeeping forces entered Kosovo from Bosnia and seized Pristina International Airport.
In 2010, James Blunt described in an interview how his unit was given the assignment of securing Pristina during the advance of the 30,000-strong peacekeeping force and how the Russian army had moved in and taken control of the city's airport before his unit's arrival. As the first officer on the scene, Blunt shared a part in the difficult task of addressing the potentially violent international incident. According to Blunt's account, verified by General Mike Jackson, there was a stand-off with the Russians, and the NATO Supreme Commander, US General Wesley Clark, gave orders to over-power them. Whilst these were questioned by Blunt, they were rejected by General Jackson, with the now famous line, "I'm not having my soldiers responsible for starting World War III."
Furthermore, in June 2000, arms trading relations between Russia and Serbia were exposed which lead to the retaliation and bombings of Russian Checkpoints and area Police Stations. Outpost Gunner was established on a high point in the Preševo Valley by Echo Battery 1/161 Field Artillery in an attempt to monitor and assist with peacekeeping efforts in the Russian Sector. Operating under the support of 2/3 Field Artillery, 1st Armored Division, the Battery was able to successfully deploy and continuously operate a Firefinder Radar which allowed the NATO forces to keep a closer watch on activities in the Sector and the Preševo Valley. Eventually a deal was struck whereby Russian forces operated as a unit of KFOR but not under the NATO command structure.
Reaction to the war.
Support for the war.
Support for the Kosovan War and, in particular, the legitimacy of NATO's bombing campaign came from a variety of sources. Every member of NATO, every EU country, and all of Serbia's neighbours, supported military action with statements from the leaders of Bill Clinton, Václav Havel and Tony Blair respectively describing the war as, "an attack by tanks and artillery on a largely defenseless people whose leaders already have agreed to peace," "the first war for values" and one "to avert what would otherwise be a humanitarian disaster in Kosovo.". Others included the then U.N. Secretary General Kofi Annan who was reported by some sources as acknowledging that the NATO action was legitimate who emphasised that there were times when the use of force was legitimate in the pursuit of peace though Annan stressed that the "Council should have been involved in any decision to use force." The distinction between the legality and legitimacy of the intervention was further highlighted in two separate reports: one conducted by the Independent International Commission on Kosovo entitled The Kosovo Report which found that, "the NATO military intervention was illegal but legitimate", and the second published by the NATO Office of Information and Press which reported that, "the human rights violations committed on a large scale in Kosovo provide an 
incontestable ground with reference to the humanitarian aspect of NATO's intervention." Some critics note that that NATO did not have the backing of the United Nations Security Council meant that its intervention had no legal basis, but according to some legal scholars, "there are nonetheless certain bases for that action that are not legal, but justified.” 
Aside from politicians and diplomats, commentators and intellectuals also supported the war. Michael Ignatieff called NATOs intervention a "morally justifiable response to ethnic cleansing and the resulting flood of refugees, and not the cause of the flood of refugees" while Christopher Hitchens said NATO intervened only, "when Serbian forces had resorted to mass deportation and full-dress ethnic "cleansing."" Writing in The Nation, Richard A. Falk wrote that, "the NATO campaign achieved the removal of Yugoslav military forces from Kosovo and, even more significant, the departure of the dreaded Serbian paramilitary units and police" while an article in The Guardian wrote that for Mary Kaldor, Kosovo represented a laboratory on her thinking for human security, humanitarian intervention and international peacekeeping, the latter two which she defined as, "a genuine belief in the equality of all human beings; and this entails a readiness to risk lives of peacekeeping troops to save the lives of others where this is necessary."
Criticism of the case for war.
Some criticized the NATO intervention as a political diversionary tactic, coming as it did on the heels of the Monica Lewinsky scandal. Some support for this hypothesis may be found in the fact that coverage of the bombing directly replaced coverage of the Monica Lewinsky scandal in American news cycles. Also, some point out that before the bombing, rather than there being an unusually bloody conflict, the KLA was not engaged in a widespread civil war against Yugoslav forces and the death toll among all concerned (including ethnic Albanians) skyrocketed after the NATO intervention.; the absence of war did not mean the presence of peace between Albanians and Serbians however as other sources have noted including: the murder of 1500 Albanians and displacement of 270,000 before the NATO intervention and the systematic repression of the Albanian population through constitutional changes by the Milosevic regime that imposed an "apartheid" in Kosovo. 
Many on the left of Western politics saw the NATO campaign as U.S. aggression and imperialism, while critics on the right considered it irrelevant to their countries' national security interests. Noam Chomsky, Edward Said and Tariq Ali were prominent in opposing the campaign. However, in comparison with the anti-war protests against the 2003 invasion of Iraq, the campaign against the war in Kosovo aroused much less public support.
A number of critics have emerged since the end of the war. They have accused the coalition of leading a war in Kosovo under the false pretense of genocide. U.S. President Clinton and his administration were accused of inflating the number of Kosovo Albanians killed by Serbians. 
After the bombing of the Chinese embassy in Belgrade, Chinese Premier Jiang Zemin said that the US was using its economic and military superiority to aggressively expand its influence and interfere in the internal affairs of other countries. Chinese leaders called the NATO campaign a dangerous precedent of naked aggression, a new form of colonialism, and an aggressive war groundless in morality or law. It was seen as part of a plot by the US to destroy Yugoslavia, expand eastward and control all of Europe.
The United Nations Charter does not allow military interventions in other sovereign countries with few exceptions which, in general, need to be decided upon by the United Nations Security Council; this legal enjoinment has proved controversial with many legal scholars who argue that though the Kosovo War illegal, it was still legitimate. The issue was brought before the UN Security Council by Russia, in a draft resolution which, "inter alia", would affirm "that such unilateral use of force constitutes a flagrant violation of the United Nations Charter". China, Namibia, and Russia voted for the resolution, the other members against, thus it failed to pass.
The war inflicted many casualties. Already by March 1999, the combination of fighting and the targeting of civilians had left an estimated 1,500–2,000 civilians and combatants dead. Final estimates of the casualties are still unavailable for either side.
The war was also controversial because of the choice of targets NATO engaged. The destruction of bridges over the Danube greatly disrupted shipping on the river for months afterwards, causing serious economic damage to countries along the length of the river. Moreover, only state-owned factories were targeted, leading critics to suspect that the bombing campaign was partly designed to prepare the way for a free market-based reconstruction by wealthy foreign powers. Perhaps the most controversial deliberate attack of the war was that made against the headquarters of Serbian television on April 23, which killed at least fourteen people. NATO justified the attack on the grounds that the Serbian television headquarters was part of the Milošević regime's "propaganda machine" and opponents of Milošević inside Serbia charged that the managers of the state TV station had been forewarned of the attack but ordered staff to remain inside the building despite an air raid alert; a later report conducted by the ICTY entitled Final Report to the Prosecutor by the Committee Established to Review the NATO Bombing Campaign Against the Federal Republic of Yugoslavia opined that, "Insofar as the attack actually was aimed at disrupting the communications network, it was legally acceptable" and that, "NATO’s targeting of the RTS building for propaganda purposes was an incidental (albeit complementary) aim of its primary goal of disabling the Serbian military command and control system and to destroy the nerve system and apparatus that keeps Milosević in power." In regards to civilian casualties, it further stated that though they were, "unfortunately high, they do not appear to be clearly disproportionate."
Casualties.
Civilian losses.
In June 2000, the Red Cross reported that 3,368 civilians (2,500 Albanians, 400 Serbs, and 100 Roma) were still missing, nearly one year after the conflict. 
A study by researchers from the Center for Disease Control and Prevention in Atlanta, Georgia published in 2000 in medical journal the Lancet estimated that "12,000 deaths in the total population" could be attributed to war. This number was achieved by surveying 1,197 households from February 1998 through June 1999. 67 out of the 105 deaths reported in the sample population were attributed to war-related trauma, which extrapolates to be 12,000 deaths if the same war-related mortality rate is applied to Kosovo's total population. The highest mortality rates were in men between 15 and 49 (5,421 victims of war) as well as for men over 50 (5,176 victims). For persons younger than 15, the estimates were 160 victims for males and 200 for females. For women between 15–49 the estimate is that there were 510 victims; older than 50 years the estimate is 541 victims. The authors stated that it is not "possible to differentiate completely between civilian and military casualties".
In the 2008 joint study by the Humanitarian Law Center (an NGO from Serbia and Kosovo), The International Commission on Missing Person, and the Missing Person Commission of Serbia made a name-by-name list of war and post-war victims. According to the Kosovo Memory Book, 13,421 people were killed in Kosovo during the conflict, from 1 January 1998 up until December 2000. Of that sum, 10,533 were Albanians, 2,238 were Serbs, 126 Roma, 100 Bosniaks and others.
Civilians killed by NATO airstrikes.
Yugoslavia claimed that NATO attacks caused between 1,200 and 5,700 civilian casualties. NATO's Secretary General, Lord Robertson, wrote after the war that "the actual toll in human lives will never be precisely known" but he then offered the figures found in a report by Human Rights Watch as a reasonable estimate. This report counted between 488 and 527 civilian deaths (90 to 150 of them killed from cluster bomb use) in 90 separate incidents, the worst of which were the 87 Albanian refugees who perished at the hands of NATO bombs, near Koriša. 
Attacks in Kosovo overall were more deadly due to the confused situation with many refugee movements— the one-third of the incidents there account for more than half of the deaths.
Civilians killed by Yugoslav forces.
Various estimates of the number of killings attributed to Yugoslav forces have been announced through the years.
The estimate of 10,000 deaths is used by the United States Department of State, which cited human rights abuses as its main justification for attacking Yugoslavia.
Statistical experts working on behalf of the ICTY prosecution estimate that the total number of dead is about 10,000. Eric Fruits, a professor at Portland State University, argued that the experts' analyses were based on fundamentally flawed data and that none of its conclusions are supported by any valid statistical analysis or tests.
In August 2000, the International Criminal Tribunal for the former Yugoslavia (ICTY) announced that it had exhumed 2,788 bodies in Kosovo, but declined to say how many were thought to be victims of war crimes. Earlier however, KFOR sources told Agence France Presse that of the 2,150 bodies that had been discovered up until July 1999, about 850 were thought to be victims of war crimes.
NATO losses.
Military casualties on the NATO side were light. According to official reports, the alliance suffered no fatalities as a result of combat operations. However, in the early hours of May 5, an American military AH-64 Apache helicopter crashed not far from the border between Serbia and Albania.
Another American AH-64 helicopter crashed about 40 miles (64 km) northeast of Tirana, Albania's capital, very close to the Albanian/Kosovo border. According to CNN, the crash happened 45 miles (72 km) northeast of Tirana. The two American pilots of the helicopter, Army Chief Warrant Officers David Gibbs and Kevin L. Reichert, died in that crash. They were the only NATO ground casualties during the war, according to NATO official statements.
There were other casualties after the war, mostly due to land mines. After the war, the alliance reported the loss of the first US stealth plane (an F-117A stealth fighter) ever shot down by enemy fire. Furthermore an F-16 fighter was lost near Šabac and whose remains are on display in Museum of Aviation in Belgrade, 32 unmanned aerial vehicles (UAVs) from different nations were lost. The wreckages of downed UAVs were shown on Serbian television during the war. Some claim a second F-117A was also heavily damaged, and although it made it back to its base, it never flew again. A-10 Thunderbolts have been reported as casualties, with two shot down
 and another two damaged. Three soldiers of the United States Army have been snatched by Yugoslav Forces across the Macedonian border.
Yugoslav military losses.
NATO did not release any official casualty estimates. The Yugoslav authorities claimed 462 soldiers were killed and 299 wounded by NATO airstrikes. The names of Yugoslav casualties were recorded in a "book of remembrance".
Of military equipment, NATO destroyed around 50 Yugoslav aircraft including 6 MiG-29s destroyed in air-to-air combat. A number of G-4 Super Galebs were destroyed in their hardened aircraft shelter by bunker-busting bombs which started a fire which spread quickly because the shelter doors were not closed. At the end of war, NATO officially claimed that they had destroyed 93 Yugoslav tanks. Yugoslavia admitted a total of 3 destroyed tanks. The latter figure was verified by European inspectors when Yugoslavia rejoined the Dayton accords, by noting the difference between the number of tanks then and at the last inspection in 1995. NATO claimed that the Yugoslav army lost 93 tanks (M-84's and T-55's), 132 APCs, and 52 artillery pieces. Newsweek, the second-largest news weekly magazine in the U.S, gained access to a suppressed US Air Force report that claimed the real numbers were "3 tanks, not 120; 18 armored personnel carriers, not 220; 20 artillery pieces, not 450". Most of the targets hit in Kosovo were decoys, such as tanks made out of plastic sheets with telegraph poles for gun barrels, or old World War II–era tanks which were not functional. Anti-aircraft defences were preserved by the simple expedient of not turning them on, preventing NATO aircraft from detecting them, but forcing them to keep above a ceiling of 15,000 feet (5,000 m), making accurate bombing much more difficult. Towards the end of the war, it was claimed that carpet bombing by B-52 aircraft had caused huge casualties among Yugoslav troops stationed along the Kosovo–Albania border. Careful searching by NATO investigators found no evidence of any such large-scale casualties.
However, the most significant loss for the Yugoslav Army was the damaged and destroyed infrastructure. Almost all military air bases and airfields (Batajnica, Lađevci, Slatina, Golubovci, Kovin, and Đakovica) and other military buildings and facilities were badly damaged or destroyed. Unlike the units and their equipment, military buildings couldn't be camouflaged. thus, defence industry and military technical overhaul facilities were also seriously damaged (Utva, Zastava Arms factory, Moma Stanojlović air force overhaul center, technical overhaul centers in Čačak and Kragujevac). Moreover, in an effort to weaken the Yugoslav Army, NATO targeted several important civilian facilities (the Pančevo oil refinery, bridges, TV antennas, railroads, etc.)
KLA losses.
Kosovo Liberation Army losses are difficult to analyze. According to some reports there were around 1,000 fatalities on the KLA side. Difficulties arise in calculating an accurate figure. Things are complicated by the difficulty of determining who was a KLA member and who was a civilian. For example, the Yugoslavs considered any armed Albanian to be a member of the KLA, regardless of whether he was officially a card-carrying member, so someone who is counted as a civilian by the Albanian side might be counted as a KLA combatant by the Serbs. Also, many KLA members were not wearing any uniforms and had no identification.
Aftermath.
Within three weeks, over 500,000 Albanian refugees had returned home. By November 1999, according to the UN High Commissioner for Refugees, 848,100 out of 1,108,913 had returned.
During the war, 90,000 Serbs fled from Kosovo. The Yugoslav Red Cross had also registered 247,391 mostly Serbian refugees by November. The persistent anti-Serb attacks and riots, including against other non-Albanians, had remained in the anarchic stage until some form of order was established in 2001. This order disintegrated during the 2004 pogrom against non Albanians. More than 164,000 Serbs have left Kosovo during the seven weeks since Yugoslav and Serb forces withdrew and the NATO-led Kosovo Force (KFOR) entered the province.
War crimes.
Serbian war crimes.
The International Criminal Tribunal for the former Yugoslavia charged Milošević with crimes against humanity, violating the laws or customs of war, grave breaches of the Geneva Conventions and genocide for his role during the wars in Croatia, Bosnia, and Kosovo.
Before the end of the bombing, Yugoslav President Slobodan Milošević, along with Milan Milutinović, Nikola Šainović, Dragoljub Ojdanić and Vlajko Stojiljković were charged by the International Criminal Tribunal for the Former Yugoslavia (ICTY) with crimes against humanity including murder, forcible transfer, deportation, and "persecution on political, racial or religious grounds".
Further indictments were leveled in October 2003 against former armed forces chief of staff Nebojša Pavković, former army corps commander Vladimir Lazarević, former police official Vlastimir Đorđević, and the current head of Serbia's public security, Sreten Lukić. All were indicted for crimes against humanity and violations of the laws or customs of war.
War crimes prosecutions have also been carried out in Yugoslavia. Yugoslav soldier Ivan Nikolić was found guilty in 2002 of war crimes in the deaths of two civilians in Kosovo. A significant number of Yugoslav soldiers were tried by Yugoslav military tribunals during the war.
Albanian war crimes.
The ICTY also leveled indictments against KLA members Fatmir Limaj, Haradin Bala, Isak Musliu, and Agim Murtezi for crimes against humanity. They were arrested on February 17 and 18, 2003. Charges were soon dropped against Agim Murtezi as a case of mistaken identity, whereas Fatmir Limaj was acquitted of all charges on November 30, 2005 and released. The charges were in relation to the prison camp run by the defendants at Lapušnik between May and July 1998.
In 2008, Carla Del Ponte published a book in which she alleged that, after the end of the war in 1999, Kosovo Albanians were smuggling organs of between 100 and 300 Serbs and other minorities from the province to Albania. The ICTY and the Serbian War Crimes Tribunal are currently investigating these allegations, as numerous witnesses and new materials have recently emerged.
On March 2005, a U.N. tribunal indicted Kosovo Prime Minister Ramush Haradinaj for war crimes against the Serbs. On March 8, he tendered his resignation. Haradinaj, an ethnic Albanian, was a former commander who led units of the Kosovo Liberation Army and was appointed Prime Minister after winning an election of 72 votes to three in the Kosovo's Parliament in December 2004. Haradinaj was acquitted on all counts. The Office of the Prosecutor has appealed his acquittal, and as of July 2008, the matter remains unresolved.
NATO war crimes.
The Yugoslav government and a number of international pressure groups (e.g. Amnesty International) claimed that NATO had carried out war crimes during the conflict, notably the bombing of the Serbian TV headquarters in Belgrade on April 23, 1999, where 16 people were killed and 16 more were injured. Sian Jones of Amnesty stated, "The bombing of the headquarters of Serbian state radio and television was a deliberate attack on a civilian object and as such constitutes a war crime". However, a later report conducted by the ICTY entitled Final Report to the Prosecutor by the Committee Established to Review the NATO Bombing Campaign Against the Federal Republic of Yugoslavia sided with NATO's version of the attack, opining that, "Insofar as the attack actually was aimed at disrupting the communications network, it was legally acceptable" and that, "NATO’s targeting of the RTS building for propaganda purposes was an incidental (albeit complementary) aim of its primary goal of disabling the Serbian military command and control system and to destroy the nerve system and apparatus that keeps Milosević in power." In regards to civilian casualties, it further stated that though they were, "unfortunately high, they do not appear to be clearly disproportionate." Activist/Writer Noam Chomsky claims this is inaccurate as the mass exodus of civilians did not occur until after the NATO bombing, and in his view NATO acted without the support of the United Nations and therefore this constitutes a war crime.
Military and political consequences.
The Kosovo war had a number of important consequences in terms of the military and political outcome. The status of Kosovo remains unresolved; international negotiations began in 2006 to determine the level of autonomy Kosovo would have, as envisaged under UN Security Council Resolution 1244, but failed. The province is administered by the United Nations despite its unilateral declaration of independence on February 17, 2008.
The UN-backed talks, led by UN Special Envoy Martti Ahtisaari, had begun in February 2006. Whilst progress was made on technical matters, both parties remained diametrically opposed on the question of status itself. In February 2007, Ahtisaari delivered a draft status settlement proposal to leaders in Belgrade and Pristina, the basis for a draft UN Security Council Resolution which proposes "supervised independence" for the province, which is in contrary to UN Security Council Resolution 1244. By July 2007, the draft resolution, which was backed by the United States, United Kingdom, and other European members of the Security Council, had been rewritten four times to try to accommodate Russian concerns that such a resolution would undermine the principle of state sovereignty. Russia, which holds a veto in the Security Council as one of five permanent members, stated that it would not support any resolution which is not acceptable to both Belgrade and Priština.
The campaign exposed significant weaknesses in the U.S. arsenal, which were later addressed for the Afghanistan and Iraq campaigns. Apache attack helicopters and AC-130 Spectre gunships were brought up to the front lines but were never actually used after two Apaches crashed during training in the Albanian mountains. Stocks of many precision missiles were run down to critically low levels; had the campaign lasted much longer, NATO would have had to revert back to using "dumb" bombs for lack of anything better. The situation was not any better with the combat aircraft; continuous operations meant skipped maintenance schedules and many aircraft were withdrawn from service awaiting spare parts and service. Also, many of the precision-guided weapons proved unable to cope with Balkan weather, as the clouds blocked the laser guidance beams. This was resolved by retrofitting bombs with Global Positioning System satellite guidance devices that are immune to bad weather. Also, although pilotless surveillance aircraft were extensively used, it often proved the case that attack aircraft could not be brought to the scene quickly enough to hit targets of opportunity. This led to the fitting of missiles to Predator drones in Afghanistan, reducing the "sensor to shooter" time to virtually nothing.
Military decorations.
As a result of the Kosovo War, the North Atlantic Treaty Organisation created a second NATO medal, the NATO Medal for Kosovo Service, an international military decoration. Shortly thereafter, NATO created the Non-Article 5 Medal for Balkans service to combine both Yugoslavian and Kosovo operations into one service medal.
Due to the involvement of the United States armed forces, a separate U.S. military decoration, known as the Kosovo Campaign Medal, was established by President Bill Clinton in 2000.
Weaponry & Vehicular Units used on all sides.
A variety of weapons were used by the Yugoslav security forces and the Kosovo Liberation Army during the conflict. NATO only operated aircraft and various naval units for the duration of the conflict.
The following weapons used by Yugoslav government forces are listed below. Most of them were Yugoslav made weaponry, while almost all of the AA units were Soviet made.
The following weapons used by the Kosovo Liberation Army are listed below. They mostly consist of Soviet Kalashnikov weaponry, also Chinese derivatives of the AK-47 and some Western weaponry.
The following aircraft used by NATO are listed below.
Literature.
and in novels

Kurdish genocide

Kuril Islands
The Kuril Islands or Kurile Islands (, , or ; ; Japanese: ), in Russia's Sakhalin Oblast region, form a volcanic archipelago that stretches approximately northeast from Hokkaido, Japan, to Kamchatka, Russia, separating the Sea of Okhotsk from the North Pacific Ocean. There are 56 islands and many more minor rocks. It consists of Greater Kuril Ridge and Lesser Kuril Ridge. The total land area is about and total population about 19,000.
All of the islands are under the Russian jurisdiction, but Japan claims the two southernmost large islands (Iturup and Kunashir) as part of its territory, as well as Shikotan and the Habomai islets, which has led to the ongoing Kuril Islands dispute.
Nomenclature.
The name "Kuril" originates from the autonym of the aboriginal Ainu, the islands' original inhabitants: "kur", meaning man. It may also be related to names for other islands that have traditionally been inhabited by the Ainu people, such as "Kuyi" or "Kuye" for Sakhalin and "Kai" for Hokkaidō. In Japanese, the Kuril Islands are known as the Chishima Islands (Kanji: , literally, "Thousand Islands Archipelago"), also known as the Kuriru Islands (Kanji: , literally, "Kuril Archipelago"). Once the Russians reached the islands in the 18th century they found a pseudo-etymology from Russian "kurit" ("курить" - "to smoke") due to the continual fumes and steam above the islands from volcanoes.
Geography.
The Kuril Islands form part of the ring of tectonic instability encircling the Pacific ocean referred to as the Ring of Fire. The islands themselves are summits of stratovolcanoes that are a direct result of the subduction of the Pacific Plate under the Okhotsk Plate, which forms the Kuril Trench some east of the islands. The chain has around 100 volcanoes, some 40 of which are active, and many hot springs and fumaroles. There is frequent seismic activity, including a magnitude 8.5 earthquake in 1963 and one of magnitude 8.3 recorded on November 15, 2006, which resulted in tsunami waves up to reaching the California coast.
The climate on the islands is generally severe, with long, cold, stormy winters and short and notoriously foggy summers. The average annual precipitation is , most of which falls as snow.
The chain ranges from temperate to sub-Arctic climate types, and the vegetative cover consequently ranges from tundra in the north to dense spruce and larch forests on the larger southern islands. The highest elevations on the islands are Alaid volcano (highest point: ) on Atlasov Island at the northern end of the chain and Tyatya volcano () on Kunashir Island at the southern end.
Landscape types and habitats on the islands include many kinds of beach and rocky shores, cliffs, wide rivers and fast gravelly streams, forests, grasslands, alpine tundra, crater lakes and peat bogs. The soils are generally productive, owing to the periodic influxes of volcanic ash and, in certain places, owing to significant enrichment by seabird guano. However, many of the steep, unconsolidated slopes are susceptible to landslides and newer volcanic activity can entirely denude a landscape.
Marine ecology.
Owing to their location along the Pacific shelf edge and the confluence of Okhotsk Sea gyre and the southward Oyashio Current, the Kuril islands are surrounded by waters that are among the most productive in the North Pacific, supporting a wide range and high abundance of marine life.
Invertebrates: Extensive kelp beds surrounding almost every island provide crucial habitat for sea urchins, various mollusks and countless other invertebrates and their associated predators. Many species of squid provide a principal component of the diet of many of the smaller marine mammals and birds along the chain.
Fish: Further offshore, walleye pollock, Pacific cod, several species of flatfish are of the greatest commercial importance. During the 1980s, migratory Japanese sardine was one of the most abundant fish in the summer and the main commercial species, but the fishery collapsed and by 1993 no sardines were reported caught leading to significant economic contraction in the few settlements on the islands. Several salmon species, notably pink and sockeye, spawn on some of the larger islands.
Pinnipeds: The Kuril islands are home to two species of Eared Seal, the Steller Sea Lion and northern fur seal, both of which aggregate on several smaller islands along the chain in the summer to form several of the largest reproductive rookeries in Russia. A distinct Kuril island subspecies of the Common Seal ("Phoca vitulina stejnegeri") and Largha are also abundant.
Pinnipeds were a significant object of harvest for the indigenous populations of the Kuril islands, both for food and materials such as skin and bone. The long term fluctuations in the range and distribution of human settlements along the Kuril island presumably tracked the pinniped ranges. In historical times, fur seals were heavily exploited for their fur in the 19th and early 20th centuries and several of the largest reproductive rookeries, as on Raykoke island, were extirpated. In contrast, commercial harvest of the true seals and Steller Sea Lions has been relatively insignificant on the Kuril islands proper. Since the 1960s there has been essentially no additional harvest and the pinniped populations in the Kuril islands appear to be fairly healthy and in some cases expanding. The notable exception is the now extinct Japanese Sea lion which was known to occasionally haul out on the Kuril islands.
Sea otters were exploited very heavily for their pelts in the 19th century. Indeed, the pursuit of the valuable otter pelts drove the expansion of the Russians onto the islands and much of the Japanese interest. Their numbers consequently dwindled rapidly. A near total ban on harvest since the mid 20th century has allowed the species to recover and they are now reasonably abundant throughout the chain.
Cetaceans: The most abundant cetaceans include Orcas, Harbor and Dall's Porpoises. Baird's and Cuvier's Beaked Whales, Minke Whales, Fin Whales, and Sperm Whales are also observed regularly. The surrounding water is considered as the major habitat for North Pacific Right Whales, one of the most endangered of all whale species.
Seabirds: The Kuril islands are home to many millions of seabirds, including Northern Fulmars, Tufted Puffins, Murres, Kittiwakes, Guillemots, Auklets, Petrels, Gulls, Cormorants. On many of the smaller islands in summer, where terrestrial predators are absent, virtually every possibly hummock, cliff niche or underneath of boulder is occupied by a nesting bird.
Terrestrial ecology.
The composition of terrestrial species on the Kuril islands is dominated by Asian mainland taxa via migration from Hokkaido and Sakhalin Islands and by Kamchatkan taxa from the North. While highly diverse, there is a relatively low level of endemism.
Because of the generally smaller size and isolation of the central islands, few major terrestrial mammals have colonized these, though red and arctic foxes were introduced for the sake of the fur trade in the 1880s. The bulk of the terrestrial mammal biomass is taken up by rodents, many introduced in historical times. The largest southernmost and northernmost islands are inhabited by brown bear, foxes, and martens. Some species of deer are found on the more southerly islands. It is claimed that a wild cat, the Kurilian Bobtail, originates from the Kuril Islands. The bobtail is due to the mutation of a dominant gene. The cat has been domesticated and exported to nearby Russia and bred there, becoming a popular domestic cat.
Among terrestrial birds, ravens, peregrine falcons, some wrens and wagtails are common.
Human settlement history.
The Ainu people were early inhabitants of Kuril Islands, although there are few records that pre-date the 17th century. The Japanese administration first took nominal control of the islands in the Edo period of Japan, in the form of claims by the Matsumae clan. It is claimed that the Japanese knew of the northern islands 370 years ago. On "Shōhō Onkuko Ezu", a map of Japan made by the Tokugawa shogunate, in 1644, there are 39 large and small islands shown northeast of the Shiretoko peninsula and Cape Nosappu.
The Russian Empire began to advance into the Kurils in the early 17th century. Although the Russians often sent expedition parties for research and hunted sea otters, they never went south of Urup island.
Russian settlements extended as far as Iturup in the 18th century. Parts of the islands south of Iturup were occupied by guards of the Tokugawa shogunate.
In 1811, Russian Captain Vasily Golovnin and his crew, who stopped at Kunashir during their hydrographic survey, were captured by retainers of the Nambu clan, and sent to the Matsumae authorities. Because a Japanese trader, Takadaya Kahei, was also captured by Petr Rikord, Captain of a Russian vessel near Kunashir in 1812, Japan and Russia entered into negotiations to establish the border between the two countries.
The "Treaty of Commerce, Navigation and Delimitation" was concluded in 1855, and the border was established between Iturup and Urup. This border confirmed that Japanese territory stretched south from Iturup and Russian territory stretched north of Urup. Sakhalin remained a place where people from both countries could live. The Treaty of Saint Petersburg in 1875 resulted in Japan relinquishing all rights over Sakhalin in exchange for Russia ceding all of the Kuril Islands south of Kamchatka.
During the Russo-Japanese War of 1904–1905, Gunji, a retired Japanese military man and local settler in Shumshu, led an invading party to the Kamchatka coast. Russia sent reinforcements to the area to capture and intern this group. After the war was over, Japan received fishing rights in Russian waters as part of the Russo-Japanese Fisheries Agreement until 1945.
During their armed intervention in Siberia 1918–1925, Japanese forces from the northern Kurils, along with United States and European forces, occupied southern Kamchatka. Japanese vessels made naval strikes against Petropavlovsk-Kamchatsky.
The Soviet Union seized southern Sakhalin and the Kuril islands at the end of World War II. Japan maintains a claim to the four southernmost islands of Kunashir, Iturup, Shikotan, and the Habomai rocks, together called the "Northern Islands Territories" (see Kuril Islands dispute).
Japanese administration.
In 1869, the Meiji government established the Colonization Commission in Sapporo to aid in the development of the northern area. Ezo was renamed Hokkaidō and Kita Ezo later received the name of Karafuto. Eleven provinces and 86 districts were founded by Meiji government and were put under the control of feudal clans. Because the Meiji government could not sufficiently cope with Russians moving to south Sakhalin, Japan negotiated with Russia over control of the Kuril Islands, resulting in the Treaty of Saint Petersburg that ceded the eighteen islands north of Uruppu to Japan and all of Sakhalin to Russia.
Road networks and post offices were established on Kunashiri and Etorofu. Life on the islands became more stable when a regular sea route connecting islands with Hokkaidō was opened and a telegraphic system began. At the end of the Taishō period, towns and villages were organized in the northern territories and village offices were established on each island. The Habomai island towns were all part of Habomai Village for example. In other cases the town and village system was not adopted on islands north of Uruppu, which were under direct control of the Nemuro Subprefectural office of the Hokkaidō government.
Each village had a district forestry system, a marine product examination center, salmon hatchery, post office, police station, elementary school, Shinto temple, and other public facilities. In 1930, 8,300 people lived on Kunashiri island and 6,000 on Etorofu island, and most of them were engaged in coastal and high sea fishing.
There were 17,291 Japanese islanders on the Kurils.
Current situation and the economy.
As of 2003, roughly 16,800 people (ethnic Russians, Ukrainians, Belarusians, Tatars, Nivkhs, Oroch) inhabited the Kuril Islands. Fishing is the primary occupation. The islands have strategic and economic value, in terms of fisheries and also mineral deposits of pyrite, sulfur, and various polymetallic ores.
In recent times the economic rise of the Russian Federation has been seen on the Kurils too.
The most visible sign of improvement is the new construction in infrastructure. Construction workers are now working vigorously to build a pier and a breakwater in Kitovy Bay, central Iturup, where barges are still a major means of transport sailing between the cove and ships anchored offshore. A new road has been carved through the woods near Kurilsk, the island's biggest village, going to the site of an airport scheduled to open in 2010 at a cost of 1.26 billion rubles (US$44 million).
Gidrostroy, the Kurils' biggest business group with interests in fishing as well as construction and real estate, built its second fish processing factory on Iturup island in 2006, introducing a state-of-the-art conveyor system.
To deal with a rise in the demand of electricity, the local government is also upgrading a state-run geothermal power plant at Mount Baransky, an active volcano, where steam and hot water can be found.
Military.
The main Russian force stationed on the islands is the 18th Machine Gun Artillery Division, which has its headquarters in Goryachiye Klyuchi on Iturup Island. There are also Border Guard Service troops stationed on the islands. According to analysts, the division is unlikely to be able to defend the islands against an attack on its own. In February 2011, Russian President Dmitry Medvedev called for substantial reinforcements of the Kuril Islands defences following the heating up of the dispute in early 2011.
Atlasov Island.
The second northernmost, Atlasov Island (Oyakoba in Japanese), is an almost perfect volcanic cone rising sheer out of the sea; it has been praised by the Japanese in haiku, wood-block prints, and other forms, in much the same way as the better-known Mt. Fuji.
List of the islands.
While in Russian sources the islands are mentioned for the first time in 1646, the earliest detailed information about them was provided by the explorer Vladimir Atlasov in 1697. In the 18th and early 19th centuries, the Kuril Islands were explored by Danila Antsiferov, I.Kozyrevsky, Ivan Yevreinov, Fyodor Luzhin, Martin Shpanberg, Adam Johann von Krusenstern, Vasily Golovnin, and Henry James Snow.
North Kurils (Kita-chishima / 北千島)
South Kurils (Minami-chishima / 南千島)

Watergate scandal
The Watergate scandal was a political scandal that occurred in the United States in the 1970s as a result of the June 1972 break-in at the Democratic National Committee headquarters at the Watergate office complex in Washington, D.C., and the Nixon administration's attempted cover-up of its involvement.
The scandal eventually led to the resignation of Richard Nixon, the President of the United States, on August 9, 1974, the only resignation of a U.S. President. The scandal also resulted in the indictment, trial, conviction and incarceration of 43 people, including dozens of Nixon's top administration officials.
The affair began with the arrest of five men for breaking and entering into the Democratic National Committee (DNC) headquarters at the Watergate complex on June 17, 1972. The Federal Bureau of Investigation (FBI) connected cash found on the burglars to a slush fund used by the Committee for the Re-Election of the President, a fundraising group for the Nixon campaign. In July 1973, as evidence mounted against the president's staff, including testimony provided by former staff members in an investigation conducted by the Senate Watergate Committee, it was revealed that President Nixon had a tape-recording system in his offices and he had recorded many conversations.
Recordings from these tapes implicated the president, revealing he had attempted to cover up the break-in. After a protracted series of bitter court battles, the U.S. Supreme Court ruled that the president had to hand over the tapes to government investigators; he ultimately complied.
Facing near-certain impeachment in the House of Representatives and a strong possibility of a conviction in the Senate, Nixon resigned the presidency on August 9, 1974. His successor, Gerald Ford, then issued a pardon to Nixon.
Wiretapping of the Democratic Party's headquarters.
In January 1972, G. Gordon Liddy, general counsel to the Committee for the Re-Election of the President (CRP), presented a campaign intelligence plan to CRP's Acting Chairman Jeb Stuart Magruder, Attorney General John Mitchell, and Presidential Counsel John Dean, that involved extensive illegal activities against the Democratic Party. Mitchell viewed the plan as unrealistic, but two months later he approved a reduced version which involved burgling the Democratic National Committee's (DNC) headquarters at the Watergate Complex in Washington, D.C and placing wiretaps. Liddy was put in charge of the operation. He was assisted by former CIA Agent E. Howard Hunt and CRP Security Coordinator James McCord. John Mitchell resigned as Attorney General to become chairman of CRP.
After two attempts to break into the Watergate Complex failed, on May 17, Liddy's team placed wiretaps on the telephones of DNC Chairman Lawrence O'Brien and Executive Director of Democratic States' Chairman R. Spencer Oliver, Jr. When Magruder and Mitchell read transcripts from the wiretaps, they deemed the information inadequate and ordered another break-in.
Shortly after 1 am on June 17, 1972, Frank Wills, a security guard at the Watergate Complex, noticed tape covering the latch on several doors in the complex (allowing the doors to close but remain unlocked). He removed the tape, and thought nothing of it. He returned an hour later, and having discovered that someone had retaped the locks, Wills called the police. Five men were discovered and arrested inside the DNC's office. The five men were Virgilio González, Bernard Barker, James W. McCord, Jr., Eugenio Martínez, and Frank Sturgis, who were charged with attempted burglary and attempted interception of telephone and other communications. On September 15, a grand jury indicted them, as well as Hunt and Liddy, for conspiracy, burglary, and violation of federal wiretapping laws. The five burglars who broke into the office were tried by Judge John Sirica and convicted on January 30, 1973.
Coverup and its unraveling.
Initial coverup.
Within hours of the burglars' arrest, the FBI discovered the name of E. Howard Hunt in the address books of Barker and Martínez. Nixon administration officials were concerned because Hunt and Liddy were also involved in another secret operation, known as the White House plumbers, which was set up to stop security 'leaks' and to investigate other sensitive security matters. Dean would later testify he was ordered by top Nixon aide John Ehrlichman to "" a briefcase full of surveillance equipment and other evidence found in Hunt's office. Nixon ordered his Chief of Staff H.R. Haldeman to have the CIA block the FBI's investigation into the source of the funding for the burglary.
A few days later, Nixon's Press Secretary, Ron Ziegler, described the event as "a third rate burglary attempt". On August 29 at a news conference, President Nixon stated Dean had conducted a thorough investigation of the matter, when in fact Dean had not conducted any investigation at all. Nixon also said, "I can say categorically that... no one in the White House staff, no one in this Administration, presently employed, was involved in this very bizarre incident." On September 15, Nixon congratulated Dean, saying, "The way you've handled it, it seems to me, has been very skillful, because you—putting your fingers in the dikes every time that leaks have sprung here and sprung there."
Money trail.
On June 19, 1972, it was publicly revealed that one of the Watergate burglars was a Republican Party security aide. Former Attorney General John Mitchell, who at the time was the head of the Nixon re-election campaign (CRP), denied any involvement with the Watergate break-in or knowledge of the five burglars. On August 1, a $25,000 cashier's check earmarked for the Nixon re-election campaign was found in the bank account of one of the Watergate burglars. Further investigation by the FBI would reveal still more thousands had supported their travel and expenses in the months leading up to their arrests. Examination showed links to the finance committee of CRP.
Several donations (totaling $86,000) were made by individuals who thought they were making private donations by certified and cashier's checks for the President's re-election. Investigators' examination of the bank records of a Miami company run by Watergate burglar Barker revealed an account controlled by him personally had deposited a check and then transferred it (through the Federal Reserve Check Clearing System).
The banks that had originated the checks were keen to ensure the depository institution used by Barker had acted properly in ensuring the checks had been received and endorsed by the check’s payee, prior to its acceptance for deposit in Bernard Barker's account. Only in this way would the issuing banks not be held liable for the unauthorized and improper release of funds from their customer’s accounts.
The investigation by the FBI, which cleared Barker’s bank of fiduciary malfeasance, led to the direct implication of members of the CRP, to whom the checks had been delivered. Those individuals were the Committee bookkeeper and its treasurer, Hugh Sloan.
The Committee, as a private organization, followed normal business practice in allowing only duly-authorized individual(s) to accept and endorse on behalf of the Committee. Therefore, no financial institution could accept or process a check on behalf of the Committee unless it had been endorsed and by a duly-authorized individual. On the checks deposited into Barker’s bank account was the endorsement of Committee treasurer Hugh Sloan, who was authorized by the Finance Committee. But once Sloan had endorsed a check made payable to the Committee, he had a legal and fiduciary responsibility to see that the check was deposited into the accounts which were named on the check and only the accounts so named. Sloan failed to do that. When he was confronted with the potential charge of federal bank fraud, he revealed he had been directed by Committee deputy director Jeb Magruder and finance director Maurice Stans to give the money to G. Gordon Liddy.
Liddy gave the money to Barker and attempted to hide its origin. Barker had attempted to disguise the funds by depositing them into bank accounts which were located in banks outside of the United States. What Barker, Liddy, and Sloan did not know was that the complete record of all such transactions are held for roughly six months. Barker’s use of foreign banks to deposit checks and withdraw the funds via cashier's checks and money orders in April and May 1972 guaranteed the banks would keep the entire transaction records until October and November 1972.
All five of the Watergate burglars were directly or indirectly tied to the 1972 CRP, causing Judge Sirica to suspect a conspiracy involving higher-echelon government officials.
On September 29, 1972 it was revealed that John Mitchell, while serving as Attorney General, controlled a secret Republican fund used to finance intelligence-gathering against the Democrats. On October 10, the FBI reported the Watergate break-in was only part of a massive campaign of political spying and sabotage on behalf of the Nixon re-election committee. Despite these revelations, Nixon's campaign was never seriously jeopardized, and on November 7, the President was re-elected in one of the biggest landslides in American political history.
Role of the media.
The connection between the break-in and the re-election committee was highlighted by media coverage — in particular, investigative coverage by "The Washington Post", "Time Magazine", and "The New York Times". The coverage dramatically increased publicity and consequent political repercussions. Relying heavily upon anonymous sources, "Post" reporters Bob Woodward and Carl Bernstein uncovered information suggesting knowledge of the break-in, and attempts to cover it up, led deep into the Justice Department, the FBI, the CIA, and the White House.
Chief among the "Post's" anonymous sources was an individual whom Woodward and Bernstein had nicknamed Deep Throat; thirty years later in 2005, he was revealed to be William Mark Felt, Sr., the former Deputy Director of the FBI. Felt met secretly with Woodward, telling him of Howard Hunt’s involvement with the Watergate break-in, and that the White House staff regarded the stakes in Watergate extremely high. Felt warned Woodward that the FBI wanted to know where he and other reporters were getting their information, as they were uncovering a wider web of crimes than first disclosed. In one of their last meetings, all of which took place at an underground parking garage somewhere in Washington, DC at 2:00 am, Felt cautioned Woodward that he might be followed and not to trust their phone conversations to be secure. Felt also planted leaks about Watergate to Time Magazine, the Washington Daily News and other publications. While Carl Bernstein has ascribed Felt's motives to truth telling and protecting the justice system against Presidential abuse, historian Max Holland in his 2012 book "Leak: Why Mark Felt Became Deep Throat" claimed Felt planted the leaks to obtain the FBI director's job (the leaks hurt L. Patrick Gray, Nixon's friend who had recently been chosen for the director's position over Felt).. John Dean remarked that "Max has got it right—he nailed it”. Bob Woodward who was interviewed for the book said the idea that they were reporting just what prosecutors had already found is "factually wrong" and a lot of the book is speculations and conjecture. Carl Bernstein said the book is part of the revisionism and debunking industries. 
During this early period, most of the media failed to grasp the full implications of the scandal, and concentrated reporting on other topics related to the 1972 Presidential election. After the revelation that one of the convicted burglars wrote to Judge Sirica alleging a high-level coverup, the media shifted its focus. "Time Magazine" described Nixon as undergoing "daily hell and very little trust". The distrust between the press and the Nixon administration was mutual and greater than usual due to lingering dissatisfaction with events from the Vietnam War. Public distrust of the media reached over 40%.
Nixon and top administration officials discussed using government agencies to "get" what they perceived as hostile media organizations. The discussions had precedent. At the request of Nixon's White House in 1969, the FBI tapped the phones of five reporters. In 1971, the White House requested an audit of the tax return of the editor of "Newsday", after he wrote a series of articles about the financial dealings of a friend of the President's.
The Administration and their supporters accused the media of making "wild accusations", putting too much emphasis on this story, and of having a liberal bias against the Administration. Nixon said in a May 1974 interview with a supporter that if he had followed the liberal policies which he thought the media preferred, "Watergate would have been a blip." The media noted that most of the reporting turned out to be accurate and the competitive nature of the media guaranteed massive coverage of the political scandal. Applications to journalism schools reached an all-time high in 1974.
Scandal blows wide open.
On March 23, 1973, Judge Sirica read the court a letter from Watergate burglar James McCord alleging perjury had been committed in the Watergate trial, and defendants had been pressured to remain silent. Trying to make them talk, Sirica gave Hunt and two burglars provisional sentences of up to 40 years. On March 28 on Nixon's orders, aide John Ehrlichman told Attorney General Richard Kleindienst that nobody in the White House had prior knowledge of the burglary. On April 13, Magruder told U.S. attorneys that he had perjured himself during the burglars' trial, and implicated John Dean and John Mitchell.
Two days later, Dean told Nixon that he had been cooperating with the U.S. attorneys. On that same day, U.S. attorneys told Nixon that Haldeman, Ehrlichman, Dean and other White House officials were implicated in the coverup.
On April 30, Nixon asked for the resignation of H. R. Haldeman and John Ehrlichman, two of his most influential aides, both of whom were indicted, convicted and ultimately sentenced to prison. He fired White House Counsel John Dean, who went on to testify before the Senate and became the key witness against the president. Writing from prison for "New West" and "New York Magazine" in 1977, Ehrlichman claimed Nixon had offered him a large sum of money, which he declined.
On the same day, Nixon appointed a new Attorney General, Elliot Richardson, and gave him authority to designate a special counsel for the Watergate investigation who would be independent of the regular Justice Department hierarchy. In May 1973, Richardson named Archibald Cox to the position.
Senate Watergate hearings and revelation of the Watergate Tapes.
On February 7, 1973, the United States Senate voted 77–0 to approve and establish a select committee to investigate Watergate, with Sam Ervin named chairman the next day. The hearings held by the Senate Committee, in which Dean and other former administration officials testified, were broadcast from May 17 to August 7, 1973. The three major networks of the time agreed to take turns covering the hearings live, each network thus maintained coverage of the hearings every third day, starting with ABC on May 17 and ending with NBC on August 7. An estimated 85% of Americans with television sets tuned in to at least one portion of the hearings.
On Friday, July 13, 1973, during a preliminary interview, the Deputy Minority Counsel Donald Sanders asked White House assistant Alexander Butterfield if there was any type of recording system in the White House.
Butterfield said he was reluctant to answer, but finally stated there was a new system in the White House that automatically recorded everything in the Oval Office, the Cabinet Room and others, as well as Nixon's private office in the Old Executive Office Building. 
On Monday, July 16, 1973, in front of a live, televised audience, the Chief Minority Counsel Fred Thompson asked Butterfield if he was "aware of the installation of any listening devices in the Oval Office of the President?" Butterfield's revelation of the taping system transformed the Watergate investigation yet again. Special Prosecutor Cox immediately subpoenaed the tapes, as did the Senate, but Nixon refused to release them, citing his executive privilege as President of the United States, and ordered Cox to drop his subpoena. Cox refused.
On February 6, 1974, the United States House of Representatives voted 410-4 to approve , giving the Judiciary Committee authority to investigate impeachment charges against the President.
"Saturday Night Massacre".
When Cox refused to drop his subpoena, on October 20, 1973, Nixon demanded the resignations of Attorney General Richardson and his deputy William Ruckelshaus for refusing to fire the special prosecutor. Nixon's search for someone in the Justice Department willing to fire Cox ended with the Solicitor General Robert Bork. Though Bork claims to believe Nixon's order to be valid and appropriate, he considered resigning to avoid being "perceived as a man who did the President's bidding to save my job." To prevent further damage to the Justice Department, Richardson and Ruckelshaus persuaded him not to resign. As the new acting department head, Bork carried out the presidential order and dismissed the special prosecutor.
These actions met considerable public criticism. Responding to the allegations of possible wrongdoing, in front of 400 Associated Press managing editors on November 17, 1973, Nixon stated emphatically, "I'm not a crook." He needed to allow Bork to appoint a new special prosecutor; he chose Leon Jaworski to continue the investigation.
Legal action against Nixon Administration members.
On March 1, 1974, a grand jury in Washington, D.C., indicted several former aides of President Nixon, who became known as the "Watergate Seven": Haldeman, Ehrlichman, Mitchell, Charles Colson, Gordon C. Strachan, Robert Mardian and Kenneth Parkinson, for conspiring to hinder the Watergate investigation. The grand jury secretly named President Nixon as an unindicted co-conspirator. The special prosecutor dissuaded them from an indictment of Nixon, arguing that a President can only be indicted after he leaves office. John Dean, Jeb Stuart Magruder, and other figures had already pled guilty. On April 5, 1974, Dwight Chapin, the former Nixon appointments secretary, was convicted of lying to the grand jury. Two days later, the same grand jury indicted Ed Reinecke, the Republican lieutenant governor of California, on three charges of perjury before the Senate committee.
Release of the transcripts.
The Nixon administration struggled to decide what materials to release. All parties involved agreed that all pertinent information should be released. Whether to release profanity and vulgarity unedited divided his advisers. His legal team favored releasing the tapes unedited, while Press Secretary Ron Ziegler preferred using an edited version where "expletive deleted" would replace the raw material. After several weeks of debate, they decided to release an edited version. Nixon announced the release of the transcripts in a speech to the nation on April 29, 1974. Nixon noted that any audio pertinent to national security information could be redacted from the released tapes.
Initially, Nixon was given a positive reaction for his speech. As people read the transcripts over the next couple of weeks, however, former supporters among the public, media and political community called for Nixon's resignation or impeachment. Vice President Gerald Ford said, "While it may be easy to delete characterization from the printed page, we cannot delete characterization from people's minds with a wave of the hand." The Senate Republican Leader Hugh Scott said the transcripts revealed a "deplorable, disgusting, shabby, and immoral" performance on the part of the President and his former aides. The House Republican Leader John Jacob Rhodes agreed with Scott, and Rhodes recommended that if Nixon's position continued to deteriorate, he "ought to consider resigning as a possible option." The editors of the newspaper "The Chicago Tribune", a publication that had supported Nixon, wrote, "He is humorless to the point of being inhumane. He is devious. He is vacillating. He is profane. He is willing to be led. He displays dismaying gaps in knowledge. He is suspicious of his staff. His loyalty is minimal". The "Providence Journal" wrote, "Reading the transcripts is an emetic experience;" "One comes away feeling unclean." This newspaper continued, that, while the transcripts may not have revealed an indictable offense, they showed Nixon contemptuous of the United States, its institutions, and its people. According to "Time magazine", the Republican Party leaders in the Western United States felt that while there remained a significant number of Nixon loyalists in the party, the majority believed that Nixon should step down as quickly as possible. They were disturbed by the bad language and the coarse, vindictive tone of the conversations in the transcripts.
Supreme Court.
The issue of access to the tapes went to the Supreme Court. On July 24, 1974, in "United States v. Nixon", the Court, which did not include the recused Justice William Rehnquist, ruled unanimously that claims of executive privilege over the tapes were void. They ordered the president to release them to the special prosecutor. On July 30, 1974, President Nixon complied with the order and released the subpoenaed tapes.
Release of the tapes.
The tapes revealed several crucial conversations that took place between the President and his counsel, John Dean, on March 21, 1973. In this conversation, Dean summarized many aspects of the Watergate case, and focused on the subsequent coverup, describing it as a "cancer on the presidency." The burglary team was being paid hush money for their silence and Dean stated: "That's the most troublesome post-thing, because Bob is involved in that; John [Ehrlichman is involved in that; I am involved in that; Mitchell is involved in that. And that's an obstruction of justice." Dean continues and states that Howard Hunt is blackmailing the White House, demanding money immediately, and President Nixon replies that the blackmail money should be paid: "…just looking at the immediate problem, don't you have to have – handle Hunt's financial situation damn soon? […] you've got to keep the cap on the bottle that much, in order to have any options."
At the time of the initial congressional impeachment, it was not known if Nixon had known and approved of the payments to the Watergate defendants earlier than this conversation. Nixon's conversation with Haldeman on August 1, 1972, is one of several that establishes this. Nixon states: "Well…they have to be paid. That's all there is to that. They have to be paid" During the congressional debate on impeachment, some believed that impeachment required a criminally indictable offense. President Nixon's agreement to make the blackmail payments was regarded as an affirmative act to obstruct justice.
On December 7, 1973, it was found that an 18½ minute portion of one recorded tape had been erased. Nixon's longtime personal secretary, Rose Mary Woods, said she had accidentally erased the tape by pushing the wrong pedal on her tape player when answering the phone. The press ran photos showing that it was unlikely for Woods to answer the phone and keep her foot on the pedal. Later forensic analysis determined that the tape had been erased in several segments – at least five, and perhaps as many as nine.
Final investigations and resignation.
Nixon's position was becoming increasingly precarious. On February 6, 1974, the House of Representatives approved giving the Judiciary Committee authority to investigate impeachment of the President. The House Judiciary Committee voted 27-11 on July 27, 1974 to recommend the first article of impeachment against the president: obstruction of justice. The second: abuse of power, and third: contempt of Congress articles were passed on July 29, 1974 and July 30, 1974, respectively. (On August 20, 1974, the Committee would formally submit H. Rept. 93-1305 which included the text of the resolution impeaching President Nixon and setting forth articles of impeachment against him.)
"Smoking Gun" tape.
On August 5, 1974, the White House released a previously unknown audio tape from June 23, 1972. Recorded only a few days after the break-in, it documented the initial stages of the coverup: it revealed Nixon and Haldeman meeting in the Oval Office and formulating a plan to block investigations by having the CIA falsely claim to the FBI that national security was involved. Haldeman introduces the topic as follows: "…the Democratic break-in thing, we're back to the–in the, the problem area because the FBI is not under control, because Gray doesn't exactly know how to control them, and they have… their investigation is now leading into some productive areas […] and it goes in some directions we don't want it to go." After explaining how the money from CRP was traced to the burglars, Haldeman explained to Nixon the coverup plan: "the way to handle this now is for us to have Walters call Pat Gray [FBI and just say, 'Stay the hell out of this …this is ah, business here we don't want you to go any further on it.'" President Nixon approved the plan, and after he is given more information about the involvement of his campaign in the break-in, he tells Haldeman: "All right, fine, I understand it all. We won't second-guess Mitchell and the rest." Returning to the use of the CIA to obstruct the FBI, he instructs Haldeman: "You call them in. Good. Good deal. Play it tough. That's the way they play it and that's the way we are going to play it."
Prior to the release of this tape, President Nixon had denied political motivations in his instructions to the CIA, and claimed he had no knowledge prior to March 21, 1973 of any involvement by senior campaign officials such as John Mitchell. The contents of this tape persuaded Nixon's own lawyers, Fred Buzhardt and James St. Clair, that "The tape proved that the President had lied to the nation, to his closest aides, and to his own lawyersfor more than two years." The tape, which was referred to as a "smoking gun" by Barber Conable, damaged Nixon politically. The ten congressmen who had voted against all three articles of impeachment in the committee announced that they would all support impeachment when the vote was taken in the full House.
In the week before Nixon's resignation, Ehrlichman and Haldeman unsuccessfully tried to get Nixon to grant them the pardons which Nixon had promised them before their April 1973 resignations.
Resignation.
Throughout this time, Nixon denied any involvement in the scandal. After being told by key Republican Senators that enough votes existed to remove him, he decided to resign. In a nationally televised address from the Oval Office on the evening of August 8, 1974, the president said,
The morning that his resignation was to take effect, President and Mrs. Nixon and their family said farewell to the White House staff in the East Room. A helicopter carried them from the White House to Andrews Air Force base in Maryland. Nixon later wrote that he thought, "As the helicopter moved on to Andrews, I found myself thinking not of the past, but of the future. What could I do now?…" At Andrews, he and his family boarded Air Force One to El Toro Marine Corps Air Station in California, and then were transported to his home in San Clemente.
President Ford's pardon of Nixon.
With President Nixon's resignation, Congress dropped its impeachment proceedings. Criminal prosecution was still a possibility both on the Federal and State level. Nixon was succeeded by Vice President Gerald Ford as President, who on September 8, 1974, issued a full and unconditional pardon of Nixon, immunizing him from prosecution for any crimes he had "committed or may have committed or taken part in" as president. In a televised broadcast to the nation, Ford explained that he felt the pardon was in the best interest of the country. He said that the Nixon family's situation "is an American tragedy in which we all have played a part. It could go on and on and on, or someone must write the end to it. I have concluded that only I can do that, and if I can, I must."
Nixon proclaimed his innocence until his death in 1994. In his official response to the pardon, he said that he "was wrong in not acting more decisively and more forthrightly in dealing with Watergate, particularly when it reached the stage of judicial proceedings and grew from a political scandal into a national tragedy."
Some commentators have argued that pardoning Nixon contributed to President Ford's loss of the presidential election of 1976. Allegations of a secret deal made with Ford, promising a pardon in return for Nixon's resignation, led Ford to testify before the House Judiciary Committee on October 17, 1974.
In his autobiography "A Time to Heal", Ford wrote about a meeting he had with Nixon's Chief of Staff, Alexander Haig. Haig was explaining what he and Nixon's staff thought were Nixon's only options. He could try to ride out the impeachment and fight against conviction in the Senate all the way, or he could resign. His options for resigning were to delay his resignation until further along in the impeachment process to try and settle for a censure vote in Congress, or to pardon himself and then resign. Haig told Ford that some of Nixon's staff suggested that Nixon could agree to resign in return for an agreement that Ford would pardon him.
Aftermath.
Final legal actions and effect on the law profession.
Charles Colson pleaded guilty to charges concerning the Daniel Ellsberg case; in exchange, the indictment against him for covering up the activities of the Committee to Re-elect the President was dropped, as it was against Strachan. The remaining five members of the Watergate Seven indicted in March went on trial in October 1974. On January 1, 1975, all but Parkinson were found guilty. In 1976, the U.S. Court of Appeals ordered a new trial for Mardian; subsequently, all charges against him were dropped. Haldeman, Ehrlichman, and Mitchell exhausted their appeals in 1977. Ehrlichman entered prison in 1976, followed by the other two in 1977. Since Nixon and many senior officials involved in Watergate were lawyers, the scandal severely tarnished the public image of the legal profession.
To defuse public demand for direct federal regulation of lawyers (as opposed to leaving it in the hands of state bar associations or courts), the American Bar Association (ABA) launched two major reforms. First, the ABA decided that its existing Model Code of Professional Responsibility (promulgated 1969) was a failure. In 1983 it replaced it with the Model Rules of Professional Conduct. The MRPC have been adopted in part or in whole by 49 states (and is being considered by the last one, California). Its preamble contains an emphatic reminder that the legal profession can remain self-governing only if lawyers behave properly. Second, the ABA promulgated a requirement that law students at ABA-approved law schools take a course in professional responsibility (which means they must study the MRPC). The requirement remains in effect.
On June 24 and 25, 1975, Nixon gave secret testimony to a grand jury. According to news reports at the time, Nixon answered questions about the 18-1/2 minute tape gap, altering White House tape transcripts turned over to the House Judiciary Committee, using the Internal Revenue Service to harass political enemies, and a $100,000 contribution from billionaire Howard Hughes. Aided by the Public Citizen Litigation Group, the historian Stanley Kutler, who has written several books about Nixon and Watergate, sued for release of the transcripts of the testimony. President Obama's justice department opposed the transcripts release on privacy grounds. On July 29, 2011, the U.S. District Judge Royce Lamberth granted Kutler's request, saying that historical interests trumped privacy interests. He noted that Nixon and other key figures likely to be mentioned were deceased and most of the surviving figures had testified under oath, written about or were interviewed about Watergate. The transcripts were not immediately released pending the government's decision on whether to appeal. They were released in their entirety on November 10, 2011, although the names of people still alive were redacted.
Texas A&M University-Central Texas professor Luke Nichter wrote the chief judge of the federal court in Washington to in an effort release hundreds of pages of sealed records of the Watergate 7. In June 2012 The U.S. Department of Justice wrote the court that it would not object to the materials release with some exceptions.
Political and cultural reverberations.
The effect on the 1974 Senate election and House election three months later was significant. The Democrats gained five seats in the Senate and 49 in the House. Watergate led to Congress passing legislation making changes in rules for campaign financing. The scandal contributed to Congress' amending the Freedom of Information Act in 1974, as well as to laws requiring new financial disclosures by key government officials, such as the Ethics in Government Act. While not legally required, other types of personal disclosure, such as releasing recent income tax forms, became expected. Presidents since Franklin D. Roosevelt had recorded many of their conversations, but after Watergate, this practice purportedly ended.
It is argued that Ford's pardon of Nixon played a major role in his defeat in the 1976 presidential election against Jimmy Carter.
According to Thomas J. Johnson, a professor of journalism at Southern Illinois University, Secretary of State Henry Kissinger predicted during Nixon's final days that history would remember Nixon as a great president and that Watergate would be relegated to a "minor footnote."
When Congress investigated the scope of the President's legal powers, it belatedly found that the United States had been declared by presidential administrations to be in a continuous open-ended state of emergency since 1950. Congress enacted the National Emergencies Act in 1976 to regulate such declarations.
The Watergate scandal left such an impression on the national and international consciousness that many scandals since then have been labeled with the suffix "-gate".
In 2010 Congressmen Ron Paul questioned whether the Federal Reserve Bank had been used to funnel illegal money during Watergate and other scandals. This led House Financial Services Committee Chairman Barney Frank to ask the agency to investigate the charges. In April 2012, the Federal Reserve bank inspector general released a report that found "we did not find any evidence of undue political interference with or improper actions by Federal Reserve officials related to the cash found on the Watergate burglars."
In the aftermath of Watergate, "follow the money" became part of the American lexicon and is widely believed to have been uttered by Mark Felt to Woodward and Bernstein. The phrase was never used in the book "All The President's Men" and did not become associated with "All the President's Men" until the movie version of the book was released.
Purpose of the break-in.
Despite the enormous impact of the Watergate scandal, the actual purpose of the break-in of the DNC offices has never been conclusively established. Some hypotheses suggest that the burglars were after specific information. The likeliest of these hypotheses suggests that the target of the break-in was the offices of Larry O'Brien, the Chairman of the DNC. In 1968, O'Brien was appointed by Vice President Hubert Humphrey to serve as the national director of Humphrey's presidential campaign and, separately, by Howard Hughes, to serve as Hughes' public-policy lobbyist in Washington. O'Brien was elected national chairman of the DNC in 1968 and 1970. With the upcoming Presidential election, former Howard Hughes business associate John H. Meier, working with Hubert Humphrey and others, wanted to feed misinformation to Richard Nixon. John Meier's father had been a German agent during World War II. Meier had joined the FBI and in the 1960s had contracted to the CIA to eliminate Fidel Castro using Mafia bosses Sam Giancana and Santo Trafficante. In late 1971, the President’s brother, Donald Nixon, was collecting intelligence for his brother at the time and was asking Meier about Larry O'Brien. In 1956, Donald Nixon had borrowed $205,000 from Howard Hughes and never repaid the loan. The fact of the loan surfaced during the 1960 presidential election campaign embarrassing Richard Nixon and became a real political liability. According to author Donald M. Bartlett, Richard Nixon would do whatever was necessary to prevent another Hughes-Nixon family embarrassment. From 1968 to 1970, Hughes withdrew nearly half a million dollars from the Texas National Bank of Commerce for contributions to both Democrats and Republicans, including presidential candidates Humphrey and Nixon. Hughes wanted Donald Nixon and Meier involved but Richard Nixon was opposed to their involvement.
Meier told Donald that he was sure the Democrats would win the election because they had considerable information on Richard Nixon’s illicit dealings with Howard Hughes that had never been released, and that Larry O’Brien had the information. O’Brien, who had received $25,000 from Hughes, didn’t actually have any documents but Meier claims to have wanted Richard Nixon to think he did. It is only a question of conjecture then that Donald called his brother Richard and told him that Meier gave the Democrats all the Hughes information that could destroy him and that O’Brien had the proof. The fact is Larry O'Brien, elected Democratic Party Chairman, was also a lobbyist for Howard Hughes in a Democratic controlled Congress and the possibility of his finding out about Hughes' illegal contributions to the Nixon campaign was too much of a danger for Nixon to ignore and O'Brien's office at Watergate became a target of Nixon's intelligence in the political campaign. This hypothesis has been proposed as a motivation for the break-in.
James F. Neal who prosecuted the Watergate 7 did not believe Nixon had ordered the break in because of Nixon's surprised reaction when he was told about it. He cited the June 23, 1972, conversation when Nixon asked Haldeman: "Who was the asshole that did it?".

White supremacy
White supremacy is the belief, and/or promotion of the belief, that white people are superior to people of other racial backgrounds. The term is sometimes used specifically to describe a political ideology that advocates the social, political, historical and/or industrial dominance by whites.
White supremacy, as with racial supremacism in general, is rooted in ethnocentrism and a desire for hegemony and power,
 and has frequently resulted in violence against non-whites. Different forms of white supremacy have different conceptions of who is considered white, and not all white supremacist organizations agree on who is their greatest enemy.
White supremacist groups can be found in some countries and regions with a significant white population including Europe, North America, Australia, New Zealand, Latin America, and South Africa. The militant approach taken by white supremacist groups has caused them to be watched closely by law enforcement officials. Some have even been labelled as terrorists. Some European countries have laws forbidding hate speech, as well as other laws that ban or restrict some white supremacist organizations.
Systemic white supremacy.
White supremacy was dominant in the United States before the American Civil War and for decades after Reconstruction. In large areas of the United States, this included the holding of non-whites (specifically African Americans) in chattel slavery. The outbreak of the Civil War saw the desire to uphold white supremacy cited as a cause for state secession and the formation of the Confederate States of America.
In some parts of the United States, many people who were considered non-white were disenfranchised, barred from government office, and prevented from holding most government jobs well into the second half of the 20th century. Many U.S. states banned interracial marriage through anti-miscegenation laws until 1967, when these laws were declared unconstitutional. White leaders often viewed Native Americans as obstacles to economic and political progress, rather than as settlers in their own right.
White supremacy was also dominant in South Africa under apartheid and in parts of Europe at various time periods. Governments of many European-settled countries bordering the Pacific Ocean limited immigration and naturalization from the Asian Pacific countries, usually on a cultural basis. South Africa maintained its white supremacist apartheid system until the early 1990s.
Academic use of the term.
This and similar definitions are adopted or proposed by Charles Mills, bell hooks, David Gillborn, and Neely Fuller Jr. Some anti-racist educators, such as Betita Martinez and the Challenging White Supremacy workshop, also use the term in this way. The term expresses historic continuities between a pre-Civil Rights era of open white supremacism and the current racial power structure of the United States. It also expresses the visceral impact of structural racism through "provocative and brutal" language that characterizes racism as "nefarious, global, systemic, and constant." Academic users of this term sometimes prefer it to "racism" because it allows for a disconnection between racist feelings and white racial advantage or privilege.
Ideologies and movements.

The eugenicist Madison Grant argued that the Nordic race had been responsible for most of humanity's great achievements, and that admixture was "race suicide". In Grant's 1916 book, "The Passing of the Great Race", Europeans who were not of Germanic origin, but who had Nordic characteristics such as blonde/red hair and blue/green/gray eyes were considered to be a Nordic admixture and suitable for Aryanization.
In the United States, the Ku Klux Klan (KKK) is the group most associated with the white supremacist movement. Many white supremacist groups are based on the concept of preserving genetic purity, and do not focus solely on discrimination by skin color. The KKK's reasons for supporting racial segregation are not primarily based on religious ideals, but some Klan groups are openly Protestant. The KKK and other white supremacist groups like Aryan Nations, The Order and the White Patriot Party are considered Anti-Semitic.
Christian Identity is another movement closely tied to white supremacy. Some white supremacists identify themselves as Odinists, although many Odinists reject white supremacy. Some white supremacist groups, such as the South African Boeremag, conflate elements of Christianity and Odinism. The World Church of the Creator (now called the Creativity Movement) is atheistic and denounces the Christian religion and other deistic religions. Aside from this, its ideology is similar to many Christian Identity groups, in their belief that there is a Jewish conspiracy in control of governments, the banking industry and the media. Matthew F. Hale, founder of the World Church of the Creator has published articles stating that all races other than white are "mud races," which the religion teaches. 
The white supremacist ideology has become associated with a racist faction of the skinhead subculture, despite the fact that when the skinhead culture first developed in the United Kingdom in the late 1960s, it was heavily influenced by black fashions and music, especially Jamaican reggae and ska, and African American soul music By the 1980s, a sizeable and vocal white power skinhead faction had formed.
White supremacist recruitment tactics are primarily on a grassroots level and on the Internet. Widespread access to the Internet has led to a dramatic increase in white supremacist websites. The Internet provides a venue to openly express white supremacist ideas at little social cost, because people who post the information are able to remain anonymous.
Alliances with black supremacist groups.
Due to some commonly held separatist ideologies, some white supremacist organizations have found limited common cause with black supremacist or extremist organizations.
In 1961 and 1962 George Lincoln Rockwell, the leader of the American Nazi Party, was invited to speak by Elijah Muhammad at a Nation of Islam rally. In 1965, after breaking with the Nation of Islam and denouncing its separatist doctrine, Malcolm X told his followers that the Nation of Islam under Elijah Muhammad had made agreements with the American Nazi Party and the Ku Klux Klan that "were not in the interests of Negros." In 1985 Louis Farrakhan invited white supremacist Tom Metzger, leader of the White Aryan Resistance (a neo-Nazi white power group), to attend a NOI gathering. "The Washington Times" reports Metzger's words of praise: "They speak out against the Jews and the oppressors in Washington... They are the black counterpart to us."

Women's rights
Women's rights are the rights and entitlements claimed for women and girls of many societies worldwide. 
In some places these rights are institutionalized or supported by law, local custom, and behaviour, whereas in others they may be ignored or suppressed. They differ from broader notions of human rights through claims of an inherent historical and traditional bias against the exercise of rights by women and girls in favour of men and boys.
Issues commonly associated with notions of women's rights include, though are not limited to, the right: to bodily integrity and autonomy; to vote (suffrage); to hold public office; to work; to fair wages or equal pay; to own property; to education; to serve in the military or be conscripted; to enter into legal contracts; and to have marital, parental and religious rights.
History of women's rights.
China.
The status of women in China was low, largely due to the custom of foot binding. About 45% of Chinese women had bound feet in the 19th century. For the upper classes, it was almost 100%. In 1912, the Chinese government ordered the cessation of foot-binding. Foot-binding involved alteration of the bone structure so that the feet were only about 4 inches long. The bound feet caused difficulty of movement, thus greatly limiting the activities of women.
Due to the social custom that men and women should not be near to one another, the women of China were reluctant to be treated by male doctors of Western Medicine. This resulted in a tremendous need for female doctors of Western Medicine in China. Thus, female medical missionary Dr. Mary H. Fulton (1854-1927) was sent by the Foreign Missions Board of the Presbyterian Church (USA) to found the first medical college for women in China. Known as the Hackett Medical College for Women (夏葛女子醫學院), this College was located in Guangzhou, China, and was enabled by a large donation from Mr. Edward A.K. Hackett (1851-1916) of Indiana, USA. The College was aimed at the spreading of Christianity and modern medicine and the elevation of Chinese women's social status.
Greece.
The status of women in ancient Greece varied form city state to city state. Records exist of women in ancient Delphi, Gortyn, Thessaly, Megara and Sparta owning land, the most prestigious form of private property at the time.
In ancient Athens, women had no legal personhood and were assumed to be part of the oikos headed by the male kyrios. Until marriage, women were under the guardianship of their father or other male relative, once married the husband became a woman’s kyrios. As women were barred from conducting legal proceedings, the kyrios would do so on their behalf. Athenian women had limited right to property and therefore were not considered full citizens, as citizenship and the entitlement to civil and political rights was defined in relation to property and the means to life. However, women could acquire rights over property through gifts, dowry and inheritance, though her kyrios had the right to dispose of a woman’s property. Athenian women could enter into a contract worth less than the value of a “medimnos of barley” (a measure of grain), allowing women to engage in petty trading. Slaves, like women, were not eligible for full citizenship in ancient Athens, though in rare circumstances they could become citizens if freed. The only permanent barrier to citizenship, and hence full political and civil rights, in ancient Athens was gender. No women ever acquired citizenship in ancient Athens, and therefore women were excluded in principle and practice from ancient Athenian democracy.
By contrast, Spartan women enjoyed a status, power, and respect that was unknown in the rest of the classical world. Although Spartan women were formally excluded from military and political life they enjoyed considerable status as mothers of Spartan warriors. As men engaged in military activity, women took responsibility for running estates. Following protracted warfare in the 4th century BC Spartan women owned approximately between 35% and 40% of all Spartan land and property. By the Hellenistic Period, some of the wealthiest Spartans were women. Spartan women rarely married before the age of 20, and unlike Athenian women who wore heavy, concealing clothes and were rarely seen outside the house, Spartan women wore short dresses and went where they pleased. Girls as well as boys received an education, and young women as well as young men may have participated in the "Gymnopaedia" ("Festival of Nude Youths").
Plato acknowledged that extending civil and political rights to women would substantively alter the nature of the household and the state. Aristotle, who had been taught by Plato, denied that women were slaves or subject to property, arguing that "nature has distinguished between the female and the slave", but he considered wives to be "bought". He argued that women's main economic activity is that of safeguarding the household property created by men. According to Aristotle the labour of women added no value because "the art of household management is not identical with the art of getting wealth, for the one uses the material which the other provides".
Contrary to these views, the Stoic philosophers argued for equality of the sexes, sexual inequality being in their view contrary to the laws of nature. In doing so, they followed the Cynics, who argued that men and women should wear the same clothing and receive the same kind of education. They also saw marriage as a moral companionship between equals rather than a biological or social necessity, and practiced these views in their lives as well as their teachings. The Stoics adopted the views of the Cynics and added them to their own theories of human nature, thus putting their sexual egalitarianism on a strong philosophical basis.
Rome.
Father Knows Best.
Under Roman Law all legitimate children male or female fell under Patria Potestas. Patria Potestas was technically absolute and early on included the right to kill children, but during the Late Republic customs changed, and during the Empire, legal rules changed in reflection. The unique thing about Patria Potestas was that it had no age limits, according to Gaius a man could be consul, have a wife and children of his own and future prominence but as long as his father was alive was still under his potestas (power) and so could own nothing. Patria Potestas only ended with either the death of the father, or emancipation by him. Early in the Republic Manus Marriage ended the potestas for women, but during the middle and later Republic that form of marriage became rare, eventually disappearing completely.
Marriage Under Law.
Rome had only two forms of marriage, and both had exactly the opposite view of legal effects. Manus Marriage was the earlier form of marriage and placed the woman under her husband's manus legally standing in the position of a daughter. Under this type of marriage women could own nothing, and had little if any legal protections. On the other hand a woman assumed the position of her husband's daughter in Manus Marriage making her agnatically instead of cognatically related to her children.
Marriage Sine Manu was the second form of marriage that replaced Manus, and was the opposite of Manus. Women married Sine Manu experienced no legal changes, so if her father was alive at time of marriage she continued to be his dependent and before the reign of Marcus Aurelius he could even force an end to the marriage. The lack of any legal change of status for the women meant that (provided their father had either died or emancipated them) they could own property, conduct most forms of business, and divorce her husband (without any reason needed). Legally speaking the only lack of independence a woman in Rome experienced in a marriage without Manus was from her father. The only legal issue related to marriage was dowry. A dowry was not required by law, but was usually provided by a father or if a father was nonexistent it would be whatever the bride wished to come out of her own estate. It was administered by the husband, but in the event of a divorce he was required to provide either the dowry or the equivalent of it back to his wife. In the case of adultery, husbands got to keep portions of the dowry.
Politics.
Legally speaking women were banned from politics. As with freedmen and slaves of the Imperial Family women of the imperial family gained some benefits from the fall of the Republic, but because the nature of the Principate was to hide dictatorship such power had to be subtle and kept out of the public eye when possible. The ban on women and politics was they could not vote or run for office (sine suffragio) enlist in the army, or represent somebody else in court, women speaking their minds was not considered politics and so some women like Hortensia managed to make appearances in politics without violating the law.
Inheritance Rights.
Everyone under the potestas of another had equal rights of inheritance under Roman Law, and wills that did otherwise ran risks of being challenged and invalidated as negligent.
Stoic Influence.
Stoic philosophies had a strong effect on the development of law in ancient Rome. The Roman stoic thinkers Seneca and Musonius Rufus developed theories of just relationships (not to be confused with equality in society, or even equality) arguing that nature gives men and women equal capacity for virtue and equal obligations to act virtuously (a vague concept). Therefore they argued that men and women have an equal need for philosophical education. Stoic theories entered Roman law first through the Roman lawyer and senator Marcus Tullius Cicero and the influence of stoicism and philosophy increased while the status of women improved under the Empire.
Religious scriptures.
Bible.
See Women in the Bible
"Adam named his wife Eve, because she would become the mother of all the living." (Genesis 3:20)
"Now Deborah, a prophet, the wife of Lappidoth, was leading Israel at that time." (Judges 4:4)
God chose a woman, Deborah, to lead Israel.
Qur'an.
The Qur'an, revealed to Muhammad over the course of 23 years, provide guidance to the Islamic community and modified existing customs in Arab society. From 610 and 661, known as the early reforms under Islam, the Qur'an introduced fundamental reforms to customary law and introduced rights for women in marriage, divorce and inheritance. By providing that the wife, not her family, would receive a dowry from the husband, which she could administer as her personal property, the Qur'an made women a legal party to the marriage contract.
While in customary law inheritance was limited to male descendents, the Qur'an introduced rules on inheritance with certain fixed shares being distributed to designated heirs, first to the nearest female relatives and then the nearest male relatives. According to Annemarie Schimmel "compared to the pre-Islamic position of women, Islamic legislation meant an enormous progress; the woman has the right, at least according to the letter of the law, to administer the wealth she has brought into the family or has earned by her own work."
The general improvement of the status of Arab women included prohibition of female infanticide and recognizing women's full personhood. Women were generally given greater rights than women in pre-Islamic Arabia and medieval Europe. Women were not accorded with such legal status in other cultures until centuries later. According to Professor William Montgomery Watt, when seen in such historical context, Muhammad "can be seen as a figure who testified on behalf of women’s rights."
The Middle Ages.
According to English Common Law, which developed from the 12th century onward, all property which a wife held at the time of a marriage became a possession of her husband. Eventually English courts forbade a husband's transferring property without the consent of his wife, but he still retained the right to manage it and to receive the money which it produced. French married women suffered from restrictions on their legal capacity which were removed only in 1965. In the 16th century, the Reformation in Europe allowed more women to add their voices, including the English writers Jane Anger, Aemilia Lanyer, and the prophetess Anna Trapnell. English and American Quakers believed that men and women were equal. Many Quaker women were preachers. Despite relatively greater freedom for Anglo-Saxon women, until the mid-19th century, writers largely assumed that a patriarchal order was a natural order that had always existed. This perception was not seriously challenged until the 18th century when Jesuit missionaries found matrilineality in native North American peoples.
18th and 19th century Europe.
Starting in the late 18th century, and throughout the 19th century, rights, as a concept and claim, gained increasing political, social and philosophical importance in Europe. Movements emerged which demanded freedom of religion, the abolition of slavery, rights for women, rights for those who did not own property and universal suffrage. In the late 18th century the question of women's rights became central to political debates in both France and Britain. At the time some of the greatest thinkers of the Enlightenment, who defended democratic principles of equality and challenged notions that a privileged few should rule over the vast majority of the population, believed that these principles should be applied only to their own gender and their own race. The philosopher Jean Jacques Rousseau for example thought that it was the order of nature for woman to obey men. He wrote "Women do wrong to complain of the inequality of man-made laws" and claimed that "when she tries to usurp our rights, she is our inferior".
“All citizens including women are equally admissible to all public dignities, offices and employments, according to their capacity, and with no other distinction than that of their virtues and talents”.
De Gouges also draws attention to the fact that under French law women were fully punishable, yet denied equal rights.
Mary Wollstonecraft, a British writer and philosopher, published "A Vindication of the Rights of Woman" in 1792, arguing that it was the education and upbringing of women that created limited expectations. Wollstonecraft attacked gender oppression, pressing for equal educational opportunities, and demanded "justice!" and "rights to humanity" for all. Wollstonecraft, along with her British contemporaries Damaris Cudworth and Catherine Macaulay started to use the language of rights in relation to women, arguing that women should have greater opportunity because like men, they were moral and rational beings.
"We are continually told that civilization and Christianity have restored to the woman her just rights. Meanwhile the wife is the actual bondservant of her husband; no less so, as far as the legal obligation goes, than slaves commonly so called."
Then a member of parliament, Mill argued that women should be given the right to vote, though his proposal to replace the term "man" with "person" in the second Reform Bill of 1867 was greeted with laughter in the House of Commons and defeated by 76 to 196 votes. His arguments won little support amongst contemporaries but his attempt to amend the reform bill generated greater attention for the issue of women's suffrage in Britain. Initially only one of several women’s rights campaign, suffrage became the primary cause of the British women’s movement at the beginning of the 20th century. At the time the ability to vote was restricted to wealthy property owners within British jurisdictions. This arrangement implicitly excluded women as property law and marriage law gave men ownership rights at marriage or inheritance until the 19th century. Although male suffrage broadened during the century, women were explicitly prohibited from voting nationally and locally in the 1830s by a Reform Act and the Municipal Corporations Act. Millicent Fawcett and Emmeline Pankhurst led the public campaign on women's suffrage and in 1918 a bill was passed allowing women over the age of 30 to vote.
Equal employment rights for women and men.
The rights of women and men to have equal pay and equal benefits for equal work were openly denied by the British Hong Kong Government up to the early 1970s. Leslie Wah-Leung Chung (鍾華亮, 1917-2009), President of the Hong Kong Chinese Civil Servants’ Association 香港政府華員會 (1965-68), contributed to the establishment of equal pay for men and women, including the right for married women to be permanent employees. Before this, the job status of a woman changed from permanent employee to temporary employee once she was married, thus losing the pension benefit. Some of them even lost their jobs. Since nurses were mostly women, this improvement of the rights of married women meant much to the Nursing profession.
Suffrage, the right to vote.
During the 19th century some women began to agitate for the right to vote and participate in government and law making. Other women opposed suffrage like Helen Kendrick Johnson, whose prescient 1897 work Woman and the Republic contains perhaps the best arguments against women's suffrage of the time. The ideals of women's suffrage developed alongside that of universal suffrage and today women's suffrage is considered a right (under the Convention on the Elimination of All Forms of Discrimination Against Women). During the 19th century the right to vote was gradually extended in many countries and women started to campaign for their right to vote. In 1893 New Zealand became the first country to give women the right to vote on a national level. Australia gave women the right to vote in 1902. A number of Nordic countries gave women the right to vote in the early 20th century – Finland (1906), Norway (1913), Denmark and Iceland (1915). With the end of the First World War many other countries followed – the Netherlands (1917), Austria, Azerbaijan, Canada, Czechoslovakia, Georgia, Poland,and Sweden (1918), Germany and Luxembourg (1919), and the United States (1920) . Spain gave women the right to vote in 1931, France in 1944, Belgium, Italy, Romania and Yugoslavia in 1946. Switzerland gave women the right to vote in 1971, and Liechtenstein in 1984.
In Latin America some countries gave women the right to vote in the first half of the 20th century – Ecuador (1929), Brazil (1932), El Salvador (1939), Dominican Republic (1942), Guatemala (1956) and Argentina (1946). In India, under colonial rule, universal suffrage was granted in 1935. Other Asian countries gave women the right to vote in the mid 20th century – Japan (1945), China (1947) and Indonesia (1955). In Africa women generally got the right to vote along with men through universal suffrage – Liberia (1947), Uganda (1958) and Nigeria (1960). In many countries in the Middle East universal suffrage was acquired after the Second World War, although in others, such as Kuwait, suffrage is very limited. On 16 May 2005, the Parliament of Kuwait extended suffrage to women by a 35–23 vote.
Property rights.
During the 19th century some women in the United States and Britain began to challenge laws that denied them the right to their property once they married. Under the common law doctrine of "coverture" husbands gained control of their wives' real estate and wages. Beginning in the 1840s, state legislatures in the United States and the British Parliament began passing statutes that protected women's property from their husbands and their husbands' creditors. These laws were known as the Married Women's Property Acts. Courts in the 19th-century United States also continued to require privy examinations of married women who sold their property. A privy examination was a practice in which a married woman who wished to sell her property had to be separately examined by a judge or justice of the peace outside of the presence of her husband and asked if her husband was pressuring her into signing the document.
Modern movements.
In the subsequent decades women's rights again became an important issue in the English speaking world. By the 1960s the movement was called "feminism" or "women's liberation." Reformers wanted the same pay as men, equal rights in law, and the freedom to plan their families or not have children at all. Their efforts were met with mixed results.
In the UK, a public groundswell of opinion in favour of legal equality had gained pace, partly through the extensive employment of women in what were traditional male roles during both world wars. By the 1960s the legislative process was being readied, tracing through MP Willie Hamilton's select committee report, his equal pay for equal work bill, the creation of a Sex Discrimination Board, Lady Sear's draft sex anti-discrimination bill, a government Green Paper of 1973, until 1975 when the first British Sex Discrimination Act, an Equal Pay Act, and an Equal Opportunities Commission came into force. With encouragement from the UK government, the other countries of the EEC soon followed suit with an agreement to ensure that discrimination laws would be phased out across the European Community.
In the USA, the National Organization for Women (NOW) was created in 1966 with the purpose of bringing about equality for all women. NOW was one important group that fought for the Equal Rights Amendment (ERA). This amendment stated that "equality of rights under the law shall not be denied or abridged by the United States or any state on account of sex." But there was disagreement on how the proposed amendment would be understood. Supporters believed it would guarantee women equal treatment. But critics feared it might deny women the right be financially supported by their husbands. The amendment died in 1982 because not enough states had ratified it. ERAs have been included in subsequent Congresses, but have still failed to be ratified.
In Ukraine, FEMEN was founded in 2008. The organisation is internationally known for its topless protests against sex tourists, international marriage agencies, sexism and other social, national and international social illnesses. FEMEN has sympathisers groups in many European countries through social media.
Birth control and reproductive rights.
In the 1870s feminists advanced the concept of "voluntary motherhood" as a political critique of "involuntary motherhood" and expressing a desire for women's emancipation. Advocates for voluntary motherhood disapproved of contraception, arguing that women should only engage in sex for the purpose of procreation and advocated for periodic or permanent abstinence.
In the early 20th century "birth control" was advanced as alternative to the then fashionable terms "family limitation" and "voluntary motherhood". The phrase "birth control" entered the English language in 1914 and was popularised by Margaret Sanger, who was mainly active in the US but had gained an international reputation by the 1930s. The British birth control campaigner Marie Stopes made contraception acceptable in Britain during the 1920 by framing it in scientific terms. Stopes assisted emerging birth control movements in a number of British colonies. The birth control movement advocated for contraception so as to permit sexual intercourse as desired without the risk of pregnancy. By emphasising "control" the birth control movement argued that women should have control over their reproduction and the movement had close ties to the feminist movement. Slogans such as "control over our own bodies" criticised male domination and demanded women's liberation, a connotation that is absent from the family planning, population control and eugenics movements. In the 1960s and 1970s the birth control movement advocated for the legalisation of abortion and large scale education campaigns about contraception by governments. In the 1980s birth control and population control organisations co-operated in demanding rights to contraception and abortion, with an increasing emphasis on "choice".
Birth control has become a major themes in feminist politics who cited reproduction issues as examples of women's powerlessness to exercise their rights. The societal acceptance of birth control required the separation of sex from procreation, making birth control a highly controversial subject in the 20th century. In a broader context birth control has become an arena for conflict between liberal and conservative values, raising questions about family, personal freedom, state intervention, religion in politics, sexual morality and social welfare. "Reproductive rights", that is rights relating to sexual reproduction and reproductive health, were first discussed as a subset of human rights at the United Nation's 1968 International Conference on Human Rights. Reproductive rights are not recognised in international human rights law and is an umbrella term that may include some or all of the following rights: the right to legal or safe abortion, the right to control one's reproductive functions, the right to access quality reproductive healthcare, and the right to education and access in order to make reproductive choices free from coercion, discrimination, and violence. Reproductive rights may also be understood to include education about contraception and sexually transmitted infections, and freedom from coerced sterilization and contraception, protection from gender-based practices such as female genital mutilation (FGM) and male genital mutilation (MGM). Reproductive rights are understood as rights of both men and women, but are most frequently advanced as women's rights.
Women's access to legal abortions is restricted by law in most countries in the world. Where abortion is permitted by law, women may only have limited access to safe abortion services. Only a small number of countries prohibit abortion in all cases. In most countries and jurisdictions, abortion is allowed to save the pregnant woman's life, or where the pregnancy is the result of rape or incest. According to Human Rights Watch "Abortion is a highly emotional subject and one that excites deeply held opinions. However, equitable access to safe abortion services is first and foremost a human right. Where abortion is safe and legal, no one is forced to have one. Where abortion is illegal and unsafe, women are forced to carry unwanted pregnancies to term or suffer serious health consequences and even death. Approximately 13% of maternal deaths worldwide are attributable to unsafe abortion—between 68,000 and 78,000 deaths annually." According to Human Rights Watch "the denial of a pregnant woman's right to make an independent decision regarding abortion violates or poses a threat to a wide range of human rights." Other groups however, such as the Catholic Church, the Christian right and most Orthodox Jews, regard abortion not as a right but as a 'moral evil'.
United Nations and World Conferences on Women.
In 1946 the United Nations established a Commission on the Status of Women. Originally as the Section on the Status of Women, Human Rights Division, Department of Social Affairs, and now part of the Economic and Social Council (ECOSOC). Since 1975 the UN has held a series of world conferences on women's issues, starting with the World Conference of the International Women's Year in Mexico City. These conferences created an international forum for women's rights, but also illustrated divisions between women of different cultures and the difficulties of attempting to apply principles universally. Four World Conferences have been held, the first in Mexico City (International Women's Year, 1975), the second in Copenhagen (1980) and the third in Nairobi (1985). At the Fourth World Conference on Women in Beijing (1995), "The Platform for Action" was signed. This included a commitment to achieve "gender equality and the empowerment of women". In 2010, UN Women is founded by merging of Division for the Advancement of Women, International Research and Training Institute for the Advancement of Women, Office of the Special Adviser or Gender Issues Advancement of Women and United Nations Development Fund for Women by General Assembly Resolution 63/311.
Natural law and women's rights.
17th century natural law philosophers in Britain and America, such as Thomas Hobbes, Jean-Jacques Rousseau and John Locke, developed the theory of natural rights in reference to ancient philosophers such as Aristotle and the Christian theologise Aquinas. Like the ancient philosophers, 17th century natural law philosophers defended slavery and an inferior status of women in law. Relying on ancient Greek philosophers, natural law philosophers argued that natural rights where not derived from god, but were "universal, self-evident, and intuitive", a law that could be found in nature. They believed that natural rights were self-evident to "civilised man" who lives "in the highest form of society". Natural rights derived from human nature, a concept first established by the ancient Greek philosopher Zeno of Citium in "Concerning Human Nature". Zenon argued that each rational and civilized male Greek citizen had a "divine spark" or "soul" within him that existed independent of the body. Zeno founded the Stoic philosophy and the idea of a human nature was adopted by other Greek philosophers, and later natural law philosophers and western humanists. Aristotle developed the widely adopted idea of rationality, arguing that man was a "rational animal" and as such a natural power of reason. Concepts of human nature in ancient Greece depended on gender, ethnic, and other qualifications and 17th century natural law philosophers came to regard women along with children, slaves and non-whites, as neither "rational" nor "civilised". Natural law philosophers claimed the inferior status of women was "common sense" and a matter of "nature". They believed that women could not be treated as equal due to their "inner nature". The views of 17th century natural law philosophers were opposed in the 18th and 19th century by Evangelical natural theology philosophers such as William Wilberforce and Charles Spurgeon, who argued for the abolition of slavery and advocated for women to have rights equal to that of men. Modern natural law theorist, and advocates of natural rights, claim that all people have a human nature, regardless of gender, ethnicity or other qualifications, therefore all people have natural rights.
Human rights and women's rights.
Convention on the Elimination of All Forms of Discrimination Against Women.
The Universal Declaration of Human Rights, adopted in 1948, enshrines "the equal rights of men and women", and addressed both the equality and equity issues.
In 1979 the United Nations General Assembly adopted the Convention on the Elimination of All Forms of Discrimination against Women (CEDAW) for legal implementation of the Declaration on the Elimination of Discrimination against Women. Described as an international bill of rights for women, it came into force on 3 September 1981. The UN member states that have not ratified the convention are Iran, Nauru, Palau, Somalia, Sudan, Tonga, and the United States. Niue and the Vatican City, which are non-member states, have also not ratified it.
Any distinction, exclusion or restriction made on the basis of sex which has the effect or purpose of impairing or nullifying the recognition, enjoyment or exercise by women, irrespective of their marital status, on a basis of equality of men and women, of human rights and fundamental freedoms in the political, economic, social, cultural, civil or any other field.
It also establishes an agenda of action for putting an end to sex-based discrimination for which states ratifying the Convention are required to enshrine gender equality into their domestic legislation, repeal all discriminatory provisions in their laws, and enact new provisions to guard against discrimination against women. They must also establish tribunals and public institutions to guarantee women effective protection against discrimination, and take steps to eliminate all forms of discrimination practiced against women by individuals, organizations, and enterprises.
United Nations Security Council Resolution 1325.
On 31 October 2000, the United Nations Security Council unanimously adopted United Nations Security Council Resolution 1325, the first formal and legal document from the United Nations Security Council that requires all states respect fully international humanitarian law and international human rights law appicable to the rights and protection of women and girls during and after the armed conflicts.
Maputo Protocol.
The Protocol to the African Charter on Human and Peoples’ Rights on the Rights of Women in Africa, better known as the Maputo Protocol, was adopted by the African Union on 11 July 2003 at its second summit in Maputo, Mozambique. On 25 November 2005, having been ratified by the required 15 member nations of the African Union, the protocol entered into force. The protocol guarantees comprehensive rights to women including the right to take part in the political process, to social and political equality with men, and to control of their reproductive health, and an end to female genital mutilation.
Rape and sexual violence.
Rape, sometimes called sexual assault, is an assault by a person involving sexual intercourse with or sexual penetration of another person without that person's consent. Rape is generally considered a serious sex crime as well as a civil assault. When part of a widespread and systematic practice rape and sexual slavery are now recognised as crime against humanity and war crime. Rape is also now recognised as an element of the crime of genocide when committed with the intent to destroy, in whole or in part, a targeted group.
Rape as an element of the crime of genocide.
In 1998, the International Criminal Tribunal for Rwanda established by the United Nations made landmark decisions that rape is a crime of genocide under international law. The trial of Jean-Paul Akayesu, the mayor of Taba Commune in Rwanda, established precedents that rape is an element of the crime of genocide. The Akayesu judgement includes the first interpretation and application by an international court of the 1948 Convention on the Prevention and Punishment of the Crime of Genocide. The Trial Chamber held that rape, which it defined as "a physical invasion of a sexual nature committed on a person under circumstances which are coercive", and sexual assault constitute acts of genocide insofar as they were committed with the intent to destroy, in whole or in part, a targeted group, as such. It found that sexual assault formed an integral part of the process of destroying the Tutsi ethnic group and that the rape was systematic and had been perpetrated against Tutsi women only, manifesting the specific intent required for those acts to constitute genocide.
Judge Navanethem Pillay said in a statement after the verdict: “From time immemorial, rape has been regarded as spoils of war. Now it will be considered a war crime. We want to send out a strong message that rape is no longer a trophy of war.”
Rape and sexual enslavement as crime against humanity.
The Rome Statute Explanatory Memorandum, which defines the jurisdiction of the International Criminal Court, recognises rape, sexual slavery, enforced prostitution, forced pregnancy, enforced sterilization, "or any other form of sexual violence of comparable gravity" as crime against humanity if the action is part of a widespread or systematic practice. The Vienna Declaration and Programme of Action also condemn systematic rape as well as murder, sexual slavery, and forced pregnancy, as the "violations of the fundamental principles of international human rights and humanitarian law." and require a particularly effective response.
Rape was first recognised as crime against humanity when the International Criminal Tribunal for the former Yugoslavia issued arrest warrants based on the Geneva Conventions and Violations of the Laws or Customs of War. Specifically, it was recognised that Muslim women in Foca (southeastern Bosnia and Herzegovina) were subjected to systematic and widespread gang rape, torture and sexual enslavement by Bosnian Serb soldiers, policemen, and members of paramilitary groups after the takeover of the city in April 1992. The indictment was of major legal significance and was the first time that sexual assaults were investigated for the purpose of prosecution under the rubric of torture and enslavement as a crime against humanity. The indictment was confirmed by a 2001 verdict by the International Criminal Tribunal for the former Yugoslavia that rape and sexual enslavement are crimes against humanity. This ruling challenged the widespread acceptance of rape and sexual enslavement of women as intrinsic part of war. The International Criminal Tribunal for the former Yugoslavia found three Bosnian Serb men guilty of rape of Bosniac (Bosnian Muslim) women and girls (some as young as 12 and 15 years of age), in Foca, eastern Bosnia and Herzegovina. Furthermore two of the men were found guilty of the crime against humanity of sexual enslavement for holding women and girls captive in a number of de facto detention centres. Many of the women subsequently disappeared.

World War II
World War II, or the Second World War (often abbreviated as WWII or WW2), was a global war that was underway by 1939 and ended in 1945. It involved a vast majority of the world's nations—including all of the great powers—eventually forming two opposing military alliances: the Allies and the Axis. It was the most widespread war in history, with more than 100 million people serving in military units. In a state of "total war", the major participants placed their entire economic, industrial, and scientific capabilities at the service of the war effort, erasing the distinction between civilian and military resources. Marked by significant events involving the mass death of civilians, including the Holocaust and the only use of nuclear weapons in warfare, it resulted in 50 million to over 70 million fatalities. These deaths make World War II by far the deadliest conflict in all of human history.
Although the Empire of Japan was already at war with the Republic of China in 1937, the world war is generally said to have begun on 1 September 1939, with the invasion of Poland by Germany, and subsequent declarations of war on Germany by France and most of the countries of the British Empire and Commonwealth. Germany set out to establish a large empire in Europe. From late 1939 to early 1941, in a series of campaigns and treaties, Germany conquered or subdued much of continental Europe. Following the Molotov–Ribbentrop Pact, the nominally neutral Soviet Union fully or partially invaded, occupied and annexed territories of its six European neighbours, including Poland. The United Kingdom and its Commonwealth remained the only major force continuing the fight against the Axis, with battles taking place in North Africa as well as the long-running Battle of the Atlantic. In June 1941, the European Axis launched an invasion of the Soviet Union, giving a start to the largest land theatre of war in history, which tied down the major part of the Axis' military forces for the rest of the war. In December 1941, the Empire of Japan, which aimed to dominate East Asia and Indochina, joined the Axis, attacked the United States and European territories in the Pacific Ocean, and quickly conquered much of the West Pacific.
The Axis advance was stopped in 1942, after Japan lost a series of naval battles and European Axis troops were defeated in North Africa and, decisively, at Stalingrad. In 1943, with a series of German defeats in Eastern Europe, the Allied invasion of Fascist Italy, and American victories in the Pacific, the Axis lost the initiative and undertook strategic retreat on all fronts. In 1944, the Western Allies invaded France, while the Soviet Union regained all of its territorial losses and invaded Germany and its allies. The war in Europe ended with the capture of Berlin by Soviet and Polish troops and the subsequent German unconditional surrender on 8 May 1945. During 1944 and 1945 the United States defeated the Japanese Navy and captured key West Pacific islands, dropping atomic bombs on the country as the invasion of the Japanese archipelago became imminent. This was followed by the Soviet Union declaring war on Japan and invading Japanese-controlled Manchuria The war in Asia ended on 15 August 1945 when the Empire of Japan agreed to surrender.
The total victory of the Allies over the Axis in 1945 ended the conflict. World War II altered the political alignment and social structure of the world. The United Nations (UN) was established to foster international cooperation and prevent future conflicts. The great powers that were the victors of the war—the United States, Soviet Union, China, the United Kingdom, and France—became the permanent members of the United Nations Security Council. The Soviet Union and the United States emerged as rival superpowers, setting the stage for the Cold War, which lasted for the next 46 years. Meanwhile, the influence of European great powers started to decline, while the decolonisation of Asia and Africa began. Most countries whose industries had been damaged moved towards economic recovery. Political integration, especially in Europe, emerged as an effort to stabilise postwar relations.
Chronology.
The start of the war is generally held to be 1 September 1939, beginning with the German invasion of Poland; Britain and France declared war on Germany two days later. Other dates for the beginning of war include the start of the Second Sino-Japanese War on 7 July 1937.
Others follow British historian A. J. P. Taylor, who held that the Sino-Japanese War and war in Europe and its colonies occurred simultaneously and the two wars merged in 1941. This article uses the conventional dating. Other starting dates sometimes used for World War II include the Italian invasion of Abyssinia on 3 October 1935. British historian Antony Beevor views the beginning of the Second World War as the Japanese invasion of Manchuria in August 1939.
The exact date of the war's end is also not universally agreed upon. It has been suggested that the war ended at the armistice of 14 August 1945 (V-J Day), rather than the formal surrender of Japan (2 September 1945); in some European histories, it ended on V-E Day (8 May 1945). However, the Treaty of Peace with Japan was not signed until 1951, and that with Germany not until 1990.
Background.
World War I radically altered the political map, with the defeat of the Central Powers, including Austria-Hungary, Germany and the Ottoman Empire; and the 1917 Bolshevik seizure of power in Russia. Meanwhile, existing victorious Allies such as France, Belgium, Italy, Greece and Romania gained territories, while new states were created out of the collapse of Austria-Hungary and the Russian and Ottoman Empires.
Despite the pacific movement in the aftermath of the war, the losses still caused irredentist and revanchist nationalism to became important in a number of European states. Irredentism and revanchism were strong in Germany because of the significant territorial, colonial, and financial losses incurred by the Treaty of Versailles. Under the treaty, Germany lost around 13 percent of its home territory and all of its overseas colonies, while German annexation of other states was prohibited, reparations were imposed, and limits were placed on the size and capability of the country's armed forces. Meanwhile, the Russian Civil War had led to the creation of the Soviet Union.
The German Empire was dissolved in the German Revolution of 1918–1919, and a democratic government, later known as the Weimar Republic, was created. The interwar period saw strife between supporters of the new republic and hardline opponents on both the right and left. Although Italy as an Entente ally made some territorial gains, Italian nationalists were angered that the promises made by Britain and France to secure Italian entrance into the war were not fulfilled with the peace settlement. From 1922 to 1925, the Fascist movement led by Benito Mussolini seized power in Italy with a nationalist, totalitarian, and class collaborationist agenda that abolished representative democracy, repressed socialist, left wing and liberal forces, and pursued an aggressive foreign policy aimed at forcefully forging Italy as a world power—a "New Roman Empire". 
In Germany, the Nazi Party led by Adolf Hitler sought to establish a fascist government in Germany. With the onset of the Great Depression, domestic support for the Nazis rose and, in 1933, Hitler was appointed Chancellor of Germany. In the aftermath of the Reichstag fire, Hitler created a totalitarian single-party state led by the Nazis.
The Kuomintang (KMT) party in China launched a unification campaign against regional warlords and nominally unified China in the mid-1920s, but was soon embroiled in a civil war against its former Chinese communist allies. In 1931, an increasingly militaristic Japanese Empire, which had long sought influence in China as the first step of what its government saw as the country's right to rule Asia, used the Mukden Incident as a pretext to launch an invasion of Manchuria and establish the puppet state of Manchukuo. 
Too weak to resist Japan, China appealed to the League of Nations for help. Japan withdrew from the League of Nations after being condemned for its incursion into Manchuria. The two nations then fought several battles, in Shanghai, Rehe and Hebei, until the Tanggu Truce was signed in 1933. Thereafter, Chinese volunteer forces continued the resistance to Japanese aggression in Manchuria, and Chahar and Suiyuan.
Adolf Hitler, after an unsuccessful attempt to overthrow the German government in 1923, became the Chancellor of Germany in 1933. He abolished democracy, espousing a radical, racially motivated revision of the world order, and soon began a massive rearmament campaign. Meanwhile, France, to secure its alliance, allowed Italy a free hand in Ethiopia, which Italy desired as a colonial possession. The situation was aggravated in early 1935 when the Territory of the Saar Basin was legally reunited with Germany and Hitler repudiated the Treaty of Versailles, accelerated his rearmament programme and introduced conscription.
Hoping to contain Germany, the United Kingdom, France and Italy formed the Stresa Front. The Soviet Union, concerned due to Germany's goals of capturing vast areas of eastern Europe, wrote a treaty of mutual assistance with France. Before taking effect though, the Franco-Soviet pact was required to go through the bureaucracy of the League of Nations, which rendered it essentially toothless. However, in June 1935, the United Kingdom made an independent naval agreement with Germany, easing prior restrictions. The United States, concerned with events in Europe and Asia, passed the Neutrality Act in August. In October, Italy invaded Ethiopia, and Germany was the only major European nation to support the invasion. Italy subsequently dropped its objections to Germany's goal of absorbing Austria.
Hitler defied the Versailles and Locarno treaties by remilitarizing the Rhineland in March 1936. He received little response from other European powers. When the Spanish Civil War broke out in July, Hitler and Mussolini supported the fascist and authoritarian Nationalist forces in their civil war against the Soviet-supported Spanish Republic. Both sides used the conflict to test new weapons and methods of warfare, with the Nationalists winning the war in early 1939. In October 1936, Germany and Italy formed the Rome-Berlin Axis. A month later, Germany and Japan signed the Anti-Comintern Pact, which Italy would join in the following year. In China, after the Xi'an Incident the Kuomintang and communist forces agreed on a ceasefire in order to present a united front to oppose Japan.
Pre-war events.
Italian invasion of Ethiopia (1935).
The Second Italo–Abyssinian War was a brief colonial war that began in October 1935 and ended in May 1936. The war was fought between the armed forces of the Kingdom of Italy ("Regno d'Italia") and the armed forces of the Ethiopian Empire (also known as Abyssinia). The war resulted in the military occupation of Ethiopia and its annexation into the newly created colony of Italian East Africa ("Africa Orientale Italiana", or AOI); in addition, it exposed the weakness of the League of Nations as a force to preserve peace. Both Italy and Ethiopia were member nations, but the League did nothing when the former clearly violated the League's own Article X.
Spanish Civil War (1936-39).
Germany and Italy lent support to the Nationalist insurrection led by general Francisco Franco in Spain. The Soviet Union supported the existing government, the Spanish Republic, which showed leftist tendencies. Both Germany and the USSR used this proxy war as an opportunity to test improved weapons and tactics. The deliberate Bombing of Guernica by the German Condor Legion in April 1937 contributed to widespread concerns that the next major war would include extensive terror bombing attacks on civilians.
Japanese invasion of China (1937).
In July 1937, Japan captured the former Chinese imperial capital of Beijing after instigating the Marco Polo Bridge Incident, which culminated in the Japanese campaign to invade all of China. The Soviets quickly signed a non-aggression pact with China to lend materiel support, effectively ending China's prior cooperation with Germany. Generalissimo Chiang Kai-shek deployed his best army to defend Shanghai, but after three months of fighting, Shanghai fell. The Japanese continued to push the Chinese forces back, capturing the capital Nanking in December 1937 and committed the Nanking Massacre.
In June 1938, Chinese forces stalled the Japanese advance by flooding the Yellow River; this manoeuvre bought time for the Chinese to prepare their defenses at Wuhan, but the city was taken by October. Japanese military victories did not bring about the collapse of Chinese resistance that Japan had hoped to achieve, instead the Chinese government relocated inland to Chongqing and continued the war.
Japanese invasion of the Soviet Union and Mongolia (1938).
On 29 July 1938, the Japanese invaded the USSR and were checked at the Battle of Lake Khasan. Although the battle was a Soviet victory, the Japanese dismissed it as an inconclusive draw, and on 11 May 1939 decided to move the Japanese-Mongolian border up to the Khalkhin Gol River by force. After initial successes the Japanese assault on Mongolia was checked by the Red Army that inflicted the first major defeat on the Japanese Kwantung Army.
These clashes convinced some factions in the Japanese government that they should focus on conciliating the Soviet government to avoid interference in the war against China and instead turn their military attention southward, towards the US and European holdings in the Pacific, and also prevented the sacking of experienced Soviet military leaders such as Georgy Zhukov, who would later play a vital role in the defence of Moscow.
European occupations and agreements.
In Europe, Germany and Italy were becoming bolder. In March 1938, Germany annexed Austria, again provoking little response from other European powers. Encouraged, Hitler began pressing German claims on the Sudetenland, an area of Czechoslovakia with a predominantly ethnic German population; and soon France and Britain conceded this territory to Germany in the Munich Agreement, which was made against the wishes of the Czechoslovak government, in exchange for a promise of no further territorial demands. Soon after that, however, Germany and Italy forced Czechoslovakia to cede additional territory to Hungary and Poland. In March 1939, Germany invaded the remainder of Czechoslovakia and subsequently split it into the German Protectorate of Bohemia and Moravia and the pro-German client state, the Slovak Republic.
Alarmed, and with Hitler making further demands on Danzig, France and Britain guaranteed their support for Polish independence; when Italy conquered Albania in April 1939, the same guarantee was extended to Romania and Greece. Shortly after the Franco-British pledge to Poland, Germany and Italy formalised their own alliance with the Pact of Steel.
In August 1939, Germany and the Soviet Union signed the Molotov–Ribbentrop Pact, a non-aggression treaty with a secret protocol. The parties gave each other rights, "in the event of a territorial and political rearrangement," to "spheres of influence" (western Poland and Lithuania for Germany, and eastern Poland, Finland, Estonia, Latvia and Bessarabia for the USSR). It also raised the question of continuing Polish independence.
Course of the war.
War breaks out in Europe (1939).
On 1 September 1939, Germany and Slovakia—a client state in 1939—attacked Poland. On 3 September France and Britain, followed by the countries of the Commonwealth, declared war on Germany but provided little support to Poland other than a small French attack into the Saarland. Britain and France also began a naval blockade of Germany on 3 September which aimed to damage the country's economy and war effort. 
On 17 September, after signing a cease-fire with Japan, the Soviets also invaded Poland. Poland's territory was divided between Germany and the Soviet Union, with Lithuania and Slovakia also receiving small shares. The Poles did not surrender; they established a Polish Underground State and an underground Home Army, and continued to fight with the Allies on all fronts outside Poland. 
About 100,000 Polish military personnel were evacuated to Romania and the Baltic countries; many of these soldiers later fought against the Germans in other theatres of the war. Poland's Enigma codebreakers were also evacuated to France. During this time, Japan launched its first attack against Changsha, a strategically important Chinese city, but was repulsed by late September.
Following the invasion of Poland and a German-Soviet treaty governing Lithuania, the Soviet Union forced the Baltic countries to allow it to station Soviet troops in their countries under pacts of "mutual assistance." Finland rejected territorial demands and was invaded by the Soviet Union in November 1939. The resulting conflict ended in March 1940 with Finnish concessions. France and the United Kingdom, treating the Soviet attack on Finland as tantamount to entering the war on the side of the Germans, responded to the Soviet invasion by supporting the USSR's expulsion from the League of Nations.
In Western Europe, British troops deployed to the Continent, but in a phase nicknamed the Phoney War by the British and "Sitzkrieg" ("sitting war") by the Germans, neither side launched major operations against the other until April 1940. The Soviet Union and Germany entered a trade pact in February 1940, pursuant to which the Soviets received German military and industrial equipment in exchange for supplying raw materials to Germany to help circumvent the Allied blockade.
In April 1940, Germany invaded Denmark and Norway to secure shipments of iron ore from Sweden, which the Allies were about to disrupt. Denmark immediately capitulated, and despite Allied support, Norway was conquered within two months. In May 1940 Britain invaded Iceland to preempt a possible German invasion of the island. British discontent over the Norwegian campaign led to the replacement of Prime Minister Neville Chamberlain with Winston Churchill on 10 May 1940.
Axis advances.
Germany invaded France, Belgium, the Netherlands, and Luxembourg on 10 May 1940. The Netherlands and Belgium were overrun using blitzkrieg tactics in a few days and weeks, respectively. The French-fortified Maginot Line and the Allied forces in Belgium were circumvented by a flanking movement through the thickly wooded Ardennes region, mistakenly perceived by French planners as an impenetrable natural barrier against armoured vehicles. 
British troops were forced to evacuate the continent at Dunkirk, abandoning their heavy equipment by early June. On 10 June, Italy invaded France, declaring war on both France and the United Kingdom; twelve days later France surrendered and was soon divided into German and Italian occupation zones, and an unoccupied rump state under the Vichy Regime. On 3 July, the British attacked the French fleet in Algeria to prevent its possible seizure by Germany.
In June, during the last days of the Battle of France, the Soviet Union forcibly annexed Estonia, Latvia and Lithuania, and then annexed the disputed Romanian region of Bessarabia. Meanwhile, Nazi-Soviet political rapprochement and economic cooperation gradually stalled, and both states began preparations for war.
With France neutralized, Germany began an air superiority campaign over Britain (the Battle of Britain) to prepare for an invasion. The campaign failed, and the invasion plans were canceled by September. Using newly captured French ports, the German Navy enjoyed success against an over-extended Royal Navy, using U-boats against British shipping in the Atlantic. Italy began operations in the Mediterranean, initiating a siege of Malta in June, conquering British Somaliland in August, and making an incursion into British-held Egypt in September 1940. Japan increased its blockade of China in September by seizing several bases in the northern part of the now-isolated French Indochina.
Throughout this period, the neutral United States took measures to assist China and the Western Allies. In November 1939, the American Neutrality Act was amended to allow "cash and carry" purchases by the Allies. In 1940, following the German capture of Paris, the size of the United States Navy was significantly increased and, after the Japanese incursion into Indochina, the United States embargoed iron, steel and mechanical parts against Japan. In September, the United States further agreed to a trade of American destroyers for British bases. Still, a large majority of the American public continued to oppose any direct military intervention into the conflict well into 1941. 
At the end of September 1940, the Tripartite Pact united Japan, Italy and Germany to formalize the Axis Powers. The Tripartite Pact stipulated that any country, with the exception of the Soviet Union, not in the war which attacked any Axis Power would be forced to go to war against all three. During this time, the United States continued to support the United Kingdom and China by introducing the Lend-Lease policy authorizing the provision of materiel and other items and creating a security zone spanning roughly half of the Atlantic Ocean where the United States Navy protected British convoys. As a result, Germany and the United States found themselves engaged in sustained naval warfare in the North and Central Atlantic by October 1941, even though the United States remained officially neutral.
The Axis expanded in November 1940 when Hungary, Slovakia and Romania joined the Tripartite Pact. Romania would make the large contribution into the Axis war against the USSR, partially to recapture territory ceded to the USSR, partially to pursue its leader Ion Antonescu's desire to combat communism. In October 1940, Italy invaded Greece but within days was repulsed and pushed back into Albania, where a stalemate soon occurred. In December 1940, British Commonwealth forces began counter-offensives against Italian forces in Egypt and Italian East Africa. By early 1941, with Italian forces having been pushed back into Libya by the Commonwealth, Churchill ordered a dispatch of troops from Africa to bolster the Greeks. The Italian Navy also suffered significant defeats, with the Royal Navy putting three Italian battleships out of commission by a carrier attack at Taranto, and neutralising several more warships at the Battle of Cape Matapan.
The Germans soon intervened to assist Italy. Hitler sent German forces to Libya in February, and by the end of March they had launched an offensive against the diminished Commonwealth forces. In under a month, Commonwealth forces were pushed back into Egypt with the exception of the besieged port of Tobruk. The Commonwealth attempted to dislodge Axis forces in May and again in June, but failed on both occasions. In early April, following Bulgaria's signing of the Tripartite Pact, the Germans intervened in the Balkans by invading Greece and Yugoslavia following a coup; here too they made rapid progress, eventually forcing the Allies to evacuate after Germany conquered the Greek island of Crete by the end of May. 
The Allies did have some successes during this time. In the Middle East, Commonwealth forces first quashed a coup in Iraq which had been supported by German aircraft from bases within Vichy-controlled Syria, then, with the assistance of the Free French, invaded Syria and Lebanon to prevent further such occurrences. In the Atlantic, the British scored a much-needed public morale boost by sinking the German flagship "Bismarck". Perhaps most importantly, during the Battle of Britain the Royal Air Force had successfully resisted the Luftwaffe's assault, and the German bombing campaign largely ended in May 1941.
In Asia, despite several offensives by both sides, the war between China and Japan was stalemated by 1940. In order to increase pressure on China by blocking supply routes, and to better position Japanese forces in the event of a war with the Western powers, Japan had seized military control of southern Indochina In August of that year, Chinese communists launched an offensive in Central China; in retaliation, Japan instituted harsh measures (the Three Alls Policy) in occupied areas to reduce human and material resources for the communists. Continued antipathy between Chinese communist and nationalist forces culminated in armed clashes in January 1941, effectively ending their co-operation. 
With the situation in Europe and Asia relatively stable, Germany, Japan, and the Soviet Union made preparations. With the Soviets wary of mounting tensions with Germany and the Japanese planning to take advantage of the European War by seizing resource-rich European possessions in Southeast Asia, the two powers signed the Soviet–Japanese Neutrality Pact in April 1941. By contrast, the Germans were steadily making preparations for an attack on the Soviet Union, amassing forces on the Soviet border.
War becomes global (1941).
On 22 June 1941, Germany, along with other European Axis members and Finland, invaded the Soviet Union in Operation Barbarossa. The primary targets of this surprise offensive were the Baltic region, Moscow and Ukraine, with an ultimate goal of ending the 1941 campaign near the Arkhangelsk-Astrakhan line, connecting the Caspian and White Seas. Hitler's objectives were to eliminate the Soviet Union as a military power, exterminate Communism, generate "Lebensraum" ("living space") by dispossessing the native population and guarantee access to the strategic resources needed to defeat Germany's remaining rivals.
Although the Red Army was preparing for strategic counter-offensives before the war, "Barbarossa" forced the Soviet supreme command to adopt a strategic defence. During the summer, the Axis made significant gains into Soviet territory, inflicting immense losses in both personnel and materiel. By the middle of August, however, the German Army High Command decided to suspend the offensive of a considerably depleted Army Group Centre, and to divert the 2nd Panzer Group to reinforce troops advancing towards central Ukraine and Leningrad. The Kiev offensive was overwhelmingly successful, resulting in encirclement and elimination of four Soviet armies, and made further advance into Crimea and industrially developed Eastern Ukraine (the First Battle of Kharkov) possible.
The diversion of three quarters of the Axis troops and the majority of their air forces from France and the central Mediterranean to the Eastern Front prompted Britain to reconsider its grand strategy. In July, the UK and the Soviet Union formed a military alliance against Germany The British and Soviets invaded Iran to secure the Persian Corridor and Iran's oil fields. In August, the United Kingdom and the United States jointly issued the Atlantic Charter.
By October, when Axis operational objectives in Ukraine and the Baltic region were achieved, with only the sieges of Leningrad and Sevastopol continuing, a major offensive against Moscow had been renewed. After two months of fierce battles, the German army almost reached the outer suburbs of Moscow, where the exhausted troops were forced to suspend their offensive. Large territorial gains were made by Axis forces, but their campaign had failed to achieve its main objectives: two key cities remained in Soviet hands, the Soviet capability to resist was not broken, and the Soviet Union retained a considerable part of its military potential. The "blitzkrieg" phase of the war in Europe had ended.
By early December, freshly mobilised reserves allowed the Soviets to achieve numerical parity with Axis troops. This, as well as intelligence data that established a minimal number of Soviet troops in the East sufficient to prevent any attack by the Japanese Kwantung Army, allowed the Soviets to begin a massive counter-offensive that started on 5 December along a front and pushed German troops west.
German successes in Europe encouraged Japan to increase pressure on European governments in south-east Asia. The Dutch government agreed to provide Japan oil supplies from the Dutch East Indies, while refusing to hand over political control of the colonies. Vichy France, by contrast, agreed to a Japanese occupation of French Indochina. In July 1941, the United States, United Kingdom and other Western governments reacted to the seizure of Indochina with a freeze on Japanese assets, while the United States (which supplied 80 percent of Japan's oil) responded by placing a complete oil embargo. That meant Japan was essentially forced to choose between abandoning its ambitions in Asia and the prosecution of the war against China, or seizing the natural resources it needed by force; the Japanese military did not consider the former an option, and many officers considered the oil embargo an unspoken declaration of war.
Japan planned to rapidly seize European colonies in Asia to create a large defensive perimeter stretching into the Central Pacific; the Japanese would then be free to exploit the resources of Southeast Asia while exhausting the over-stretched Allies by fighting a defensive war. To prevent American intervention while securing the perimeter it was further planned to neutralise the United States Pacific Fleet from the outset. On 7 December (8 December in Asian time zones), 1941, Japan attacked British and American holdings with near-simultaneous offensives against Southeast Asia and the Central Pacific. These included an attack on the American fleet at Pearl Harbor, landings in Thailand and Malaya and the battle of Hong Kong.
These attacks led the U.S., Britain, Australia and other Allies to formally declare war on Japan. Germany and the other members of the Tripartite Pact responded by declaring war on the United States. In January, the United States, Britain, Soviet Union, China, and 22 smaller or exiled governments issued the Declaration by United Nations, which affirmed the Atlantic Charter. The Soviet Union did not adhere to the declaration; it maintained a neutrality agreement with Japan, and exempted itself from the principle of self-determination. From 1941, Stalin persistently asked Churchill, and then Roosevelt, to open a 'second front' in France. The Eastern front became the major theatre of war in Europe and the many millions of Soviet casualties dwarfed the few hundred thousand of the Western Allies; Churchill and Roosevelt said they needed more preparation time, leading to claims they stalled to save Western lives at the expense of Soviet lives.
Meanwhile, by the end of April 1942, Japan and its ally Thailand had almost fully conquered Burma, Malaya, the Dutch East Indies, Singapore, and Rabaul, inflicting severe losses on Allied troops and taking a large number of prisoners. Despite a stubborn resistance in Corregidor, the Philippines was eventually captured in May 1942, forcing the government of the Philippine Commonwealth into exile. Japanese forces also achieved naval victories in the South China Sea, Java Sea and Indian Ocean, and bombed the Allied naval base at Darwin, Australia. The only real Allied success against Japan was a Chinese victory at Changsha in early January 1942. These easy victories over unprepared opponents left Japan overconfident, as well as overextended.
Germany retained the initiative as well. Exploiting dubious American naval command decisions, the German navy ravaged Allied shipping off the American Atlantic coast. Despite considerable losses, European Axis members stopped a major Soviet offensive in Central and Southern Russia, keeping most territorial gains they achieved during the previous year. In North Africa, the Germans launched an offensive in January, pushing the British back to positions at the Gazala Line by early February, followed by a temporary lull in combat which Germany used to prepare for their upcoming offensives.
Axis advance stalls (1942).
In early May 1942, Japan initiated operations to capture Port Moresby by amphibious assault and thus sever communications and supply lines between the United States and Australia. The Allies, however, prevented the invasion by intercepting and defeating the Japanese naval forces in the Battle of the Coral Sea. Japan's next plan, motivated by the earlier Doolittle Raid, was to seize Midway Atoll and lure American carriers into battle to be eliminated; as a diversion, Japan would also send forces to occupy the Aleutian Islands in Alaska. In early June, Japan put its operations into action but the Americans, having broken Japanese naval codes in late May, were fully aware of the plans and force dispositions and used this knowledge to achieve a decisive victory at Midway over the Imperial Japanese Navy.
With its capacity for aggressive action greatly diminished as a result of the Midway battle, Japan chose to focus on a belated attempt to capture Port Moresby by an overland campaign in the Territory of Papua. The Americans planned a counter-attack against Japanese positions in the southern Solomon Islands, primarily Guadalcanal, as a first step towards capturing Rabaul, the main Japanese base in Southeast Asia.
Both plans started in July, but by mid-September, the Battle for Guadalcanal took priority for the Japanese, and troops in New Guinea were ordered to withdraw from the Port Moresby area to the northern part of the island, where they faced Australian and United States troops in the Battle of Buna-Gona. Guadalcanal soon became a focal point for both sides with heavy commitments of troops and ships in the battle for Guadalcanal. By the start of 1943, the Japanese were defeated on the island and withdrew their troops. In Burma, Commonwealth forces mounted two operations. The first, an offensive into the Arakan region in late 1942, went disastrously, forcing a retreat back to India by May 1943. The second was the insertion of irregular forces behind Japanese front-lines in February which, by the end of April, had achieved dubious results.
On Germany's , the Axis defeated Soviet offensives in the Kerch Peninsula and at Kharkov, and then launched their main summer offensive against southern Russia in June 1942, to seize the oil fields of the Caucasus and occupy Kuban steppe, while maintaining positions on the northern and central areas of the front. The Germans split the Army Group South into two groups: Army Group A struck lower Don River while Army Group B struck south-east to the Caucasus, towards Volga River. The Soviets decided to make their stand at Stalingrad, which was in the path of the advancing German armies.
By mid-November the Germans had nearly taken Stalingrad in bitter street fighting when the Soviets began their second winter counter-offensive, starting with an encirclement of German forces at Stalingrad and an assault on the Rzhev salient near Moscow, though the latter failed disastrously. By early February 1943, the German Army had taken tremendous losses; German troops at Stalingrad had been forced to surrender and the front-line had been pushed back beyond its position before the summer offensive. In mid-February, after the Soviet push had tapered off, the Germans launched another attack on Kharkov, creating a salient in their front line around the Russian city of Kursk.
By November 1941, Commonwealth forces had launched a counter-offensive, Operation Crusader, in North Africa, and reclaimed all the gains the Germans and Italians had made. In the West, concerns the Japanese might use bases in Vichy-held Madagascar caused the British to invade the island in early May 1942. This success was offset soon after by an Axis offensive in Libya which pushed the Allies back into Egypt until Axis forces were stopped at El Alamein. On the Continent, raids of Allied commandos on strategic targets, culminating in the disastrous Dieppe Raid, demonstrated the Western Allies' inability to launch an invasion of continental Europe without much better preparation, equipment, and operational security.
In August 1942, the Allies succeeded in repelling a second attack against El Alamein and, at a high cost, managed to deliver desperately needed supplies to the besieged Malta. A few months later, the Allies commenced an attack of their own in Egypt, dislodging the Axis forces and beginning a drive west across Libya. This attack was followed up shortly after by an Anglo-American invasion of French North Africa, which resulted in the region joining the Allies. Hitler responded to the French colony's defection by ordering the occupation of Vichy France; although Vichy forces did not resist this violation of the armistice, they managed to scuttle their fleet to prevent its capture by German forces. The now pincered Axis forces in Africa withdrew into Tunisia, which was conquered by the Allies in May 1943.
Allies gain momentum (1943).
Following the Guadalcanal Campaign, the Allies initiated several operations against Japan in the Pacific. In May 1943, Allied forces were sent to eliminate Japanese forces from the Aleutians, and soon after began major operations to isolate Rabaul by capturing surrounding islands, and to breach the Japanese Central Pacific perimeter at the Gilbert and Marshall Islands. By the end of March 1944, the Allies had completed both of these objectives, and additionally neutralised the major Japanese base at Truk in the Caroline Islands. In April, the Allies then launched an operation to retake Western New Guinea.
In the Soviet Union, both the Germans and the Soviets spent the spring and early summer of 1943 making preparations for large offensives in Central Russia. On 4 July 1943, Germany attacked Soviet forces around the Kursk Bulge. Within a week, German forces had exhausted themselves against the Soviets' deeply echeloned and well-constructed defences and, for the first time in the war, Hitler cancelled the operation before it had achieved tactical or operational success. This decision was partially affected by the Western Allies' invasion of Sicily launched on 9 July which, combined with previous Italian failures, resulted in the ousting and arrest of Mussolini later that month.
On 12 July 1943, the Soviets launched their own counter-offensives, thereby dispelling any hopes of the German Army for victory or even stalemate in the east. The Soviet victory at Kursk heralded the downfall of German superiority, giving the Soviet Union the initiative on the Eastern Front. The Germans attempted to stabilise their eastern front along the hastily fortified Panther-Wotan line, however, the Soviets broke through it at Smolensk and by the Lower Dnieper Offensives.
In early September 1943, the Western Allies invaded the Italian mainland, following an Italian armistice with the Allies. Germany responded by disarming Italian forces, seizing military control of Italian areas, and creating a series of defensive lines. German special forces then rescued Mussolini, who then soon established a new client state in German occupied Italy named the Italian Social Republic. The Western Allies fought through several lines until reaching the main German defensive line in mid-November.
German operations in the Atlantic also suffered. By May 1943, as Allied counter-measures became increasingly effective, the resulting sizable German submarine losses forced a temporary halt of the German Atlantic naval campaign. In November 1943, Franklin D. Roosevelt and Winston Churchill met with Chiang Kai-shek in Cairo and then with Joseph Stalin in Tehran. The former conference determined the post-war return of Japanese territory, while the latter included agreement that the Western Allies would invade Europe in 1944 and that the Soviet Union would declare war on Japan within three months of Germany's defeat.
From November 1943, during the seven-week Battle of Changde, the Chinese forced Japan to fight a costly war of attrition, while awaiting Allied relief. In January 1944, the Allies launched a series of attacks in Italy against the line at Monte Cassino and attempted to outflank it with landings at Anzio. By the end of January, a major Soviet offensive expelled German forces from the Leningrad region, ending the longest and most lethal siege in history. 
The following Soviet offensive was halted on the pre-war Estonian border by the German Army Group North aided by Estonians hoping to re-establish national independence. This delay slowed subsequent Soviet operations in the Baltic Sea region. By late May 1944, the Soviets had liberated Crimea, largely expelled Axis forces from Ukraine, and made incursions into Romania, which were repulsed by the Axis troops. The Allied offensives in Italy had succeeded and, at the expense of allowing several German divisions to retreat, on 4 June Rome was captured.
The Allies experienced mixed fortunes in mainland Asia. In March 1944, the Japanese launched the first of two invasions, an operation against British positions in Assam, India, and soon besieged Commonwealth positions at Imphal and Kohima. In May 1944, British forces mounted a counter-offensive that drove Japanese troops back to Burma, and Chinese forces that had invaded northern Burma in late 1943 besieged Japanese troops in Myitkyina. The second Japanese invasion attempted to destroy China's main fighting forces, secure railways between Japanese-held territory and capture Allied airfields. By June, the Japanese had conquered the province of Henan and begun a renewed attack against Changsha in the Hunan province.
Allies close in (1944).
On 6 June 1944 (known as D-Day), after three years of Soviet pressure, the Western Allies invaded northern France. After reassigning several Allied divisions from Italy, they also attacked southern France. These landings were successful, and led to the defeat of the German Army units in France. Paris was liberated by the local resistance assisted by the Free French Forces on 25 August and the Western Allies continued to push back German forces in Western Europe during the latter part of the year. An attempt to advance into northern Germany spearheaded by a major airborne operation in the Netherlands ended with a failure. After that, the Western Allies slowly pushed into Germany, unsuccessfully trying to cross the Rur river in a large offensive. In Italy the Allied advance also slowed down, when they ran into the last major German defensive line.
On 22 June, the Soviets launched a strategic offensive in Belarus (known as "Operation Bagration") that resulted in the almost complete destruction of the German Army Group Centre. Soon after that, another Soviet strategic offensive forced German troops from Western Ukraine and Eastern Poland. The successful advance of Soviet troops prompted resistance forces in Poland to initiate several uprisings, though the largest of these, in Warsaw, as well as a Slovak Uprising in the south, were not assisted by the Soviets and were put down by German forces. The Red Army's strategic offensive in eastern Romania cut off and destroyed the considerable German troops there and triggered a successful coup d'état in Romania and in Bulgaria, followed by those countries' shift to the Allied side.
In September 1944, Soviet Red Army troops advanced into Yugoslavia and forced the rapid withdrawal of the German Army Groups E and F in Greece, Albania and Yugoslavia to rescue them from being cut off. By this point, the Communist-led Partisans under Marshal Josip Broz Tito, who had led an increasingly successful guerrilla campaign against the occupation since 1941, controlled much of the territory of Yugoslavia and were engaged in delaying efforts against the German forces further south. In northern Serbia, the Red Army, with limited support from Bulgarian forces, assisted the Partisans in a joint liberation of the capital city of Belgrade on 20 October. A few days later, the Soviets launched a massive assault against German-occupied Hungary that lasted until the fall of Budapest in February 1945. In contrast with impressive Soviet victories in the Balkans, the bitter Finnish resistance to the Soviet offensive in the Karelian Isthmus denied the Soviets occupation of Finland and led to the signing of Soviet-Finnish armistice on relatively mild conditions, with a subsequent shift to the Allied side by Finland.
By the start of July, Commonwealth forces in Southeast Asia had repelled the Japanese sieges in Assam, pushing the Japanese back to the Chindwin River while the Chinese captured Myitkyina. In China, the Japanese were having greater successes, having finally captured Changsha in mid-June and the city of Hengyang by early August. Soon after, they further invaded the province of Guangxi, winning major engagements against Chinese forces at Guilin and Liuzhou by the end of November and successfully linking up their forces in China and Indochina by the middle of December.
In the Pacific, American forces continued to press back the Japanese perimeter. In mid-June 1944 they began their offensive against the Mariana and Palau islands, and decisively defeated Japanese forces in the Battle of the Philippine Sea. These defeats led to the resignation of Japanese Prime Minister Tōjō and provided the United States with air bases to launch intensive heavy bomber attacks on the Japanese home islands. In late October, American forces invaded the Filipino island of Leyte; soon after, Allied naval forces scored another large victory during the Battle of Leyte Gulf, one of the largest naval battles in history.
Axis collapse, Allied victory (1945).
On 16 December 1944, Germany attempted its last desperate measure for success on the Western Front by using most of its remaining reserves to launch a massive counter-offensive in the Ardennes to attempt to split the Western Allies, encircle large portions of Western Allied troops and capture their primary supply port at Antwerp in order to prompt a political settlement. By January, the offensive had been repulsed with no strategic objectives fulfilled. In Italy, the Western Allies remained stalemated at the German defensive line. In mid-January 1945, the Soviets attacked in Poland, pushing from the Vistula to the Oder river in Germany, and overran East Prussia. On 4 February, U.S., British, and Soviet leaders met for the Yalta Conference. They agreed on the occupation of post-war Germany, and on when the Soviet Union would join the war against Japan.
In February, the Soviets invaded Silesia and Pomerania, while Western Allies entered Western Germany and closed to the Rhine river. By March, the Western Allies crossed the Rhine north and south of the Ruhr, encircling the German Army Group B, while the Soviets advanced to Vienna. In early April, the Western Allies finally pushed forward in Italy and swept across Western Germany, while Soviet forces stormed Berlin in late April; the two forces linked up on Elbe river on 25 April. On 30 April 1945, the Reichstag was captured, signalling the military defeat of the Third Reich.
Several changes in leadership occurred during this period. On 12 April, U.S. President Roosevelt died and was succeeded by Harry Truman. Benito Mussolini was killed by Italian partisans on 28 April. Two days later, Hitler committed suicide, and was succeeded by Grand Admiral Karl Dönitz.
German forces surrendered in Italy on 29 April. The German instrument of surrender was signed on 7 May in Reims, and ratified on 8 May in Berlin. German Army Group Centre resisted in Prague until 11 May.
In the Pacific theatre, American forces accompanied by the forces of the Philippine Commonwealth advanced in the Philippines, clearing Leyte by the end of April 1945. They landed on Luzon in January 1945 and captured Manila in March following a battle which reduced the city to ruins. Fighting continued on Luzon, Mindanao and other islands of the Philippines until the end of the war.
In May 1945, Australian troops landed in Borneo, overrunning the oilfields there. British, American and Chinese forces defeated the Japanese in northern Burma in March, and the British pushed on to reach Rangoon by 3 May. Chinese forces started to counterattack in Battle of West Hunan that occurred between 6 April and 7 June 1945. American forces also moved towards Japan, taking Iwo Jima by March, and Okinawa by the end of June. American bombers destroyed Japanese cities, and American submarines cut off Japanese imports.
On 11 July, the Allied leaders met in Potsdam, Germany. They confirmed earlier agreements about Germany, and reiterated the demand for unconditional surrender of all Japanese forces by Japan, specifically stating that "the alternative for Japan is prompt and utter destruction". During this conference the United Kingdom held its general election, and Clement Attlee replaced Churchill as Prime Minister. 
As Japan continued to ignore the Potsdam terms, the United States dropped atomic bombs on the Japanese cities of Hiroshima and Nagasaki in early August. Between the two bombings, the Soviets, pursuant to the Yalta agreement, invaded Japanese-held Manchuria, and quickly defeated the Kwantung Army, which was the largest Japanese fighting force. The Red Army also captured Sakhalin Island and the Kuril Islands. On 15 August 1945 Japan surrendered, with the surrender documents finally signed aboard the deck of the American battleship USS "Missouri" on 2 September 1945, ending the war.
Aftermath.
The Allies established occupation administrations in Austria and Germany. The former became a neutral state, non-aligned with any political bloc. The latter was divided into western and eastern occupation zones controlled by the Western Allies and the USSR, accordingly. A denazification program in Germany led to the prosecution of Nazi war criminals and the removal of ex-Nazis from power, although this policy moved towards amnesty and re-integration of ex-Nazis into West German society. 
Germany lost a quarter of its pre-war (1937) territory, the eastern territories: Silesia, Neumark and most of Pomerania were taken over by Poland; East Prussia was divided between Poland and the USSR, followed by the expulsion of the 9 million Germans from these provinces, as well as of 3 million Germans from the Sudetenland in Czechoslovakia, to Germany. By the 1950s, every fifth West German was a refugee from the east. The USSR also took over the Polish provinces east of the Curzon line (from which 2 million Poles were expelled), Eastern Romania, and part of eastern Finland and three Baltic states.
In an effort to maintain peace, the Allies formed the United Nations, which officially came into existence on 24 October 1945, and adopted The Universal Declaration of Human Rights in 1948, as a common standard for all member nations. The great powers that were the victors of the war—the United States, Soviet Union, China, Britain, and France—formed the permanent members of the UN's Security Council. The five permanent members remain so to the present, although there have been two seat changes, between the Republic of China and the People's Republic of China in 1971, and between the Soviet Union and its successor state, the Russian Federation, following the dissolution of the Soviet Union. The alliance between the Western Allies and the Soviet Union had begun to deteriorate even before the war was over. 
Germany had been "de facto" divided, and two independent states, Federal Republic of Germany and German Democratic Republic were created within the borders of Allied and Soviet occupation zones, accordingly. The rest of Europe was also divided onto Western and Soviet spheres of influence. Most eastern and central European countries fell into the Soviet sphere, which led to establishment of Communist led regimes, with full or partial support of the Soviet occupation authorities. As a result, Poland, Hungary, Czechoslovakia, Romania, Albania, and East Germany became Soviet Satellite states. Communist Yugoslavia conducted a fully independent policy causing tension with the USSR.
Post-war division of the world was formalised by two international military alliances, the United States-led NATO and the Soviet-led Warsaw Pact; the long period of political tensions and military competition between them, the Cold War, would be accompanied by an unprecedented arms race and proxy wars.
In Asia, the United States led the occupation of Japan and administrated Japan's former islands in the Western Pacific, while the Soviets annexed Sakhalin and the Kuril Islands. Korea, formerly under Japanese rule, was divided and occupied by the US in the South and the Soviet Union in the North between 1945 and 1948. Separate republics emerged on both sides of the 38th parallel in 1948, each claiming to be the legitimate government for all of Korea, which led ultimately to the Korean War. 
In China, nationalist and communist forces resumed the civil war in June 1946. Communist forces were victorious and established the People's Republic of China on the mainland, while nationalist forces retreated to Taiwan in 1949. In the Middle East, the Arab rejection of the United Nations Partition Plan for Palestine and the creation of Israel marked the escalation of the Arab-Israeli conflict. While European colonial powers attempted to retain some or all of their colonial empires, their losses of prestige and resources during the war rendered this unsuccessful, leading to decolonisation.
The global economy suffered heavily from the war, although participating nations were affected differently. The US emerged much richer than any other nation; it had a baby boom and by 1950 its gross domestic product per person was much higher than that of any of the other powers and it dominated the world economy. The UK and US pursued a policy of industrial disarmament in Western Germany in the years 1945–1948. Due to international trade interdependencies this led to European economic stagnation and delayed European recovery for several years. 
Recovery began with the mid 1948 currency reform in Western Germany, and was sped up by the liberalization of European economic policy that the Marshall plan (1948–1951) both directly and indirectly caused. The post 1948 West German recovery has been called the German economic miracle. Also the Italian and French economies rebounded. By contrast, the United Kingdom was in a state of economic ruin, and continued relative economic decline for decades. 
The Soviet Union, despite enormous human and material losses, also experienced rapid increase in production in the immediate post-war era. Japan experienced incredibly rapid economic growth, becoming one of the most powerful economies in the world by the 1980s. China returned to its pre-war industrial production by 1952.
Impact.
Casualties and war crimes.
Estimates for the total casualties of the war vary, because many deaths went unrecorded. Most suggest that some 60 million people died in the war, including about 20 million soldiers and 40 million civilians.
Many civilians died because of disease, starvation, massacres, bombing and deliberate genocide. The Soviet Union lost around 27 million people during the war, including 8.7 million military and 19 million civilian deaths. The largest portion of military dead were ethnic Russians (5,756,000), followed by ethnic Ukrainians (1,377,400). One of every four Soviet citizens was killed or wounded in that war. Germany sustained 5.3 million military losses, mostly on the Eastern Front and during the final battles in Germany.
Of the total deaths in World War II approximately 85 percent—mostly Soviet and Chinese—were on the Allied side and 15 percent on the Axis side. Many of these deaths were caused by war crimes committed by German and Japanese forces in occupied territories. An estimated 11 to 17 million civilians died as a direct or indirect result of Nazi ideological policies, including the systematic genocide of around six million Jews during The Holocaust along with a further five million Roma, homosexuals as well as Slavs and other ethnic and minority groups. 
Roughly 7.5 million civilians died in China under Japanese occupation. Hundreds of thousands (varying estimates) of ethnic Serbs, along with gypsies and Jews, were murdered by the Axis-aligned Croatian Ustaše in Yugoslavia, with retribution-related killings of Croatian civilians just after the war ended.
The best-known Japanese atrocity was the Nanking Massacre, in which several hundred thousand Chinese civilians were raped and murdered. Between 3 million to more than 10 million civilians, mostly Chinese, were killed by the Japanese occupation forces. Mitsuyoshi Himeta reported 2.7 million casualties occurred during the "Sankō Sakusen". General Yasuji Okamura implemented the policy in Heipei and Shantung.
The Axis forces employed limited biological and chemical weapons. The Italians used mustard gas during their conquest of Abyssinia, while the Imperial Japanese Army used a variety of such weapons during their invasion and occupation of China ("see Unit 731") and in early conflicts against the Soviets. Both the Germans and Japanese tested such weapons against civilians and, in some cases, on prisoners of war.
While many of the Axis's acts were brought to trial in the world's first international tribunals, incidents caused by the Allies were not. Examples of such Allied actions include population transfers in the Soviet Union and Japanese American internment in the United States; the Operation Keelhaul, expulsion of Germans after World War II, rape during the occupation of Germany; the Soviet Union's Katyn massacre, for which Germans faced counter-accusations of responsibility. Large numbers of famine deaths can also be partially attributed to the war, such as the Bengal famine of 1943 and the Vietnamese famine of 1944–45.
It has been suggested by some historians, e.g. Jörg Friedrich, that the mass-bombing of civilian areas in enemy territory, including Tokyo and most notably the German cities of Dresden, Hamburg and Cologne by Western Allies, which resulted in the destruction of more than 160 cities and the deaths of more than 600,000 German civilians be considered as war crimes.
Concentration camps and slave work.
The Nazis were responsible for The Holocaust, the killing of approximately six million Jews (overwhelmingly Ashkenazim), as well as two million ethnic Poles and four million others who were deemed "unworthy of life" (including the disabled and mentally ill, Soviet prisoners of war, homosexuals, Freemasons, Jehovah's Witnesses, and Romani) as part of a programme of deliberate extermination. About 12 million, most of whom were Eastern Europeans, were employed in the German war economy as forced labourers.
In addition to Nazi concentration camps, the Soviet gulags (labour camps) led to the death of citizens of occupied countries such as Poland, Lithuania, Latvia, and Estonia, as well as German prisoners of war (POWs) and even Soviet citizens who had been or were thought to be supporters of the Nazis. Sixty percent of Soviet POWs of the Germans died during the war. Richard Overy gives the number of 5.7 million Soviet POWs. Of those, 57 percent died or were killed, a total of 3.6 million. Soviet ex-POWs and repatriated civilians were treated with great suspicion as potential Nazi collaborators, and some of them were sent to the Gulag upon being checked by the NKVD.
Japanese prisoner-of-war camps, many of which were used as labour camps, also had high death rates. The International Military Tribunal for the Far East found the death rate of Western prisoners was 27.1 percent (for American POWs, 37 percent), seven times that of POWs under the Germans and Italians. While 37,583 prisoners from the UK, 28,500 from the Netherlands, and 14,473 from United States were released after the surrender of Japan, the number for the Chinese was only 56.
According to historian Zhifen Ju, at least five million Chinese civilians from northern China and Manchukuo were enslaved between 1935 and 1941 by the East Asia Development Board, or "Kōain", for work in mines and war industries. After 1942, the number reached 10 million. The U.S. Library of Congress estimates that in Java, between 4 and 10 million "romusha" (Japanese: "manual laborers"), were forced to work by the Japanese military. About 270,000 of these Javanese laborers were sent to other Japanese-held areas in South East Asia, and only 52,000 were repatriated to Java.
On 19 February 1942, Roosevelt signed Executive Order 9066, interning thousands of Japanese, Italians, German Americans, and some emigrants from Hawaii who fled after the bombing of Pearl Harbor for the duration of the war. The U.S. and Canadian governments interned 150,000 Japanese-Americans, In addition, 14,000 German and Italian residents of the U.S. who had been assessed as being security risks were also interned.
In accordance with the Allied agreement made at the Yalta Conference millions of POWs and civilians were used as forced labor by the Soviet Union. In Hungary's case, Hungarians were forced to work for the Soviet Union until 1955.
Home fronts and production.
In Europe, before the outbreak of the war, the Allies had significant advantages in both population and economics. In 1938, the Western Allies (United Kingdom, France, Poland and British Dominions) had a 30 percent larger population and a 30 percent higher gross domestic product than the European Axis (Germany and Italy); if colonies are included, it then gives the Allies more than a 5:1 advantage in population and nearly 2:1 advantage in GDP. In Asia at the same time, China had roughly six times the population of Japan, but only an 89 percent higher GDP; this is reduced to three times the population and only a 38 percent higher GDP if Japanese colonies are included.
Though the Allies' economic and population advantages were largely mitigated during the initial rapid blitzkrieg attacks of Germany and Japan, they became the decisive factor by 1942, after the United States and Soviet Union joined the Allies, as the war largely settled into one of attrition. While the Allies' ability to out-produce the Axis is often attributed to the Allies having more access to natural resources, other factors, such as Germany and Japan's reluctance to employ women in the labour force, Allied strategic bombing, and Germany's late shift to a war economy contributed significantly. Additionally, neither Germany nor Japan planned to fight a protracted war, and were not equipped to do so. To improve their production, Germany and Japan used millions of slave labourers; Germany used about 12 million people, mostly from Eastern Europe, while Japan pressed more than 18 million people in Far East Asia.
Occupation.
In Europe, occupation came under two very different forms. In Western, Northern and Central Europe (France, Norway, Denmark, the Low Countries, and the annexed portions of Czechoslovakia) Germany established economic policies through which it collected roughly 69.5 billion reichmarks (27.8 billion US Dollars) by the end of the war; this figure does not include the sizable plunder of industrial products, military equipment, raw materials and other goods. Thus, the income from occupied nations was over 40 percent of the income Germany collected from taxation, a figure which increased to nearly 40 percent of total German income as the war went on.
In the East, the much hoped for bounties of "Lebensraum" were never attained as fluctuating front-lines and Soviet scorched earth policies denied resources to the German invaders. Unlike in the West, the Nazi racial policy encouraged excessive brutality against what it considered to be the "inferior people" of Slavic descent; most German advances were thus followed by mass executions. Although resistance groups did form in most occupied territories, they did not significantly hamper German operations in either the East or the West until late 1943.
In Asia, Japan termed nations under its occupation as being part of the Greater East Asia Co-Prosperity Sphere, essentially a Japanese hegemony which it claimed was for purposes of liberating colonised peoples. Although Japanese forces were originally welcomed as liberators from European domination in many territories, their excessive brutality turned local public opinions against them within weeks. During Japan's initial conquest it captured of oil (~5.5×105 tonnes) left behind by retreating Allied forces, and by 1943 was able to get production in the Dutch East Indies up to , 76 percent of its 1940 output rate.
Advances in technology and warfare.
Aircraft were used for reconnaissance, as fighters, bombers and ground-support, and each role was advanced considerably. Innovation included airlift (the capability to quickly move limited high-priority supplies, equipment and personnel); and of strategic bombing (the bombing of civilian areas to destroy industry and morale). Anti-aircraft weaponry also advanced, including defences such as radar and surface-to-air artillery, such as the German 88 mm gun. The use of the jet aircraft was pioneered, and though late introduction meant it had little impact, it led to jets becoming standard in worldwide air forces.
Advances were made in nearly every aspect of naval warfare, most notably with aircraft carriers and submarines. Although at the start of the war aeronautical warfare had relatively little success, actions at Taranto, Pearl Harbor, the South China Sea and the Coral Sea established the carrier as the dominant capital ship in place of the battleship. 
In the Atlantic, escort carriers proved to be a vital part of Allied convoys, increasing the effective protection radius and helping to close the Mid-Atlantic gap. Carriers were also more economical than battleships due to the relatively low cost of aircraft and their not requiring to be as heavily armoured. Submarines, which had proved to be an effective weapon during the First World War were anticipated by all sides to be important in the second. The British focused development on anti-submarine weaponry and tactics, such as sonar and convoys, while Germany focused on improving its offensive capability, with designs such as the Type VII submarine and wolfpack tactics. Gradually, improving Allied technologies such as the Leigh light, hedgehog, squid, and homing torpedoes proved victorious.
Land warfare changed from the static front lines of World War I to increased mobility and combined arms. The tank, which had been used predominantly for infantry support in the First World War, had evolved into the primary weapon. In the late 1930s, tank design was considerably more advanced than it had been during World War I, and advances continued throughout the war in increasing speed, armour and firepower.
At the start of the war, most commanders thought enemy tanks should be met by tanks with superior specifications. This idea was challenged by the poor performance of the relatively light early tank guns against armour, and German doctrine of avoiding tank-versus-tank combat. This, along with Germany's use of combined arms, were among the key elements of their highly successful blitzkrieg tactics across Poland and France. Many means of destroying tanks, including indirect artillery, anti-tank guns (both towed and self-propelled), mines, short-ranged infantry antitank weapons, and other tanks were utilised. Even with large-scale mechanisation, infantry remained the backbone of all forces, and throughout the war, most infantry were equipped similarly to World War I.
The portable machine gun spread, a notable example being the German MG42, and various submachine guns which were suited to close combat in urban and jungle settings. The assault rifle, a late war development incorporating many features of the rifle and submachine gun, became the standard postwar infantry weapon for most armed forces.
Most major belligerents attempted to solve the problems of complexity and security presented by using large codebooks for cryptography with the use of ciphering machines, the most well known being the German Enigma machine. SIGINT ("sig"nals "int"elligence) was the countering process of decryption, with the notable examples being the Allied breaking of Japanese naval codes and British Ultra, which was derived from methodology given to Britain by the Polish Cipher Bureau, which had been decoding Enigma for seven years before the war. Another aspect of military intelligence was the use of deception, which the Allies used to great effect, such as in operations Mincemeat and Bodyguard. Other technological and engineering feats achieved during, or as a result of, the war include the world's first programmable computers (Z3, Colossus, and ENIAC), guided missiles and modern rockets, the Manhattan Project's development of nuclear weapons, operations research and the development of artificial harbours and oil pipelines under the English Channel.

Middle Ages
The Middle Ages (adjectival forms: medieval, mediaeval, and mediæval) is the period of European history encompassing the 5th to the 15th centuries, normally marked from the collapse of the Western Roman Empire (the end of Classical Antiquity) until the beginning of the Renaissance and the Age of Discovery, the periods which ushered in the Modern Era. The mediaeval period thus is the mid-time of the traditional division of Western history into Classical, Medieval, and Modern periods; moreover, the Middle Ages usually is divided into the Early Middle Ages, the High Middle Ages, and the Late Middle Ages.
In the Early Middle Ages, depopulation, deurbanization, and barbarian invasions, begun in Late Antiquity, continued apace. The barbarian invaders formed new kingdoms in the remains of the Western Roman Empire. In the 7th century North Africa and the Middle East, once part of the Eastern Roman Empire, became an Islamic Empire after conquest by Muhammad's successors. Although there were substantial changes in society and political structures, the break with Antiquity was not complete. The Eastern Roman Empire – or Byzantine Empire – survived and remained a major power. Additionally, most of the new kingdoms incorporated many of the extant Roman institutions, while monasteries were founded as Christianity expanded in western Europe. In the 7th and 8th centuries, the Franks, under the Carolingian dynasty, established an empire covering much of western Europe; the Carolingian Empire endured until the 9th century, when it succumbed to the pressures of invasion — the Vikings from the north; the Magyars from the east, and the Saracens from the south.
During the High Middle Ages, which began after AD 1000, the population of Europe increased greatly as technological and agricultural innovations allowed trade to flourish and crop yields to increase. Manorialism — the organization of peasants into villages that owed rent and labor services to the nobles; and feudalism — the political structure whereby knights and lower-status nobles owed military service to their overlords, in return for the right to rent from lands and manors - were two of the ways society was organized in the High Middle Ages. Kingdoms became more centralized after the breakup of the Carolingian Empire. The Crusades, first preached in 1095, were military attempts, by western European Christians, to regain control of the Middle Eastern Holy Land from the Muslims, and succeeded long enough to establish Christian states in the Near East. Intellectual life was marked by scholasticism and the founding of universities; and the building of Gothic cathedrals, which was one of the outstanding artistic achievements of the High Middle Ages.
The Late Middle Ages were marked by difficulties and calamities, such as famine, plague, and war, which much diminished the population of western Europe; in the four years from 1347 through 1350, the Black Death killed approximately a third of the European population. Controversy, heresy, and schism within the Church paralleled the warfare between states, the civil war, and peasant revolts occurring in the kingdoms. Cultural and technological developments transformed European society, concluding the Late Middle Age and beginning the Early Modern period.
Etymology and periodization.
The Middle Ages is one of the three major periods in the most enduring scheme for analyzing European history: classical civilization, or Antiquity, the Middle Ages, and the modern period. Leonardo Bruni was the first historian to use tripartite periodization in his "History of the Florentine People" (1442). The "Middle Ages" first appears in Latin in 1469 as "media tempestas" or "middle season". In early usage, there were many variants, including "medium aevum", or "middle age", first recorded in 1604, and "media scecula", or "middle ages", first recorded in 1625. Tripartite periodization became standard after the German historian Christoph Cellarius published "Universal History Divided into an Ancient, Medieval, and New Period" in 1683. English is the only major language that retains the plural form.
The most commonly given start date for the Middle Ages is 476, first used by Bruni. For Europe as a whole, 1500 is often considered to be the end of the Middle Ages, but there is no universally agreed upon end date; depending on the context, events such as Christopher Columbus's first voyage to the Americas in 1492, conquest of Constantinople by the Turks in 1453, or the Protestant Reformation in 1517 are sometimes used. In contrast, English historians often use the Battle of Bosworth Field in 1485 to mark the end of the period. For Spain, dates commonly used are the death of King Ferdinand II in 1516, the death of Queen Isabella I of Castile in 1504, or the conquest of Granada in 1492.
Historians in the Romance languages tend to divide the Middle Ages into two parts: an earlier "High" and later "Low" period. English-speaking historians, following their German counterparts, generally subdivide the Middle Ages into three intervals: "Early", "High" and "Late". Belgian historian Henri Pirenne and Dutch historian Johan Huizinga popularized the following subdivisions in the early 20th century: the Early Middle Ages from 476 to 1000, the High Middle Ages from 1000 to 1300, and the Late Middle Ages from 1300 to 1453. In the 19th century, the entire Middle Ages were often referred to as the "Dark Ages", but with the creation of these subdivisions use of this term was restricted to the Early Middle Ages, at least among historians.
Timeline.
 The army doubled in size and various reforms in composition resulted in a new emphasis on cavalry and smaller units instead of the legion as the main tactical unit. The need for revenue led to increased taxes and a decline in numbers of the curial landowning class, and decreasing numbers of them willing to shoulder the burdens of holding office in their native towns. More bureaucrats were needed in the central administration to deal with the needs of the army, which led to complaints from civilians that there were more tax-collectors in the empire than tax-payers. 
The Emperor Diocletian (r. 284–305) split the empire into separately administered eastern and western halves in 286; however, the empire was not considered divided by its inhabitants or rulers, as legal and administrative promulgations in one division were considered valid in the other. In 330, after a period of civil war, Constantine the Great (r. 306–337) refounded the city of Byzantium as the newly renamed eastern capital, Constantinople. Diocletian's reforms created a strong governmental bureaucracy, reformed taxation, and strengthened the army, which bought the empire time but did not completely resolve the problems it was facing: excessive taxation, a declining birthrate, and pressures on its frontiers amongst others. Civil war between rival emperors became common in the middle of the 4th century, diverting men from the empire's frontier forces and allowing the barbarians to encroach. But for much of the 4th century, Roman society had reached a new, stable form that differed from the earlier classical period in a number of significant ways - a widening gulf between the rich and poor as well as a decline in the vitality of the smaller towns. Another change was the conversion of the empire to Christianity, which occurred in a gradual process that lasted from the 2nd through the 5th centuries.
In 376, the Ostrogoths, fleeing from the Huns, received permission from the Roman emperor Valens (r. 364–378) to settle in the Roman province of Thracia. The settlement did not go smoothly, and when Roman officials mishandled the situation, the Ostrogoths began to raid and plunder Thracia. Valens, attempting to put down the disorder, was killed in battle with the Ostrogoths at the Battle of Adrianople on 9 August 378. Besides the barbarian threat from the north, internal divisions within the empire, especially within the Christian Church, caused troubles. In 400, the Visigoths invaded the Western Roman Empire and, although briefly forced back from Italy, in 410 they were able to sack the city of Rome. While the Visigoths were invading, in 406 the Alans, Vandals, and Suevi crossed into Gaul; over the next three years they spread across Gaul and in 409 crossed the Pyrenees Mountains into modern-day Spain. Other groups of barbarians took part in the movements of peoples in this time period. The Franks, Alemanni, and the Burgundians eventually all ended up in northern Gaul while the Angles, Saxons, and Jutes settled in Britain. In the 430s the Huns began invading the empire; their king Attila led invasions into the Balkans in 442 and 447, into Gaul in 451, and into Italy in 452. With Attila's death in 453, the Hunnic confederation he led fell apart. All of these invasions by the varied tribes totally rearranged the political and demographic face of what had been the Western Roman Empire.
By the end of the 5th century the western section of the empire was divided into smaller political units, ruled by the tribes that had invaded in the early part of the century. The last emperor of the west, Romulus Augustulus, was deposed in 476, which has led that year to be traditionally cited as the end of the Western Roman Empire. The Eastern Roman Empire, conventionally referred to as the "Byzantine Empire" after the fall of its western counterpart, had little ability to assert control over the lost western territories. Even though Byzantine emperors maintained a claim over the territory, and no barbarian king in the west dared to elevate himself to the position of Emperor of the West, Byzantine control of most of the West could not be sustained; the reconquest of the Italian peninsula and Mediterranean periphery by Justinian was the sole, and temporary, exception.
Early Middle Ages.
New societies.
Although the political structure in western Europe had changed, the divide is not as extensive as some historians have claimed. Although usually described as "invasions", they were not always just military expeditions but were mostly caused by the movement of peoples immigrating into the Empire. Such movements were aided by the refusal of the western Roman elites to either support the army or pay the taxes that would have allowed the military to suppress the migration. The emperors of the 5th century were often controlled by military strongmen such as Stilicho (d. 408), Ricimer (d. 472), Gundobad (d. 516), or Aspar (d. 471), and when the western emperors ceased, many of the kings who replaced them were from the same background as those military strongmen. Intermarriage between the new kings and the Roman elites was common. This led to a fusion of the Roman culture with the customs of the invading tribes, including the popular assemblies which allowed free male tribal members more say in political matters. Material artifacts left by the Romans and the invaders are often similar, with tribal items often being obviously modeled on Roman objects. Similarly, much of the intellectual culture of the new kingdoms was directly based on Roman intellectual traditions. An important difference was the gradual loss of tax revenue by the new polities. Many of the new political entities no longer provided their armies with tax revenues, instead allocating land or rents. This meant there was less need for large tax revenues and so the taxation systems decayed. Warfare was common between and within the kingdoms. Slavery declined as the supply declined, and society became more rural.
Between the 5th and 8th centuries, new peoples and powerful individuals filled the political void left by Roman centralized government. The Ostrogoths settled in Italy in the late 5th century under Theodoric (d. 526) and set up a kingdom marked by its cooperation between the Italians and the Ostrogoths, at least until the last years of Theodoric's reign. The Burgundians settled in Gaul, and after an earlier kingdom was destroyed by the Huns in 436, formed a new kingdom in the 440s between today's Geneva and Lyon. This grew to be a powerful kingdom in the late 5th and early 6th centuries. In northern Gaul, the Franks and Britons set up small kingdoms. The Frankish kingdom was centered in northeastern Gaul and the first king of whom much is known is Childeric, who died in 481. Under Childeric's son Clovis (r. 509–511), the Frankish kingdom expanded and converted to Christianity. The Britons, related to the natives of Britannia, settled in what is now Brittany, which took its name from their settlement. Other kingdoms were established by the Visigoths in Spain, the Suevi in northwestern Spain, and the Vandals in North Africa. In the 6th century, the Lombards settled in northern Italy, replacing the Ostrogothic kingdom with a grouping of duchies that occasionally selected a king to rule over all of them. By the late 6th century this arrangement had been replaced by a permanent monarchy.
With the invasions came new ethnic groups into parts of Europe, but the settlement was uneven, with some regions such as Spain having a larger settlement of new peoples than other places. Gaul's settlement was uneven, with the barbarians settling much thicker in the northeast than in the southwest. Slavonic peoples settled in central and eastern Europe and into the Balkan Peninsula. The settlement of peoples was accompanied by changes in languages. The Latin of the Western Roman Empire was gradually replaced by languages based on Latin but distinct. These changes from Latin to the new languages like French or Portuguese or Romanian took many centuries, however, and went through a number of stages. Greek remained the language of the Byzantine Empire, but the migrations of the Slavs added Slavonic languages to the mix.
Byzantine survival.
As western Europe witnessed the formation of new kingdoms, the eastern section of the Roman Empire remained intact and even enjoyed an economic revival that lasted into the early 7th century. There were fewer invasions of the eastern section of the Empire, with the majority occurring in the Balkans. Peace with Persia, the traditional enemy of Rome, lasted throughout most of the 5th century. The Eastern Empire was marked by closer relations between the political state and Christian church, with doctrinal matters assuming an importance in eastern politics that they did not have in western Europe. Legal developments included the codification of Roman law known as the "Theodosian Code". Under the emperor Justinian (r. 527–565), a further compilation took place, known as the "Corpus Juris Civilis". Justinian also oversaw the construction of the Hagia Sophia in Constantinople and the reconquest of North Africa from the Vandals and Italy from the Ostrogoths. The conquest of Italy was not complete, as a deadly outbreak of plague in 542 led to the rest of Justinian's reign concentrating on defensive measures rather than further conquests. At the emperor's death, the Byzantines had control of most of Italy, North Africa, and a small foothold in southern Spain. Justinian's reconquests have often been criticized for overextending his realm and setting the stage for the Muslim conquests. Many of the difficulties faced by Justinian's successors were due not just to overtaxation for Justinian's wars, but to the essentially civilian nature of the empire which made raising troops difficult.
In the eastern empire the slow infiltration of the Balkans by the Slavs added a further complication. Although it began as a small invasion, by the late 540s Slavic tribes were in Thrace and Illyrium, and had defeated an imperial army near Adrianople in 551. In the 560s the Avars began to expand from their base on the north bank of the Danube River; by the end of the 6th century they were the dominant power in Central Europe and routinely able to force the eastern emperors to give tribute. They remained a strong power until 796. Further complications were the involvement of the emperor Maurice (r. 582–602) in Persian politics when he intervened in a succession dispute. This led to a period of peace but when Maurice was overthrown in turn, the Persians invaded and during the reign of the emperor Heraclius (r. 610–641) managed to control large chunks of the Empire, including Egypt, Syria, and Asia Minor. Heraclius was eventually able to secure a peace treaty with the Persians in 628 that restored the earlier boundaries of the Empire.
Western society.
Society in Western Europe changed with the new rulers. Some of the Roman elite families died out while others became more involved with Church than secular affairs. The older values of Latin classics scholarship and education mostly disappeared, and while literacy remained an important skill, it became a practical skill. In the 4th century, Jerome dreamed that God rebuked him for spending more time reading Cicero than the Bible. By the 6th century, Gregory of Tours had a similar dream, but instead of being chastised for reading Cicero, he was chastised for learning shorthand. By the late 6th century, the principal means of instruction in the Church ceased to be the book and was replaced with music and art. With laymen, a similar change took place, with the aristocratic culture focusing on great feasts held in halls. Clothing for the elites was richly embellished with jewels and gold. Lords and kings supported entourages of fighters who formed the backbone of the military forces of the time. Family ties between the elites were important, as were the virtues of loyalty, courage, and honour. These ties led to the prevalence of the feud in aristocratic society, examples of which included those related by Gregory of Tours that took place in Merovingian Gaul. Most feuds, however, seem to have ended quickly with the payment of some sort of compensation usually ending the feud. Women took part in aristocratic society mainly in terms of their functions as wives or mothers of men, with the role of mother of a ruler being especially prominent in Merovingian Gaul. In Anglo-Saxon society, the lack of many child rulers meant less role for women as queen mothers but this was compensated for by the increased role played by abbesses of monasteries. Only in Italy does it appear that women were considered as always under the protection and control of some male relative.
Peasant society is much less documented than the nobility. Most of the surviving information available to historians comes from archaeology; few detailed written records documenting peasant life remain from before the 9th century. Most the descriptions of the lower classes come from either law codes or writers from the upper classes. Landholding patterns in the West were not uniform, with some areas having greatly fragmented landholding patterns and other areas with a pattern of large, contiguous blocks of land being the norm. These differences allowed for a wide variety of peasant societies with some being dominated by aristocratic landholders and others having a great deal of autonomy. Land settlement also varied greatly. Some peasants lived in large settlements that numbered as many as 700 inhabitants. Others lived in small groups of a few families and still others lived on isolated farms spread over the countryside. There were also areas where the pattern was a mix of two or more of those systems. Unlike in the late Roman period, there was no sharp break between the legal status of the free peasant and the aristocrat, however, and it was possible for a free peasant's family to rise into the aristocracy over a number of generations through military service to a powerful lord.
Roman city life and culture changed greatly in the early Middle Ages. Although Italian cities remained inhabited places, they contracted greatly in size. Rome shrank from a population of hundreds of thousands to around 30,000 by the end of the end of the sixth century. Roman temples were converted into Christian churches and the city walls remained in use. In Northern Europe, cities also shrank, while the public monuments and other public buildings were raided for building materials. The establishment of new kingdoms often meant some growth for the towns chosen as capitals.
Rise of Islam.
Religious beliefs in the eastern empire and Persia were in flux during the late 6th and early 7th centuries. Judaism was an active proselytising faith, and at least one Arab political leader converted to Judaism. Christianity had active missions competing with the Persian's Zoroastrianism in seeking converts, especially amongst residents of the Arabian peninsula. All strands came together with emergence of Islam in Arabia during the lifetime of Muhammad. After Muhammad's death in 632, Islamic forces went on to conquer much of the eastern Empire as well as Persia, starting with Syria in 634–635 and later as far as Egypt in 640–641, Persia between 637 and 642, North Africa in the later 7th century and the Iberian Peninsula in 711. 
The Islamic conquests only slowed in the middle of the 8th century. The first check was the defeat of Muslim forces at the Battle of Poitiers in 732, which led to the reconquest of southern France by the Franks. But the main reason for the ebbing of Islamic conquests in Europe was the overthrow of the Umayyad dynasty and its replacement by the Abbasid dynasty. The Abbasids moved their capital to Baghdad and their interests were more concerned with the Middle East rather than Europe. The Abbasids lost control of sections of the Muslim lands - with Umayyad descendants taking over Spain along with the Aghlabids controlling North Africa and the Tulunids ruling Egypt. By the middle of the 8th century, new trading patterns were emerging in the Mediterranean, with trade between the Franks and the Arabs replacing the old Roman patterns of trade. Franks traded timber, furs, swords and slaves to the Arabs in return for silks and other fabrics, spices, and precious metals.
Trade and economy.
The barbarian invasions of the 4th and 5th centuries caused disruption in trade networks around the Mediterranean. African trade goods disappear from the archeological record slowly, first disappearing from the interior of Europe and by the 7th century they are usually only found in a few cities such as Rome or Naples. By the end of the 7th century, under the impact of the Muslim conquests, African products are no longer found in Western Europe, and have been mostly replaced by local products. The replacement of trade goods with local products was a trend throughout the old Roman lands that happened in the Early Middle Ages. This was especially marked in the lands that did not lie on the Mediterranean, such as northern Gaul or Britain. What non-local goods that appear in the archeological record are usually luxury goods. In the northern parts of Europe, not only were the trade networks local, but those goods that were produced were simple, with little use of pottery or other complex products. Around the Mediterranean Sea, however, pottery remained prevalent and appears to have been traded over medium range networks and not just produced locally.
Church and monasticism.
Christianity was a major unifying factor between Eastern and western Europe before the Arab conquests, but the conquest of North Africa sundered maritime connections between the areas. Increasingly the Byzantine Church, which became the Orthodox Church, differed in language, practices, and liturgy from the western Church, which became the Catholic Church. The eastern church used Greek instead of the western Latin. Theological and political differences emerged, and by the early and middle 8th century issues such as iconoclasm, clerical marriage, and state control of the church had widened enough that the cultural and religious differences were greater than the similarities. The formal break came in 1054, when the papacy and the patriarchy of Constantinople clashed over papal supremacy and mutually excommunicated each other, which led to the division of Christianity into two churches – the Roman Catholic Church and the Eastern Orthodox Church.
The structure of the Roman Empire survived the barbarian invasions in the west mostly intact, but the papacy was little regarded, with few of the western bishops looking to the bishop of Rome for religious or political leadership. Many of the popes prior to 750 were in any case more concerned with Byzantine affairs and eastern theological concerns. The register, or archived copies of the letters, of Pope Gregory the Great, (pope 590–604) survives, and of those more than 850 letters, the vast majority were concerned with affairs in Italy or Constantinople. The only part of western Europe where the papacy had influence was Britain, where Gregory had sent the Gregorian mission in 597 to convert the Anglo-Saxons to Christianity. Other missionary efforts were led by the Irish, who between the 5th and the 7th centuries were the most active missionaries in western Europe, with missionaries going first to England and Scotland and then later onto the continent. Irish missionaries, under such monks as Columba (d. 597) and Columbanus (d. 615), not only founded monasteries but also taught in Latin and Greek and were active authors of secular and religious works.
The Early Middle Ages witnessed the rise of monasticism in the West. The shape of European monasticism was determined by traditions and ideas that originated in the deserts of Egypt and Syria. The style of monasticism that focuses on community experience of the spiritual life, called cenobitism, was pioneered by Pachomius (d. 348) in the 4th century. Monastic ideals spread from Egypt to western Europe in the 5th and 6th centuries through hagiographical literature such as the "Life of Anthony". Benedict of Nursia (d. 547) wrote the Benedictine Rule for Western monasticism during the 6th century, detailing the administrative and spiritual responsibilities of a community of monks led by an abbot. Monks and monasteries had a deep effect on the religious and political life of the Early Middle Ages, in various cases acting as land trusts for powerful families, centres of propaganda and royal support in newly conquered regions, bases for mission, and proselytization. In addition, they were the main and sometimes only outposts of education and literacy in a region. Many of the surviving manuscripts of the Roman classics were copied in monasteries in the early Middle Ages. Monks were also the authors of new works, including history, theology, and other subjects, which were written by authors such as Bede (d. 735), a native of northern England who wrote in the late 7th and early 8th century.
Carolingian Europe.
The Frankish kingdom in northern Gaul developed into kingdoms called Austrasia, Neustria, and Burgundy during the 6th and 7th centuries, under the Merovingians who were descended from Clovis. The 7th century was a tumultuous period of civil wars between Austrasia and Neustria. Such warfare was exploited by Pippin of Landen, the Mayor of the Palace who became the power behind the throne. Later members of his family line inherited the office, acting as advisors and regents. One of his descendents, Charles Martel (d. 741), won the Battle of Poitiers in 732, halting the advance of Muslim armies across the Pyrenees. Muslim armies had earlier conquered the Visigothic kingdom of Spain, after defeating the last Visigothic king Ruderic (d. 711 or 712) at the Battle of Guadalete in 711, finishing the conquest by 719. Across the English Channel in the British Isles, the island of Britain was divided into small states dominated by the kingdoms of Northumbria, Mercia, Wessex, and East Anglia, which were descended from the Anglo-Saxon invaders. Smaller kingdoms in present-day Wales and Scotland were still under the control of the original native British and Picts. Ireland was divided into even smaller political units, usually known as tribal kingdoms, which were under the control of kings. There were perhaps as many as 150 local kings in Ireland, of varying importance.
The Carolingian dynasty, as the successors to Charles Martel are known, officially took control of the kingdoms of Austrasia and Neustria in a coup of 753 led by (r. 752–768). A contemporary chronicle claims that Pippin sought, and gained, authority for this coup from Pope (pope 752–757). Pippin's takeover was reinforced with propaganda that portrayed the Merovingians as inept or cruel rulers and exalted the accomplishments of Charles Martel and circulated stories of the family's great piety. At the time of his death in 768, Pippin left his kingdom in the hands of his two sons, Charles (r. 768–814) and Carloman (r. 768–771). When Carloman died of natural causes, Charles blocked the succession of Carloman's minor son and installed himself as the king of the united Austrasia and Neustria. Charles, known to his contemporaries as Charles the Great or Charlemagne, embarked in 774 upon a program of systematic expansion that would unify a large portion of Europe, eventually controlling modern-day France, northern Italy, and Saxony. In the wars that lasted just beyond 800, he rewarded loyal allies with war booty and command over parcels of land. In 774, Charlemagne conquered the Lombards, which freed the papacy from the fear of Lombard conquest and marked the beginnings of the Papal States.
The coronation of Charlemagne as emperor on Christmas Day 800 is regarded as a turning-point in medieval history, marking a return of the western Roman Empire, since the new emperor ruled over much of the area previously controlled by the western emperors. It also marks a change in Charlemagne's relationship with the Byzantine Empire, as the assumption of the imperial title by the Carolingians asserted their equivalency to the eastern empire. However, there were a number of differences between the newly established Carolingian Empire and both the older western Roman Empire and the concurrent Byzantine Empire. The Frankish lands were rural in character, with few cities, and what cities existed were very small. Farming techniques were not advanced, and most of the people were peasants settled on small farms. Little trade existed and much of that was with the northern realms of the British Isles and Scandinavia, in contrast to the older Roman Empire which had its trading networks centered on the Mediterranean. The administration of the empire was from an itinerant court that traveled with the emperor as well as through approximately 300 imperial officials called counts, who administered the counties which the empire had been divided into. Clergy and local bishops were used as imperial officials also, as well as the imperial officials called "missi dominici", who served as roving inspectors and troubleshooters.
Carolingian Renaissance.
Charlemagne's court in Aachen was the centre of the cultural revival sometimes referred to as the "Carolingian Renaissance". The period saw an increase in literacy, developments in the arts, architecture and jurisprudence, as well as liturgical and scriptural studies. The English monk Alcuin (d. 804) was invited to Aachen, and brought the classical Latin education available in the monasteries of Northumbria. Charlemagne's chancery made use of a new script today known as Carolingian minuscule, allowing a common writing style that advanced communication across much of Europe. Charlemagne sponsored changes in church liturgy, imposing the Roman form of church service on his domains, as well as the Gregorian chant form of liturgical music in the churches. An important activity for scholars during this period was the copying, correcting, and dissemination of basic works on religious and secular topics, with the aim of encourage learning. New works on religious topics and schoolbooks were also produced.
Breakup of the Carolingian Empire.
While Charlemagne planned to continue the Frankish tradition of dividing his kingdom between all his heirs, this ended when only one son, Louis the Pious (r. 814–840), was still alive by 813. That year, Charlemagne crowned Louis as his successor, and died in 814. Louis's long reign of 26 years was marked by numerous divisions of the empire among his sons and, after 829, numerous civil wars between various alliances of father and sons against other sons over the control of various parts of the empire. Eventually, Louis recognized his eldest son (d. 855) as emperor and gave him Italy. Louis divided the rest of the empire between Lothair and Charles the Bald (d. 877), his youngest son. Lothair took East Francia, comprising both banks of the Rhine and eastwards, leaving Charles West Francia with the empire to the west of the Rhineland and the Alps. Louis the German (d. 876), the middle child, who had been rebellious to the last, was allowed to keep Bavaria under the of his elder brother. The division was not undisputed. of Aquitaine (d. after 864), the emperor's grandson, rebelled in a contest for Aquitaine, while Louis the German tried to annex all of East Francia. Louis died in 840, with the empire still in chaos.
A three-year civil war followed his death. By the Treaty of Verdun (843), a kingdom between the Rhine and Rhone rivers was created for Lothair to go with his lands in Italy, and his imperial title was recognized. Louis the German was in control of Bavaria and the eastern lands in modern-day Germany. Charles the Bald received the western Frankish lands, comprising most of modern-day France. Charlemagne's grandsons and great-grandsons divided their kingdoms between their descendants, eventually causing all internal cohesion to be lost.
The breakup of the Carolingian Empire was accompanied by the invasions, migrations, and raids of external foes. The Atlantic and northern shores were harassed by the Vikings, who also raided the British Isles and settled in both Britain and Ireland as well as the distant island of Iceland. A further settlement of Vikings was made in France in 911 under the chieftain Rollo (d. around 931), who received permission from the Frankish king Charles the Simple (r. 898–922) to settle in what became Normandy. The eastern parts of the Frankish kingdoms, especially Germany and Italy, were under constant Magyar assault until their great defeat at the Battle of the Lechfeld in 955. The breakup of the Abbasid dynasty meant that the Islamic world fragmented into a number of smaller political states, some of which began expanding into Italy and Sicily, as well as over the Pyrenees into the southern parts of the Frankish kingdoms.
New kingdoms and a revived Byzantium.
Efforts by local kings to fight back the invaders led to the formation of new political entities. In Britain, King Alfred the Great (r. 871–899) in the late 9th century came to a settlement with the Viking invaders, with Danish settlements in Northumbria, Mercia, and parts of East Anglia. By the middle of the 10th century, Alfred's successors had conquered Northumbria, and restored English control over most of the southern part of the island of Great Britain. In northern Britain, Kenneth mac Alpin (d. "c." 860) united the Picts and the Scots into one kingdom. In the early 10th century, the Ottonian dynasty had established itself in Germany, and the Ottonians were engaged in driving back the Magyar invaders. Their efforts culminated in the coronation in 962 of (r. 936–973) as emperor. In 972, Otto secured the recognition of his title by the Byzantine Empire, and sealed the recognition with the marriage of his son Otto II to Theophanu, a daughter of the previous Byzantine Emperor Romanos II (r. 959–963). Italy was drawn into the Ottonian sphere by the late 10th century, after a period of instability. The western Frankish kingdom was more fragmented, and although a nominal king remained theoretically in charge, much of the political power had devolved to the local lords.
Missionary efforts to Scandinavia during the 9th and 10th centuries helped strengthen the growth of kingdoms there. Swedish, Danish, and Norwegian kingdoms gained power and territory in the course of the 9th and 10th centuries, and some of the kings converted to Christianity, although the process was not complete by 1000. Scandinavians also expanded and colonized throughout Europe. Besides the settlements in Ireland, England, and Normandy, further settlement took place in what became Russia as well as in Iceland. Swedish traders and raiders ranged down the rivers of the Russian steppe, and even attempted to seize Constantinople in 860 and in 907. Christian Spain, initially driven into a small section of the peninsula in the north, expanded slowly south during the 9th and 10th centuries, establishing the kingdoms of Asturias and León in the process.
In eastern Europe, Byzantium had revived its fortunes under the Emperor Basil I (r. 867–886) and his successors Leo VI (r. 886–912) and Constantine VII (r. 913–959), members of the Macedonian dynasty. Commerce revived and the emperors oversaw the extension of a uniform administration to all the provinces. The military was reorganized which allowed the emperors John I (r. 969–976) and Basil II (r. 976–1025) to expand the frontiers of the empire on all fronts. The imperial court was the centre of a revival of classical learning, a process known as the Macedonian Renaissance. Writers such as John Geometres composed new hymns, poems, and other works. Missionary efforts by both eastern and western clergy resulted in the conversion of the Moravians, Bulgars, Bohemians, Poles, Magyars, and the Slavic inhabitants of the Kievan Rus'. These conversions contributed to the founding of political states in the lands of those peoples – the states of Moravia, Bulgaria, Bohemia, Poland, Hungary, and the Kievan Rus'.
Art and architecture.
Few truly large stone buildings were attempted between the Constantinian basilicas of the 4th century and the 8th century, but many smaller stone buildings were built during the 6th and 7th centuries. By the beginning of the 8th century, the Carolingian Empire revived the basilica form of architecture. One feature of the renewed basilica was the use of a transept, or the "arms" of a cross-shaped building that are perpendicular to the long nave. Other new features of religious architecture include the crossing tower and a monumental entrance to the church, usually at the west end of the building.
Carolingian art was produced for a small group of figures around the court, and the monasteries and churches they supported. It was dominated by efforts to regain the dignity and classicism of imperial Roman and Byzantine art, but was also influenced by the Insular art of the British Isles. Insular art integrated the energy of Irish Celtic and Anglo-Saxon Germanic styles of ornament with Mediterranean forms such as the book and established many characteristics of art for the rest of the medieval period. Surviving religious works from the Early Middle Ages are mostly illuminated manuscripts and carved ivories, originally made for metalwork that has been destroyed for its materials. Objects in precious metals were the most prestigious form of art, but nearly all are lost, except for a few crosses like the Cross of Lothair, several reliquaries, and finds such as the Anglo-Saxon burial at Sutton Hoo and the hoards of Gourdon from Merovingian France, Guarrazar from Visigothic Spain and Nagyszentmiklós near Byzantine territory. There are numbers of survivals from the large brooches in fibula or penannular form that were a key piece of personal adornment for elites, including the Irish Tara Brooch. Highly decorated books were mostly Gospel books and these have survived in larger numbers, including the Insular Book of Kells and Book of Lindisfarne, and the imperial Codex Aureus of St. Emmeram, which is one of the few to retain its "treasure binding" of gold encrusted with jewels. Charlemagne's court seems to have been responsible for the crucial acceptance of figurative monumental sculpture in Christian art, and by the end of the period near life-size figures such as the Gero Cross were common in important churches.
Military and technological developments.
During the later Roman Empire, the principal military developments had to do with attempts to create an effective cavalry force as well as the continued development of highly specialized types of troops. The creation of cataphract-type soldiers was an important feature of the 5th century. The various invading tribes had differing emphasis on types of soldiers - ranging from the primarily infantry Anglo-Saxon invaders of Britain to the Vandals and Visigoths which had a high percentage of cavalry in their armies. During the early invasion period, the stirrup had not been introduced into warfare, which limited the usefulness of cavalry as shock troops, but not to the extent that has generally been proclaimed. It was still possible for cavalry to use shock tactics in battle, especially when the saddle was built up in front and back to allow greater support to the rider. The greatest changes in military affairs during the invasion was the adoption of the Hunnic composite bow in place of the earlier, and weaker, Scythian composite bow. Another development of the invasion period was the increasing use of longswords and the decrease in the use of scale armour and the increasing use of mail amour and lamellar armour.
During the early Carolingian period, a decline in the importance of infantry and light cavalry began, with a corresponding dominance of military events by the elite. The use of militia-type levies of the free population declined over the Carolingian period. Although much of the Carolingian armies were mounted, a large proportion during the early period appear to have been mounted infantry, rather than true cavalry. One exception was Anglo-Saxon England, where the armies were still composed of local levies, known as the "fyrd", which were led by the local elites. In military technology, one of the main change was the return of the crossbow, which had previously been known in Roman times, but reappeared as a military weapon during the last part of the Early Middle Ages. Another great change was the introduction of the stirrup, which allowed the more effective use of cavalry as shock troops. One final technological change that had implications beyond the military was the horseshoe, which allowed horses to be used in rocky terrain.
High Middle Ages.
Society and economic life.
The High Middle Ages saw an expansion of population. Rough estimates of the increase from the year 1000 until 1347 indicate that the population of Europe grew from 35 to 80 million. The exact cause or causes of the growth remain unclear; improved agricultural techniques, the decline of slaveholding, a more clement climate and the lack of invasion have all been put forward. As much as 90 percent of the European population remained rural peasants. Many of them, however, were no longer settled in isolated farms but had gathered into small communities, usually known as manors or villages. These peasants were often subject to noble overlords and owed them rents and other services, in a system known as manorialism. There remained, however, a few free peasants throughout this period and beyond.
Other sections of society included the nobility, clergy and townsmen. Nobles, both the titled and simple knights, were the exploiters of the manors and the peasants, although they did not own lands outright, rather they were granted rights to the income from a manor or other lands by an overlord through the customs of feudalism. During the 11th and 12th centuries, these lands, or fiefs, came to be considered hereditary and in most areas they were no longer divisible between all the heirs as had been the case in the early medieval period. Instead, most fiefs and lands went to the eldest son. The dominance of the nobility was built upon its control of the land, its military service as heavy cavalry, control of castles, and the various immunities from taxes or other impositions that the nobles enjoyed. Heavy cavalry had been introduced into Europe from the Persian cataphract of the 5th and 6th centuries, but the addition of the stirrup in the 7th allowed the full force of the horse and rider to be used in combat. Stone castles began to be constructed in the 9th and 10th centuries in response to the disorders of the time, and allowed inhabitants to take refuge from invaders. Control of castles allowed the nobles to defy kings or other overlords.
The clergy was divided into two types – the secular clergy who lived in the world, and the regular clergy, or those who lived under a religious rule and were usually monks. Most of the regular clergy were drawn from the ranks of the nobility, the same social class that served as the recruiting ground for the upper levels of the secular clergy. The local parish priests were often drawn from the peasant class. Townsmen were in a somewhat unusual position, as they did not fit into the traditional three-fold division of society into nobles, clergy, and peasants. During the 12th and 13th centuries, the ranks of the townsmen expanded greatly as existing towns grew and new population centres were founded.
In Central and Northern Italy and in Flanders, the rise of towns that were, to a degree, self-governing, stimulated economic growth and created an environment for new types of trade associations. Commercial cities on the shores of the Baltic entered into agreements known as the Hanseatic League, and Italian city-states such as Venice, Genoa, and Pisa expanded their trade throughout the Mediterranean. Besides new trading opportunities, the agricultural and technological improvements enabled the increase in crop yields, which in turn allowed the trade networks to expand. Rising trade brought new methods of dealing with money, and gold coinage was again minted in Europe, at first in Italy and later in France and other countries. New forms of commercial contracts emerged, allowing risk to be shared amongst merchants. Accounting methods improved, partly through the use of double-entry bookkeeping; letters of credit also emerged, to allow easy transmission of money through the trading networks.
Political states.
The High Middle Ages is a formative period in the history of the Western state. Kings in France, England and Spain consolidated their power, and set up lasting governing institutions. Also new kingdoms like Hungary and Poland, after their conversion to Christianity, became Central-European powers. Hungary owed its settlement to the Magyars, who settled there around 900 under King Árpád (d. around 907) after their invasions during the 9th centuries. The papacy, long attached to an ideology of independence from the secular kings, first asserted its claims to temporal authority over the entire Christian world. The Papal Monarchy reached its apogee in the early 13th century under the pontificate of (pope 1198–1216). Northern Crusades and the advance of Christian kingdoms and military orders into previously pagan regions in the Baltic and Finnic northeast brought the forced assimilation of numerous native peoples into Europe.
During the early High Middle Ages, Germany was under the rule of the Saxon dynasty, which struggled to control the powerful dukes ruling over territorial duchies tracing back to the Migration period. In 1024, the ruling dynasty changed to the Salian dynasty, who famously clashed with the papacy under Emperor (r. 1084–1105) over church appointments. His successors continued to struggle against the papacy as well as the German nobility. After the death of Emperor (r. 1111–1125) without heirs, a period of instability arose until Barbarossa (r. 1155–1190) took the imperial throne in the late 12th century. Although Barbarossa managed to rule effectively, the basic problems remained, and his successors continued to struggle with them into the 13th century. One difficulty was the invasion of the Mongols into Europe in the mid 13th century. Mongols campaigns first shattered the Kievan Rus principalities and then invaded eastern Europe in 1241, 1259, and 1287.
France under the Capetian dynasty, began to slowly expand its power over the nobility, managing to expand out of the Ile de France to exert control over more of the country as the 11th and 12th centuries. They faced a powerful rival in the Dukes of Normandy, who in 1066 under William the Conqueror (duke 1135–1187), subjugated England and created a cross-channel empire that would last, in various forms, throughout the rest of the Middle Ages. Under the Angevin dynasty of King (r. 1154–1189) and his sons, the kings of England ruled over England and large sections of France. However King John (r. 1199–1216) lost Normandy and the rest of the northern French possessions in 1204. This led to dissension amongst the English nobility, while John's financial exactions to pay for his unsuccessful attempts to regain Normandy led in 1215 to "Magna Carta", a charter that confirmed the rights and privileges of free men in England. Under (r. 1216–1272), John's son, further concessions were made to the nobility, and royal power was diminished. The French monarchy, however, continued to make gains against the nobility during the late 12th and 13th centuries, bringing more territories within the kingdom under their personal rule and centralizing the royal administration. Normans not only expanded into England, but also settled in Sicily and southern Italy, when Robert Guiscard (d. 1085) landed there in 1059 and established a duchy that later became a kingdom.
Crusades.
In the 11th century, the Seljuk Turks took over much of the Middle East, taking the ancient lands of Persia during the 1040s, Armenia in the 1060s, and capturing Jerusalem in 1070. In 1071, the Turkish army defeated the Byzantine army at the Battle of Manzikert and captured the Byzantine Emperor Romanus IV (r. 1068–1071). This allowed the Turks to invade Asia Minor, which dealt a dangerous blow to the Byzantine Empire by seizing a large part of the empire's population and its economic heartland. Although the Byzantines managed to regroup and recover somewhat, they never regained Asia Minor and were often on the defensive. The Turks also ran into difficulties, losing control of Jerusalem to the Fatimids of Egypt and suffering from a series of internal civil wars.
The Crusades intended to seize Jerusalem from Muslim control. The first Crusade was preached by Pope Urban II (pope 1088–1099) at the Council of Clermont in 1095 in response to a request from the Byzantine Emperor Alexios I Komnenos (r. 1081–1118) for aid against further Muslim advances. Urban promised indulgence to anyone who took part. Tens of thousands of people from all levels of society mobilized across Europe, and captured Jerusalem in 1099 during the First Crusade. The Crusaders consolidated their conquests in a number of Crusader states. During the 12th century and 13th century, there were a series of conflicts between them and the surrounding Islamic states. Further crusades were called to aid the Crusaders, or to try to regain Jerusalem, which was captured by Saladin in 1187. Military religious orders such as the Knights Templar and the Knights Hospitaller were formed and went on to play an integral role in the Crusader states. In 1203, the Fourth Crusade was diverted from the Holy Land to Constantinople, and captured that city in 1204, setting up a Latin Empire of Constantinople and greatly weakening the Byzantine Empire, which finally recaptured Constantinople in 1261, but the Byzantines never regained their former strength. By 1291 all the Crusader states had been either captured or forced from the mainland, with a titular Kingdom of Jerusalem surviving on the island of Cyprus for a number of years after 1291.
Popes called for crusades to take place other than in the Holy Land, with crusades being proclaimed in Spain, southern France, and along the Baltic. The Spanish crusades became fused with the Reconquista, or reconquest, of Spain from the Muslims. Although the Templars and Hospitallers took part in the Spanish crusades, Spanish military religious orders were also founded in imitation of the Templars and Hospitallers, with most of them becoming part of the two main orders of Calatrava and Santiago by the beginning of the 12th century. Northern Europe also remained outside Christian influence until the 11th century or later; these areas also became crusading venues as part of the Northern Crusades of the 12th through the 14th centuries. This too spawned a military order, the Order of the Sword Brothers. Another order, the Teutonic Knights, although originally founded in the Crusader states, focused much of its activity in the Baltic after 1225, and in 1309 moved its headquarters to Marienburg in Prussia.
Intellectual life.
During the 11th century, developments in philosophy and theology began to stimulate intellectual activity. There was debate between the realists and the nominalists over the concept of "universals". Philosophical discourse was stimulated by the rediscovery of Aristotle and his emphasis on empiricism and rationalism. Scholars such as Peter Abelard (d. 1142) and Peter Lombard (d. 1164) introduced Aristotelian logic into theology. The late 11th and early 12th century also saw the rise of cathedral schools throughout western Europe, which signaled the shift of learning from monasteries to cathedrals and towns. Cathedral schools were then in turn replaced in the late 11th century by the universities established in major European cities. Philosophy and theology fused in scholasticism, an attempt by 12th and 13th-century scholars to reconcile Christian theology with itself, which eventually resulted in a system of thought that tried to employ a systemic approach to truth and reason. This culminated in the thought of Thomas Aquinas (d. 1274), who wrote the "Summa Theologica", or "Summary of Theology".
Besides the universities, royal and noble courts saw the development of chivalry and the ethos of courtly love. This culture was expressed in the vernacular languages rather than Latin, and comprised poems, stories, legends and popular songs spread by troubadors. Often the stories were written down in the "chansons de geste", or "songs of great deeds", such as "The Song of Roland" or "The Song of Hildebrand". Besides these products of chivalry, other writers composed histories, both secular and religious. Geoffrey of Monmouth (d. around 1155) composed his "Historia Regum Britanniae", which was a collection of stories and legends about Arthur. Other works were more clearly history, such as Otto von Freising's (d. 1158) "Gesta Friderici Imperatoris" detailing the deeds of Emperor Frederick I or William of Malmesbury's (d. around 1143) "Gesta Regum" on the kings of England.
Legal studies also advanced during the 12th century. Both secular law and canon law, or ecclesiastical law, were studied in the High Middle Ages. Secular law, or Roman law, was advanced greatly by the discovery of the "corpus iuris civilis" in the 11th century, and by 1100 Roman law was being taught at Bologna. This teaching of Roman law led to the recording and standardization of legal codes throughout western Europe. Canon law was also studied, and around 1140 a monk named Gratian (flourished 12th century), a teacher at Bologna, wrote what became the standard text of canon law – the "Decretum".
Among the results of the Greek and Islamic influence on this period in European history was the replacement of Roman numerals with the decimal positional number system and the invention of algebra, which allowed more advanced mathematics. Astronomy also advanced, with the translation of Ptolomey's "Almagest" from Greek into Latin in the late 12th century. Medicine was also studied, especially in southern Italy, where Islamic medicine influenced the school at Salerno.
Technology and military.
In the 12th and 13th centuries, Europe saw a number of innovations in the management of the means of production and economic growth. Major technological advances include the invention of the windmill, the first mechanical clocks, the first investigations of optics and the creation of crude lenses, the manufacture of distilled spirits and the use of the astrolabe. Glassmaking advanced with the development of a process that allowed the creation of transparent glass in the early 13th century. Transparent glass made possible the science of optics by Roger Bacon (d. 1294), who is credited with the invention of eyeglasses.
A major agricultural innovation was the development of a 3-field rotation system for planting crops. The development of the heavy plow allowed heavier soils to be farmed more efficiently, an advance that was helped along by the spread of the horse collar, which led to the use of draught horses in place of oxen. Horses are faster than oxen and require less pasture, factors which aided the utilization of the 3-field system.
The development of cathedrals and castles advanced building technology, leading to the development of large stone buildings. Ancillary structures included new town halls, houses, bridges, and tithe barns. Shipbuilding also improved, with the use of the rib and plank method rather than the old Roman system of mortice and tenon. Other improvements to ships included the use of lateen sails and the stern-post rudder, both of which increased the speed at which ships could be sailed. 
Crossbows, which had been known in Late Antiquity, increased in use, partly because of the increase in siege warfare in the 10th and 11th centuries. Military affairs saw an increase in the use of infantry with specialized roles during this period. Besides the still dominant heavy cavalry, armies often included both mounted and infantry crossbowmen, as well as sappers and engineers. The increasing use of crossbows during the 12th and 13th centuries led to the use of closed-face helmets, heavy body armour, as well as horse armour. Gunpowder was known in Europe by the mid-13th century with a recorded use in European warfare by the English against the Scots in 1304, although it was merely used as an explosive and not as a weapon. Cannon were being used for sieges in the 1320s, and hand held guns were known and in use by the 1360s.
Architecture and art.
In the 10th century the establishment of churches and monasteries lead to the development of stone architecture that elaborated vernacular Roman forms, which led to it being later named Romanesque. Where available, Roman brick and stone buildings were recycled for their materials. From the fairly tentative beginnings known as the First Romanesque, the style flourished and spread across Europe in a remarkably homogeneous form. Right before 1000 there was a great wave of building stone churches all over Europe. Besides the architecture, "virtually all the churches in the West were decorated with wall-paintings", of which few survive. The architectural features of Romanesque are massive stone walls, openings topped by semi-circular arches, small windows, and, particularly in France, arched stone vaults. The large portal with coloured sculpture in high relief became a central feature of facades, especially in France, and the capitals of columns were often carved with narrative scenes of imaginative monsters and animals. The distinctive European form of the castle was developed, and became crucial to politics and warfare.
Romanesque art, especially metalwork, was at its most sophisticated in Mosan art, where distinct artistic personalities such as Nicholas of Verdun (d. 1205) become apparent, and an almost classical style is seen in works like a font at Liège, contrasting with the writhing animals of the exactly contemporary Gloucester Candlestick. Large illuminated bibles and psalters were the typical forms of luxury manuscripts, and wall-painting flourished in churches, often following a scheme with a "Last Judgement" on the west wall, a Christ in Majesty at the east end, and narrative biblical scenes down the nave, or in the best surviving example, at Saint-Savin-sur-Gartempe, on the barrel-vaulted roof. 
From the early 12th century, French builders developed the Gothic style, marked by the use of rib vaults, pointed arches, flying buttresses, and large stained glass windows. The Gothic style was mainly used in churches and cathedrals, and continued in use until the 16th century in much of Europe. Classic examples of Gothic architecture include Chartres Cathedral and Reims Cathedral in France as well as Salisbury Cathedral in England. Stained glass became a crucial element in the design of churches, which continued to use extensive wall-paintings, now almost all lost. 
During this period the practice of manuscript illumination gradually passed from monasteries to lay workshops, so that "by 1300 most monks bought their books in shops", and the book of hours developed as a form of devotional book for lay-people. Metalwork continued to be the most prestigious form of art, with Limoges enamel an option for reliquaries and crosses, but in Italy the innovations of Cimabue, followed by the Trecento masters Giotto (d. 1337) and Duccio (d. around 1318), greatly increased the sophistication and status of panel painting and fresco. In the 12th century secular art increased with the growing prosperity and many carved ivory objects such as gaming-pieces, combs, and small religious figures survive.
Church and society.
Monastic reform became an important issue during the 11th century, as elites began to worry that monks were not adhering to the rules binding them to a stricy religious life. Cluny Abbey, founded in the Mâcon in 909, was established as part of the Cluniac Reforms, a larger movement of monastic reform in response to this fear. The monastery quickly established a reputation for austerity and rigour. Cluny sought to maintain a high quality of spiritual life by electing its own abbot without interference from laymen, thus maintaining economic and political independence from local lords and placing itself under the protection of the papacy.
Monastic reform inspired change in the secular church. The ideals that it was based upon were brought to the papacy by Pope Leo IX (pope 1049–1054), and provided the ideology of the clerical independence that led to the Investiture Controversy in the late 11th century. This involved Pope Gregory VII (pope 1073–1085) and Emperor Henry IV, who initially clashed over episcopal appointments, disputes that turned into a battle over the ideas of investiture, clerical marriage, and simony. The emperor saw the protection of the Church as one of his responsibilities as well as wanting to preserve the right to appoint his own choices as bishops within his lands. The papacy, however, insisted on the Church's independence from secular lords These issues themselves remained unresolved after the compromise of 1122 known as the Concordat of Worms. The conflict represents a significant stage in the creation of a papal monarchy separate from and equal to lay authorities. It also had the permanent consequence of empowering German princes at the expense of the German emperors.
The High Middle Ages was a period of great religious movements. Besides the Crusaders and monastic reformers, other people sought to participate in new forms of religious life. New monastic orders were founded, including the Carthusians, the Cistercians, and the military orders such as the Knights Templar. These new orders were formed in response to the feeling of the laity that Benedictine monasticism no longer met the needs of the laymen. Laymen and those wishing to enter the religious life wanted to return to the simpler hermetical monasticism of early Christianity or to live an Apostolic life. In the 13th century, mendicant orders – the Franciscans and the Dominicans – who swore vows of poverty and earned their living by begging, were approved by the papacy. Besides the recognized orders, other religious groups such as the Waldensians and the Humiliati attempted to return to the life of early Christianity in the middle 12th and early 13th centuries, but they were condemned as heretical by the papacy. Others joined the Cathars, another heretical movement condemned by the papacy. In 1209, a crusade was preached against the Cathars, the Albigensian Crusade, which in combination with the medieval Inquisition, finally eliminated them.
Late Middle Ages.
War, famine and plague.
The first years of the 14th century were marked by a number of famines, culminating in the Great Famine of 1315–1317. The causes of the Great Famine were not just related to the ongoing climatic change that was taking place, a slow transition from the Medieval Warm Period to the Little Ice Age, but also had causes in overspecialization in single crops, which left the population vulnerable when bad weather caused crop failures. Other troubles included an economic downturn and the aforementioned climate change – which resulted in the average annual temperature for Europe declining 2 degrees Celsius during the 14th century.
These troubles were followed in 1347 by the Black Death, a disease that spread throughout Europe in the years 1348, 1349, and 1350. The death toll was probably about 35 million people in total in Europe, about one-third of the population. Towns were especially hard-hit because of the crowded conditions. Large areas of land were left sparsely inhabited, and in some places fields were left unworked. Because of the sudden decline in available labourers, the price of wages rose as landlords sought to entice workers to their fields, but the lower rents were balanced out by the lower demand for food, which cut into agricultural income. Urban workers also felt that they had a right to greater earnings, and popular uprisings broke out across Europe. Among the uprisings were the "jacquerie" in France, the Peasants' Revolt in England, and revolts in the cities of Florence in Italy and Ghent and Bruges in Flanders. The trauma of the plague led to an increased piety throughout Europe, which manifested itself in the foundation of new charities, the extreme self-mortification of the flagellants, and the scapegoating of the Jews. Conditions were further unsettled by the return of the plague throughout the rest of the 14th century. It continued to strike Europe throughout the rest of the Middle Ages.
State resurgence.
The Late Middle Ages also witnessed the rise of strong, royalty-based nation-states throughout Europe, particularly in England, France, and the Christian kingdoms of the Iberian Peninsula – Aragon, Castile, and Portugal. The long conflicts of the later Middle Ages strengthened royal control over the kingdoms, even though they were extremely hard on the peasantry. Kings profited from warfare by gaining land and extended royal legislation throughout their kingdoms. Paying for the wars required that the methods of taxation become more efficient and the rate of taxation often increased. The requirement to obtain the consent of those taxed meant that representative bodies such as the English Parliament or the French Estates General gained some power and new authority.
Throughout the 14th century, French kings sought to expand their influence throughout the kingdom at the expense of the territorial holdings of the nobility. This ran into difficulties when they attempted to confiscate the holdings of the English kings in southern France, leading to the Hundred Years' War, which lasted until 1453. The stresses of this war almost caused the disintegration of the French kingdom during the early years of the war. In the early 15th century, France once more teetered on the brink of dissolving, but in the late 1420s military successes led by Joan of Arc (d. 1431) led to the eventual victory of the French kings over the English with the capture of the last of the English possessions in southern France in 1453. The price was high, however, as the population of France at the end of the Wars was likely half what it had been prior to the start of the conflict. Conversely, the Wars had a positive effect on English national identity, doing much to fuse the various local identities into a national English ideal. The conflict with the French also helped create a national culture in England that was separate from French culture, which had been the dominant cultural influence in England prior to the outbreak of the Hundred Years' War. The early Hundred Years' War also saw the dominance of the English longbow, and the appearance of cannon on the battlefield at the Battle of Crecy in 1346.
In modern-day Germany, the Empire continued, but the elective nature of the imperial crown meant that there was no strong dynasty around which a strong state could form. Further east, the kingdoms of Poland, Hungary, and Bohemia grew into powerful kingdoms. The Iberian Peninsula kingdoms continued to gain land from the Muslim kingdoms of the peninsula, with Portugal concentrating on expanding overseas during the 15th century while the other kingdoms were riven by difficulties over the royal succession and other concerns throughout the 15th century. England, after losing the Hundred Years' War, went on to suffer a long civil war known as the Wars of the Roses, which lasted into the 1490s. Scandinavia went through a period of union under the Union of Kalmar in the late 14th and early 15th century, but dissolved once more after the death of Queen Margaret I of Denmark (r. in Denmark 1353–1412), who had united Norway, Denmark, and Sweden. The major power around the Baltic Sea was the city states of the Hanseatic League, a commercial confederation which traded from western Europe to Russia.
Collapse of Byzantium.
Although the Palaeologi emperors managed to recapture Constantinople from the western Europeans in 1261, they were never able to regain control of much of the former imperial lands. They usually controlled only a small section of the Balkan Peninsula near Constantinople, the city itself, and some coastal lands on the Black Sea and around the Aegean Sea. The former Byzantine lands in the Balkans were divided between the new kingdoms of Serbia and Bulgaria and the city-state of Venice. The power of the Byzantine emperors was threatened by a new Turkish tribe, the Ottomans, who established themselves in Anatolia in the 13th century and steadily expanded throughout the 14th century. The Ottomans expanded into Europe, reducing Bulgaria to a vassal state by 1366 and taking over Serbia after the Serbian defeat at the Battle of Kosovo in 1389. Western Europeans rallied to the plight of the Christians in the Balkans and declared a new Crusade in 1396, and a great army was sent to the Balkans which met defeat at the Battle of Nicopolis. Constantinople finally was captured by the Ottomans in 1453.
Controversy within the Church.
The troubled 14th century saw both the Avignon Papacy of 1305–1378, also called the "Babylonian Captivity of the Papacy" (a reference to the Babylonian Captivity of the Jews), and then the Great Schism that lasted from 1378 to 1418, when there were two, then later three, rival popes, each supported by a number of states. In the early years of the 15th century, after a century of turmoil, ecclesiastical officials convened in Constance in 1414, and in 1415 the council deposed one of the rival popes, leaving only two claimants. Further depositions followed, and in November 1417 the council elected Martin V (pope 1417–1431) as pope.
Besides the schism, the western church was riven by theological controversies, some of which turned into heresies. John Wyclif (d. 1384), an English theologian, was condemned as a heretic in 1415 for teaching that the laity should have access to the text of the Bible as well as holding views on the Eucharist that were contrary to church doctrine. Wyclif's teachings influenced two of the major heretical movements of the later Middle Ages – Lollardry in England and Hussitism in Bohemia. The Bohemians were also influenced by the teaching of Jan Hus, who was eventually burned at the stake in 1415 after being condemned as a heretic by the Council of Constance. The Hussite church, although subject to a crusade being called against it, survived past the end of the Middle Ages.
The papacy refined the concept of transubstantiation further in the Late Middle Ages, stating that the clergy alone was allowed to partake of the wine in the Eucharist. This further distanced the secular laity from the clergy. The laity continued the practices of pilgrimages, veneration of relics, and the belief in power of the Devil. Mystics such as Meister Eckhart (d. 1327) or Thomas à Kempis (d. 1471) wrote works that taught the laity to focus on their inner spiritual life, something that contributed to the Protestant Reformation. Besides mysticism, belief in witches and witchcraft became widespread, and by the late 15th century the Church had begun to lend credence to populist fears of witchcraft with its condemnation of witches in 1484 and the publication of the "Malleus Maleficarum", the most popular handbook for witchhunters, in 1486.
Scholars, intellectuals, and exploration.
The Later Middle Ages saw a reaction against scholasticism led by John Duns Scotus (d. 1308) and William of Ockham (d. around 1348), both of whom objected to the application of reason to faith. Their efforts, along with others, led to an undermining of the prevailing Platonic idea of "universals". Ockham's insistence that reason operates independently of faith allowed science to be separated from theology and philosophy. Legal studies were marked by the steady advance of Roman law into areas of jurisprudence previously governed by customary law. The one exception to this trend was England, where the common law remained pre-eminent. Countries also codified their laws, with legal codes being promulgated in countries as far apart as Castile, Poland, and Lithuania.
Education remained mostly focused on the training of future clergy. The basic learning of the letters and numbers remained the province of the family or a village priest, but the secondary subjects of the trivium – grammar, rhetoric, logic – were studied in either cathedral schools or in schools provided by cities. Commercial secondary schools spread also, with some towns in Italy having more than one such enterprise. Universities also spread throughout Europe in the 14th and 15th centuries. The rise of vernacular literature increased in pace, with Dante, Petrarch and Giovanni Boccaccio in 14th century Italy, Geoffrey Chaucer and William Langland in England, and François Villon and Christine de Pizan in France. Literature remained mainly religious in character, but although much of this continued to be written in Latin, a new demand developed for saints' lives and other devotional tracts in the vernacular languages. Theatre also developed in the guise of miracle plays put on by the Church. At the end of the period, the development of the printing press around 1450 led to the establishment of publishing houses throughout Europe by 1500.
Beginning in the early 15th century, the countries of the Iberian peninsula began sponsoring exploration past the boundaries of Europe. Prince Henry the Navigator of Portugal (d. 1460), sent expeditions that discovered the Canary Islands, the Azores, and Cape Verde during his lifetime. After his death, exploration continued, with Bartholomew Diaz (d. 1500) going around the Cape of Good Hope in 1486 and Vasco de Gama (d. 1524) sailing around Africa to India in 1498. The combined Spanish monarchies of Castile and Aragon sponsored Christopher Columbus' (d. 1506) voyage of exploration in 1492 that discovered the Americas. The English crown under King Henry VII (r. 1485–1509) sponsored the voyage of John Cabot (d. 1498) in 1497, which landed on Cape Breton Island.
Technological and military developments.
One of the major developments in the military sphere during the Late Middle Ages was the increasing use of infantry and light cavalry. The English also employed longbowmen, but other countries were unable to create similar forces that enjoyed the same military success. Armour continued to advance, spurred on by the increasing power of crossbows, and plate armour was developed to help protect against the threat from crossbows as well as the hand-held guns that were developed. Pole-arms reached new prominence with the development of the Flemish and Swiss infantry armed with pikes and other long spears.
Late medieval art and architecture.
The Late Middle Ages in Europe as a whole correspond to the Trecento and Early Renaissance in Italy, while Northern Europe and Spain continued to use Gothic styles, increasingly elaborate in the 15th century, until almost the end of the period. International Gothic was a courtly style that reached much of Europe in the decades around 1400, producing masterpieces such as the Très Riches Heures du Duc de Berry. All over Europe secular art continued to increase in quantity and quality, and in the 15th century the mercantile classes of Italy and Flanders became important patrons, commissioning small portraits of themselves in oils as well as a growing range of luxury items such as jewellery, ivory caskets, cassone chests and maiolica pottery. These objects also included the Hispano-Moresque ware produced by mostly Mudéjar potters in Spain. Although royalty owned huge collections of plate, little survives except for the Royal Gold Cup. Italian silk manufacture developed, so that Western churches and elites no longer needed to rely on imports from Byzantium or the Islamic world. In France and Flanders tapestry weaving of sets like "The Lady and the Unicorn" became a major luxury industry.
The large external sculptural schemes of Early Gothic churches gave way to more sculpture inside the building, as tombs became more elaborate and other features such as pulpits were sometimes lavishly carved, as in the Pulpit by Giovanni Pisano in Sant'Andrea. Painted or carved wooden relief altarpieces became common, especially as churches created many side-chapels. Early Netherlandish painting with artists such as Jan van Eyck (d. 1441) and Rogier van der Weyden (d. 1464) rivalled that of Italy, as did northern illuminated manuscripts, which in the 15th century began to be collected on a large scale by secular elites, who also commissioned secular books, especially histories. From about 1450 printed books rapidly became popular, though still expensive, and there were around 30,000 different editions of incunabula printed by 1500, and by then illuminated manuscripts were only commissioned by royalty and a few others. Very small woodcuts, nearly all religious, were affordable even by peasants in parts of Northern Europe from the middle of the 15th century, with more expensive engravings supplying a wealthier market with a variety of images.
Modern image.
The medieval period is frequently caricatured as supposedly a "time of ignorance and superstition" which placed "the word of religious authorities over personal experience and rational activity." This is a legacy from both the Renaissance and Enlightenment, when scholars contrasted their intellectual cultures with the medieval period, with a negative attitude toward the Middle Ages. Renaissance scholars saw the Classical world as a time of high culture and civilization, and saw the Middle Ages as a decline from that culture. Enlightenment scholars saw reason as superior to faith, and thus viewed the Middle Ages as a time of ignorance and superstition.
Others argue that reason was generally held in high regard during the Middle Ages. Science historian Edward Grant writes, "If revolutionary rational thoughts were expressed the 18th century, they were only made possible because of the long medieval tradition that established the use of reason as one of the most important of human activities". Also, contrary to common belief, David Lindberg writes, "the late medieval scholar rarely experienced the coercive power of the church and would have regarded himself as free (particularly in the natural sciences) to follow reason and observation wherever they led".
The caricature of the period is also reflected in a number of more specific notions. For instance, a claim that was first propagated in the 19th century and is still very common in popular culture is the supposition that all people in the Middle Ages believed that the Earth was flat. This claim is mistaken. In fact, lecturers in the medieval universities commonly advanced evidence in favor of the idea that the Earth was a sphere. Lindberg and Numbers write: "There was scarcely a Christian scholar of the Middle Ages who did not acknowledge [Earth's] sphericity and even know its approximate circumference".

Native Americans in the United States
Native Americans in the United States are the indigenous peoples in North America within the boundaries of the present-day continental United States, parts of Alaska, and the island state of Hawaii. They are composed of numerous, distinct Native American tribes and ethnic groups, many of which survive as intact political communities. The terms used to refer to Native Americans have been controversial. According to a 1995 U.S. Census Bureau set of home interviews, most of the respondents with an expressed preference refer to themselves as American Indians (or simply Indians), and this term has been adopted by major newspapers and some academic groups; however, this term does not typically include Native Hawaiians or certain Alaskan Natives, such as Aleuts, Cup'ik/Yup'ik, and Inuit peoples.
Since the end of the 15th century, the migration of Europeans to the Americas, and their importation of Africans as slaves, has led to centuries of conflict and adjustment between Old and New World societies. Europeans created most of the early written historical record about Native Americans after the colonists' immigration to the Americas. Many Native Americans lived as hunter-gatherer societies and told their histories by oral traditions. In many groups, women carried out sophisticated cultivation of numerous varieties of staple crops: maize, beans and squash. The indigenous cultures were quite different from those of the agrarian, proto-industrial, mostly Christian immigrants from western Eurasia. Many Native cultures were matrilineal; the people occupied lands for use of the entire community, for hunting or agriculture. Europeans at that time had patriarchal cultures and had developed concepts of individual property rights with respect to land that were extremely different.
The differences in cultures between the established Native Americans and immigrant Europeans, as well as shifting alliances among different nations of each culture through the centuries, caused extensive political tension, ethnic violence and social disruption. The Native Americans suffered high fatalities from the contact with infectious Eurasian diseases, to which they had no acquired immunity. Epidemics after European contact caused the greatest loss of life for indigenous populations. Estimates of the pre-Columbian population of what today constitutes the U.S. vary significantly, ranging from 1 million to 18 million.
After the colonies revolted against Great Britain and established the United States of America, President George Washington and Henry Knox conceived of the idea of "civilizing" Native Americans in preparation for assimilation as U.S. citizens. Assimilation (whether voluntary as with the Choctaw, or forced) became a consistent policy through American administrations. During the 19th century, the ideology of manifest destiny became integral to the American nationalist movement. Expansion of European-American populations to the west after the American Revolution resulted in increasing pressure on Native American lands, warfare between the groups, and rising tensions. In 1830, the U.S. Congress passed the Indian Removal Act, authorizing the government to relocate Native Americans from their homelands within established states to lands west of the Mississippi River, accommodating European-American expansion.
The first European Americans to encounter the western interior tribes were generally fur traders and trappers. There were also Jesuit missionaries active in the Northern Tier. As United States expansion reached into the American West, settler and miner migrants came into increasing conflict with the Great Basin, Great Plains, and other Western tribes. These were complex nomadic cultures based on horse culture and seasonal bison hunting. They carried out strong resistance to United States incursions in the decades after the American Civil War, in a series of Indian Wars, which were frequent up until the 1890s, but continued into the 20th century. The transcontinental railroad brought more non-Natives into tribal land in the west. Over time, the U.S. forced a series of treaties and land cessions by the tribes, and established reservations for them in many western states. U.S. agents encouraged Native Americans to adopt European-style farming and similar pursuits, but European-American agricultural technology of the time was inadequate for often dry reservation lands. In 1924, Native Americans who were not already U.S. citizens were granted citizenship by Congress.
Contemporary Native Americans have a unique relationship with the United States because they may be members of nations, tribes, or bands with sovereignty and treaty rights. Since the late 1960s, Native American activism has led to the building of cultural infrastructure and wider recognition: they have founded independent newspapers and online media; FNX, the first Native American television channel (2011), community schools, tribal colleges, and tribal museums and language programs; Native American studies programs in major universities; and national and state museums. Native American and Alaskan Native authors have been increasingly published; they work as academics, policymakers, doctors, and in a wide variety of occupations. Cultural activism has led to an expansion of efforts to teach and preserve indigenous languages for younger generations. Their societies and cultures flourish within a larger population of descendants of immigrants (both voluntary and involuntary): African, Asian, Middle Eastern, European, and other peoples.
History.
Pre-Columbian.
Other than Neolithic Revolution, "Neolithic" is used to describe advanced stone age cultures in Eurasia, Africa, and other regions and is not usually used to describe Native American cultures. The archaeological periods used are the classifications of archaeological periods and cultures established in Gordon Willey and Philip Phillips' 1958 book "Method and Theory in American Archaeology". They divided the archaeological record in the Americas into five phases., see Archaeology of the Americas. 
According to the most generally accepted theory of the settlement of the Americas, migrations of humans from Eurasia to the Americas took place via Beringia, a land bridge which connected the two continents across what is now the Bering Strait. The number and composition of the migrations is still being debated. Falling sea levels associated with an intensive period of Quaternary glaciation created the Bering land bridge that joined Siberia to Alaska about 60,000–25,000 years ago. The latest this migration could have taken place is 12,000 years ago; the earliest remains undetermined. 
Three major migrations occurred, as traced by linguistic and genetic data; the early Paleoamericans soon spread throughout the Americas, diversifying into many hundreds of culturally distinct nations and tribes. By 8000 BCE the North American climate was very similar to today's. A study published in 2012 gives genetic backing to the 1986 theory put forward by linguist Joseph Greenberg that the Americas must have been populated in three waves, based on language differences.
The Clovis culture, a megafauna hunting culture, is primarily identified by use of fluted spear points. Artifacts from this culture were first excavated in 1932 near Clovis, New Mexico. The Clovis culture ranged over much of North America and also appeared in South America. The culture is identified by the distinctive Clovis point, a flaked flint spear-point with a notched flute, by which it was inserted into a shaft. Dating of Clovis materials has been by association with animal bones and by the use of carbon dating methods. Recent reexaminations of Clovis materials using improved carbon-dating methods produced results of 11,050 and 10,800 radiocarbon years B.P. (roughly 9100 to 8850 BCE).
Numerous Paleoindian cultures occupied North America, with some arrayed around the Great Plains and Great Lakes of the modern United States of America and Canada, as well as adjacent areas to the West and Southwest. According to the oral histories of many of the indigenous peoples of the Americas, they have been living on this continent since their genesis, described by a wide range of traditional creation stories. Other tribes have stories that recount migrations across long tracts of land and a great river, believed to be the Mississippi. Genetic and linguistic data connect the indigenous people of this continent with ancient northeast Asians. Archeological and linguistic data has enabled scholars to discover some of the migrations within the Americas.
The Folsom Tradition was characterized by use of Folsom points as projectile tips, and activities known from kill sites, where slaughter and butchering of bison took place. Folsom tools were left behind between 9000 BCE and 8000 BCE.
Na-Dené-speaking peoples entered North America starting around 8000 BCE, reaching the Pacific Northwest by 5000 BCE, and from there migrating along the Pacific Coast and into the interior. Linguists, anthropologists and archeologists believe their ancestors comprised a separate migration into North America, later than the first Paleo-Indians. They migrated into Alaska and northern Canada, south along the Pacific Coast, into the interior of Canada, and south to the Great Plains and the American Southwest. They were the earliest ancestors of the Athabascan- speaking peoples, including the present-day and historical Navajo and Apache. They constructed large multi-family dwellings in their villages, which were used seasonally. People did not live there year round, but for the summer to hunt and fish, and to gather food supplies for the winter. The Oshara Tradition people lived from 5500 BCE to 600 CE. They were part of the Southwestern Archaic Tradition centered in north-central New Mexico, the San Juan Basin, the Rio Grande Valley, southern Colorado, and southeastern Utah.
Since the 1990s, archeologists have explored and dated eleven Middle Archaic sites in present-day Louisiana and Florida at which early cultures built complexes with multiple earthwork mounds; they were societies of hunter-gatherers rather than the settled agriculturalists believed necessary according to the theory of Neolithic Revolution to sustain such large villages over long periods. The prime example is Watson Brake in northern Louisiana, whose 11-mound complex is dated to 3500 BCE, making it the oldest, dated site in the Americas for such complex construction. It is nearly 2,000 years older than the Poverty Point site. Construction of the mounds went on for 500 years until was abandoned about 2800 BCE, probably due to changing environmental conditions.
Poverty Point culture is a Late Archaic archaeological culture that inhabited the area of the lower Mississippi Valley and surrounding Gulf Coast. The culture thrived from 2200 BCE to 700 BCE, during the Late Archaic period. Evidence of this culture has been found at more than 100 sites, from the major complex at Poverty Point, Louisiana across a range to the Jaketown Site near Belzoni, Mississippi. 
Poverty Point is a complex of six major earthwork concentric rings, with additional platform mounds at the site. Artifacts show the people traded with other Native Americans located from Georgia to the Great Lakes region. This is one among numerous mound sites of complex indigenous cultures throughout the Mississippi and Ohio valleys. They were one of several succeeding cultures often described as mound builders.
The Woodland period of North American pre-Columbian cultures refers to the time period from roughly 1000 BCE to 1,000 CE in the eastern part of North America. The term "Woodland" was coined in the 1930s and refers to prehistoric sites dated between the Archaic period and the Mississippian cultures. The Hopewell tradition is the term used to describe common aspects of the Native American culture that flourished along rivers in the northeastern and midwestern United States from 200 BCE to 500 CE.
The Hopewell tradition was not a single culture or society, but a widely dispersed set of related populations, who were connected by a common network of trade routes, known as the Hopewell Exchange System. At its greatest extent, the Hopewell exchange system ran from the Southeastern United States into the southeastern Canadian shores of Lake Ontario. Within this area, societies participated in a high degree of exchange; most activity was conducted along the waterways that served as their major transportation routes. The Hopewell exchange system traded materials from all over the United States.
Coles Creek culture is an archaeological culture from the Lower Mississippi valley in the southern present-day United States. The period marked a significant change in the cultural history of the area. Population increased dramatically. There is strong evidence of a growing cultural and political complexity, especially by the end of the Coles Creek sequence. Although many of the classic traits of chiefdom societies were not yet manifested, by 1000 CE the formation of simple elite polities had begun. Coles Creek sites are found in Arkansas, Louisiana, Oklahoma, Mississippi, and Texas. It is considered ancestral to the Plaquemine culture.
Hohokam is one of the four major prehistoric archaeological traditions of the present-day American Southwest. Living as simple farmers, they raised corn and beans. The early Hohokam founded a series of small villages along the middle Gila River. The communities were located near good arable land, with dry farming common in the earlier years of this period. Wells, usually less than deep, were dug for domestic water supplies by 300 CE to 500 CE. Early Hohokam homes were constructed of branches bent in a semi-circular fashion and covered with twigs and reeds. The last layer was heavily applied mud and other materials at hand.
The Mississippian culture, which extended throughout the Ohio and Mississippi valleys and built sites throughout the Southeast, created the largest earthworks in North America north of Mexico, most notably at Cahokia, on a tributary of the Mississippi River in present-day Illinois. Its ten-story Monks Mound has a larger circumference than the Pyramid of the Sun at Teotihuacan or the Great Pyramid of Egypt. The city complex was based on the culture's cosmology; it included more than 100 mounds, positioned to support their sophisticated knowledge of astronomy, and built with knowledge of varying soil types. 
It included a Woodhenge, whose sacred cedar poles were placed to mark the summer and winter solstices and fall and spring equinoxes. The society began building at this site about 950 CE, and reached its peak population in 1,250 CE of 20,000–30,000 people, which was not equalled by any city in the present-day United States until after 1800. Cahokia was a major regional chiefdom, with trade and tributary chiefdoms located in a range of areas from bordering the Great Lakes to the Gulf of Mexico. In the sixteenth century, the earliest Spanish explorers encountered Mississippian peoples in the interior of present-day North Carolina and the Southeast.
Sophisticated pre-Columbian sedentary societies evolved in North America. The Mississippian culture developed the Southeastern Ceremonial Complex, the name which archeologists have given to the regional stylistic similarity of artifacts, iconography, ceremonies and mythology. The rise of the complex culture was based on the people's adoption of maize agriculture, development of greater population densities, and chiefdom-level complex social organization from 1200 CE to 1650 CE. 
While Eastern Woodlands tribes developed their own agriculture, the introduction of maize from Mesoamerica allowed the accumulation of crop surpluses to support a higher density of population. This in turn led to the development of specialized skills among some of the peoples. The Ceremonial Complex represents a major component of the religion of the Mississippian peoples, and is one of the primary means by which their religion is understood.
The Haudenosaunee (Iroquois League of Nations or "People of the Long House"), then based in present-day upstate and western New York, had a confederacy model from the mid-15th century. Some historians have suggested that it contributed to the political thinking during the development of the later United States government. Their system of affiliation was a kind of federation, different from the strong, centralized European monarchies. 
Leadership was restricted to a group of 50 sachem chiefs, each representing one clan within a tribe; the Oneida and Mohawk people had nine seats each; the Onondagas held fourteen; the Cayuga had ten seats; and the Seneca had eight. Representation was not based on population numbers, as the Seneca tribe greatly outnumbered the others. When a sachem chief died, his successor was chosen by the senior woman of his tribe in consultation with other female members of the clan; property and hereditary leadership were passed matrilineally. Decisions were not made through voting but through consensus decision making, with each sachem chief holding theoretical veto power. The Onondaga were the "firekeepers", responsible for raising topics to be discussed. They occupied one side of a three-sided fire (the Mohawk and Seneca sat on one side of the fire, the Oneida and Cayuga sat on the third side.) 
Elizabeth Tooker, an anthropologist, has said that it was unlikely the US founding fathers were inspired by the confederacy, as it bears little resemblance to the system of governance adopted in the United States. For example, it is based on inherited rather than elected leadership, selected by female members of the tribes, consensus decision-making regardless of population size of the tribes, and a single group capable of bringing matters before the legislative body.
Long-distance trading did not prevent warfare and displacement among the indigenous peoples, and their oral histories tell of numerous migrations to the historic territories where Europeans encountered them. The Iroquois invaded and attacked tribes in the Ohio River area of present-day Kentucky and claimed the hunting grounds. Historians have placed these events as occurring as early as the 13th century, or in the 17th century Beaver Wars.
Through warfare, the Iroquois drove several tribes to migrate west to what became known as their historically traditional lands west of the Mississippi River. Tribes originating in the Ohio Valley who moved west included the Osage, Kaw, Ponca and Omaha people. By the mid-17th century, they had resettled in their historical lands in present-day Kansas, Nebraska, Arkansas and Oklahoma. The Osage warred with Caddo-speaking Native Americans, displacing them in turn by the mid-18th century and dominating their new historical territories.
European exploration and colonization.
After 1492 European exploration and colonization of the Americas revolutionized how the Old and New Worlds perceived themselves. One of the first major contacts, in what would be called the American Deep South, occurred when the conquistador Juan Ponce de León landed in La Florida in April 1513. Ponce de León was later followed by other Spanish explorers, such as Pánfilo de Narváez in 1528 and Hernando de Soto in 1539. The subsequent European colonists in North America often rationalized their expansion of empire with the assumption that they were saving a barbaric, pagan world by spreading Christian civilization.
In the Spanish colonization of the Americas, the policy of Indian Reductions resulted in the forced conversions to Catholicism of the indigenous people in northern "Nueva España." They had long-established spiritual and religious traditions and theological beliefs. What developed during the colonial years and since has been a syncretic Catholicism that absorbed and reflected indigenous beliefs; the religion changed in New Spain.
Impact on native populations.
From the 16th through the 19th centuries, the population of Indians declined in the following ways: epidemic diseases brought from Europe; genocide and warfare at the hands of European explorers and colonists, as well as between tribes; displacement from their lands; internal warfare, enslavement; and a high rate of intermarriage. Most mainstream scholars believe that, among the various contributing factors, epidemic disease was the overwhelming cause of the population decline of the American natives because of their lack of immunity to new diseases brought from Europe. With the rapid declines of some populations and continuing rivalries among their nations, Native Americans sometimes re-organized to form new cultural groups, such as the Seminoles of Florida in the eighteenth century and the Mission Indians of Alta California.
Estimating the number of Native Americans living in what is today the United States of America before the arrival of the European explorers and settlers has been the subject of much debate. While it is difficult to determine exactly how many Natives lived in North America before Columbus, estimates range from a low of 2.1 million (Ubelaker 1976) to 7 million people (Russell Thornton) to a high of 18 million (Dobyns 1983). A low estimate of around 1 million was first posited by the anthropologist James Mooney in the 1890s, by calculating population density of each culture area based on its carrying capacity.
In 1965, the American anthropologist Henry Dobyns published studies estimating the original population to have been 10 to 12 million. By 1983, he increased his estimates to 18 million. 
He took into account the mortality rates caused by infectious diseases of European explorers and settlers, against which Native Americans had no immunity. Dobyns combined the known mortality rates of these diseases among native people with reliable population records of the 19th century, to calculate the probable size of the original populations. By 1800, the Native population of the present-day United States had declined to approximately 600,000, and only 250,000 Native Americans remained in the 1890s.
Chicken pox and measles, endemic but rarely fatal among Europeans (long after being introduced from Asia), often proved deadly to Native Americans. Smallpox epidemics often immediately followed European exploration and sometimes destroyed entire village populations. While precise figures are difficult to determine, some historians estimate that at least 30% (and sometimes 50% to 70%) of some Native populations died after first contact due to Eurasian smallpox. One element of the Columbian exchange suggests explorers from the Christopher Columbus expedition contracted syphilis from indigenous peoples and carried it back to Europe, where it spread widely. Other researchers believe that the disease existed in Europe and Asia before Columbus and his men returned from exposure to indigenous peoples of the Americas, but that they brought back a more virulent form.
In 1618–1619, smallpox killed 90% of the Native Americans in the area of the Massachusetts Bay. Historians believe many Mohawk in present-day New York became infected after contact with children of Dutch traders in Albany in 1634. The disease swept through Mohawk villages, reaching the Onondaga at Lake Ontario by 1636, and the lands of the western Iroquois by 1679, as it was carried by Mohawk and other Native Americans who traveled the trading routes. The high rate of fatalities caused breakdowns in Native American societies and disrupted generational exchange of culture.
Between 1754 and 1763, many Native American tribes were involved in the French and Indian War/Seven Years War. Those involved in the fur trade in the northern areas tended to ally with French forces against British colonial militias. Native Americans fought on both sides of the conflict. The greater number of tribes fought with the French in the hopes of checking British expansion. The British had made fewer allies, but it was joined by some tribes that wanted to prove assimilation and loyalty in support of treaties to preserve their territories. They were often disappointed when such treaties were later overturned. The tribes had their own purposes, using their alliances with the European powers to battle traditional Native enemies.
After European explorers reached the West Coast in the 1770s, smallpox rapidly killed at least 30% of Northwest Coast Native Americans. For the next 80 to 100 years, smallpox and other diseases devastated native populations in the region. Puget Sound area populations, once estimated as high as 37,000 people, were reduced to only 9,000 survivors by the time settlers arrived en masse in the mid-19th century. The Spanish missions in California did not significantly affect the population of Native Americans, but the numbers of the latter decreased rapidly after California ceased to be a Spanish colony, especially during the second half of the 19th century and the beginning of the 20th (see chart on the right).
Smallpox epidemics in 1780–1782 and 1837–1838 brought devastation and drastic depopulation among the Plains Indians. By 1832, the federal government established a smallpox vaccination program for Native Americans ("The Indian Vaccination Act of 1832"). It was the first federal program created to address a health problem of Native Americans.
Animal introductions.
With the meeting of two worlds, animals, insects, and plants were carried from one to the other, both deliberately and by chance, in what is called the Columbian Exchange. Sheep, pigs, horses, and cattle were all Old World animals that were introduced to contemporary Native Americans who never knew such animals. 
In the 16th century, Spaniards and other Europeans brought horses to Mexico. Some of the horses escaped and began to breed and increase their numbers in the wild. The early American horse had been game for the earliest humans on the continent. It was hunted to extinction about 7000 BCE, just after the end of the last glacial period. Native Americans benefited by reintroduction of horses. As they adopted use of the animals, they began to change their cultures in substantial ways, especially by extending their nomadic ranges for hunting. 
The reintroduction of the horse to North America had a profound impact on Native American culture of the Great Plains. The tribes trained and used horses to ride and to carry packs or pull travois. The people fully incorporated the use of horses into their societies and expanded their territories. They used horses to carry goods for exchange with neighboring tribes, to hunt game, especially bison, and to conduct wars and horse raids.
King Philip's War.
King Philip's War, also called Metacom's War or Metacom's Rebellion, was an armed conflict between Native American inhabitants of present-day southern New England and English colonists and their Native American allies from 1675 to 1676. It continued in northern New England (primarily on the Maine frontier) even after King Philip was killed, until a treaty was signed at Casco Bay in April 1678. According to a combined estimate of loss of life in Schultz and Tougias' "King Philip's War, The History and Legacy of America's Forgotten Conflict" (based on sources from the Department of Defense, the Bureau of Census, and the work of Colonial historian Francis Jennings), 800 out of 52,000 English colonists of New England (1 out of every 65) and 3,000 out of 20,000 natives (3 out of every 20) lost their lives due to the war, which makes it proportionately one of the bloodiest and costliest in the history of America. More than half of New England's 90 towns were assaulted by Native American warriors. One in ten soldiers on both sides were wounded or killed.
The war is named after the main leader of the Native American side, Metacomet (also known as Metacom or Pometacom) who was known to the English as King Philip. He was the last Massasoit (Great Leader) of the Pokanoket Tribe/Pokanoket Federation and Wampanoag Nation. Upon their loss to the Colonists and the attempted genocide of the Pokanoket Tribe and Royal Line, many managed to flee to the North to continue their fight against the British (Massachusetts Bay Colony) by joining with the Abanaki Tribes and Wabanaki Federation.
Foundations for freedom.
Some Europeans considered Native American societies to be representative of a golden age known to them only in folk history. The political theorist Jean Jacques Rousseau wrote that the idea of freedom and democratic ideals was born in the Americas because "it was only in America" that Europeans from 1500 to 1776 knew of societies that were "truly free."
In the twentieth century, some writers have credited the Iroquois nations' political confederacy and democratic government as being influences for the development of the Articles of Confederation and the United States Constitution. In October 1988, the U.S. Congress passed Concurrent Resolution 331 to recognize the influence of the Iroquois Constitution upon the U.S. Constitution and Bill of Rights. 
But, leading historians of the period note that historic evidence is lacking to support such an interpretation. Gordon Wood wrote, "The English colonists did not need the Indians to tell them about federalism or self-government. The New England Confederation was organized as early as 1643." The historian Jack Rakove, a specialist in early American history, in 2005 noted that the voluminous documentation of the Constitutional proceedings "contain no significant reference to Iroquois." Secondly, he notes: "All the key political concepts that were the stuff of American political discourse before the Revolution and after, had obvious European antecedents and referents: bicameralism, separation of powers, confederations, and the like." 
American Revolution.
During the American Revolution, the newly proclaimed United States competed with the British for the allegiance of Native American nations east of the Mississippi River. Most Native Americans who joined the struggle sided with the British, based both on their trading relationships and hopes that colonial defeat would result in a halt to further colonial expansion onto Native American land. Many native communities were divided over which side to support in the war and others wanted to remain neutral. The first native community to sign a treaty with the new United States Government was the Lenape. For the Iroquois Confederacy, based in New York, the American Revolution resulted in civil war. The only Iroquois tribes to ally with the colonials were the Oneida and Tuscarora.
Frontier warfare during the American Revolution was particularly brutal, and numerous atrocities were committed by settlers and native tribes alike. Noncombatants suffered greatly during the war. Military expeditions on each side destroyed villages and food supplies to reduce the ability of people to fight, as in frequent raids by both sides in the Mohawk Valley and western New York. The largest of these expeditions was the Sullivan Expedition of 1779, in which American colonial troops destroyed more than 40 Iroquois villages to neutralize Iroquois raids in upstate New York. The expedition failed to have the desired effect: Native American activity became even more determined.
The British made peace with the Americans in the Treaty of Paris (1783), through which they ceded vast Native American territories to the United States without informing or consulting with the Native Americans. The Northwest Indian War was led by Native American tribes trying to repulse American settlers. The United States initially treated the Native Americans who had fought as allies with the British as a conquered people who had lost their lands. Although most members of the Iroquois tribes went to Canada with the Loyalists, others tried to stay in New York and western territories to maintain their lands. The state of New York made a separate treaty with Iroquois nations and put up for sale of land that had previously been their territories. The state established small reservations in western New York for the remnant peoples. 
18th century United States.
The United States was eager to expand, to develop farming and settlements in new areas, and to satisfy land hunger of settlers from New England and new immigrants. The national government initially sought to purchase Native American land by treaties. The states and settlers were frequently at odds with this policy.
[[File:Portrait of George Washington.jpeg|upright|thumb|George Washington advocated the advancement of Native American society and he "harbored some measure of goodwill towards the Indians."]]
European nations sent Native Americans (sometimes against their will) to the Old World as objects of curiosity. They often entertained royalty and were sometimes prey to commercial purposes. Christianization of Native Americans was a charted purpose for some European colonies.
United States policy toward Native Americans had continued to evolve after the American Revolution. George Washington and Henry Knox believed that Native Americans were equals but that their society was inferior. Washington formulated a policy to encourage the "civilizing" process. Washington had a six-point plan for civilization which included,
1. impartial justice toward Native Americans 
2. regulated buying of Native American lands 
3. promotion of commerce 
4. promotion of experiments to civilize or improve Native American society 
5. presidential authority to give presents 
6. punishing those who violated Native American rights.
Robert Remini, a historian, wrote that "once the Indians adopted the practice of private property, built homes, farmed, educated their children, and embraced Christianity, these Native Americans would win acceptance from white Americans." The United States appointed agents, like Benjamin Hawkins, to live among the Native Americans and to teach them how to live like whites.
In the late 18th century, reformers starting with Washington and Knox, supported educating native children and adults, in efforts to "civilize" or otherwise assimilate Native Americans to the larger society (as opposed to relegating them to reservations). The Civilization Fund Act of 1819 promoted this civilization policy by providing funding to societies (mostly religious) who worked on Native American improvement.
19th century.
Resistance.
As American expansion continued, Native Americans resisted settlers' encroachment in several regions of the new nation (and in unorganized territories), from the Northwest to the Southeast, and then in the West, as settlers encountered the tribes of the Great Plains. 
East of the Mississippi River, an intertribal army led by Tecumseh, a Shawnee chief, fought a number of engagements in the Northwest during the period 1811–12, known as Tecumseh's War. In the latter stages, Tecumseh's group allied with the British forces in the War of 1812 and was instrumental in the conquest of Detroit. Conflicts in the Southeast include the Creek War and Seminole Wars, both before and after the Indian Removals of most members of the Five Civilized Tribes beginning in the 1830s under President Andrew Jackson's policies.
Native American nations on the plains in the west continued armed conflicts with the United States throughout the 19th century, through what were called generally "Indian Wars." The Battle of Little Bighorn (1876) was one of the greatest Native American victories. Defeats included the Sioux Uprising of 1862, the Sand Creek Massacre (1864) and Wounded Knee in 1890. Indian Wars continued into the early 20th century.
According to the U.S. Bureau of the Census (1894), Thornton, Russell (1990). "American Indian Holocaust and Survival: A Population History since 1492". University of Oklahoma Press. p. 48. ISBN 978-0-8061-2220-5 
American expansion.
In July 1845, the New York newspaper editor John L. O’Sullivan coined the phrase, "Manifest Destiny," as the "design of Providence" supporting the territorial expansion of the United States. Manifest Destiny had serious consequences for Native Americans, since continental expansion for the United States took place at the cost of their occupied land. Manifest Destiny was a justification for expansion and westward movement, or, in some interpretations, an ideology or doctrine that helped to promote the process of civilization. Advocates of Manifest Destiny believed that expansion was not only good, but that it was obvious and certain. The term was first used primarily by Jacksonian Democrats in the 1840s to promote the annexation of much of what is now the Western United States (the Oregon Territory, the Texas Annexation, and the Mexican Cession).
The age of Manifest Destiny, which came to be associated with extinguishing American Indian territorial claims and removing them to reservations, gained ground as the United States population explored and settled west of the Mississippi River. Although Indian Removal from the Southeast had been proposed by some as a humanitarian measure to ensure their survival away from Americans, conflicts of the nineteenth century led some Americans to regard the natives as "savages".
Civil War.
Many Native Americans served in the military during the Civil War, the vast majority of whom siding with the Union. By fighting with the whites, Native Americans hoped to gain favor with the prevailing government by supporting the war effort. They also believed war service might mean an end to discrimination and relocation from ancestral lands to western territories. While the war raged and African Americans were proclaimed free, the U.S. government continued its policies of assimilation, submission, removal, or extermination of Native Americans.
General Ely S. Parker, a member of the Seneca tribe, created the articles of surrender which General Robert E. Lee signed at Appomattox Court House on April 9, 1865. Gen. Parker, who served as Gen. Ulysses S. Grant's military secretary and was a trained attorney, was once rejected for Union military service because of his race. At Appomattox, Lee is said to have remarked to Parker, "I am glad to see one real American here," to which Parker replied, "We are all Americans." General Stand Watie, a leader of the Cherokee Nation and Confederate Indian cavalry commander, was the last Confederate General to surrender his troops.
Removals and reservations.
In the 19th century, the incessant westward expansion of the United States incrementally compelled large numbers of Native Americans to resettle further west, often by force, almost always reluctantly. Native Americans believed this forced relocation illegal, given the Hopewell Treaty of 1785. Under President Andrew Jackson, United States Congress passed the Indian Removal Act of 1830, which authorized the President to conduct treaties to exchange Native American land east of the Mississippi River for lands west of the river. 
As many as 100,000 Native Americans relocated to the West as a result of this Indian Removal policy. In theory, relocation was supposed to be voluntary and many Native Americans did remain in the East. In practice, great pressure was put on Native American leaders to sign removal treaties.
The most egregious violation of the stated intention of the removal policy took place under the Treaty of New Echota, which was signed by a dissident faction of Cherokees but not the principal chief. The following year, the Cherokee conceded to removal, but Georgia included their land in a lottery for European-American settlement before that. President Jackson used the military to gather and transport the Cherokee to the west, whose timing and lack of adequate supplies led to the deaths of an estimated 4,000 Cherokees on the Trail of Tears. About 17,000 Cherokees, along with approximately 2,000 enslaved blacks held by Cherokees, were taken by force migration to Indian Territory.
Tribes were generally located to reservations where they could more easily be separated from traditional life and pushed into European-American society. Some southern states additionally enacted laws in the 19th century forbidding non-Native American settlement on Native American lands, with the intention to prevent sympathetic white missionaries from aiding the scattered Native American resistance.
Native Americans and U.S. Citizenship.
In 1817, the Cherokee became the first Native Americans recognized as U.S. citizens. Under Article 8 of the 1817 Cherokee treaty, "Upwards of 300 Cherokees (Heads of Families) in the honest simplicity of their souls, made an election to become American citizens." The next earliest recorded date of Native Americans' becoming U.S. citizens was in 1831, when some Mississippi Choctaw became citizens after the United States Congress ratified the Treaty of Dancing Rabbit Creek. 
1. Treaty provision (as with the Cherokee) 
2. Registration and land allotment under the Dawes Act of February 8, 1887
3. Issuance of Patent in Fee simple 
4. Adopting Habits of Civilized Life 
5. Minor Children 
6. Citizenship by Birth 
7. Becoming Soldiers and Sailors in the U.S. Armed Forces 
8. Marriage to a U.S. citizen 
9. Special Act of Congress. 
In 1857, Chief Justice Roger B. Taney expressed the opinion of the court that since Native Americans were "free and independent people" that they could become U.S. citizens. Taney asserted that Native Americans could be naturalized and join the "political community" of the United States.
After the American Civil War, the Civil Rights Act of 1866 states, "that all persons born in the United States, and not subject to any foreign power, excluding Indians not taxed, are hereby declared to be citizens of the United States". This was affirmed by the ratification of the Fourteenth Amendment. The concept of Native Americans as U.S. citizens fell out of favor among politicians at the time. Senator Jacob Howard of Michigan commented, “I am not yet prepared to pass a sweeping act of naturalization by which all the Indian savages, wild or tame, belonging to a tribal relation, are to become my fellow-citizens and go to the polls and vote with me". ("Congressional Globe", 1866, 2895) In a Senate floor debate regarding the Fourteenth Amendment, James Rood Doolittle of Wisconsin stated, " ... all those wild Indians to be citizens of the United States, the Great Republic of the world, whose citizenship should be a title as proud as that of king, and whose danger is that you may degrade that citizenship ("Congressional Globe", 1866, 2892)."
Indian Appropriations Act of 1871.
In 1871 Congress added a rider to the Indian Appropriations Act ending United States recognition of additional Native American tribes or independent nations, and prohibiting additional treaties.
Education and Indian boarding schools.
After the Indian wars in the late 19th century, the United States established Native American boarding schools, initially run primarily by or affiliated with Christian missionaries. At this time American society thought that Native American children needed to be acculturated to the general society. The boarding school experience often proved traumatic to Native American children, who were forbidden to speak their native languages, taught Christianity and denied the right to practice their native religions, and in numerous other ways forced to abandon their Native American identities and adopt European-American culture. Since the twentieth century, investigations documented cases of sexual, physical and mental abuse occurring at such schools. 
While problems were documented as early as the 1920s, some of the schools continued into the 1960s. Since the rise of self-determination for Native Americans, they have generally emphasized education of their children at schools near where they live. In addition, many federally recognized tribes have taken over operations of such schools and added programs of language retention and revival to strengthen their cultures. Beginning in the 1970s, tribes have also founded colleges at their reservations, controlled and operated by Native Americans, to educate their young for jobs as well as to pass on their cultures.
Twentieth century.
On August 29, 1911 Ishi, generally considered to have been the last Native American to live most of his life without contact with European-American culture, was discovered attempting to steal meat near Oroville, California after a forest fire drove him from nearby mountains. He was the last of his tribe, the rest having been massacred by a party of White "Indian fighters" in 1865 when he was a boy. He was taken in by anthropologists at the University of California who studied his language and culture, and provided him a home until his death from tuberculosis five years later.
On June 2, 1924 U.S. Republican President Calvin Coolidge signed the Indian Citizenship Act, which made citizens of the United States of all Native Americans, who were not already citizens, born in the United States and its territories. Prior to passage of the act, nearly two-thirds of Native Americans were already U.S. citizens.
American Indians today in the U.S. have all the rights guaranteed in the U.S. Constitution, can vote in elections, and run for political office. There has been controversy over how much the federal government has jurisdiction over tribal affairs, sovereignty, and cultural practices.
World War II.
Some 44,000 Native Americans served in the United States military during World War II: at the time, one-third of all able-bodied Indian men from 18 to 50 years of age. Described as the first large-scale exodus of indigenous peoples from the reservations since the removals of the 19th century, the men's service with the US military in the international conflict was a turning point in Native American history. The overwhelming majority of Native Americans welcomed the opportunity to serve; they had a voluntary enlistment rate that was 40% higher than those drafted. War Department officials said that if the entire population had enlisted in the same proportion as the Native Americans, the response would have rendered the draft unnecessary. 
Their fellow soldiers often held them in high esteem, in part since the legend of the tough Native American warrior had become a part of the fabric of American historical legend. White servicemen sometimes showed a lighthearted respect toward Native American comrades by calling them "chief". The resulting increase in contact with the world outside of the reservation system brought profound changes to Native American culture. "The war", said the U.S. Indian Commissioner in 1945, "caused the greatest disruption of Native life since the beginning of the reservation era", affecting the habits, views, and economic well-being of tribal members. The most significant of these changes was the opportunity—as a result of wartime labor shortages—to find well-paying work in cities, and many people relocated to urban areas, particularly on the West Coast with the buildup of the defense industry.
There were also losses as a result of the war. For instance, a total of 1,200 Pueblo men served in World War II; only about half came home alive. In addition many more Navajo served as Code talkers for the military in the Pacific. The code they made, although cryptologically very simple, was never cracked by the Japanese.
Self-determination.
Military service and urban residency contributed to the rise of American Indian activism, particularly after the 1960s and the occupation of Alcatraz Island (1969–1971) by a student Indian group from San Francisco. In the same period, the American Indian Movement (AIM) was founded in Minneapolis, and chapters were established throughout the country, where American Indians combined spiritual and political activism. Political protests gained national media attention and the sympathy of the American public.
Through the mid-1970s, conflicts between governments and Native Americans occasionally erupted into violence. A notable late 20th-century event was the Wounded Knee incident on the Pine Ridge Indian Reservation. Upset with tribal government and the failures of the federal government to enforce treaty rights, about 300 Oglala Lakota and American Indian Movement (AIM) activists took control of Wounded Knee on February 27, 1973. 
Indian activists from around the country joined them at Pine Ridge, and the occupation became a symbol of rising American Indian identity and power. Federal law enforcement officials and the national guard cordoned off the town, and the two sides had a standoff for 71 days. During much gunfire, one United States Marshal was wounded and paralyzed. In late April a Cherokee and local Lakota man were killed by gunfire; the Lakota elders ended the occupation to ensure no more lives were lost. 
In June 1975, two FBI agents seeking to make an armed robbery arrest at Pine Ridge Reservation were wounded in a firefight, and killed at close range. The AIM activist Leonard Peltier was sentenced in 1976 to two consecutive terms of life in prison in the FBI deaths.
In 1968 the government enacted the Indian Civil Rights Act. This gave tribal members most of the protections against abuses by tribal governments that the Bill of Rights accords to all U.S. citizens with respect to the federal government. In 1975 the U.S. government passed the Indian Self-Determination and Education Assistance Act, marking the culmination of 15 years of policy changes. It resulted from American Indian activism, the Civil Rights Movement, and community development aspects of President Lyndon Johnson's social programs of the 1960s. The Act recognized the right and need of Native Americans for self-determination. It marked the U.S. government's turn away from the 1950s policy of termination of the relationship between tribes and the government. The U.S. government encouraged Native Americans' efforts at self-government and determining their futures. Tribes have developed organizations to administer their own social, welfare and housing programs, for instance. Tribal self-determination has created tension with respect to the federal government's historic trust obligation to care for Indians, however, the Bureau of Indian Affairs has never lived up to that responsibility.
By this time, tribes had already started to establish community schools to replace the BIA boarding schools. Led by the Navajo Nation in 1968, tribes started tribal colleges and universities, to build their own models of education on reservations, preserve and revive their cultures, and develop educated workforces. In 1994 the U.S. Congress passed legislation recognizing the tribal colleges as land-grant colleges, which provided opportunities for funding. Thirty-two tribal colleges in the United States belong to the American Indian Higher Education Consortium. By the early 21st century, tribal nations had also established numerous language revival programs in their schools.
In addition, Native American activism has led major universities across the country to establish Native American studies programs and departments, increasing awareness of the strengths of Indian cultures, providing opportunities for academics, and deepening research on history and cultures in the United States. Native Americans have entered academia; journalism and media; politics at local, state and federal levels; and public service, for instance, influencing medical research and policy to identify issues related to American Indians. 
In 1981, Tim Giago founded the "Lakota Times", an independent Native American newspaper, located at the Pine Ridge Reservation but not controlled by tribal government. He later founded the Native American Journalists Association. Other independent newspapers and media corporations have been developed, so that Native American journalists are contributing perspective on their own affairs and other policies and events.
In 2004 Senator Sam Brownback (Republican of Kansas) introduced a joint resolution (Senate Joint Resolution 37) to "offer an apology to all Native Peoples on behalf of the United States" for past "ill-conceived policies" by the U.S. government regarding Indian Tribes. President Barack Obama signed the historic apology into law in 2009, as section Section 8113 of the 2010 defense appropriations bill.
After years of investigation and independent work by Native American journalists, in 2003 the U.S. government indicted suspects in the December 1975 murder of Anna Mae Aquash at the Pine Ridge Indian Reservation. A "Mi'kmaq," Aquash was the highest-ranking woman activist in the American Indian Movement (AIM) at the time. She was killed several months after two FBI agents had been killed at the reservation. Many Lakota believe that she was killed by AIM on suspicion of having been an FBI informant, but she never worked for the FBI. Arlo Looking Cloud was convicted in federal court in 2004. In 2007 the United States extradited AIM activist John Graham from Canada to stand trial for her murder. He was also convicted and sentenced to life.
Demographics.
Population and distribution.
The 2010 census permitted respondents to self-identify as being of one or more races. Self-identification dates from the census of 1960; prior to that the race of the respondent was determined by opinion of the census taker. The option to select more than one race was introduced in 2000. If American Indian or Alaska Native was selected, the form requested the individual provide the name of the "enrolled or principal tribe". The 2010 Census showed that the U.S. population on April 1, 2010, was 308.7 million.
Out of the total U.S. population, 2.9 million people, or 0.9 percent, reported American Indian and Alaska Native alone. In addition, 2.3 million people, or another 0.7 percent, reported American Indian and Alaska Native in combination with one or more other races. Together, these two groups totaled 5.2 million people. Thus, 1.7 percent of all people in the United States identified as American Indian and Alaska Native, either alone or in combination with one or more other races.
The definition of American Indian or Alaska Native used in the 2010 census:
78% of Native Americans live outside a reservation. Full-blood individuals are more likely to live on a reservation than mixed-blood individuals. The Navajo, with 286,000 full-blood individuals, is the largest tribe if only full-blood individuals are counted; the Navajo are the tribe with the highest proportion of full-blood individuals, 86.3%. The Cherokee have a different history; it is the largest tribe with 819,000 individuals, and it has 284,000 full-blood individuals.
Population by tribal grouping.
Below are numbers for US citizens self-identifying to selected tribal grouping, according to the 2000 US census.
Current legal status.
There are 562 federally recognized tribal governments in the United States. These tribes possess the right to form their own governments, to enforce laws (both civil and criminal) within their lands, to tax, to establish requirements for membership, to license and regulate activities, to zone and to exclude persons from tribal territories. Limitations on tribal powers of self-government include the same limitations applicable to states; for example, neither tribes nor states have the power to make war, engage in foreign relations, or coin money (this includes paper currency).
Many Native Americans and advocates of Native American rights point out that the U.S. federal government's claim to recognize the "sovereignty" of Native American peoples falls short, given that the United States wishes to govern Native American peoples and treat them as subject to U.S. law. Such advocates contend that full respect for Native American sovereignty would require the U.S. government to deal with Native American peoples in the same manner as any other sovereign nation, handling matters related to relations with Native Americans through the Secretary of State, rather than the Bureau of Indian Affairs. The Bureau of Indian Affairs reports on its website that its "responsibility is the administration and management of of land held in trust by the United States for American Indians, Indian tribes, and Alaska Natives". Many Native Americans and advocates of Native American rights believe that it is condescending for such lands to be considered "held in trust" and regulated in any fashion by other than their own tribes, whether the U.S. or Canadian governments, or any other non-Native American authority.
As of year 2000, the largest tribes in the United States by population were Navajo, Cherokee, Choctaw, Sioux, Chippewa, Apache, Blackfeet, Iroquois, and Pueblo. In 2000, eight of ten Americans with Native American ancestry were of mixed ancestry. It is estimated that by 2100 that figure will rise to nine out of ten.
In addition, there are a number of tribes that are recognized by individual states, but not by the federal government. The rights and benefits associated with state recognition vary from state to state.
Some tribal nations have been unable to document the cultural continuity required for federal recognition. The Muwekma Ohlone of the San Francisco bay area are pursuing litigation in the federal court system to establish recognition. Many of the smaller eastern tribes, long considered remnants of extinct peoples, have been trying to gain official recognition of their tribal status. Several in Virginia and North Carolina have gained state recognition. Federal recognition confers some benefits, including the right to label arts and crafts as Native American and permission to apply for grants that are specifically reserved for Native Americans. But gaining federal recognition as a tribe is extremely difficult; to be established as a tribal group, members have to submit extensive genealogical proof of tribal descent and continuity of the tribe as a culture.
In July 2000 the Washington Republican Party adopted a resolution recommending that the federal and legislative branches of the U.S. government terminate tribal governments. In 2007 a group of Democratic Party congressmen and congresswomen introduced a bill in the U.S. House of Representatives to "terminate" the Cherokee Nation. This was related to their voting to exclude Cherokee Freedmen as members of the tribe unless they had a Cherokee ancestor on the Dawes Rolls, although all Cherokee Freedmen and their descendants had been members since 1866.
As of 2004, various Native Americans are wary of attempts by others to gain control of their reservation lands for natural resources, such as coal and uranium in the West.
In the state of Virginia, Native Americans face a unique problem. Virginia has no federally recognized tribes but the state has recognized eight. This is related historically to the greater impact of disease and warfare on the Virginia Indian populations, as well as their intermarriage with Europeans and Africans. Some people confused the ancestry with culture, but groups of Virginia Indians maintained their cultural continuity. Most of their early reservations were ended under the pressure of early European settlement.
Some historians also note the problems of Virginia Indians in establishing documented continuity of identity, due to the work of Walter Ashby Plecker (1912–1946). As registrar of the state's Bureau of Vital Statistics, he applied his own interpretation of the one-drop rule, enacted in law in 1924 as the state's Racial Integrity Act. It recognized only two races: "white" and "colored".
Plecker, a segregationist, believed that the state's Native Americans had been "mongrelized" by intermarriage with African Americans; to him, ancestry determined identity, rather than culture. He thought that some people of partial black ancestry were trying to "pass" as Native Americans. Plecker thought that anyone with any African heritage had to be classified as colored, regardless of appearance, amount of European or Native American ancestry, and cultural/community identification. Plecker pressured local governments into reclassifying all Native Americans in the state as "colored", and gave them lists of family surnames to examine for reclassification based on his interpretation of data and the law. This led to the state's destruction of accurate records related to families and communities who identified as Native American (as in church records and daily life). By his actions, sometimes different members of the same family were split by being classified as "white" or "colored". He did not allow people to enter their primary identification as Native American in state records. In 2009, the Senate Indian Affairs Committee endorsed a bill that would grant federal recognition to tribes in Virginia.
To achieve federal recognition and its benefits, tribes must prove continuous existence since 1900. The federal government has maintained this requirement, in part because through participation on councils and committees, federally recognized tribes have been adamant about groups' satisfying the same requirements as they did.
Contemporary issues.
According to 2003 United States Census Bureau estimates, a little over one third of the 2,786,652 Native Americans in the United States live in three states: California at 413,382, Arizona at 294,137 and Oklahoma at 279,559.
Native American struggles amid poverty to maintain life on the reservation or in larger society have resulted in a variety of health issues, some related to nutrition and health practices. The community suffers a vulnerability to and disproportionately high rate of alcoholism. 
Numerous tribal governments have long prohibited the sale of alcohol on reservations, but generally it is readily for sale in nearby border towns, and off-reservation businesses and states gain income from the business. As an example, in 2010, beer sales at off-reservation outlets in Whiteclay, Nebraska generated $413,932 that year in federal and sales taxes. Their customers are overwhelmingly Lakota from the Pine Ridge Indian Reservation in South Dakota. 
Acknowledging that prohibition has not worked, in a major change in strategy since the late twentieth century, as of 2007, 63 percent of the federally recognized tribes in the lower 48 states had legalized alcohol sales on their reservations. Among these, all the other tribes in South Dakota have legalized sales, as have many in Nebraska. The tribes decided to retain the revenues that previously would go to the states through retail sales taxes on this commodity. Legalizing the sales enables the tribes to keep more money within their reservation economies and support new businesses and services, as well as to directly regulate, police and control alcohol sales. The retained revenues enable them to provide health care and build facilities to better treat individuals and families suffering from alcohol abuse. In some cases, legalization of alcohol sales also supported the development of resorts and casinos, to generate revenues for other economic enterprises. 
In addition to increasing numbers of American Indians entering the fields of community health and medicine, agencies working with Native American communities have sought partnerships, representatives of policy and program boards, and other ways to learn and respect their traditions, and to integrate the benefits of Western medicine within their own cultural practices.
In the early 21st century, Native American communities have exhibited continuing growth and revival, playing a larger role in the American economy, and in the lives of Native Americans. Communities have consistently formed governments that administer services such as firefighting, natural resource management, social programs and health care, housing and law enforcement. Numerous tribes have founded tribal colleges. Most Native American communities have established court systems to adjudicate matters related to local ordinances. Most also look to various forms of moral and social authority, such as forms of restorative justice, vested in the traditional culture of the tribal nation. Native American professionals have founded associations in journalism, law, medicine and other fields to encourage students in these fields, provide professional training and networking opportunities, and entree into mainstream institutions. 
To address the housing needs of Native Americans, Congress passed the "Native American Housing and Self Determination Act" (NAHASDA) in 1996. This legislation replaced public housing built by the BIA, and other 1937 Housing Act programs directed towards Indian Housing Authorities, with a block-grant program. It provides funds to be administered by the Tribes to develop their own housing.
Societal discrimination and racism.
Universities have conducted relatively little public opinion research on attitudes toward Native Americans among the general public. In 2007 the non-partisan Public Agenda organization conducted a focus group study. Most non-Native Americans admitted they rarely encountered Native Americans in their daily lives. While sympathetic toward Native Americans and expressing regret over the past, most people had only a vague understanding of the problems facing Native Americans today. For their part, Native Americans told researchers that they believed they continued to face prejudice and mistreatment in the broader society.
Journalists have covered issues of discrimination.
Affirmative action issues.
Federal contractors and subcontractors such as businesses and educational institutions are legally required to adopt equal opportunity employment and affirmative action measures intended to prevent discrimination against employees or applicants for employment, on the basis of "color, religion, sex, or national origin". For this purpose, an American Indian or Alaska Native is defined as "A person having origins in any of the original peoples of North and South America (including Central America), and who maintains a tribal affiliation or community attachment." However, self-reporting is permitted, "Educational Institutions and Other Recipients Should Allow Students and Staff To Self-Identify Their Race and Ethnicity Unless Self-Identification Is Not Practicable or Feasible." 
Self-reporting opens the door to "box checking" by people who despite not having a substantial relationship to Native American culture innocently or fraudulently "check the box" for Native American. On August 15, 2011 the American Bar Association passed a resolution recommending to law schools that supporting information such as evidence of tribal enrollment or connection with Native American culture be required.
Native American mascots in sports.
American Indian activists in the United States and Canada have criticized the use of Native American mascots in sports, as perpetuating stereotypes. European Americans have had a history of "playing Indian" that dates back to at least the 18th century. While supporters of the mascots say they embody the heroism of Native American warriors, AIM particularly has criticized the use of mascots as offensive and demeaning. 
While many universities and professional sports teams (for example, the Cleveland Indians, who had a Chief Wahoo) no longer use such images without consultation and approval by the respective nation, some lower-level schools continue to do so. On the other hand, in the Bay Area of California, Tomales Bay High and Sequoia High have retired their Indian mascots.
In August 2005, the National Collegiate Athletic Association (NCAA) banned the use of "hostile and abusive" Native American mascots in postseason tournaments. An exception was made to allow the use of tribal names if approved by that tribe (such as the Seminole Tribe of Florida's approving use of their name for the team of Florida State University.)
Historical depictions in art.
Native Americans have been depicted by American artists in various ways at different historical periods. During the 16th century, the artist John White made watercolors and engravings of the people native to the southeastern states. John White’s images were, for the most part, faithful likenesses of the people he observed.
The artist Theodore de Bry used White’s original watercolors to make a book of engravings entitled, "A briefe and true report of the new found land of Virginia". In his book, de Bry often altered the poses and features of White’s figures to make them appear more European. During the period when White and de Bry were working, when Europeans were first coming into contact with Native Americans, Europeans were greatly interested in native American cultures. Their curiosity created demand for a book like de Bry’s.
A number of 19th and 20th-century United States and Canadian painters, often motivated by a desire to document and preserve Native culture, specialized in Native American subjects. Among the most prominent of these were Elbridge Ayer Burbank, George Catlin, Seth Eastman, Paul Kane, W. Langdon Kihn, Charles Bird King, Joseph Henry Sharp, and John Mix Stanley.
During the construction of the Capitol building in the early 19th century, the U.S. government commissioned a series of four relief panels to crown the doorway of the Rotunda. The reliefs encapsulate a vision of European—Native American relations that had assumed mythic historical proportions by the 19th century. The four panels depict: "The Preservation of Captain Smith by Pocahontas" (1825) by Antonio Capellano, "The Landing of the Pilgrims" (1825) and "The Conflict of Daniel Boone and the Indians" (1826–27) by Enrico Causici, and "William Penn’s Treaty with the Indians" (1827) by Nicholas Gevelot. 
The reliefs by European sculptors present versions of the Europeans and the Native Americans, in which the Europeans appear refined and the natives appear ferocious. The Whig representative of Virginia, Henry A. Wise, wrote about how Native Americans might think of the reliefs: "We give you corn, you cheat us of our lands: we save your life, you take ours." While many 19th-century images of Native Americans conveyed similarly negative messages, artists such as Charles Bird King sought to express a more balanced image of Native Americans.
During this time, some fiction writers were informed about and sympathetic to Native American culture. Marah Ellis Ryan conveyed the culture with sympathy.
In the 20th century, early portrayals of Native Americans in movies and television roles were first performed by European Americans dressed in mock traditional attire. Examples included "The Last of the Mohicans" (1920), "Hawkeye and the Last of the Mohicans" (1957), and "F Troop" (1965–67). In later decades, Native American actors such as Jay Silverheels in "The Lone Ranger" television series (1949–57) came to prominence. Roles of Native Americans were limited and not reflective of Native American culture. By the 1970s some Native American film roles began to show more complexity, such as those in "Little Big Man" (1970), "Billy Jack" (1971), and "The Outlaw Josey Wales" (1976), which depicted Native Americans in minor supporting roles.
For years, Native people on U.S. television were relegated to secondary, subordinate roles. During the years of the series "Bonanza" (1959–1973), no major or secondary Native characters appeared on a consistent basis. The series "The Lone Ranger" (1949–1957), "Cheyenne" (1957–1963), and "Law of the Plainsman" (1959–1963) had Native characters who were essentially aides to the central white characters. This continued in such series as "How the West Was Won". These programs resembled the "sympathetic" yet contradictory film "Dances With Wolves" of 1990, in which, according to Ella Shohat and Robert Stam, the narrative choice was to relate the Lakota story as told through a Euro-American voice, for wider impact among a general audience.
Like the 1992 remake of "The Last of the Mohicans" and "" (1993), "Dances with Wolves" employed a number of Native American actors, and made an effort to portray Indigenous languages.
In the same period, the TNT Network presented a television movie on Geronimo, as well as two others on Native American historical figures, and a six-part documentary series on Native history, all within a 14-month period.
In 2004 producer Guy Perrotta presented the film "" (2004), a television documentary on the first major war between colonists and Native peoples in the Americas. Perrotta and Charles Clemmons intended to increase public understanding of the significance of this early event. They believed it had significance not only for northeastern Native Peoples and descendants of English and Dutch colonists, but for all Americans today. 
Wanting to make the film historically accurate and unbiased, the producers invited a broadly based Advisory Board, and used scholars, Native Americans, and descendants of the colonists to help tell the story. They elicited personal and often passionate viewpoints from contemporary Americans. The production portrayed the conflict as a struggle between different value systems, which included not only the Pequot, but a number of other Native American tribes, most of which allied with the English. It presents facts and seeks to help viewers better understand the several peoples who fought the War.
In 2009 "We Shall Remain" (2009), a television documentary by Ric Burns and part of the American Experience series, presented a five-episode series "from a Native American perspective". It represented "an unprecedented collaboration between Native and non-Native filmmakers and involves Native advisors and scholars at all levels of the project." The five episodes explore the impact of King Philip's War on the northeastern tribes, the "Native American confederacy" of Tecumseh's War, the US-forced relocation of Southeastern tribes known as the Trail of Tears, the pursuit and capture of Geronimo and the Apache Wars, and concludes with the Wounded Knee incident, participation by the American Indian Movement, and the increasing resurgence of modern Native cultures since.
Terminology differences.
Common usage in the United States.
Native Americans are more commonly known as Indians or American Indians, and have been known as Aboriginal Americans, Amerindians, Amerinds, Colored, First Americans, Native Indians, Indigenous, Original Americans, Red Indians, Redskins or Red Men.
The term "Native American" was introduced in the United States by academics in preference to the older term "Indian" to distinguish the indigenous peoples of the Americas from the people of India, and to avoid negative stereotypes associated with the term "Indian". Some academics believe that the term "Indian" should be considered outdated or offensive. Many indigenous Americans, however, prefer the term "American Indian". Others point out that anyone born in the United States is, technically, native to America. In this sense, "native" was substituted for "indigenous". Today, people from India (and their descendants) who are citizens of the United States are called "Indian Americans" or "Asian Indians".
Criticism of the neologism "Native American" comes from diverse sources. Russell Means, an American Indian activist, opposes the term "Native American" because he believes it was imposed by the government without the consent of American Indians. He has also argued that the use of the word "Indian" derives not from a confusion with India but from a Spanish expression "En Dio", meaning "in God". 
Furthermore, some American Indians question the term "Native American" because, they argue, it serves to ease the conscience of "white America" with regard to past injustices done to American Indians by effectively eliminating "Indians" from the present. Still others (both Indians and non-Indians) argue that "Native American" is problematic because "native of" literally means "born in," so any person born in the Americas could be considered "native". The compound "Native American" is generally capitalized to differentiate the reference to the indigenous peoples.
A 1995 U.S. Census Bureau survey found that more Native Americans in the United States preferred "American Indian" to "Native American". Most American Indians are comfortable with "Indian", "American Indian", and "Native American", and the terms are often used interchangeably. The traditional term is reflected in the name chosen for the National Museum of the American Indian, which opened in 2004 on the Mall in Washington, D.C..
Recently, the U.S. Census Bureau has introduced the "Asian-Indian" category to avoid ambiguity for descendants of people from India.
Gambling industry.
Gambling has become a leading industry. Casinos operated by many Native American governments in the United States are creating a stream of gambling revenue that some communities are beginning to use as leverage to build diversified economies. Native American communities have waged and prevailed in legal battles to assure recognition of rights to self-determination and to use of natural resources. Some of those rights, known as treaty rights, are enumerated in early treaties signed with the young United States government. These casinos have brought an influx of money to the tribes; according to tribal accounting firm Joseph Eve, CPAs, the average net profit of Indian casinos is 38.85%. 
Tribal sovereignty has become a cornerstone of American jurisprudence, and at least on the surface, in national legislative policies. Although many Native American tribes have casinos, the impact of Native American gaming is widely debated. Some tribes, such as the Winnemem Wintu of Redding, California, feel that casinos and their proceeds destroy culture from the inside out. These tribes refuse to participate in the gambling industry.
Crime on reservations.
Prosecution of serious crime, historically endemic on reservations, was required by the 1885 Major Crimes Act, 18 U.S.C. §§1153, 3242, and court decisions to be investigated by the federal government, usually the Federal Bureau of Investigation, and prosecuted by United States Attorneys of the United States federal judicial district in which the reservation lies. An investigation by "The Denver Post" in 2007 found that crimes in Indian Country have been a low priority both with the FBI and most federal prosecutors. 
Often serious crimes have been either poorly investigated or prosecution has been declined. Tribal courts were limited to sentences of one year or less, until on July 29, 2010 the Tribal Law and Order Act was enacted which in some measure reforms the system permitting tribal courts to impose sentences of up to three years provided proceedings are recorded and additional rights are extended to defendants. The Justice Department on January 11, 2010 initiated the Indian Country Law Enforcement Initiative which recognizes problems with law enforcement on reservations and assigns top priority to solving existing problems.The Department of Justice recognizes the unique legal relationship that the United States has with federally recognized tribes. As one aspect of this relationship, in much of Indian Country, the Justice Department alone has the authority to seek a conviction that carries an appropriate potential sentence when a serious crime has been committed. Our role as the primary prosecutor of serious crimes makes our responsibility to citizens in Indian Country unique and mandatory. Accordingly, public safety in tribal communities is a top priority for the Department of Justice.
Emphasis was placed on improving prosecution of crimes involving domestic violence and sexual assault.
"Public Law 280 and Law Enforcement in Indian Country – Research Priorities December 2005", accessed August 12, 2010
As of 2012, a high incidence of rape continued to impact Native American women and Alaskan native women. According to the Justice Department 1 in 3 women have suffered rape or attempted rape, more than twice the national rate. 80% of Native American sexual assault victims report that their attacker was "non-Indian". On June 6, 2012 the Justice Department announced a pilot plan to establish joint federal-tribal response teams on 6 Montana reservations to combat rape and sexual assault.
Society, language, and culture.
Ethno-linguistic classification.
Far from forming a single ethnic group, Native Americans were divided into several hundred ethno-linguistic groups, most of them grouped into the Na-Dené (Athabaskan), Algic (including Algonquian), Uto-Aztecan, Iroquoian, Siouan–Catawban, Yok-Utian, Salishan and Yuman phyla, besides many smaller groups and several language isolates. Demonstrating genetic relationships has proved difficult due to the great linguistic diversity present in North America.
Of the surviving languages, Uto-Aztecan has the most speakers (1.95 million) if the languages in Mexico are considered (mostly due to 1.5 million speakers of Nahuatl); Nadene comes in second with approximately 180,200 speakers (148,500 of these are speakers of Navajo). Na-Dené and Algic have the widest geographic distributions: Algic currently spans from northeastern Canada across much of the continent down to northeastern Mexico (due to later migrations of the Kickapoo) with two outliers in California (Yurok and Wiyot).
Na-Dené spans from Alaska and western Canada through Washington, Oregon, and California to the U.S. Southwest and northern Mexico (with one outlier in the Plains).
Another area of considerable diversity appears to have been the Southeast; however, many of these languages became extinct from European contact and as a result they are, for the most part, absent from the historical record.
Cultural aspects.
Though cultural features, language, clothing, and customs vary enormously from one tribe to another, there are certain elements which are encountered frequently and shared by many tribes.
Early hunter-gatherer tribes made stone weapons from around 10,000 years ago; as the age of metallurgy dawned, newer technologies were used and more efficient weapons produced. Prior to contact with Europeans, most tribes used similar weaponry. The most common implements were the bow and arrow, the war club, and the spear. Quality, material, and design varied widely. Native American use of fire both helped provide and prepare for food and altered the landscape of the continent to help the human population flourish.
Large mammals like mammoths and mastodons were largely extinct by around 8000 BCE. Native Americans switched to hunting other large game, such as bison. The Great Plains tribes were still hunting the bison when they first encountered the Europeans. The Spanish reintroduction of the horse to North America in the 17th century and Native Americans' learning to use them greatly altered the natives' culture, including changing the way in which they hunted large game. (Evidence of pre-historic horses prior to the arrival of the Spanish has been found in the La Brea Tar Pits in Los Angeles, California.) In addition, horses became such a valuable, central element of Native lives that they were counted as a measure of wealth.
Society and art.
The Iroquois, living around the Great Lakes and extending east and north, used strings or belts called "wampum" that served a dual function: the knots and beaded designs mnemonically chronicled tribal stories and legends, and further served as a medium of exchange and a unit of measure. The keepers of the articles were seen as tribal dignitaries.
Pueblo peoples crafted impressive items associated with their religious ceremonies. "Kachina" dancers wore elaborately painted and decorated masks as they ritually impersonated various ancestral spirits. Sculpture was not highly developed, but carved stone and wood fetishes were made for religious use. Superior weaving, embroidered decorations, and rich dyes characterized the textile arts. Both turquoise and shell jewelry were created, as were high-quality pottery and formalized pictorial arts.
Navajo spirituality focused on the maintenance of a harmonious relationship with the spirit world, often achieved by ceremonial acts, usually incorporating sandpainting. The colors—made from sand, charcoal, cornmeal, and pollen—depicted specific spirits. These vivid, intricate, and colorful sand creations were erased at the end of the ceremony.
Agriculture.
An early crop the Native Americans grew was squash. Others early crops included cotton, sunflower, pumpkins, tobacco, goosefoot, knotgrass, and sump weed.
Agriculture in the southwest started around 4,000 years ago when traders brought cultigens from Mexico. Due to the varying climate, some ingenuity was needed for agriculture to be successful. The climate in the southwest ranged from cool, moist mountains regions, to dry, sandy soil in the desert. Some innovations of the time included irrigation to bring water into the dry regions and the selection of seed based on the traits of the growing plants that bore them. In the southwest, they grew beans that were self-supported, much like the way they are grown today.
In the east, however, they were planted right by corn in order for the vines to be able to "climb" the cornstalks. The most important crop the Native Americans raised was maize. It was first started in Mesoamerica and spread north. About 2,000 years ago it reached eastern America. This crop was important to the Native Americans because it was part of their everyday diet; it could be stored in underground pits during the winter, and no part of it was wasted. The husk was made into art crafts, and the cob was used as fuel for fires. By 800 CE the Native Americans had established three main crops — beans, squash, and corn — called the three sisters.
The agriculture gender roles of the Native Americans varied from region to region. In the southwest area, men prepared the soil with hoes. The women were in charge of planting, weeding, and harvesting the crops. In most other regions, the women were in charge of doing everything, including clearing the land. Clearing the land was an immense chore since the Native Americans rotated fields frequently. There is a tradition that Squanto showed the Pilgrims in New England how to put fish in fields to act like a fertilizer, but the truth of this story is debated. 
Native Americans did plant beans next to corn; the beans would replace the nitrogen which the corn took from the ground, as well as using corn stalks for support for climbing. Native Americans used controlled fires to burn weeds and clear fields; this would put nutrients back into the ground. If this did not work, they would simply abandon the field to let it be fallow, and find a new spot for cultivation.
Europeans in the eastern part of the continent observed that Natives cleared large areas for cropland. Their fields in New England sometimes covered hundreds of acres. Colonists in Virginia noted thousands of acres under cultivation by Native Americans.
Native Americans commonly used tools such as the hoe, maul, and dibber. The hoe was the main tool used to till the land and prepare it for planting; then it was used for weeding. The first versions were made out of wood and stone. When the settlers brought iron, Native Americans switched to iron hoes and hatchets. The dibber was a digging stick, used to plant the seed. Once the plants were harvested, women prepared the produce for eating. They used the maul to grind the corn into mash. It was cooked and eaten that way or baked as corn bread.
Religion.
Traditional Native American ceremonies are still practiced by many tribes and bands, and the older theological belief systems are still held by many of the "traditional" people. These spiritualities may accompany adherence to another faith, or can represent a person's primary religious identity. While much Native American spiritualism exists in a tribal-cultural continuum, and as such cannot be easily separated from tribal identity itself, certain other more clearly defined movements have arisen among "traditional" Native American practitioners, these being identifiable as "religions" in the clinical sense. 
Traditional practices of some tribes include the use of sacred herbs such as tobacco, sweetgrass or sage. Many Plains tribes have sweatlodge ceremonies, though the specifics of the ceremony vary among tribes. Fasting, singing and prayer in the ancient languages of their people, and sometimes drumming are also common.
The Midewiwin Lodge is a traditional medicine society inspired by the oral traditions and prophesies of the Ojibwa (Chippewa) and related tribes.
Another significant religious body among Native peoples is known as the Native American Church. It is a syncretistic church incorporating elements of Native spiritual practice from a number of different tribes as well as symbolic elements from Christianity. Its main rite is the peyote ceremony. Prior to 1890, traditional religious beliefs included Wakan Tanka. In the American Southwest, especially New Mexico, a syncretism between the Catholicism brought by Spanish missionaries and the native religion is common; the religious drums, chants, and dances of the Pueblo people are regularly part of Masses at Santa Fe's Saint Francis Cathedral. Native American-Catholic syncretism is also found elsewhere in the United States. (e.g., the National Kateri Tekakwitha Shrine in Fonda, New York and the National Shrine of the North American Martyrs in Auriesville, New York).
The eagle feather law (Title 50 Part 22 of the Code of Federal Regulations) stipulates that only individuals of certifiable Native American ancestry enrolled in a federally recognized tribe are legally authorized to obtain eagle feathers for religious or spiritual use. The law does not allow Native Americans to give eagle feathers to non-Native Americans.
Gender roles.
Gender roles were differentiated in most Native American tribes, and both had power in decisionmaking within the tribe. Many tribes, such as the Haudenosaunee Five Nations and the Southeast Muskogean tribes, had matrilineal systems, in which property and hereditary leadership were controlled by and passed through the maternal lines. The children were considered to belong to the mother's clan and achieved status within it. 
When the tribe adopted war captives, the children became part of their mother's clan and accepted in the tribe. In Cherokee and other matrilineal cultures, wives owned the family property. When young women married, their husbands joined them in their mother's household. 
This enabled the young women to have assistance for childbirth and rearing; it also protected her in case of conflicts between the couple. If they separated or the man was killed at war, the woman had her family to assist her. In addition, in matrilineal culture, the mother's brother was the leading male figure in a male child's life, as he mentored the child within the mother's clan.
The husband had no standing in his wife's and children's clan, as he belonged to his own mother's clan. Hereditary clan chief positions passed through the mother's line, not the father's. Chiefs were selected on recommendation of women elders, who also could disapprove of a chief. There were sometimes hereditary roles for men called peace chiefs, but war chiefs were selected based on proven prowess in battle. Men usually had the roles of hunting, waging war, and negotiating with other tribes, including the Europeans after their arrival.
Others were patriarchal, although several different systems were in use. In the patrilineal tribes, such as the Omaha, Osage and Ponca, hereditary leadership passed through the male line, and children were considered to belong to the father and his clan. For this reason, when Europeans or American men took wives from such tribes, their children were considered "white" like their fathers, or "half-breeds". Generally such children could have no official place in the tribe because their fathers did not belong to it, unless they were adopted by a male and made part of his family.
Men hunted, traded and made war. The women had primary responsibility for the survival and welfare of the families (and future of the tribe); they gathered and cultivated plants, used plants and herbs to treat illnesses, cared for the young and the elderly, made all the clothing and instruments, and processed and cured meat and skins from the game. They tanned hides to make clothing as well as bags, saddle cloths, and tepee covers. Mothers used cradleboards to carry an infant while working or traveling. 
At least several dozen tribes allowed polygyny to sisters, with procedural and economic limits.
Apart from making homes, women had many additional tasks that were also essential for the survival of the tribes. They made weapons and tools, took care of the roofs of their homes and often helped their men hunt bison.
In some of the Plains Indian tribes, medicine women gathered herbs and cured the ill.
The Sioux girls were encouraged to learn to ride, hunt and fight. Though fighting was mostly left to the boys and men, occasionally women fought with them, especially if the tribe was severely threatened.
Sports.
Native American leisure time led to competitive individual and team sports. Jim Thorpe, Joe Hipp, Notah Begay III, Jacoby Ellsbury, and Billy Mills are well known professional athletes.
Team based.
Native American ball sports, sometimes referred to as lacrosse, stickball, or baggataway, was often used to settle disputes, rather than going to war, as a civil way to settle potential conflict. The Choctaw called it "isitoboli" ("Little Brother of War"); the Onondaga name was "dehuntshigwa'es" ("men hit a rounded object"). There are three basic versions, classified as Great Lakes, Iroquoian, and Southern. 
The game is played with one or two rackets/sticks and one ball. The object of the game is to land the ball on the opposing team's goal (either a single post or net) to score and to prevent the opposing team from scoring on your goal. The game involves as few as twenty or as many as 300 players with no height or weight restrictions and no protective gear. The goals could be from around apart to about ; in Lacrosse the field is . A Jesuit priest referenced stickball in 1729, and George Catlin painted the subject.
Individual based.
Chunkey was a game that consisted of a stone shaped disk that was about 1–2 inches in diameter. The disk was thrown down a corridor so that it could roll past the players at great speed. The disk would roll down the corridor, and players would throw wooden shafts at the moving disk. The object of the game was to strike the disk or prevent your opponents from hitting it.
U.S. Olympics.
Jim Thorpe, a Sauk and Fox Native American, was an all-round athlete playing football and baseball in the early 20th century. Future President Dwight Eisenhower injured his knee while trying to tackle the young Thorpe. In a 1961 speech, Eisenhower recalled Thorpe: "Here and there, there are some people who are supremely endowed. My memory goes back to Jim Thorpe. He never practiced in his life, and he could do anything better than any other football player I ever saw."
In the 1912 Olympics, Thorpe could run the 100-yard dash in 10 seconds flat, the 220 in 21.8 seconds, the 440 in 51.8 seconds, the 880 in 1:57, the mile in 4:35, the 120-yard high hurdles in 15 seconds, and the 220-yard low hurdles in 24 seconds. He could long jump 23 ft 6 in and high-jump 6 ft 5 in. He could pole vault , put the shot , throw the javelin , and throw the discus . Thorpe entered the U.S. Olympic trials for both the pentathlon and the decathlon.
Billy Mills, a Lakota and USMC officer, won the gold medal in the 10,000 meter run at the 1964 Tokyo Olympics. He was the only American ever to win the Olympic gold in this event. An unknown prior to the Olympics, Mills finished second in the U.S. Olympic trials.
Billy Kidd, part Abenaki from Vermont, became the first American male to medal in alpine skiing in the Olympics, taking silver at age 20 in the slalom in the 1964 Winter Olympics at Innsbruck, Austria.Six years later at the 1970 World Championships, Kidd won the gold medal in the combined event and took the bronze medal in the slalom.
Music and art.
Traditional Native American music is almost entirely monophonic, but there are notable exceptions. Native American music often includes drumming and/or the playing of rattles or other percussion instruments but little other instrumentation. Flutes and whistles made of wood, cane, or bone are also played, generally by individuals, but in former times also by large ensembles (as noted by Spanish conquistador de Soto). The tuning of modern flutes is typically pentatonic.
Performers with Native American parentage have occasionally appeared in American popular music, such as Robbie Robertson (The Band), Rita Coolidge, Wayne Newton, Gene Clark, Buffy Sainte-Marie, Blackfoot, Tori Amos, Redbone, and CocoRosie. Some, such as John Trudell, have used music to comment on life in Native America, and others, such as R. Carlos Nakai integrate traditional sounds with modern sounds in instrumental recordings. A variety of small and medium-sized recording companies offer an abundance of recent music by Native American performers young and old, ranging from pow-wow drum music to hard-driving rock-and-roll and rap.
The most widely practiced public musical form among Native Americans in the United States is that of the pow-wow. At pow-wows, such as the annual Gathering of Nations in Albuquerque, New Mexico, members of drum groups sit in a circle around a large drum. Drum groups play in unison while they sing in a native language and dancers in colorful regalia dance clockwise around the drum groups in the center. Familiar pow-wow songs include honor songs, intertribal songs, crow-hops, sneak-up songs, grass-dances, two-steps, welcome songs, going-home songs, and war songs. Most indigenous communities in the United States also maintain traditional songs and ceremonies, some of which are shared and practiced exclusively within the community.
Native American art comprises a major category in the world art collection. Native American contributions include pottery, paintings, jewellery, weavings, sculpture, basketry, and carvings. Franklin Gritts was a Cherokee artist who taught students from many tribes at Haskell Institute (now Haskell Indian Nations University) in the 1940s, the "Golden Age" of Native American painters. The integrity of certain Native American artworks is protected by an act of Congress that prohibits representation of art as Native American when it is not the product of an enrolled Native American artist.
Traditional economy.
The Inuit, or Eskimo, prepared and buried large amounts of dried meat and fish. Pacific Northwest tribes crafted seafaring dugouts long for fishing. Farmers in the Eastern Woodlands tended fields of maize with hoes and digging sticks, while their neighbors in the Southeast grew tobacco as well as food crops. On the Plains, some tribes engaged in agriculture but also planned buffalo hunts in which herds were driven over bluffs. 
Dwellers of the Southwest deserts hunted small animals and gathered acorns to grind into flour with which they baked wafer-thin bread on top of heated stones. Some groups on the region's mesas developed irrigation techniques, and filled storehouses with grain as protection against the area's frequent droughts.
In the early years, as these native peoples encountered European explorers and settlers and engaged in trade, they exchanged food, crafts, and furs for blankets, iron and steel implements, horses, trinkets, firearms, and alcoholic beverages.
Contemporary barriers to economic development.
Today, other than tribes successfully running casinos, many tribes struggle, as they are often located on reservations isolated from the main economic centers of the country. The estimated 2.1 million Native Americans are the most impoverished of all ethnic groups. According to the 2000 Census, an estimated 400,000 Native Americans reside on reservation land. While some tribes have had success with gaming, only 40% of the 562 federally recognized tribes operate casinos. According to a 2007 survey by the U.S. Small Business Administration, only 1% of Native Americans own and operate a business. 
Native Americans rank at the bottom of nearly every social statistic: highest teen suicide rate of all minorities at 18.5 per 100,000, highest rate of teen pregnancy, highest high school drop-out rate at 54%, lowest per capita income, and unemployment rates between 50% to 90%. Many Native Americans have become urbanized to survive, moving to urban centers in the states where their reservations are, or out of state. Others have entered academic and political fields that take them away from the reservations.
A major barrier to development is the lack of entrepreneurial knowledge and experience within Indian reservations. "A general lack of education and experience about business is a significant challenge to prospective entrepreneurs," was the report on Native American entrepreneurship by the Northwest Area Foundation in 2004. "Native American communities that lack entrepreneurial traditions and recent experiences typically do not provide the support that entrepreneurs need to thrive. Consequently, experiential entrepreneurship education needs to be embedded into school curricula and after-school and other community activities. This would allow students to learn the essential elements of entrepreneurship from a young age and encourage them to apply these elements throughout life.". "Rez Biz" magazine addresses these issues.
Native Americans, Europeans, and Africans.
Interracial relations between Native Americans, Europeans, and Africans is a complex issue that has been mostly neglected with "few in-depth studies on interracial relationships". Some of the first documented cases of European/Native American intermarriage and contact were recorded in Post-Columbian Mexico. One case is that of Gonzalo Guerrero, a European from Spain, who was shipwrecked along the Yucatan Peninsula, and fathered three Mestizo children with a Mayan noblewoman. Another is the case of Hernán Cortés and his mistress La Malinche, who gave birth to another of the first multi-racial people in the Americas.
Assimilation.
European impact was immediate, widespread, and profound—more than any other race that had contact with Native Americans during the early years of colonization and nationhood. Europeans living among Native Americans were often called "white indians". They "lived in native communities for years, learned native languages fluently, attended native councils, and often fought alongside their native companions."
Early contact was often charged with tension and emotion, but also had moments of friendship, cooperation, and intimacy. Marriages took place in English, Spanish, and French colonies between Native Americans and Europeans. Given the preponderance of men among the colonists in the early years, generally European men married American Indian women. 
In 1528, Isabel de Moctezuma, an heir of Moctezuma II, was married to Alonso de Grado, a Spanish Conquistador. After his death, the widow married Juan Cano de Saavedra. Together they had five children. Many heirs of Emperor Moctezuma II were acknowledged by the Spanish crown, who granted them titles including Duke of Moctezuma de Tultengo.
On April 5, 1614, Pocahontas married the Englishman John Rolfe. They had a child called Thomas Rolfe. Intimate relations among Native American and Europeans were widespread, beginning with the French and Spanish explorers and trappers. For instance, in the early 19th century, the Native American woman Sacagawea, who would help translate for the Lewis and Clark Expedition, was married to the French-Canadian trapper Toussaint Charbonneau. They had a son named Jean Baptiste Charbonneau. This was the most typical pattern among the traders and trappers.
There was fear on both sides, as the different peoples realized how different their societies were. The whites regarded the Indians as "savage" because they were not Christian. They were suspicious of cultures which they did not understand. The Native American author, Andrew J. Blackbird, wrote in his "History of the Ottawa and Chippewa Indians of Michigan," (1897), that white settlers introduced some immoralities into Native American tribes. Many Indians suffered because the Europeans introduced alcohol and the whiskey trade resulted in alcoholism among the people, who were alcohol-intolerant.
"The Ottawas and Chippewas were quite virtuous in their primitive state, as there were no illegitimate children reported in our old traditions. But very lately this evil came to exist among the Ottawas-so lately that the second case among the Ottawas of 'Arbor Croche' is yet living in 1897. And from that time this evil came to be quite frequent, for immorality has been introduced among these people by evil white persons who bring their vices into the tribes."
The U. S. government had two purposes when making land agreements with Native Americans: to open it up more land for white settlement, and to ease tensions between whites and Native Americans by forcing Natives to use the land in the same way as did the whites - for subsistence farms. The government used a variety of strategies to achieve these goals; many treaties required Native Americans to become farmers in order to keep their land. Government officials often did not translate the documents which Native Americans were forced to sign, and native chiefs often had little or no idea what they were signing.
For a Native American man to marry a white woman, he had to get consent of her parents, as long as "he can prove to support her as a white woman in a good home". In the early 19th century, the Shawnee Tecumseh and blonde hair & blued eyed Rebbecca Galloway had an inter-racial affair. In the late 19th century, three European-American middle-class women teachers at Hampton Institute married Native American men whom they had met as students.
As European-American women started working independently at missions and Indian schools in the western states, there were more opportunities for their meeting and developing relationships with Native American men. For instance, Charles Eastman, a man of European and Lakota descent whose father sent both his sons to Dartmouth College, got his medical degree at Boston University and returned to the West to practice. He married Elaine Goodale, whom he met in South Dakota. He was the grandson of Seth Eastman, a military officer from Maine, and a chief's daughter. Goodale was a young European-American teacher from Massachusetts and a reformer, who was appointed as the US superintendent of Native American education for the reservations in the Dakota Territory. They had six children together.
European enslavement.
When Europeans arrived as colonists in North America, Native Americans changed their practice of slavery dramatically. Native Americans began selling war captives to whites rather than integrating them into their own societies as they had done before. As the demand for labor in the West Indies grew with the cultivation of sugar cane, Europeans enslaved Native Americans for the Thirteen Colonies, and some were exported to the "sugar islands." The British settlers, especially those in the southern colonies, purchased or captured Native Americans to use as forced labor in cultivating tobacco, rice, and indigo. Accurate records of the numbers enslaved do not exist. Scholars estimate tens of thousands of Native Americans may have been enslaved by the Europeans, being sold by Native Americans themselves.
The slave trade of Native Americans lasted only until around 1730. It gave rise to a series of devastating wars among the tribes, including the Yamasee War. The Indian Wars of the early 18th century, combined with the increasing importation of African slaves, effectively ended the Native American slave trade by 1750. Colonists found that Native American slaves could easily escape, as they knew the country. The wars cost the lives of numerous colonial slave traders and disrupted their early societies. The remaining Native American groups banded together to face the Europeans from a position of strength. Many surviving Native American peoples of the southeast strengthened their loose coalitions of language groups and joined confederacies such as the Choctaw, the Creek, and the Catawba for protection.
Native American women were at risk for rape whether they were enslaved or not; during the early colonial years, settlers were disproportionately male. They turned to Native women for sexual relationships. Both Native American and African enslaved women suffered rape and sexual harassment by male slaveholders and other white men.
Traditions of Native American slavery.
The majority of Native American tribes did practice some form of slavery before the European introduction of African slavery into North America, but none exploited slave labor on a large scale. In addition, Native Americans did not buy and sell captives in the pre-colonial era, although they sometimes exchanged enslaved individuals with other tribes in peace gestures or in exchange for their own members.
The conditions of enslaved Native Americans varied among the tribes. In many cases, young enslaved captives were adopted into the tribes to replace warriors killed during warfare or by disease. Other tribes practiced debt slavery or imposed slavery on tribal members who had committed crimes; but, this status was only temporary as the enslaved worked off their obligations to the tribal society.
Among some Pacific Northwest tribes, about a quarter of the population were slaves. Other slave-owning tribes of North America were, for example, Comanche of Texas, Creek of Georgia, the Pawnee, and Klamath.
Native American and African relations.
African and Native Americans have interacted for centuries. The earliest record of Native American and African contact occurred in April 1502, when Spanish colonists transported the first Africans to Hispaniola to serve as slaves.
Sometimes Native Americans resented the presence of African Americans. The "Catawaba tribe in 1752 showed great anger and bitter resentment when an African American came among them as a trader." To gain favor with Europeans, the Cherokee exhibited the strongest color prejudice of all Native Americans. He contends that because of European fears of a unified revolt of Native Americans and African Americans, the colonists encouraged hostility between the ethnic groups: "Whites sought to convince Native Americans that African Americans worked against their best interests." In 1751, South Carolina law stated: 
 In addition, in 1758 the governor of South Carolina James Glen wrote: it has always been the policy of this government to create an aversion in them Indians to Negroes. Europeans considered both races inferior and made efforts to make both Native Americans and Africans enemies. Native Americans were rewarded if they returned escaped slaves, and African Americans were rewarded for fighting in the late nineteenth-century Indian Wars.
"Native Americans, during the transitional period of Africans becoming the primary race enslaved, were enslaved at the same time and shared a common experience of enslavement. They worked together, lived together in communal quarters, produced collective recipes for food, shared herbal remedies, myths and legends, and in the end they intermarried." Because of a shortage of men due to warfare, many tribes encouraged marriage between the two groups, to create stronger, healthier children from the unions.
In the 18th century, many Native American women married freed or runaway African men due to a decrease in the population of men in Native American villages. Records show that many Native American women bought African men but, unknown to the European sellers, the women freed and married the men into their tribe. When African men married or had children by a Native American woman, their children were born free, because the mother was free (according to the principle of partus sequitur ventrum, which the colonists incorporated into law.)
European colonists often required the return of runaway slaves to be included as a provision in treaties with American Indians. In 1726, the British Governor of New York exacted a promise from the Iroquois to return all runaway slaves who had joined up with them. In the mid 1760s, the government requested the Huron and Delaware to return runaway slaves, but there was no record of slaves having been returned. Colonists placed ads about runaway slaves.
While numerous tribes used captive enemies as servants and slaves, they also often adopted younger captives into their tribes to replace members who had died. In the Southeast, a few Native American tribes began to adopt a slavery system similar to that of the American colonists, buying African American slaves, especially the Cherokee, Choctaw, and Creek. Though less than 3% of Native Americans owned slaves, divisions grew among the Native Americans over slavery. Among the Cherokee, records show that slave holders in the tribe were largely the children of European men that had shown their children the economics of slavery. As European colonists took slaves into frontier areas, there were more opportunities for relationships between African and Native American peoples.
Based on the work of geneticists, a PBS series on African Americans explained that while most African Americans are racially mixed, it is relatively rare that they have Native American ancestry. According to the PBS series, the most common "non-black" mix is English and Scots-Irish. However, the Y-chromosome and mtDNA (mitochondrial DNA) testing processes for direct-line male and female ancestors can fail to pick up the heritage of many ancestors. (Some critics thought the PBS series did not sufficiently explain the limitations of DNA testing for assessment of heritage.) 
Another study suggests that relatively few Native Americans have African-American heritage. A study reported in "The American Journal of Human Genetics" stated, "We analyzed the European genetic contribution to 10 populations of African descent in the United States (Maywood, Illinois; Detroit; New York; Philadelphia; Pittsburgh; Baltimore; Charleston, South Carolina; New Orleans; and Houston) ... mtDNA haplogroups analysis shows no evidence of a significant maternal Amerindian contribution to any of the 10 populations." A few writers persist in the myth that most African Americans have Native American heritage.
DNA testing has limitations and should not be depended on by individuals to answer all their questions about heritage. So far, such testing cannot distinguish among the many distinct Native American tribes. No tribes accept DNA testing to satisfy their differing qualifications for membership, usually based on documented blood quantum or descent from ancestor(s) listed on the Dawes Rolls.
Native American adoption of African slavery.
Native Americans interacted with enslaved Africans and African Americans on many levels. Over time all the cultures interacted. Native Americans began slowly to adopt white culture. Native Americans in the South shared some experiences with Africans, especially during the period, primarily in the 17th century, when both were enslaved. The colonists along the Atlantic Coast had begun enslaving Native Americans to ensure a source of labor. At one time the slave trade was so extensive that it caused increasing tensions with the various Algonquian tribes, as well as the Iroquois. Based in New York and Pennsylvania, they had threatened to attack colonists on behalf of the related Iroquoian Tuscarora before they migrated out of the South in the early 1700s.
In the 1790s, Benjamin Hawkins was assigned as the US agent to the southeastern tribes, who became known as the Five Civilized Tribes for their adoption of numerous Anglo-European practices. He advised the tribes to take up slaveholding to aid them in European-style farming and plantations. He thought their traditional form of slavery, which had looser conditions, was less efficient than chattel slavery. In the nineteenth century, some members of these tribes who were more closely associated with settlers, began to purchase African-American slaves for workers. They adopted some European-American ways to benefit their people. 
The writer William Loren Katz contends that Native Americans treated their slaves better than did the typical European American in the Deep South. Though less than 3% of Native Americans owned slaves, bondage created destructive cleavages among those who were slaveholders.
Among the Five Civilized Tribes, mixed-race slaveholders were generally part of an elite hierarchy, often based on their mothers' clan status, as the societies had matrilineal systems. As did Benjamin Hawkins, European fur traders and colonial officials tended to marry high-status women, in strategic alliances seen to benefit both sides. The Choctaw, Creek and Cherokee believed they benefited from stronger alliances with the traders and their societies. The women's sons gained their status from their mother's families; they were part of hereditary leadership lines who exercised power and accumulated personal wealth in their changing Native American societies. The historian Greg O'Brien calls them the Creole generation to show that they were part of a changing society. The chiefs of the tribes believed that some of the new generation of mixed-race, bilingual chiefs would lead their people into the future and be better able to adapt to new conditions influenced by European Americans. 
Proposals for Indian Removal heightened the tensions of cultural changes, due to the increase in the number of mixed-race Native Americans in the South. Full bloods, who tended to live in areas less affected by colonial encroachment, generally worked to maintain traditional ways, including control of communal lands. While the traditional members often resented the sale of tribal lands to Anglo-Americans, by the 1830s they agreed it was not possible to go to war with the colonists on this issue.
Who are Native Americans?
Admixture and genetics.
Intertribal mixing was common among Native American tribes, so individuals often had ancestry from more than one tribe, particularly after tribes lost so many members from disease. Bands or entire tribes occasionally split or merged to form more viable groups in reaction to the pressures of climate, disease and warfare. 
A number of tribes traditionally adopted captives into their group to replace members who had been captured or killed in battle. These captives were from rival tribes and later from European settlements. Some tribes also sheltered or adopted white traders and runaway slaves, and others owned slaves of their own. Tribes with long trading histories with Europeans show a higher rate of European admixture, reflecting years of intermarriage between European men and Native American women. A number of paths to genetic and ethnic diversity among Native Americans existed.
In recent years, genetic genealogists have been able to determine the proportion of Native American ancestry carried by the African-American population. The literary and history scholar Henry Louis Gates, Jr. had experts on his TV programs who discussed African-American ancestry. They stated that 5% of African Americans have at least 12.5% Native American ancestry. A greater percentage could have a smaller proportion of Indian ancestry, but their conclusions show that popular estimates of admixture may have been too high.
DNA testing is not sufficient to qualify a person for specific tribal membership, as it cannot distinguish among Native American groups.
Native American identity has historically been based on culture, not just biology, as many American Indian peoples adopted captives from their enemies and assimilated them into their tribes. The Indigenous Peoples Council on Biocolonialism (IPCB) notes that:
Geneticists state:Not all Native Americans have been tested; especially with the large number of deaths due to disease such as small pox, it is unlikely that Native Americans only have the genetic markers they have identified, even when their maternal or paternal bloodline does not include a non-Native American.
Tribal Classifications.
To receive tribal services, a Native American must be a certified member of a recognized tribal organization. Each tribal government makes its own rules for eligibility of citizens or tribal members. The federal government has standards related to services available to certified Native Americans. For instance, federal scholarships for Native Americans require the student to be enrolled in a federally recognized tribe and have at least one-quarter Native American descent (equivalent to one grandparent), attested to by a Certificate of Degree of Indian Blood (CDIB) card. Among tribes, qualification may be based upon a required percentage of Native American "blood" (or the "blood quantum") of an individual seeking recognition, or documented descent from an ancestor on the Dawes Rolls or other registers.
Some tribes have begun requiring genealogical DNA testing, but this is usually related to an individual's proving parentage or direct descent from a certified member. Requirements for tribal membership vary widely by tribe. The Cherokee require documented genealogical descent from a Native American listed on the early 1906 Dawes Rolls. Tribal rules regarding recognition of members who have heritage from multiple tribes are equally diverse and complex.
Tribal membership conflicts have led to a number of legal disputes, court cases, and the formation of activist groups. One example of this are the Cherokee Freedmen. Today, they include descendants of African Americans once enslaved by the Cherokees, who were granted, by federal treaty, citizenship in the historic Cherokee Nation as freedmen after the Civil War. The modern Cherokee Nation, in the early 1980s, excluded them from citizenship, unless individuals can prove descent from a Cherokee Native American (not Cherokee Freedmen) listed on the Dawes Rolls.
Genetics.
Genetic history of indigenous peoples of the Americas primarily focus on Human Y-chromosome DNA haplogroups and Human mitochondrial DNA haplogroups. "Y-DNA" is passed solely along the patrilineal line, from father to son, while "mtDNA" is passed down the matrilineal line, from mother to offspring of both sexes. Neither recombines, and thus Y-DNA and mtDNA change only by chance mutation at each generation with no intermixture between parents' genetic material. Autosomal "atDNA" markers are also used, but differ from mtDNA or Y-DNA in that they overlap significantly. AtDNA is generally used to measure the average continent-of-ancestry genetic admixture in the entire human genome and related isolated populations.
The genetic pattern indicates Indigenous Americans experienced two very distinctive genetic episodes; first with the initial-peopling of the Americas, and secondly with European colonization of the Americas. The former is the determinant factor for the number of gene lineages, zygosity mutations and founding haplotypes present in today's Indigenous Amerindian populations.
Human settlement of the New World occurred in stages from the Bering sea coast line, with an initial 15, 000 to 20,000-year layover on Beringia for the small founding population. The micro-satellite diversity and distributions of the Y lineage specific to South America indicates that certain Amerindian populations have been isolated since the initial colonization of the region. The Na-Dené, Inuit and Indigenous Alaskan populations exhibit haplogroup Q (Y-DNA) mutations, however, that are distinct from other indigenous Amerindians, and that have various mtDNA and atDNA mutations. This suggests that the paleo-Indian migrants into the northern extremes of North America and Greenland were descended from a later, independent migrant population.

Nazism
Nazism (German: Nationalsozialismus; English long form National Socialism) was the ideology of the Nazi Party and Nazi Germany. It is a variety of fascism that incorporates biological racism and antisemitism. Nazism used elements of the far-right racist "Völkisch" German nationalist movement and the anti-communist "Freikorps" paramilitary culture which fought against the communists in post-World War I Germany. It was designed to draw workers away from communism and into "Völkisch" nationalism. Major elements of Nazism have been described as far-right, such as allowing domination of society by people deemed racially superior, while purging society of people declared inferior which were said to be a threat to national survival.
Nazi philosophy claimed that an Aryan master race was superior to all other races. To maintain what it regarded as the purity and strength of the Aryan race, the Nazis sought to exterminate Jews and Romani, and the physically and mentally disabled. Other groups deemed "degenerate" or "asocial" received exclusionary treatment by the Nazi state and included homosexuals, blacks, Jehovah's Witnesses and political opponents. The Nazis promoted German territorial expansionism to gain "Lebensraum" ("living space") for German settlers and to bring labor, food and materials into the nation for growth.
Nazi "Führer" Adolf Hitler had objected to the party's previous leader's decision to use the word "Socialist" in its name as Hitler at the time instead preferred to use "Social Revolutionary". Upon taking over the leadership, Hitler kept the term but defined socialism as meaning a commitment of an individual to a community. Hitler claimed that true socialism does not repudiate private property unlike the claims of Marxism, and claimed that the "Marxians have stolen the term and confused its meaning" and said that "Communism is not socialism. Marxism is not socialism." Nazism favoured private property, freedom of contract, and promoted the creation of national solidarity that would transcend class differences. The Nazis outlawed strikes by employees and lockouts by employers, because these were regarded a threat to national unity. Instead, the state controlled and approved wage and salary levels.
Etymology.
The full name of Adolf Hitler's party was "Nationalsozialistische Deutsche Arbeiterpartei" (National Socialist German Workers' Party). The acronym "Nazi" was formed from the first syllable of "NAtional" and the second syllable of "SoZIalist". Such acronyms, usually formed from the initial letters or syllables of successive parts of compound names, were popular in the Third Reich. Another such example was Gestapo for "GEheime STAatsPOlizei" (Secret State Police).
Position in the political spectrum.
A majority of scholars identify Nazism in practice as a form of far-right politics. Far right themes in Nazism include the argument that superior people have a right to dominate over others and purge society of supposed inferior elements. Adolf Hitler and other proponents officially portrayed Nazism as being neither left- nor right-wing, but syncretic. Hitler in "Mein Kampf" directly attacked both left-wing and right-wing politics in Germany, saying: 
Today our left-wing politicians in particular are constantly insisting that their craven-hearted and obsequious foreign policy necessarily results from the disarmament of Germany, whereas the truth is that this is the policy of traitors [...] But the politicians of the Right deserve exactly the same reproach. It was through their miserable cowardice that those ruffians of Jews who came into power in 1918 were able to rob the nation of its arms.
Hitler, when asked whether he supported the "bourgeois right-wing", claimed that Nazism was not exclusively for any class, and indicated that it favoured neither the left nor the right, but preserved "pure" elements from both "camps", stating: "From the camp of bourgeois tradition, it takes national resolve, and from the materialism of the Marxist dogma, living, creative Socialism".
The Nazis were strongly influenced by the post-World War I far-right in Germany, which held common beliefs such as anti-Marxism, anti-liberalism, and anti-Semitism, along with nationalism, contempt towards the Treaty of Versailles, and condemnnation of the Weimar Republic for signing the armistice in November 1918 that later led to their signing of the Treaty of Versailles. A major inspiration for the Nazis were the far-right nationalist "Freikorps", paramilitary organizations that engaged in political violence after World War I. Initially, the post-World War I German far right was dominated by monarchists, but the younger generation, who were associated with "Völkisch" nationalism, were more radical and did not express any emphasis on the restoration of the German monarchy. This younger generation desired to dismantle the Weimar Republic and create a new radical and strong state based upon a martial ruling ethic that could revive the "Spirit of 1914" that was associated with German national unity ("Volksgemeinschaft").
The Nazis, the far-right monarchist and reactionary German National People's Party (DNVP), and others, such as monarchist officers of the German army and several prominent industrialists, formed an alliance in opposition to the Weimar Republic on 11 October 1931 in Bad Harzburg; officially known as the "National Front", but commonly referred to as the Harzburg Front. The Nazis stated the alliance was purely tactical and there remained substantial differences with the DNVP. The Nazis described the DNVP as a bourgeois party and called themselves an anti-bourgeois party. After the elections in 1932, the alliance broke after the DNVP lost many of its seats in the Reichstag. The Nazis denounced them as "an insignificant heap of reactionaries". The DNVP responded by denouncing the Nazis for their socialism, their street violence, and the "economic experiments" that would take place if the Nazis rose to power.
Te exiled Kaiser Wilhelm II, who fled Germany into exile amidst an attempted communist revolution in Germany, initially supported the Nazi Party, and his four sons of the exiled German royal family, including Prince Eitel Friedrich and Prince Oskar, became members of the Nazi Party, in hopes that in exchange for their support, the Nazis would permit the restoration of the monarchy.
There were factions in the Nazi Party, both conservative and radical. The conservative Nazi Hermann Göring urged Hitler to conciliate with capitalists and reactionaries. Other prominent conservative Nazis included Heinrich Himmler and Reinhard Heydrich.
The radical Nazi Joseph Goebbels, hated capitalism, viewing it as having Jews at its core, and he stressed the need for the party to emphasize both a proletarian and national character. Those views were shared by Otto Strasser, who later left the Nazi Party in the belief that Hitler had betrayed the party's socialist goals by allegedly endorsing capitalism. Large segments of the Nazi Party staunchly supported its official socialist, revolutionary, and anti-capitalist positions and expected both a social and economic revolution upon the party gaining power in 1933. Many of the million members of the Sturmabteilung (SA) were committed to the party's official socialist program. The leader of the SA, Ernst Röhm, pushed for a "second revolution" (the "first revolution" being the Nazis' seizure of power) that would entrench the party's official socialist program. Further, Röhm desired that the SA absorb the much smaller German Army into its ranks under his leadership.
Prior to becoming an anti-Semite and a Nazi, Hitler had lived a Bohemian lifestyle as a wandering watercolour artist in Austria and southern Germany, though he maintained elements of it later in life. Hitler served in World War I and after the war his battalion was absorbed by the Bavarian Soviet Republic from 1918 to 1919, where he was elected Deputy Battalion Representative. According to historian Thomas Weber, he attended the funeral of communist Kurt Eisner (a German Jew), wearing a black mourning armband on one arm and a red communist armband on the other. Further that Hitler's political beliefs had not yet solidified, and at that time he supported the idea of a classless society and was an anti-monarchist. In "Mein Kampf", Hitler never mentioned any service with the Bavarian Soviet Republic, and he stated that he became an anti-Semite in 1913 in Vienna. This statement has been disputed with the contention he in fact was not an anti-Semite at that time. Hitler altered his political views in response to the Treaty of Versailles of June 1919, and it was then that he became an anti-Semitic, German nationalist. As a Nazi, Hitler had expressed opposition to capitalism; he regarded capitalism as having Jewish origins, and accused capitalism of holding nations ransom in the interests of a parasitic cosmopolitan rentier class.
Hitler took a pragmatic position between the conservative and radical factions of the Nazi Party, in that he accepted private property and allowed capitalist private enterprises to exist as long as they adhered to the goals of the Nazi state. However, if a capitalist private enterprise resisted Nazi goals, he sought to destroy it. Upon the Nazis achieving power, Röhm's SA began attacks against individuals deemed to be associated with conservative reaction, without Hitler's authorization to do so. Hitler considered Röhm's independent actions to be violating and possibly threatening his leadership, as well as jeopardizing the regime by alienating the conservative President Paul von Hindenburg and the conservative-oriented German Army. This resulted in Hitler purging Röhm and other radical members of the SA in what came to be known as the Night of the Long Knives.
Although he opposed communist ideology, Hitler on numerous occasions publicly praised the Soviet Union's leader Joseph Stalin and Stalinism. Hitler commended Stalin for seeking to purify the Communist Party of the Soviet Union of Jewish influences, noting Stalin's purging of Jewish communists such as Leon Trotsky, Grigory Zinoviev, Lev Kamenev and Karl Radek. While Hitler always intended to bring Germany into conflict against the Soviet Union to gain "Lebensraum" ("living space"), he supported a temporary strategic alliance between Nazi Germany and the Soviet Union to form a common anti-liberal front to crush liberal democracies, particularly France.
Origins.
Nationalism, antisemitism and racism.
One of the most significant ideological influences on the Nazis was the German nationalist Johann Gottlieb Fichte, whose works had served as inspiration to Hitler and other Nazi members, including Dietrich Eckart and Arnold Fanck. In "Speeches to the German Nation" (1808), written amid Napoleonic France's occupation of Berlin, Fichte called for a German national revolution against the French occupiers, making passionate public speeches, arming his students for battle against the French, and stressing the need for action by the German nation to free itself. Fichte's nationalism was populist and opposed to traditional elites, spoke of the need of a "People's War" ("Volkskrieg"), and put forth concepts similar to those the Nazis adopted. Fichte promoted German exceptionalism and stressed the need for the German nation to be purified (including purging the German language of French words, a policy that the Nazis undertook upon rising to power).
"Völkisch" nationalism denounced soulless materialism, individualism, and secularized urban industrial society, while advocating a "superior" society based on ethnic German "folk" culture and German "blood". It denounced foreigners, foreign ideas and declared that Jews, national minorities, Catholics, and Freemasons were "traitors to the nation" and unworthy of inclusion. "Völkisch" nationalism saw the world in terms of natural law and romanticism, viewed societies as organic, extolling the virtues of rural life, condemning the neglect of tradition and decay of morals, denounced the destruction of the natural environment, and condemned "cosmopolitan" cultures such as Jews and Romani.
During the era of Imperial Germany, "Völkisch" nationalism was overshadowed by both Prussian patriotism and the federalist tradition of various states therein. The events of World War I including the end of the Prussian monarchy in Germany, resulted in a surge of revolutionary "Völkisch" nationalism. The Nazis supported such revolutionary "Völkisch" nationalist policies. The Nazis claimed that their ideology was influenced by the leadership and policies of German Chancellor Otto von Bismarck, the founder of the German Empire. The Nazis declared that they were dedicated to continuing the process of creating a unified German nation state that Bismarck had begun and desired to achieve. While Hitler was supportive of Bismarck's creation of the German Empire, he was critical of Bismarck's moderate domestic policies. On the issue of Bismarck's support of a "Kleindeutschland" ("Lesser Germany", excluding Austria) versus the pan-German "Großdeutschland" ("Greater Germany") of the Nazis, Hitler stated that Bismarck's attainment of "Kleindeutschland" was the "highest achievement" Bismarck could have achieved "within the limits possible of that time". In "Mein Kampf" ("My Struggle"), Hitler presented himself as a "second Bismarck".
The concept of the Aryan race which the Nazis promoted stems from racial theories asserting that Europeans are the descendants of Indo-Iranian settlers, people of ancient India and ancient Persia. Proponents of this theory based their assertion on the similarity of European words and their meaning to those of Indo-Iranian languages. Johann Gottfried Herder argued that the Germanic peoples held close racial connections with the ancient Indians and ancient Persians, who he claimed were advanced peoples possessing a great capacity for wisdom, nobility, restraint, and science. Contemporaries of Herder utilized the concept of the Aryan race to draw a distinction between what they deemed "high and noble" Aryan culture versus that of "parasitic" Semitic culture.
Notions of white supremacy and Aryan racial superiority combined in the nineteenth century, with white supremacists maintaining that white people were members of an Aryan "master race" which is superior to other races, and particularly the Semitic race, which they associated with "cultural sterility". Arthur de Gobineau, a French racial theorist and aristocrat, blamed the fall of the "ancien régime" in France on racial degeneracy caused by racial intermixing, which he argued destroyed the purity of the Aryan race. Gobineau's theories, which attracted a strong following in Germany, emphasized the existence of an irreconcilable polarity between Aryan and Jewish cultures.
Aryan mysticism claimed that Christianity originated in Aryan religious tradition and that Jews had usurped the legend from Aryans. Houston Stewart Chamberlain, an English proponent of racial theory, supported notions of Germanic supremacy and anti-Semitism in Germany. Chamberlain's work, "Foundations of the Nineteenth Century" (1899) praised Germanic peoples for their creativity and idealism while asserting that the Germanic spirit was threatened by a "Jewish" spirit of selfishness and materialism. Chamberlain used his thesis to promote monarchical conservatism while denouncing democracy, liberalism, and socialism. The book became popular, especially in Germany. Chamberlain stressed the need of a nation to maintain racial purity in order to prevent degeneration, and argued that racial intermingling with Jews should never be permitted. In 1923, Chamberlain met Hitler, whom he admired as a leader of the rebirth of the free spirit.
Beginning in the 1870s, German "Völkisch" nationalism began to adopt anti-Semitic and racist themes and was adopted by a number of radical right political movements.
"The Protocols of the Elders of Zion" (1912) was an anti-Semitic forgery created by the police of the Russian Empire. Anti-Semites believed it was real and the Protocol surged in popularity after World War I. "The Protocols" claimed that there was a secret international Jewish conspiracy to take over the world. Hitler had been introduced to "The Protocols" by Alfred Rosenberg, and from 1920 onward Hitler focused his attacks on claiming that Judaism and Marxism were directly connected; that Jews and Bolsheviks were one and the same and that Marxism was a Jewish ideology. Hitler believed that "The Protocols" were authentic.
Radical anti-Semitism was promoted by prominent advocates of "Völkisch" nationalism including Eugen Diederichs, Paul de Lagarde, and Julius Langbehn. De Lagarde called the Jews a "bacillus, the carrier of decay...who pollute every national culture...and destroy all faith with their materialistic liberalism" and he called for the extermination of the Jews. Langbehn called for a war of annihilation of the Jews and Langbehn's genocidal policies were published by the Nazis and given to soldiers on the front during World War II.
Johann Gottlieb Fichte accused Jews in Germany of having been, and inevitably continuing to be, a "state within a state" in Germany that was a threat to German national unity. Fichte promoted two options to address this: the first was the creation of a Jewish state in Palestine to impel the Jews to leave Europe. The other option was violence against Jews, saying that the goal would be "...to cut off all their heads in one night, and set new ones on their shoulders, which should not contain a single Jewish idea".
The Nazis claimed that Bismarck was unable to complete German national unification because of Jewish infiltration of the German parliament, and that their abolition of parliament ended the obstacle to unification. Using the "stab in the back" legend, the Nazis accused Jews, and other populaces it considered non-German, of possessing extra-national loyalties, thereby exacerbating German anti-semitism about the "Judenfrage" (the Jewish Question), the perennial far right political canard popular when the ethnic Völkisch movement and their politics of Romantic nationalism for establishing a "Großdeutschland" were strong. 
Nazism's racial policy positions may have developed from the views of important biologists of the 19th century, including French biologist Jean-Baptiste Lamarck, through Ernst Haeckel's idealist version of Lamarckism and the father of genetics, German botanist Gregor Mendel. However Haeckel's works were later condemned and banned from bookshops and libraries by the Nazis as inappropriate for “National-Socialist formation and education in the Third Reich.” This may have been because of his "monist" atheistic, materialist philosophy which the Nazis disliked. Unlike Darwinian theory, Lamarckian theory officially ranked races in a hierarchy of evolution from apes while Darwinian theory did not grade races in a hierarchy of higher or lower evolution from apes, simply categorizing humans as a whole of all as having progressed in evolution from apes. Many Lamarckians viewed "lower" races as having been exposed to debilitating conditions for too long for any significant "improvement" of their condition in the near future. Haeckel utilized Lamarckian theory to describe the existence of interracial struggle and put races on a hierarchy of evolution, ranging from being wholly human to subhuman.
Mendelian inheritance or Mendelism was supported by the Nazis and also mainstream eugenics proponents at the time. The Mendelian theory of inheritance declared that genetic traits and attributes were passed from one generation to another. Proponents of eugenics used Mendelian inheritance theory to demonstrate the transfer of biological illness and impairments from parents to children, including mental disability; others also utilized Mendelian theory to demonstrate the inheritance of social traits, with racialists claiming a racial nature of certain general traits such as inventiveness or criminal behaviour.
During his youth in Austria, Hitler was politically influenced by Austrian pan-Germanist proponent Georg Ritter von Schönerer, who advocated radical German nationalism, anti-Semitism, anti-Catholicism, anti-Slavism and anti-Habsburg views. From von Schönerer and his followers, Hitler adopted for the Nazi movement the "Heil" greeting, the "Führer" title, and the model of absolute party leadership. Hitler was also impressed with the populist anti-Semitism and anti-liberal bourgeois agitation of Karl Lueger, who as the mayor of Vienna during Hitler's time in the city used a rabble-rousing oratory style that appealed to the wider masses. Unlike von Schönerer, however, Lueger was not a German nationalist, but a pro-Catholic Habsburg supporter.
Response to World War I and fascism.
During World War I, German sociologist Johann Plenge spoke of the rise of a "National Socialism" in Germany within what he termed the "ideas of 1914" that were a declaration of war against the "ideas of 1789" (the French Revolution). According to Plenge, the "ideas of 1789" that included rights of man, democracy, individualism and liberalism were being rejected in favour of "the ideas of 1914" that included "German values" of duty, discipline, law, and order. Plenge believed that ethnic solidarity ("Volksgemeinschaft") would replace class division and that "racial comrades" would unite to create a socialist society in the struggle of "proletarian" Germany against "capitalist" Britain. He believed that the "Spirit of 1914" manifested itself in the concept of the "People's League of National Socialism". This National Socialism was a form of state socialism that rejected the "idea of boundless freedom" and promoted an economy that would serve the whole of Germany under the leadership of the state. This National Socialism was opposed to capitalism due to the components that were against "the national interest" of Germany, but insisted that National Socialism would strive for greater efficiency in the economy. Plenge advocated an authoritarian rational ruling elite to develop National Socialism through a hierarchical technocratic state. Plenge's ideas formed the basis of Nazism.
Oswald Spengler, a German cultural philosopher, was a major influence on Nazism; although after 1933 Spengler became alienated from Nazism and was later condemned by the Nazis for criticizing Adolf Hitler. Spengler's conception of national socialism along with a number of his political views were shared by the Nazis and the Conservative Revolutionary movement. Spengler's views were also popular amongst Italian Fascists, including Benito Mussolini. 
Spengler's book "The Decline of the West" (1918) written during the final months of World War I, addressed the claim of decadence of modern European civilization, whicht he claimed was caused by atomizing and irreligious individualization and cosmopolitanism. Spengler's major thesis was that a law of historical development of cultures existed involving a cycle of birth, maturity, aging, and death when it reaches its final form of civilization. Upon reaching the point of civilization, a culture will lose its creative capacity and succumb to decadence until the emergence of "barbarians" create a new epoch. Spengler considered the Western world as having succumbed to decadence of intellect, money, cosmopolitan urban life, irreligious life, individualization, and the end of biological fertility as well as "spiritual" fertility. He believed that the "young" German nation as an imperial power would inherit the legacy of Ancient Rome, lead a restoration of value in "blood" and instinct, while the ideals of rationalism would be revealed as absurd.
Spengler's notions of "Prussian socialism" as described in his book "Preussentum und Sozialismus" ("Prussiandom and Socialism", 1919), influenced Nazism and the Conservative Revolutionary movement. Spengler wrote: "The meaning of socialism is that life is controlled not by the opposition between rich and poor, but by the rank that achievement and talent bestow. That is "our" freedom, freedom from the economic despotism of the individual." Spengler adopted the anti-English ideas addressed by Plenge and Sombart during World War I that condemned English liberalism and English parliamentarianism while advocating a national socialism that was free from Marxism and that would connect the individual to the state through corporatist organization. Spengler claimed that socialistic Prussian characteristics existed across Germany, including creativity, discipline, concern for the greater good, productivity and self-sacrifice. He prescribed war as a necessity, saying "War is the eternal form of higher human existence and states exist for war: they are the expression of the will to war."
Spengler's definition of socialism did not advocate a change to property relations. He denounced Marxism for seeking to train the proletariat to "expropriate the expropriator", the capitalist, and then to let them live a life of leisure on this expropriation. He claimed that "Marxism is the capitalism of the working class" and not true socialism. True socialism, according to Spengler, would be in the form of corporatism, stating that "local corporate bodies organized according to the importance of each occupation to the people as a whole; higher representation in stages up to a supreme council of the state; mandates revocable at any time; no organized parties, no professional politicians, no periodic elections."
Arthur Moeller van den Bruck who initially was the dominant figure of the Conservative Revolutionaries influenced Nazism. He rejected reactionary conservatism, while proposing a new state, that he coined the "Third Reich", which would unite all classes under authoritarian rule. Van den Bruck advocated a combination of the nationalism of the right and the socialism of the left.
Fascism was a major influence on Nazism. The seizure of power by Italian Fascist leader Benito Mussolini in the March on Rome in 1922 drew admiration by Hitler who less than a month later had begun to model himself and the Nazi Party upon Mussolini and the Fascists. Hitler presented the Nazis as a German fascism. 
In November 1923, the Nazis attempted a "March on Berlin" modelled upon the March on Rome that resulted in the failed Beer Hall Putsch in Munich. Other Nazis — especially more radical ones such as Gregor Strasser, Joseph Goebbels and Heinrich Himmler — rejected Italian Fascism, accusing it of being too conservative or capitalist. Alfred Rosenberg condemned Italian Fascism for being racially confused and having influences from philo-Semitism. Strasser criticized the policy of "Führerprinzip" as being created by Mussolini, and considered its presence in Nazism as a foreign imported idea. Throughout the relationship between Nazi Germany and Fascist Italy, a number of lower-ranking Nazis scornfully viewed fascism as a conservative movement that lacked a full revolutionary potential.
Ideology.
From 1920 to 1923, Hitler formulated his ideology, then published it in 1925–26, as "Mein Kampf", a two-volume, biography and political manifesto.
Though Hitler for "tactical" reasons had rhetorically declared a 1920 party platform with socialist platitudes "unshakable," actually "many paragraphs of the party program were obviously merely a demagogic appeal to the mood of the lower classes at a time when they were in bad straits and were sympathetic to radical and even socialist slogans...Point 11, for example...Point 12...nationalization...Point 16...communalization... put in at the insistence of Drexler and Feder, who apparently really believed in the 'socialism' of National Socialism." In actual practice, such points were mere slogans, "most of them forgotten by the time the party came to power... the Nazi leader himself was later to be embarrassed when reminded of some of them." Historian Conan Fischer argues that the Nazis were sincere in their use of the adjective "socialist", which they saw as inseparable from the adjective "national", and meant it as a socialism of the master race, rather than the socialism of the "underprivileged and oppressed seeking justice and equal rights."
Social class.
Despite many working-class supporters and members, the appeal of the Nazi Party was arguably more effective with the middle class. Moreover, the financial collapse of the white collar middle-class of the 1920s figures much in their strong support of Nazism, thus the great percentage of declared middle-class support for the Nazis. In the poor country that was the Weimar Republic of the early 1930s, the Nazi Party realised their socialist policies with food and shelter for the unemployed and the homeless — later recruited to the Brownshirt "Sturmabteilung" (SA — Storm Detachment).
Sex and gender.
Nazi ideology advocated excluding women from political involvement and confining them to the spheres of "Kinder, Küche, Kirche" (Children, Kitchen, Church).
Opposition to homosexuality.
After the Night of the Long Knives, Hitler promoted Himmler and the SS, who then zealously suppressed homosexuality, saying: "We must exterminate these people root and branch ... the homosexual must be eliminated." In 1936, Himmler established the "Reichszentrale zur Bekämpfung der Homosexualität und Abtreibung" ("Reich Central Office for the Combating of Homosexuality and Abortion"). The Nazi régime incarcerated some 100,000 homosexuals during the 1930s. As concentration camp prisoners, homosexual men were forced to wear pink triangle badges.
Racial policy.
Several of the founders and leaders of the Nazi Party were members of the "Thule-Gesellschaft" (Thule Society), who romanticized Aryan race superstitions with ritual and theology. Originally, derived from the "Germanenorden", the Thule Society shared the racist superstitions of Ariosophy and the society's activities consisted of anti-Semitism lectures and excursions of Germanic antiquity. The Thule Society member, Dietrich Eckart, coached Adolf Hitler in public speaking, and Hitler later dedicated "Mein Kampf" to Eckart. The DAP had initial support from the Thule Society — but after Hitler had taken over the Party, by denigrating their superstitious approach to politics, the society's members were quickly marginalised to allow the party to become a mass movement. 
Hitler viewed individual races as being part of a hierarchy, and he espoused the "aristocratic idea of nature". This view led to his assertion of superior and higher qualities of the Aryan race. Hitler claimed to have first developed his worldview while in Vienna from 1907 to 1913, concluding that the Austro–Hungarian Empire comprised racial, religious, and cultural hierarchies; he viewed "Aryans" as the ultimate master race inhabiting the top, whilst Jews and Gypsies were at bottom. Other research suggests that Hitler's virulent antisemitism was a post-war development, influenced from the Russian civil war. The idea of the Russian roots of Nazism has been explored by Walter Laqueur and Michael Kellogg.
The racist subject of Nazism was "Das Volk", the German people living under continual cultural attack by Judeo-Bolshevism. Nazi Party leadership sought to unify the "Volk", and strongly encouraged stoicism, self-discipline and self-sacrifice to achieve final victory. Nazi propagandist Joseph Goebbels frequently employed antisemitic rhetoric to underline this view: "The Jew is the enemy and destroyer of the purity of blood, the conscious destroyer of our race ... As socialists, we are opponents of the Jews, because we see, in the Hebrews, the incarnation of capitalism, of the misuse of the nation's goods." 
In the pseudoscientific treatise, "The Myth of the Twentieth Century" — according to Terrence Ball and Richard Bellamy, the second-most important book to Nazism, after "Mein Kampf" — Reichstag Secretary, Alfred Rosenberg proposed that, "rom a northern centre of creation which, without postulating an actual submerged Atlantic continent, we may call Atlantis, swarms of warriors once fanned out, in obedience to the ever-renewed and incarnate Nordic longing for distance to conquer and space to shape". 
According to Nazism, through struggle and proper "breeding", the "strong" would subdue the "weak" and rise to dominance. For example, Nazi policy since 1920 emphasized that only people of "German blood" could be considered German citizens thus excluding people of Jewish descent, a view that ultimately resulted in the killing of millions of people in the Holocaust. 
To maintain the "purity and strength" of the Aryan race, the Nazis sought to exterminate Jews, Romani, and the physically and mentally disabled. Other groups deemed "degenerate" and "asocial" who were not targeted for extermination, but received exclusionary treatment by the Nazi state, included homosexuals, blacks, Jehovah's Witnesses and political opponents. One of Hitler's ambitions at the start of the war was to exterminate, expel, or enslave most or all Slavs from central and eastern Europe (i.e., Poles, Russians, Ukrainians, etc.) so as to make living space for German settlers.
We may be inhumane, but if we rescue Germany we have achieved the greatest deed in the world. We may work injustice, but if we rescue Germany then we have removed the greatest injustice in the world. We may be immoral, but if our people is rescued we have opened the way for morality.
The number of Germans of African descent was low; however, some of them were enlisted into Nazi organisations like the Hitler Youth and the "Wehrmacht".
Religion.
The Nazi Party Programme of 1920 guaranteed freedom for all religious denominations not hostile to the State and endorsed Positive Christianity to combat “the Jewish-materialist spirit”. It was a modified version of Christianity which emphasized racial purity and nationalism. The Nazis were aided by theologians, such as, Dr. Ernst Bergmann (philosopher). Bergmann, in his work, "Die 25 Thesen der Deutschreligion" (Twenty-five Points of the German Religion), held that the Old Testament and portions of the New Testament of the Bible were inaccurate. He claimed that Jesus was not a Jew and of Aryan origin, and that Adolf Hitler was the new messiah. At the same time the Nazis utilized Protestant Martin Luther in their propaganda. Nazis publicly displayed an original of Luther's "On the Jews and their Lies" during the annual Nuremberg rallies. The Nazis endorsed the pro-Nazi Protestant German Christians organization.
The Nazis were initially highly hostile to Catholics because most Catholics supported the German Centre Party. Catholics opposed the Nazis' promotion of sterilization of those deemed inferior, and the Catholic Church forbid its members to vote for the Nazis. In 1933, extensive Nazi violence occurred against Catholics due to the their association with the Centre Party and their opposition to the Nazi regime's sterilization laws. The Nazis demanded that Catholics declare their loyalty to the German state. In propaganda, the Nazis used elements of Germany's Catholic history, in particular the German Catholic Teutonic Knights and their campaigns in Eastern Europe. The Nazis identified them as "sentinels" in the East against "Slavic chaos", though beyond that symbolism the influence of the Teutonic Knights on Nazism was limited. Hitler also admitted that the model of the Nazis' night rallies was inspired by the Catholic rituals he witnessed during his Catholic upbringing. The Nazis did seek official reconciliation with the Catholic Church and endorsed the creation of the pro-Nazi Catholic "Kreuz und Adler" organization that supported a national Catholicism. On 20 July 1933, a successful concordat ("Reichskonkordat") was signed between Nazi Germany and the Catholic Church which demanded loyalty of German Catholics to the German state in exchange for acceptance of the Catholic Church in Germany. The Catholic Church then ended its ban on members supporting the Nazi Party.
Historian Michael Burleigh claims that Nazism used Christianity for political purposes, but such use required that "fundamental tenets were stripped out, but the remaining diffuse religious emotionality had its uses". Burleigh claims that Nazism's conception of spirituality was "self-conciously pagan and primitive". However, historian Roger Griffin rejects the claim that Nazism was primarily pagan, noting that although there were some influential neo-paganists in the Nazi Party, such as Heinrich Himmler and Alfred Rosenberg, they represented a minority and their views did not influence Nazi ideology beyond its use for symbolism; its noted that Hitler denounced Germanic paganism in "Mein Kampf" and condemned Rosenburg's and Himmler's paganism as "nonsense".
Economics.
Hitler believed that private ownership was useful in that it encouraged creative competition and technical innovation, but insisted that it had to conform to national interests and be "productive" rather than "parasitical". Private property rights were conditional upon the economic mode of use, if it did not advance Nazi economic goals then the state could nationalize it. Although the Nazis privatised public properties and public services, they also increased economic state control. Under Nazi economics, free competition and self-regulating markets diminished; nevertheless, Hitler's social Darwinist beliefs made him reluctant to entirely disregard business competition and private property as economic engines.
To tie farmers to their land, selling agricultural land was prohibited. Farm ownership was nominally private, but discretion over operations and residual income were proscribed. That was achieved by granting business monopoly rights to marketing boards, to control production and prices with a quota system.
Anti-communism.
Historians Ian Kershaw and Joachim Fest argue that in post-World War I Germany, the Nazis were one of many nationalist and fascist political parties contending for the leadership of Germany's anti-communist movement. The Nazis claimed that communism was dangerous to the well-being of nations because of its intention to dissolve private property, its support of class conflict, its aggression against the middle class, its hostility to small businessmen, and its atheism. Nazism rejected class conflict-based socialism and economic egalitarianism, favouring instead a stratified economy with social classes based on merit and talent, retaining private property, and the creation of national solidarity that transcends class distinction.
During the 1920s, Hitler urged disparate Nazi factions to unite in opposition to "Jewish Marxism." Hitler asserted that the "three vices" of "Jewish Marxism" were democracy, pacifism and internationalism.
In 1930, Hitler said: "Our adopted term ‘Socialist' has nothing to do with Marxian Socialism. Marxism is anti-property; true Socialism is not." In 1942, Hitler privately said: "I absolutely insist on protecting private property ... we must encourage private initiative".
During the late 1930s and the 1940s, anti-communist regimes and groups that supported Nazism included the Falange in Spain; the Vichy regime and the 33rd Waffen Grenadier Division of the SS Charlemagne (1st French) in France; and the Cliveden Set, Lord Halifax, and associates of Neville Chamberlain in Britain.
Anti-capitalism.
The Nazis argued that capitalism damages nations due to international finance, the economic dominance of big business, and Jewish influences. Nazi propaganda posters in working-class districts emphasized anti-capitalism, such as one that said: "The maintenance of a rotten industrial system has nothing to do with nationalism. I can love Germany and hate capitalism."
Hitler, both in public and in private, expressed strong disdain for capitalism, accusing modern capitalism of holding nations ransom in the interests of a parasitic cosmopolitan rentier class. He opposed free-market capitalism's profit-seeking impulses and desired an economy in which community interests would be upheld. He distrusted capitalism for being unreliable, due to its egotistic nature, and he preferred a state-directed economy that is subordinated to the interests of the Volk. Hitler told a party leader in 1934, "The economic system of our day is the creation of the Jews." Hitler said to Benito Mussolini that "Capitalism had run its course". Hitler also said that the business bourgeoisie "know nothing except their profit. 'Fatherland' is only a word for them." Hitler admired Napoleon as a role model for his anti-conservative, anti-capitalist and anti-bourgeois attitudes.
In "Mein Kampf", Hitler effectively supported mercantilism, in the belief that economic resources from their respective territories should be seized by force; he believed that the policy of "Lebensraum" would provide Germany with such economically valuable territories. He believed that the only means to maintain economic security was to have direct control over resources rather than being forced to rely on world trade. He claimed that war to gain such resources was the only means to surpass the failing capitalist economic system.
A number of other Nazis held strong revolutionary socialist and anti-capitalist beliefs, most prominently Ernst Röhm, the leader of the Sturmabteilung (SA). Röhm claimed that the Nazis' rise to power constituted a national revolution, but insisted that a socialist "second revolution" was required for Nazi ideology to be fulfilled. Röhm's SA began attacks against individuals deemed to be associated with conservative reaction. Hitler saw Röhm's independent actions as violating and possibly threatening his leadership, as well as jeopardizing the regime by alienating conservative President Paul von Hindenburg and the conservative-oriented German Army. This resulted in Hitler purging Röhm and other radical members of the SA. Another radical Nazi, Propaganda Minister Joseph Goebbels adamantly stressed the socialist character of Nazism, and claimed in his diary that if he were to pick between Bolshevism and capitalism, he said "in final analysis", "it would be better for us to go down with Bolshevism than live in eternal slavery under capitalism."

Holocaust denial
Holocaust denial is the act of denying the genocide of Jews in the Holocaust during World War II. The key claims of Holocaust denial are: the German Nazi government had no official policy or intention of exterminating Jews, Nazi authorities did not use extermination camps and gas chambers to mass murder Jews, and the actual number of Jews killed was significantly (typically an order of magnitude) lower than the historically accepted figure of 5 to 6 million.
Holocaust deniers generally do not accept the term "denial" as an appropriate description of their activities, and use the term "revisionism" instead. Scholars use the term "denial" to differentiate Holocaust deniers from historical revisionists, who use established historical methodologies. The methodologies of Holocaust deniers are criticized as based on a predetermined conclusion that ignores extensive historical evidence to the contrary.
Most Holocaust denial claims imply, or openly state, that the Holocaust is a hoax arising out of a deliberate Jewish conspiracy to advance the interest of Jews at the expense of other peoples. For this reason, Holocaust denial is generally considered to be an antisemitic conspiracy theory.
Examination of claims.
Holocaust denial is widely viewed as failing to adhere to rules for the treatment of evidence, principles that mainstream historians (as well as scholars in other fields) regard as basic to rational inquiry.
The Holocaust was well documented by the bureaucracy of the Nazi government itself. It was further witnessed by the Allied forces who entered Germany and its associated Axis states towards the end of World War II.
Much of the controversy surrounding the claims of Holocaust deniers centers on the methods used to present arguments that the Holocaust allegedly "never happened as commonly accepted". Numerous accounts have been given by Holocaust deniers (including evidence presented in court cases) of claimed facts and evidence; however, independent research has shown these claims to be based upon flawed research, biased statements, or even deliberately falsified evidence. Opponents of Holocaust denial have documented numerous instances in which such evidence was altered or manufactured (see Nizkor Project and David Irving). According to Pierre Vidal-Naquet, "in our society of image and spectacle, extermination on paper leads to extermination in reality."
Attempts at concealment by perpetrators.
Eisenhower, upon finding the victims of the death camps, ordered all possible photographs to be taken, and for the German people from surrounding villages to be ushered through the camps and even made to bury the dead. He wrote the following to General Marshall after visiting a German internment camp near Gotha, Germany: 
History and development after World War II.
After World War II, many of the former leaders of the SS left Germany and began using their propaganda skills to defend their actions (or, their critics contended, to rewrite history). Denial materials began to appear shortly after the war.
Harry Elmer Barnes.
Harry Elmer Barnes, an American, was at one time a mainstream historian; he assumed a Holocaust-denial stance in the later years of his life. Between World War I and World War II, Barnes became well known as an anti-war writer and a leader in the historical revisionism movement, where he had worked closely from 1924 onwards with Centre for the Study of the Causes of the War. This institute was a pseudo-historical think-tank based in Berlin, secretly funded by the German government and headed by a former "völkisch" activist named Major Alfred von Wegerer, whose sole purpose was to prove Germany was the victim of Allied aggression in 1914. Following World War II, Barnes became convinced that allegations made against Germany and Japan, including the Holocaust, were wartime propaganda used to justify U.S. involvement in World War II.
In his 1962 pamphlet, "Revisionism and Brainwashing", Barnes claimed that there was a “lack of any serious opposition or concerted challenge to the atrocity stories and other modes of defamation of German national character and conduct”. Barnes went on to write that in his view there was “a failure to point out the atrocities of the Allies were more brutal, painful, mortal and numerous than the most extreme allegations made against the Germans”. Starting at this time, Barnes started to cite the French Holocaust denier Paul Rassinier, whom Barnes called a “distinguished French historian” who Barnes claimed had exposed the “exaggerations of the atrocity stories". In a 1964 article entitled “Zionist Fraud” published in the "American Mercury," Barnes wrote that: Using Rassinier as his source, Barnes claimed that Germany was the victim of aggression in both 1914 and 1939, and the Holocaust was just propaganda to justify a war of aggression against Germany. Barnes took the view that World War II had ended in disaster for the West with Germany divided and the United States locked into the Cold War, made all the worse in Barnes’s eyes, as in his view Germany never wanted war. Barnes claimed that in order to justify the “horrors and evils of the Second World War”, the Allies were required to make the Nazis the “scapegoat” for their own misdeeds. Barnes claimed there were two false claims made about World War II, namely that Germany started the war in 1939, and the Holocaust, which Barnes denied.
Following the example of Barnes, a few other early libertarian writers also concerned with anti-war historical revisionism began to take a Holocaust-denial stance, including James J. Martin. Most libertarians, however—even those who otherwise hold Barnes' writings in high regard—reject his Holocaust denial. Barnes' name has since been appropriated by some modern Holocaust deniers in an attempt to lend credibility to their cause, most notably Willis Carto.
The beginnings of the modern denial movement.
In 1961, the American historian and a leading protégé of Barnes, David Hoggan published "Der Erzwungene Krieg" ("The Forced War") in West Germany, which claimed that Germany had been the victim of an Anglo-Polish conspiracy in 1939. Though "Der Erzwungene Krieg" was primarily concerned with the origins of World War II, it also down-played or justified the effects of Nazi antisemitic measures in the pre-1939 period. For an example, Hoggan justified the huge one billion "Reich"-mark fine imposed on the entire Jewish community in Germany after the 1938 "Kristallnacht" as a reasonable measure to prevent what he called "Jewish profiteering" at the expense of German insurance companies and alleged that no Jews were killed in the "Kristallnacht" (in fact, 91 German Jews were killed in the "Kristallnacht"). Subsequently, Hoggan wrote one of the first books denying the Holocaust in 1969 entitled "The Myth of the Six Million", which was published by the Noontide Press, a small Los Angeles publisher specializing in antisemitic literature. Hoggan became one of the early stars of the Holocaust denial movement, because he had a number of university professorships.
In 1964, French historian Paul Rassinier published "The Drama of the European Jews." Rassinier was himself a concentration camp survivor (imprisoned in Buchenwald for his having helped French Jews escape the Nazis), and modern-day deniers continue to cite his works as scholarly research that questions the accepted facts of the Holocaust. Critics argued that Rassinier did not cite evidence for his claims and ignored information that contradicted his assertions; he nevertheless remains influential in Holocaust denial circles for being one of the first deniers to propose that a vast Zionist/Allied/Soviet conspiracy faked the Holocaust, a theme that would be picked up in later years by other authors.
The publication of Arthur Butz's "The Hoax of the Twentieth Century: The case against the presumed extermination of European Jewry" in 1976; and David Irving's "Hitler's War" in 1977 brought other similarly inclined individuals into the fold. In December 1978 and January 1979, Robert Faurisson, a French professor of literature at the University of Lyon, wrote two letters to "Le Monde" claiming that the gas chambers used by the Nazis to exterminate the Jews did not exist. A colleague of Faurisson, Jean-Claude Pressac, who initially shared Faurisson's views, later became convinced of the Holocaust's evidence while investigating documents at Auschwitz in 1979. He published his conclusions along with much of the underlying evidence in his 1989 book, "Auschwitz: Technique and operation of the gas chambers".
Henry Bienen, the former president of Northwestern University, has described Arthur Butz's view of the Holocaust as an "embarrassment to Northwestern". In 2006, sixty of Butz's colleagues from the Department of Electrical Engineering and Computer Science faculty signed a censure describing Butz's Holocaust denial as "an affront to our humanity and our standards as scholars". The letter also called for Butz to "leave our Department and our University and stop trading on our reputation for academic excellence."
Institute for Historical Review.
In 1978 Willis Carto founded the Institute for Historical Review (IHR) as an organization dedicated to publicly challenging the commonly accepted history of the Holocaust. The IHR sought from the beginning to attempt to establish itself within the broad tradition of historical revisionism, by soliciting token supporters who were not from a neo-Nazi background such as James J. Martin and Samuel Edward Konkin III, and by promoting the writings of French socialist Paul Rassinier and American anti-war historian Harry Elmer Barnes to attempt to show that Holocaust denial had a broader base of support besides just neo-Nazis. The IHR brought most of Barnes' writings, which had been out of print since his death, back into print. While IHR included articles on other topics and sold books by mainstream historians in its catalog, the majority of material published and distributed by IHR was devoted to questioning the facts surrounding the Holocaust.
The IHR became one of the most important organizations devoted to Holocaust denial. In recent years the IHR underwent an internal power struggle which ousted Willis Carto and put Mark Weber in charge. Carto went on to found the "Barnes Review" magazine after his ouster from IHR, a magazine which is also devoted to Holocaust denial.
Bradley Smith and the Committee for Open Debate on the Holocaust.
In 1987, Bradley R. Smith, a former media director of the Institute for Historical Review, founded the Committee for Open Debate on the Holocaust (CODOH). In the United States, CODOH has repeatedly tried to place newspaper advertisements questioning whether the Holocaust happened, especially in college campus newspapers. Some newspapers have accepted the advertisements, while others have rejected them. Bradley Smith has more recently sought other avenues to promote Holocaust denial – with little success. On September 8, 2009, The Harvard Crimson school paper ran a paid ad from Bradley R Smith. It was quickly criticized and an apology was issued from the editor, claiming it was a mistake.
Bradley referred to his tactics as the CODOH campus project. Bradley says, “I don’t want to spend time with adults anymore, I want to go to students. They are superficial. They are empty vessels to be filled.” “What I wanted to do was I wanted to set forth three or four ideas that students might be interested in, that might cause them to think about things or to have questions about things. And I wanted to make it as simple as possible, and to set it up in a way that could not really be debated”. Holocaust deniers have placed[…]“Full page advertisements in college and university newspaper, including those of Brandeis University, Boston College, Pennsylvania State University, and Queens College. Some of these ads arguing that Holocaust never happened ran without comment; others generated op-ed pieces by professors and students.
James Keegstra.
In 1984, James Keegstra, a Canadian high-school teacher, was charged with denying the Holocaust and making antisemitic claims in his classroom as part of the course material. Keegstra and his lawyer, Doug Christie, argued that the section of the Criminal Code of Canada (now section 319{2}), is an infringement of the Charter of Rights (section 9{b}). The case was appealed to the Supreme Court of Canada, where it was decided that the law he was convicted under did infringe on his freedom of expression, but it was a justified infringement. Keegstra was convicted, and fired from his job.
The Zündel trials.
The Toronto-based photo retoucher Ernst Zündel operated a small-press publishing house called Samisdat Publishing, which published and distributed Holocaust-denial material such as "Did Six Million Really Die?" by Richard Harwood (a.k.a. Richard Verrall – a British neo-Nazi leader). In 1985, he was tried in R. v. Zundel and convicted under a "false news" law and sentenced to 15 months imprisonment by an Ontario court for "disseminating and publishing material denying the Holocaust." The Holocaust historian Raul Hilberg was a notable witness for the prosecution at the 1985 trial. Zündel gained considerable notoriety after this conviction, and a number of free-speech activists stepped forward to defend his right to publish his opinions. After his conviction in 1985, Zündel was able to have it overturned in an appeal on a legal technicality, leading to a second trial in 1988, in which he was again convicted. The 1988 trial was notable for the appearance of Fred A. Leuchter, David Irving and Robert Faurisson as defense witnesses for Zündel, and for the presentation of the pseudo-scientific Leuchter report as a defense document. The Leuchter report was published in Canada in 1988 by Samisdat Publishers and in Britain in 1989 by Irving's Focal Point Publishing. In both of his trials, Zündel was defended by Douglas Christie and Barbara Kulaszka. His conviction was overturned in 1992 when the Supreme Court of Canada declared the "false news" law unconstitutional.
Zündel has a website, web-mastered by his wife Ingrid, which publicises his viewpoints. In January 2002, the Canadian Human Rights Tribunal delivered a ruling in a complaint involving his website, in which it was found to be contravening the Canadian Human Rights Act. The court ordered Zündel to cease communicating hate messages. In February 2003, the American INS arrested him in Tennessee, USA, on an immigration violations matter, and few days later, Zündel was sent back to Canada, where he tried to gain refugee status. Zündel remained in prison until March 1, 2005, when he was deported to Germany and prosecuted for disseminating hate propaganda. On February 15, 2007, Zündel was convicted on 14 counts of incitement under Germany's "Volksverhetzung" law, which bans the incitement of hatred against a portion of the population, and given the maximum sentence of five years in prison.
Ernst Nolte.
The German philosopher and historian Ernst Nolte, starting in the 1980s, advanced a set of theories, which though not denying the Holocaust appeared to flirt with Holocaust denial as a serious historical argument. In a letter to the Israeli historian Otto Dov Kulka of December 8, 1986 Nolte criticized the work of the French Holocaust denier Robert Faurisson on the ground that the Holocaust did occur, but went on to argue that Faurison’s work was motivated by what Nolte claimed were the admirable motives of sympathy towards the Palestinians and opposition to Israel. In his 1987 book "Der europäische Bürgerkrieg" ("The European Civil War"), Nolte claimed that the intentions of Holocaust deniers are "often honourable", and that some of their claims are "not obviously without foundation". Nolte himself, though he has never denied the occurrence of the Holocaust, has claimed that the Wannsee Conference of 1942 never happened, and that the minutes of the conference were post-war forgeries done by "biased" Jewish historians designed to discredit Germany
The British historian Ian Kershaw has argued that Nolte was operating on the borderlines of Holocaust denial with his implied claim that the "negative myth" of the Third Reich was created by Jewish historians, his allegations of the domination of Holocaust scholarship by “biased” Jewish historians, and his statements that one should withhold judgment on Holocaust deniers, whom Nolte takes considerable pains to stress are not exclusively Germans or fascists. In Kershaw's opinion, Nolte is attempting to imply that perhaps Holocaust deniers are on to something. In a 1990 interview, Nolte implied that there was something to the Leuchter report: "If the revisionists deniers and Leuchter among them have made it clear to the public that even "Auschwitz" must be an object of scientific inquiry and controversy then they should be given credit for this. Even if it finally turned out that the number of victims was even greater and the procedures were even more horrific than has been assumed until now." In his 1993 book "Streitpunkte" ("Points of Contention"), Nolte praised the work of Holocaust deniers as superior to "mainstream scholars". Nolte wrote that "radical revisionists have presented research which, if one is familiar with the source material and the critique of the sources, is probably superior to that of the established historians of Germany". In a 1994 interview with "Der Spiegel" magazine, Nolte stated "I cannot rule out the importance of the investigation of the gas chambers in which they looked for remnants of the process engendered by Zyklon B", and that “'Of course, I am against revisionists, but Fred Leuchter's "study" of the Nazi gas ovens has to be given attention, because one has to stay open to "other" ideas.”
The British historian Richard J. Evans in his 1989 book "In Hitler's Shadow" expressed the view that Nolte’s reputation as a scholar was in ruins as a result of these and other controversial statements on his part. The American historian Deborah Lipstadt in a 2003 interview stated: 
The Mayer Controversy.
In 1988, the American historian Arno J. Mayer published a book entitled "Why Did the Heavens Not Darken?", which did not deny the Holocaust, but appeared to lend support to Holocaust denial by stating that the majority of people who died at Auschwitz were the victims of diseases rather than gassing. In addition, critics of Mayer such as Lucy Dawidowicz assailed him for listing the works of Arthur Butz and Paul Rassinier in his bibliography, and charged his statements about Auschwitz were factually incorrect. Holocaust expert Robert Jan van Pelt has noted that Mayer's book is as close as a mainstream historian has ever come to supporting Holocaust denial. Holocaust deniers such as David Irving have often cited Mayer’s book as one reason for embracing Holocaust denial. Though Mayer has been often condemned for his statement about the reasons for the Auschwitz death toll, his book does not deny the Holocaust as Holocaust deniers often claim.
Holocaust deniers have often quoted out of context Mayer’s sentence in "Why Did the Heavens Not Darken?" that “Sources for the study of the gas chambers at once rare and unreliable” as the authors Michael Shermer and Alex Grobman have noted that the paragraph from which the sentence is taken states that the SS destroyed the majority of the documention relating to the operation of the gas chambers in the death camps, which is why Mayer feels that sources for the operation of the gas chambers are "rare" and "unreliable"
The Israeli historian Yehuda Bauer wrote that Mayer "popularizes the nonsense that the Nazis saw in Marxism and Bolshevism their main enemy, and the Jews unfortunately got caught up in this; when he links the destruction of the Jews to the ups and downs of German warfare in the Soviet Union, in a book that is so cocksure of itself that it does not need a proper scientific apparatus, he is really engaging in a much more subtle form of Holocaust denial".
Ken McVay and "alt.revisionism".
Ken McVay, an American resident in Canada, was disturbed by the efforts of organizations like the Simon Wiesenthal Center to suppress the speech of the Holocaust deniers, feeling that it was better to confront them openly than to try to censor them. On the Usenet newsgroup "alt.revisionism" he began a campaign of "truth, fact, and evidence," working with other participants on the newsgroup to uncover factual information about the Holocaust and counter the arguments of the deniers by proving them to be based upon misleading evidence, false statements, and outright lies. He founded the Nizkor Project to expose the activities of the Holocaust deniers, who responded to McVay with personal attacks, slander, and death threats.
David Irving and the Lipstadt libel case.
Deborah Lipstadt's 1993 book "Denying the Holocaust" was sharply critical of questionable analytical methods used by various Holocaust deniers, in particular British author David Irving, whom she accused of deliberately misrepresenting evidence to justify his preconceived conclusions. In 1996 Irving filed a libel suit against Lipstadt and her publisher, Penguin Books. American historian Christopher Browning, an expert witness for the defense, wrote a comprehensive essay for the court summarizing the voluminous evidence for the reality of the Holocaust, and under cross-examination, effectively countered all of Irving's principal arguments to the contrary. Cambridge historian Richard J. Evans, another defense expert witness, spent two years examining Irving's writings, and confirmed his misrepresentations, including evidence that he had knowingly used forged documents as source material. The judge, Justice Charles Gray, ultimately delivered a long and decisive verdict in favor of Lipstadt that referred to Irving as a "Holocaust denier" and "right-wing pro-Nazi polemicist."
In February 2006 Irving was arrested in Austria, where Holocaust denial is illegal, for a speech he had made in 1989 in which he denied the existence of gas chambers at Auschwitz. Irving was aware of the outstanding arrest warrant, but chose to go to Austria anyway "to give a lecture to a far-right student fraternity." Although he pleaded guilty to the charge, Irving said he had been "mistaken", and had changed his opinions on the Holocaust. "I said that then, based on my knowledge at the time, but by 1991 when I came across the Eichmann papers, I wasn't saying that anymore and I wouldn't say that now. The Nazis did murder millions of Jews." Irving served 13 months of a 3 year sentence in an Austrian prison, and was deported in early 2007. The episode sparked intense international debate over the limits of freedom of speech. Upon hearing of Irving's sentence, Lipstadt said, "I am not happy when censorship wins, and I don't believe in winning battles via censorship ... The way of fighting Holocaust deniers is with history and with truth."
According to "CNN", upon Irving's return to the UK, he "vow to repeat views denying the Holocaust that led to his conviction" stating he felt "no need any longer to show remorse" for his Holocaust views.
Recent developments and trends.
In Turkey, in 1996, the Islamic preacher Harun Yahya distributed thousands of copies of a book which was originally published the previous year, entitled "Soykırım Yalanı" ("The Holocaust Lie") and mailed unsolicited texts to American and European schools and colleges. The publication of "Soykırım Yalanı" sparked much public debate. This book claims that “what is presented as Holocaust is the death of some Jews due to the typhus plague during the war and the famine towards the end of the war caused by the defeat of the Germans.” In March 1996, a Turkish painter and intellectual, Bedri Baykam, published a strongly worded critique of the book in the Ankara daily newspaper "Siyah-Beyaz" ("Black and White"). A legal suit for slander was brought against him. During the trial in September, Baykam exposed the real author of the book as Adnan Oktar. The suit was withdrawn in March 1997.
In France, Holocaust denial became more prominent in the 1990s as "négationnisme," though the movement has existed in ultra-left French politics since at least the 1960s, led by figures such as Pierre Guillaume (who was involved in the bookshop La Vieille Taupe during the 1960s). Recently, elements of the extreme far right in France have begun to build on each other's negationist arguments, which often span beyond the Holocaust to cover a range of antisemitic views, incorporating attempts to tie the Holocaust to the Biblical massacre of the Canaanites, critiques of Zionism, and other material fanning what has been called a "conspiratorial Judeo-phobia" designed to legitimize and "banalize" antisemitism.
In Belgium in 2001, Roeland Raes, the ideologue and vice-president of one of the country's largest political parties, the Vlaams Belang (formerly named Vlaams Blok, Flemish Bloc), gave an interview on Dutch TV where he cast doubt over the number of Jews murdered by the Nazis during the Holocaust. In the same interview he questioned the scale of the Nazis' use of gas chambers and the authenticity of Anne Frank's diary. In response to the media assault following the interview, Raes was forced to resign his position but vowed to remain active within the party. Three years later, the Vlaams Blok was convicted of racism and chose to disband. Immediately afterwards, it legally reformed under the new name Vlaams Belang (Flemish Interest) with the same leaders and the same membership.
Accusations of a Zionist conspiracy.
A different version of this conspiracy theory claims that Nazis and Zionists had a shared interest or even cooperated in the extermination of Europe's Jewry, as persecution would force them to flee to Palestine, then under British Mandate administration. Similar claims are occasionally heard from Hezbollah.
Holocaust denial in the Arab world.
Denials of the Holocaust have been regularly promoted by various Arab leaders and others and in Arab media throughout the Middle East. According to Associated Press reports, Arab world attitudes towards the Holocaust range from total denial to a minimization of the extent of the genocide and holocaust denial is rife within Palestinian society and in the Palestinian territories. In 2009, a University of Haifa survey revealed that 40.5 percent of Israeli Arabs claim the Holocaust never happened. Prominent Arab figures from the Middle East have rarely made publicized visits to Auschwitz and individuals from the Syrian government, the Palestinian Authority, and a number of Palestinian groups have all engaged in various aspects of Holocaust denial. According to Robert Satloff writing in the Washington Post, "A respected Holocaust research institution recently reported that Egypt, Qatar and Saudi Arabia all promote Holocaust denial and protect Holocaust deniers." 
According to Bernard Lewis, the three most common positions on the historicity of the Holocaust are: "it never happened; it was greatly exaggerated; the Jews deserved it anyway. On the last point, some more enterprising writers add a rebuke to Hitler for not having finished the job." 
In August 2002, the Zayed Center for Coordination and Follow-Up, an Arab League think-tank whose Chairman, Sultan bin Zayed bin Sultan Al Nahyan, served as Deputy Prime Minister of the United Arab Emirates, promoted a Holocaust denial symposium in Abu Dhabi. The government of the United Arab Emirates closed down the Zayed Center as a result.
Hamas leaders have also promoted Holocaust denial; Abdel Aziz al-Rantissi held that the Holocaust never occurred, that Zionists were behind the action of Nazis, and that Zionists funded Nazism. A press release by Hamas in April 2000 decried "the so-called Holocaust, which is an alleged and invented story with no basis." In August 2009, Hamas refused to allow Palestinian children to learn about the Holocaust, which it called "a lie invented by the Zionists" and referred to Holocaust education as a "war crime."
Holocaust denial has also been resisted by prominent intellectual figures in the Arab world; in 2001, an outcry led by Palestinian poet Mahmoud Darwish, Lebanese writer Elias Khoury and others brought about the cancellation of a conference the Holocaust denial organization Institute for Historical Review had planned to hold in Beirut.
In 2005 the Egyptian Muslim Brotherhood leader, Mohammed Mahdi Akef, denounced what he called "the myth of the Holocaust" in defending Iranian president Mahmoud Ahmadinejad's denial of the Holocaust.
In 2007, the founder of the Islamic Movement in Israel, Sheikh Abdullah Nimr Darwish, condemned Holocaust denial in the Muslim world (especially that by Mahmoud Ahmedinejad).
Holocaust denial has been practiced in schools and youth organisations. A private English-language school in western Beirut censored excerpts of the diary of Anne Frank out of a school textbook after it caused uproar when Hezbollah learned the chapter was included in the textbook. The United Nations body UNESCO stopped funding a children's magazine sponsored by the Palestinian Authority that commended Hitler's killing of Jews. It deplored this publication as contrary to its principles of building tolerance and respect for human rights and human dignity.
In a debate which aired on "Al-Alam TV" on May 5, 2010 (as translated by MEMRI), Ali Hatar of the "Jordanian Association against Zionism and Racism" stated that "To this day, those who claim that Holocaust did take place have been unable to provide any evidence whatsoever to that effect." He claimed that a report by the Red Cross in 1949 "refutes the claim that anyone was killed in these camps, during the so-called Holocaust. It also mentions the self-management the camps by the Jews."
Iranian President Ahmadinejad.
Iranian President Mahmoud Ahmadinejad frequently denies the Holocaust, although he has on occasion confirmed his belief in it.
Holocaust denial is relatively new to the Middle East, as Kenneth Jacobson, assistant national director of the Anti-Defamation League, said in an interview with "Haaretz": "Adopting the theories of Holocaust denial of Western scholars is a relatively new phenomenon in the Muslim world. The accepted attitude had been to say that whereas it was true the Holocaust had taken place, the Palestinians should not have to pay the price. A look at Iranian President Mahmoud Ahmadinejad's statements shows that he has mixed the two approaches."
In a December 2005 speech, Ahmadinejad said that a legend was fabricated and had been promoted to protect Israel. He said,
The remarks immediately provoked international controversy as well as swift condemnation from government officials in Israel, Europe, and the United States. All six political parties in the German parliament signed a joint resolution condemning this Holocaust denial.
Hamas political leader Khaled Mashaal described Ahmadinejad's comments as "courageous" and stated that "Muslim people will defend Iran because it voices what they have in their hearts, in particular the Palestinian people." In the United States, the Muslim Public Affairs Council condemned Ahmadinejad's remarks.
On April 24, 2006, Ahmadinejad demanded a free evaluation of the real extent of the Holocaust "in order to find the ultimate truth." In a May 30, 2006 interview with "Der Spiegel", Ahmadinejad again questioned the Holocaust several times, insisting there were "two opinions" on it. When asked if the Holocaust was a myth, he responded "I will only accept something as truth if I am actually convinced of it".
On December 11, 2006, the "International Conference to Review the Global Vision of the Holocaust" opened to widespread condemnation. The conference, called for by and held at the behest of Ahmadinejad, was widely described as a "Holocaust denial conference" or a "meeting of Holocaust deniers", though Iran denied it was a Holocaust denial conference. A few months before it opened, the Iranian Foreign Ministry spokesman Hamid Reza Asefi stated: "The Holocaust is not a sacred issue that one can't touch. I have visited the Nazi camps in Eastern Europe. I think it is exaggerated."
Mir-Hossein Mousavi is the former Prime minister of Iran and an opposition leader.
During a TV-debate preceding Iran's 2009 elections, the Jerusalem Post reported that Mousavi "slam Ahmadinejad's Holocaust denial". He also said that it had cost Iran its international standing. According to Press TV, Mousavi has said that the Holocaust is not Iran's business, and that Iran should instead try to "find the most reasonable way to solve the Palestine case".
In early June 2009, Ahmadinejad described Israel as "the most criminal regime in human history" and spoke about the "great deception of the Holocaust" in a speech quoted by IRIB.
At the September 2009 Quds Day ceremonies in Tehran, Ahmadinejad stated Israel was created on "a lie and a mythical claim," that the Western powers "launched the myth of the Holocaust. They lied, they put on a show and then they support the Jews" – what the "New York Times" considered his "among his harshest statements on the topic," and one immediately condemned by the US, UK, French and German governments.
In September 2010, during a State visit to New York City, Ahmadinejad once again questioned the Holocaust, saying it “has been exaggerated as a pretext for war.” In an interview with the editor of the magazine "Atlantic Monthly" on September 28, he said, “The question is, why don't we allow this subject to be examined further ... It is incorrect to force only one view on the rest of the world.” He added: “How come when it comes to the subject of the Holocaust there is so much sensitivity?”
Ahmadinejad made similar statements later that day during what was described by Agence France-Presse as a “chaotic speech” at the United Nations summit on the Millennium Development Goals. He further charged that the U.S. government "orchestrated" the World Trade Center attacks in order to reverse declines in the U.S. economy and "save the Zionist regime." He broke off at one point during the speech to complain that his words were not being accurately translated. (Organizers said they were translating from a prepared text submitted by the Iranian delegation.)
Ahmadinejad was praised by Syrian Author Muhammad Nimr Al-Madani (author of ""Were the Jews Burned in the Ovens?", Beirut: Al-Manara, 2001), who has previously claimed that "Hitler Was Falsely Accused of Committing Genocide against the Jews". In an interview on "Al-Alam TV" (Iran), Al-Madani stated that "I was very happy when the Iranian president denied the Holocaust. Since I am convinced of the need to fight this lie, I was filled with admiration at the words of the Iranian president" and that "those who claim that the Holocaust took place do not have any proof." He also praised Ahmadinejad as "the first leader in the world to adopt Holocaust denial. This is a great event."
Propaganda in the media.
According to James Najarian, Holocaust deniers working for the Institute for Historical review are not trained in history and "put out sham scholarly articles in the mock-academic publication, the "Journal of Historical Review"". They appeal to “our objectivity, our sense of fair play, and our distrust of figurative language”. Thus, they rely on facts to grab the readers’ attention. These facts, however, are strung by what Narjarian calls “fabricated decorum” and are re-interpreted for their use. For example, they pay particular attention to inconsistencies in numbers.
Holocaust denial propaganda in all forms has shown to influence the audiences that it reaches. In fact, even the well-educated—that is, college graduates and current university students alike—are susceptible to such propaganda when it is presented before them. This stems from the growing disbelief that audiences feel after being exposed to such information, especially since Holocaust witnesses themselves are decreasing in number. Studies centered on the psychological effects of Holocaust denial propaganda confirm this assertion. Linda M. Yelland and William F. Stone, in particular, show that Denial essays decrease readers’ belief in the Holocaust, regardless of their prior Holocaust awareness.
Reactions to Holocaust denial.
Types of reaction.
Scholarly response to Holocaust denial can be roughly divided into three categories: Some academics refuse to engage Holocaust deniers or their arguments at all, on grounds that doing so lends them unwarranted legitimacy. A second group of scholars, typified by the American historian Deborah Lipstadt, have tried to raise awareness of the methods and motivations of Holocaust denial without legitimizing the deniers themselves. "We need not waste time or effort answering the deniers' contentions," Lipstadt wrote. "It would be never-ending ... Their commitment is to an ideology and their 'findings' are shaped to support it." A third group, typified by the Nizkor Project, responds to arguments and claims made by Holocaust denial groups by pointing out inaccuracies and errors in their evidence.
Even scholarly responses, however, can trigger vigorous rebuttals. In 1996, the British historian David Irving brought a civil defamation suit against Lipstadt and her publisher, stemming from Lipstadt's book "Denying the Holocaust", in which she named Irving as "one of the more dangerous" Holocaust deniers, because he was a published author, and was viewed by some as a legitimate military historian. He was "familiar with historical evidence," she wrote, and "bends it until it conforms with his ideological leanings and political agenda." Irving, who appeared as a defense witness in Ernst Zündel's trial in Canada, and once declared at a rally of Holocaust deniers that "more women died in the back seat of Edward Kennedy's car than ever died in a gas chamber at Auschwitz", claimed that Lipstadt's allegation damaged his reputation. After a two-month trial in London, the trial judge issued a 333-page ruling against Irving.
Public figures and scholars.
A number of public figures and scholars have spoken out against Holocaust denial. The American Historical Association, the oldest and largest society of historians and teachers of history in the United States, states that Holocaust denial is "at best, a form of academic fraud." Dr. William Shulman, director of the Holocaust Research Center, described the denial "as if these people the Holocaust were killed twice", a sentiment echoed by literary theorist Jean Baudrillard, who argued that "Forgetting the extermination is part of the extermination itself." In 2006, UN Secretary General Kofi Annan said: "Remembering is a necessary rebuke to those who say the Holocaust never happened or has been exaggerated. Holocaust denial is the work of bigots; we must reject their false claims whenever, wherever and by whomever they are made." Holocaust survivor and Nobel Prize winner Elie Wiesel calls the Holocaust "the most documented tragedy in recorded history. Never before has a tragedy elicited so much witness from the killers, from the victims and even from the bystanders—millions of pieces here in the museum what you have, all other museums, archives in the thousands, in the millions." He made a similar statement on a special edition of "The Oprah Winfrey Show" after his final trip to Auschwitz, along with host Winfrey.
In January 2007, the United Nations General Assembly condemned "without reservation any denial of the Holocaust", though Iran disassociated itself from the resolution.
Holocaust denial and antisemitism.
Holocaust denial is generally viewed as antisemitic. The "Encyclopedia of Genocide and Crimes Against Humanity", for example, defines Holocaust denial as "a new form of anti-Semitism, but one that hinges on age-old motifs". The Anti-Defamation League has stated that "Holocaust denial is a contemporary form of the classic anti-Semitic doctrine of the evil, manipulative and threatening world Jewish conspiracy" and French historian Valérie Igounet has written that "Holocaust denial is a convenient polemical substitute for anti-semitism." In 2005, the European Monitoring Centre on Racism and Xenophobia (now the Fundamental Rights Agency) published a "working definition" of antisemitism which gave as an example of the way that antisemitism might manifest itself, "denying the fact, scope, mechanisms (e.g. gas chambers) or intentionality of the genocide of the Jewish people at the hands of National Socialist Germany and its supporters and accomplices during World War II (the Holocaust)".
In a defense of Holocaust denier Bishop Richard Williamson against the charge of being antisemitic, the journalist and writer Kevin Myers argued "It is not anti-Semitic to make a fool of yourself in public about a historical fact. It is anti-Semitic to preach or promote a dislike of Jews because they are Jews, which is what Bishop Williamson has not done."
Laws against Holocaust denial.
Holocaust denial is explicitly or implicitly illegal in 17 countries: Austria, Belgium, Canada, Czech Republic, France, Germany, Hungary, Israel, Liechtenstein, Lithuania, Luxembourg, Netherlands, Poland, Portugal, Romania, Slovakia, and Switzerland. The European Union's Framework decision on Racism and Xenophobia states that denying or grossly trivializing "crimes of genocide" should be made "punishable in all EU Member States". Slovakia criminalized denial of fascist crimes in general in late 2001; in May 2005, the term "Holocaust" was explicitly adopted by the penal code and in 2009, it became illegal to deny any act regarded by an international criminal court as genocide. The Parliament of Hungary adopted the most recent legislation, which declared denial or trivialization of the Holocaust a crime punishable by up to three years imprisonment, in February 2010.
Such legislation remains controversial. In October 2007, a tribunal declared Spain's Holocaust denial law unconstitutional. In 2007 Italy rejected a denial law proposing a prison sentence of up to four years. In 2006 the Netherlands rejected a draft law proposing a maximum sentence of one year on denial of genocidal acts in general, although specifically denying the Holocaust remains a criminal offense there. The United Kingdom has twice rejected Holocaust denial laws. Denmark and Sweden have also rejected such legislation.
A number of deniers have been prosecuted under various countries' denial laws. French literature professor Robert Faurisson, for example, was convicted and punished under the Gayssot Act in 1990. Some historians oppose such laws, among them Vidal-Naquet, an outspoken critic of Faurisson, on the grounds that denial legislation imposes "historical truth as legal truth." Other academics favor criminalization. Holocaust denial, they contend, is "the worst form of racism and its most respectable version because it pretends to be a research." In the Belgian Senate the Minister of Justice Laurette Onkelinx compared laws criminalizing Holocaust denial with those condemning incitement to ethnic or racial hatred in the United Kingdom and the Netherlands.
Focus on Allied war crimes in Holocaust denial literature.
The focus on supposed Allied atrocities during the war has also been a theme in Holocaust denial literature, particularly in countries where outright denial of the Holocaust is illegal. According to historian Deborah Lipstadt, the concept of "comparable Allied wrongs" such as the post-war expulsions and alleged Allied war crimes like the bombing of Dresden, is at the center of, and a continuously repeated theme of, contemporary Holocaust denial; phenomenon she calls "immoral equivalencies". Pierre Vidal-Naquet pointed out the same phenomenon in the earlier version of "Les Assassins de la mémoire" under the title "Auschwitz et le tiers monde" ("Les Assassins de la mémoire", Paris, 2005, pp. 170–180), and accurately about the declarations of Klaus Barbie's lawyer Jacques Vergès. In 1977, Martin Broszat in a review of David Irving's book "Hitler's War" maintained that the picture of World War II drawn by Irving was done in a such way to imply moral equivalence between the actions of the Axis and Allied states with both sides equally guilty of terrible crimes, leading to Hitler's "fanatical, destructive will to annihilate" being downgraded to being "no longer an exceptional phenomenon".
Other genocide denials.
Other acts of genocide have met similar attempts to deny and minimize. Gregory H. Stanton, formerly of the US State Department and the founder of Genocide Watch, lists denial as the final stage of a genocide development: "Denial is the eighth stage that always follows a genocide. It is among the surest indicators of further genocidal massacres. The perpetrators of genocide dig up the mass graves, burn the bodies, try to cover up the evidence and intimidate the witnesses. They deny that they committed any crimes, and often blame what happened on the victims."

Ireland
Ireland (, ; ; Ulster-Scots: "Airlann" or "Airlan") is an island to the north-west of continental Europe. It is the third-largest island in Europe and the twentieth-largest island on Earth. To its east is the larger island of Great Britain, from which it is separated by the Irish Sea.
Politically, Ireland is divided between the Republic of Ireland, which covers just under five-sixths of the island, and Northern Ireland, a part of the United Kingdom, which covers the remainder and is located in the north-east of the island. The population of Ireland is approximately 6.4 million. Just under 4.6 million live in the Republic of Ireland and just under 1.8 million live in Northern Ireland.
Relatively low-lying mountains surrounding a central plain epitomise Ireland's geography with several navigable rivers extending inland. The island has lush vegetation, a product of its mild but changeable oceanic climate, which avoids extremes in temperature. Thick woodlands covered the island until the 17th century. Today, it is one of the most deforested areas in Europe. There are twenty-six extant mammal species native to Ireland.
A Norman invasion in the Middle Ages gave way to a Gaelic resurgence in the 13th century. Over sixty years of intermittent warfare in the 1500s led to English dominance after 1603. In the 1690s, a system of Protestant English rule was designed to materially disadvantage the Catholic majority and Protestant dissenters, and was extended during the 18th century. In 1801, Ireland became a part of the United Kingdom. A war of independence in the early 20th century led to the partition of the island, creating the Irish Free State, which became increasingly sovereign over the following decades. Northern Ireland remained a part of the United Kingdom and saw much civil unrest from the late 1960s until the 1990s. This subsided following a political agreement in 1998. In 1973, both parts of Ireland joined the European Economic Community.
Irish culture has had a significant influence on other cultures, particularly in the fields of literature and, to a lesser degree, science and education. A strong indigenous culture exists, as expressed for example through Gaelic games, Irish music and the Irish language, alongside mainstream Western culture, such as contemporary music and drama, and a culture with much in common with Great Britain, as expressed through sports such as soccer, rugby, horse racing, and golf, as well as the English language.
History.
Pre-history.
Most of Ireland was covered with ice until the end of the last ice age over 9,000 years ago. Sea levels were lower and Ireland, like Great Britain, was part of continental Europe. Mesolithic stone age inhabitants arrived some time after 8,000 BC and agriculture followed with the Neolithic Age around 4,500 to 4,000 BC when sheep, goats, cattle and cereals were imported from the Iberian peninsula.
At the Céide Fields, preserved beneath a blanket of peat in present-day County Mayo, is an extensive field system, arguably the oldest in the world, dating from not long after this period. Consisting of small divisions separated by dry-stone walls, the fields were farmed for several centuries between 3,500 and 3,000 BC. Wheat and barley were the principal crops.
The Bronze Age – defined by the use of metal – began around 2,500 BC, with technology changing people's everyday lives during this period through innovations such as the wheel, harnessing oxen, weaving textiles, brewing alcohol, and skillful metalworking, which produced new weapons and tools, along with fine gold decoration and jewellery, such as brooches and torcs. According to John T. Koch and others, Ireland in the Late Bronze Age was part of a maritime trading-networked culture called the Atlantic Bronze Age that also included Britain, France, Spain and Portugal where Celtic languages developed.
The Iron Age in Ireland is traditionally associated with people known as the "Celts". The Celts were commonly thought to have colonised Ireland in a series of invasions between the 8th and 1st centuries BC. The Gaels, the last wave of Celts, were said to have divided the island into five or more kingdoms after conquering it. However, some academics favour a theory that emphasises the diffusion of culture from overseas as opposed to a military colonisation. Finds such as Clonycavan Man are given as evidence for this theory.
Late antiquity and early medieval times.
The earliest written records of Ireland come from classical Greco-Roman geographers. Ptolemy in his "Almagest" refers to Ireland as "Mikra Brettania" ("Lesser Britain"), in contrast to the larger island, which he called "Megale Brettania" ("Great Britain"). In his later work, "Geography", Ptolemy refers to Ireland as "Iouernia" and to Great Britain as "Albion". These "new" names were likely to have been the Celtic names for the islands at the time. The earlier names, in contrast, were likely to have been coined before direct contact with local peoples was made.
The Romans would later refer to Ireland by this name too in its Latinised form, "Hibernia", or Scotia. Ptolemy records sixteen tribes inhabiting every part of Ireland in 100 AD. The relationship between the Roman Empire and the tribes of ancient Ireland is unclear. However, a number of finds of Roman coins have been found, for example at New Grange.
Ireland continued as a patchwork of rival tribes but, beginning in the 7th century AD, a concept of national kingship gradually became articulated through the concept of a High King of Ireland. Medieval Irish literature portrays an almost unbroken sequence of High Kings stretching back thousands of years but modern historians believe the scheme was constructed in the 8th century to justify the status of powerful political groupings by projecting the origins of their rule into the remote past.
The High King was said to preside over the patchwork of provincial kingdoms that together formed Ireland. All of these kingdoms had their own kings but were at least nominally subject to the High King. The High King was drawn from the ranks of the provincial kings and ruled also the royal kingdom of Meath, with a ceremonial capital at the Hill of Tara. The concept only became a political reality in the Viking Age and even then was not a consistent one. However, Ireland did have a unifying rule of law: the early written judicial system, the Brehon Laws, administered by a professional class of jurists known as the "brehons".
"The Chronicle of Ireland" records that in 431 AD Bishop Palladius arrived in Ireland on a mission from Pope Celestine I to minister to the Irish "already believing in Christ." The same chronicle records that Saint Patrick, Ireland's best known patron saint, arrived the following year. There is continued debate over the missions of Palladius and Patrick but the consensus is that they both took place and that the older druid tradition collapsed in the face of the new religion. Irish Christian scholars excelled in the study of Latin and Greek learning and Christian theology. In the monastic culture that followed the Christianisation of Ireland, Latin and Greek learning was preserved in Ireland during the Early Middle Ages in contrast to elsewhere in Europe, where the Dark Ages followed the decline of the Roman Empire.
The arts of manuscript illumination, metalworking and sculpture flourished and produced treasures such as the "Book of Kells", ornate jewellery and the many carved stone crosses that still dot the island today. A mission founded in 563 on Iona by the Irish monk Saint Columba began a tradition of Irish missionary work that spread Christianity and learning to Scotland, England and the Frankish Empire on Continental Europe after the fall of Rome. These missions continued until the late Middle Ages, establishing monasteries and centres of learning, producing scholars such as Sedulius Scottus and Johannes Eriugena and exerting much influence in Europe.
From the 9th century, waves of Viking raiders plundered Irish monasteries and towns. These raids added to a pattern of raiding and endemic warfare that was already deep-seated in Ireland. The Vikings also were involved in establishing most of the major coastal settlements in Ireland: Dublin, Limerick, Cork, Wexford, Waterford, and also Carlingford, Strangford, Annagassan, Arklow, Youghal, Lough Foyle and Lough Ree.
Norman and English invasions.
On May 1, 1169, an expedition of Cambro-Norman knights with an army of about six hundred landed at Bannow Strand in present-day County Wexford. It was led by Richard de Clare, called "Strongbow" due to his prowess as an archer. The invasion, which coincided with a period of renewed Norman expansion, was at the invitation of Dermot Mac Murrough, the king of Leinster.
In 1166, Mac Murrough had fled to Anjou, France following a war involving Tighearnán Ua Ruairc, of Breifne, and sought the assistance of the Angevin king, Henry II, in recapturing his kingdom. In 1171, Henry arrived in Ireland in order to review the general progress of the expedition. He wanted to re-exert royal authority over the invasion which was expanding beyond his control. Henry successfully re-imposed his authority over Strongbow and the Cambro-Norman warlords and persuaded many of the Irish kings to accept him as their overlord, an arrangement confirmed in the 1175 Treaty of Windsor.
The invasion was legitimised by the provisions of the Papal Bull "Laudabiliter", issued by Adrian IV in 1155. The bull encouraged Henry to take control in Ireland in order to oversee the financial and administrative reorganisation of the Irish Church and its integration into the Roman Church system. Some restructuring had already begun at the ecclesiastical level following the Synod of Kells in 1152. There has been significant controversy regarding authenticity of "Laudabiliter", and there is no general agreement as to whether the bull was genuine or a forgery.
In 1172, the new pope, Alexander III, further encouraged Henry to advance the integration of the Irish Church with Rome. Henry was authorised to impose a tithe of one penny per hearth as an annual contribution. This church levy, called Peter's Pence, is still extant in Ireland as a voluntary donation. In turn, Henry accepted the title of Lord of Ireland which Henry conferred on his younger son, John Lackland, in 1185. This defined the Irish state as the Lordship of Ireland. When Henry's successor died unexpectedly in 1199, John inherited the crown of England and retained the Lordship of Ireland.
Over the century that followed, Norman feudal law gradually replaced the Gaelic Brehon Law so that by the late 13th century the Norman-Irish had established a feudal system throughout much of Ireland. Norman settlements were characterised by the establishment of baronies, manors, towns and the seeds of the modern county system. A version of the Magna Carta (the Great Charter of Ireland), substituting "Dublin" for "London" and "Irish Church" for "Church of England", was published in 1216 and the Parliament of Ireland was founded in 1297.
However, from the mid-14th century, after the Black Death, Norman settlements in Ireland went into a period of decline. The Norman rulers and the Gaelic Irish elites intermarried and the areas under Norman rule became Gaelicised. In some parts, a hybrid Hiberno-Norman culture emerged. In response, the Irish parliament passed the Statutes of Kilkenny in 1367. These were a set of laws designed to prevent the assimilation of the Normans into Irish society by requiring English subjects in Ireland to speak English, follow English customs and abide by English law. However, by the end of the 15th century central English authority in Ireland had all but disappeared and a renewed Irish culture and language, albeit with Norman influences, was dominant again. English Crown control remained relatively unshaken in an amorphous foothold around Dublin known as The Pale and under the provisions of Poynings' Law of 1494, the Irish Parliamentary legislation was subject to the approval of the English Parliament.
Kingdom of Ireland.
The title of "King of Ireland" was re-created in 1542 by Henry VIII, then King of England, of the Tudor dynasty. English rule of law was reinforced and expanded in Ireland during the latter part of the 16th century leading to the Tudor conquest of Ireland. A near complete conquest was achieved by the turn of the 17th century, following the Nine Years' War and the Flight of the Earls. This control was further consolidated during the wars and conflicts of the 17th century, which witnessed English and Scottish colonisation in the Plantations of Ireland, the Wars of the Three Kingdoms and the Williamite War. Irish losses during the Wars of the three Kingdoms (which, in Ireland, included the Irish Confederacy and the Cromwellian conquest of Ireland) are estimated to include 20,000 battlefield casualties. 200,000 civilians are estimated to have died as a result of a combination of war-related famine, displacement, guerilla activity and pestilence over the duration of the war. A further 50,000 were sent to slavery in the West Indies. Some historians estimate that as much as half of the pre-war population of Ireland may have died as a result of the conflict.
The religious struggles of the 17th century left a deep sectarian division in Ireland. Religious allegiance now determined the perception in law of loyalty to the Irish King and Parliament. After the passing of the Test Act 1672, and with the victory of the forces of the dual monarchy of William and Mary over the Jacobites, Roman Catholics and nonconforming Protestant Dissenters were barred from sitting as members in the Irish Parliament. Under the emerging penal laws Irish Roman Catholics and Dissenters were increasingly deprived of various and sundry civil rights even to the ownership of hereditary property. Additional regressive punitive legislation followed 1703, 1709 and 1728. This completed a comprehensive systemic effort to materially disadvantage Roman Catholics and Protestant Dissenters, while enriching a new ruling class of Anglican conformists. The new Anglo-Irish ruling class became known as the Protestant Ascendancy.
An extraordinary climatic shock known as the "Great Frost" struck Ireland and the rest of Europe between December 1739 and September 1741, after a decade of relatively mild winters. The winters destroyed stored crops of potatoes and other staples and the poor summers severely damaged harvests. This resulted in the famine of 1740. An estimated 250,000 people (about one in eight of the population) died from the ensuing pestilence and disease. The Irish government halted export of corn and kept the army in quarters but did little more. Local gentry and charitable organisations provided relief but could do little to prevent the ensuing mortality.
In the aftermath of the famine, an increase in industrial production and a surge in trade brought a succession of construction booms. The population soared in the latter part of this century and the architectural legacy of Georgian Ireland was built. In 1782, Poynings' Law was repealed, giving Ireland legislative independence from Great Britain for the first time since 1495. The British government, however, still retained the right to nominate the government of Ireland without the consent of the Irish parliament.
In 1798, members of the Protestant Dissenter tradition (mainly Presbyterian) made common cause with Roman Catholics in a republican rebellion inspired and led by the Society of United Irishmen, with the aim of creating an independent Ireland. Despite assistance from France the rebellion was put down by British and Irish government and yeomanry forces. In 1800, the British and Irish parliaments both passed Acts of Union that, with effect from 1 January 1801, merged the Kingdom of Ireland and the Kingdom of Great Britain to create a United Kingdom of Great Britain and Ireland.
Union with Great Britain.
The passage of the Act in the Irish Parliament was ultimately achieved with substantial majorities, having failed on the first attempt in 1799. According to contemporary documents and historical analysis, this was achieved through a considerable degree of bribery, with funding provided by the British Secret Service Office, and the awarding of peerages, places and honours to secure votes. Thus, Ireland became part of an extended United Kingdom, ruled directly by a united parliament at Westminster in London.
Aside from the development of the linen industry, Ireland was largely passed over by the industrial revolution, partly because it lacked coal and iron resources and partly because of the impact of the sudden union with the structurally superior economy of England, which saw Ireland as a source of agricultural produce and capital.
The Great Famine of the 1840s caused the deaths of one million Irish people and over a million more emigrated to escape it. By the end of the decade, half of all immigration to the United States was from Ireland. Mass emigration became deeply entrenched and the population continued to decline until the mid-20th century. Immediately prior to the famine the population was recorded as 8.2 million by the 1841 census. The population has never returned to this level since. The population continued to fall until 1961 and it was not until the 2006 census that the last county of Ireland (County Leitrim) to record a rise in population since 1841 did so.
The 19th and early 20th centuries saw the rise of modern Irish nationalism, primarily among the Roman Catholic population. The pre-eminent Irish political figure after the Union was Daniel O'Connell. He was elected as Member of Parliament for Ennis in a surprise result and despite being unable to take his seat as a Roman Catholic. O'Connell spearheaded a vigorous campaign that was taken up by the Prime Minister, the Irish-born soldier and statesman, the Duke of Wellington. Steering the Catholic Relief Bill through Parliament, aided by future prime minister Robert Peel, Wellington prevailed upon a reluctant George IV to sign the Bill and proclaim it into law. George's father had opposed the plan of the earlier Prime Minister, Pitt the Younger, to introduce such a bill following the Union of 1801, fearing Catholic Emancipation to be in conflict with the Act of Settlement 1701.
A subsequent campaign, led by O'Connell, for the repeal of the Act of Union failed. Later in the century, Charles Stewart Parnell and others campaigned for autonomy within the Union, or "Home Rule". Unionists, especially those located in Ulster, were strongly opposed to Home Rule, which they thought would be dominated by Catholic interests. After several attempts to pass a Home Rule bill through parliament, it looked certain that one would finally pass in 1914. To prevent this from happening, the Ulster Volunteers were formed in 1913 under the leadership of Edward Carson.
Their formation was followed in 1914 by the establishment of the Irish Volunteers, whose aim was to ensure that the Home Rule Bill was passed. The Act was passed but with the "temporary" exclusion of the six counties of Ulster that would become Northern Ireland. Before it could be implemented, however, the Act was suspended for the duration of the First World War. The Irish Volunteers split into two groups. The majority, approximately 175,000 in number, under John Redmond, took the name National Volunteers and supported Irish involvement in the war. A minority, approximately 13,000, retained the Irish Volunteers' name, and opposed Ireland's involvement in the war.
The failed Easter Rising of 1916 was carried out by the latter group in alliance with a smaller socialist militia, the Irish Citizen Army. The British response, executing fifteen leaders of the Rising over a period of ten days and imprisoning or interning more than a thousand people, turned the mood of the country in favour of the rebels. Support for Irish republicanism increased further due to the ongoing war in Europe, as well as the Conscription Crisis of 1918. The pro-independence republican party, Sinn Féin, received overwhelming endorsement in the general election of 1918, and in 1919 proclaimed an Irish Republic, setting up its own parliament (Dáil Éireann) and government. Simultaneously the Volunteers, which became known as the Irish Republican Army (IRA), launched a three-year guerilla war, which ended in a truce in July 1921 (although violence continued until June 1922, mostly in Northern Ireland).
In December 1921, the Anglo-Irish Treaty was concluded between the British Government and representatives of the Second Dáil. It gave Ireland complete independence in its home affairs and practical independence for foreign policy, but an opt-out clause allowed Northern Ireland to remain within the United Kingdom, which it immediately exercised as expected. Additionally, an oath of allegiance to the King was to be taken. Disagreements over these provisions led to a split in the nationalist movement and a subsequent civil war between the new government of the Irish Free State and those opposed to the treaty, led by Éamon de Valera. The civil war officially ended in May 1923 when de Valera issued a cease-fire order.
Partition.
Independent Ireland.
During its first decade the newly formed Irish Free State was governed by the victors of the civil war. When de Valera achieved power, he took advantage of the Statute of Westminster and political circumstances to build upon inroads to greater sovereignty made by the previous government. The oath was abolished and in 1937 a new constitution was adopted. This completed a process of gradual separation from the British Empire that governments had pursued since independence. However, it was not until 1949 that the state was declared, officially, to be the Republic of Ireland.
The state was neutral during World War II, but offered clandestine assistance to the Allies, particularly in the potential defence of Northern Ireland. Despite being neutral, approximately 50,000 volunteers from independent Ireland joined the British forces during the war, four being awarded Victoria Crosses.
German Intelligence was also active in Ireland, with both the "Abwehr" ([ˈapveːɐ̯], German for Defence; the German military intelligence service) and the SD (the "Sicherheitsdienst", English: Security Service, the intelligence service of the SS) sending agents there. German intelligence operations effectively ended in September 1941 when police made arrests on the basis of surveillance carried out on the key diplomatic legations in Ireland, including that of the United States. To the authorities counterintelligence was a fundamental line of defence. With a regular army of only slightly over seven thousand men at the start of the war, and with limited supplies of modern weapons, the state would have had great difficulty in defending itself from invasion from either side of the conflict.
Large-scale emigration marked the 1950s and 1980s, but beginning in 1987 the economy improved, and the 1990s saw the beginning of substantial economic growth. This period of growth became known as the "Celtic Tiger". The Republic's real GDP grew by an average of 9.6% per annum between 1995 and 1999, in which year the Republic joined the euro. In 2000 Ireland was the sixth-richest country in the world in terms of GDP per capita. Social changes followed quickly on the heels of economic prosperity, ranging from the 'modernisation' of the annual parade in Dublin to mark the principal national holiday of Saint Patrick's Day (17 March), to the decline in authority of the Catholic Church. The financial crisis of 2008–2010 dramatically ended this period of boom. GDP fell by 3% in 2008 and by 7.1% in 2009, the worst year since records began (although earnings by foreign-owned businesses continued to grow). The state has since experienced deep recession, with unemployment, which doubled during 2009, remaining above 14% in 2012.
Northern Ireland.
Northern Ireland was created as a division of the United Kingdom by the Government of Ireland Act 1920 and until 1972 it was a self-governing jurisdiction within the United Kingdom with its own parliament and prime minister. Northern Ireland, as part of the United Kingdom, was not neutral during the Second World War and Belfast suffered four bombing raids in 1941. Conscription was not extended to Northern Ireland and roughly an equal number volunteered from Northern Ireland as volunteered from the south. One, James Joseph Magennis, received the Victoria Cross for valour.
Although Northern Ireland was largely spared the strife of the civil war, in decades that followed partition there were sporadic episodes of inter-communal violence. Nationalists, mainly Roman Catholic, wanted to unite Ireland as an independent republic, whereas unionists, mainly Protestant, wanted Northern Ireland to remain in the United Kingdom. The Protestant and Catholic communities in Northern Ireland voted largely along sectarian lines, meaning that the Government of Northern Ireland (elected by "first-past-the-post" from 1929) was controlled by the Ulster Unionist Party. Over time, the minority Catholic community felt increasingly alienated with further disaffection fueled by practices such as gerrymandering and discrimination in housing and employment.
In the late 1960s, nationalist grievances were aired publicly in mass civil rights protests, which were often confronted by loyalist counter-protests. The government's reaction to confrontations was seen to be one-sided and heavy-handed in favour of unionists. Law and order broke down as unrest and inter-communal violence increased. The Northern Ireland government requested the British Army to aid the police, who were exhausted after several nights of serious rioting. In 1969, the paramilitary Provisional IRA, which favoured the creation of a united Ireland, emerged from a split in the Irish Republican Army and began a campaign against what it called the "British occupation of the six counties".
Other groups, on both the unionist side and the nationalist side, participated in violence and a period known as the Troubles began. Over 3,600 deaths resulted over the subsequent three decades of conflict. Owing to the civil unrest during the Troubles, the British government suspended home rule in 1972 and imposed direct rule. There were several unsuccessful attempts to end the Troubles politically, such as the Sunningdale Agreement of 1973. In 1998, following a ceasefire by the Provisional IRA and multi-party talks, the Good Friday Agreement was concluded as a treaty between the British and Irish governments, annexing the text agreed in the multi-party talks. The substance of the Agreement (formally referred to as the Belfast Agreement) was later endorsed by referendums in both parts of Ireland. The Agreement restored self-government to Northern Ireland on the basis of power-sharing in a regional Executive drawn from the major parties in a new Northern Ireland Assembly, with entrenched protections for the two main communities. The Executive is jointly headed by a First Minister and deputy First Minister drawn from the unionist and nationalist parties. Violence had decreased greatly after the Provisional IRA and loyalist ceasefires in 1994 and in 2005 the Provisional IRA announced the end of its armed campaign and an independent commission supervised its disarmament and that of other nationalist and unionist paramilitary organisations. The Assembly and power-sharing Executive were suspended several times but were restored again in 2007. In that year the British government officially ended its military support of the police in Northern Ireland (Operation Banner) and began withdrawing troops.
On Wednesday, 27 June 2012, Northern Ireland's deputy first minister and former IRA commander, Martin McGuinness, shook hands with Queen Elizabeth II in Belfast, a handshake symbolizing reconciliation between the two nations.
All-island institutions.
The North/South Ministerial Council, established under the 1998 Good Friday Agreement, is an institution through which ministers from the Government of Ireland and the Northern Ireland Executive agree all-island policies. At least six of these policy areas must have an associated all-island "implementation bodies" and at least six others must be implemented separately in each jurisdiction. For example, food safety is managed on an all-island basis by the Food Safety Promotion Board and Waterways Ireland is responsible for the maintenance and development of certain inland waterways on the island of Ireland. On the other hand, the two jurisdictions have common health and transport policies but these are implemented separately by already-existing bodies in each jurisdiction.
Further development of the role and function of the Council are possible "with the specific endorsement of the Northern Ireland Assembly and Oireachtas, subject to the extent of the competences and responsibility of the two Administrations."
The North/South Ministerial Council and the Northern Ireland Assembly are defined in the Good Friday Agreement as being "mutually inter-dependent, and that one cannot successfully function without the other." Participation in the Council is a requisite for the operation of the Northern Ireland Assembly and participation in the Northern Ireland Executive. When devolution in Northern Ireland is suspended, the powers of the Northern Ireland Executive revert to the British–Irish Intergovernmental Conference.
The British–Irish Intergovernmental Conference provides for co-operation between the Government of Ireland and the Government of the United Kingdom on all matter of mutual interest, especially Northern Ireland. In light of Ireland's particular interest in the governance of Northern Ireland, "regular and frequent" meetings co-chaired by the Irish Minister for Foreign Affairs and the UK Secretary of State for Northern Ireland, dealing with non-devolved matters to do with Northern Ireland and non-devolved all-Ireland issues, are required to take place under the establishing treaty.
There is no joint parliamentary forum for the island of Ireland, like there is between the UK and Ireland as a whole. However, under the Good Friday Agreement, the Oireachtas and Northern Ireland Assembly are asked to consider developing one. The Agreement also contains a suggestion for the creation of a consultative forum composed of members of civil society from Northern Ireland and the Republic of Ireland. Under the 2007, St. Andrew's Agreement, the Northern Ireland Executive agreed to support the establishment of a North/South Consultative Forum and to encourage parties in the Northern Ireland Assembly to support the creation of a North/South parliamentary forum.
Three major political parties, Sinn Féin, the Irish Green Party and, most recently, Fianna Fáil, and several smaller parties are organised on an all-island basis. However, only Sinn Féin and the Greens have contested elections and have held legislative seats in both jurisdictions. The two jurisdictions share transport, telecommunications, energy and water systems. With a few notable exceptions, the island is the main organisational unit for major religious, cultural and sporting organisations.
Single energy market.
Despite the two jurisdictions using two distinct currencies (the Euro and Pound Sterling), a growing amount of commercial activity is carried out on an all-island basis. This has been facilitated by the two jurisdictions' shared membership of the European Union, and there have been calls from members of the business community and policymakers for the creation of an "all-island economy" to take advantage of economies of scale and boost competitiveness. One area in which the island already operates as a single market is electricity and there are plans for the creation of an all-island gas market.
For much of their existence electricity networks in the Republic of Ireland and Northern Ireland were entirely separate. Both networks were designed and constructed independently post partition. However, as a result of changes over recent years they are now connected with three interlinks and also connected through Great Britain to mainland Europe. The situation in Northern Ireland is complicated by the issue of private companies not supplying Northern Ireland Electricity (NIE) with enough power. In the Republic of Ireland, the ESB has failed to modernise its power stations and the availability of power plants has recently averaged only 66%, one of the worst such rates in Western Europe. EirGrid is building a HVDC transmission line between Ireland and Great Britain with a capacity of 500 MW, about 10% of Ireland's peak demand.
As with electricity, the natural gas distribution network is also now all-island, with a pipeline linking Gormanston, County Meath, and Ballyclare, County Antrim. Most of Ireland's gas comes through interconnectors between Twynholm in Scotland and Ballylumford, County Antrim and Loughshinny, County Dublin. A decreasing supply is coming from the Kinsale gas field off the County Cork coast and the Corrib Gas Field off the coast of County Mayo has yet to come on-line. The County Mayo field is facing some localised opposition over a controversial decision to refine the gas onshore.
There have been recent efforts in Ireland to use renewable energy such as wind power. Large wind farms are being constructed in coastal counties such as Cork, Donegal, Mayo and Antrim. The construction of wind farms has in some cases been delayed by opposition from local communities, some of whom consider the wind turbines to be unsightly. The Republic of Ireland is also hindered by an ageing network that was not designed to handle the varying availability of power that comes from wind farms. The ESB's Turlough Hill facility is the only power-storage facility in the state.
Geography.
The island of Ireland is located in the north-west of Europe, between latitudes 51° and 56° N, and longitudes 11° and 5° W. It is separated from the neighbouring island of Great Britain by the Irish Sea and the North Channel, which has a width of at its narrowest point. To the west is the northern Atlantic Ocean and to the south is the Celtic Sea, which lies between Ireland and Brittany, in France. Ireland and Great Britain, together with nearby islands, are known collectively as the British Isles. As the term British Isles is controversial in relation to Ireland, the alternate term "Britain and Ireland" is often used as a neutral term for the islands.
A ring of coastal mountains surround low plains at the centre of the island. The highest of these is Carrauntoohil () in County Kerry, which rises to above sea level. The most arable land lies in the province of Leinster. Western areas can be mountainous and rocky with green panoramic vistas. The River Shannon, the island's longest river at long, rises in County Cavan in the north west and flows to Limerick city in the mid west.
The island's lush vegetation, a product of its mild climate and frequent rainfall, earns it the sobriquet "the Emerald Isle". Overall, Ireland has a mild but changeable oceanic climate with few extremes. The climate is typically insular and is temperate avoiding the extremes in temperature of many other areas in the world at similar latitudes. This is a result of the moderating moist winds which ordinarily prevail from the South-Western Atlantic.
Precipitation falls throughout the year but is light overall, particularly in the east. The west tends to be wetter on average and prone to Atlantic storms, especially in the late autumn and winter months. These occasionally bring destructive winds and higher total rainfall to these areas, as well as sometimes snow and hail. The regions of north County Galway and east County Mayo have the highest incidents of recorded lightning annually for the island, with lightening occurring approximately five to ten days per year in these areas. Munster, in the south, records the least snow whereas Ulster, in the north, records the most.
Inland areas are warmer in summer and colder in winter. Usually around 40 days of the year are below freezing at inland weather stations, compared to 10 days at coastal stations. Ireland is sometimes affected by heat waves, most recently in 1995, 2003 and 2006. In common with the rest of Europe, Ireland experienced unusually cold weather during the winter of 2009/10. Temperatures fell as low as −17.2 °C (1 °F) in County Mayo on December 20 and up to a metre (3 ft) of snow in mountainous areas.
The island consists of varied geological provinces. In the far west, around County Galway and County Donegal, is a medium to high grade metamorphic and igneous complex of Caledonide affinity, similar to the Scottish Highlands. Across southeast Ulster and extending southwest to Longford and south to Navan is a province of Ordovician and Silurian rocks, with similarities to the Southern Uplands province of Scotland. Further south, along the County Wexford coastline, is an area of granite intrusives into more Ordovician and Silurian rocks, like that found in Wales. In the southwest, around Bantry Bay and the mountains of Macgillicuddy's Reeks, is an area of substantially deformed, but only lightly metamorphosed, Devonian-aged rocks. This partial ring of "hard rock" geology is covered by a blanket of Carboniferous limestone over the centre of the country, giving rise to a comparatively fertile and lush landscape. The west-coast district of the Burren around Lisdoonvarna has well-developed karst features. Significant stratiform lead-zinc mineralisation is found in the limestones around Silvermines and Tynagh.
Hydrocarbon exploration is ongoing following the first major find at the Kinsale Head gas field off Cork in the mid-1970s. More recently, in 1999, economically significant finds of natural gas were made in the Corrib Gas Field off the County Mayo coast. This has increased activity off the west coast in parallel with the "West of Shetland" step-out development from the North Sea hydrocarbon province. The Helvick oil field, estimated to contain over of oil, is another recent discovery.
Places of interest.
There are three World Heritage Sites on the island: the Brú na Boinne, Skellig Michael and the Giant's Causeway. A number of other places are on the tentative list, for example the Burren, the Ceide Fields and Mount Stewart.
Some of the most visited sites in Ireland include Bunratty Castle, the Rock of Cashel, the Cliffs of Moher, Holy Cross Abbey and Blarney Castle. Historically important monastic sites include Glendalough and Clonmacnoise, which are maintained as national monuments in the Republic of Ireland.
Dublin is the most heavily touristed region and home to several of the most popular attractions such as the Guinness Storehouse and Book of Kells. The west and south west, which includes the Lakes of Killarney and the Dingle peninsula in County Kerry and Connemara and the Aran Islands in County Galway, are also popular tourist destinations. Achill Island lies off the coast of County Mayo and is Ireland's largest island. It is a popular tourist destination for surfing and contains 5 Blue Flag beaches and Croaghaun one of the worlds highest sea cliffs. Stately homes, built during the 17th, 18th and 19th centuries in Palladian, Neoclassical and neo-Gothic styles, such as, Castle Ward, Castletown House, Bantry House, are also of interest to tourists. Some have been converted into hotels, such as Ashford Castle, Castle Leslie and Dromoland Castle.
County Meath

Flora and fauna.
As Ireland was isolated from mainland Europe by rising sea levels after the ice age, it has less diverse animal and plant species than either Great Britain or mainland Europe. There are 55 mammal species in Ireland and of them only 26 land mammal species are considered native to Ireland. Some species, such as, the red fox, hedgehog and badger, are very common, whereas others, like the Irish hare, red deer and pine marten are less so. Aquatic wildlife, such as species of sea turtle, shark, seal, whale, and dolphin, are common off the coast. About 400 species of birds have been recorded in Ireland. Many of these are migratory, including the Barn Swallow. Most of Ireland's bird species come from Iceland, Greenland and Africa.
Several different habitat types are found in Ireland, including farmland, open woodland, temperate broadleaf and mixed forests, conifer plantations, peat bogs and a variety of coastal habitats. However, agriculture drives current land use patterns in Ireland, limiting natural habitat preserves, particularly for larger wild mammals with greater territorial needs. With no top predator in Ireland, populations of animals, such as semi-wild deer, that cannot be controlled by smaller predators, such as the fox, are controlled by annual culling.
There are no snakes in Ireland and only one reptile (the common lizard) is native to the island. Extinct species include the Irish elk, the great auk and the wolf. Some previously extinct birds, such as, the Golden Eagle, have recently been reintroduced after decades of extirpation.
Until medieval times Ireland was heavily forested with oak, pine and birch. Forests today cover about 12.6% of Ireland, of which 4,450 km² or one million acres is owned by Coillte, the Republic's forestry service. The Republic lies in 42nd place (out of 55) in a list of the most forested countries in Europe. Much of the land is now covered with pasture and there are many species of wild-flower. Gorse ("Ulex europaeus"), a wild furze, is commonly found growing in the uplands and ferns are plentiful in the more moist regions, especially in the western parts. It is home to hundreds of plant species, some of them unique to the island, and has been "invaded" by some grasses, such as "Spartina anglica".
"Codium fragile" ssp. "atlanticum" has recently been established to be native, although for many years it was regarded as an alien species.
Because of its mild climate, many species, including sub-tropical species such as palm trees, are grown in Ireland. Phytogeographically, Ireland belongs to the Atlantic European province of the Circumboreal Region within the Boreal Kingdom. The island itself can be subdivided into two ecoregions: the Celtic broadleaf forests and North Atlantic moist mixed forests.
Impact of agriculture.
The long history of agricultural production, coupled with modern intensive agricultural methods such as pesticide and fertiliser use and runoff from contaminants into streams, rivers and lakes, impact the natural fresh-water ecosystems and have placed pressure on biodiversity in Ireland.
A land of green fields for crop cultivation and cattle rearing limits the space available for the establishment of native wild species. Hedgerows, however, traditionally used for maintaining and demarcating land boundaries, act as a refuge for native wild flora. This ecosystem stretches across the countryside and acts as a network of connections to preserve remnants of the ecosystem that once covered the island. Subsidies under the Common Agricultural Policy, which supported agricultural practices that preserved hedgerow environments, are undergoing reforms. The Common Agricultural Policy had in the past subsidised potentially destructive agricultural practices, for example by emphasising production without placing limits on indiscriminate use of fertilisers and pesticides; but recent reforms have gradually decoupled subsidies from production levels and introduced environmental and other requirements.
Forest covers about 12.6% of the country, most of it designated for commercial production. Forested areas typically consist of monoculture plantations of non-native species, which may result in habitats that are not suitable for supporting native species of invertebrates. Remnants of native forest can be found scattered around the island, in particular in the Killarney National Park. Natural areas require fencing to prevent over-grazing by deer and sheep that roam over uncultivated areas. Grazing in this manner is one of the main factors preventing the natural regeneration of forests across many regions of the country.
Demography.
People have lived in Ireland for over 9,000 years, although only a limited amount is known about the palaeolithic, neolithic and Bronze Age inhabitants of the island. Early historical and genealogical records note the existence of dozens of different peoples that may or may not be mythological, for example the Cruithne, Attacotti, Conmaicne, Eóganachta, Érainn, and Soghain, to name but a few. Over the past 1000 years or so, Vikings, Normans, Scots and English have all added to the Gaelic population and have had significant influences on Irish Culture.
Ireland's largest religious group is Christianity. The largest denomination is Roman Catholicism representing over 73% for the island (and about 87% of the Republic of Ireland). Most of the rest of the population adhere to one of the various Protestant denominations (about 53% of Northern Ireland). The largest is the Anglican Church of Ireland. The Muslim community is growing in Ireland, mostly through increased immigration. The island has a small Jewish community. About 4% of the Republic's population and about 14% of the Northern Ireland population describe themselves as of no religion. In a 2010 survey conducted on behalf of the Irish Times, 32% of respondents said they went to a religious service more than once a week.
The population of Ireland rose rapidly from the 16th century until the mid-19th century, but a devastating famine in the 1840s caused one million deaths and forced over one million more to emigrate in its immediate wake. Over the following century the population was reduced by over half, at a time when the general trend in European countries was for populations to rise by an average of three-fold.
Divisions and settlements.
Traditionally, Ireland is subdivided into four provinces: Connacht (west), Leinster (east), Munster (south), and Ulster (north). In a system that developed between the 13th and 17th centuries, Ireland has 32 traditional counties. Twenty-six of these counties are in the Republic of Ireland and six are in Northern Ireland. The six counties that constitute Northern Ireland are all in the province of Ulster (which has nine counties in total). As such, "Ulster" is often used as a synonym for Northern Ireland, although the two are not coterminous.
In the Republic of Ireland, counties form the basis of the system of local government. Counties Dublin, Cork, Limerick, Galway, Waterford and Tipperary have been broken up into smaller administrative areas. However, they are still treated as counties for cultural and some official purposes, for example postal addresses and by the Ordnance Survey Ireland. Counties in Northern Ireland are no longer used for local governmental purposes, but, as in the Republic, their traditional boundaries are still used for informal purposes such as sports leagues and in cultural or tourism contexts.
City status in Ireland is decided by legislative or royal charter. Dublin, with over 1 million residents in the Greater Dublin Area, is the largest city on the island. Belfast, with 579,726 residents, is the largest city in Northern Ireland. City status does not directly equate with population size. For example, Armagh, with 14,590 is the seat of the Church of Ireland and the Roman Catholic Primate of All Ireland and was re-granted city status by Queen Elizabeth II in 1994 (having lost that status in local government reforms of 1840). In the Republic of Ireland, Kilkenny, seat of the Butler dynasty, while no longer a city for administrative purposes (since the 2001 Local Government Act), is entitled by law to continue to use the description.
Migration.
The population of Ireland collapsed dramatically during the second half of the 19th century. A population of over 8 million in 1841 was reduced to slightly more than 4 million by 1921. In part, the fall in population was due to death from the Great Famine of 1845 to 1852, which took about 1 million lives. However, by far the greater cause of population decline was the dire economic state of the country which led to an entrenched culture of emigration lasting until the 21st century.
Emigration from Ireland in the 19th century contributed to the populations of England, the United States, Canada and Australia where today a large Irish diaspora lives. Today 4.3 million Canadians, or 14% of her population, are of Irish descent. A total of 36 million Americans claim Irish ancestry – more than 12% of the total population and 20% of the white population. Massachusetts is the most Irish of US states with 23.8% of the population claiming Irish ancestry. The pattern of immigration over this period particularly devastated the western and southern seaboards. Prior to the Great Famine, the provinces of Connacht, Munster and Leinster were more or less evenly populated whereas Ulster was far less densely populated than the other three. Today, Ulster and Leinster, and in particular Dublin, have a far greater population density than Munster and Connacht.
With growing prosperity since the last decade of the 20th century, Ireland became a destination for immigrants. Since the European Union expanded to include Poland in 2004, Polish people have made up the largest number of immigrants (over 150,000) from Central Europe. There has also been significant immigration from Lithuania, the Czech Republic and Latvia.
The Republic of Ireland in particular has seen large-scale immigration. The 2006 census recorded that 420,000 foreign nationals, or about 10% of the population, lived in the Republic of Ireland. Chinese and Nigerians, along with people from other African countries, have accounted for a large proportion of the non–European Union migrants to Ireland. Up to 50,000 eastern European migrant workers may have left Ireland since the end of 2008.
Languages.
Two main languages are spoken in Ireland: Irish and English. Both languages have widely contributed to literature. Irish, now a minority but official language of the Republic of Ireland, was the vernacular of the Irish people for over two thousand years and was probably introduced by some sort of proto-Gaelic migration during the Iron age, possibly earlier. It began to be written down after Christianisation in the 5th century and spread to Scotland and the Isle of Man where it evolved into the Scottish Gaelic and Manx languages respectively. It has a vast treasure of written texts from many centuries, and is divided by linguists into Old Irish from the 6th to 10th century, Middle Irish from the 10th to 13th century, Early Modern Irish until the 17th century, and the Modern Irish spoken today. It remained the dominant language of Ireland for most of those periods, having influences from Latin, Old Norse, French and English. It declined under British rule but remained the majority tongue until the early 19th century, and since then has been a minority language, although revival efforts are continuing in both the Republic of Ireland and Northern Ireland. However, Gaeltacht or Irish-speaking areas are still seeing a decline in the language. Irish language is a compulsory subject in the state education system in the Republic, and the Gaelscoil movement has seen many Irish medium schools established in both jurisdictions.
English was first introduced to Ireland in the Norman invasion. It was spoken by a few peasants and merchants brought over from England, and was largely replaced by Irish before the Tudor Conquest of Ireland. It was introduced as the official language with the Tudor and Cromwellian conquests. The Ulster plantations gave it a permanent foothold in Ulster, and it remained the official and upper-class language elsewhere, the Irish-speaking chieftains and nobility having been deposed. Language shift during the 19th century replaced Irish with English as the first language for a vast majority of the population. Less than 10% of the population of the Republic of Ireland today speak Irish regularly outside of the education system and 38% of those over 15 years are classified as "Irish speakers." In Northern Ireland, English is the de facto official language, but official recognition is afforded to Irish, including specific protective measures under Part III of the European Charter for Regional or Minority Languages. A lesser status (including recognition under Part II of the Charter) is given to Ulster Scots dialects, which are also spoken by some in the Republic of Ireland. In recent decades, with the increase in immigration, many more languages have been introduced, particularly deriving from Asia and Eastern Europe.
Culture.
Ireland's culture comprises elements of the culture of ancient immigration and influences (such as Gaelic culture) and more recent Anglicisation and Americanisation as well as participation in a broader European culture. In broad terms, Ireland is regarded as one of the Celtic nations of Europe, which also includes Scotland, Wales, Cornwall, Isle of Mann and Brittany. This combination of cultural influences is visible in the intricate designs termed "Irish interlace" or "Celtic knotwork." These can be seen in the ornamentation of medieval religious and secular works. The style is still popular today in jewellery and graphic art, as is the distinctive style of traditional Irish music and dance, and has become indicative of modern "Celtic" culture in general.
Religion has played a significant role in the cultural life of the island since ancient times (and since the 17th century plantations, has been the focus of political identity and divisions on the island). Ireland's pre-Christian heritage fused with the Celtic Church following the missions of Saint Patrick in the 5th century. The Hiberno-Scottish missions, begun by the Irish monk Saint Columba, spread the Irish vision of Christianity to pagan England and the Frankish Empire. These missions brought written language to an illiterate population of Europe during the Dark Ages that followed the fall of Rome, earning Ireland the sobriquet, "the island of saints and scholars". In more recent years, the Irish pubs have become outposts of Irish culture worldwide.
The Republic of Ireland's national theatre is the Abbey Theatre founded in 1904 and the national Irish-language theatre is An Taibhdhearc, established in 1928 in Galway. Playwrights such as Seán O'Casey, Brian Friel, Sebastian Barry, Conor McPherson and Billy Roche are internationally renowned.
Art.
There are a number of languages used in Ireland. Irish is the only language to have originated from within the island. Since the late 19th century, English has become the predominant first language having been a spoken language in Ireland since the Middle Ages. A large minority claim some ability to speak Irish today, although it is the first language only of a small percentage of the population. Under Constitution of Ireland, both languages have official status with Irish being the national and first official language. In Northern Ireland English is the dominant state language, whilst Irish and Ulster Scots are recognised minority languages.
Ireland has made a large contribution to world literature in all its branches, particularly in the English language. Poetry in Irish is the oldest vernacular poetry in Europe, with the earliest examples dating from the 6th century. In English, Jonathan Swift, still often called the foremost satirist in the English language, was wildly popular in his day for works such as "Gulliver's Travels" and "A Modest Proposal" and Oscar Wilde is known most for his often quoted witticisms.
In the 20th century, Ireland produced four winners of the Nobel Prize for Literature: George Bernard Shaw, William Butler Yeats, Samuel Beckett and Seamus Heaney. Although not a Nobel Prize winner, James Joyce is widely considered to be one of the most significant writers of the 20th century. Joyce's 1922 novel "Ulysses" is considered one of the most important works of Modernist literature and his life is celebrated annually on 16 June in Dublin as "Bloomsday". Modern Irish literature is often connected with its rural heritage through writers such as John McGahern and poets such as Seamus Heaney.
The Irish traditional music and dance has seen a recent surge in popularity, not least through the phenomenon of "Riverdance", a theatrical performance of Irish traditional dancing. In the middle years of the 20th century, as Irish society was modernising, traditional music fell out of favour, especially in urban areas. During the 1960s, inspired by the American folk music movement, there was a revival of interest in Irish traditional music led by groups such as The Dubliners, The Chieftains, Emmet Spiceland, The Wolfe Tones, the Clancy Brothers, Sweeney's Men and individuals like Seán Ó Riada and Christy Moore.
Groups and musicians including Horslips, Van Morrison and Thin Lizzy incorporated elements of Irish traditional music into contemporary rock music and, during the 1970s and 1980s, the distinction between traditional and rock musicians became blurred, with many individuals regularly crossing over between these styles of playing. This trend can be seen more recently in the work of artists like Enya, The Saw Doctors, The Corrs, Sinéad O'Connor, Clannad, The Cranberries, Black 47 and The Pogues among others.
During the 1990s a sub-genre of folk metal emerged in Ireland that fused heavy metal music with Irish and Celtic music. The pioneers of this sub-genre were Cruachan, Primordial, and Waylander. Some contemporary music groups stick closer to a "traditional" sound, including Altan, Téada, Danú, Dervish, Lúnasa, and Solas. Others incorporate multiple cultures in a fusion of styles, such as Afro Celt Sound System and Kíla.
The earliest known Irish graphic art and sculpture are Neolithic carvings found at sites such as Newgrange and is traced through Bronze age artefacts and the religious carvings and illuminated manuscripts of the medieval period. During the course of the 19th and 20th centuries, a strong tradition of painting emerged, including such figures as John Butler Yeats, William Orpen, Jack Yeats and Louis le Brocquy. Contemporary Irish visual artists of note include Sean Scully, Kevin Abosch, and Alice Maher.
Science.
The Irish philosopher and theologian Johannes Scotus Eriugena was considered one of the leading intellectuals of his early Middle Ages. Sir Ernest Henry Shackleton, an Anglo-Irish explorer, was one of the principal figures of Antarctic exploration. He, along with his expedition, made the first ascent of Mount Erebus and the discovery of the approximate location of the South Magnetic Pole. Robert Boyle was a 17th-century natural philosopher, chemist, physicist, inventor and early gentleman scientist. He is largely regarded one of the founders of modern chemistry and is best known for the formulation of Boyle's law. 19th century physicist, John Tyndall, discovered the Tyndall effect, which explains why the sky is blue. Father Nicholas Joseph Callan, Professor of Natural Philosophy in Maynooth College, is best known for his invention of the induction coil, transformer and he discovered an early method of galvanisation in the 19th century.
Other notable Irish physicists include Ernest Walton, winner of the 1951 Nobel Prize in Physics. With Sir John Douglas Cockcroft, he was the first to split the nucleus of the atom by artificial means and made contributions to the development of a new theory of wave equation. William Thomson, or Lord Kelvin, is the person whom the absolute temperature unit, the Kelvin, is named after. Sir Joseph Larmor, a physicist and mathematician, made innovations in the understanding of electricity, dynamics, thermodynamics and the electron theory of matter. His most influential work was Aether and Matter, a book on theoretical physics published in 1900.
George Johnstone Stoney introduced the term "electron" in 1891. John Stewart Bell was the originator of Bell's Theorem and a paper concerning the discovery of the Bell-Jackiw-Adler anomaly and was nominated for a Nobel prize. Notable mathematicians include Sir William Rowan Hamilton, famous for work in classical mechanics and the invention of quaternions. Francis Ysidro Edgeworth's contribution of the Edgeworth Box remains influential in neo-classical microeconomic theory to this day; while Richard Cantillon inspired Adam Smith, among others. John B. Cosgrave was a specialist in number theory and discovered a 2000-digit prime number in 1999 and a record composite Fermat number in 2003. John Lighton Synge made progress in different fields of science, including mechanics and geometrical methods in general relativity. He had mathematician John Nash as one of his students.
Ireland has nine universities, seven in the Republic of Ireland and two in Northern Ireland, including Trinity College, Dublin and the University College Dublin, as well as numerous third-level colleges and institutes and a branch of the Open University, the Open University in Ireland.
Sport.
The island of Ireland fields a single international team in most sports. One notable exception to this is Association football, although both associations continued to field international teams under the name "Ireland" until the 1950s. An all-Ireland club competition for soccer, the Setanta Cup, was created in 2005.
Gaelic football is the most popular sport in Ireland in terms of match attendance and community involvement, with about 2,600 clubs on the island. In 2003 it represented 34% of total sports attendances at events in Ireland and abroad, followed by hurling at 23%, soccer at 16% and rugby at 8% and the All-Ireland Football Final is the most watched event in the sporting calendar. Soccer is the most widely played team game on the island, and the most popular in Northern Ireland. Swimming, golf, aerobics, soccer, cycling, Gaelic football and billiards/snooker are the sporting activities with the highest levels of playing participation. The sport is also the most notable exception where the Republic of Ireland and Northern Ireland field separate international teams.
In recent years ice hockey has seen an increase in popularity, notably with the Belfast Giants ice hockey team in Northern Ireland. Northern Ireland have also produced two World Snooker Champions. Many other sports are also played and followed, including basketball, boxing, cricket, fishing, greyhound racing, handball, hockey, horse racing, motor sport, show jumping and tennis.
Field sports.
Gaelic football, hurling and handball are the best-known of the Irish traditional sports, collectively known as Gaelic games. Gaelic games are governed by the Gaelic Athletic Association (GAA), with the exception of ladies' Gaelic football and camogie (women's variant of hurling), which are governed by separate organisations. The headquarters of the GAA (and the main stadium) is located at the 82,500 capacity Croke Park in north Dublin. Many major GAA games are played there, including the semi-finals and finals of the All-Ireland Senior Football Championship and All-Ireland Senior Hurling Championship. During the redevelopment of the Lansdowne Road stadium in 2007–10, international rugby and soccer were played there. All GAA players, even at the highest level, are amateurs, receiving no wages, although they are permitted to receive a limited amount of sport-related income from commercial sponsorship.
The Irish Football Association (IFA) was originally the governing body for soccer across the island. The game has been played in an organised fashion in Ireland since the 1870s, with Cliftonville F.C. in Belfast being Ireland's oldest club. It was most popular, especially in its first decades, around Belfast and in Ulster. However, some clubs based outside Belfast thought that the IFA largely favoured Ulster-based clubs in such matters as selection for the national team. In 1921, following an incident in which, despite an earlier promise, the IFA moved an Irish Cup semi-final replay from Dublin to Belfast
Dublin-based clubs broke away to form the Football Association of the Irish Free State. Today the southern association is known as the Football Association of Ireland (FAI). Despite being initially blacklisted by the Home Nations' associations, the FAI was recognised by FIFA in 1923 and organised its first international fixture in 1926 (against Italy). However, both the IFA and FAI continued to select their teams from the whole of Ireland, with some players earning international caps for matches with both teams. Both also referred to their respective teams as "Ireland".
In 1950, FIFA directed the associations only to select players from within their respective territories and, in 1953, directed that the FAI's team be known only as "Republic of Ireland" and that the IFA's team be known as "Northern Ireland" (with certain exceptions). Northern Ireland qualified for the World Cup finals in 1958 (reaching the quarter-finals), 1982 and 1986. The Republic qualified for the World Cup finals in 1990 (reaching the quarter-finals), 1994, 2002 and the European Championships in 1988 and 2012. Across Ireland, there is significant interest in the English and, to a lesser extent, Scottish soccer leagues.
Unlike soccer, Ireland continues to field a single national rugby team and a single association, the Irish Rugby Football Union (IRFU), governs the sport across the island. The Irish rugby team have played in every Rugby World Cup, making the quarter-finals in four of them. Ireland also hosted games during the 1991 and the 1999 Rugby World Cups (including a quarter-final). There are four professional Irish teams; all four play in the Magners League (now called the RaboDirect Pro12) and at least three compete for the Heineken Cup. Irish rugby has become increasingly competitive at both the international and provincial levels since the sport went professional in 1994. During that time, Ulster (1999), Munster (2006 and 2008) and Leinster (2009 and 2011) have won the Heineken Cup. In addition to this, the Irish International side has had increased success in the Six Nations Championship against the other European elite sides. This success, including Triple Crowns in 2004, 2006 and 2007, culminated with a clean sweep of victories, known as a Grand Slam, in 2009.
The Ireland cricket team was among the associate nations that qualified for the 2007 Cricket World Cup. It defeated Pakistan and finished second in its pool, earning a place in the Super 8 stage of the competition. The team also competed in the 2009 ICC World Twenty20 after jointly winning the qualifiers, where they also made the Super 8 stage. Ireland also won the 2009 ICC World Cup Qualifier to secure their place in the 2011 Cricket World Cup, as well as official ODI status through 2013. Kevin O'Brien scored the fastest century in Word Cup history (113 runs off 63 balls), as Ireland produced one of the great upsets to defeat England by 3 wickets in the 2011 tournament
Rugby league in Ireland is governed by Rugby League Ireland, which runs the Irish Elite League, there are currently 20 teams across Ulster, Munster and Leinster. The Irish rugby league team is made up predominantly of players based in Ireland, England and Australia. Ireland reached the quarter-finals of the 2000 Rugby League World Cup as well as reaching the semi finals in the 2008 Rugby League World Cup.
Other sports.
Horse racing and greyhound racing are both popular in Ireland. There are frequent horse race meetings and greyhound stadiums are well-attended. The island is noted for the breeding and training of race horses and is also a large exporter of racing dogs. The horse racing sector is largely concentrated in the County Kildare.
Irish athletics has seen some development in recent times, with Sonia O'Sullivan winning two notable medals at 5,000 metres; gold at the 1995 World Championships and silver at the 2000 Sydney Olympics. Gillian O'Sullivan won silver in the 20k walk at the 2003 World Championships, while sprint hurdler Derval O'Rourke won gold at the 2006 World Indoor Championship in Moscow. Olive Loughnane won a silver medal in the 20k walk in the World Athletics Championships in Berlin in 2009.
Ireland has won more medals in boxing than in any other Olympic sport. Boxing is governed by the Irish Amateur Boxing Association. Michael Carruth won a gold medal in the Barcelona Olympic Games and in 2008 Kenneth Egan won a silver medal in the Beijing Games. Paddy Barnes secured bronze in those games and gold in the 2010 European Amateur Boxing Championships (where Ireland came 2nd in the overall medal table) and 2010 Commonwealth Games. Katie Taylor has won gold in every European and World championship since 2005.
Golf is very popular and golf tourism is a major industry attracting more than 240,000 golfing visitors annually. The 2006 Ryder Cup was held at The K Club in County Kildare. Pádraig Harrington became the first Irishman since Fred Daly in 1947 to win the British Open at Carnoustie in July 2007. He successfully defended his title in July 2008 before going on to win the PGA Championship in August. Harrington became the first European to win the PGA Championship in 78 years and was the first winner from Ireland. Three golfers from Northern Ireland have been particularly successful. In 2010, Graeme McDowell became the first Irish golfer to win the U.S. Open, and the first European to win that tournament since 1970. Rory McIlroy, at the age of 22, won the 2011 U.S. Open, while Darren Clarke's latest victory was the 2011 Open Championship at Royal St. George's. In August 2012, McIlroy won his 2nd major championship by winning the USPGA Championship by a record margin of 8 shots.
The west coast of Ireland, Lahinch and Donegal Bay in particular, have popular surfing beaches, being fully exposed to the Atlantic Ocean. Donegal Bay is shaped like a funnel and catches west/south-west Atlantic winds, creating good surf, especially in winter. In recent years, Bundoran has hosted European championship surfing. Scuba diving is increasingly popular in Ireland with clear waters and large populations of sea life, particularly along the western seaboard. There are also many shipwrecks along the coast of Ireland, with some of the best wreck dives being in Malin Head and off the County Cork coast.
With thousands of lakes, over of fish bearing rivers and over of coastline, Ireland is a popular angling destination. The temperate Irish climate is suited to sport angling. While salmon and trout fishing remain popular with anglers, salmon fishing in particular received a boost in 2006 with the closing of the salmon driftnet fishery. Coarse fishing continues to increase its profile. Sea angling is developed with many beaches mapped and signposted, and the range of sea angling species is around 80.
Food and drink.
Food and cuisine in Ireland takes its influence from the crops grown and animals farmed in the island's temperate climate and from the social and political circumstances of Irish history. For example, whilst from the Middle Ages until the arrival of the potato in the 16th century the dominant feature of the Irish economy was the herding of cattle, the number of cattle a person owned was equated to their social standing. Thus herders would avoid slaughtering a milk-producing cow.
For this reason, pork and white meat were more common than beef and thick fatty strips of salted bacon (or rashers) and the eating of salted butter (i.e. a dairy product rather than beef itself) have been a central feature of the diet in Ireland since the Middle Ages. The practice of bleeding cattle and mixing the blood with milk and butter (not unlike the practice of the Maasai) was common and black pudding, made from blood, grain (usually barley) and seasoning, remains a breakfast staple in Ireland. All of these influences can be seen today in the phenomenon of the "breakfast roll".
The introduction of the potato in the second half of the 16th century heavily influenced cuisine thereafter. Great poverty encouraged a subsistence approach to food and by the mid-19th century the vast majority of the population sufficed with a diet of potatoes and milk. A typical family, consisting of a man, a woman and four children, would eat of potatoes a week. Consequently, dishes that are considered as national dishes represent a fundamental unsophistication to cooking, such as the Irish stew, bacon and cabbage, boxty, a type of potato pancake, or colcannon, a dish of mashed potatoes and kale or cabbage.
Since the last quarter of the 20th century, with a re-emergence of wealth in Ireland, a "New Irish Cuisine" based on traditional ingredients incorporating international influences has emerged. This cuisine is based on fresh vegetables, fish (especially salmon, trout, oysters, mussels and other shellfish), as well as traditional soda breads and the wide range of hand-made cheeses that are now being produced across the country. The potato remains however a fundamental feature of this cuisine and the Irish remain the highest per capita consumers of potatoes in Europe. An example of this new cuisine is "Dublin Lawyer": lobster cooked in whiskey and cream. Traditional regional foods can be found throughout the country, for example coddle in Dublin or drisheen in Cork, both a type of sausage, or blaa, a doughy white bread particular to Waterford.
Ireland once dominated the world's market for whiskey, producing 90% of the world's whiskey at the start of the 20th century. However, as a consequence of bootleggers during the prohibition in the United States (who sold poor-quality whiskey bearing Irish-sounding names thus eroding the pre-prohibition popularity for Irish brands) and tariffs on Irish whiskey across British Empire during the Anglo-Irish Trade War of the 1930s, sales of Irish whiskey worldwide fell to a mere 2% by the mid-20th century. In 1953, an Irish government survey, found that 50 per cent of whiskey drinkers in the United States had never heard of Irish whiskey.
Irish whiskey, however, remained popular domestically and in recent decades has grown in popularity again internationally. Typically, Irish whiskey is not as smoky as a Scotch whisky, but not as sweet as American or Canadian whiskies. Whiskey forms the basis of traditional cream liqueurs, such as Baileys, and the "Irish coffee" (a cocktail of coffee and whiskey reputedly invented at Foynes flying-boat station) is probably the best-known Irish cocktail.
Stout, a kind of porter beer, particularly Guinness, is typically associated with Ireland, although historically it was more closely associated with London. Porter remains very popular, although it has lost sales since the mid-20th century to lager. Cider, particularly "Magners" (marketed in the Republic of Ireland as "Bulmers"), is also a popular drink. Red lemonade, a soft-drink, is consumed on its own and as a mixer, particularly with whiskey.

Irredentism
Irredentism (from Italian "irredento", "unredeemed") is any position advocating annexation of territories administered by another state on the grounds of common ethnicity or prior historical possession, actual or alleged. It is often advocated by pan-nationalist movements and is a feature of identity politics, cultural and political geography. Because most borders have been moved and redrawn over time, a great many countries could theoretically present irredentist claims to their neighbors. Germany's Anschluss of Austria and annexation of German-speaking Sudetenland from Czechoslovakia in 1938 and a return of territory from Czechoslovakia to Hungary as a result of the First Vienna Award are perhaps historical examples of this idea in practice.
However, some states are the subject of potential irredentism from their inception. Post–World War I Eastern Europe, the Balkans, and the Near East had borders carved out by the Allies that left many of the new states in that region unsatisfied due to minority populations and conflicting historical claims. Many of Africa's borders were artificially imposed by European colonial powers. The result split ethnic groups between different countries, such as the Yoruba who are divided between Nigeria and Benin. In some cases, the irredentist argumentation continued well past the Second World War and on to the present day.
An area that may be subjected to a potential claim is therefore sometimes called an irredenta. Not all irredentas are involved in actual irredentism.
Origins.
The word was coined in Italy from the phrase "Italia irredenta" ("unredeemed Italy"). This originally referred to Austro-Hungarian rule over mostly or partly Italian-inhabited territories such as Trentino, Trieste, Istria and Dalmatia during the 19th and early 20th century.
A common way to express a claim to adjacent territories on the grounds of historical or ethnic association is by using the epithet "Greater" before the country name. This conveys the image of national territory at its maximum conceivable extent with the country "proper" at its core. The use of "Greater" does not always convey an irredentistic meaning.
During the unification of Germany, the term "Großdeutschland" (or greater Germany) referred to a possible German nation consisting of the states that later comprised the Second German Empire "and" Austria; the term "lesser" Germany, or small Germany, or "Kleindeutschland", referred to a possible German state without Austria. The term was also used by Germans referring to Greater Germany, a state consisting of pre World War I Germany, actual Austria and the Sudetenland.
Constitutional irredentism.
Some states formalize their irredentist claims by including them in their constitutional documents.
Afghanistan.
The Afghan border with Pakistan, known as the Durand Line, was arbitrarily drawn by colonial officials of the British Empire in 1893 following the Second Afghan War. Accordingly, the Pashtun tribes inhabiting the border areas were arbitrarily divided; the tribes have never accepted the still-porous border. The Durand Line was not intended as a permanent border, and clashes broke out in the 1950s and 1960s between Afghanistan and Pakistan over the issue. All Afghan governments of the past century have declared, with varying intensity, a long-term goal of re-uniting all Pashtun-dominated areas under Afghan rule.
Argentina.
The Argentine government has maintained a claim over the Falkland Islands since 1833, and renewed it as recently as June 2009. It considers the archipelago part of the Tierra del Fuego Province, along with South Georgia and the South Sandwich Islands.
Bolivia.
The 2009 constitution of Bolivia states that the country has an unrenounceable right over the territory that gives it access to the Pacific Ocean and its maritime space. This is understood as Chilean territory that Bolivia and Peru ceded after the War of the Pacific which left Bolivia a landlocked country.
People's Republic of China.
The preamble to the Constitution of the People's Republic of China states "Taiwan is part of the sacred territory of the People's Republic of China. It is the lofty duty of the entire Chinese people, including our compatriots in Taiwan, to accomplish the great task of reunifying the motherland." The PRC claim to sovereignty over Taiwan is generally based on the successor state theory, with the PRC claiming that it is the successor state to the Republic of China.
Republic of China (Taiwan).
Article 4 of the Constitution of the Republic of China originally stated that "he territory of the Republic of China within its existing national boundaries shall not be altered except by a resolution of the National Assembly", although recent constitutional changes have moved this power to that of a national referendum. The PRC's influence in international organizations prevents Taiwan from participating in many such organizations. In some organizations the Republic of China is able to participate as Chinese Taipei. The PRC has an extensive missile build-up near Taiwan and passed an Anti-Secession Law in 2005 threatening to use force.
Throughout the 1950s and 1960s, the ROC government on Taiwan maintained itself to be the legitimate ruler of Mainland China. As part of its current policy of 'status quo', the ROC has not renounced claims over the territories currently controlled by the People's Republic of China, Mongolia, and Tuvan Republic in Russia, Northern Burma and some Central Asian states bordering areas. However, the ROC does not actively pursue these claims in practice; the remaining claims that the ROC are actively seeking are the Diaoyu Islands, whose sovereignty is also asserted by Japan and the PRC; and the Spratly Islands in South China Sea, with multiple claimants.
Comoros.
Article 1 of the Constitution of the Union of the Comoros begins: "The Union of the Comoros is a republic, composed of the autonomous islands of Mohéli, Mayotte, Anjouan, and Grande Comore." Mayotte, geographically a part of the Comoro Islands, was the only island of the four to vote against independence from France (independence losing 37%-63%) in the referendum held December 22, 1974. The total vote was 94%-5% in favor of independence. Mayotte is currently a "departmental collectivity" of the French Republic.
India.
All of the European colonies on the Indian subcontinent which were not part of the British Raj have been annexed by the Republic of India since it gained its independence from the British Empire. An example of such territories was the 1961 Indian annexation of Goa and Indian integration of Junagadh.
Akhand Bharat is another irridentist call for "undivided India" to include Pakistan and Bangladesh into India to form a Hindu Rashtra raised by mainstream Indian political organization Vishva Hindu Parishad (VHP), Rashtriya Swayamsevak Sangh (RSS) and Bharatiya Janata Party (BJP).
From 1956 after King of Kashmir ceded to India entirely resulting from a Pakistani invasion of Kashmir earlier, India has claimed the entire area of Kashmir as part of their state's "national territory." Meanwhile Pakistan has claimed almost all of the state except for the portion of the state Pakistan ceded to China. Both currently administer large sections of the area, and the two countries have fought multiple wars over the area. India and Pakistan aspire to take Pakistan-administered Kashmir, and Indian-administered Kashmir, respectively, so that Kashmir may be re-united under their respective rule.
Indonesia.
Indonesia claimed all territories of the former Dutch East Indies, and previously viewed British plans to group the Straits Settlements, the Federated Malay States, the Unfederated Malay States, Sarawak and British North Borneo into a new independent federation of Malaysia as a threat to its objective to create a united state called Greater Indonesia. The Indonesian opposition of Malaysian formation has led to Indonesia-Malaysia confrontation in early 1960s. It had also held Portuguese Timor from 1975 to 2002, based on irredentist claims.
The idea of uniting former British and Dutch colonial possessions in Southeast Asia actually have its roots in early 20th century, as the concept of Greater Malay ("Melayu Raya") was coined in British Malaya espoused by students and graduates of Sultan Idris Training College for Malay Teachers in the late 1920s. Some of political figures in Indonesia including Muhammad Yamin and Sukarno revived the idea in the 1950s and named the political union concept as Greater Indonesia.
Ireland.
From 1937 until 1998, Articles 2 and 3 of the Constitution of Ireland provided that "national territory consists of the whole island of Ireland". However, "[pending the re-integration of the national territory", the powers of the state were restricted to legislate only for the area that had ceded from the United Kingdom. Arising from the Northern Ireland peace process, the matter was mutually resolved in 1998. The Republic of Ireland's constitution was altered by referendum and its territorial claim to Northern Ireland was dropped. The amended constitution asserts that while it is the entitlement of "every person born in the island of Ireland … to be part of the Irish Nation" and to hold Irish citizenship, "a united Ireland shall be brought about only by peaceful means with the consent of a majority of the people, democratically expressed, in both jurisdictions in the island." Certain joint policy and executive bodies were created between Northern Ireland, the part of the island that remained in the United Kingdom, and the Republic of Ireland, and these were given executive authority. The advisory and consultative role of the government of Ireland in the government of Northern Ireland granted by the United Kingdom, that had begun with the 1985 Anglo-Irish Agreement, was maintained. The two states also settled the long-running dispute concerning their respective names: "Ireland" and the "United Kingdom of Great Britain and Northern Ireland", with both governments agreeing to use those names.
Israel.
The entire area of the West Bank and Gaza, previously annexed by Jordan and occupied by Egypt respectively, was controlled by Israel from the 1967 war until August 2005, when Israel withdrew from Gaza. Israel never explicitly claimed any of the West Bank for its own state except the city of Jerusalem, which it unilaterally annexed in 1980. However, Israel has settled hundreds of thousands of its citizens in various Israeli controlled settlements in the West Bank.
Article 3 of the Basic Law of the Palestinian Authority, which was ratified in 2002 by the Palestinian National Authority and serves as an interim constitution, states that "Jerusalem is the capital of Palestine." The Israeli annexing instrument, the Jerusalem Law—one of the Basic Laws of Israel that "serve in the place of a constitution"—declares Jerusalem, "complete and united", to be the capital of Israel, creating a conflict with Palestinian claims. "De facto", the Palestinian government administers the parts of the West Bank that Israel has granted it authority over from Ramallah, while the Gaza Strip is administered from Gaza.
According to United Nations Resolutions 242 and 338, East Jerusalem is part of the occupied territories. The United States does not recognize Israeli sovereignty over East Jerusalem and maintains its embassy in Tel Aviv. In Jerusalem, the United States maintains a Consulate General as a diplomatic representation to the city of Jerusalem alone, separate from the US's representation to the state of Israel. The Consulate General maintains two buildings in the city as they were established before the 1967 war, one building on what was the Israeli side and one on what was the Jordanian-annexed side of Jerusalem.
Korea.
Since their founding, both Korean states have disputed the legitimacy of the other. South Korea's constitution claims jurisdiction over the entire Korean peninsula. It acknowledges the division of Korea only indirectly by requiring the president to work for reunification. North Korea's constitution also stresses the importance of reunification, but makes no similar claim to the entire peninsula.
United States.
The first constitution of the United States, the Articles of Confederation, included a provision in Article XI to allow the admission of Canada as a state.
Other irredentism.
Until the Nineteenth Amendment of the Constitution of Ireland in 1998 the Irish Republic claimed the territory of six counties that form Northern Ireland. 
Spain claims the British overseas territory of Gibraltar, ceded to Britain in perpetuity in 1713 under the Treaty of Utrecht, and argues its case at the United Nations claiming its territorial integrity is affected. During World War II, the Spanish Falangist media agitated for irredentism claiming for Spain the French Navarre, French Basque Country and Roussillon (French Catalonia) as well. Morocco makes similar claims against Spain over the North African enclaves of Ceuta and Melilla. Portugal does not recognize as Spanish the territory of Olivenza conquered by Spain during the Napoleonic Wars. [http://www.elpais.com/articulo/espana/eterna/disputa/Olivenza-Olivenca/elpepunac/20061204elpepinac_13/Tes]
Some of the most violent irredentist conflicts of recent times in Europe flared up as a consequence of the break-up of the former Yugoslavia in the early 1990s. The wars in Croatia and Bosnia and Herzegovina were largely about creating a new political framework of states, each of which would be ethnically and politically homogeneous. The conflict erupted further south with the ethnic Albanian majority in Kosovo seeking to switch allegiance to the adjoining state of Albania. Greece claims that the use of the name Republic of Macedonia by its northern neighbor signifies an irredentist claim on the northern province of Macedonia in Greece. 
South Asia too is another region in which armed irredentist movements have been active for almost a century, due to the Balkanization of North-East India, Burma and Bangladesh under British colonialism. Most prominent amongst them are the Naga fight for Greater Nagaland, the Chin struggle for a unified Chinland and other self-determinist movements by the ethnic indigenous peoples of the erstwhile Assam both under the British and post-British Assam under India.
Irredentism is acute in the Caucasus region, too. The Nagorno-Karabakh movement’s original slogan of miatsum (‘union’) was explicitly oriented towards unification with Armenia, feeding an Azerbaijani understanding of the conflict as a bilateral one between itself and an irredentist Armenia. According to Prof. Thomas Ambrosio, "Armenia's successful irredentist project in the Nagorno-Karabakh region of Azerbaijan" and "From 1992 to the cease-fire in 1994, Armenia encountered a highly permissive or tolerant international environment that allowed its annexation of some 15 percent of Azerbaijani territory".
In the view of Nadia Milanova, Nagorno-Karabakh represents a combination of separatism and irredentism.
The Syrian Social Nationalist Party, which operates in Lebanon and Syria, works for the unification of most modern states of the Levant and beyond in a single state referred to as Greater Syria. The proposed Syrian country includes Israel, Jordan, Iraq, Kuwait; and southern Turkey, northern Egypt, and southwestern Iran.
Japan claims the Russian-administered Kuril Islands, the four southernmost isles of the island chain north of Hokkaido, annexed by the Soviet Union following World War II.
The 1909 Gando Convention addressed a territory dispute between China and Joseon Korea in China's favor. Both Korean states now accept the convention border as an administrative boundary. However, because the convention was made by the occupying Empire of Japan, South Korea has disputed its legality and some Koreans claim that Korea extends into "de facto" PRC territory. The most ambitious claims include all parts of Manchuria that the Goguryeo kingdom controlled. Both Korean states claim the Liancourt Rocks, which Japan annexed while Korea was a Japanese protectorate.
Irredentism is commonplace in Africa due to the political boundaries of former European colonial nation-states passing through tribal boundaries, and recent declarations of independence after civil war. For example, some Ethiopian nationalist circles still claim the former Ethiopian province of Eritrea (internationally recognized as the independent State of Eritrea in 1993 after a 30 year civil war). Ogaden in eastern Ethiopia has seen a movement seeking to make it part of Somalia.
North American.
Irredentism is also expressed by some Chicano "nationalists" and Mexican-American activists in the Aztlán movement. They call for the return of formerly Mexican-dominated lands in the Southwestern United States back to Mexico after the US annexed lands in the Treaty of Guadalupe Hidalgo to become the present-day states of California, Texas, Nevada and Utah; and parts of Colorado, Arizona, and New Mexico.
UK issues.
A unique situation exists with that of Berwick. Part of the citizenry of the town support the transfer of Berwick to Scotland, although others would prefer it to remain as part of the English county of Northumberland. However, due to the nature of the political union between Scotland and England forming the UK the reunification of Berwick goes largely unpursued. Various debates have arisen surrounding the constitutional future of Berwick, or Berwick-upon-Tweed as it is known in England, but have been largely academic. 
Irredentism was also one of main reasons for the People's Republic of China to assume sovereignty over Hong Kong. The territory had been leased by the British for 99 years. In 1997, when the lease ran out, the United Kingdom relenquished control of Hong Kong. However, in the case of Hong Kong, irredentism was incidental as the he New Territories part of the British colony were only on a lease expiring in 1997 anyway and, with their surrender, it was thought the Crown territory of Hong Kong itself would be nonviable as an entity independent of mainland China. Of course, irredentism could be considered to have played a role in that the People's Republic of China had no intention of renewing the lease on the New Territories.

Israel
Israel, officially the State of Israel ( or ; , , ; , , ), is a parliamentary republic in the Middle East, along the eastern shore of the Mediterranean Sea. It borders Lebanon in the north, Syria in the northeast, Jordan and the West Bank in the east, Egypt and the Gaza Strip on the southwest, and the Gulf of Aqaba in the Red Sea to the south, and it contains geographically diverse features within its relatively small area. Israel is defined as a Jewish and Democratic State in its Basic Laws and is the world's only Jewish-majority state.
Following the adoption of a resolution by the United Nations General Assembly on 29 November 1947, recommending the adoption and implementation of the United Nations partition plan of Mandatory Palestine, on 14 May 1948 David Ben-Gurion, the Executive Head of the World Zionist Organization and president of the Jewish Agency for Palestine, declared "the establishment of a Jewish state in Eretz Israel, to be known as the State of Israel", a state independent upon the termination of the British Mandate for Palestine, 15 May 1948. Neighboring Arab states invaded the next day in support of the Palestinian Arabs. Israel has since fought several wars with neighboring Arab states, in the course of which it has occupied the West Bank, Sinai Peninsula (between 1967 and 1982), Gaza Strip and the Golan Heights. Portions of these territories, including East Jerusalem, have been annexed by Israel, but the border with the neighboring West Bank has not yet been permanently defined. Israel has signed peace treaties with Egypt and Jordan, but efforts to resolve the Israeli–Palestinian conflict have so far not resulted in peace.
Israel's financial centre is Tel Aviv, while Jerusalem is the country's most populous city and its capital (although not recognized internationally as such). The population of Israel, as defined by the Israel Central Bureau of Statistics, was estimated in 2012 to be 7,933,200 people, of whom 5,978,600 are Jewish. Arabs form the country's second-largest ethnic group with 1,636,600 people (including Druze and Bedouins). The great majority of Israeli Arabs are settled-Muslims, with smaller but significant numbers of semi-settled Negev Bedouins and Arab Christians. Other minorities include various ethnic and ethno-religious denominations such as Druze, Circassians, Black Hebrew Israelites, Samaritans, Maronites and others.
Israel is a representative democracy with a parliamentary system, proportional representation and universal suffrage. The Prime Minister serves as head of government and the Knesset serves as Israel's unicameral legislative body. Israel has one of the highest life expectancies in the world. It is a developed country, an OECD member, and its economy, based on the nominal gross domestic product, was the 41st-largest in the world in 2011. Israel has the highest standard of living in the Middle East.
Etymology.
Upon independence in 1948, the new Jewish state was formally named "Medinat Yisrael", or the State of Israel, after other proposed historical and religious names including "Eretz Israel" ("the Land of Israel"), Zion, and Judea, were considered and rejected. In the early weeks of independence, the government chose the term "Israeli" to denote a citizen of Israel, with the formal announcement made by Minister of Foreign Affairs Moshe Sharett.
The name Israel has historically been used, in common and religious usage, to refer to the biblical Kingdom of Israel or the entire Jewish nation. According to the Hebrew Bible the name "Israel" was given to the patriarch Jacob (Standard ', '; Septuagint "Israēl"; "struggle with God") after he successfully wrestled with the angel of the Lord. Jacob's twelve sons became the ancestors of the Israelites, also known as the "Twelve Tribes of Israel" or "Children of Israel". Jacob and his sons had lived in Canaan but were forced by famine to go into Egypt for four generations until Moses, a great-great grandson of Jacob, led the Israelites back into Canaan the "Exodus". The earliest archaeological artifact to mention the word "Israel" is the Merneptah Stele of ancient Egypt (dated to the late 13th century BCE).
The area is also known as the Holy Land, being holy for all Abrahamic religions including Judaism, Christianity, Islam and the Bahá'í Faith. Prior to the Israeli Declaration of Independence of 1948, the whole region was known by various other names including Southern Syria, Syria Palestina, Kingdom of Jerusalem, Iudaea Province, Coele-Syria, Retjenu, Canaan and, particularly, Palestine.
History.
Antiquity.
The notion of the "Land of Israel", known in Hebrew as "Eretz Yisrael" (or "Eretz Yisroel"), has been important and sacred to the Jewish people since Biblical times. According to the Torah, God promised the land to the three Patriarchs of the Jewish people. On the basis of scripture, the period of the three Patriarchs has been placed somewhere in the early 2nd millennium BCE, and the first Kingdom of Israel was established around the 11th century BCE. Subsequent Israelite kingdoms and states ruled intermittently over the next four hundred years, and are known from various extra-biblical sources.
The northern Kingdom of Israel, as well as Philistine city states fell in 722 BCE, though the southern Kingdom of Judah and several Phoenician city states continued their existence as the region came under Assyrian rule. With the emergence of Babylonians, Judah was eventually conquered as well.
Classical period.
With successive Persian rule, the region, divided between Syria-Coele province and later the autonomous Yehud Medinata, was gradually developing back into urban society, largely dominated by Judeans. The Greek conquests largely skipped the region without any resistance or interest. Incorporated into Ptolemaic and finally Seleucid Empires, southern Levant was heavily hellenized, building the tensions between Judeans and Greeks. The conflict erupted in 167 BCE with the Maccabean Revolt, which succeeded in establishing an independent Hasmonean Kingdom in Judah, which later expanded over much of modern Israel, as the Seleucids gradually lost control in the region.
The Roman Empire invaded the region in 63 BCE, first taking control of Syria, and then intervening in the Hasmonean civil war. The struggle between pro-Roman and pro-Parthian factions in Judea eventually led to the installation of Herod the Great and consolidation of the Herodian Kingdom as vassal Judean state of Rome. With the decline of Herodians, Judea, transformed into a Roman province, became the site of a violent struggle of Jews against Greco-Romans, culminating in the Jewish-Roman Wars, ending in wide-scale destruction and genocide. Jewish presence in the region significantly dwindled after the failure of the Bar Kokhba revolt against the Roman Empire in 132 CE. Nevertheless, there was a continuous small Jewish presence and Galilee became its religious center. The Mishnah and part of the Talmud, central Jewish texts, were composed during the 2nd to 4th centuries CE in Tiberias and Jerusalem. The region came to be populated predominantly by Greco-Romans on the coast and Samaritans in the hill-country. Christianity was gradually evolving over Roman paganism, when the area under Byzantine rule was transformed into Deocese of the East, as Palaestina Prima and Palaestina Secunda provinces. Through the 5th and 6th centuries, dramatic events of Samaritan Revolts reshaped the land, with massive destruction to Byzantine Christian and Samaritan societies and a resulting decrease of the population. After the Persian conquest and the installation of a short lived Jewish Commonwealth in 614 CE, the Byzantine Empire reinstalled its rule in 625 CE, resulting in further decline and destruction.
Muslim rule.
In 635 CE, the region, including Jerusalem, was conquered by the Arabs and was to remain under Muslim control for the next 1300 years. Control of the region transferred between the Umayyads, Abbasids, and Crusaders throughout the next six centuries, before being conquered by the Mamluk Sultanate, in 1260. In 1516, the region was conquered by the Ottoman Empire, and remained under Turkish rule until the end of the First World War when Britain defeated the Ottoman forces and set up a military administration across the former Ottoman Syria. The territory was divided under the mandate system and the area which included modern day Israel named Mandatory Palestine.
Zionism and the British mandate.
Since the Diaspora, some Jews have aspired to return to "Zion" and the "Land of Israel", though the amount of effort that should be spent towards such an aim was a matter of dispute. The hopes and yearnings of Jews living in exile were articulated in the Hebrew Bible, and is an important theme of the Jewish belief system. After the Jews were expelled from Spain in 1492, some communities settled in Palestine. During the 16th century, Jewish communities struck roots in the Four Holy Cities—Jerusalem, Tiberias, Hebron, and Safed—and in 1697, Rabbi Yehuda Hachasid led a group of 1,500 Jews to Jerusalem. In the second half of the 18th century, Eastern European opponents of Hasidism, known as the Perushim, settled in Palestine.
The first wave of modern Jewish migration to Ottoman-ruled Palestine, known as the First Aliyah, began in 1881, as Jews fled pogroms in Eastern Europe. Although the Zionist movement already existed in practice, Austro-Hungarian journalist Theodor Herzl is credited with founding political Zionism, a movement which sought to establish a Jewish state in the Land of Israel, by elevating the Jewish Question to the international plane. In 1896, Herzl published "Der Judenstaat" ("The State of the Jews"), offering his vision of a future Jewish state; the following year he presided over the first World Zionist Congress.
The Jewish Legion, a group primarily of Zionist volunteers, assisted in the British conquest of Palestine in 1917. Arab opposition to British rule and Jewish immigration led to the 1920 Palestine riots and the formation of a Jewish militia known as the Haganah (meaning "The Defense" in Hebrew), from which the Irgun and Lehi, or "Stern Gang", paramilitary groups later split off. In 1922, the League of Nations granted Britain a mandate over Palestine under terms similar to the Balfour Declaration. The population of the area at this time was predominantly Arab and Muslim, with Jews accounting for about 11% of the population.
The Third (1919–1923) and Fourth Aliyahs (1924–1929) brought an additional 100,000 Jews to Palestine. Finally, the rise of Nazism and the increasing persecution of Jews in the 1930s led to the Fifth Aliyah, with an influx of a quarter of a million Jews. This was a major cause of the Arab revolt of 1936–1939 and led the British to introduce restrictions on Jewish immigration to Palestine with the White Paper of 1939. With countries around the world turning away Jewish refugees fleeing the Holocaust, a clandestine movement known as Aliyah Bet was organized to bring Jews to Palestine. By the end of World War II, the Jewish population of Palestine had increased to 33% of the total population.
Independence and first years.
After World War II, Britain found itself in fierce conflict with the Jewish community, as the Haganah joined Irgun and Lehi in an armed struggle against British rule. At the same time, hundreds of thousands of Jewish Holocaust survivors and refugees sought a new life far from their destroyed communities in Europe. The Yishuv attempted to bring these refugees to Palestine but many were turned away or rounded up and placed in detention camps by the British. In 1947, the British government announced it would withdraw from Mandatory Palestine, stating it was unable to arrive at a solution acceptable to both Arabs and Jews.
On 15 May 1947, the General Assembly of the newly formed United Nations resolved that a committee, United Nations Special Committee on Palestine (UNSCOP), be created "to prepare for consideration at the next regular session of the Assembly a report on the question of Palestine". In the Report of the Committee dated 3 September 1947 to the UN General Assembly, the majority of the Committee in Chapter VI proposed a plan to replace the British Mandate with "an independent Arab State, an independent Jewish State, and the City of Jerusalem..., the last to be under an International Trusteeship System". On 29 November 1947, the General Assembly adopted a resolution recommending the adoption and implementation of the "Plan of Partition with Economic Union" as Resolution 181 (II). The Plan attached to the resolution was essentially that proposed by the majority of the Committee in the Report of 3 September 1947.
The Jewish Agency, which was the recognized representative of the Jewish community, accepted the plan, but the Arab League and Arab Higher Committee of Palestine rejected it. On 1 December 1947, the Arab Higher Committee proclaimed a three-day strike, and Arab bands began attacking Jewish targets. The Jews were initially on the defensive as civil war broke out, but gradually moved onto the offensive. The Palestinian Arab economy collapsed and 250,000 Palestinian-Arabs fled or were expelled.
On 14 May 1948, the day before the expiration of the British Mandate, David Ben-Gurion, the head of the Jewish Agency, declared "the establishment of a Jewish state in Eretz-Israel, to be known as the State of Israel". The only reference in the text of the Declaration to the borders of the new state is the use of the term, "Eretz-Israel".
The following day, the armies of four Arab countries—Egypt, Syria, Transjordan and Iraq—entered what had been British Mandate Palestine, launching the 1948 Arab–Israeli War; Saudi Arabia sent a military contingent to operate under Egyptian command; Yemen declared war but did not take military action. In a cablegram of the same day from the Secretary-General of the League of Arab States to the UN Secretary-General, the Arab states gave a justification for this "intervention". After a year of fighting, a ceasefire was declared and temporary borders, known as the Green Line, were established. Jordan annexed what became known as the West Bank and East Jerusalem, and Egypt took control of the Gaza Strip. The United Nations estimated that more than 700,000 Palestinians were expelled or fled during the conflict from what would become Israel.
Israel was admitted as a member of the United Nations by majority vote on 11 May 1949. In the early years of the state, the Labor Zionist movement led by Prime Minister David Ben-Gurion dominated Israeli politics. These years were marked by an influx of Holocaust survivors and Jews from Arab lands, many of whom faced persecution and expulsion from their original countries. Consequently, the population of Israel rose from 800,000 to two million between 1948 and 1958. During this period, food, clothes and furniture had to be rationed in what became known as the Austerity Period. Between 1948–1970, approximately 1,151,029 Jewish refugees relocated to Israel. Some arrived as refugees with no possessions and were housed in temporary camps known as "ma'abarot"; by 1952, over 200,000 immigrants were living in these tent cities. The need to solve the crisis led Ben-Gurion to sign a reparations agreement with West Germany that triggered mass protests by Jews angered at the idea that Israel could accept monetary compensation for the Holocaust.
In the 1950s, Israel was frequently attacked by Palestinian fedayeen, mainly from the Egyptian-occupied Gaza Strip, leading to several Israeli counter-raids. In 1950 Egypt closed the Suez Canal to Israeli shipping and tensions mounted as armed clashes took place along Israel's borders. In 1956, Israel joined a secret alliance with Great Britain and France aimed at regaining control of the Suez Canal, which the Egyptians had nationalized (see the Suez Crisis). Israel overran the Sinai Peninsula but was pressured to withdraw by the United Nations in return for guarantees of Israeli shipping rights in the Red Sea and the Canal.
In the early 1960s, Israel captured Nazi war criminal Adolf Eichmann in Argentina and brought him to Israel for trial. The trial had a major impact on public awareness of the Holocaust. Eichmann remains the only person ever to be executed by an Israeli court.
Conflicts and peace treaties.
Since 1964, Arab countries were trying to divert the headwaters of the Jordan river to deprive Israel of water resources, provoking tensions with Syria and Lebanon. Arab nationalists led by Egyptian President Gamal Abdel Nasser refused to recognize Israel, and called for its destruction. By 1966, Israeli-Arab relations had deteriorated to the point of actual battles taking place between Israeli and Arab forces. In 1967, Egypt expelled UN peacekeepers, stationed in the Sinai Peninsula since 1957, and announced a partial blockade of Israel's access to the Red Sea. In May 1967 a number of Arab states began to mobilize their forces. Israel saw these actions as a "casus belli". On 5 June 1967, Israel launched a pre-emptive strike against Egypt, Jordan, Syria and Iraq. In a Six-Day War, Israeli military superiority was clearly demonstrated against their more numerous Arab foes. Israel succeeded in capturing the West Bank, the Gaza Strip, Sinai Peninsula and the Golan Heights. Jerusalem's boundaries were enlarged, incorporating East Jerusalem, and the 1949 Green Line became the administrative boundary between Israel and the occupied territories.
Following the war, Israel faced much internal resistance from the Arab Palestinians and Egyptian hostilities in the Sinai. Most important among the various Palestinian and Arab groups was the Palestinian Liberation Organization (PLO), established in 1964, which initially committed itself to "armed struggle as the only way to liberate the homeland". In the late 1960s and early 1970s, Palestinian groups launched a wave of attacks against Israeli and Jewish targets around the world, including a massacre of Israeli athletes at the 1972 Summer Olympics in Munich. The Israeli government responded with an assassination campaign against the organizers, a bombing and a raid on the PLO headquarters in Lebanon.
On 6 October 1973, as Jews were observing Yom Kippur, the Egyptian and Syrian armies launched a surprise attack against Israeli forces in the Sinai Peninsula and Golan Heights. The war ended on 26 October with Israel successfully repelling Egyptian and Syrian forces but suffering significant losses. An internal inquiry exonerated the government of responsibility for failures before and during the war, but public anger forced Prime Minister Golda Meir to resign.
In July 1976 Israeli commandos carried out a rescue mission which succeeded in rescuing 102 hostages who were being held by Palestinian guerillas at Entebbe International Airport close to Kampala, Uganda.
The 1977 Knesset elections marked a major turning point in Israeli political history as Menachem Begin's Likud party took control from the Labor Party. Later that year, Egyptian President Anwar El Sadat made a trip to Israel and spoke before the Knesset in what was the first recognition of Israel by an Arab head of state. In the two years that followed, Sadat and Begin signed the Camp David Accords (1978) and the Israel–Egypt Peace Treaty (1979). Israel withdrew from the Sinai Peninsula and agreed to enter negotiations over an autonomy for Palestinians in the West Bank and the Gaza Strip.
On 11 March 1978, a PLO guerilla raid from Lebanon led to the Coastal Road Massacre, in which 38 Israeli civilians were killed and 71 injured. Israel responded by launching an invasion of southern Lebanon to destroy the PLO bases south of the Litani River. Most PLO fighters withdrew, but Israel was able to secure southern Lebanon until a UN force and the Lebanese army could take over. However, the PLO soon resumed its policy of attacks against Israel. In the next few years the PLO infiltrated back south and kept up a sporadic shelling across the border. Israel carried out numerous retaliatory attacks by air and on the ground.
Meanwhile, Begin's government actively encouraged Israelis to settle in the occupied West Bank, leading to increasing friction with the Palestinians in that area. The Basic Law: Jerusalem, the Capital of Israel, passed in 1980, was believed by some to reaffirm Israel's 1967 annexation of Jerusalem by government decree and reignited international controversy over the status of the city. However, there has never been an Israeli government act which defined what it considers to be the extent of the territory of Israel and no act which specifically included East Jerusalem therein. The position of the majority of UN member states is reflected in numerous resolutions declaring that actions taken by Israel to settle its citizens in the West Bank, and impose its laws and administration on East Jerusalem are illegal and have no validity.
On 7 June 1981, the Israeli air force destroyed Iraq's sole nuclear power plant, which was under construction just outside Baghdad.
Following a series of PLO attacks in 1982, Israel invaded Lebanon once again to destroy the bases from which the PLO launched attacks and missiles into northern Israel. In the first six days of fighting, the Israelis destroyed the military forces of the PLO in Lebanon and decisively defeated the Syrians. An Israeli government inquiry – the Kahan Commission – would later hold Begin, Sharon and several Israeli generals as indirectly responsible for the Sabra and Shatila massacres. In 1985 Israel responded to a Palestinian terrorist attack in Cyprus by bombing the PLO headquarters in Tunis. Israel withdrew from most of Lebanon in 1986, but maintained a borderland buffer zone in southern Lebanon until 2000. The First Intifada, a Palestinian uprising against Israeli rule, broke out in 1987 with waves of uncoordinated demonstrations and violence occurring in the occupied West Bank and Gaza. Over the following six years, the Intifada became more organised and included economic and cultural measures aimed at disrupting the Israeli occupation. More than a thousand people were killed in the violence, many of them stone-throwing youths. Responding to continuing PLO guerilla raids into northern Israel, Israel launched another punitive raid into southern Lebanon in 1988. Amid rising tensions over the Kuwait crisis, Israeli border guards fired into a rioting Palestinian crowd near the Al-Aqsa mosque in Jerusalem. 20 people were killed and some 150 injured. During the 1991 Gulf War, the PLO supported Saddam Hussein and Iraqi Scud missile attacks against Israel. Despite public outrage, Israel heeded US calls to refrain from hitting back and did not participate in that war.
In 1992, Yitzhak Rabin became Prime Minister following an election in which his party called for compromise with Israel's neighbors. The following year, Shimon Peres on behalf of Israel, and Mahmoud Abbas for the PLO, signed the Oslo Accords, which gave the Palestinian National Authority the right to govern parts of the West Bank and the Gaza Strip. The PLO also recognized Israel's right to exist and pledged an end to terrorism. In 1994, the Israel–Jordan Treaty of Peace was signed, making Jordan the second Arab country to normalize relations with Israel. Arab public support for the Accords was damaged by the continuation of Israeli settlements and checkpoints, and the deterioration of economic conditions. Israeli public support for the Accords waned as Israel was struck by Palestinian suicide attacks. Finally, while leaving a peace rally in November 1995, Yitzhak Rabin was assassinated by a far-right-wing Jew who opposed the Accords.
At the end of the 1990s, Israel, under the leadership of Benjamin Netanyahu, withdrew from Hebron, and signed the Wye River Memorandum, giving greater control to the Palestinian National Authority. Ehud Barak, elected Prime Minister in 1999, began the new millennium by and conducting negotiations with Palestinian Authority Chairman Yasser Arafat and U.S. President Bill Clinton at the 2000 Camp David Summit. During the summit, Barak offered a plan for the establishment of a Palestinian state, but Yasser Arafat rejected it. After the collapse of the talks and a controversial visit by Likud leader Ariel Sharon to the Temple Mount, the Second Intifada began. Sharon became prime minister in a 2001 special election. During his tenure, Sharon carried out his plan to unilaterally withdraw from the Gaza Strip and also spearheaded the construction of the Israeli West Bank barrier, defeating the Intifada.
In July 2006, a Hezbollah artillery assault on Israel's northern border communities and a cross-border abduction of two Israeli soldiers precipitated the month-long Second Lebanon War.Escalation of hostilities in Lebanon and in Israel since Hizbollah's attack on Israel on 12 July 2006 On 6 September 2007, Israeli Air Force destroyed a nuclear reactor in Syria. In May 2008, Israel confirmed it had been discussing a peace treaty with Syria for a year, with Turkey as a go-between. However, at the end of the year, Israel entered another conflict as a ceasefire between Hamas and Israel collapsed. The Gaza War lasted three weeks and ended after Israel announced a unilateral ceasefire. Hamas announced its own ceasefire, with its own conditions of complete withdrawal and opening of border crossings. Despite neither the rocket launchings nor Israeli retaliatory strikes having completely stopped, the fragile ceasefire remained in order.
Geography and climate.
Israel is at the eastern end of the Mediterranean Sea, bounded by Lebanon to the north, Syria to the northeast, Jordan to the east, and Egypt to the southwest. It lies between latitudes 29° and 34° N, and longitudes 34° and 36° E.
The sovereign territory of Israel, excluding all territories captured by Israel during the 1967 Six-Day War, is approximately in area, of which two percent is water. However Israel is so narrow that the exclusive economic zone in the Mediterranean is double the land area of the country. The total area under Israeli law, when including East Jerusalem and the Golan Heights, is , and the total area under Israeli control, including the military-controlled and partially Palestinian-governed territory of the West Bank, is . Despite its small size, Israel is home to a variety of geographic features, from the Negev desert in the south to the inland fertile Jezreel Valley, mountain ranges of the Galilee, Carmel and toward the Golan in the north. The Israeli Coastal Plain on the shores of the Mediterranean is home to seventy percent of the nation's population. East of the central highlands lies the Jordan Rift Valley, which forms a small part of the Great Rift Valley.
The Jordan River runs along the Jordan Rift Valley, from Mount Hermon through the Hulah Valley and the Sea of Galilee to the Dead Sea, the lowest point on the surface of the Earth. Further south is the Arabah, ending with the Gulf of Eilat, part of the Red Sea. Unique to Israel and the Sinai Peninsula are makhteshim, or erosion cirques. The largest makhtesh in the world is Ramon Crater in the Negev, which measures . A report on the environmental status of the Mediterranean basin states that Israel has the largest number of plant species per square meter of all the countries in the basin.
Temperatures in Israel vary widely, especially during the winter. The more mountainous regions can be windy, cold, and sometimes snowy; Jerusalem usually receives at least one snowfall each year. Meanwhile, coastal cities, such as Tel Aviv and Haifa, have a typical Mediterranean climate with cool, rainy winters and long, hot summers. The area of Beersheba and the Northern Negev has a semi-arid climate with hot summers, cool winters and fewer rainy days than the Mediterranean climate. The Southern Negev and the Arava areas have desert climate with very hot and dry summers, and mild winters with few days of rain. The highest temperature in the continent of Asia () was recorded in 1942 at Tirat Zvi kibbutz in the northern Jordan river valley.
From May to September, rain in Israel is rare. With scarce water resources, Israel has developed various water-saving technologies, including drip irrigation. Israelis also take advantage of the considerable sunlight available for solar energy, making Israel the leading nation in solar energy use per capita (practically every house uses solar panels for water heating).
Four different phytogeographic regions exist in Israel, due to the country's location between the temperate and the tropical zones, bordering the Mediterranean Sea in the west and the desert in the east. For this reason the flora and fauna of Israel is extremely diverse. There are 2,867 known species of plants found in Israel. Of these, at least 253 species are introduced and non-native. There are 380 Israeli nature reserves.
Politics.
Israel operates under a parliamentary system as a democratic republic with universal suffrage. A member of parliament supported by a parliamentary majority becomes the prime minister—usually this is the chair of the largest party. The prime minister is the head of government and head of the cabinet. Israel is governed by a 120-member parliament, known as the Knesset. Membership of the Knesset is based on proportional representation of political parties, with a 2% electoral threshold, which in practice has resulted in coalition governments.
Parliamentary elections are scheduled every four years, but unstable coalitions or a no-confidence vote by the Knesset can dissolve a government earlier. The Basic Laws of Israel function as an uncodified constitution. In 2003, the Knesset began to draft an official constitution based on these laws. The president of Israel is head of state, with limited and largely ceremonial duties.
Legal system.
Israel has a three-tier court system. At the lowest level are magistrate courts, situated in most cities across the country. Above them are district courts, serving both as appellate courts and courts of first instance; they are situated in five of Israel's six districts. The third and highest tier is the Supreme Court, located in Jerusalem; it serves a dual role as the highest court of appeals and the High Court of Justice. In the latter role, the Supreme Court rules as a court of first instance, allowing individuals, both citizens and non-citizens, to petition against the decisions of state authorities. Although Israel supports the goals of the International Criminal Court, it has not ratified the Rome Statute, citing concerns about the ability of the court to remain free from political impartiality.
Israel's legal system combines three legal traditions: English common law, civil law, and Jewish law. It is based on the principle of "stare decisis" (precedent) and is an adversarial system, where the parties in the suit bring evidence before the court. Court cases are decided by professional judges rather than juries. Marriage and divorce are under the jurisdiction of the religious courts: Jewish, Muslim, Druze, and Christian. A committee of Knesset members, Supreme Court justices, and Israeli Bar members carries out the election of judges. Administration of Israel's courts (both the "General" courts and the Labor Courts) is carried by the Administration of Courts, situated in Jerusalem. Both General and Labor courts are paperless courts: the storage of court files, as well as court decisions, are conducted electronically.
Israel's seeks to defend human rights and liberties in Israel. Israel is the only country in the region ranked "Free" by Freedom House based on the level of civil liberties and political rights; the "Palestinian Authority-Administered Territories" was ranked "Not Free." In 2012, Israel proper was ranked 92nd according to Reporters Without Borders' Press Freedom Index – the highest ranking in the region.
Administrative divisions.
The State of Israel is divided into six main administrative districts, known as "mehozot" (מחוזות; singular: "mahoz") – Center, Haifa, Jerusalem, North, Southern, and Tel Aviv Districts, as well as the Judea and Samaria Area in the West Bank. Districts are further divided into fifteen sub-districts known as "nafot" (נפות; singular: "nafa"), which are themselves partitioned into fifty natural regions.
For statistical purposes, the country is divided into three metropolitan areas: Tel Aviv metropolitan area (population 3,206,400), Haifa metropolitan area (population 1,021,000), and Beer Sheva metropolitan area (population 559,700). Israel's largest municipality, both in population and area, is Jerusalem with 773,800 residents in an area of 126 square kilometers (49 sq mi) (in 2009).
Israeli government statistics on Jerusalem include the population and area of East Jerusalem, which is widely recognized as part of the Palestinian territories under Israeli occupation. Tel Aviv, Haifa, and Rishon LeZion rank as Israel's next most populous cities, with populations of 393,900, 265,600, and 227,600 respectively.
Israeli-occupied territories.
In 1967, as a result of the Six-Day War, Israel gained control of the West Bank (Judaea and Samaria), East Jerusalem, the Gaza strip and the Golan Heights. Israel also took control of the Sinai Peninsula, but returned it to Egypt as part of the 1979 Israel–Egypt Peace Treaty.
Following Israel's capture of these territories, settlements consisting of Israeli citizens were established within each of them. Israel applied civilian law to the Golan Heights and East Jerusalem, incorporating them into its sovereign territory and granting their inhabitants permanent residency status and the choice to apply for citizenship. In contrast, the West Bank has remained under military occupation, and Palestinians in this area cannot become citizens. The Gaza Strip is independent of Israel with no Israeli military or civilian presence, but Israel continues to maintain control of its airspace and waters. The Gaza Strip and the West Bank are seen by the Palestinians and most of the international community as the site of a future Palestinian state. The UN Security Council has declared the annexation of the Golan Heights and East Jerusalem to be "null and void" and continues to view the territories as occupied. The International Court of Justice, principal judicial organ of the United Nations, asserted, in its 2004 advisory opinion on the legality of the construction of the Israeli West Bank barrier, that the lands captured by Israel in the Six-Day War, including East Jerusalem, are occupied territory.
The status of East Jerusalem in any future peace settlement has at times been a difficult hurdle in negotiations between Israeli governments and representatives of the Palestinians, as Israel views it as its sovereign territory, as well as part of its capital. Most negotiations relating to the territories have been on the basis of United Nations Security Council Resolution 242, which emphasises "the inadmissibility of the acquisition of territory by war", and calls on Israel to withdraw from occupied territories in return for normalization of relations with Arab states, a principle known as "Land for peace".
The West Bank was annexed by Jordan in 1948, following the Arab rejection of the UN decision to create two states in Palestine. Only Britain recognized this annexation and Jordan has since ceded its claim to the territory to the PLO. The West Bank was occupied by Israel in 1967 during the Six-Day War. The population are mainly Arab Palestinians, including refugees of the 1948 Arab-Israeli War. From their occupation in 1967 until 1993, the Palestinians living in these territories were under Israeli military administration. Since the Israel–PLO letters of recognition, most of the Palestinian population and cities have been under the internal jurisdiction of the Palestinian Authority, and only partial Israeli military control, although Israel has on several occasions redeployed its troops and reinstated full military administration during periods of unrest. In response to increasing attacks as part of the Second Intifada, the Israeli government started to construct the Israeli West Bank barrier. When completed, approximately 13% of the Barrier will be constructed on the Green Line or in Israel with 87% inside the West Bank.
The Gaza Strip was occupied by Egypt from 1948 to 1967 and then by Israel after 1967. In 2005, as part of Israel's unilateral disengagement plan, Israel removed all of its settlers and forces from the territory. Israel does not consider the Gaza Strip to be occupied territory and declared it a "foreign territory". That view has been disputed by numerous international humanitarian organizations and various bodies of the United Nations. Following June 2007, when Hamas assumed power in the Gaza Strip, Israel tightened its control of the Gaza crossings along its border, as well as by sea and air, and prevented persons from entering and exiting the area except for isolated cases it deemed humanitarian. Gaza has a border with Egypt and an agreement between Israel, the European Union and the PA governed how border crossing would take place (it was monitored by European observers). Egypt adhered to this agreement under Mubarak and prevented access to Gaza until April 2011 when it announced it was opening its border with Gaza.
Foreign relations.
Israel maintains diplomatic relations with 157 countries and has 100 diplomatic missions around the world. Only three members of the Arab League have normalized relations with Israel: Egypt and Jordan signed peace treaties in 1979 and 1994, respectively, and Mauritania opted for full diplomatic relations with Israel in 1999. Despite the peace treaty between Israel and Egypt, Israel is still widely considered an enemy country among Egyptians. Under Israeli law, Lebanon, Syria, Saudi Arabia, Iraq, and Yemen are enemy countries and Israeli citizens may not visit them without permission from the Ministry of the Interior.
The Soviet Union and the United States were the first two countries to recognize the State of Israel, having declared recognition roughly simultaneously. The United States may regard Israel as its primary ally in the Middle East, based on "common democratic values, religious affinities, and security interests". The United States has provided $68 billion in military assistance and $32 billion in grants to Israel since 1967, under the Foreign Assistance Act (period beginning 1962), more than any other country for that period until 2003. Their bilateral relations are multidimensional and the United States is the principal proponent of the Arab-Israeli peace process. The United States and Israeli views differ on some issues, such as the Golan Heights, Jerusalem, and settlements.
India established full diplomatic ties with Israel in 1992 and has fostered a strong military, technological and cultural partnership with the country since then. According to an international opinion survey conducted in 2009 on behalf of the Israeli Foreign Ministry, India is the most pro-Israel country in the world. India is the largest customer of Israeli military equipment and Israel is the second-largest military partner of India after the Russian Federation. India is also the third-largest Asian economic partner of Israel and the two countries enjoy extensive space technology ties. India became the top source market for Israel from Asia in 2010 with 41,000 tourist arrivals in that year.
Germany's strong ties with Israel include cooperation on scientific and educational endeavors and the two states remain strong economic and military partners. Under the reparations agreement, Germany had paid 25 billion euros in reparations to the Israeli state and individual Israeli holocaust survivors. The UK has kept full diplomatic relations with Israel since its formation having had two visits from heads of state in 2007. Relations between the two countries were also made stronger by former prime minister Tony Blair's efforts for a two state resolution. The UK is seen as having a "natural" relationship with Israel on account of the British Mandate for Palestine. Iran had diplomatic relations with Israel under the Pahlavi dynasty but withdrew its recognition of Israel during the Islamic Revolution.
Although Turkey and Israel did not establish full diplomatic relations until 1991, Turkey has cooperated with the State since its recognition of Israel in 1949. Turkey's ties to the other Muslim-majority nations in the region have at times resulted in pressure from Arab and Muslim states to temper its relationship with Israel. Relations between Turkey and Israel took a downturn after the Gaza War and Israel's raid of the Gaza flotilla. IHH, which organized the flotilla, is a Turkish charity that some believe has ties to Hamas and Al-Qaeda.
Relation between Israel and Greece have improved since 1995 due to the decline of Israeli-Turkish relations. The two countries have a defence cooperation agreement and in 2010, the Israeli Air Force hosted Greece’s Hellenic Air Force in a joint exercise at the Uvda base. The joint Cyprus-Israel oil and gas explorations centered on the Leviathan gas field are also an important factor for Greece, given its strong links with Cyprus. Israel is the second largest importer of Greek products in the Middle East. In 2010, the Greek Prime minister George Papandreou made an official visit to Israel after many years, in order to improve bilateral relations between the two countries.
Israel and Cyprus have a number of bilateral agreements and many official visits have taken place between the two countries. The countries have ties on energy, agricultural, military and tourism matters. The prospects of joint exploitation of oil and gas fields off Cyprus, as well as cooperation in the world's longest sub-sea electric power cable has strengthened relations between the countries.
Azerbaijan is one of the few majority Muslim countries to develop bilateral strategic and economic relations with Israel. The relationship includes cooperation in trade and security matters and cultural and educational exchanges. Azerbaijan supplies Israel with a substantial amount of its oil needs, and Israel has helped modernize the Armed Forces of Azerbaijan. In the spring of 2012, the two countries reportedly concluded an arms deal worth $1.6 billion. In 2005, Azerbaijan was Israel's fifth largest trading partner.
In Africa, Ethiopia is Israel's main and closest ally in the continent due to common political, religious and security interests. Israel provides expertise to Ethiopia on irrigation projects and thousands of Ethiopian Jews (Beta Israel) live in Israel.
As a result of the 2009 Gaza War, Mauritania, Qatar, Bolivia, and Venezuela suspended political and economic ties with Israel.
Military.
Israel has the highest ratio of defense spending to GDP and as a percentage of the budget of all developed countries. The Israel Defense Forces is the sole military wing of the Israeli security forces, and is headed by its Chief of General Staff, the "Ramatkal", subordinate to the Cabinet. The IDF consist of the army, air force and navy. It was founded during the 1948 Arab–Israeli War by consolidating paramilitary organizations—chiefly the Haganah—that preceded the establishment of the state. The IDF also draws upon the resources of the Military Intelligence Directorate ("Aman"), which works with the Mossad and Shabak. The Israel Defense Forces have been involved in several major wars and border conflicts in its short history, making it one of the most battle-trained armed forces in the world.
Most Israelis are drafted into the military at the age of 18. Men serve three years and women two to three years. Following mandatory service, Israeli men join the reserve forces and usually do up to several weeks of reserve duty every year until their forties. Most women are exempt from reserve duty. Arab citizens of Israel (except the Druze) and those engaged in full-time religious studies are exempt from military service, although the exemption of yeshiva students has been a source of contention in Israeli society for many years. An alternative for those who receive exemptions on various grounds is "Sherut Leumi", or national service, which involves a program of service in hospitals, schools and other social welfare frameworks. As a result of its conscription program, the IDF maintains approximately 176,500 active troops and an additional 445,000 reservists.
The nation's military relies heavily on high-tech weapons systems designed and manufactured in Israel as well as some foreign imports. Since 1967, the United States has been a particularly notable foreign contributor of military aid to Israel: the US is expected to provide the country with $3.15 billion per year from 2013–2018. The Arrow missile is one of the world's few operational anti-ballistic missile systems.
Since the Yom Kippur War, Israel has developed a network of reconnaissance satellites. The success of the "Ofeq" program has made Israel one of seven countries capable of launching such satellites. Since its establishment, Israel has spent a significant portion of its gross domestic product on defense. In 1984, for example, the country spent 24% of its GDP on defense. By 2006, that figure had dropped to 7.3%.
Israel is widely believed to possess nuclear weapons as well as chemical and biological weapons of mass destruction. Israel has not signed the Treaty on the Non-Proliferation of Nuclear Weapons and maintains a policy of deliberate ambiguity toward its nuclear capabilities. Since the Gulf War in 1991, when Israel was attacked by Iraqi Scud missiles, all homes in Israel are required to have a reinforced security room impermeable to chemical and biological substances.
The IDF has also been deployed on humanitarian missions, usually involving rescue workers and medical personnel, along with relief workers and body identifiers from ZAKA and the Israel Police. After the 2010 Haiti earthquake, a rescue team was dispatched to Haiti, which consisted of 40 doctors, 20 nurses and rescue workers, and two rescue planes loaded with medical equipment and a field hospital with X-ray equipment, intensive care units, and operating rooms. Other recent recipients of aid include Japan (a medical team after the 2011 tsunami), Congo 2008, Sri Lanka 2005 (tsunami), India and El Salvador 2001 (earthquakes), Ethiopia 2000, Turkey 1998 (earthquake), Kosovo 1999 (refugees) and Rwanda 1994 (refugees).
Israel is consistently rated very low in the Global Peace Index, ranking 145th out of 153 nations for peacefulness in 2011.
Economy.
Israel is considered one of the most advanced countries in Southwest Asia in economic and industrial development. In 2010, it joined the OECD. The country is ranked 3rd in the region on the World Bank's Ease of Doing Business Index as well as in the World Economic Forum's Global Competitiveness Report. It has the second-largest number of startup companies in the world (after the United States) and the largest number of NASDAQ-listed companies outside North America.
In 2010, Israel ranked 17th among of the world's most economically developed nations, according to IMD's World Competitiveness Yearbook. The Israeli economy was ranked first as the world's most durable economy in the face of crises, and was also ranked first in the rate of research and development center investments.
The Bank of Israel was ranked first among central banks for its efficient functioning, up from the 8th place in 2009. Israel was also ranked as the worldwide leader in its supply of skilled manpower. The Bank of Israel holds $78 billion of foreign-exchange reserves.
Despite limited natural resources, intensive development of the agricultural and industrial sectors over the past decades has made Israel largely self-sufficient in food production, apart from grains and beef. Other major imports to Israel, totaling $47.8 billion in 2006, include fossil fuels, raw materials, and military equipment. Leading exports include electronics, software, computerized systems, communications technology, medical equipment, pharmaceuticals, fruits, chemicals, military technology, and cut diamonds; in 2006, Israeli exports reached $42.86 billion, and by 2010 they had reached $80.5 billion a year.
Israel is a leading country in the development of solar energy. Israel is a global leader in water conservation and geothermal energy, and its development of cutting-edge technologies in software, communications and the life sciences have evoked comparisons with Silicon Valley. According to the OECD, Israel is also ranked 1st in the world in expenditure on Research and Development (R&D) as a percentage of GDP. Intel and Microsoft built their first overseas research and development centers in Israel, and other high-tech multi-national corporations, such as IBM, Cisco Systems, and Motorola, have opened facilities in the country. In July 2007, U.S. billionaire Warren Buffett's Berkshire Hathaway bought an Israeli company Iscar, its first non-U.S. acquisition, for $4 billion. Since the 1970s, Israel has received military aid from the United States, as well as economic assistance in the form of loan guarantees, which now account for roughly half of Israel's external debt. Israel has one of the lowest external debts in the developed world, and is a net lender in terms of net external debt (the total value of assets vs. liabilities in debt instruments owed abroad), which stood at a surplus of US$58.7 billion.
Days of working time in Israel are Sunday through Thursday (for 5 a days 'week'), or Friday (for 6 a days 'week'). In observance of "Shabbat", in places where Friday is a work day and the majority of population is Jewish, Friday is a "short day", usually lasting till 14:00 in the winter, or 16:00 in the summer. Several proposals have been raised to adjust the work week with the majority of the world, and make Sunday a non-working day, while extending working time of other days, and/or replacing Friday with Sunday as a work day
Tourism.
Tourism, especially religious tourism, is an important industry in Israel, with the country's temperate climate, beaches, archaeological and historical sites, and unique geography also drawing tourists. Israel's security problems have taken their toll on the industry, but the number of incoming tourists is on the rebound. In 2008, over 3 million tourists visited Israel. Israel has the highest number of museums per capita in the world.
Transport.
Israel has 18,096 kilometers (11,244 mi) of paved roads, and 2.4 million motor vehicles. The number of motor vehicles per 1,000 persons was 324, relatively low with respect to developed countries. Israel has 5,715 buses on scheduled routes, operated by several carriers, the largest of which is Egged, serving most of the country. Railways stretch across 949 kilometers (590 mi) and are operated solely by government-owned Israel Railways (All figures are for 2008). Following major investments beginning in the early-to-mid 1990s, the number of train passengers per year has grown from 2.5 million in 1990, to 35 million in 2008; railways are also used to transport 6.8 million tons of cargo, per year.
Israel is served by two international airports, Ben Gurion International Airport, the country's main hub for international air travel near Tel Aviv-Yafo, Ovda Airport in the south, as well as several small domestic airports. Ben Gurion, Israel's largest airport, handled over 12.1 million passengers in 2010.
On the Mediterranean coast, Haifa Port is the country's oldest and largest port, while Ashdod Port is one of the few deep water ports in the world built on the open sea. In addition to these, the smaller Port of Eilat is situated on the Red Sea, and is used mainly for trading with Far East countries.
Science and technology.
Israel's eight public universities are subsidized by the state. The Hebrew University of Jerusalem, Israel's oldest university, houses the Jewish National and University Library, the world's largest repository of books on Jewish subjects. The Hebrew University is consistently ranked among world's 100 top universities by the prestigious ARWU academic ranking. Other major universities in the country include the Technion, the Weizmann Institute of Science, Tel Aviv University (TAU), Bar-Ilan University, the University of Haifa, The Open University and Ben-Gurion University of the Negev. Israel's seven research universities (excluding the Open University) are consistently ranked among top 500 in the world. Israel has produced six Nobel Prize-winning scientists since 2002 and publishes among the most scientific papers per capita of any country in the world.
Israel has embraced solar energy; its engineers are on the cutting edge of solar energy technology and its solar companies work on projects around the world. Over 90% of Israeli homes use solar energy for hot water, the highest per capita in the world. According to government figures, the country saves 8% of its electricity consumption per year because of its solar energy use in heating. The high annual incident solar irradiance at its geographic latitude creates ideal conditions for what is an internationally renowned solar research and development industry in the Negev Desert.
Israel is one of the world's technological leaders in water technology. In 2011, its water technology industry was worth around $2 billion a year with annual exports of products and services in the tens of millions of dollars. The ongoing shortage of water in the country has spurred innovation in water conservation techniques, and a substantial agricultural modernisation, drip irrigation, was invented in Israel. Israel is also at the technological forefront of desalination and water recycling. The Ashkelon seawater reverse osmosis (SWRO) plant, the largest in the world, was voted 'Desalination Plant of the Year' in the Global Water Awards in 2006. Israel hosts an annual Water Technology Exhibition and Conference (WaTec) that attracts thousands of people from across the world. By the end of 2013, 85 percent of the country's water consumption will be from reverse osmosis. As a result of innovations in reverse osmosis technology, Israel is set to become a net exporter of water in the coming years.
Israel has led the world in stem-cell research papers per capita since 2000. In addition, Israeli universities are among 100 top world universities in mathematics (Hebrew University, TAU and Technion), physics (TAU, Hebrew University and Weizmann Institute of Science), chemistry (Technion and Weizmann Institute of Science), computer science (Weizmann Institute of Science, Technion, Hebrew University, TAU and BIU) and economics (Hebrew University and TAU).
Israel has a modern electric car infrastructure involving a countrywide network of recharging stations to facilitate the charging and exchange of car batteries. It is thought that this will lower Israel's oil dependency and lower the fuel costs of hundreds of Israel's motorists that use cars powered only by electric batteries. The Israeli model is being studied by several countries and being implemented in Denmark and Australia.
In 2009 Israel was ranked 2nd among 20 top countries in space sciences by Thomson Reuters agency. Since 1988 Israel Aerospace Industries have indigenously designed and built at least 13 commercial, research and spy satellites. Most were launched to orbit from Israeli air force base "Palmachim" by the Shavit space launch vehicle. Some of Israel's satellites are ranked among the world's most advanced space systems. In 2003, Ilan Ramon became Israel's first astronaut, serving as payload specialist of STS-107, the fatal mission of the Space Shuttle "Columbia".
Demographics.
In 2012, Israel's population was an estimated 7,933,200 people, of whom 5,978,600 are Jews. Arab citizens of Israel comprise 20.6% of the country's total population.
Over the last decade, large numbers of migrant workers from Romania, Thailand, China, Africa and South America have settled in Israel. Exact figures are unknown, as many of them are living in the country illegally, but estimates run in the region of 203,000. , approximately 60,000 African migrants have entered Israel.
Retention of Israel's population since 1948 is about even or greater, when compared to other countries with mass immigration. Emigration from Israel (yerida) to other countries, primarily the United States and Canada, is described by demographers as modest, but is often cited by Israeli government ministries as a major threat to Israel's future.
, over 300,000 Israeli citizens live in West Bank settlements such as Ma'ale Adumim and Ariel, and communities that predated the establishment of the State but were re-established after the Six-Day War, in cities such as Hebron and Gush Etzion. 18,000 Israelis live in Golan Heights settlements. In 2011, there were 250,000 Jews living in East Jerusalem. The total number of Israeli settlers is over 500,000 (6.5% of the Israeli population). Approximately 7,800 Israelis lived in settlements in the Gaza Strip, until they were evacuated by the government as part of its 2005 disengagement plan.
Israel was established as a homeland for the Jewish people and is often referred to as a Jewish state. The country's Law of Return grants all Jews and those of Jewish lineage the right to Israeli citizenship. Over three quarters, or 75.5%, of the population are Jews from a diversity of Jewish backgrounds. Around 4% of Israelis (300,000), ethnically defined as "others", are Russian-descendants of Jewish origin or family who are not Jewish according to rabbinical law, but were eligible for Israeli citizenship under the Law of Return. Approximately 68% of Israeli Jews are Israeli-born, 22% are immigrants from Europe and the Americas, and 10% are immigrants from Asia and Africa (including the Arab World). Jews who left or fled Arab and Muslim countries and their descendants, known as "Mizrahi" and "Sephardi" Jews, constitute approximately 50% of Jewish Israelis. Jews from Eastern Europe and the former Soviet Union and their Israeli-born descendants, or "Ashkenazi" Jews, form most of the rest of the Jewish population.
Languages.
Israel has two official languages, Hebrew and Arabic. Hebrew is the primary language of the state and is spoken by the majority of the population, and Arabic is spoken by the Arab minority. Many Israelis communicate reasonably well in English, as many television programs are broadcast in this language and English is taught from the early grades in elementary school. As a country of immigrants, many languages can be heard on the streets. Due to mass immigration from the former Soviet Union and Ethiopia (some 120,000 Ethiopian Jews live in Israel), Russian and Amharic are widely spoken. Between 1990 and 1994, the Russian immigration increased Israel's population by twelve percent. More than one million Russian-speaking immigrants arrived in Israel from the former Soviet Union states between 1990 and 2004. French is spoken by around 700,000 Israelis, mostly originating from France and North Africa (see Maghrebi Jews).
Religion.
Israel and the Palestinian territories comprise the major part of the Holy Land, a region of significant importances to all Abrahamic religions – Jews, Christians, Muslims and Baha'is.
The religious affiliation of Israeli Jews varies widely: a social survey for those over the age of 20 indicates that 55% say they are "traditional", while 20% consider themselves "secular Jews", 17% define themselves as "Religious Zionists"; 8% define themselves as "Haredi Jews". While the ultra-Orthodox, or Haredim, represented only 5% of Israel's population in 1990, they are expected to represent more than one-fifth of Israel's Jewish population by 2028.
Making up 16% of the population, Muslims constitute Israel's largest religious minority. About 2% of the population are Christian and 1.5% are Druze. The Christian population primarily comprises Arab Christians, but also includes post-Soviet immigrants and the Foreign Laborers of multinational origins and followers of Messianic Judaism, considered by most Christians and Jews to be a form of Christianity. Members of many other religious groups, including Buddhists and Hindus, maintain a presence in Israel, albeit in small numbers. Out of more than one million immigrants from the former Soviet Union in Israel, about 300,000 are considered not Jewish by the Orthodox rabbinate.
The city of Jerusalem is of special importance to Jews, Muslims and Christians as it is the home of sites that are pivotal to their religious beliefs, such as the Israeli-controlled Old City that incorporates the Western Wall and the Temple Mount, the Al-Aqsa Mosque and the Church of the Holy Sepulchre.
Other locations of religious importance in Israel are Nazareth (holy in Christianity as the site of the Annunciation of Mary), Tiberias and Safed (two of the Four Holy Cities in Judaism), the White Mosque in Ramla (holy in Islam as the shrine of the prophet Saleh), and the Church of Saint George in Lod (holy in Christianity and Islam as the tomb of Saint George or Al Khidr).
A number of other religious landmarks are located in the West Bank, among them Joseph's tomb in Shechem, the birthplace of Jesus and Rachel's Tomb in Bethlehem, and the Cave of the Patriarchs in Hebron.
The administrative center of the Bahá'í Faith and the Shrine of the Báb are located at the Bahá'í World Centre in Haifa and the leader of the faith is buried in Acre. Apart from maintenance staff, there is no Bahá'í community in Israel, although it is a destination for pilgrimages. Bahá'í staff in Israel do not teach their faith to Israelis following strict policy.
Education.
Israel has a school life expectancy of 15.5 years and a literacy rate of 97.1% according to the United Nations. The State Education Law, passed in 1953, established five types of schools: state secular, state religious, ultra orthodox, communal settlement schools, and Arab schools. The public secular is the largest school group, and is attended by the majority of Jewish and non-Arab pupils in Israel. Most Arabs send their children to schools where Arabic is the language of instruction.
Education is compulsory in Israel for children between the ages of three and eighteen. Schooling is divided into three tiers – primary school (grades 1–6), middle school (grades 7–9), and high school (grades 10–12) – culminating with "Bagrut" matriculation exams. Proficiency in core subjects such as mathematics, the Hebrew language, Hebrew and general literature, the English language, history, Biblical scripture and civics is necessary to receive a Bagrut certificate. In Arab, Christian and Druze schools, the exam on Biblical studies is replaced by an exam on Muslim, Christian or Druze heritage. In 2003, over half of all Israeli twelfth graders earned a matriculation certificate. The Hebrew University of Jerusalem and Tel Aviv University are ranked among the world's top 100 universities by Times Higher Education magazine. Israel ranks third in the world in the number of academic degrees per capita (20 percent of the population).
Culture.
Israel's diverse culture stems from the diversity of the population: Jews from around the world have brought their cultural and religious traditions with them, creating a melting pot of Jewish customs and beliefs. Israel is the only country in the world where life revolves around the Hebrew calendar. Work and school holidays are determined by the Jewish holidays, and the official day of rest is Saturday, the Jewish Sabbath. Israel's substantial Arab minority has also left its imprint on Israeli culture in such spheres as architecture, music, and cuisine.
Literature.
Israeli literature is primarily poetry and prose written in Hebrew, as part of the renaissance of Hebrew as a spoken language since the mid-19th century, although a small body of literature is published in other languages, such as English. By law, two copies of all printed matter published in Israel must be deposited in the Jewish National and University Library at the Hebrew University of Jerusalem. In 2001, the law was amended to include audio and video recordings, and other non-print media. In 2006, 85 percent of the 8,000 books transferred to the library were in Hebrew.
The Hebrew Book Week (He: ) is held each June and features book fairs, public readings, and appearances by Israeli authors around the country. During the week, Israel's top literary award, the Sapir Prize, is presented.
In 1966, Shmuel Yosef Agnon shared the Nobel Prize in Literature with German Jewish author Nelly Sachs. Leading Israeli poets have been Yehuda Amichai, Nathan Alterman and Rachel Bluwstein. Internationally famous contemporary Israeli novelists include Amos Oz and David Grossman.
Israel has also been the home of two leading Palestinian poets and writers: Emile Habibi, whose novel "The Secret Life of Saeed the Pessoptimist", and other writings, won him the Israel prize for Arabic literature; and Mahmoud Darwish, considered by many to be "the Palestinian national poet." Darwish was born and raised in northern Israel, but lived his adult life abroad after joining the Palestine Liberation Organization.
Music and dance.
Israeli music contains musical influences from all over the world; Sephardic music, Hasidic melodies, Belly dancing music, Greek music, jazz, and pop rock are all part of the music scene.
The nation's canonical folk songs, known as "Songs of the Land of Israel," deal with the experiences of the pioneers in building the Jewish homeland. The Hora (הורה) circle dance introduced by early Jewish settlers was originally popular in the Kibbutzim and outlying communities. It became a symbol of the Zionist reconstruction and of the ability to experience joy amidst austerity. It now plays a significant role in modern Israeli folk dancing and is regularly performed at weddings and other celebrations, and in group dances throughout Israel.
Modern dance in Israel is a flourishing field, and several Israeli choreographers such as Ohad Naharin, Rami Beer, Barak Marshall and many others, are considered to be among the most versatile and original international creators working today. Famous Israeli companies include the Batsheva Dance Company and the Kibbutz Contemporary Dance Company.
Among Israel's world-renowned orchestras is the Israel Philharmonic Orchestra, which has been in operation for over seventy years and today performs more than two hundred concerts each year. Israel has also produced many musicians of note, some achieving international stardom. Itzhak Perlman, Pinchas Zukerman and Ofra Haza are among the internationally acclaimed musicians born in Israel.
Israel has participated in the Eurovision Song Contest nearly every year since 1973, winning the competition three times and hosting it twice. Eilat has hosted its own international music festival, the Red Sea Jazz Festival, every summer since 1987.
Israel is home to many Palestinian musicians, including internationally acclaimed oud and violin virtuoso Taiseer Elias, singer Amal Murkus, and brothers Samir and Wissam Joubran. Israeli Arab musicians have achieved fame beyond Israel's borders: Elias and Murkus frequently play to audiences in Europe and America, and oud player Darwish Darwish (Prof. Elias's student) was awarded first prize in the all-Arab oud contest in Egypt in 2003. The Jerusalem Academy of Music and Dance has an advanced degree program, headed by Taiseer Elias, in Arabic music.
Cinema and theatre.
Ten Israeli films have been final nominees for Best Foreign Language Film at the Academy Awards since the establishment of Israel. The 2009 movie "Ajami" was the third consecutive nomination of an Israeli film.
Continuing the strong theatrical traditions of the Yiddish theater in Eastern Europe, Israel maintains a vibrant theatre scene. Founded in 1918, Habima Theatre in Tel Aviv is Israel's oldest repertory theater company and national theater.
Palestinian Israeli filmmakers have made a number of films, some of them controversial, dealing with the Arab-Israel conflict and the status of Palestinians within Israel. Mohammed Bakri's 2002 film "Jenin, Jenin", about an Israeli military action in the West Bank town of Jenin, won the Best Film award at the Carthage International film festival, but was widely criticized within Israel for allegedly distorting the story of the battle. "Ajami", a 2009 film about violence and discrimination in a mixed Jewish-Arab neighborhood in south Tel Aviv-Jaffa, was written and directed jointly by Palestinain Scandar Copti and Jewish Israeli Yaron Shani. It won an honorable mention in the Cannes Film Festival. "The Syrian Bride", about a Druze wedding between families on opposite sides of the Israel–Syria ceasefire line in the Golan Heights, was directed by a Jewish Israeli (Eran Riklis), but had an almost completely Druze cast.
Museums.
The Israel Museum in Jerusalem is one of Israel's most important cultural institutions and houses the Dead Sea scrolls, along with an extensive collection of Judaica and European art. Israel's national Holocaust museum, Yad Vashem, is the world central archive of Holocaust-related information. Beth Hatefutsoth (the Diaspora Museum), on the campus of Tel Aviv University, is an interactive museum devoted to the history of Jewish communities around the world.
Apart from the major museums in large cities, there are high-quality artspaces in many towns and "kibbutzim". "Mishkan Le'Omanut" on Kibbutz Ein Harod Meuhad is the largest art museum in the north of the country.
Several museums are devoted to Islamic culture, including the Rockefeller Museum, which specializes in archaeological remains from the Ottoman and other periods of Middle East history, and the L. A. Mayer Institute for Islamic Art, also in Jerusalem.
Sports.
The Maccabiah Games, an Olympic-style event for Jewish athletes and Israeli athletes, was inaugurated in the 1930s, and has been held every four years since then. In 1964 Israel hosted and won the Asian Nations Cup; in 1970 the Israel national football team managed to qualify to the FIFA World Cup, which is still considered the biggest achievement of Israeli football.
Israel was excluded from the 1978 Asian Games due to Arab pressure on the organizers. The exclusion left Israel in limbo and it ceased competing in Asian competitions. In 1994, UEFA agreed to admit Israel and all Israeli sporting organizations now compete in Europe.
The most popular spectator sports in Israel are association football and basketball. The Israeli Premier League is the country's premier football league, and the Israeli Basketball Super League is the premier basketball league. Maccabi Haifa, Maccabi Tel Aviv, Hapoel Tel Aviv and Beitar Jerusalem are the largest sports clubs. Maccabi Tel Aviv, Maccabi Haifa and Hapoel Tel Aviv have competed in the UEFA Champions League and Hapoel Tel Aviv reached the UEFA Cup quarter-finals. Maccabi Tel Aviv B.C. has won the European championship in basketball five times. Israeli tennis champion Shahar Pe'er ranked 11th in the world on 31 January 2011.
Chess is a leading sport in Israel and is enjoyed by people of all ages. There are many Israeli grandmasters and Israeli chess players have won a number of youth world championships. Israel stages an annual international championship and hosted the World Team Chess Championship in 2005. The Ministry of Education and the World Chess Federation agreed upon a project of teaching chess within Israeli schools, and it has been introduced into the curriculum of some schools. The city of Beersheba has become a national chess center, with the game being taught in the city's kindergartens. Owing partly to Soviet immigration, it is home to the largest number of chess grandmasters of any city in the world.
The Israeli chess team won the silver medal at the 2008 Chess Olympiad and the bronze, coming in third among 148 teams, at the 2010 Olympiad.
Israeli grandmaster Boris Gelfand won the Chess World Cup in 2009 and the 2011 Candidates Tournament for the right to challenge the world champion. He only lost the World Chess Championship 2012 to reigning world champion Anand after a speed-chess tie breaker.
Krav Maga, a martial art developed by Jewish ghetto defenders during the struggle against fascism in Europe, is used by the Israeli security forces and police. Its effectiveness and practical approach to self-defense, have won it widespread admiration and adherence round the world.
To date, Israel has won seven Olympic medals since its first win in 1992, including a gold medal in windsurfing at the 2004 Summer Olympics. Israel has won over 100 gold medals in the Paralympic Games and is ranked about 15th in the all-time medal count. The 1968 Summer Paralympics were hosted by Israel.
Cuisine.
Israeli cuisine includes local dishes as well as dishes brought to the country by Jewish immigrants from around the world. Since the establishment of the State in 1948, and particularly since the late 1970s, an Israeli fusion cuisine has developed.
Israeli cuisine has adopted, and continues to adapt, elements of various styles of Jewish cuisine, particularly the Mizrahi, Sephardic, and Ashkenazi styles of cooking, along with Moroccan Jewish, Iraqi Jewish, Ethiopian Jewish, Indian Jewish, Iranian Jewish and Yemeni Jewish influences. It incorporates many foods traditionally eaten in the Arab, Middle Eastern and Mediterranean cuisines, such as "falafel", "hummus", "shakshouka", "couscous", and "za'atar", which have become common ingredients in Israeli cuisine.

Legality of cannabis
The legality of cannabis concerns laws which in most countries regulate the use, possession, cultivation, transfer, and trade in cannabis. Since the beginning of widespread cannabis prohibition around the mid 20th century, most countries have not re-legalized it for personal use, although more than 10 countries tolerate (or have decriminalized) its use and/or its cultivation in limited quantities. Medicinal use of cannabis is legal in a number of countries, including Canada, the Czech Republic, Israel and 16 states of the United States (though it is illegal, according to U.S. federal law). In the Netherlands cannabis is formally illegal, but Justice guidelines show that no action is to be taken in case of possession of a small amount and sale under strict conditions.
Some countries have laws that are not as vigorously prosecuted as others but, apart from the countries that offer access to medical marijuana, most countries have various penalties ranging from lenient to very severe. Some infractions are taken more seriously in some countries than others in regard to the cultivation, use, possession or transfer of cannabis for recreational use. A few jurisdictions have lessened penalties for possession of small quantities of cannabis, making it punishable by confiscation and a fine, rather than imprisonment. Some jurisdictions/drug courts use mandatory treatment programs for young or frequent users, with freedom from narcotic drugs as the goal and a few jurisdictions permit cannabis use for medicinal purposes. There are also changes in a more restrictive direction as in Canada. Drug tests to detect cannabis are increasingly common in many countries and have resulted in jail sentences and people losing their jobs. However, simple possession can carry long jail sentences in some countries, particularly in parts of East Asia, such as Malaysia where the sale of cannabis may lead to a sentence of life in prison or even execution.
Under the name cannabis, 19th century medical practitioners sold the drug (usually as a tincture), popularizing the word amongst English-speakers. It was rumoured that Queen Victoria's menstrual pains were treated with cannabis; her personal physician, Sir John Russell Reynolds, wrote an article in the first edition of the medical journal "The Lancet" about the benefits of cannabis. In 1894, the "Report of the Indian Hemp Drugs Commission" commissioned by the UK Secretary of State and the government of India, was instrumental in the decision not to criminalize the drug in those countries. From 1860 different states in the United States started to implement regulations for sales of "Cannabis sativa." In 1925 a change of the International Opium Convention banned exportation of "Indian hemp" to countries that have prohibited its use. Importing countries were required to issue certificates approving the importation and stating that the shipment was to be used "exclusively for medical or scientific purposes".
In 1937 the F.D. Roosevelt administration crafted the 1937 Marihuana Tax Act, the first US national law making cannabis possession illegal via an unpayable tax on the drug.
The name "marijuana" (Mexican Spanish "marihuana", "mariguana") is associated almost exclusively with the plant's psychoactive use. The term is now well known in English largely due to the efforts of American drug prohibitionists during the 1920s and 1930s. Mexico itself had passed prohibition in 1925, following the International Opium Convention. The prohibitionists deliberately used a Mexican name for cannabis in order to turn the US populace against the idea that it should be legal by playing to negative attitudes towards that nationality. ("See 1937 Marihuana Tax Act"). Those who demonized the drug by calling it marihuana omitted the fact that the "deadly marihuana" was identical to "Cannabis sativa", which had at the time a reputation for pharmaceutical safety. However, due to variations in the potency of the preparations, "Cannabis indica" in the 1930s had lost most of its former popularity as a medical drug.
Many advocate legalization of cannabis, believing that it will eliminate the illegal trade and associated crime, yield a valuable tax-source and reduce policing costs. Cannabis is now available as a palliative agent, in Canada, with a medical prescription. In 1969, only 16% percent of voters in the USA supported legalization, according to a poll by Gallup. According to the same source, that number had risen to 36% by 2005. More recent polling indicates that the number has risen even further since the financial crisis of 2007-2009: in 2009, between 46% and 56% of US voters would support legalization. In Europe has the development turned in the opposite direction in the Netherlands where the last few years certain strains of cannabis with higher concentrations of THC and drug tourism have challenged the former policy with legal sales of cannabis and led to more restrictive approach; e.g. ban of all sales of cannabis to tourists in coffee shops from the end of 2011 onward.
Detection and the law.
As cannabis and its cultivation are illegal in most parts of the world, considerable resources and effort are committed to both interdiction and counter-interdiction of cultivation. Thermal imaging helicopters (to detect hot lighting), inspection of trash (to find evidence of cultivation including waste plant matter), examination of credit card purchases (to find purchases from hydroponic equipment vendors), and analysis of energy bills (to detect energy usage patterns of marijuana growers), have been used in prosecutions. In the US, thermal imaging cameras are considered to violate civil liberties embedded in the United States Constitution. This has resulted in significant changes to domestic growing trends and has increased availability. 
=By country=
Australia.
It is illegal to use, possess, grow or sell cannabis in Australia, but penalties differ for each state or territory. In the Australian Capital Territory, South Australia, Western Australia and the Northern Territory there are differing degrees of decriminalization for minor offenses. In New South Wales, Victoria, Tasmania and Queensland the possession of cannabis is considered a criminal offense.
In the ACT a civil penalty system for possession of small amounts of cannabis was introduced in 1993. Possession of up to 25g or two non-hydroponic plants attracts a fine of A$100 to be paid within 60 days. Offenders can choose to attend the Alcohol and Drug Program. In South Australia possession of small quantities of cannabis is decriminalized attracting fines similar to a parking ticket. However, penalties for cultivation of marijuana have become harsher since the widespread advent of large scale cultivation. There is much confusion on the subject, with many people believing that possession of a certain amount is legal.
The Northern Territory, since 1996, adults found in possession of up to 50 grams of marijuana, one gram of hash oil, 10 grams of hash or cannabis seed, or two non-hydroponic plants can be fined $200 with 28 days to expiate rather than face a criminal charge.
In Western Australia, as of August 2011: A person found in possession of 10 grams or less of cannabis will receive a Cannabis Intervention Requirement notice to attend a mandatory one on one counselling session. Quantities larger than this attract a penalty of A$2000 or two years in jail, or both. A person found in possession of more than 100g of cannabis would be deemed to have that quantity for supply and could face a penalty of A$20,000 or two years in jail. It is also illegal for cannabis smoking implements to be displayed in shops or sold, with fines up to A$10,000 for sales to adults and jail for up to two years or a fine of up to A$24,000 for selling to minors. Opposing political sides have accused the government of changing the laws to appear tough on drugs in response to an increased public fear of clandestine drug labs following a number of them exploding in suburban areas.
In New South Wales, Queensland, Victoria and Tasmania first-time offences for possession and use of small amounts of cannabis or cannabis products (e.g. cannabis oil or resin) can be dealt with by diversion programs, which aim to divert offenders into education, assessment and treatment programs. In New South Wales if you are caught with up to 15g of cannabis, at the police's discretion, up to two cautions can be issued. In Tasmania up to three cautions can be issued for possession of up to 50g of cannabis, with a hierarchy of referrals for treatment then intervention for each caution. Similarly in Victoria up to 50g of cannabis will attract a caution and the opportunity to attend an education program; only two cautions will be dealt out. In Queensland possession of cannabis or any schedule 1 or 2 drug specified in the Drugs Misuse Regulation 1987 carries a maximum prison sentence of 15 years, however, jail terms for minor possessions are very rare. Possession of smoking utensils or anything used to smoke cannabis is also a criminal offense in Queensland. However, under the Police Powers and Responsibilities Act 2000 a person who admits to carrying not more than 50 grams (and is not committing any other offence) must be offered a drug diversion program.
With the rapid expansion in hydroponic cannabis cultivation, the Australian Drug Misuse and Trafficking Act (1985) was amended in 2006, reducing the amount of cannabis grown indoors under hydroponic conditions that qualifies as a 'commercial quantity' or as a 'large quantity'.
Bangladesh.
Cannabis is grown throughout the Bengal region, which is currently split between Bangladesh and the Indian state of West Bengal. In both parts of Bengal, cannabis (Bengali: গাঁজা "gãja") has been widely used for centuries. Cannabis was banned in Northern Bangladesh in 1984. As of now, cannabis is still illegally available in the underground markets of Bangladesh, and is in somewhat common use among people. It is known as ganja or hashish, and drunk in bhang.
Belgium.
Individual or solo use by adults has the lowest priority to police and government instances, if the use doesn't cause any problems to their environment. This basically means only the use in public places, possession of more than 3 grams, or the sale of the drug are pursued in court. However, the use in the presence of minors is strictly forbidden. The cultivation of one female cannabis plant for personal use is decriminalized.
Other than cultivating a female cannabis plant, there is no legal way of obtaining cannabis.
Brazil.
On June 15, 2011, the eight ministers of Brazil's Supreme Court (STF) that participated in the trial were unanimous in free demonstrations for the legalization of drugs, such as the Marcha da Maconha (, "Marijuana Walk") in Brazil (part of the Global Marijuana March), in which they decided that the demonstrations are an exercise of freedom of expression and not incitement to crime, as argued judges who have banned the march in the past. The discussion of the "Marcha da Maconha" reached the Supreme Court in June 2009 when the Deputy Attorney General of the Republic Deborah Duprat filed the claim of breach of fundamental precept, ADPF 187. In the lawsuit, the attorney states that the legal prohibition of the demonstrations in favor of marijuana and other narcotics have been based on misinterpretation of the Criminal Code. She said that it is "wrong" to say that the realization of these events are an "apology to crime".
The practice of smoking marijuana was bought to Brazil from its African slaves, and with the eugenic positivist intellectual and political status quo of the Western civilization in the early 20th century, its use was deemed as a signal of decadence by its stigmatized use as a recreational drug of the poor, the rural people and the Afro-Brazilian. It was deemed to cause serious harm both to the physical and to the mental health of smokers and blamed recreational cannabis use for multiple problems such as "idiocy, violence, unbridled sensuality, madness and racial degeneration". In fact, little knowledge about cannabis was generalized, with many likening its effects to those produced by opium, and also considered to be immensely addictive in similar levels. Its association with the counterculture and left-wing youths during the highly anti-Communist military dictatorship, initially a strong ally of the United States' government, fortified its negative perceptions both by the authorities and the masses, and many myths relative to marijuana and its users circulate up to day, even being the topic by far not a taboo as it was in the past decades.
Nevertheless, since the neoliberal centre-right government of Fernando Henrique Cardoso (1994–2002), position strengthened in the so-called "Era Lula" (2003–2010), individual marijuana use by adults started to have no major importance to police and government instances – though not, ironically (since the country has major crime problems with drug dealers), its domestic cultivation for own consumption. One can see and smell people smoking the so-called "maconha" openly in Brazil's Centre-Southern half as well as in the Northeastern states, and recreational use of cannabis in private became more accepted among large sectors of the middle classes since the early 1990s. The academic milieu is no exception and, today, a sizeable minority of Brazilian University lecturers, students and researchers smoke cannabis.
Canada.
Cannabis is currently illegal in Canada, with exceptions only for medical usage. The marijuana laws in Canada are currently under review as an Ontario court judge deemed the laws unconstitutional thus giving the government 90 days, as of April 13, 2011, to revamp the law. As of June 22, 2011, the prosecutor and federal government was granted a stay on the 90 day deadline, extending it by an additional 6 months, pushing the deadline back to November.
In October 2007, Prime Minister Harper announced a new National Anti-Drug Strategy. A proposed Bill would have dealers facing one-year mandatory prison sentences if they’re operating for organized crime purposes, or if violence is involved. Dealers would also face a two-year mandatory jail sentence if they’re selling to youth, or dealing drugs near a school or an area normally frequented by youth. Additionally, people in Canada who run a large marijuana grow operation of at least 500 plants would risk facing a mandatory two-year jail term. Maximum penalties for producing cannabis would increase from 7 to 14 years.
Perhaps the biggest proposed policy change is mandatory six-month sentencing for those growing as little as one marijuana plant for the purposes of trafficking. If the Bill passes, this is also likely to be felt by small-time distributors who are not linked to the ring of organized crime, and who usually face no more than a fine if caught.
The Conservative Party now holds a majority government, with the NDP (New Democratic Party) as the official opposition. Previous attempts by past Liberal Governments in the late 1990s and early 2000s to decriminalize marijuana for personal use have failed to become law.
On September 20, 2011, the newly-elected Conservative majority government re-introduced an omnibus crime bill, Bill C-10. (formely known as the "Safe Streets and Communities Act") The bill combines more than 10 different pieces of previously unpassed criminal legislation, as well as proposing to amend the Criminal Code of Canada with respect to drug offences. This bill specifically targets growers, dealers and consumers of cannabis, introducing mandatory minimum sentences for the cultivation of modest amounts of cannabis. This proposed legislation has come under substantial criticism and scrutiny from opposition party MPs as well as numerous experts and intellectuals, particularly from the US. The position of the Harper government is notably in defiance of credible evidence of the harm caused by the decades of drug prohibition, contrary to many US states (most notably Texas), which are relaxing drug laws. The provinces of Ontario, Quebec and British Columbia have expressed their opposition towards bearing the likely great costs and other effects the bill will bring, particularly since the government has not yet disclosed the costs as well as some other information associated with the proposed legislation.
Costa Rica.
Cannabis is used in Costa Rica, in spite of it being illegal. Police officers might not arrest someone unless the amount carried is seemingly for distribution or selling. Much of it is grown in the rain forest reserves, as no person can be prosecuted for that, but more potent strains are grown hydroponically in small grow-ops in San José. There is a small percentage coming from Jamaica, but the most popular kind is grown locally. Laura Chinchilla, the president of Costa Rica (2010–2014) stated -"It must be approached very rigorously based on empiric evidence and the experiences other countries have had when boarding widely the concept of legalization [...]" after a meeting with José Miguel Insulza, Secretary General of the Organization of American States, regarding the fight against hard drug smuggling from Colombia to the USA.
Czech Republic.
In 1938 production and possession (but not the consumption) of drugs became a punishable crime in Czechoslovakia. The law did not distinguish between different types of drugs. Until the Velvet Revolution (1989) narcotics were only a minor problem in Czech society. A law from 1992 stopped criminalization of drug possession for personal use. This changed in 1998, ""possession of more than a small amount of drugs"" (the amount was not defined) became a criminal offence again. The limits were defined later through internal research by Czech law enforcers making the possession of under 15 grams not a crime. The owner could be fined. Consumption was not punishable. Enforcement of the law was spotty and sometimes inconsistent. The impact of this change was reviewed by a Czech Government report which found the availability of illicit drugs did not decrease and there had been no reduction in prevalence of illicit drug use as a result of the 1998 re-criminalisation. 
Possession of “larger than a small amount” of marijuana can result in a jail sentence of up to one year. For other illicit drugs, the sentence is two years. Trafficking offenses carry stiffer sentences. The Czech Republic now joins Portugal as a European country that has decriminalized drug possession.
Young people are the most frequent users of marijuana: a poll from 2007 estimated that almost 30% of Czechs under 24 had tried it. In 2007 the Supreme Court of the Czech Republic ruled that mere cultivation of hemp should not be punishable unless production of the drug is proven; an officer from the Czech anti-drug unit was quoted saying that "this decision is irrelevant to our work." As of 2007 several initiatives towards either decriminalization of marijuana or creating a more tolerated category of "soft drugs."
Denmark.
In Denmark, despite a general public tolerance towards cannabis for private consumption, cannabis remains illegal. Possession of less than 10 grams (.35 oz) cannabis is punishable by a fine of 2000DKK (370USD) for a first-time offender, 3000DKK for a second-time offender, and 4000DKK for a third-time offender. However, possession of small quantities of cannabis, or public use, often is tolerated by the police and people involved in it go away with a verbal warning.
Denmark's capital, Copenhagen is home to a self-proclaimed autonomous neighborhood called Christiania, where cannabis and hashish are both sold openly. In a display of Denmark’s tolerance, this sale, which has fueled an alternative, freewheeling, culture in Christiania, was allowed largely unhindered until 2004, when sanctions were imposed to moderate it. Since 2004, a number of raids led by Danish authorities have led to unrest and tension between Christiania's residents and the Danish government.
In recent years, Copenhagen Municipality has been in favor of legalizing cannabis via state-run coffee-shops, in order to take over the control of the substance which is currently mostly supplied by criminal gangs. The proposal could make the city the first to fully legalise marijuana consumption, but it still has to be approved by the Folketing.
Estonia.
It is illegal to grow, possess or trade cannabis in Estonia. Consumption and possession in small amounts will lead to a fine. Larger amounts than 10 grams is considered trafficking and can lead to a maximum jail sentence of 5 years. Growing is illegal and can lead to a jail sentence, which can also be up to 5 years. Possession of seeds is legal, import and export is illegal.
Finland.
Possession, manufacture and use of cannabis products were prohibited by law in Finland in 1972. The parliamentary discussion and the following vote resulted in a stalemate, so the issue was resolved by drawing lots - which resulted in cannabinoid products becoming illegal.
In practice, possession or manufacture of cannabis products is considered to be a minor misdemeanor punishable by a minor fine (normally in the range of 60-500 euros). A supreme court decision of 2004 set up a "half a dozen" precedent: Cultivation of up to 6 plants for personal use is subject to the same penalties as personal use. The same applies to distribution and use within a "closed circle of users".
However, open distribution is generally punished very severely.
Aside from criminal penalties, users are often persecuted by welfare authorities on the pretext of child welfare (if the user has offspring); withdrawal of driving license is also commonplace.
In 2010 police first time used the law passed in 2006, which makes selling equipment for creating or growing drugs illegal. This resulted in closing of a gardening store Viherpeukku and 200 home searches through the customer register. The owners of Viherpeukku were charged for selling gardening equipment with knowledge, that they could be used in home growing of Cannabis. Some controversy rose from the home searches due many of them being done into legal chili farmers houses. Those charges were later dropped by the supreme court. The court saw that although the owners might have known that some of the fertilizers may have been used for cultivation of cannabis, they are not directly aiming at that market.
France.
In France the law prohibits "any presentation in a favorable light" of narcotic substances. Because of this law, organizations seeking to promote the decriminalization (as the collective information and research cannabis) are often put off-the-law and therefore risk severe penalties for incitement to drug use. In addition, a public body, MILDT (Interministerial Mission for the fight against drugs and addiction) informs extensively (website, brochures, etc..) On the hard drugs, placing cannabis in the midst of them, the compared to drugs such as cocaine or LSD.
Harm reduction is recognized by French law since 2004.
The law allows the movement of hemp (cannabis seeds) and their trade between the Member States of the European Free Trade Area (EU + Norway, Switzerland and Iceland).
Individuals can use hemp legal (with a certificate of compliance) for personal use only; their production, use and cultivation for commercial or professional activity is subject to authorization. These varieties are in fact non-psychoactive hemp. Individuals are required to retain certificates of conformity provided for sale of hemp or, failing that, the package that lists the references, in order to prove that the variety planted or owned is allowed. These varieties of cannabis on the list issued by the European Union, must be a decree that requires their permission.
All imports from countries not members of the European zone of free exchange can be performed by an importer licensed by the European Union.
The specificity of the French law led to a formal speech that can seem quite confusing to most other European nationals.
Besides the debate, French law bans the production, possession, sale, purchase and use of drugs, with penalties more or less severe depending on the act.
Traffic, that is to say, the possession, transport, supply, transfer or acquisition of narcotic, is punished with imprisonment for a term exceeding ten years or a fine up to 7.5 million euros
The simple use is normally punished by a maximum sentence of one year imprisonment or a fine of up to 3 750 euros. However, the consumer can simply be treated as a trafficker and therefore be liable to the same penalties. Indeed, cannabis necessarily implies to hold, and thus to buy or to produce, leaving free the judge to penalize the user on the basis of the Code of Public Health (use ) or the Penal Code (possession / trafficking / production). Specifically, the judge's decision will depend mainly seizures, history of the accused, etc..
As for production, even for personal use, it is punishable by a maximum sentence of twenty years'imprisonment or a fine of up to 7.5 million euros.
Germany.
While illegal, possession is generally not fined as long as a certain maximum amount (so called "geringe Menge" = English "small amount") is not exceeded. This maximum amount varies between 6 and 15 grams depending on which particular federal state the person is in and the potential amount of THC. The person caught will have the cannabis confiscated. Until 2002 one could have one's driver's license taken away because of cannabis possession, even if driving a car was not involved. This still happens today. "Use" of cannabis is not illegal in Germany.
Law enforcement in the city of Berlin and many other major cities currently places a very low priority on enforcement of cannabis laws; many people smoke openly in parks and bars throughout the central city.
Honduras.
In Honduras it is illegal to grow, plant, harvest, collect or possess cannabis. Violators can face 9 to 12 years in prison and a fine of 5,000 Lps. (US$265) to 25,000 Lps. (US$1,323). It is also illegal to own cannabis seeds. Traffickers can face 15 to 20 years in prison and a fine of 1,000,000 Lps. to 5,000,000 Lps.
Hong Kong.
Mainland China has a different legal system from Hong Kong.
India.
Often seen as the country where the plant originates from, throughout India it is illegal to grow, consume, or traffic cannabis since 1980, although there is a variation in penalties and enforcement according to the region. Usage of cannabis, also locally known as ganja (Sanskrit "ganjika") or "bhang" (when made into a drink) is common and not prosecuted throughout India. Sadhus openly smoke "ganja" and there are government licensed "bhang" shops in some regions. Furthermore, on the festival of Holi, cannabis is widely consumed in the open in its numerous forms. Charas, bhang and ganja (with seeds in it) are by far the most common forms of the drug in India; it is widely available and bhang and ganja are relatively inexpensive. Charas on the other hand is quite expensive and not available all over the country.
Ireland.
The most recent Misuse of Drugs (Designation) Order (S.I. No. 69/1998) lists cannabis, cannabis resin, cannabis and its derivatives as Schedule 1 drugs under the Misuse of Drugs Acts of 1977 and 1984. As a consequence manufacture, production, preparation, sale, supply, distribution and possession of cannabis is unlawful for any purpose, except under license from the Minister for Health.
The gardaí (Irish police) have a level of discretion when dealing with recreational cannabis users. To procure a conviction any cannabis seized has to be sent for analysis to the Garda Forensic Science Laboratory. This, along with the time needed to process the arrest, means that individual gardaí may decide not to arrest for small amounts,
Gardaí cannot arrest for simple possession if they are satisfied with the name and address of the offender. If there are enough drugs for sale or supply then Gardaí can arrest but the drug will be seized and the name and address of the individual will be taken. Possession of cannabis is an arrestable offense and, in 2003, 53 per cent of all drug confiscations and 70 per cent of all drug-related prosecutions were for cannabis. Trafficking or possession with intent to supply are serious offenses under Irish law.
There is no law against possession or sale of cannabis seeds. However, the growing of cannabis, even for medicinal benefits by genuine sufferers, is often treated harshly by the courts.
Various movements have been founded to legalize the drug, including an attempt at starting a cannabis legalization political party. Current Dáil member Luke Flanagan the former mayor of Roscommon is known for his long running campaign to legalise cannabis.
Israel.
Israel considers cannabis illegal; however, punishment is not severe for "personal use". The amount defined by the law as "for personal use" is 15g of marijuana and hashish. Due to the popularity of nargila in Israel, smoking using paraphernalia is a common sight at popular street cafes. Consequently, there is little social stigma attached to smoking using marijuana paraphernalia.
A medical marijuana program is existent; however patients must meet certain prerequisites. The categories include patients suffering from nausea induced by chemotherapy or those in the later stages of HIV. Trials have been conducted by the IDF for soldiers experiencing Posttraumatic stress disorder.
Italy.
Cannabis is illegal in Italy. Current legislation establishes quantitative limits of active ingredient: within those limits it is considered an administrative offense, over them it is regarded as pushing; whoever is considered to produce, sell, give or traffic every kind of substance is punished with 6–20 years of imprisonment. The years are reduced to 1-3 if the cultivation is for personal use only. However, jurisprudence is contradictory concerning growing for personal use. Medical use of substances prepared with marijuana are legal, if provided by medical prescription.
In July 2008, however, the Italian Supreme Court ruled that Rastafari may be allowed to possess greater amounts of cannabis legally, owing to its use by them as a sacrament.
Japan.
Penalties for possession or use of marijuana in Japan are severe, and convicted offenders can expect long jail sentences and fines. Possession of any amount, as little as 0.1 g, is punishable by jail sentence for up to 5 years and/or a fine of up to 30,000,000 yen (USD 344 790). Moreover, the defendant has to stay in police custody for at least a few weeks until a court decision is made.
Mexico.
On April 29, 2006, the Congress of Mexico passed a bill decriminalizing possession of small amounts of drugs intended for recreational use (up to 5g for marijuana). The new bill was hoped to relieve cartel-related crime as well as reduce drug-related arrests. A possibly unintended consequence would have been increased tourism. The move caused many in the US government to question Mexico's commitment to the War on Drugs. However, President Fox sent the legislation back, asking that the decriminalization be removed. This action showed the U.S. government's influence over the Mexican Government's decisions, sparking broad controversy over the bill. On October 14, 2008 a bill was proposed in Mexico City's Congress to legalize the consumption, possession and commerce of Marijuana. The bill states that only a person over 18 can have access to the drug, the places where marijuana is sold cannot also sell alcoholic drinks, and must be at least 1000 meters away from schools. The Government would issue special licenses for the distribution of marijuana in special places, similar to the legislation in the Netherlands.
On August 21, 2009, Mexico decriminalized "personal use" possession of up to 5 grams of marijuana, half a gram of cocaine, 50 milligrams of heroin, 40 milligrams for methamphetamine and 0.015 milligrams of LSD.
Nepal.
Marijuana was made illegal in Nepal in mid 70's but it was never really enforced. It is widely tolerated: in some parts of the country - mostly in rural areas - it is a way of life. Law against marijuana is rarely enforced although selling and transporting of hashish could be taken seriously. It has been a very popular destination for teenagers from countries like Israel for the same reason. 
Netherlands.
The possession/purchase of Cannabis is tolerated in small amounts. One can purchase cannabis in special shops (called "coffeeshops") if one is aged eighteen and over. Sale and purchase of cannabis anywhere else is illegal. Cultivation and wholesale of cannabis is likewise "tolerated" in small amounts (guidelines here are no more than five plants at home or the possession of 5 grams per adult max.). The tolerance guidelines appear in appendix of the Opium Act. The Opium Act states very clearly that every part of the hemp plant is banned except for the seeds – this is in accordance with many of the international treaties which the Netherlands have signed. It is for this reason Cannabis cannot be legalised in the Netherlands. Thus, it remains illegal but it is "tolerated." A recent court decision allowed a medical cannabis to avoid legal prosecution for possession of a small number of cannabis plants; however, the state is appealing the decision.
By 2009, 27 "coffee shops" selling cannabis in Rotterdam, Netherlands, all within 250 meters from schools must close down. This is nearly half of the coffeeshops that currently operate within its municipality. This is due to a new policy of city mayor Ivo Opstelten and the town council as a result of increased use of "soft drugs" among pupils.
Although outdoor use is prohibited this is also "tolerated" in most places.
Since January 2006 certain areas in the district "De Baarsjes" in Amsterdam have been declared official cannabis-free zones because of nuisance to inhabitants of the areas.
A special road sign was chosen out of 3 designs by Hans Bos to designate the areas.
This sign is not a recognized traffic sign however as it is not used outside of Amsterdam. For a while the municipality of Amsterdam sold the signs in an effort to curtail theft of traffic sign.
Higher concentrations of THC and drug tourism have challenged the current policy and led to a re-examination of the current approach; e.g. ban of all sales of cannabis to tourists in coffee shops from end of 2011 was proposed but currently only the border city of Maastricht has adopted the measure in order to test out its feasibility. In May 2011 decided the government that, starting in 2012, each coffee shop must operate like a private club with some 1,000 to 1,500 members. In order to qualify for a membership card, applicants have to be adult Dutch resident, membership will only to be allowed in one club. As of October, 2012 the Dutch government has scrapped the plan to require club membership, instead leaving it up to individual cities to decide who is allowed in their coffeshops.
New Zealand.
Possession of cannabis is illegal in New Zealand and can result in a fine of up to $500 or even a 3-month prison sentence (though the latter is rarely used). Anyone caught in possession of more than 28 grams of cannabis or 100 cannabis joints is classed as a dealer unless s/he can prove they are not. Cannabis is a class C drug in New Zealand, of which the penalty for dealing can result in a maximum prison sentence of 8 years under the New Zealand Misuse of Drugs Act 1975. There have been many public campaigns to decriminalise cannabis but so far none have succeeded.
Norway.
Any consumption, possession, buying or selling of cannabis is prohibited by law in Norway. Possession of up to 15 grams of cannabis will be punished by fines and anything above 15 grams can be punished by jail. Jail penalties may vary due to the amount of cannabis involved but they range from 6 months to 21 years.
There have recently been some political discussion whether or not to decriminalize marijuana, but so far (as of September 2011), only two political parties, the youth rally of the party Venstre (a liberal party) (the party itself states decriminalization) and The Greens state legalization or decriminalization as a goal. The political parties themselves are often internally split on this matter.
Peru.
In Peru usage of marijuana and possession of up to 8 grams is legal if no other drugs are carried.
Poland.
Cannabis is a controlled substance in Poland and its possession remains a criminal offence which can be
punished with imprisonment up to 3 years, or up to 8 years if the quantity in possession is considered 'large'
upon current law. No specific measurements are given to determine if an amount is to be considered 'small' or
'large'. Cultivation is also illegal and is threatened with up to 3 years of imprisonment and up to 8 years if
considered 'large'.
On 1st April 2011, the Polish parliament passed an amendment to the 2005 'Ustawa o przeciwdziałaniu narkomanii'
("Drug-dependence Counteract Law") to create a possibility of dropping prosecution for possession of small amounts
of drugs for personal use. The law introduces the possibility when a person caught possesses negligible amounts of
drugs for personal use only and the 'social harmfulness' of the case is considered to be low (i.e.-negligible).
Nonetheless the "small amounts" are still undetermined and a temporary detention and house search by the police continues to apply
in virtually every case.
At the same time the reformed law raised the maximum applicable penalties for possession of large amounts of
controlled substances (including cannabis) from 8 to 10 years of imprisonment and from 10 to 12 years for trafficking
of large amounts of controlled substances, among other related crimes. This implies hardening the law without
eliminating the ambiguous terms 'small amounts'/'large amounts'.
These amendments entered into legal force on 8th December 2011.
Portugal.
Personal consumption of cannabis is limited in the range of 2.5 gram marijuana, 0.5 gram hashish and 0.25 of hash oil per day. One may possess no more than 10 daily doses, otherwise it may be categorized as trafficking. The consumption still entails a penalty and fine. Cultivation however, is still completely illegal and even cultivation of a single plant is assumed to indicate involvement with trafficking. Possession of seeds is also illegal and despite there being several "head shops" or "grow shops" in Portugal, they, too, are forbidden to market cannabis seeds. At the same time, the number of grow shops has increased over the past few years, which seems to indicate that cultivation for personal use (in Portuguese: auto-cultivo) is becoming a more common practice. The 2006 Global Marijuana March () was celebrated for the first time in Lisbon and in 2007 both Lisbon and Porto celebrated it.
Romania.
Romania is a leader in hemp fiber, second only to China. However, possession of any quantity is punishable by law. Marijuana is considered high risk drug.
Law no. 143/2000 on combating illicit drug trafficking and use.
Chapter II sanctioning illicit trafficking and other operations with controlled substances national
Article 4. Cultivation, production, manufacture, testing, extraction, preparation, processing, purchase or possession of drugs for personal use, without law, shall be punished with imprisonment for 2–5 years. Decriminalization is proposed, but it doesn't have any political support (only 2 politicians are public known to be pro-decriminalization). The media is totally against any kind of pro-marijuana manifestations and therefore has a big impact on the population, as most of the mid-age and elderly people cannot distinguish between soft and hard drugs. The possession of seeds is not banned by law (it is not illegal, but neither legal), but if caught possessing seeds, they are usually confiscated without any other consequence.
Hashish is considered a high-risk drug, therefore even the possession of very small quantities is usually punished with jail time.
Russia.
Possession of up to 6 grams (dry weight) of cannabis or 2 grams of hashish is punishable by fine 4000-5000 roubles or administrative detention of up to 15 days (KoAP 6.8). Possession of more than this amount is punishable by prison term (UK 228). Growing more than 20 plants is punishable by prison term (UK 231).
Consumption is not criminalized, punishable, or technically subject to fining. In practice carrying any amount of illegal drugs is considering in court as "transfer" and is punishable by 4 to 8 years of imprisonment (UK 228.1). However, "intoxicated in public" fines (approximately $10) can be and are applied to those visibly under influence in public places. Note that, for intoxication in public fines to be applied, the offending substance does not have to be identified (or illegal, for that matter), and the fine is applied for being in a state of influence that is a potential or actual public nuisance, not for the fact of consumption.
South Africa.
The use, possession, cultivation and supply of cannabis remains illegal in the Republic of South Africa. South Africa was the first country to enact anti-cannabis legislation at the turn of the 20th century in 1908. NORML ZA (the National Organization for the Reform of Marijuana Laws in South Africa) is currently the largest cannabis advocacy group and claims to represent the country's estimated 2-3 million regular cannabis users. "The Dagga Couple" are gaining prominence for their bid to have cannabis 're-legalized' in the country's Constitutional Court. They have launched a nationwide campaign aimed at educating the public about the real reasons as to why cannabis was made illegal and why these laws should be overturned. The Dagga Couple are also producing a blueprint, which will indicate how the government could go about regulating a cannabis market in the event that it should be legalized
Spain.
In Spain the possession and use of cannabis in public places is classed as a misdemeanour under public health laws and is punishable by fines and confiscation. Trafficking is a criminal offense.
One can be denounced for doing so by neighbors or ill-wishers, and the burden is then effectively on the user or grower to prove that the material is for personal use only. 
In recent years a number of members' associations have been established throughout the country in an attempt to extend the boundary of the Spanish citizen's constitutional rights. In an association cannabis is grown and shared among the members. The association may not promote or be seen to encourage the use of cannabis and it must be a closed group for existing adult consumers only, distributing only small amounts regularly to each member (typically 10 grams per week) so as to prevent the possibility of trafficking. As well as a membership fee, members must pay for what they consume and prices may not be much different than on the black market.
Where the associations have come under legal challenge they have been able to surmount this, and in at least one case have secured the return of several kilos of confiscated plants. The umbrella group for cannabis associations in Spain is the Federación de Asociaciones Cannábicas: http://www.fac.cc/ and Politic Group:RCN-NOK Representacion Cannabica de Navarra: http://www.rcnavarra.org/
However, the autonomous Basque Country in the northern region of Spain has announced it is to legalise the sale and cultivation of cannabis to persons over the age of 18.
Sweden.
Swedish Cannabis Law.
It is illegal to purchase, possess, sell, transfer or consume any amount of cannabis in Sweden. If police suspect someone has consumed cannabis they could be ordered to take a drug test, which is seen as a way to prove consumption. Minor offenses, such as simple consumption generally renders a 30 day-fine (a day-fine is currently between 50 to 1000 SEK, depending on salary) while possession and even occasional cultivation of plants for personal use attracts higher fines (up to 150 day-fines) as long as they are under the threshold for minor drug offenses. For the purchase, smuggling and possession of larger amounts, organized cultivation or sale, the punishments range from 6 months to 10 years imprisonment The combined sentence can be even longer, for example when a series of crimes are added up into one sentence. Depending on the circumstances 14 or 18 years is the maximum penalty before limitation rules set in.
Every time reasonable suspicion arises, the police are obliged to intervene under a zero tolerance strategy even though mere police intuition is legally insufficient. The expressed aim of government is the creation of a ""drug-free society"" and the police are to give high priority towards drug crimes. However, as a condition of largely being a victimless crime, the police's own efforts are essential to apprehend cannabis offenders. That is, as opposed to many other crimes where a victim will report it to the police, they must apprehend the drug users and more advanced criminals for themselves. Influenced by the practices in the US, all police officers in external duty are to receive training to become Drug Recognition Experts (DRE) to better detect persons under the influence of drugs. Something that have led to increasing numbers of apprehended drug users. The traffic police especially, have integrated DRE-practices to test suspected drivers into their every day routine. 
Cannabis seeds are not legally classified as cannabis and mere possession of seeds is not illegal. 
Growing cannabis for industrial use is legal for farmers with at least 4 ha land if the grower has applied for area-based support for the crop and grows EU certified seeds(low % of THC).
Cannabinoid mouth spray Sativex that is derived from cannabis plants was approved in Sweden for the treatment of spasticity due to Multiple Sclerosis on 22 December 2011.
With the exemption of Khat, Cannabis has the least "penal value" per effective dose. Even with the general exemption for drug offences, among juveniles this is of special priority regardless of what drugs are involved. When juveniles are apprehended, the police are obliged to report the young user to the municipal social care. Although the charges often are dropped in consideration of their youth, the social service may then take various measures ranging from just talking to the adolescent and their parents to placing the delinquent in forced treatment for substance abuse.
In 2011 the Swedish government has given 48 MSEK (6 million USD) extra to a campaign against smoking of cannabis among young men in the biggest cities. What this budget will entail is still under debate but it is administrated by other authorities than the Police.
Switzerland.
As of 1/1/12 home grown cannabis is legal up to 4 plants each. The sale of cannabis is illegal.
Cannabis is classified as an illegal narcotic in Switzerland. The production and sale of illegal narcotics is punishable by a monetary penalty or by imprisonment of up to three years, as are public incitements to the consumption of illegal narcotics.
The enforcement of the prohibition on cannabis is spotty, because around 500,000 Swiss people are believed to use cannabis regularly or occasionally. In a health poll conducted in 1997, 7% of people aged 15 to 39 stated that they were currently consuming cannabis. Also, in 1998, some 250 hectares of land were used in Switzerland to grow cannabis, yielding more than 100 tons of cannabis per year. The product is sold mostly on the street and (in "scent bags" or covertly) through "cannabis shops" clustered in the urban centers. These shops, of which there were about 135 in 1999 and which authorities believe earn about 85-95% of their income with illegal narcotics, are the target of irregular police crackdowns in some cities, while in others they are tolerated to some degree. Overall, enforcement varies substantially depending on the canton. Some tolerate limited public consumption while others periodically attempt to limit it. Nationwide, police registered some 27,000 cannabis-related infractions in 1999.
Breaking News: [16.11.2011]
Cannabis plants can flourish freely in the lounge or on the balcony of individuals, provided they are four in number, and they are not marketed. This authorization derives from Latin Concordat on culture and commerce of hemp, which was ratified this year by the cantons of Vaud, Neuchâtel, Geneva and Fribourg. The Jura, Valais and Ticino, have yet to decide.
This text, which should come into force on 1 January 2012, aims to harmonize the regulation of culture and commerce of hemp in the different cantons. As noted in today's Le Matin, the heads of the Departments of Justice and Police also hope that this arrangement will play a preventive role.
"Avoiding anarchy"
"This is a regulation to prevent anarchy and tourism between the cantons," said State Councilor Jean Studer Neuchâtel in the daily Romand.
Thus, each person who wishes to grow more than four plants has an obligation to announce it to the competent authorities in order to receive authorization. In addition, recent reserve the right to control nuisance, including homes.
If the text has attracted the majority of speaking cantons, the Valais. In The Morning Rothen Michel, president of the PDC of Valais, said that his party will oppose the ratification of the Concordat, discussed today at the Grand Council of Valais. "We have always been against the decriminalization of consumption, we can not accept that the law allows each to grow four plants of hemp home."
Syria.
Under the laws of the government of Bashar al-Assad, cannabis use carries harsh penalties, up to life imprisonment. However, in some Kurdish areas cleared of government forces during the Syrian civil war, cannabis cultivation has emerged as a common way of earning income in the war-torn region.
Turkey.
The THC-containing cannabis is totally forbidden in Turkey. Persons carrying less than 12.5 grams of cannabis are required to attend rehab once a week and are subjected to mandatory drug screenings for a six month period if it is a first time offense. If it is not, the punishment is one year of prison. Drug trafficking is punished with long term imprisonment.
United Kingdom.
Cannabis is illegal in the United Kingdom but punishments are usually minor, resulting in a confiscation and a "cannabis warning" for small amounts. A record of the warning is retained on police information databases for intelligence purposes (effectively so the police can check to see if someone has previously been given a warning) and a crime is recorded under the Home Office Counting Rules but this is not disclosable to third parties. A cannabis warning will not show up on a CRB check, though a police caution for cannabis possession would do (which is usually the next step if someone already with a warning is caught and arrested). Technically there is nothing to prevent the police from giving an individual with personal use amounts of cannabis repeated cannabis warnings, but most forces operate along guidelines that if someone has been caught once (sometimes twice) within a 12 month period then they are arrested if caught again. Cannabis warnings can only be given to persons aged 18 and over. Due to international agreements the UK is signatory to, the cannabis warning process could not be extended to those under 18, who have to either be dealt with unofficially by confiscation and parental disclosure or by means of arrest.
In 1928: Cannabis became illegal in the United Kingdom as a class B drug.
In 2004, cannabis was downgraded to a class C substance. Consequently there was a "significant fall in its use" and a "50 per cent rise in the number of people" seeking "medical treatment after using the drug".
In 2008, the government commissioned a study into the effects of downgrading cannabis from a class B to a class C.
On May 7, 2008: Against the advice of the government's own commissioned report, the Home Secretary, Jacqui Smith, announced the government’s intention to once again reclassify cannabis as a class B drug.
Then-prime minister Gordon Brown announced that the government would set aside the findings of the committee.
On 26 January 2009: Cannabis was reclassified as a Class B substance.
In November 2009: Professor David Nutt was asked to resign from his position as chairman of the Government's Advisory Council on the Misuse of Drugs by the then Home Secretary (Alan Johnson), after publishing in a professional journal figures which indicated that cannabis was less harmful than both alcohol and tobacco. Several other members of the Advisory Council resigned in protest.
Afterwards, discussions were being focused towards imposing a new 'code of conduct'; in order to avoid any similar action in future, rather than of the issue at hand (that being the legality of the plant cannabis itself) also this is not under Common law offences, the basis for Statutory law in the UK.
On 17 August 2010: Professor Sir Ian Gilmore criticised prohibition, revitalising the topic in hand.
On 14 September 2010: Professor Roger Pertwee suggests that "policymakers should consider the setting up of a committee to license the sale of recreational cannabis." 
On 18 September 2010: "Tim Hollis, chairman of the Association of Chief Police Officers’ drugs committee" says that he "does not want to criminalise people caught with minor amounts of substances such as cannabis."
On 20 September 2010: "Ewan Hoyle, founder of Liberal Democrats for Drug Policy Reform, says his party should support legalisation [of cannabis".
On 3 October 2010: Presenter Evan Davis compared “having a spliff” with potentially risky activities (like skiing), whilst interviewing Lord Young.
On 11 October 2010: Welsh actor and musician, Rhys Ifans "calls for cannabis decriminalisation" or legalisation within the United Kingdom.
On the same day: An editorial in the British Medical Journal, written by Professor Robin Room, suggested "that the sale of cannabis should be licensed like cigarettes because banning it had not worked".
On 1 November 2010: Professor David Nutt publishes a paper which classes alcohol as being more dangerous than cannabis or heroin under a new 'points system'.
On 7 November 2010: Lord Taverne asked at question time in the House of Lords: "If the Government believes in evidence-based policy, is it not obvious in light of this Nutt's report and many other reports that make similar conclusions that the present classification of Ecstasy in class A and cannabis in class B is not in any way based on evidence of the physical or the social impact? 
On 10 November 2010: Cartrain manages to smuggle in and light up a joint in the House of Commons, shouting "decriminalise cannabis" whilst being hauled out by the police.
On 16 December 2010, Bob Ainsworth, the former minister and Home Office Parliamentary Under-Secretary with responsibility for Drugs and Organised Crime explained why he thinks certain illicit substances should be legalised.
On the same day: Peter Lilley, the former Tory deputy leader, said that he favoured legalising cannabis, while continuing the ban on hard drugs.
On 27 December 2010: Liam Smith labels Bob Ainsworth a "coward" for refusing to act when he had the power to do so. In defence Bob Ainsworth says: “If I had put forward the views that I was slowly developing as a minister then, I would have had to resign." 
On 9 March 2011: The House of Lords "heard calls for the establishment of a royal commission to examine decriminalising drug use." 
On 21 March 2011: "War on drugs has failed, say former heads of MI5, CPS and [the BBC", who have helped create (with several Lords and MPs) "a new All-Party Parliamentary Group on Drug Policy Reform are calling for new policies to be drawn up on the basis of scientific evidence."
On 2 June 2011: "Several high profile figures" "signed an open letter urging Prime Minister David Cameron to consider decriminalising drugs." (including Judi Dench, Sir Richard Branson, Sting, an ex-drugs minister and three former chief constables.) 
On 14 June 2011: "A senior policeman in Brighton and Hove" said that "the government should consider decriminalising personal drug use." and "Brighton Pavilion MP Caroline Lucas said the “war on drugs has failed”."
On 29 June 2011: "During Prime Minister’s questions", "Liberal Democrat MP Julian Huppert asked:" "Does the Prime Minister believe that drugs policy has been failing for decades, as he said in 2005, and does he agree that the Government should initiate a discussion of alternative ways including the possibility of legalisation regulation to tackle the global drugs dilemma as he voted for in 2002." 
On 21 July 2011: Former MP, Evan Harris, "said that every scientific advisor had agreed it was a good idea to declassify cannabis from category B to C. But because of a story in the Mail on Sunday, the Labour government broke the law." 
On 27 July 2011: Liberal Democrat MP Julian Huppert wrote "Britain's drug policy has failed" and "It's time for a radical overhaul"; affirming his belief(s).
On 24 January 2012: The Sentencing Council issued 'Update 6' of their sentencing guidelines. In the update it states that for the cultivation of cannabis, when the offender has a 'Lesser role' (including things like growing solely for personal use, being forced to do it etc.) and the offence is category 4 (the production of 9 plants or less, assuming 40g or less per plant) the starting point for sentencing is a 'band c fine' (150% of your weekly income, after tax), decreasing to 'discharge' or increasing to 'low level community order' (community service, curfew, attendance centre or similar for a small amount of time) depending on other mitigating or aggravating factors such as theft of electricity, the presence of children or whether the offender has grown the plants for use in the treatment of a valid medical condition.
United States.
Federal.
Non-medical
Colonel Joseph Franklin Siler, MD (1875–1960) U.S. Army, performed the first controlled clinical studies of marijuana use by soldiers. Siler et al., "Marihuana Smoking in Panama," The Military Surgeon, 73: 269-280, 1933.
Cannabis is classified as a Schedule I drug under the federal Controlled Substances Act of 1970 and is deemed to have a high potential for abuse and no legitimate medical uses. As such, it prohibits the possession, usage, purchase, sale, and/or cultivation of marijuana.
US Federal Courts have interpreted numerous state laws on multiple occasions. The United States Supreme Court ruled in United States v. Oakland Cannabis Buyers' Coop and Gonzales v. Raich that the federal government has the authority to regulate and criminalize cultivation and distribution of cannabis under the interstate commerce clause, as even purely intrastate sales will affect the market price in other states by altering nationwide supply and demand patterns.
Medical
California.
In 1996 California voters passed Proposition 215, later renamed the Compassionate Use Act, by means of popular initiative. It allows patients with a valid doctor's recommendation, and the patient's designated Primary Caregivers, to possess and cultivate marijuana for personal medical use, and has since been expanded to protect a growing system of collective and cooperative distribution. It was the first such law in the nation, and was followed by similar laws in Alaska, Colorado, Hawaii, Maine, Michigan, Montana, Nevada, New Jersey, New Mexico, Oregon, Rhode Island, Vermont, and Washington.
California state common law has interpreted the initiative on multiple occasions. In 2007 the courts upheld a decision of a trial court in "City of Garden Grove v. Superior Court" to "the Garden Grove Police Department to give [Felix Kha back his marijuana" because "it is not the job of local police to enforce the federal drug law". In 2010 the California Supreme Court struck down limits on how much marijuana people could grow or possess in "People v. Kelly", saying it's OK for people with doctors' permission to grow or possess "reasonable amounts".
In California there are designated shops for people who are permitted by law to purchase and use marijuana. Today there are even marijuana bakeries that make a wide variety of treats that range from chocolate bars to foods such as nachos and baked goods. These shops are made for people who have illnesses which allow them to purchase medical marijuana to go to if they do not wish to smoke in order to get the needed marijuana into their system.
However, California is not the only state that has legalized cannabis for medical use. 16 states and the District of Columbia have also legalized it for medical purposes. Besides California, the other states that have legalized marijuana for medical purposes are Arizona, Alaska, Colorado, Connecticut, Delaware, Hawaii, Maine, Michigan, Montana, Nevada, New Jersey, New Mexico, Oregon, Rhode Island, Vermont, and Washington.
Proposals.
Back in 1972, during the presidential campaign, Democratic candidate George McGovern made a bold move to legalize marihuana.
In early 2009, California state representative Tom Ammiano introduced a bill, titled Marijuana Control, Regulation, and Education Act, to legalize, regulate, and tax the recreational use of cannabis in California. According to the Wall Street Journal, Ammiano, a Democrat, estimates that marijuana legalization "would generate more than $1 billion annually for the cash-strapped state". Currently, marijuana is California's biggest cash crop, with annual sales reaching $14
billion. The bill "proposes a tax of $50 on an ounce of marijuana, which sells for a few hundred dollars on the street".
On January 16, 2009, a pair of bills (House Bill 2929 and Senate Bill 1801) were introduced into the Massachusetts legislature. Its stated objectives are "the reduction of cannabis abuse, the elimination of marijuana-related crime and the raising of public revenue." The bill proposes an excise on all cannabis sold that would range from $150 per ounce to $250 per ounce depending on the levels of THC present.
Multiple attempts at rescheduling cannabis at a federal level have failed in the past. In June 2009, the Personal Use of Marijuana by Responsible Adults Act of 2009 was introduced into the US House of Representatives by Barney Frank co-sponsored by Ron Paul and three other congressmen. If enacted, the bill "would eliminate federal penalties for the personal possession of up to 100 grams (over three and one-half ounces)". This would effectively leave the legality of cannabis possession for states to decide.
In 2010, Proposition 19, titled the "Regulate, Control, and Tax Cannabis Act of 2010", qualified for the November California ballot. Rejected by 54% of voters, this initiative would have legalized the recreational use of cannabis and its related activities in the State of California. It would also have allowed local governments to regulate and tax the newly created cannabis market. Supporters of the initiative received funding from many sources, most notably, a founder of Facebook.com and George Soros.
On June 23, 2011, Congressmen Barney Frank (D-MA) and Ron Paul (R-TX) introduced a bill in the House of Representatives that would end the federal prohibition on the cultivation, sale, and use of marijuana. The bill would limit the federal government's role in marijuana regulation to international and interstate smuggling.
Debate.
A majority of Americans (56%) are in favor of marijuana legalization, believing that marijuana should be regulated in a way similar to tobacco and cigarettes, and that it should not be a criminal offense to consume marijuana in the home, based on a national survey of 1,000 citizens of voting age. A September 2009 article in "Fortune Magazine" notes that President Barack Obama’s stance regarding marijuana, expressed by the U.S. Attorney General’s Office. The U.S. Attorney General, has all but decriminalized its use in the United States. Eric Holder, confirmed at a press conference that his Office would no longer subject individuals who were complying with state medical marijuana laws to federal drug raids and prosecutions. However, these raids are still taking place as of 2012 and marijuana use is not even close to being decriminalized. The article likens Obama’s policy toward marijuana, in terms of its eventual outcome, to the Twenty-First Amendment of the U.S. Constitution, which repealed the federal prohibition on alcoholic beverage sales. However, the official response to the petitions on the White House's website to legalize and regulate marijuana can be seen here: https://wwws.whitehouse.gov/petitions?_escaped_fragment_=/responses#!/response/what-we-have-say-about-legalizing-marijuana
Uruguay.
Uruguayan law and government agree that drug use should be considered a complex multifactorial issue. The law does not consider the user or consumer as the problem. Drug consumption is legal and is not criminalized in Uruguay. As of April 26, 2011, Cannabis is legal to grow in small amounts for home consumption. The law prohibits traffic, distribution, and production of drugs. Police acts are generally oriented towards the reduction of large-scale drug trafficking. The state takes a public health approach in regards to the population of users or potential users. These include offering free healthcare services at public events where drug consumption is likely to occur (e.g., rock concerts) and voluntary rehabilitation services. Policy is based on epidemiological evidence regarding demonstrable public harm. Thus, government efforts over the past decade to reduce drug consumption have been largely oriented towards tobacco and alcohol, and more recently coca-paste.
In June 2012, the Uruguayan government presided by José Mujica announced plans to legalize state-controlled sales of marijuana in order to fight drug-related crimes and health issues. The government stated that they will ask global leaders to do the same. Time Magazine featured an article where it considers that Uruguay's proposal to legalize marijuana sales and make its government the sole seller reflects a growing worldwide urge to find new and less violent solutions to the drug war. Nobel prize winner Mario Vargas Llosa praised the decision as "courageous". "Monocle" magazine expressed its admiration for the bold step taken by President José Mujica.
Mujica's plan would allow users to cultivate the plant for non-commercial use and grant licenses to professional farmers for larger scale production. The plan includes a system of user registry, a tax, and quality control, all coordinated through the existing agency that monitors tobacco, alcohol and pharmaceuticals. He estimates that with 70,000 monthly users, the country will have to produce more than 5,000 pounds each month.
Use of capital punishment against the cannabis trade.
Several countries have either carried out or legislated capital punishment for cannabis trafficking.
Non-drug purposes.
Hemp is the common name for cannabis and is the English term used when this annual herb is grown for non-drug purposes. These include industrial purposes for which cultivation licenses may be issued in the European Union (EU). When grown for industrial purposes hemp is often called industrial hemp, and a common product is fibre for use in a variety of different ways. Fuel is often a by-product of hemp cultivation.
Hemp may be grown also for food (the edible seeds), though in the UK Defra (the UK's Department for the Environment, Food and the Rural Affairs) will not issue cultivation licenses for this purpose, treating it as a non-food crop, though the seed appears on the UK market as a food product.
In the UK hemp seed and fibre have always been perfectly legal products. Cultivation for non drug purposes was however completely prohibited from 1928 until circa 1998, when Home Office industrial-purpose licenses became available under the Misuse of Drugs Act 1971.
Industrial strains intended for legal use within the EU are bred to comply with regulations limiting THC content to 0.2%. (THC content is a measure of the herb's drug potential and can reach 25% or more in drug strains).

Louisiana Purchase
The Louisiana Purchase ( "Sale of Louisiana") was the acquisition by the United States of America in 1803 of of France's claim to the territory of Louisiana. The U.S. paid 50 million francs ($11,250,000) plus cancellation of debts worth 18 million francs ($3,750,000), for a total sum of 15 million dollars (less than 3 cents per acre) for the Louisiana territory ($ million in dollars, less than 42 cents per acre).
The Louisiana territory encompassed all or part of 15 current U.S. states and two Canadian provinces. The land purchased contained all of present-day Arkansas, Missouri, Iowa, Oklahoma, Kansas, and Nebraska; parts of Minnesota that were west of the Mississippi River; most of North Dakota; most of South Dakota; northeastern New Mexico; northern Texas; the portions of Montana, Wyoming, and Colorado east of the Continental Divide; Louisiana west of the Mississippi River, including the city of New Orleans; and small portions of land that would eventually become part of the Canadian provinces of Alberta and Saskatchewan.
France controlled this vast area from 1699 until 1762, the year it gave the territory to its ally Spain. Under Napoleon Bonaparte, France took back the territory in 1800 in the hope of building an empire in North America. A slave revolt in Haiti and an impending war with Britain, however, led France to abandon these plans and sell the entire territory to the United States, who had originally intended only to seek the purchase of New Orleans and its adjacent lands.
The purchase of the territory of Louisiana took place during the presidency of Thomas Jefferson. At the time, the purchase faced domestic opposition because it was thought to be unconstitutional. Although he agreed that the U.S. Constitution did not contain provisions for acquiring territory, Jefferson decided to go ahead with the purchase anyway in order to remove France's presence in the region and to protect both U.S. trade access to the port of New Orleans and free passage on the Mississippi River.
Background.
Throughout the later half of the 18th century, Louisiana was a pawn on the chessboard of European politics. It was originally claimed by Spain, but also claimed by the French, who established most of the colonists as part of New France. Following the Seven Years War and French defeat by Great Britain, Spain gained control of the territory west of the Mississippi River. As the area was being gradually settled by United States migrants, many Americans, including Jefferson, assumed that it would be acquired "piece by piece." The risk of another power taking it from a weakened Spain would make "profound reconsideration" of this policy necessary.
The city of New Orleans controlled the Mississippi River due to its location; other locations for ports were attempted, but did not succeed. New Orleans was already important for shipping agricultural goods to and from the parts of the United States west of the Appalachian Mountains. Pinckney's Treaty, signed with Spain on October 27, 1795, gave American merchants "right of deposit" in New Orleans, granting them use of the port to store goods for export. Americans used this right to transport products such as flour, tobacco, pork, bacon, lard, feathers, cider, butter, and cheese. The treaty also recognized American rights to navigate the entire Mississippi River, which had become vital to the growing trade of the western territories.
In 1798 Spain revoked this treaty, prohibiting American use of New Orleans, and greatly upsetting the Americans. In 1801, Spanish Governor Don Juan Manuel de Salcedo took over from the Marquess of Casa Calvo, and restored the right to deposit goods from the United States. Napoleon Bonaparte had gained Louisiana for French ownership from Spain in 1800 under the Treaty of San Ildefonso, after being a Spanish colony since 1762. But the treaty was kept secret. Louisiana remained nominally under Spanish control until a transfer of power to France on November 30, 1803, just three weeks before the cession to the United States.
James Monroe and Robert R. Livingston traveled to Paris to negotiate the purchase of New Orleans in 1802. Their interest was only in gaining control of New Orleans and its environs; they did not anticipate the much larger purchase that would follow.
The Louisiana Purchase was by far the largest territorial gain in U.S. history, stretching from the Mississippi River to the Rocky Mountains. The purchase doubled the size of the United States. Before the Louisiana Purchase in 1803, Louisiana had been under control of the Spanish since 1763. Although Spain was America’s ally in the Revolution, they didn’t want the Americans to settle on their land or territory. The Louisiana Purchase territory was home for many of the Cajuns after the British forced them to leave from their former home of Nova Scotia, Canada.
Although the purchase was thought of as unjust and unconstitutional, Jefferson believed there was no evidence of unconstitutional actions taking place during the purchase of what became fifteen states. In hindsight, the Louisiana Purchase could be considered one of Thomas Jefferson’s greatest contributions to the United States.
Jefferson’s letter went on with the same heat to a much quoted passage about “the day that France takes possession of New Orleans.” Not only did he say that day would be a low point in France’s history, for it would seal America’s marriage with the British fleet and nation, but he added, astonishingly, that it would start a massive shipbuilding program.
Negotiation.
While the sale of the territory by Spain back to France in 1800 went largely unnoticed, fear of an eventual French invasion spread nationwide when, in 1801, Napoleon sent a military force to secure New Orleans. Southerners feared that Napoleon would free all the slaves in Louisiana, which could trigger slave uprisings elsewhere. Though Jefferson urged moderation, Federalists sought to use this against Jefferson and called for hostilities against France. Undercutting them, Jefferson took up the banner and threatened an alliance with Britain, although relations were uneasy in that direction. In 1801 Jefferson supported France in its plan to take back Saint-Domingue, then under control of Toussaint Louverture after a slave rebellion.
Jefferson sent Livingston to Paris in 1801 after discovering the transfer of Louisiana from Spain to France under the Third Treaty of San Ildefonso. Livingston was authorized to purchase New Orleans.
In January 1802, France sent General LeClerc to Saint-Domingue to re-establish slavery, reduce the rights of free people of color and take back control of the island from slave rebels. This colony had been the wealthiest for France in the Caribbean, and Napoleon wanted its productivity restored. Alarmed about the French actions and its intention to re-establish empire in North America, Jefferson declared neutrality in relation to the Caribbean, refusing credit and other assistance to the French but allowing war contraband to get through to the rebels to prevent France from getting a foothold again.
In November 1803, France withdrew its 7,000 surviving troops from Saint-Domingue (more than two-thirds of its troops died there) and gave up its ambitions in the western hemisphere. In 1804 Haiti declared independence but, fearing a slave revolt at home, Jefferson and the US Congress refused to recognize the new republic, the second in the Western Hemisphere, and imposed a trade embargo against it. This made it difficult for the country to recover after the wars.
In 1803, Pierre Samuel du Pont de Nemours, a French nobleman, began to help negotiate with France at the request of Jefferson. Du Pont was living in the United States at the time and had close ties to Jefferson as well as the prominent politicians in France. He engaged in back-channel diplomacy with Napoleon on Jefferson's behalf during a visit to France and originated the idea of the much larger Louisiana Purchase as a way to defuse potential conflict between the United States and Napoleon over North America.
Jefferson disliked the idea of purchasing Louisiana from France, as that could imply that France had a right to be in Louisiana. Jefferson believed that a U.S. President did not have the authority to make such a deal: it was not specified in the Constitution. He also thought that to do so would erode states' rights by increasing federal executive power. On the other hand, he was aware of the potential threat that France could be in that region and was prepared to go to war to prevent a strong French presence there.
Throughout this time, Jefferson had up-to-date intelligence on Napoleon's military activities and intentions in North America. Part of his evolving strategy involved giving du Pont some information that was withheld from Livingston. He also gave intentionally conflicting instructions to the two. Desperate to avoid possible war with France, Jefferson sent James Monroe to Paris in 1802 to negotiate a settlement, with instructions to go to London to negotiate an alliance if the talks in Paris failed. Spain procrastinated until late 1802 in executing the treaty to transfer Louisiana to France, which allowed American hostility to build. Also, Spain's refusal to cede Florida to France meant that Louisiana would be indefensible. Monroe had been formally expelled from France on his last diplomatic mission, and the choice to send him again conveyed a sense of seriousness.
Napoleon needed peace with Great Britain to implement the Treaty of San Ildefonso and take possession of Louisiana. Otherwise, Louisiana would be an easy prey for Britain or even for the United States. But in early 1803, continuing war between France and Britain seemed unavoidable. On March 11, 1803, Napoleon began preparing to invade Britain.
A slave revolution in Saint-Domingue (present-day Republic of Haiti) over previous years had resulted in massacres of the planter class. An expeditionary force under Napoleon's brother-in-law Charles Leclerc in January 1802, supplemented by 20,000 troops over the next 21 months, had tried to re-conquer the territory and re-establish slavery. But yellow fever and the fierce resistance of black revolutionaries destroyed the French army in what became the only successful slave revolt in history, and it withdrew its surviving troops in November 1803. In 1804 Haiti became the first independent black state in the New World.
As Napoleon had failed to re-enslave Haiti, he abandoned his plans to rebuild France's New World empire. Without sufficient revenues from sugar colonies in the Caribbean, Louisiana had little value to him. Spain had not yet completed the transfer of Louisiana to France, and war between France and Britain was imminent. Out of anger against Spain and the unique opportunity to sell something that was useless and not truly his yet, Napoleon decided to sell the entire territory.
Although the foreign minister Talleyrand opposed the plan, on April 10, 1803, Napoleon told the Treasury Minister François de Barbé-Marbois that he was considering selling the entire Louisiana Territory to the United States. On April 11, 1803, just days before Monroe's arrival, Barbé-Marbois offered Livingston all of Louisiana for $15 million, equivalent to about $ in present-day values.
The American representatives were prepared to pay up to $10 million for New Orleans and its environs, but were dumbfounded when the vastly larger territory was offered for $15 million. Jefferson had authorized Livingston only to purchase New Orleans. However, Livingston was certain that the United States would accept the offer.
The Americans thought that Napoleon might withdraw the offer at any time, preventing the United States from acquiring New Orleans, so they agreed and signed the Louisiana Purchase Treaty on April 30, 1803. On July 4, 1803, the treaty reached Washington, D.C.. The Louisiana Territory was vast, stretching from the Gulf of Mexico in the south to Rupert's Land in the north, and from the Mississippi River in the east to the Rocky Mountains in the west. Acquiring the territory would double the size of the United States at a sum of less than 3 cents per acre.
Domestic opposition.
The American purchase of the Louisiana territory was not accomplished without domestic opposition. Jefferson's philosophical consistency was in question because of his strict interpretation of the Constitution. Many people believed he, and other Jeffersonians such as James Madison, were being hypocritical by doing something they surely would have argued against with Alexander Hamilton. The Federalists strongly opposed the purchase, favoring close relations with Britain over closer ties to Napoleon, and were concerned that the United States had paid a large sum of money just to declare war on Spain.
Both Federalists and Jeffersonians were concerned about whether the purchase was unconstitutional. Many members of the United States House of Representatives opposed the purchase. Majority Leader John Randolph led the opposition. The House called for a vote to deny the request for the purchase, but it failed by two votes, 59–57. The Federalists even tried to prove the land belonged to Spain, not France, but available records proved otherwise.
The Federalists also feared that the political power of the Atlantic seaboard states would be threatened by the new citizens of the west, bringing about a clash of western farmers with the merchants and bankers of New England. There was concern that an increase in the number of slave-holding states created out of the new territory would exacerbate divisions between north and south as well. A group of northern Federalists led by Massachusetts Senator Timothy Pickering went so far as to explore the idea of a separate northern confederacy.
Another concern was whether it was proper to grant citizenship to the French, Spanish, and free black people living in New Orleans, as the treaty would dictate. Critics in Congress worried whether these "foreigners", unacquainted with democracy, could or should become citizens.
Most domestic objections were politically settled, overridden, or simply hushed up. One problem, however, was too important to argue down convincingly: Napoleon did not have the right to sell Louisiana to the United States. The sale violated the 1800 Third Treaty of San Ildefonso in several ways. Furthermore, France had promised Spain it would never sell or alienate Louisiana to a third party. Napoleon, Jefferson, Madison, and the members of Congress all knew this during the debates about the purchase in 1803. Spain protested strongly, and Madison made some attempt to justify the purchase to the Spanish government, but was unable to do so convincingly. So, he tried continuously until results had been proven remorsefully inadequate.
That the Louisiana Purchase was illegal was described pointedly by the historian Henry Adams, who wrote: "The sale of Louisiana to the United States was trebly invalid; if it were French property, Bonaparte could not constitutionally alienate it without the consent of the Chambers; if it were Spanish property, he could not alienate it at all; if Spain had a right of reclamation, his sale was worthless."
Treaty signing.
On Saturday, April 30, 1803, the Louisiana Purchase Treaty was signed by Robert Livingston, James Monroe, and Barbé Marbois in Paris. Jefferson announced the treaty to the American people on July 4. After the signing of the Louisiana Purchase agreement in 1803, Livingston made this famous statement, "We have lived long, but this is the noblest work of our whole lives...From this day the United States take their place among the powers of the first rank."
The United States Senate ratified the treaty with a vote of twenty-four to seven on October 20. On the following day, it authorized President Jefferson to take possession of the territory and establish a temporary military government. In legislation enacted on October 31, Congress made temporary provisions for local civil government to continue as it had under French and Spanish rule and authorized the President to use military forces to maintain order. Plans were also set forth for several missions to explore and chart the territory, the most famous being the Lewis and Clark Expedition.
France turned New Orleans over on December 20, 1803 at The Cabildo. On March 10, 1804, a formal ceremony was conducted in St. Louis to transfer ownership of the territory from France to the United States.
Effective on October 1, 1804, the purchased territory was organized into the Territory of Orleans (most of which became the state of Louisiana) and the District of Louisiana, which was temporarily under the control of the governor and judges of the Indiana Territory.
Boundaries.
A dispute immediately arose between Spain and the United States regarding the extent of Louisiana. The territory's boundaries had not been defined in the 1762 Treaty of Fontainebleau that ceded it from France to Spain, nor the 1800 Third Treaty of San Ildefonso ceding it back to France, nor the 1803 Louisiana Purchase agreement ceding it to the United States.
The United States claimed Louisiana included the entire western portion of the Mississippi River drainage basin to the crest of the Rocky Mountains and land extending southeast to the Rio Grande and West Florida. Spain insisted that Louisiana comprised no more than the western bank of the Mississippi River and the cities of New Orleans and St. Louis. The dispute was ultimately resolved by the Adams-Onis Treaty of 1819, with the United States gaining most of what it had claimed in the west.
The relatively narrow Louisiana of New Spain had been a special province under the jurisdiction of the Captaincy General of Cuba while the vast region to the west was in 1803 still considered part of the Commandancy General of the Provincias Internas. Louisiana had never been considered to be one of New Spain's internal provinces.
If the territory included all the tributaries of the Mississippi on its western bank, the northern reaches of the Purchase extended into the equally ill-defined British possession—Rupert's Land of British North America, now part of Canada. The Purchase originally extended just beyond the 50th parallel. However, the territory north of the 49th parallel (including the Milk River and Poplar River watersheds) was ceded to the UK in exchange for parts of the Red River Basin south of 49th parallel in the Anglo-American Convention of 1818.
The eastern boundary of the Louisiana purchase was the Mississippi River, from its source to the 31st parallel, although the source of the Mississippi was, at the time, unknown. The eastern boundary below the 31st parallel was unclear; the U.S. claimed the land as far as the Perdido River, and Spain claimed the border of its Florida Colony remained the Mississippi river. In early 1804, Congress passed the Mobile Act which recognized West Florida as being part of the United States. The Adams–Onís Treaty with Spain (1819) resolved the issue upon ratification in 1821. Today, the 31st parallel is the northern boundary of the western half of the Florida Panhandle, and the Perdido is the western boundary of Florida.
Because the western boundary was contested at the time of the Purchase, President Jefferson immediately began to organize three missions to explore and map the new territory. All three started from the Mississippi River. The Lewis and Clark Expedition (1804) traveled up the Missouri River; the Red River Expedition (1806) explored the Red River basin; the Pike Expedition (1806) also started up the Missouri, but turned south to explore the Arkansas River watershed. The maps and journals of the explorers helped to define the boundaries during the negotiations leading to the Adams–Onís Treaty, which set the western boundary as follows: north up the Sabine River from the Gulf of Mexico to its intersection with the 32nd parallel, due north to the Red River, up the Red River to the 100th meridian, north to the Arkansas River, up the Arkansas River to its headwaters, due north to the 42nd parallel and due west to its previous boundary.
Slavery.
Governing the Louisiana Territory was more difficult than acquiring it. Its European peoples, of ethnic French, Spanish and Mexican descent, were largely Catholic; in addition, there was a large population of enslaved Africans made up of a high proportion of recent arrivals from Africa, as Spain had continued the international slave trade. This was particularly true of the area of the present-day state of Louisiana, which also contained a large number of free people of color. Both present-day Arkansas and Missouri also had some people holding slaves.
Some slaveholders feared that acquisition of the new territory might inspire American slaves to follow the example of those in Saint-Domingue and revolt. Southern slave-owners wanted the US to establish slavery laws in Louisiana, so they could be supported in taking their slaves to the new territory to undertake new agricultural developments, as well as to reduce the threat of future slave revolts.
The Louisiana Territory was broken into smaller portions for administration, and the territories passed slavery laws similar to those in the southern states but trying to encompass the preceding French and Spanish rule (for instance, Spain had prohibited slavery of Native Americans in 1769, but some slaves of mixed African-Native American descent were still being held in St. Louis when the US took over the Louisiana Territory). In a freedom suit that went from Missouri to the US Supreme Court, slavery of Native Americans was finally ended in 1836. The institutionalization of slavery under US territorial law in the Louisiana Territory contributed to the American Civil War a half century later. As states organized within the territory, the status of slavery in each state became a matter of contention in Congress, as southern states wanted slavery extended to the west, and northern states just as strongly opposed new states being admitted as slave states. The Missouri Compromise of 1820 was a temporary solution.
Asserting U.S. possession.
After the early explorations, the U.S. government sought to establish control of the region, since trade along the Mississippi and Missouri rivers was still dominated by British and French traders from Canada and allied Indians, especially the Sauk and Fox. The United States adapted the former Spanish facility at Fort Bellefontaine as a fur trading post near St. Louis in 1804 for business with the Sauk and Fox. In 1808 two military forts with trading factories were built, Fort Osage along the Missouri River in western present-day Missouri and Fort Madison along the Upper Mississippi River in eastern present-day Iowa. With tensions increasing with Great Britain, in 1809 Fort Bellefontaine was converted to a US military fort, and used for that purpose until 1826.
During the War of 1812, Great Britain and allied Indians defeated U.S. forces in the Upper Mississippi; the US abandoned both Fort Osage and Fort Madison, as it did several U.S. forts built during the war, including Fort Johnson and Fort Shelby. After U.S. ownership of the region was confirmed in the Treaty of Ghent (1814), the U.S. built or expanded forts along the Mississippi and Missouri rivers, including adding to Fort Bellefontaine, and constructing Fort Armstrong (1816) and Fort Edwards (1816) in Illinois, Fort Crawford (1816) in Prairie du Chien Wisconsin, Fort Snelling (1819) in Minnesota, and Fort Atkinson (1819) in Nebraska.
Financing.
The American government used $3 million in gold as a down payment, and issued bonds for the balance to pay France for the purchase. Earlier that year, Francis Baring and Company of London had become the U.S. government's official banking agent in London. Because of this favored position, the US asked the Baring firm to handle the transaction. Francis Baring's son Alexander was in Paris at the time and helped in the negotiations. Another Baring advantage was a close relationship with Hope and Company of Amsterdam. The two banking houses worked together to facilitate and underwrite the Purchase. Because Napoleon wanted to receive his money as quickly as possible, the two firms received the American bonds and paid cash to France.
Nature of sale.
The historian James Loewen is among those who assert that the United States purchased only France's claim to the Louisiana Territory, as the land belonged to the tribes who inhabited the area. In his view, the US acquired the lands slowly throughout the nineteenth century by purchases from individual Native American tribes and by wars against them. The question is discussed at length in the article on Aboriginal title in the United States, as well as in articles on the American Indian Wars and the U.S. Supreme Court case "Johnson v. M'Intosh".
The issue of the legitimacy of the Louisiana Purchase is similar to that of the 1867 Alaska Purchase. In that case, the land rights were resolved more than 100 years later with the 1971 Alaska Native Claims Settlement Act (ANCSA). Some Alaska Natives continue to resent the Alaska Federation of Natives' lack of legitimacy to act on their behalf. See also Indian Land Claims Settlements for other cases where native land title claims were extinguished with monetary compensation.
The proceeds.
Despite issuing orders that the over 60 million francs were to be spent on the construction of five new canals in France, Bonaparte spent the whole amount on his planned invasion of the United Kingdom.

Majestic 12
Majestic 12 (or MJ-12) is the supposed code name of an alleged secret committee of scientists, military leaders, and government officials, formed in 1947 by an executive order by U.S. President Harry S. Truman. The purpose of the committee would be to investigate the recovery of a UFO north of Roswell, New Mexico during July 1947. 
Initial indications of such a group's existence appeared in 1978 in declassified Canadian documents. Another reference to a classified group called "MJ-12" was discovered in 1980, but was later claimed to be a hoax. In 1984 a set of documents were discovered in United States archives, which closely resemble real declassified documents, but which the FBI have declared to be "completely bogus".
UFO conspiracy theories sometimes incorporate Majestic 12.
Initial discoveries.
In 1978, Canadian researcher Arthur Bray uncovered previously classified Canadian UFO documents naming Dr. Vannevar Bush as heading a highly secret UFO investigation group within the U.S. Research and Development Board. No name for the group was given. Bray published excerpts of the documents in his 1979 book, "The U.F.O. Connection". The author of the documents, Wilbert Smith, was a UFOlogist working in the Canadian Department of Transport who is not known to have had any security clearance, and the skeptical researcher Christopher D. Allan concludes that there is no way any such group headed by Bush could have come to his knowledge. On the contrary, Smith's claims could have instigated the MJ-12 hoax.
The earliest appearance of the term "MJ Twelve" was a message of unclear origin dated November 17, 1980. This so-called "Project Aquarius" Teletype message had been given to Albuquerque physicist and businessman Paul Bennewitz in November, 1980, by U.S. Air Force Office of Special Investigations counterintelligence officer Richard C. Doty. Bennewitz had photographed and recorded electronic data of what he believed to be UFO activity over nearby Kirtland AFB, a sensitive nuclear facility. Bennewitz reported his findings to officials at Kirtland, including Doty. In 1989, the UFOlogist Bill Moore claimed that the documents were actually a hoax created by Doty as part of an attempt to drive Bennewitz insane. One sentence in the lengthy Teletype message read, "The official US Government policy and results of Project Aquarius is still classified TOP SECRET with no dissemination outside channels and with access restricted to 'MJ TWELVE.'"
In 1983, Doty also contacted UFO researcher and journalist Linda Moulton Howe, revealing alleged high-level UFO documents, including those describing crashed alien flying saucers and recovery of aliens. Doty again mentioned MJ-12, explaining that “MJ” stood for “Majority” (not “Majestic”).
Because the entire MJ-12 affair made its first appearance only a year after Bray had made public the incriminating Canadian documents about the secret UFO committee, one theory is that the Project Aquarius Teletype message was part of a counterintelligence hoax to discredit the information in the just-revealed Canadian documents. Thus the various MJ-12 documents could be fake, but the secret committee described in the verified Canadian documents could still have been real. (See Arguments for below)
Moore's fictional MJ-12 in 1982-3.
In 1982 Moore approached nuclear physicist and UFO researcher Stanton T. Friedman about creating bogus Roswell documents, with the idea of encouraging witnesses to come forward. Also, in early 1982, Moore had approached former "National Enquirer" reporter Bob Pratt (who had first published a story on Roswell in the "Enquirer" in 1980). Moore asked Pratt to collaborate on a novel called "MAJIK-12". As a result of this behavior, Pratt always believed that the Majestic-12 papers were a hoax, either perpetrated personally by Moore or perhaps by AFOSI, with Doty using Moore as a willing target. Noted UFO skeptic Philip J. Klass also argued that Moore was the most likely hoaxer of the initial batch of MJ-12 documents. Moore, however, flatly denied creating the documents, but eventually thought that maybe he had been set up. Unlike Pratt, who was convinced they were a hoax, Friedman would investigate the historical and technical details in the MJ-12 documents and become their staunchest defender.
In 1983, Moore approached UFOlogist Brad Sparks and asked him about a plan to create counterfeit government UFO documents, hoping to induce former military officers to speak out. Sparks strongly urged Moore not to do this. Moore also showed Sparks a copy of the Aquarius message.
Moore and Shandera's 1984-5 discoveries.
What came to be known as the "MJ-12 papers" – detailing a secret UFO committee allegedly involving Vannevar Bush – first appeared on a roll of film in late 1984 in the mailbox of television documentary producer (and amateur ufologist) Jaime Shandera. Shandera had been collaborating with Bill Moore since 1980.
Moore said in 1989 that these documents were also a hoax created by Doty. Furthermore, the film mailed to Shandera with the MJ-12 documents was postmarked "Albuquerque," raising the obvious suspicion that the MJ-12 documents were more bogus documents arising from Doty and AFOSI in Albuquerque.
The Eisenhower briefing document.
The film allegedly received by Shandera in 1984 consisted of two MJ-12 documents. The main document, dated November 18, 1952, was supposedly prepared by Rear Admiral Roscoe Hillenkoetter, the first CIA director, to brief incoming president Dwight Eisenhower on the committee's progress. The document lists all the MJ-12 members and discusses United States Air Force investigations and concealment of a crashed alien spacecraft near Roswell, New Mexico, plus another crash in northern Mexico in December 1950.
Eisenhower did indeed receive extensive briefings from alleged MJ12 member Walter Bedell Smith in Atlanta on November 15, 1952, and a briefing at the Pentagon on November 18, 1952, by the Joint Chiefs of Staff, which would have included alleged MJ-12 members Twining and Vandenberg. However, Eisenhower’s Pentagon briefings are still classified and thus the subject matter discussed remains speculative.
The Cutler/Twining memo.
In 1985, Shandera and Moore began receiving post cards postmarked “New Zealand” with a return address of "Box 189, Addis Ababa, Ethiopia." The cards contained a series of cryptic messages referring to "Reeses not "Reece's", according to Blum, 1990--> Pieces" and "Suitland" (among other terms) that Shandera and Moore assumed were a code; however, they were unable to "decode" the seeming message.
A few months later, a happenstance request from Friedman unlocked the mystery: busy due to previous obligations, Friedman asked Moore and Shandera to examine newly declassified Air Force documents at the National Archives (NARA) repository in Suitland, Maryland; the head archivist there was named Ed Reese.
After a few days in Suitland, Shandera and Moore discovered yet another MJ-12 document, the so-called Cutler/Twining memo, dated July 14, 1954. Interestingly enough, the memo turned up in "Box 189" of the record group. In this memo, NSC Executive Secretary and Eisenhower’s National Security Advisor Robert Cutler informed Air Force Chief of Staff (and alleged MJ-12 member) Nathan Twining of a change of plans in a scheduled MJ-12 briefing.
The Cutler-Twining memo lacked a distinctive catalog number, leading many to suspect that whether hoaxed or genuine, the memo was almost certainly planted in the archives.
Moore and Shandera have been accused of hoaxing the memo and then planting it in the archives. However, Friedman notes that the memo, unlike the other early MJ-12 papers which were available only as photos, is on original onionskin paper widely used by the government at that time (1953 - early 70's) and unavailable in stationery stores. The document also has some subtle historical and other details that a civilian hoaxer would be unlikely to know, such as a red pencil declassification marking also found with the other declassified files. Furthermore, NARA security procedures would make it difficult for a visitor to the Archives to plant such a document; even the skeptical Klass argued that NARA security procedures made it highly unlikely that Shandera and Moore could have planted the Cutler-Twining memo in the archives. Instead, Friedman has argued that one of the many Air Force personnel involved in declassifying NARA documents could easily have planted the Cutler/Twining memo in with other unrelated documents.
However, most researchers have argued that various subtle details point to a forgery. For example, the date of the alleged MJ-12 meeting does not correspond to any known meeting of import (see Arguments against for more examples). However, this doesn’t negate Friedman’s point that the memo could have been planted by someone in the Air Force.
Other theories about the MJ-12 group.
Since the first MJ-12 documents, thousands of pages of other supposedly leaked government documents mentioning MJ-12 and a government coverup of UFOs have also appeared. All of them are controversial, with many disputing their authenticity. A few have been proven to be unquestionably fraudulent, usually retyped rewrites of unrelated government documents. The most notable "new" MJ-12 document is a lengthy, Linotype-set manual allegedly dating from 1954, called the MJ-12 "Special Operations Manual (SOM)". It deals primarily with the handling of crash debris and alien bodies. Objections to its authenticity usually center on questions of style and some historical anachronisms.
Another government group recently associated with MJ-12 was the CIA's Office of National Estimates or ONE, a forerunner of the current National Intelligence Council (NIC). ONE was created in 1950 by CIA director Gen. Walter Bedell Smith, alleged to have replaced Secretary of Defense James Forrestal on MJ-12 after his death. A history of the NIC states that ONE was a type of super branch of the CIA "whose sole task was to produce coordinated 'National Intelligence Estimates.'" Besides Smith, it apparently consisted of 11 other members. A recent article on the history of the CIA's involvement in UFO investigations states that ONE received a UFO intelligence briefing on January 30, 1953, immediately after the end of the CIA's UFO debunking study known as the Robertson Panel. Members of ONE at that time included FBI director J. Edgar Hoover, William Bundy, President Eisenhower's chief of staff Admiral B. Bieri, and William Langer, a Harvard historian, who was chairman. Referring to ONE as "super think tank" within the CIA, the article states, "ONE is as close as we get to a documented version of the rumoured Majestic-12 group."
Connection to the secret Pratt documents.
At the Mutual UFO Network (MUFON) 2007 Symposium in Denver, Colorado, UFO researcher Brad Sparks presented a paper that describes the MJ-12 documents as an elaborate disinformation campaign perpetrated by Bill Moore, Richard C. Doty, and other Air Force Office of Special Investigations (AFOSI) personnel. The sources for this information are files dating from 1981 (three years before the first alleged MJ-12 documents surfaced) that UFO researcher Bob Pratt gave MUFON before his death in 2005. The information lay hidden in MUFON's archives until they were digitized as part of MUFON's Pandora Project and made available to UFO researchers. Of interest will be the paragraph that has a handwritten date of 1/02/82 and states: "3. UFO project is Aquarius, classified Top Secret with access restricted to MJ 12. (MJ may be "magic"). This project begun about 1966, but apparently inherited files of earlier project."
Membership.
All the alleged original members of MJ-12 were notable for their military, government, and/or scientific achievements, and all were deceased when the documents first surfaced (the last to die was Jerome Hunsaker, only a few months before the MJ-12 papers first appeared).
The original composition was six civilians (mostly scientists), and six high-ranking military officers, two from each major military service. Three (Souers, Vandenberg, and Hillenkoetter) had been the first three heads of central intelligence. The Moore/Shandera documents did not make clear who was the director of MJ-12, or if there was any organizational hierarchy.
According to other sources and MJ-12 papers to emerge later, famous scientists like Robert Oppenheimer, Albert Einstein, Karl Compton, Edward Teller, John von Neumann, and Wernher von Braun were also allegedly involved with MJ-12.(see also Arguments for below, particularly statements by Dr. Robert Sarbacher)
Professional and social connections among purported MJ-12 members.
Research has also shown that there were many social and professional connections among many of the alleged members of MJ-12. For example, Bush, Hunsaker, Bronk, and Berkner all sat on the oversight committee of the Research and Development Board (RDB), which Bush had established and initially chaired. Other notables on the RDB oversight committee were Karl Compton, Robert Oppenheimer, and Dr. H. P. Robertson, who headed up the debunking Robertson Panel, of which Berkner was a member.
Various alleged MJ-12 members or participants would also naturally be part of the Presidential office's National Security Council, created in 1947. This would include (depending on NSC composition, which evolved) various NSC permanent members: Executive Secretary (Souers, Cutler), the Secretary of Defense (Forrestal), the Secretary of the Army (Gray), National Security Advisor (Gray), and the Air Force Chief of Staff (Vandenberg, Twining). Other nonpermanent members who would attend NSC meetings as advisors and implement policy would be the CIA director (Hillenkoetter, Smith), the head of the Research and Development Board (Bush, Compton), the President's Special Assistant for National Security Affairs (Cutler, Gray), and the Chairman of the Joint Chiefs (Twining).
The purported members were trusted, high-ranking officials who were often involved in important government projects—they possessed diverse skills and high security clearances. However, they were not so recognizable that they would be missed if they were to be called upon in a secret emergency. If such a group existed, these individuals would make plausible members.
1988 FBI investigation.
The MJ-12 documents were first made public in 1987 by Shandera, Moore, and Friedman. Another copy of the same documents Shandera received in 1984 was mailed to British researcher Timothy Good in 1987, again from an anonymous source. Good first reproduced them in his book "Above Top Secret" (1988), but later judged the documents as likely fraudulent.
After the documents became widely known with the publication of Good’s book, the Federal Bureau of Investigation then began its own investigation, urged on by debunker Philip J. Klass. The MJ-12 documents were supposedly classified as "Top Secret", and the FBI's initial concern was that someone within the U.S. government had illegally leaked highly classified information.
The FBI quickly formed doubts as to the documents' authenticity. FBI personnel contacted the U.S. Air Force Office of Special Investigations (counterintelligence), asking if MJ-12 had ever existed. AFOSI claimed that no such committee had ever been authorized or formed, and that the documents were “bogus.” The FBI adopted the AFOSI opinion and declared the MJ-12 documents to be "completely bogus.”
However, when Stanton Friedman contacted the AFOSI officer, Col. Richard Weaver, who had rendered this opinion, Friedman said Weaver refused to document his assertion. Friedman also noted that Weaver had taught disinformation and propaganda courses for AFOSI and was principal author of the Air Force’s debunking Roswell report in 1994. (Friedman, 110-115)
Timothy Good in "Beyond Top Secret" also noted that Weaver in 1994 was the Director of Security and Special Programs Oversight of AFOSI’s Pentagon office, a very high level organization within the Office of the Secretary of the Air Force. Good commented that AFOSI is “an agency whose work involves counterintelligence and deception, and which has a long record of deep involvement in the UFO problem.” Within Weaver’s office were “special planners.” According to Good, “In Air Force parlance, the term ‘special plans’ is a euphemism for deception as well as for ‘perception management’ plans and operations.” Conducting an interview with one Roswell witness, Weaver himself admitted, “We’re the people who keep the secrets.” It is difficult to tell from interviews such as these, as the cold war tactics of deceptions within deceptions are intentionally vague as to where the disinformation and coverup of espionage ends and the government's actual investigation into UFOs begins.
William Moore would later reveal that the whole New Mexico UFO disinformation scheme was run out of the Pentagon by a Colonel Barry Hennessey of AFOSI. When the Defense Department phone directory was checked, Hennessey was listed under the "Dept. of Special Techniques." Working under him at the time was the same Col. Weaver.
Friedman therefore raised the question as to whether Weaver rendered an objective intelligence opinion about the authenticity of the MJ-12 papers or was deliberately misleading the FBI as a counterintelligence and disinformation agent, much like Doty had done with Moore and Howe earlier.
Journalist Howard Blum in his book "Out There" (1990) further described the FBI’s difficulty in getting at the truth of the matter. One frustrated FBI agent told Blum, “All we’re finding out is that the government doesn’t know what it knows. There are too many secret levels. You can’t get a straight story. It wouldn’t surprise me if we never know if the papers are genuine or not.”
Authenticity debate.
Arguments against.
Briefing document and Truman letter.
Skeptics argue there is strong evidence that the briefing document and Truman letter are fake.
The Cutler Memo.
In addition, although the Cutler memo was supposedly a carbon copy, it was folded as if it had been in a shirt pocket, which would be unusual for a carbon copy put in a file. The memo is in the National Archives; the question is how it got there, and if it is authentic.
A document entitled "SOM1-01: Extraterrestrial Entities and Technology, Recovery and Disposal" (ref. http://209.132.68.98/pdf/som101_part1.pdf) and found on www.majesticdocuments.com contains paragraphs with subheads set in the sans serif "Helvetica" typeface. The document purports to be from 1954, yet the typeface in question was first designed in 1957 by the Swiss graphic designer, Max Miedinger. The capitalized sans serif letter "R" (and others) found on many pages confirms that this typeface is not the much earlier Akzidenz Grotesk sans serif typeface. This evidence seems to strongly suggest that this document is a fabrication.

Maoism
Maoism, formally known as Mao Zedong Thought (), is a political theory derived from the teachings of the Chinese political leader Mao Zedong (1893–1976). Its followers, known as Maoists, consider it as an anti-Revisionist form of Marxism-Leninism. Developed during the 1950s and 1960s, it was widely applied as the political and military guiding ideology of the Communist Party of China (CPC).
Maoism sees the agrarian peasantry, rather than the working class, as the key revolutionary force which can fundamentally transform capitalist society towards socialism. Holding that "all political power proceeds from the barrel of a gun," Maoist organizations mainly draw upon Mao's ideology of the People's War, mobilizing large parts of rural populations to revolt against established institutions by engaging in guerrilla warfare. 
Maoism can also refer to the egalitarianism that was seen during Mao's era as opposed to the free-market ideology of Deng Xiaoping; some scholars additionally define personality cults and political sloganeering as "Maoist" practices. Contemporary Maoists in China criticize the social inequalities created by a capitalist and "revisionist" Communist party. Maoism fell into disfavour in China in 1978, when Deng Xiaoping started the "Reform and Opening" economic policies that introduced capitalist market principles.
Notable Maoist organizations and armed groups currently exist in several countries, particularly in the most impoverished sections of the third world. Examples of contemporary Maoist movements most notably include the Shining Path in Peru, the Naxalite insurgency in India, and the Communist Party of Nepal (Maoist); the latter of which is the only current Maoist party holding power through a democratic process.
Origins.
Although often described as an evolution of Marxism/Leninism, Maoism is defined more by its theoretical and ideological departures from orthodox Marxism or Leninism than by its similarities to the Western versions of modern socialism. The origins of Maoism stem not from Marxist writings alone, but also from the modern Chinese intellectual tradition in which Mao was raised.still on going.
The modern Chinese intellectual tradition.
The modern Chinese intellectual tradition of the turn of the twentieth century is defined by two central concepts, iconoclasm and nationalism.
Iconoclastic revolution/anti-Confucianism.
By the turn of the twentieth century, a proportionately small yet socially significant cross-section of China's traditional elite (i.e. landlords and bureaucrats), found themselves increasingly skeptical of the efficacy and even the moral validity of Confucianism. These skeptical iconoclasts formed a new segment of Chinese society, a modern intelligentsia, whose arrival, or as lauded historian of China Maurice Meisner would label it, their defection, heralded the beginning of the destruction of the gentry as a social class in China. The fall of the last Chinese imperial dynasty in 1911 marked the final failure of the Confucian moral order, and did much to make Confucianism synonymous with political and social conservatism in the minds of Chinese intellectuals. It was this association of conservatism and Confucianism which lent to the iconoclastic nature of Chinese intellectual thought during the first decades of the Twentieth century.
Chinese iconoclasm was expressed most clearly and vociferously by Chen Duxiu during the New Culture Movement which occurred between 1915 and 1919. Proposing the, "total destruction of the traditions and values of the past," the New Culture Movement was spearheaded by the "New Youth", a periodical which was published by Chen Duxiu and which was profoundly influential on a young Mao Zedong whose first published work appeared on the magazine's pages.
Nationalism and the appeal of Marxism.
Along with iconoclasm, radical anti-imperialism dominated the Chinese intellectual tradition and slowly evolved into a fierce nationalist fervor which influenced Mao's philosophy immensely and was crucial in adapting Marxism to the Chinese model. Vital to understanding Chinese nationalist sentiments of the time is the Treaty of Versailles which was signed in 1919. The Treaty aroused a wave of bitter nationalist resentment in Chinese intellectuals as lands formerly ceded to Germany in Shandong were, without consultation with the Chinese, transferred to Japanese control rather than returned to Chinese sovereignty. The negative reaction culminated in the May 4th Incident which occurred on that day in 1919. The protest began with 3,000 students in Beijing displaying their anger at the announcement of the Versailles Treaty's concessions to Japan yet rapidly took a violent turn as protesters began attacking the homes and offices of ministers who were seen as cooperating with, or in the direct pay of the Japanese. The May 4th Incident and Movement which followed, "catalyzed the political awakening of a society which had long seemed inert and dormant"
Yet another international event would have a large impact on not only Mao but also the Chinese intelligensia was the Bolshevik Revolution of 1917. Although the revolution did elicit interest among Chinese intellectuals, socialist revolution in China was not considered a viable option until after the May 4th Incident. Afterwards, "To become a Marxist was one way for a Chinese intellectual to reject both the traditions of the Chinese past and Western domination of the Chinese present" Maurice Meisner, "Mao's China and After", page 18.
Mao's personal philosophy.
Along with the Chinese intellectual tradition which was prevalent during his youth, it is clear that Mao's personal philosophy, his idealism and populist leanings, were foundational to the formation and profile of Maoism. Mao's political ideas emerge from his personal ethics. One source is commentaries to "A System of Ethics" by Friederich Paulsen (1917-1918) where he expressed: "I do not agree with the view that to be moral, the motive of one action has to be benefiting others...Morality does not have to be defined in relation to others...People like me want to ...satisfy our hearts to the full, and in doing so we automatically have the most valuable moral codes. Of course there are people and objects in the world, but they are only for me". His politics were consistent with these personal values and views.
Idealism.
Mao believed that human consciousness is the principal factor in human history. In other words, he may be viewed as an idealist and, as such, directly contradicted the materialistic determinist tenets of orthodox Marxism. Mao had the utmost faith that, through the actions of "dedicated revolutionaries," a new social reality could be formed which would be in harmony with his ideals.
Populism.
Mao also believed strongly in the concept of a unified "people". These notions were what prompted him to investigate the peasant uprisings in Hunan while the rest of the China's communists were in the cities and focused on the orthodox Marxist proletariat. Many of the pillars of Maoism such as the distrust of intellectuals and the abhorrence of occupational specialty are typical populist ideas. The concept of "People's War" which is so central to Maoist thought is directly populist in its origins. Mao believed that intellectuals and party cadres had to become first students of the masses to become teachers of the masses later. This concept was vital to the strategy of the "People's War."
Nationalism.
Mao's nationalist impulses also played a crucially important role in the adaption of Marxism to the Chinese model and in the formation of Maoism. Mao truly believed that China was to play a crucial preliminary role in the socialist revolution internationally. This belief, or the fervor with which Mao held it, separated Mao from the other Chinese Communists and led Mao onto the path of what Leon Trotsky called, "Messianic Revolutionary Nationalism" which was central to his personal philosophy and is demonstrated in his long-standing hostile relationship with ComIntern.
The Yan'an period.
During the period immediately following the Long March, Mao and the Chinese Communist Party were headquartered in Yan'an, which is a prefecture-level city in the Shaanxi province. During this period Mao clearly established himself as a Marxist theoretician and produced the bulk of the works which would later be canonized into the "thought of Mao Zedong". The rudimentary philosophical base of Chinese Communist ideology is laid down in Mao's numerous dialectical treatises and was conveyed to newly recruited party members. This period truly established ideological independence from Moscow for Mao and the CCP. Although the Yan'an period did answer some of the questions, both ideological and theoretical, which were raised by the Chinese Communist Revolution, it left many of the crucial questions unresolved; including how the Chinese Communist Party was supposed to launch a socialist revolution while completely separated from the urban sphere.
Components.
Contradiction.
Furthermore, each contradiction (including class struggle, the contradiction holding between relations of production and the concrete development of forces of production) expresses itself in a series of other contradictions, some dominant, others not.
Thus, the principal contradiction should be tackled with priority when trying to make the basic contradiction "solidify". Mao elaborates further on this theme in the essay On Practice. On the relation between knowledge and practice, between knowing and doing". Here, "Practice" connects "contradiction" with "class struggle" in the following way: Inside a mode of production, there are three realms where practice functions: economic production, scientific experimentation (which also takes place in economic production and should not be radically disconnected from the former) and finally, class struggle. These may be considered the proper objects of economy, scientific knowledge, and politics.
These three spheres deal with matter in its various forms, socially mediated. As a result, they are the only realms where knowledge may arise (since truth and knowledge only make sense in relation to matter, according to Marxist epistemology). Mao emphasizes—like Marx in trying to confront the "bourgeoisie idealism" of his time—that knowledge must be based on empirical evidence.
Knowledge results from hypotheses verified in the contrast with a real object; this real object, despite being mediated by the subject’s theoretical frame, retains its materiality and will offer resistance to those ideas that do not conform to its truth. Thus, in each of these realms (economic, scientific and political practice), contradictions (principle and secondary) must be identified, explored and put to function to achieve the communist goal. This involves the need to know, "scientifically", how the masses produce (how they live, think, and work), to obtain knowledge of how class struggle (the main contradiction that articulates a mode of production, in its various realms) expresses itself.
People's war and mass line.
Maoism's political orientation emphasizes the "revolutionary struggle of the vast majority of people against the exploiting classes and their state structures", which Mao termed a "People's War". Usually involving peasants, its military strategies have involved guerrilla war tactics focused on surrounding the cities from the countryside, with a heavy emphasis on political transformation through mass involvement of the lower classes of society.
Agrarian socialism.
Maoism departs from conventional European-inspired Marxism in that its focus is on the agrarian countryside, rather than the industrial urban forces. This is known as Agrarian socialism. Notably, Maoist parties in Peru, Nepal and Philippines have adopted equal stresses on urban and rural areas, depending on the country's focus of economic activity. Maoism broke with the state capitalist framework of the Soviet Union under Nikita Khrushchev and dismisses it as modern revisionism, a traditional pejorative term among communists referring to those who fight for capitalism in the name of socialism.
New Democratic revolution.
The theory of the New Democracy was known to the Chinese revolutionaries from the late 40’s. This thesis held that for the majority of the peoples of the planet, the long road to socialism could only be opened by a ‘national, popular, democratic, anti-feudal and anti-imperialist revolution language of the day, run by the communists.'
And in the context of New Democratic revolution, the rationality of such economic policies as to destroy feudalism on the basis of land to the tiller, to confiscate all foreign and domestic economic establishments with a monopolistic character and to limit, control and guide private capital that do not control public life, have been proved in practice.
Mao's intellectual Marxist development.
Mao’s "Intellectual" Marxist development can be divided into five major periods: (1) The Initial Marxist Period from 1920–1926; (2) the formative Maoist period from 1927–1935; (3) the mature Maoism period from 1935–1940; (4) the civil war period from 1940–1949; and (5) the post-1949 period, following the revolutionary victory.
Departure from Leninism.
Mao departed from Leninism not only in his near-total lack of interest in the urban working class but also in his concept of the nature and role of the Party. For Lenin, the Party was sacrosanct because it was the incarnation of the "proletarian consciousness," and there was no question about who were the teachers and who were the pupils. For Mao, on the other hand, this question would always be virtually impossible to answer.
Post-revolution.
In its post-revolutionary period, Mao Zedong's thought is defined in the CPC's Constitution as "Marxism-Leninism applied in a Chinese context", synthesized by Mao Zedong and China's "first-generation leaders". It asserts that class struggle continues even if the proletariat has already overthrown the bourgeoisie, and there are capitalist restorationist elements within the Communist Party itself. Maoism provided the CPC's first comprehensive theoretical guideline with regards to how to continue socialist revolution, the creation of a socialist society, socialist military construction, and highlights various contradictions in society to be addressed by what is termed "socialist construction". While it continues to be lauded to be the major force that defeated "imperialism and feudalism" and created a "New China" by the Communist Party of China, the ideology survives only in name on the Communist Party's Constitution; Deng Xiaoping abolished most Maoist practices in 1978, advancing a guiding ideology called "Socialism with Chinese characteristics.
Medical staff of China PLA 165 Hospital and mental hospitals in Chenzhou, Hunan claims that mental diseases should be defeated in a mental way, and mental disorders can be cured using "invincible" Maoism.
Maoism after Mao.
Shortly after Mao's death in 1976, Deng Xiaoping started the capitalist reforms of the People's Republic of China (PRC) in 1978 beginning the radical change of Mao's ideology in the PRC. Although Mao Zedong Thought nominally remains the state ideology, Deng's admonition to seek truth from facts means that state policies are judged on their practical consequences; the role of ideology in determining policy, in many areas, has thus been considerably reduced. Deng also separated Mao from Maoism, making it clear that Mao was fallible and hence that the truth of Maoism comes from observing social consequences rather than by using Mao's quotations as holy writ, as was done in Mao's lifetime.
In addition, the party constitution has been rewritten to give the capitalist ideas of Deng Xiaoping prominence over those of Mao. One consequence of this is that groups outside China which describe themselves as Maoist generally regard China as having repudiated Maoism and restored capitalism, and there is a wide perception both in and out of China that China has abandoned Maoism. However, while it is now permissible to question particular actions of Mao and to talk about excesses taken in the name of Maoism, there is a prohibition in China on either publicly questioning the validity of Maoism or questioning whether the current actions of the CPC are "Maoist."
Although Mao Zedong Thought is still listed as one of the four cardinal principles of the People's Republic of China, its historical role has been re-assessed. The Communist Party now says that Maoism was necessary to break China free from its feudal past, but that the actions of Mao are seen to have led to excesses during the Cultural Revolution.
"Chief responsibility for the grave 'Left' error of the 'cultural revolution,' an error comprehensive in magnitude and protracted in duration, does indeed lie with Comrade Mao Zedong . . . . far from making a correct analysis of many problems, he confused right and wrong and the people with the enemy. . . . Herein lies his tragedy."
Scholars outside China see this re-working of the definition of Maoism as providing an ideological justification for what they see as the restoration of the essentials of capitalism in China by Deng and his successors, who sought to "eradicate all ideological and physiological obstacles to economic reform". In 1978 this led to the Sino-Albanian Split when Albanian leader Enver Hoxha denounced Deng as a revisionist and formed Hoxhaism as an anti-revisionist form of Marxism.
Mao himself is officially regarded by the CPC as a "great revolutionary leader" for his role in fighting the Japanese and creating the People's Republic of China, but Maoism as implemented between 1959 and 1976 is regarded by today's CPC as an economic and political disaster. In Deng's day, support of radical Maoism was regarded as a form of "left deviationism" and being based on a cult of personality, although these 'errors' are officially attributed to the Gang of Four rather than to Mao himself. Thousands of Maoists were arrested in the Hua Guofeng period after 1976. The prominent Maoists, Zhang Chunqiao and Jiang Qing were sentenced to death with two-year-reprieve while some others were sentenced to life imprisonment or imprisonment over 15 years.
Maoism internationally.
Maoism outside China.
From 1962 onwards, the challenge to the Soviet hegemony in the World Communist Movement made by the CPC resulted in various divisions in communist parties around the world. At an early stage, the Albanian Party of Labour sided with the CPC. So did many of the mainstream (non-splinter group) communist parties in South-East Asia, like the Burmese Communist Party, Communist Party of Thailand, and Communist Party of Indonesia. Some Asian parties, like the Workers Party of Vietnam and the Workers Party of Korea attempted to take a middle-ground position.
The Khmer Rouge of Cambodia is said to have been a replica of the Maoist regime. According to BBC The Communist Party of Kampuchea (Cambodia), better known as the "Khmer Rouge", identified strongly with Maoism, and is generally labeled a "Maoist" movement today. Maoists, however, are quick to point out that the CPK strongly deviated from Marxist doctrine, and that the few references to Maoist China in CPK propaganda were critical of the Chinese.
In the west and south, a plethora of parties and organizations were formed that upheld links to the CPC. Often they took names such as "Communist Party (Marxist-Leninist)" or "Revolutionary Communist Party" to distinguish themselves from the traditional pro-Soviet communist parties. The pro-CPC movements were, in many cases, based among the wave of student radicalism that engulfed the world in the 1960s and 1970s.
Only one Western classic communist party sided with CPC, the Communist Party of New Zealand. Under the leadership of CPC and Mao Zedong, a parallel international communist movement emerged to rival that of the Soviets, although it was never as formalized and homogeneous as the pro-Soviet tendency.
After the death of Mao in 1976 and the resulting power-struggles in China that followed, the international Maoist movement was divided into three camps. One group, composed of various ideologically nonaligned groups, gave weak support to the new Chinese leadership under Deng Xiaoping. Another camp denounced the new leadership as traitors to the cause of Marxism-Leninism-Mao Zedong Thought. The third camp sided with the Albanians in denouncing the Three Worlds Theory of the CPC (see Sino-Albanian Split.)
Che Guevara, though initially praising the Soviet Union prior to, during and shortly after the Cuban Revolution, later came out in support of Maoism, and advocated the adoption of the ideology throughout Latin America. The pro-Albanian camp would start to function as an international group as well, led by Enver Hoxha and the APL, and was also able to amalgamate many of the communist groups in Latin America, including the Communist Party of Brazil and Marxist-Leninist Communist Party in Ecuador. Later Latin American Communists such as Peru's Shining Path also embraced the tenets of Maoism.
The new Chinese leadership showed little interest in the various foreign groups supporting Mao's China. Many of the foreign parties that were fraternal parties aligned with the Chinese government before 1975 either disbanded, abandoned the new Chinese government entirely, or even renounced Marxism-Leninism and developed into non-communist, social democratic parties. What is today called the "international Maoist movement" evolved out of the second campthe parties that opposed Deng and claimed to uphold the legacy of Mao.
India.
The Communist Party of India (Maoist) is a Maoist political party in India which aims to overthrow the government of India. It was founded on September 21, 2004, through the merger of the Communist Party of India (Marxist–Leninist) People's War and the Maoist Communist Centre of India (MCC). The merger was announced to the public on October 14 the same year. In the merger a provisional central committee was constituted, with the erstwhile People's War Group leader Muppala Lakshmana Rao alias Ganapathi as General Secretary. It is currently proscribed as a terrorist organization by the Indian government for organizing mass killings in furtherance of their ideology.
Nepal.
The Unified Communist Party of Nepal (Maoist), a national communist party with a revolutionary background, is a follower of Maoism, although it is believed that the party has developed its own ideology, Prachanda Path, which was developed taking Nepal's political, sociological and geographical constraints into consideration. Still, this party is believed to have taken Maoism as its doctrine as its name suggests.
Norway.
In Norway, the maoism of the ml-movement ("ml-bevegelsen") was described in the 2012 movie by Wong Men Hoi, "The East is Red".
Philippines.
In the Philippines, the Communist Party of the Philippines (CPP) and its New People's Army (NPA) has been waging a revolutionary war since 1968. Its strength peaked during the dictatorial rule of Ferdinand Marcos and was the main bulk of the opposition against the dictatorship. However due to controversies regarding massive purges of its members in the mid-1980s and political miscalculations, it suffered several splits within its ranks in 1992 and 1997 forming several separate communist parties. It maintains active guerrilla fronts throughout the Philippines until today and is still considered by the military as the main threat to national security. The CPP, according to the military also allegedly has been leading and influencing legal left-wing political organizations and engages in elections.
The Marxist-Leninist Party of the Philippines (MLPP), formed by former Central Luzon Regional Committee members of the CPP after the split in 1997 maintained much of the Maoist orientation from the CPP most especially on the concept of People's War. However it has put equal emphasis on legal political struggles along with armed revolution and it sees the proletariat as the leader of the Philippine revolution in union with the peasantry. The Rebolusyonaryong Hukbo ng Bayan (People's Revolutionary Army, RHB) is the armed wing of the MLPP and according to military intelligence sources, the most active and fastest growing insurgent force in the Philippines recently next to the CPP. Like its estranged political sibling the MLPP is said to be organizing legal organizations but does not engage in electoral processes.
United States.
In the United States, the Black Panther Party, especially Huey Newton, was influenced by Maoist thought.
In the USA the Kasama Project (KP), was initiated by former Revolutionary Communist Party, USA members critical of what they viewed as the dogmatism and cult of personality of RCP USA. KP describes itself as seeking to radically re-imagine contemporary revolutionary politics. It is deeply influenced by Maoist thought, in particular as developed by the RCP USA, but claims members who arrive from other traditions, such as anarchism.
Spain.
The Communist Unification of Spain is an independent party that follows Marxist-Leninism and Maoism.
Somalia.
In Africa, Siad Barre's regime in Somalia is often cited as being pro-Maoist, as it sided with the People's Republic of China during the Sino-Soviet split and, as such, China provided support to the regime during its war with the pro-Soviet nations of Ethiopia, Cuba and South Yemen.
Maoist organizations.
Today, there is no consensus on who does and who does not represent Maoism. Various efforts have sought to regroup the international communist movement under Maoism since the time of Mao's death in 1976.
One notable organization was the Revolutionary Internationalist Movement (RIM). RIM was founded in 1984 and included such notable organizations as the Communist Party of Peru (PCP), also known as "Sendero Luminoso" or "Shining Path," the then Communist Party of Nepal (Maoist), now known as the Unified Communist Party of Nepal (Maoist) UCPN(M), and the Revolutionary Communist Party USA (RCP(USA)). Today, the RIM appears to be defunct or near defunct. The magazine associated with the RIM, A World To Win, has not published an issue since 2006, though A World To Win News Service still publishes regularly on the internet.
In addition, many of the one-time RIM organizations have become increasingly critical of each other. This has resulted in many public splits. For example, recently the RCP USA has criticized the UCPN(M) as revisionist after the UCPN(M) abandoned its people's war for the parliamentary road. In addition, Red Sun, a web page that claims to be affiliated with some faction the Communist Party of Peru, has criticized both the UCPN(M) and RCP USA. Another movement that has criticized the UCPN(M) is the Communist Party of India (Maoist) -- although they were never formally a RIM member, the CPI(Maoist) was formed out of three organizations, some of which were RIM members, at conferences organized by RIM.
Another effort at regrouping the international communist movement is the International Conference of Marxist-Leninist Parties and Organizations (ICMLPO). Two notable parties that participate in the ICMLPO are the Marxist Leninist Party of Germany (MLPD) and the Communist Party of the Philippines (CPP). The ICMLPO seeks to unity around Marxism-Leninism, not Maoism. However, some of the parties and organizations within the ICMLPO identify as Mao Zedong Thought or Maoist.
Criticisms and interpretations.
Maoism has fallen out of favour within the Communist Party of China, beginning with Deng Xiaoping's reforms in 1978. Deng believed that Maoism showed the dangers of "ultra-leftism", manifested in the harm perpetrated by the various mass movements that characterized the Maoist era. In Chinese Communism, the term "left" can be taken as a euphemism for Maoist policies. However, Deng stated that the revolutionary side of Maoism should be considered separate from the governance side, leading to his famous epithet that Mao was "70% good, 30% bad". China scholars generally agree that Deng's interpretation of Maoism preserves the legitimacy of Communist rule in China but at the same time criticizes Mao's brand of economic and political governance.
Critic Graham Young claims that Maoists see Joseph Stalin as the last true socialist leader of the Soviet Union, but allows that the Maoist assessments of Stalin vary between the extremely positive and the more ambivalent. Some political philosophers, such as Martin Cohen, have seen in Maoism an attempt to combine Confucianism and Socialism - what one such called 'a third way between communism and capitalism'.
Enver Hoxha critiqued Maoism from a Marxist-Leninist perspective, arguing that "new democracy" halts class struggle, the theory of the three worlds is "counter-revolutionary" and questioned Mao's guerilla warfare methods.
External links.
Selected organizations.
Committee of Marxist-Leninist-Maoist parties from around the world

Mexican American
Mexican Americans are Americans of Mexican descent . As of July 2011, Mexican Americans make up 10.8% of the United States' population with over 33,558,000 Americans listed as being of full or partial Mexican ancestry. Mexican Americans comprise 64.6% of all Hispanics and Latinos in the United States. The United States is home to the second largest Mexican community in the world second only to Mexico itself comprising nearly 22% of the entire Mexican origin population of the world. Canada is a distant third with a small but fast-growing Mexican Canadian population of 61,505 as of 2006 (compared to 37,000 as of 2001). In addition, as of 2008 there were approximately 7,000,000 undocumented Mexicans living in the United States which if included in the count would increase the US share to over 28% of the world's Mexican origin population (Note that some of the undocumented would be captured in the US Census count depending on their willingness to provide information). Over 60% of all Mexican Americans reside in the states of California and Texas. Most Mexican Americans are the descendants of the Indigenous peoples of Mexico and/or Europeans, especially Spaniards.
History of Mexican Americans.
Mexican American history is wide-ranging, spanning more than 400 years and varying from region to region within the United States. In 1900, there were slightly more than 500,000 Hispanics living in New Mexico, California and Texas. Most were Mexican Americans of indigenous Mexican, Spanish, and other hispanicized European settlers who arrived in the Southwest during Spanish colonial times. Approximately ten percent of the current Mexican American population can trace their lineage back to these early colonial settlers.
As early as 1813 some of the Tejanos who colonized Texas in the Spanish Colonial Period established a government in Texas that looked forward to independence from Mexico. In those days, there was no concept of what a Mexican was. Many Mexicans were more loyal to their states/provinces than to their country as a whole. This was particularly true in frontier regions such as Zacatecas, Texas, Yucatan, Oaxaca, New Mexico, etc. The Mexican government became concerned by their increasing numbers and restricted the number of new Anglo-American settlers allowed to enter Texas. The Mexican government also banned slavery within the state, which angered slave owners. The American settlers along with many of the Tejanos rebelled against the centralized authority of Mexico City and the Santa Anna regime, while others remained loyal to Mexico, and still others were neutral.
"A native of San Antonio, Juan Seguín is probably the most famous Tejano to be involved in the War of Texas Independence. His story is complex because he joined the Anglo rebels and helped defeat the Mexican forces of Santa Anna. But later on, as Mayor of San Antonio, he and other Tejanos felt the hostile encroachments of the growing Anglo power against them. After receiving a series of death threats, Seguín relocated his family in Mexico, where he was coerced into military service and fought against the US in 1846–1848 Mexican-American War.
Although the events of 1836 led to independence for the people of Texas, the Hispanic population of the state was very quickly disenfranchised to the extent that their political representation in the Texas State Legislature disappeared entirely for several decades."
Californios were Spanish speaking residents of modern day California who were the original Hispanics (Mexicans (regardless of race) and local Hispanicized Indians) in the region (Alta California) before the United States acquired it as a territory. Relations between Californios and Anglo settlers were relatively good until military officer John C. Fremont arrived in Alta California with a force of 60 men on an exploratory expedition in 1846. Fremont made an agreement with Comandante Castro that he would only stay in the San Joaquin Valley for the winter, then move north to Oregon. However, Fremont remained in the Santa Clara Valley then headed towards Monterey. When Castro demanded that Fremont leave Alta California, Fremont rode to Gavilan Peak, raised a US flag and vowed to fight to the last man to defend it. After three days of tension, Fremont retreated to Oregon without a shot being fired. With relations between Californios and Anglos quickly souring, Fremont rode back into Alta California and encouraged a group of American settlers to seize a group of Castro's soldiers and their horses. Another group, seized the Presidio of Sonoma and captured Mariano Vallejo. William B. Ide was chosen Commander in Chief and on July 5, he proclaimed the creation of the Bear Flag Republic. On July 9, US forces reached Sonoma and lowered the Bear Flag Republic's flag then replaced it with a US flag. Californios organized an army to defend themselves from invading American forces after the Mexican army retreated from Alta California to defend other parts of the country. The Californios defeated an American force in Los Angeles on September 30, 1846, but were defeated after the Americans reinforced their forces in what is now southern California. The arrival of tens of thousands of people during the California Gold Rush meant the end of the Californio's ranching lifestyle. Many Anglo 49ers turned to farming and moved, often illegally, onto the land granted to Californios by the old Mexican government.
The United States first came into conflict with Mexico in the 1830s, as the westward spread of Anglo settlements and of slavery brought significant numbers of new settlers into the region known as Tejas (modern-day Texas), then part of Mexico. The Mexican-American War, followed by the Treaty of Guadalupe-Hidalgo in 1848 and the Gadsden Purchase in 1853, extended U.S. control over a wide range of territory once held by Mexico, including the present day borders of Texas and the states of New Mexico, Colorado, Utah, Nevada, Arizona, and California.
Although the treaty promised that the landowners in this newly acquired territory would enjoy full enjoyment and protection of their property as if they were citizens of the United States, many former citizens of Mexico lost their land in lawsuits before state and federal courts or as a result of legislation passed after the treaty. Even those statutes intended to protect the owners of property at the time of the extension of the United States' borders, such as the 1851 California Land Act, had the effect of dispossessing Californio owners ruined by the cost of maintaining litigation over land titles for years.
While Mexican Americans were once concentrated in the Southwest – California, Arizona, New Mexico, Colorado and Texas – they began creating communities in St. Louis, Chicago, Detroit, Cleveland, Pittsburgh, and other steel producing regions when they obtained employment during World War I. More recently, Mexican illegal immigrants have increasingly become a large part of the workforce in industries such as meat packing throughout the Midwest, in agriculture in the southeastern United States, and in the construction, landscaping, restaurant, hotel and other service industries throughout the country.
Mexican-American workers formed unions of their own and joined integrated unions. The most significant union struggle involving Mexican-Americans was the United Farm Workers' long strike and boycott aimed at grape growers in the San Joaquin and Coachella Valleys in the late 1960s. Its struggle propelled César Chávez and Dolores Huerta into national prominence
changing from a workers' rights organization that helped workers get unemployment insurance to that of a union of farmworkers almost overnight.
Mexican American identity has also changed markedly throughout these years. Over the past hundred years Mexican Americans have campaigned for voting rights, stood against educational and employment discrimination and stood for economic and social advancement. At the same time many Mexican Americans have struggled with defining and maintaining their community's identity. In the 1960s and 1970s, some Latino/Hispanic student groups flirted with nationalism and differences over the proper name for members of the community—Chicano/Chicana, Latino/Latina, Mexican Americans, or Hispanics became tied up with deeper disagreements over whether to integrate into or remain separate from mainstream American society, as well as divisions between those Mexican Americans whose families had lived in the United States for two or more generations and more recent immigrants. During this time rights groups such as the National Mexican-American Anti-Defamation Committee were founded. The states with the largest percentages and populations of Mexican-Americans are California, Arizona, New Mexico, Texas, Colorado, Nevada, and Utah. There has also been very high increasing populations in Oklahoma. Pennsylvania and Illinois.
Race and ethnicity.
The Mexican population is mainly conformed by Mestizos, individuals with a genetic background consisting of Amerindian and European contributions. Genetic heterogeneity in Mexicans results from a complex demographic history that started with the peopling of North and Central America about 15,000 yrs ago, including the settlement of at least 60 different indigenous groups in Mexico. Source
Per the 2000 U.S. Census, a plurality of 47.3% of Mexican Americans self identify as being of White race, closely followed by Mexican Americans who self identify as "Some other race", usually Mestizo (Native American/European) with 45.5%.<. Respondents who claim two or more races accounted for 5.1%, Blacks for 0.7%, and all other races for 1.4%. Mexican Americans are predominantly of Native American and European descent. Mexicans are the product of the mixture of 35 ethnic groups. According to the Mexican Genome Project, the overall gene pool of the Mexican population was calculated to be 65 percent indigenous and 35 percent non-indigenous (mostly European). According to the last Mexican census to record race (which was in 1921), 10 percent of the Mexican populace identified itself as white, 59 percent as Mestizo (Native American-European mixture), 29 percent as Native American, and 2 percent as "other", foreigner (regardless of race), or did not specify a race.
Before the United States' borders expanded westward in the 19th century, New World regions colonized by the Spanish Empire since the 16th century held to a complex caste system ("casta") that classified persons by their fractional racial makeup and geographic origin.
For certain purposes, respondents who wrote in "Chicano" or "Mexican" (or indeed, almost all Hispanic origin groups) in the ""Some other race"" category were automatically re-classified into the "White race" group.
Politics and debate of racial classification.
Since the 1848 Treaty of Guadalupe Hidalgo, which granted citizenship rights to Mexican people in the newly conquered US territory of the South West, Mexican Americans have been legally considered "White." Since legal citizenship in the United States required "white" racial status, new Mexican "Americans" had to be classified as White, whether or not they were considered white in "reality". Thus Mexican Americans were white by law, but not usually classified as such socially (depending on class and whether an individual had any degree of perceived indigenous ancestry). According to legal scholars, "Anglos rarely distinguished between Mexicans and Mexican Americans and painted a picture of 'Mexicans' as an economic and cultural threat to America. In early 1900s, Mexican Americans increasingly were denied many of the rights of citizens. Like the African American population, many were placed in segregated schools with inferior educational resources, barred from restaurants, movie theaters, bathrooms, and public swimming pools, and denied the possibility of living in white neighborhoods," in addition to being barred from serving on juries in most of the Southwest; yet none of this segregation was formally encoded in law. Thus while for legal purposes, Mexican Americans were counted as White, in everyday reality most Mexican Americans were not considered "white," did not enjoy "white" status or privileges, and were in fact typically subjected to systematic discrimination and "Jim Crow" style racial segregation. The legal designation of white racial status actually worked against Mexican American civil rights in law suits claiming racial discrimination. Such suits were typically denied on the basis that Mexican Americans were not subject to racial discrimination, despite all evidence to the contrary, because they were legally white.
In times and places where Mexicans were allotted white status, they were permitted to intermarry with what today are termed "non-Hispanic whites", though social customs typically only approved of such marriages if the Mexican partner was not of any discernable indigenous heritage.
Legally, Mexican Americans could vote and hold elected office, though they were also constrained from voting in most places by literacy tests and poll taxes. While Mexicans of Spanish descent ran the state politics and constituted most of the elite of New Mexico since colonial times, property requirements and English literacy requirements were imposed in Arizona, California, Nevada, New Mexico, and Texas in order to prevent Mexican Americans from voting. Some eligible voters were intimidated with the threat of violence if they attempted to exercise their right to vote.
Mexicans were also allowed to serve in all-white units during World War II. However, many Mexican American war veterans were discriminated against and even denied medical services by the United States Department of Veterans Affairs when they arrived home.
In the past, Mexicans were legally considered "White" because either they were considered to be of full Spanish heritage, or because of early treaty obligations to Spaniards and Mexicans that conferred citizenship status to Mexican peoples at a time when whiteness was a prerequisite for U.S. citizenship. Although Mexican Americans were legally classified as "White" in terms of official federal policy, many organizations, businesses, and homeowners associations and local legal systems had official policies to exclude Mexican Americans. Throughout the southwest discrimination in wages were institutionalized in "white wages" versus lower "Mexican wages" for the same job classifications.
Mexican Americans legally classified as "White", following anti-miscegenation laws in most western states until the 1960s, could not legally marry African or Asian Americans (See Perez v. Sharp). However, most were not socially considered white, and therefore, according to Historian Neil Foley in the book "The White Scourge" Mexicans and Mexican Americans did marry non-whites typically without reprisal.
Economic and social issues.
Immigration issues.
Since the 1960s, Mexican immigrants have met a significant portion of the demand for cheap labor in the United States. Fear of deportation makes them highly vulnerable to exploitation by employers. Many employers, however, have developed a "don't ask, don't tell" attitude toward hiring undocumented Mexican nationals. In May 2006, hundreds of thousands of undocumented immigrants, Mexicans and other nationalities, walked out of their jobs across the country in protest to support immigration reform (many in hopes of a path to citizenship similar to the Immigration Reform and Control Act of 1986, which granted citizenship to Mexican nationals living and working without documentation in the US).
In the United States, in states where Mexican Americans make up a large percentage of the population, such as California and Texas, undocumented as well as legal immigrants from Mexico and Central America in addition to Mexican Americans combined often make up a large majority of workers in many blue-collar occupations: the majority of the employed men are restaurant workers, janitors, truck drivers, gardeners, construction laborers, material moving workers, or perform other types of manual or other blue collar labor (Source, U.S. Census Bureau, American community survey data.). Many women also work in low wage service and retail occupations. In many of these places with large Latino populations, many types of blue-collar workers are often assumed to be Mexican American or Mexican or other Latino immigrants (Although a large minority are actually not. -Source, U.S. Census Bureau, American community survey data.) because of their frequent dominance in those occupations and stereotyping. Occasionally, tensions have risen between Mexican immigrants and other ethnic groups because of increasing concerns over the availability of working-class jobs to Americans and immigrants from other ethnic groups. However, tensions have also risen among Hispanic American laborers who have been displaced because of both cheap Mexican labor and ethnic profiling. African American workers in lower-wage jobs have been displaced by undocumented Mexican laborers and their neighborhoods have been transformed from majority black to majority Latino, which has caused some racial tensions between African Americans and Mexicans in the Southwest US. Even legal immigrants to the United States, both from Mexico and elsewhere, have spoken out against illegal immigration. However, according to a survey conducted by the Pew Research Center in June 2007, 63% of Americans would support an immigration policy that would put illegal immigrants on a path to citizenship if they "pass background checks, pay fines and have jobs, learn English", while 30% would oppose such a plan. The survey also found that if this program was instead labeled "amnesty", 54% would support it, while 39% would oppose.
Alan Greenspan, former Chairman of the Federal Reserve, has said that the growth of the working-age population is a large factor in keeping the economy growing and that immigration can be used to grow that population. According to Greenspan, by 2030, the growth of the US workforce will slow from 1 percent to 1/2 percent, while the percentage of the population over 65 years will rise from 13 percent to perhaps 20 percent. Greenspan has also stated that the current immigration problem could be solved with a "stroke of the pen", referring to the 2007 immigration reform bill which would have strengthened border security, created a guest worker program, and put illegal immigrants currently residing in the US on a path to citizenship if they met certain conditions.
Discrimination and stereotypes.
Throughout U.S. history, Mexican Americans have and continue to endure various types of negative stereotypes which have long circulated in media and popular culture. Mexican Americans have also faced discrimination based on ethnicity, race, culture, poverty, and use of the Spanish language.
Since the majority of illegal immigrants in the U.S. have traditionally been from Latin America, the Mexican American community has been the subject of widespread immigration raids. During The Great Depression, the United States government sponsored a Mexican Repatriation program which was intended to encourage people to voluntarily move to Mexico, but thousands were deported against their will. More than 500,000 individuals were deported, approximately 60 percent of which were actually United States citizens. In the post-war McCarthy era, the Justice Department launched Operation Wetback.
During World War II, more than 300,000 Mexican Americans served in the US armed forces. Mexican Americans were generally integrated into regular military units, however, many Mexican American war veterans were discriminated against and even denied medical services by the United States Department of Veterans Affairs when they arrived home. In 1948, war veteran Dr Hector P. Garcia founded the American GI Forum to address the concerns of Mexican American veterans who were being discriminated against. The AGIF's first campaign was on the behalf of Felix Longoria, a Mexican American private who was killed in the Philippines while in the line of duty. Upon the return of his body to his hometown of Three Rivers, Texas, he was denied funeral services because of his race.
In the 1948 case of Perez v. Sharp, Andrea Perez—a Mexican-American woman listed as White—and Sylvester Davis—an African American man—the Supreme Court of California recognized that interracial bans on marriage violated the Fourteenth Amendment of the Federal Constitution.
In 2006, "Time" magazine reported that the number of hate groups in the United States increased by 33% since 2000, primarily due to anti-illegal immigrant and anti-Mexican sentiment. According to the annual Federal Bureau of Investigation (FBI) Hate Crimes Statistics Report, in 2007, Hispanics comprised 61.7 percent of victims of crimes motivated by a bias toward the victims’ ethnicity or national origin. Since 2003 the number of both victims of anti-Hispanic crimes and incidents increased by nearly 40 percent. In 2004, the comparable figure was 51.5 percent. In California, the state with the largest Mexican American population, the number of hate crimes committed against Latinos has almost doubled.
Social status and assimilation.
Barrow (2005) finds increases in average personal and household incomes for Mexican Americans in the 21st century. U.S. born Mexican Americans earn more and are represented more in the middle and upper-class segments more than most recently arriving Mexican immigrants.
Most immigrants from Mexico, as elsewhere, come from the lower classes and from families generationally employed in lower skilled jobs. They also are most likely from rural areas. Thus, many new Mexican immigrants are not skilled in white collar professions. Recently, some professionals from Mexico have been migrating, but to make the transition from one country to another involves re-training and re-adjusting to conform to US laws —i.e. professional licensing is required.
According to James P. Smith of the Research and Development Corporation, the children and grandchildren of Latino immigrants tend to lessen educational and income gaps with native whites. Immigrant Latino men make about half of what native whites do, while second generation US-born Latinos make about 78 percent of the salaries of their native white counterparts and by the third generation US-born Latinos make on average identical wages to their US-born white counterparts.
Huntington (2005) argues that the sheer number, concentration, linguistic homogeneity, and other characteristics of Latin American immigrants will erode the dominance of English as a nationally unifying language, weaken the country's dominant cultural values, and promote ethnic allegiances over a primary identification as an American. Testing these hypotheses with data from the U.S. Census and national and Los Angeles opinion surveys, Citrin et al. (2007) show that Hispanics generally acquire English and lose Spanish rapidly beginning with the second generation, and appear to be no more or less religious or committed to the work ethic than native-born non-Mexican American whites. However, the children and grandchildren of Mexican immigrants were able to make close ties with their extended families in Mexico, since United States shares a 2,000 mile border with Mexico. Many had the opportunity to visit Mexico on a relatively frequent basis. As a result, many Mexicans were able to maintain a strong Mexican culture, language, and relationship with others.
South et al. (2005) examine Hispanic spatial assimilation and inter-neighborhood geographic mobility. Their longitudinal analysis of seven hundred Mexican, Puerto Rican, and Cuban immigrants followed from 1990 to 1995 finds broad support for hypotheses derived from the classical account of assimilation into American society. High income, English-language use, and embeddedness in American social contexts increased Latin American immigrants' geographic mobility into multi-ethnic neighborhoods. US citizenship and years spent in the United States were positively associated with geographic mobility into different neighborhoods, and coethnic contact was inversely associated with this form of mobility, but these associations operated largely through other predictors. Prior experiences of ethnic discrimination increased and therefore decreased the likelihood that Latino immigrants would move from their original neighborhoods, while residing in metropolitan areas with large Latino populations led to geographic moves into "less Anglo" census tracts.
Segregation issues.
In 2000, over nine million Mexicans Americans lived in areas considered highly segregated socially.
Segregated neighborhoods.
Neighborhoods with a high percentage of individuals who claim Latino ancestry are commonly referred to as "barrios" or "colonias." When translated from Spanish to English, barrio signifies "district" or "quarter" while colonia is the corresponding Mexican Spanish word.
A barrio has been defined as "a place where Latino immigrants can express communal culture and language within the larger American culture." In other words, the barrio is a sort of sanctuary for Spanish-speaking immigrants who may not yet be fully adjusted to the United States. In the barrio, they can converse in their native language, allowing one to communicate, find a job, and seek help with less pressure of speaking a second language. It is a place where Latino culture thrives and a source of comfort to a recent immigrant, as it would offer him or her a place to work and live while perfecting fluency of the English language.
However, some argue that the barrio also represents the inequality faced by many Mexican Americans in the United States. Barrios usually offer a lower quality of education, provide poorer jobs than other neighborhoods, and generally receive less government attention than wealthier more integrated Hispanic neighborhoods.
Housing market practices.
Studies have shown that the segregation among Mexican Americans and Mexican immigrants seems to be declining. One study from 1984 found that Mexican American applicants were offered the same housing terms and conditions as Anglo Americans. They were asked to provide the same information (regarding employment, income, credit checks, etc.) and asked to meet the same general qualifications of their Anglo peers.
However, in this same study, it was found that Mexican Americans were more likely than Anglo Americans to be asked to pay a security deposit or application fee. Another interesting aspect of this study is that the Mexican American applicants were more likely to be placed onto a waiting list than the Anglo Americans applicants.
Latino segregation versus Black segregation.
Historically, African Americans have faced much harsher treatment concerning segregation than any other racial, ethnic, or ancestral group. However, throughout the Southwest during the first fifty years of the 20th century, Mexican Americans faced segregation, despite being legally classified as "white" (The legal classification of all Mexicans as white was a convention originally enacted to enforce the Treaty of Guadalupe Hidalgo that ended the Mexican American war in 1848. According to the Treaty Mexicans remaining in the new US territory would have the right of citizens, which at that time was only granted to "white" people.) According to legal scholar Claire Sheridan, referring to the legal, social and political status of Mexican Americans in the early 20th century: "Anglos rarely distinguished between Mexicans and Mexican Americans and painted a picture of "Mexicans" as an economic and cultural threat to America. In this period, Mexican Americans increasingly were denied many of the rights of citizens. Like the African American population, many were placed in segregated schools with inferior educational resources, barred from restaurants, movie theaters, bathrooms, and public swimming pools, and denied the possibility of living in white neighborhoods. Yet none of this segregation was formally encoded in law. For legal purposes, Mexican Americans were white. They were counted as white in the census and, unlike non-whites (other than those from Africa), were able to naturalize. However, law clashed with perceptions of racial "reality," creating a citizenship status for Mexican Americans that many considered to be legal fiction. This gap between their legal and social standing was reflected in local interpretations of the law and in the regulation of their political participation through mechanisms such as poll taxes, literacy tests, and blue ribbon jury commissions. This unequal treatment continued through the war years and into the 1950s. Mexican Americans' unequal status was especially evident in their representation on juries. While not prohibited by law from serving, they were almost universally excluded on the grounds that they were not qualified to serve." 
When comparing the contemporary segregation of Mexican Americans to that of Black Americans, some scholars claim that "Latino segregation is less severe and fundamentally different than Black residential segregation." Some studies suggest that contemporary segregation of Latinos is more likely to be due to factors such as lower socioeconomic status and immigration while the segregation of African Americans is more likely to be due to larger issues of the history of racism in the US.
Segregated schools.
During certain periods, Mexican American children sometimes were forced to register at "Mexican schools", where classroom conditions were poor, the school year was shorter, and the quality of education was substandard.
Various reasons for the inferiority of the education given to Mexican American students have been listed by James A. Ferg-Cadima including: inadequate resources, poor equipment, unfit building construction, shortened school year (see below), failure to prevent drop out, limited access to high school, a watered down curriculum, poor instruction, disproportionate suspension, expulsion, harassment and non-enforced attendance rules.
In 1923, the Texas Education Survey Commission found that the school year for some non-white groups was 1.6 months shorter than the average school year. This may be connected to the fact that minority labor was needed during this time. As the agricultural field required the cheap labor provided by exploited minorities, it has been suggested that the minority school year was shortened to allow for these students to work instead of receive the extra 1.6 months of education.
Some have interpreted the shortened school year as a "means of social control" implementing policies to ensure that Mexican Americans would maintain the unskilled labor force required for a strong economy. A lesser education would serve to confine Mexican Americans to the bottom rung of the social ladder. By limiting the number of days that Mexican Americans could attend school and allotting time for these same students to work, in mainly agricultural and seasonal jobs, the prospects for higher education and upward mobility were slim.
Immigration and segregation.
Immigration hubs are popular destinations for Latino immigrants. They are increasing in size and continue to be highly segregated. The largest immigration hubs include Los Angeles, New York, and Chicago. The highly segregated areas of these cities have historically served the purpose of allowing immigrants to become comfortable in the United States, accumulate wealth, and eventually leave. The historical view of immigration hubs sees these cities as temporary starting points for immigrants. They are not expected to live their entire lives within the United States inside segregated areas. Rather, they are expected to accumulate enough wealth to start a life within the larger society.
This model of immigration and residential segregation, explained above, is the model which has historically been accurate in describing the experiences of Latino immigrants. However, the patterns of immigration seen today no longer follows this model. This old model is termed the standard spatial assimilation model. More contemporary models are the polarization model and the diffusion model.
The spatial assimilation model posits that as immigrants would live within this country's borders, they would simultaneously become more comfortable in their new surroundings, their socioeconomic status would rise, and their ability to speak English would increase. The combination of these changes would allow for the immigrant to move out of the barrio and into the dominant society. This type of assimilation reflects the experiences of immigrants of the early twentieth century. Recent, more contemporary, models of residential segregation are the polarization model and the diffusion model are described below.
Polarization model suggests that the immigration of non-Black minorities into the United States further separates Blacks and Whites, as though the new immigrants are a buffer between them. This creates a hierarchy in which Blacks are at the bottom, Whites are at the top, and other groups fill the middle. In other words, the polarization model posits that Asians and Amerindians are less segregated than their African American peers because White American society would rather live closer to Asians or Amerindians than Blacks.
The diffusion model has also been suggested as a way of describing the immigrant's experience within the United States. This model is rooted in the belief that as time passes, more and more immigrants enter the country. This model suggests that as the United States becomes more populated with a more diverse set of peoples, stereotypes and discriminatory practices will decrease, as awareness and acceptness increase. The diffusion model predicts that new immigrants will break down old patterns of discrimination and prejudice, as one becomes more and more comfortable with the more diverse neighborhoods that are created through the influx of immigrants. Applying this model to the experiences of Mexican Americans forces one to see Mexican American immigrants as positive additions to the "American melting pot," in which as more additions are made to the pot, the more equal and accepting society will become.
Overcrowding.
The issue of overcrowding is closely related to the issue of segregation and immigration. As immigrants enter the country, they are likely to settle in areas where their friends, family, or simply other who share their culture, have settled. It is not uncommon for many members of families, extended families, or friends, to live in what is considered "overcrowded" conditions.
A large aspect of the segregation of Latinos within the United States is overcrowding. Rates of overcrowding among Latinos, especially in American suburbs, are high. The U.S. Census Bureau considers a residence to be overcrowded if there is more than one person per room
There are various explanations for overcrowding. One widely held belief about overcrowding is based on a stereotype of living in close proximity simply to cultural preference. To expand on that point, it is widely believed that immigrant Hispanic families live in dense households because of their desire to remain in close proximity with extended family. However, this view does not paint the entire picture. Some families may live under one roof by choice and it is possible that Hispanic people may have different cultural standards than other population groups, thus allowing them to be more comfortable living with extended family underneath the same roof. However, one cannot reduce all problems of Hispanic overcrowding to cultural preference, as this offers an incomplete understanding of the issue at hand.
Hispanic people may live in overcrowded conditions out of economic necessity and simply because they choose to live differently than others. Lack of affordable housing and a poor selection of well-paying occupations may combine to create the necessity of many living close together. Because one certain family may find very few opportunities for sufficient housing or find themselves without adequate funds for a house of their own, they may be forced to live in crowded conditions.
The Chicano movement and the Chicano Moratorium.
In the heady days of the late 1960s, when the student movement was active around the globe, the Chicano movement conducted actions such as the mass walkouts by high school students in Denver and East Los Angeles in 1968 and the Chicano Moratorium in Los Angeles in 1970. The movement was particularly strong at the college level, where activists formed MEChA, an organization that seeks to promote Chicano unity and empowerment through education and political action, but also espouses revanchist ideals centered around "taking back" the American southwest for Mexicans. The Chicano Moratorium, formally known as the National Chicano Moratorium Committee, was a movement of Chicano anti-war activists that built a broad-based but fragile coalition of Mexican-American groups to organize opposition to the Vietnam War. The committee was led by activists from local colleges and members of the "Brown Berets", a group with roots in the high school student movement that staged walkouts in 1968, known as the East L.A. walkouts, also called "blowouts". The best known historical fact of the Moratorium was the death of Rubén Salazar, known for his reporting on civil rights and police brutality. The official story is that Salazar was killed by a tear gas canister fired by a member of the Los Angeles County Sheriff's Department into the Silver Dollar Café at the conclusion of the August 29 rally.
Mexican-American communities.
(according to the 2010 census, L.A. is now under 20% are of Mexican descent now with equally numerous Central American national groups and the rest-10% other Latino).
A dynamic community.
In the 1990s and 2000s, the Midwestern United States became a major destination for Mexican immigrants. But Mexican-Americans were already present in the Midwest's industrial cities and urban areas. Especially Mexicans/Latinos came into states like Illinois (mostly in Chicagoland), Indiana especially the Northern section, Iowa, Kansas, Michigan (i.e. the Detroit metropolitan area), Minnesota, Missouri, Nebraska and Wisconsin due to needs of the region's industrial manufacturing base.
Another destination of Mexican and Latin American immigration was the Northeastern United States, in places such as the Monongahela Valley, Pennsylvania; Mahoning Valley, Ohio; throughout Massachusetts and the state of Rhode Island; New Haven, Connecticut along with other Latin American nationalities; Washington, D.C. with Maryland and Northern Virginia included; the Hudson Valley and Long Island of New York state; the Jersey Shore region and the Delaware Valley, New Jersey. 
Communities that consist mostly of recent-arrived immigrants from Mexico, are also present in other parts of the rural Southeastern United States, in states such as Georgia, Maryland, Tennessee, Alabama, Arkansas and Oklahoma. A growing Mexican-American population is also present in urban areas such as Orlando, Florida with the Central Florida region included; the Atlanta metro area; Charlotte, North Carolina- with a majority Hispanic enclave of Eastland; New Orleans which increased after Hurricane Katrina in Sep. 2005; the Hampton Roads, Virginia area; the states of Maine, New Hampshire and Delaware; and Pennsylvania esp. in the Philadelphia metropolitan area. 
US communities with largest population of Mexican-Americans.
The top 25 US communities with the highest populations of Mexicans (Source: Census 2010)

Mexico
Mexico (; , ), officially the United Mexican States
(), is a federal constitutional republic in North America. It is bordered on the north by the United States of America; on the south and west by the Pacific Ocean; on the southeast by Guatemala, Belize, and the Caribbean Sea; and on the east by the Gulf of Mexico. Covering almost two million square kilometres (over 760,000 sq mi), Mexico is the fifth largest country in the Americas by total area and the thirteenth largest independent nation in the world. With an estimated population of over 113 million, it is the world's eleventh most populous country and the most populous Spanish-speaking country. Mexico is a federation comprising thirty-one states and a Federal District, the capital city.
In pre-Columbian Mexico many cultures matured into advanced civilizations such as the Olmec, the Toltec, the Teotihuacan, the Zapotec, the Maya and the Aztec before first contact with Europeans. In 1521, Spain conquered and colonized the territory from its base in México-Tenochtitlan, which was administered as the Viceroyalty of New Spain. This territory would eventually become Mexico following recognition of the colony's independence in 1821. The post-independence period was characterized by economic instability, the Mexican-American War and territorial cession to the United States, a civil war, two empires and a domestic dictatorship. The latter led to the Mexican Revolution in 1910, which culminated with the promulgation of the 1917 Constitution and the emergence of the country's current political system. Elections held in July 2000 marked the first time that an opposition party won the presidency from the Institutional Revolutionary Party. Since 2006 the country has been in the midst of a drug war which has caused 60,000 deaths.
Mexico has one of the world's largest economies, and is considered both a regional power and middle power. In addition, Mexico was the first Latin American member of the Organisation for Economic Co-operation and Development OECD (since 1994), and considered an upper-middle income country by the World Bank. Mexico is considered a newly industrialized country and an emerging power. It has the thirteenth largest nominal GDP and the eleventh largest GDP by purchasing power parity. The economy is strongly linked to those of its North American Free Trade Agreement (NAFTA) partners, especially the United States. Mexico ranks sixth in the world and first in the Americas by number of UNESCO World Heritage Sites with 31, and in 2007 was the tenth most visited country in the world with 21.4 million international arrivals per year.
Etymology.
After New Spain won independence from Spain, it was decided that the new country would be named after its capital, Mexico City, which was founded in 1524 on top of the ancient Aztec capital of México-Tenochtitlan. The name comes from the Nahuatl language, but its meaning is unknown.
"Mēxihco" was the Nahuatl term for the heartland of the Aztec Empire, namely, the Valley of Mexico, and its people, the Mexica, and surrounding territories which became the future State of Mexico as a division of New Spain prior to independence (compare "Latium"). It is generally considered to be a toponym for the valley which became the primary ethnonym for the Aztec Triple Alliance as a result, or vice versa.
The suffix "-co" is the Nahuatl locative, making the word a place name. Beyond that, the etymology is uncertain. It has been suggested that it is derived from Mextli or Mēxihtli, a secret name for the god of war and patron of the Aztecs, Huitzilopochtli, in which case Mēxihco means "Place where Huitzilopochtli lives". Another hypothesis suggests that "Mēxihco" derives from a portmanteau of the Nahuatl words for "moon" ("mētztli") and navel ("xīctli"). This meaning ("Place at the Center of the Moon") might then refer to Tenochtitlan's position in the middle of Lake Texcoco. The system of interconnected lakes, of which Texcoco formed the center, had the form of a rabbit, which the Mesoamericans pareidolically associated with the moon. Still another hypothesis suggests that it is derived from Mēctli, the goddess of maguey.
The name of the city-state was transliterated to Spanish as México with the phonetic value of the letter  in Medieval Spanish, which represented the voiceless postalveolar fricative . This sound, as well as the voiced postalveolar fricative , represented by a , evolved into a voiceless velar fricative during the 16th century. This led to the use of the variant Méjico in many publications in Spanish, most notably in Spain, whereas in Mexico and most other Spanish–speaking countries México was the preferred spelling. In recent years the Real Academia Española, which regulates the Spanish language, determined that both variants are acceptable in Spanish but that the normative recommended spelling is México. The majority of publications in all Spanish-speaking countries now adhere to the new norm, even though the alternative variant is still occasionally used. In English, the  in Mexico represents neither the original nor the current sound, but the consonant cluster .
The official name of the country has changed as the form of government has changed. On two occasions (1821–1823 and 1863–1867), the country was known as Imperio Mexicano (Mexican Empire). All three federal constitutions (1824, 1857 and 1917, the current constitution) used the name Estados Unidos Mexicanos—or the variants Estados Unidos mexicanos and Estados-Unidos Mexicanos, all of which have been translated as "United Mexican States". The term República Mexicana, "Mexican Republic" was used in the 1836 Constitutional Laws.
History.
Ancient cultures.
Archaic period.
The earliest human remains in Mexico are chips of stone tools found near campfire remains in the Valley of Mexico and radiocarbon-dated to c. 23,000 years ago. Mexico is the site of the domestication of maize and beans which caused a transition from paleo-Indian hunter-gatherers to sedentary agricultural villages beginning around 7000 BCE.
Classic periods.
In the subsequent formative areas maize cultivation and cultural traits such as a complex mythological and religious complex, a vigesimal numeric system, were diffused from the Mexican cultures to the rest of the Mesoamerican culture area. In this period villages began to become socially stratified and develop into chiefdoms, and the development of large ceremonial centers.
Among the earliest complex civilizations in Mexico was the Olmec culture which flourish on the Gulf Coast from around 1500 BCE. Olmec cultural traits diffused through Mexico into other formative era cultures in Chiapas, Oaxaca and the Valley of Mexico. The formative period saw the spread of distinct religious and symbolic traditions, as well as artistic and architectural complexes. In the subsequent pre-classical period, the Maya and Zapotec civilizations developed complex centers at Calakmul and Monte Albán respectively. During this period the first true Mesoamerican writing systems were developed in the Epi-Olmec and the Zapotec cultures, and the Mesoamerican writing tradition reached its height in the Classic Maya Hieroglyphic script.
In Central Mexico, the height of the classic period saw the ascendancy of Teotihuacan, which formed a military and commercial empire whose political influence stretched south into the Maya area as well as north. At its peak, Teotihuacan, containing some of the largest pyramidal structures built in the pre-Columbian Americas, had a population of more than 150,000 people. At the collapse of Teotihuacán around 600 CE, competition between several important political centers in central Mexico such as Xochicalco and Cholula ensued. At this time during the Epi-Classic Nahua peoples began moving south into Mesoamerica from the North, and became politically and culturally dominant in central Mexico, as they displaced speakers of Oto-Manguean languages.
Post-classic period.
During the early post-classic Central Mexico was dominated by the Toltec culture, Oaxaca by the Mixtec and the lowland Maya area had important centers at Chichén Itzá and Mayapán. Towards the end of the post-Classic period the Aztecs of Central Mexico built a tributary empire covering most of central Mexico. The Aztecs were noted for practicing human sacrifice on a large scale. The distinct Mesoamerican cultural tradition ended with the Spanish conquest in the 16th century, and over the next centuries Mexican indigenous cultures were gradually subjected to Spanish colonial rule.
Conquest.
The Spanish conquest of the Aztec Empire began in February 1519 when Hernán Cortés arrived at the port in Veracruz with ca. 500 conquistadores, and later moved on to the Aztec capital. On his search for gold and other riches, Cortés decided to invade and conquer the Aztec empire.
The ruler of the Aztec empire upon the arrival of the Spaniards was Moctezuma II, who was later killed; his successor and brother Cuitláhuac took control of the Aztec empire, but was among the first to fall from the smallpox epidemic a short time later. Unintentionally introduced by Spanish conquerors, smallpox ravaged Mesoamerica in the 1520s, killing more than 3 million Aztecs. Other sources, however, mentioned that the death toll of the Aztecs might have reached up to 15 million (out of a population of less than 30 million). Severely weakened, the Aztec empire was easily defeated by Cortés and his forces on his second return. Smallpox was a devastatingly selective disease—it generally only killed the Aztecs, while the Spaniards were immune to the disease. The deaths caused by smallpox are believe to have triggered a rapid growth of Christianity in Mexico and the Americas. At first, the Aztecs believed the epidemic was a punishment from an angry god, but they later accepted their fate and no longer resisted the Spanish rule. Many of the surviving Aztecs blamed the cause of smallpox to the superiority of the Christian god, which resulted in the acceptance of Catholicism and yielding to the Spanish rule throughout Mexico.
The territory became part of the Spanish Empire under the name of New Spain. Mexico City was systematically rebuilt by Cortés following the Fall of Tenochtitlan in 1521. Much of the identity, traditions and architecture of Mexico were created during the colonial period.
Independence.
On September 16, 1810, independence from Spain was declared by priest Miguel Hidalgo y Costilla, in the small town of Dolores, Guanajuato. The first insurgent group was formed by Hidalgo, the Spanish viceregal army captain Ignacio Allende, the militia captain Juan Aldama and "La Corregidora" Josefa Ortiz de Domínguez. Hidalgo and some of his soldiers were captured and executed by firing squad in Chihuahua, on July 31, 1811. Following his death, the leadership was assumed by priest José María Morelos, who occupied key southern cities.
In 1813 the Congress of Chilpancingo was convened and, on November 6, signed the "Solemn Act of the Declaration of Independence of Northern America". Morelos was captured and executed on December 22, 1815. In subsequent years, the insurgency was near collapse, but in 1820 Viceroy Juan Ruiz de Apodaca sent an army under the criollo general Agustín de Iturbide against the troops of Vicente Guerrero. Instead, Iturbide approached Guerrero to join forces, and on August 24, 1821 representatives of the Spanish Crown and Iturbide signed the "Treaty of Córdoba" and the "Declaration of Independence of the Mexican Empire", which recognized the independence of Mexico under the terms of the "Plan of Iguala".
Juárez reforms and territorial losses.
Agustín de Iturbide immediately proclaimed himself emperor of the First Mexican Empire. A revolt against him in 1823 established the United Mexican States. In 1824, a Republican Constitution was drafted and Guadalupe Victoria became the first president of the newly born country. The first decades of the post-independence period were marked by economic instability, which led to the Pastry War in 1836, and a constant strife between liberales, supporters of a federal form of government, and conservadores, proposals of a hierarchical form of government.
General Antonio López de Santa Anna, a centralist and two-time dictator, approved the Siete Leyes in 1836, a radical amendment that institutionalized the centralized form of government. When he suspended the 1824 Constitution, civil war spread across the country, and three new governments declared independence: the Republic of Texas, the Republic of the Rio Grande and the Republic of Yucatán.
Texas successfully achieved independence and was annexed by the United States. A border dispute led to the Mexican-American War, which began in 1846 and lasted for two years; the War was settled via the Treaty of Guadalupe Hidalgo, which forced Mexico to give up over half of its land to the U.S., including Alta California, New Mexico, and the disputed parts of Texas. A much smaller transfer of territory in what is today southern Arizona and southwestern New Mexico — the Gadsden Purchase — occurred in 1854. The Caste War of Yucatán, the Mayan uprising that began in 1847, was one of the most successful modern Native American revolts. Maya rebels, or Cruzob, maintained relatively independent enclaves until the 1930s.
Dissatisfaction with Santa Anna's return to power led to the liberal "Plan of Ayutla", initiating an era known as La Reforma, after which a new Constitution was drafted in 1857 that established a secular state, federalism as the form of government, and several freedoms. As the conservadores refused to recognize it, the Reform War began in 1858, during which both groups had their own governments. The war ended in 1861 with victory by the Liberals, led by Amerindian President Benito Juárez. In the 1860s Mexico underwent a military occupation by France, which established the Second Mexican Empire under the rule of Habsburg Archduke Ferdinand Maximilian of Austria with support from the Roman Catholic clergy and the conservadores, who later switched sides and joined the liberales. Maximilian surrendered, was tried on June 14 and was executed on June 19, 1867.
Porfiriato.
Porfirio Díaz, a republican general during the French intervention, ruled Mexico from 1876 to 1880 and then from 1884 to 1911 in five consecutive reelections, period known as the Porfiriato, characterized by remarkable economic achievements, investments in the arts and sciences, but also of economic inequality and political repression.
Mexican Revolution.
A likely electoral fraud that led to Diaz's fifth reelection sparked the 1910 Mexican Revolution, initially led by Francisco I. Madero.
Díaz resigned in 1911 and Madero was elected president but overthrown and murdered in a coup d'état two years later directed by conservative general Victoriano Huerta. That event re-ignited the civil war, involving figures such as Francisco Villa and Emiliano Zapata, who formed their own forces. A third force, the constitutional army led by Venustiano Carranza, managed to bring an end to the war, and radically amended the 1857 Constitution to include many of the social premises and demands of the revolutionaries into what was eventually called the 1917 Constitution. It is estimated that the war killed 900,000 of the 1910 population of 15 million. Assassinated in 1920, Carranza was succeeded by another revolutionary hero, Álvaro Obregón, who in turn was succeeded by Plutarco Elías Calles. Obregón was reelected in 1928 but assassinated before he could assume power.
PRI rule.
In 1929, Calles founded the National Revolutionary Party (PNR), later renamed the Institutional Revolutionary Party (PRI), and started a period known as the Maximato, which ended with the election of Lázaro Cárdenas, who implemented many economic and social reforms, and most significantly expropriated the oil industry into Pemex on March 18, 1938, but sparked a diplomatic crisis with the countries whose citizens had lost businesses by Cárdenas' radical measure.
Between 1940 and 1980, Mexico experienced a substantial economic growth that some historians call the "Mexican miracle". Although the economy continued to flourish, social inequality remained a factor of discontent. Moreover, the PRI rule became increasingly authoritarian and at times oppressive (see the 1968 Tlatelolco massacre, which claimed the life of around 30–800 protesters).
Electoral reforms and high oil prices followed the administration of Luis Echeverría, mismanagement of these revenues led to inflation and exacerbated the 1982 Crisis. That year, oil prices plunged, interest rates soared, and the government defaulted on its debt. President Miguel de la Madrid resorted to currency devaluations which in turn sparked inflation.
In the 1980s the first cracks emerged in PRI's monopolistic position. In Baja California, Ernesto Ruffo Appel was elected as governor. In 1988, electoral fraud prevented leftist candidate Cuauhtémoc Cárdenas from winning the national presidential elections, giving Carlos Salinas de Gortari the Presidency and leading to massive protests in Mexico City.
Salinas embarked on a program of neoliberal reforms which fixed the exchange rate, controlled inflation and culminated with the signing of the North American Free Trade Agreement (NAFTA), which came into effect on January 1, 1994. The same day, the Zapatista Army of National Liberation (EZLN) started a two-week-long armed rebellion against the federal government, and has continued as a non-violent opposition movement against neoliberalism and globalization.
Democratization.
In December 1994, a month after Salinas was succeeded by Ernesto Zedillo, the Mexican economy collapsed, with a rapid rescue packaged authorized by U.S. President Bill Clinton and major macroeconomic reforms started by president Zedillo, the economy rapidly recovered and growth peaked at almost 7% by the end of 1999.
In 2000, after 71 years, the PRI lost a presidential election to Vicente Fox of the opposition National Action Party (PAN). In the 2006 presidential elections, Felipe Calderón from the PAN was declared the winner, with a very narrow margin over leftist politician Andrés Manuel López Obrador of the Party of the Democratic Revolution (PRD). López Obrador, however, contested the election and pledged to create an "alternative government".
Administrative divisions.
The United Mexican States are a federation of thirty-one free and sovereign states, which form a union that exercises a degree of jurisdiction over the Federal District and other territories.
Each state has its own constitution, congress, and a judiciary, and its citizens elect by direct voting a governor for a six-year term, and representatives to their respective unicameral state congresses for three-year terms.
The Federal District is a special political division that belongs to the federation as a whole and not to a particular state, and as such, has more limited local rule than the nation's states.
The states are divided into municipalities, the smallest administrative political entity in the country, governed by a mayor or municipal president (Presidente municipal), elected by its residents by plurality.
Politics.
The United Mexican States are a federation whose government is representative, democratic and republican based on a presidential system according to the 1917 Constitution. The constitution establishes three levels of government: the federal Union, the state governments and the municipal governments. According to the constitution, all constituent states of the federation must have a republican form of government composed of three branches: the executive, represented by a governor and an appointed cabinet, the legislative branch constituted by a unicameral congress and the judiciary, which will include called state Supreme Court of Justice. They also have their own civil and judicial codes.
The bicameral Congress of the Union, composed of a Senate and a Chamber of Deputies, makes federal law, declares war, imposes taxes, approves the national budget and international treaties, and ratifies diplomatic appointments. Seats to federal and state legislatures are elected by a system of parallel voting that includes plurality and proportional representation. The Chamber of Deputies of the Congress of the Union is conformed by 300 deputies elected by plurality and 200 deputies by proportional representation with closed party lists for which the country is divided into 5 electoral constituencies or circumscriptions. The Senate is conformed by a total of 128 senators: 64 senators, two for each state and two for the Federal District, elected by plurality in pairs; 32 senators assigned to the first minority or first-runner up (one for each state and one for the Federal District), and 32 are assigned by proportional representation with closed party lists for which the country conforms a single electoral constituency.
The Executive, is the President of the United Mexican States, who is the head of state and government, as well as the commander-in-chief of the Mexican military forces. The President also appoints the Cabinet and other officers. The President is responsible for executing and enforcing the law, and has the authority of vetoing bills.
The Judiciary branch of government is the Supreme Court of Justice, comprised by eleven judges appointed by the President with Senate approval, who interpret laws and judge cases of federal competency. Other institutions of the judiciary are the Electoral Tribunal, collegiate, unitary and district tribunals, and the Council of the Federal Judiciary.
Three parties have historically been the dominant parties in Mexican politics: the National Action Party: a right-wing conservative party founded in 1939 and belonging to the Christian Democrat Organization of America; the Institutional Revolutionary Party, a center-left party and member of Socialist International that was founded in 1929 to unite all the factions of the Mexican Revolution and held an almost hegemonic power in Mexican politics since then; the Party of the Democratic Revolution: a left-wing party, founded in 1989 as the successor of the coalition of socialists and liberal parties.
Foreign relations.
The foreign relations of Mexico are directed by the President of Mexico and managed through the Ministry of Foreign Affairs. The principles of the foreign policy are constitutionally recognized in the Article 89, Section 10, which include: respect for international law and legal equality of states, their sovereignty and independence, non-intervention in the domestic affairs of other countries, peaceful resolution of conflicts, and promotion of collective security through active participation in international organizations. Since the 1930s, the Estrada Doctrine has served as a crucial complement to these principles.
Mexico is one of the founding members of several international organizations, most notably the United Nations, the Organization of American States, the Organization of Ibero-American States, the OPANAL and the Rio Group. In 2008, Mexico contributed over 40 million dollars to the United Nations regular budget. In addition, it has been the only Latin American member of the Organisation for Economic Co-operation and Development since it joined in 1994 though Chile is in the process of gaining full membership. Mexico is considered as a regional power hence its presence in major economic groups such as the G8+5 and the G-20. In addition, since the 1990s Mexico has sought a reform of the United Nations Security Council and its working methods with the support of Canada, Italy, Pakistan and other nine countries, which form a group informally called the Coffee Club.
After the War of Independence, the relations of Mexico were focused primarily on the United States, its northern neighbor, largest trading partner, and the most powerful actor in hemispheric and world affairs. Mexico supported the Cuban government since its establishment in the early 1960s, the Sandinista revolution in Nicaragua during the late 1970s, and leftist revolutionary groups in El Salvador during the 1980s. A greater priority to Latin America and the Caribbean has been given in the administration of President Felipe Calderón.
Military.
The Mexican Armed Forces have two branches: the Mexican Army (which includes the Mexican Air Force), and the Mexican Navy. The Mexican Armed Forces maintain significant infrastructure, including facilities for design, research, and testing of weapons, vehicles, aircraft, naval vessels, defense systems and electronics; military industry manufacturing centers for building such systems, and advanced naval dockyards that build heavy military vessels and advanced missile technologies.
In recent years, Mexico has improved its training techniques, military command and information structures and has taken steps to becoming more self-reliant in supplying its military by designing as well as manufacturing its own arms, missiles, aircraft, vehicles, heavy weaponry, electronics, defense systems, armor, heavy military industrial equipment and heavy naval vessels. Since the 1990s, when the military escalated its role in the war on drugs, increasing importance has been placed on acquiring airborne surveillance platforms, aircraft, helicopters, digital war-fighting technologies, urban warfare equipment and rapid troop transport.
Mexico has the capabilities to manufacture nuclear weapons, but forwent this possibility with the Treaty of Tlatelolco in 1968 and pledged to only use its nuclear technology for peaceful purposes. In 1970 Mexico's national institute for nuclear research successfully refined weapons grade uranium which is used in the manufacture of nuclear weapons but in April 2010, Mexico agreed to turn over its weapons grade uranium to the United States.
Historically, Mexico has remained neutral in international conflicts, with the exception of World War II. However, in recent years some political parties have proposed an amendment of the Constitution in order to allow the Mexican Army, Air Force or Navy to collaborate with the United Nations in peacekeeping missions, or to provide military help to countries that officially ask for it.
Geography.
Mexico is located between latitudes 14° and 33°N, and longitudes 86° and 119°W in the southern portion of North America. Almost all of Mexico lies in the North American Plate, with small parts of the Baja California peninsula on the Pacific and Cocos Plates. Geophysically, some geographers include the territory east of the Isthmus of Tehuantepec (around 12% of the total) within Central America. Geopolitically, however, Mexico is entirely considered part of North America, along with Canada and the United States.
Mexico's total area is , making it the world's 14th largest country by total area, and includes approximately of islands in the Pacific Ocean (including the remote Guadalupe Island and the Revillagigedo Islands), Gulf of Mexico, Caribbean, and Gulf of California. From its farthest land points, Mexico is a little over in length.
On its north, Mexico shares a border with the United States. The meandering Río Bravo del Norte (known as the Rio Grande in the United States) defines the border from Ciudad Juárez east to the Gulf of Mexico. A series of natural and artificial markers delineate the United States-Mexican border west from Ciudad Juárez to the Pacific Ocean. On its south, Mexico shares an border with Guatemala and a border with Belize.
Mexico is crossed from north to south by two mountain ranges known as Sierra Madre Oriental and Sierra Madre Occidental, which are the extension of the Rocky Mountains from northern North America. From east to west at the center, the country is crossed by the Trans-Mexican Volcanic Belt also known as the Sierra Nevada. A fourth mountain range, the Sierra Madre del Sur, runs from Michoacán to Oaxaca.
As such, the majority of the Mexican central and northern territories are located at high altitudes, and the highest elevations are found at the Trans-Mexican Volcanic Belt: Pico de Orizaba (), Popocatepetl () and Iztaccihuatl () and the Nevado de Toluca (). Three major urban agglomerations are located in the valleys between these four elevations: Toluca, Greater Mexico City and Puebla.
Climate.
The Tropic of Cancer effectively divides the country into temperate and tropical zones. Land north of the twenty-fourth parallel experiences cooler temperatures during the winter months. South of the twenty-fourth parallel, temperatures are fairly constant year round and vary solely as a function of elevation. This gives Mexico one of the world's most diverse weather systems.
Areas south of the twenty-fourth parallel with elevations up to (the southern parts of both coastal plains as well as the Yucatán Peninsula), have a yearly median temperature between . Temperatures here remain high throughout the year, with only a difference between winter and summer median temperatures. Both Mexican coasts, except for the south coast of the Bay of Campeche and northern Baja, are also vulnerable to serious hurricanes during the summer and fall. Although low-lying areas north of the twentieth-fourth parallel are hot and humid during the summer, they generally have lower yearly temperature averages (from ) because of more moderate conditions during the winter.
Many large cities in Mexico are located in the Valley of Mexico or in adjacent valleys with altitudes generally above . This gives them a year-round temperate climate with yearly temperature averages (from ) and cool nighttime temperatures throughout the year.
Many parts of Mexico, particularly the north, have a dry climate with sporadic rainfall while parts of the tropical lowlands in the south average more than of annual precipitation. For example, many cities in the north like Monterrey, Hermosillo, and Mexicali experience temperatures of or more in summer. In the Sonoran Desert temperatures reach or more.
Biodiversity.
Mexico is one of the 18 megadiverse countries of the world. With over 200,000 different species, Mexico is home of 10–12% of the world's biodiversity. Mexico ranks first in biodiversity in reptiles with 707 known species, second in mammals with 438 species, fourth in amphibians with 290 species, and fourth in flora, with 26,000 different species. Mexico is also considered the second country in the world in ecosystems and fourth in overall species. Approximately 2,500 species are protected by Mexican legislations.
As of 2002, Mexico had the second fastest rate of deforestation in the world, second only to Brazil. The government has taken another initiative in the late 1990s to expand the people's knowledge, interest and use of the country's esteemed biodiversity, through the Comisión Nacional para el Conocimiento y Uso de la Biodiversidad.
In Mexico, are considered "Protected Natural Areas." These include 34 biosphere reserves (unaltered ecosystems), 67 national parks, 4 natural monuments (protected in perpetuity for their aesthetic, scientific or historical value), 26 areas of protected flora and fauna, 4 areas for natural resource protection (conservation of soil, hydrological basins and forests) and 17 sanctuaries (zones rich in diverse species).
The discovery of the Americas brought to the rest of the world many widely used food crops and edible plants. Some of Mexico's native culinary ingredients include: chocolate, avocado, tomato, maize, vanilla, guava, chayote, epazote, camote, jícama, nopal, zucchini, tejocote, huitlacoche, sapote, mamey sapote, many varieties of beans, and an even greater variety of chiles, such as the habanero and the jalapeño. Most of these names come from indigenous languages like Nahuatl.
Due to its high biodiversity Mexico has also been a frequent site of bioprospecting by international research bodies. The first highly successful instance being the discovery in 1947 of the tuber "Barbasco" ("Dioscorea composita") which has a high content of diosgenin, revolutionizing the production of synthetic hormones in the 1950es and 1960es and eventually leading to the invention of combined oral contraceptive pills.
Economy.
Mexico has the 13th largest nominal GDP and the 11th largest by purchasing power parity. GDP annual average growth for the period of 1995–2002 was 5.1%. Foreign debt decreased to less than 20% of GDP. 17% of the population lives below Mexico's own poverty line, ranking behind Kazakhstan, Bulgaria and Thailand. The overall poverty rate however is 44.2%, while a full 70% lack one of the 8 economic indicators used to define poverty by the Mexican government. From the late 1990s, the majority of the population has been part of the growing middle class. But from 2004 to 2008 the portion of the population who received less than half of the median income has risen from 17% to 21% and the absolute levels of poverty have risen considerably from 2006 to 2010, with a rise in persons living in extreme or moderate poverty rising from 35 to 46% (52 million persons). This is also reflected by the fact that infant mortality in Mexico is three times higher than the average among OECD nations, and the literacy levels are in the median range of OECD nations. The Mexican economy is expected to nearly triple by 2020. According to Goldman Sachs, by 2050 Mexico will have the 5th largest economy in the world.
According to the OECD, worldwide Mexico is the country with the second highest degree of economic disparity between the extremely poor and extremely rich, beaten only by Chile – although it has been falling over the last decade. The bottom ten percent in the income hierarchy disposes of 1.36% of the country's resources, whereas the upper ten percent dispose of almost 36%. OECD also notes that Mexico's budgeted expenses for poverty alleviation and social development is only about a third of the OECD average – both in absolute and relative numbers.
According to a 2008 UN report the average income in a typical urbanized area of Mexico was $26,654, while the average income in rural areas just miles away was only $8,403. Daily minimum wages are set annually by law and determined by zone; $57.46 Mexican pesos ($5.75 USD) in Zona A (Baja California, Federal District, State of Mexico, and large cities), $55.84 Mexican pesos ($5.59 USD) in Zone B (Sonora, Nuevo León, Tamaulipas, Veracruz, and Jalisco), and $54.47 Mexican pesos ($5.45 USD) in Zone C (all other states)
In 2006, trade with the United States and Canada accounted for almost 50% of its exports and 45% of its imports. During the first three quarters of 2010, the United States had a $46.0 billion trade deficit with Mexico. In August 2010 Mexico surpassed France to became the 9th largest holder of US debt. The commercial and financial dependence on the US is a cause for concern. The remittances from Mexican citizens working in the United States account for 0.2% of Mexico's GDP which was equal to US$20 billion per year in 2004 and is the tenth largest source of foreign income after oil, industrial exports, manufactured goods, electronics, heavy industry, automobiles, construction, food, banking and financial services. According to Mexico's central bank, remittances in 2008 amounted to $25bn.
Mexico is the largest North American auto-producing nation, recently surpassing Canada and the U.S. The industry produces technologically complex components and engages in some research and development activities. The "Big Three" (General Motors, Ford and Chrysler) have been operating in Mexico since the 1930s, while Volkswagen and Nissan built their plants in the 1960s. In Puebla alone, 70 industrial part-makers cluster around Volkswagen. The relatively small domestic car industry is represented by DINA S.A., which has built buses and trucks for almost half a century, and the new Mastretta company that builds the high performance Mastretta MXT sports car.
Major players in the broadcasting industry are Televisa, the largest Spanish media company in the Spanish-speaking world, and TV Azteca.
Tourism.
 
Mexico reports the twenty-third highest tourism-based income in the world, and the highest in Latin America. The vast majority of tourists come to Mexico from the United States and Canada followed by Europe and Asia. A smaller number also come from other Latin American countries. In the 2008 Travel and Tourism Competitiveness Index, fifth among Latin American countries, and the ninth in the Americas.
Energy.
Energy production in Mexico is managed by state-owned companies: the Federal Commission of Electricity and Pemex.
Pemex, the public company in charge of exploration, extraction, transportation and marketing of crude oil and natural gas, as well as the refining and distribution of petroleum products and petrochemicals, is one of the largest companies in the world by revenue, making US $86 billion in sales a year. Mexico is the sixth-largest oil producer in the world, with 3.7 million barrels per day. In 1980 oil exports accounted for 61.6% of total exports; by 2000 it was only 7.3%.
The largest hydro plant in Mexico is the 2,400 MW Manuel Moreno Torres Dam in Chicoasén, Chiapas, in the Grijalva River. This is the world's fourth most productive hydroelectric plant.
Transportation.
The paved-roadway network extended for in 2005; were multi-lane freeways or expressways, most of which were tollways. Nonetheless, it still cannot meet national needs adequately. Most of the domestic passenger transport needs are served by an extensive bus network.
Mexico was one of the first Latin American countries to promote railway development, and the network covers . The Secretary of Communications and Transport of Mexico proposed a high-speed rail link that will transport its passengers from Mexico City to Guadalajara, Jalisco. The train, which travels at 300 kilometers per hour, allows passengers to travel from Mexico City to Guadalajara in just 2 hours. The whole project was projected to cost 240 billion pesos, or about 25 billion US$ and is being paid for jointly by the Mexican government and the local private sector including the wealthiest man in the world, Mexico's billionaire business tycoon Carlos Slim. The government of the state of Yucatán is also funding the construction of a high speed line connecting the cities of Cozumel to Mérida and Chichen Itza and Cancún.
In 1999, Mexico had 233 airports with paved runways; of these, 35 carry 97% of the passenger traffic. The Mexico City International Airport remains the largest in Latin America and the 44th largest in the world transporting 21 million passengers a year.
Communications.
The telecommunications industry is mostly dominated by Telmex ("Teléfonos de México"), privatized in 1990. As of 2006, Telmex had expanded its operations to Colombia, Peru, Chile, Argentina, Brazil and Uruguay and the United States. Other players in the domestic industry are Axtel and Maxcom. Due to Mexican orography, providing landline telephone service at remote mountainous areas is expensive, and the penetration of line-phones per capita is low compared to other Latin American countries, at forty-percent, however 82% of Mexicans over the age of 14 own a mobile phone. Mobile telephony has the advantage of reaching all areas at a lower cost, and the total number of mobile lines is almost two times that of landlines, with an estimation of 63 million lines. The telecommunication industry is regulated by the government through Cofetel ("Comisión Federal de Telecomunicaciones").
The Mexican satellite system is domestic and operates 120 earth stations. There is also extensive microwave radio relay network and considerable use of fiber-optic and coaxial cable. Mexican satellites are operated by "Satélites Mexicanos" (Satmex), a private company, leader in Latin America and servicing both North and South America. It offers broadcast, telephone and telecommunication services to 37 countries in the Americas, from Canada to Argentina. Through business partnerships Satmex provides high-speed connectivity to ISPs and Digital Broadcast Services. Satmex maintains its own satellite fleet with most of the fleet being Mexican designed and built.
Usage of radio, television, and Internet in Mexico is prevalent. There are approximately 1,410 radio broadcast stations and 236 television stations (excluding repeaters). Major players in the broadcasting industry are Televisa—the largest Spanish media company in the Spanish-speaking world—and TV Azteca.
Science and technology.
The National Autonomous University of Mexico was officially established in 1910, and the university become one of the most important institutes of higher learning in Mexico. UNAM provides world class education in science, medicine, and engineering. Many scientific institutes and new institutes of higher learning, such as National Polytechnic Institute (founded in 1936), were established during the first half of the 20th century. Most of the new research institutes were created within UNAM. Twelve institutes were integrated into UNAM from 1929 to 1973. In 1959, the Mexican Academy of Sciences was created to coordinate scientific efforts between academics.
In 1995 Mexican chemist Mario J. Molina shared the Nobel Prize in Chemistry with Paul J. Crutzen, and F. Sherwood Rowland for their work in atmospheric chemistry, particularly concerning the formation and decomposition of ozone. Molina, an alumnus of UNAM, became the first Mexican citizen to win the Nobel Prize in science.
In recent years, the largest scientific project being developed in Mexico was the construction of the Large Millimeter Telescope (Gran Telescopio Milimétrico, GMT), the world's largest and most sensitive single-aperture telescope in its frequency range. It was designed to observe regions of space obscured by stellar dust.
The electronics industry of Mexico has grown enormously within the last decade. In 2007 Mexico surpassed South Korea as the second largest manufacturer of televisions, and in 2008 Mexico surpassed China, South Korea and Taiwan to become the largest producer of smartphones in the world. There are almost half a million (451,000) students enrolled in electronics engineering programs.
Demographics.
The recently conducted 2010 Census showed a population of 112,336,538, making it the most populous Spanish-speaking country in the world. Assuming a growth rate of 8.8% every five years, the 2012 population can be estimated at almost 116 million. Furthermore, it is expected that Mexico's population will surpass that of Japan within the decade, putting Mexico among the world's ten most populous nations.
Mexico is ethnically diverse, the various indigenous peoples and European immigrants are united under a single national identity. The core part of Mexican national identity is formed on the basis of a synthesis of European culture with Indigenous cultures in a process known as mestizaje, alluding to the mixed biological origins of the majority of Mexicans. Mexican politicians and reformers such as José Vasconcelos and Manuel Gamio were instrumental in building a Mexican national identity on the concept of mestizaje. The term mestizo, often used in literature about Mexican social identities, carries a variety of socio-cultural, economic, racial and biological meanings. For this reason it has been deemed too imprecise to be used for ethnic classification and has been abandoned in Mexican censuses.
The category of "indígena" (indigenous) can be defined narrowly according to linguistic criteria including only speakers of one of Mexico's 62 indigenous languages or people who self-identify as having an indigenous cultural background. According to the National Commission for the Development of Indigenous Peoples, as of 2005 there are 10.1 million Mexicans who speak an indigenous language and claim indigenous heritage, representing 9.8% of the total population.
The word "mestizo" is sometimes used with the meaning of a person with mixed indigenous and European blood. This usage does not conform to the Mexican social reality where a person of pure indigenous genetic heritage would be considered Mestizo either by rejecting his indigenous culture or by not speaking an indigenous language, and a person with a very low percentage of indigenous genetic heritage would be considered fully indigenous either by speaking an indigenous language or by identifying with a particular indigenous cultural heritage.
Mexico represents the largest source of immigration to the United States. About 9% of the population born in Mexico is now living in the United States. 28.3 million Americans listed their ancestry as Mexican as of 2006. Per the 2000 U.S. Census, a plurality of 47.3% of Mexican Americans self identify as White, closely followed by Mexican Americans who self identify as "Some other race", usually Mestizo (European/Indian) with 45.5%.
Mexico is home to the largest number of U.S. citizens abroad (estimated at one million as of 1999). The Argentine community is considered to be the second largest foreign community in the country (estimated somewhere between 30,000 and 150,000). Mexico also has a large Lebanese community, now numbering around 400,000. In October 2008, Mexico agreed to deport Cubans using the country as an entry point to the US. Large numbers of Central American migrants who have crossed Guatemala's western border into Mexico are deported every year. Small numbers of illegal immigrants come from Ecuador, Cuba, China, South Africa, and Pakistan.
Indigenous peoples.
According to the National Commission for the Development of the Indigenous Peoples (CDI) there are 9,854,301 indigenous people reported in Mexico in 2000, which constitute 9.54% of the population in the country. The absolute indigenous population is growing, but at a slower rate than the rest of the population so that the percentage of indigenous peoples is nonetheless falling. The majority of the indigenous population is concentrated in the central and southern states, that are generally the least developed, and the majority of the indigenous population live in rural areas. Some indigenous communities have a degree of autonomy under the legislation of "usos y costumbres", which allows them to regulate some internal issues under customary law. According to the CDI, the states with the greatest percentage of indigenous population are: Yucatán, with 59%, Quintana Roo with 39% and Campeche with 27% of the population being indigenous, most of them Maya; Oaxaca with 48% of the population, the most numerous groups being the Mixtec and Zapotec peoples; Chiapas has 28%, the majority being Tzeltal and Tzotzil Maya; Hidalgo with 24%, the majority being Otomi; Puebla with 19%, and Guerrero with 17%, mostly Nahua people and the states of San Luis Potosí and Veracruz both home to a population of 15% indigenous people, mostly from the Totonac, Nahua and Teenek (Huastec) groups.
All of the indices of social development for the indigenous population are considerably lower than the national average. In all states indigenous people have higher infant mortality, in some states almost double of the non-indigenous populations. Literacy rates are also much lower, with 27% of indigenous children between 6 and 14 being illiterate compared to a national average of 12%. The indigenous population participate in the workforce longer than the national average, starting earlier and continuing longer. However, 55% of the indigenous population receive less than a minimum salary, compared to 20% for the national average. Many practice subsistence agriculture and receive no salaries. Indigenous people also have less access to health care and a lower quality of housing.
Population genetics.
A study by the National Institute of Genomic Medicine, Mexico reported that Mestizo Mexicans are 58.96% European, 35.05% "Asian" (Amerindian), and 5.03% African. Sonora shows the highest European contribution (70.63%) and Guerrero the lowest (51.98%) where we also observe the highest Asian contribution (37.17%). African contribution ranges from 2.8% in Sonora to 11.13% in Veracruz. 80% of the Mexican population was classed as mestizo (defined as "being racially mixed in some degree").
In May 2009, Mexico's National Institute of Genomic Medicine issued a report on a genomic study of 300 mestizos from the states of Guerrero, Sonora, Veracruz, Yucatán, Zacatecas, and Guanajuato. The study found that the Mestizo population of these Mexican states were on average 55% of indigenous ancestry followed by 41.8% of European, 1.8% of African, and 1.2% of East Asian ancestry. The study also noted that whereas Mestizo individuals from the southern state of Guerrero showed on average 66% of indigenous ancestry, those from the northern state of Sonora displayed about 61.6% European ancestry. The study found that there was an increase in indigenous ancestry as one traveled towards to the Southern states in Mexico, while the indigenous ancestry declined as one traveled to the Northern states in the country, such as Sonora.
Languages.
The country has the largest Spanish-speaking population in the world with almost a third of all Spanish native speakers.
Mexico is home to a large number of indigenous languages, spoken by some 5.4% of the population – 1.2% of the population are monolingual speakers of an indigenous language. The indigenous languages with most speakers are Nahuatl, spoken by approximately 1,45 million people, Yukatek Maya spoken by some 750,000 people and the Mixtec and Zapotec languages each spoken by more than 400,000 people. The National Institute of Indigenous Languages INALI recognizes 68 linguistic groups and some 364 different specific varieties of indigenous languages. Since the promulgation of the Law of Indigenous Linguistic Rights in 2003, these languages have had status as national languages, with equal validity with Spanish in all the areas and contexts in which they are spoken.
In addition to the indigenous languages, other minority languages are spoken by immigrant populations, such as the 80,000 German-speaking Mennonites in Mexico., and 5,000 the Chipilo dialect of the Venetian language spoken in Chipilo, Puebla.
Religion.
The 2010 census by the Instituto Nacional de Estadística y Geografía gave Roman Catholicism as the main religion, with 82.7% of the population, while 9.7% (10,924,103) belong to other Christian denominations, including Evangelicals (5.2%); Pentecostals (1.6%); other Protestant or Reformed (0.7%); Jehovah's Witnesses (1.4%); Seventh-day Adventists (0.6%); and members of The Church of Jesus Christ of Latter-day Saints (0.3%). 172,891 (or less than 0.2% of the total) belonged to other, non-Christian religions; 4.7% declared having no religion; 2.7% were unspecified.
The 92,924,489 Catholics of Mexico constitute in absolute terms the second largest Catholic community in the world, after Brazil's. 47% percent of them attend church services weekly. Most Mexican cities, towns and villages hold a yearly feast day to commemorate their local patron saints. The feast day of Our Lady of Guadalupe, the patron saint of Mexico, is celebrated on December 12 and is regarded by many Mexicans as the most important religious holiday of their country.
The 2010 census reported 314,932 members of The Church of Jesus Christ of Latter-day Saints, though the church in 2009 claimed to have over one million registered members. About 25% of registered members attend a weekly sacrament service although this can fluctuate up and down.
The presence of Jews in Mexico dates back to 1521, when Hernán Cortés conquered the Aztecs, accompanied by several Conversos. According to the 2010 census, there are 67,476 Jews in Mexico. Islam in Mexico is practiced by a small population in the city of Torreón, Coahuila, and there are an estimated 300 Muslims in the San Cristóbal de las Casas area in Chiapas. In the 2010 census 18,185 Mexicans reported belonging to an Eastern religion, a category which includes a tiny Buddhist population.
Gender equality.
The World Economic Forum 2011 Global Gender Gap Report ranked Mexico 89th out of 135 countries for gender parity, making it one of the least gender balanced countries in the North American region, particularly to the disadvantage of women, who have a below average degree of political participation and labor equality. Education and health indicators for Mexican women were however better than the average in the study.
Culture.
Mexican culture reflects the complexity of the country's history through the blending of indigenous cultures and the culture of Spain, imparted during Spain's 300-year colonization of Mexico. Exogenous cultural elements mainly from the United States have been incorporated into Mexican culture.
The Porfirian era ("el Porfiriato"), in the last quarter of the 19th century and the first decade of the 20th century, was marked by economic progress and peace. After four decades of civil unrest and war, Mexico saw the development of philosophy and the arts, promoted by President Díaz himself. Since that time, as accentuated during the Mexican Revolution, cultural identity has had its foundation in the "mestizaje", of which the indigenous (i.e. Amerindian) element is the core. In light of the various ethnicities that formed the Mexican people, José Vasconcelos in his publication "La Raza Cósmica" (The Cosmic Race) (1925) defined Mexico to be the melting pot of all races (thus extending the definition of the "mestizo") not only biologically but culturally as well. This exalting of "mestizaje" was a revolutionary idea that sharply contrasted with the idea of a superior pure race prevalent in Europe at the time.
Literature.
The literature of Mexico has its antecedents in the literatures of the indigenous settlements of Mesoamerica. The most well known prehispanic poet is Nezahualcoyotl. Modern Mexican literature was influenced by the concepts of the Spanish colonialization of Mesoamerica. Outstanding colonial writers and poets include Juan Ruiz de Alarcón and Juana Inés de la Cruz.
In light of the various ethnicities that formed the Mexican people, José Vasconcelos in his publication La Raza Cósmica (The Cosmic Race) (1925) defined Mexico to be the melting pot of all races, biologically as well as culturally.
Other writers include Alfonso Reyes, José Joaquín Fernández de Lizardi, Ignacio Manuel Altamirano, Carlos Fuentes, Octavio Paz (Nobel Laureate), Renato Leduc, Carlos Monsiváis, Elena Poniatowska, Mariano Azuela ("Los de abajo") and Juan Rulfo ("Pedro Páramo"). Bruno Traven wrote "Canasta de cuentos mexicanos", "El tesoro de la Sierra Madre."
Visual arts.
Post-revolutionary art in Mexico had its expression in the works of renowned artists such as Frida Kahlo, Diego Rivera, José Clemente Orozco, Rufino Tamayo, Federico Cantú Garza, David Alfaro Siqueiros and Juan O'Gorman. Diego Rivera, the most well-known figure of Mexican muralism, painted the Man at the Crossroads at the Rockefeller Center in New York City, a huge mural that was destroyed the next year due to the inclusion of a portrait of Russian communist leader Lenin. Some of Rivera's murals are displayed at the Mexican National Palace and the Palace of Fine Arts.
Mesoamerican architecture is mostly noted for its pyramids which are the largest such structures outside of Ancient Egypt. Spanish Colonial architecture is marked by the contrast between the simple, solid construction demanded by the new environment and the Baroque ornamentation exported from Spain. Mexico, as the center of New Spain has some of the most renowned buildings built in this style.
Cinema and media.
Mexican films from the Golden Age in the 1940s and 1950s are the greatest examples of Latin American cinema, with a huge industry comparable to the Hollywood of those years. Mexican films were exported and exhibited in all of Latin America and Europe. Maria Candelaria (1944) by Emilio Fernández, was one of the first films awarded a Palme d'Or at the Cannes Film Festival in 1946, the first time the event was held after World War II. The famous Spanish-born director Luis Buñuel realized in Mexico, between 1947 to 1965 some of him master pieces like Los Olvidados (1949), Viridiana (1961) and El angel exterminador (1963). Famous actors and actresses from this period include María Félix, Pedro Infante, Dolores del Río, Jorge Negrete and the comedian Cantinflas.
More recently, films such as Como agua para chocolate (1992), Cronos (1993), Y tu mamá también (2001), and Pan's Labyrinth (2006) have been successful in creating universal stories about contemporary subjects, and were internationally recognised, as in the prestigious Cannes Film Festival. Mexican directors Alejandro González Iñárritu (Amores perros, Babel), Alfonso Cuarón (Children of Men, Harry Potter and the Prisoner of Azkaban), Guillermo del Toro, Carlos Carrera (The Crime of Father Amaro), and screenwriter Guillermo Arriaga are some of the most known present-day film makers.
Two of the major television networks based in Mexico are Televisa and TV Azteca. Televisa is also the largest producer of Spanish-language content in the world and also the world's largest Spanish-language media network. Grupo Multimedios is another media conglomerate with Spanish-language broadcasting in Mexico, Spain, and the United States. Soap operas (telenovelas) are translated to many languages and seen all over the world with renowned names like Verónica Castro, Lucía Méndez, Lucero, and Thalía.
Music.
Mexican society enjoys a vast array of music genres, showing the diversity of Mexican culture. Traditional music includes Mariachi, Banda, Norteño, Ranchera and Corridos; on an every-day basis most Mexicans listen to contemporary music such as pop, rock, etc. in both English and Spanish. Mexico has the largest media industry in Latin America, producing Mexican artists who are famous in Central and South America and parts of Europe, especially Spain. Some well-known Mexican singers are
Thalía, Luis Miguel, Alejandro Fernández, Julieta Venegas and Paulina Rubio. Mexican singers of traditional music are: Lila Downs, Susana Harp, Jaramar, GEO Meneses and Alejandra Robles. Popular groups are Café Tacuba, Molotov and Maná, among others. Since the early years of 2000s (decade), Mexican rock has seen widespread growth both domesticly and internationally.
According to the Sistema Nacional de Fomento Musical, there are between 120 and 140 youth orchestras affiliated to this federal agency from all federal states. Some states, through their state agencies in charge of culture and the arts—Ministry or Secretary or Institute or Council of Culture, in some cases Secretary of Education or the State University—sponsor the activities of a professional Symphony Orchestra or Philharmonic Orchestra so all citizens can have access to this artistic expression from the field of classical music$3. Mexico City is the most intense hub of this activity hosting 12 professional orchestras sponsored by different agencies such as the National Institute of Fine Arts, the Secretary of Culture of the Federal District, The National University, the National Polytechnic Institute, a Delegación Política (Coyoacán) and very few are a kind of private ventures.
Cuisine.
Mexican cuisine is known for its intense and varied flavors, colorful decoration, and variety of spices. Most of today's Mexican food is based on pre-Columbian traditions, including the Aztecs and Maya, combined with culinary trends introduced by Spanish colonists.
The conquistadores eventually combined their imported diet of rice, beef, pork, chicken, wine, garlic and onions with the native pre-Columbian food, including maize, tomato, vanilla, avocado, guava, papaya, pineapple, chili pepper, beans, squash, sweet potato, peanut, and turkey.
Mexican food varies by region, because of local climate and geography and ethnic differences among the indigenous inhabitants and because these different populations were influenced by the Spaniards in varying degrees. The north of Mexico is known for its beef, goat and ostrich production and meat dishes, in particular the well-known Arrachera cut.
Central Mexico's cuisine is largely made up of influences from the rest of the country, but also has its authentics, such as barbacoa, pozole, menudo, tamales, and carnitas.
Southeastern Mexico, on the other hand, is known for its spicy vegetable and chicken-based dishes. The cuisine of Southeastern Mexico also has quite a bit of Caribbean influence, given its geographical location. Veal is common in the Yucatan. Seafood is commonly prepared in the states that border the Pacific Ocean or the Gulf of Mexico, the latter having a famous reputation for its fish dishes, in particular à la veracruzana.
In modern times, other cuisines of the world have become very popular in Mexico, thus adopting a Mexican fusion. For example, sushi in Mexico is often made with a variety of sauces based on mango or tamarind, and very often served with serrano-chili-blended soy sauce, or complemented with vinegar, habanero and chipotle peppers
The most internationally recognized dishes include chocolate, tacos, quesadillas, enchiladas, burritos, tamales and mole among others. Regional dishes include mole poblano, chiles en nogada and chalupas from Puebla; cabrito and machaca from Monterrey, cochinita pibil from Yucatán, Tlayudas from Oaxaca, as well as barbacoa, chilaquiles, milanesas, and many others.
Sports.
Mexico City hosted the XIX Olympic Games in 1968, making it the first Latin American city to do so. The country has also hosted the FIFA World Cup twice, in 1970 and 1986.
Mexico's most popular sport is association football (soccer). It is commonly believed that Football was introduced in Mexico by Cornish miners at the end of the 19th century. By 1902 a five-team league had emerged with a strong British influence. Mexico's top clubs are Guadalajara with 11 championships, América with 10 and Toluca with 10. Antonio Carbajal was the first player to appear in five World Cups, and Hugo Sánchez was named best CONCACAF player of the 20th century by IFFHS.
Baseball has traditionally been more popular than soccer in some regions. The Mexican professional league is named the Liga Mexicana de Beisbol. While usually not as strong as the United States, the Caribbean countries and Japan, Mexico has nonetheless achieved several international baseball titles. Mexico has had several players signed by Major League teams, the most famous of them being Dodgers pitcher Fernando Valenzuela.
Bullfighting is a popular sport in the country, and almost all large cities have bullrings. Plaza México in Mexico City, is the largest bullring in the world, which seats 55,000 people. Professional wrestling (or Lucha libre in Spanish) is a major crowd draw with national promotions such as AAA, LLL, CMLL and others.
Mexico is an international power in professional boxing (at the amateur level, several Olympic boxing medals have also been won by Mexico). Vicente Saldivar, Rubén Olivares, Salvador Sánchez, Julio César Chávez, Ricardo Lopez and Erik Morales are but a few Mexican fighters who have been ranked among the best of all time.
Notable Mexican athletes include golfer Lorena Ochoa, who was ranked first in the LPGA world rankings prior to her retirement, Ana Guevara, former world champion of the and Olympic subchampion in Athens 2004, and Fernando Platas, a numerous Olympic medal winning diver.
Health care.
Since the early 1990s, Mexico entered a transitional stage in the health of its population and some indicators such as mortality patterns are identical to those found in highly developed countries like Germany or Japan. Although all Mexicans are entitled to receive medical care by the state, 50.3 million Mexicans had no medical insurance as of 2002. Efforts to increase the number of people are being made, and the current administration intends to achieve universal health care by 2011.
Mexico's medical infrastructure is highly rated for the most part and is usually excellent in major cities, but rural communities still lack equipment for advanced medical procedures, forcing patients in those locations to travel to the closest urban areas to get specialized medical care.
State-funded institutions such as Mexican Social Security Institute (IMSS) and the Institute for Social Security and Services for State Workers (ISSSTE) play a major role in health and social security. Private health services are also very important and account for 13% of all medical units in the country.
Medical training is done mostly at public universities with much specializations done in vocational or internship settings. Some public universities in Mexico, such as the University of Guadalajara, have signed agreements with the U.S. to receive and train American students in Medicine. Health care costs in private institutions and prescription drugs in Mexico are on average lower than that of its North American economic partners.
Education.
In 2004, the literacy rate was at 97% for youth under the age of 14 and 91% for people over 15, placing Mexico at the 24th place in the world rank accordingly to UNESCO.
The National Autonomous University of Mexico ranks 190th place in the Top 200 World University Ranking published by The Times Higher Education Supplement in 2009. Private business schools also stand out in international rankings. IPADE and EGADE, the business schools of Universidad Panamericana and of Monterrey Institute of Technology and Higher Education respectively, were ranked in the top 10 in a survey conducted by The Wall Street Journal among recruiters outside the United States.
Law enforcement.
Public security is enacted at the three levels of government, each of which has different prerogatives and responsibilities. Local and state police department are primarily in charge of law enforcement, whereas the Mexican Federal Police are in charge of specialized duties. All levels report to the Secretaría de Seguridad Pública (Secretary of Public Security). The General Attorney's Office (Procuraduría General de la República, PGR) is the executive power's agency in charge of investigating and prosecuting crimes at the federal level, mainly those related to drug and arms trafficking, espionage, and bank robberies. The PGR operates the Federal Investigations Agency (Agencia Federal de Investigación, AFI) an investigative and preventive agency.
While the government generally respects the human rights of its citizens, serious abuses of power have been reported in security operations in the southern part of the country and in indigenous communities and poor urban neighborhoods. The National Human Rights Commission has had little impact in reversing this trend, engaging mostly in documentation but failing to use its powers to issue public condemnations to the officials who ignore its recommendations. By law, all defendants have the rights that assure them fair trials and human treatment; however, the system is overburdened and overwhelmed with several problems.
Despite the efforts of the authorities to fight crime and fraud, few Mexicans have strong confidence in the police or the judicial system, and therefore, few crimes are actually reported by the citizens. The "Global Integrity Index" which measures the existence and effectiveness of national anti-corruption mechanisms rated Mexico 31st behind Kenya, Thailand, and Russia. In 2008, president Calderón proposed a major reform of the judicial system, which was approved by the Congress of the Union, which included oral trials, the presumption of innocence for defendants, the authority of local police to investigate crime—until then a prerogative of special police units—and several other changes intended to speed up trials.
Crime.
According to a 2012 OECD study 15% of Mexicans report having been a victim of crime in the past year, a figure which among OECD countries is only higher in South Africa. As of 2010 Mexico's homicide rate was 18 per 100,000 inhabitants; the world average is 6.9 per 100,000 inhabitants. Drug-traffic and narco-related activities are a major concern in Mexico. Mexico's drug war has left over 60,000 dead and perhaps another 20,000 missing. The Mexican drug cartels have as many as 100,000 members.
Current president Felipe Calderón made abating drug-trafficking one of the top priorities of his administration deploying military personnel to cities where drug cartels operate. This move has been criticized by the opposition parties and the National Human Rights Commission for escalating the violence, but its effects have been positively evaluated by the Bureau for International Narcotics and Law Enforcement Affairs as having obtained "unprecedented results" with "many important successes". Since President Felipe Calderón launched a crackdown against cartels in 2006 more than 28,000 alleged criminals have been killed. Of the total drug-related violence 4% are innocent people, mostly by-passers and people trapped in between shootings; 90% accounts for criminals and 6% for military personnel and police officers. In October 2007, the president Calderón and US president George W. Bush announced the Mérida Initiative a plan of law enforcement cooperation between the two countries.

1953 Iranian coup d'état
The 1953 Iranian coup d'état (known in Iran as the 28 Mordad coup) was the overthrow of the democratically elected government of Iran, and its head of government Prime Minister Mohammad Mosaddegh on 19 August 1953, orchestrated by the intelligence agencies of the United Kingdom (under the name 'Operation Boot') and the United States (under the name "TPAJAX" Project). The coup saw the transition of Mohammad-Rezā Shāh Pahlavi from a constitutional monarch to an authoritarian one who relied heavily on United States support to hold on to power until his own overthrow in February 1979.
In 1951, Iran's oil industry was nationalized with near-unanimous support of Iran's parliament in a bill introduced by Mossadegh who led the nationalist parliamentarian faction. Iran's oil had been controlled by the British-owned Anglo-Iranian Oil Company (AIOC), now known as BP. Popular discontent with the AIOC began in the late 1940s, a large segment of Iran's public and a number of politicians saw the company as exploitative and a vestige of British imperialism. Despite Mosaddegh's popular support, Britain was unwilling to negotiate its single most valuable foreign asset, and instigated a worldwide boycott of Iranian oil to pressure Iran economically. Initially, Britain mobilized its military to seize control of the Abadan oil refinery, the world's largest, but Prime Minister Clement Attlee opted instead to tighten the economic boycott while using Iranian agents to undermine Mosaddegh's government. With a change to more conservative governments in both Britain and the United States, Churchill and the U.S. Eisenhower administration decided to overthrow Iran's government though the predecessor U.S. Truman administration had opposed a coup. Classified documents show British intelligence officials played a pivotal role in initiating and planning the coup, and that Washington and London shared an interest in maintaining control over Iranian oil.
Britain and the U.S. selected Fazlollah Zahedi to be the prime minister of a military government that was to replace Mosaddegh's government. Subsequently, a royal decree dismissing Mosaddegh and appointing Zahedi was drawn up by the coup plotters and signed by the Shah. The Central Intelligence Agency had successfully pressured the weak monarch to participate in the coup, while bribing street thugs, clergy, politicians and Iranian army officers to take part in a propaganda campaign against Mosaddegh and his government. At first, the coup appeared to be a failure when on the night of 15–16 August, Imperial Guard Colonel Nematollah Nassiri was arrested while attempting to arrest Mosaddegh. The Shah fled the country the next day. On 19 August, a pro-Shah mob, paid by the CIA, marched on Mosaddegh's residence. According to the CIA's declassified documents and records, some of the most feared mobsters in Tehran were hired by the CIA to stage pro-Shah riots on 19 August. Other CIA-paid men were brought into Tehran in buses and trucks, and took over the streets of the city. Between 300 and 800 people were killed during and as a direct result of the conflict. Mosaddegh was arrested, tried and convicted of treason by the Shah's military court. On 21 December 1953, he was sentenced to three years in jail, then placed under house arrest for the remainder of his life. Mosaddegh's supporters were rounded up, imprisoned, tortured or executed.
After the coup, Pahlavi ruled as an authoritarian monarch for the next 26 years, until he was overthrown in a popular revolt in 1979. The tangible benefits the United States reaped from overthrowing Iran's elected government included a share of Iran's oil wealth as well as resolute prevention of the possibility that the Iranian government might align itself with the Soviet Union, although the latter motivation produces controversy among historians. Washington continually supplied arms to the unpopular Shah, and the CIA-trained SAVAK, his repressive secret police force. The coup is widely believed to have significantly contributed to anti-American sentiment in Iran and the Middle East. The 1979 Iranian Revolution deposed the Shah and replaced the pro-Western royal dictatorship with the largely anti-Western Islamic Republic of Iran.
Background.
19th century.
Throughout the 19th century, Iran was caught between two advancing imperial powers, Russia, which was expanding southward into the Caucasus and central Asia, and Britain, which sought to dominate the Persian Gulf, the Red Sea, and India. Between 1801 and 1814 Iran signed treaties with Britain and France with an eye toward blocking Russian expansion. After two wars with czarist Russia, from 1804–13 and 1826–28, Iran ceded large tracts of territory to Russia, establishing the modern boundaries between those countries. Britain fought a war with Iran over Afghanistan in 1856–57 after which Afghanistan became independent. In 1892, the British diplomat George Curzon described Iran as "pieces on a chessboard upon which is being played out a game for the dominion of the world.
In 1872, a representative of Baron Paul Reuter, founder of the news agency, met with Naser al-Din Shah Qajar and agreed to fund the Persian monarch's upcoming lavish visit to Europe in return for broadly worded concessions in Persia, which was the country name through the centuries until 1935 when Reza Shah renamed it Iran. The concession the Shah had given to Reuter was never put into effect because of violent opposition from the Persian people and from Russia.
Early petroleum development.
In 1901, Mozzafar al-Din Shah Qajar, the Shah of Persia, granted a 60-year petroleum search concession to William Knox D'Arcy. D'Arcy paid £20,000, according to journalist-turned-historian Stephen Kinzer, and promised equal ownership shares, with 16% of any future net profit, as calculated by the company. However, the historian L.P. Elwell-Sutton wrote, in 1955, that "Persia's share was "hardly spectacular" and no money changed hands.
Elwell-Sutton, L. P. "Persian Oil: A Study in Power Politics" (Lawrence and Wishart Ltd.: London) 1955. p. 15 
On 31 July 1907, D'Arcy withdrew from his private holdings in Persia. "A new agreement was signed under which he transferred to the Burmah Oil Company all his shares in the First Exploitation Company, and with them his last direct interest in the exploitation of oil in Persia." D'Arcy received 203,067 British pounds in cash (more than ten times what the Persian monarch was supposed to have received in cash for the concession) and D'Arcy received 900,000 shares in the Burmah Oil Company, which the historian Elwell-Sutton declared was "a large sum."
In early 1908, the British-owned Burmah Oil Company decided to end its exploration for oil in Persia but on 26 May, oil came in at a depth of , "a gusher that shot fifty feet or more above the top of the rig," Elwell-Sutton wrote. "So began the industry that was to see the Royal Navy through two world wars, and to cause Persia more trouble than all the political manoeuvrings of the great powers put together."
The company grew slowly until World War I, when Persia's strategic importance led the British government to buy a controlling share in the company, essentially nationalizing British oil production in Iran. It became the Royal Navy's chief fuel source during the war.
The British angered Iranians by intervening in Iranian domestic affairs including in the Persian Constitutional Revolution (the transition from dynastic to parliamentary government).
Post-World War I.
The Persians were dissatisfied with the royalty terms of the British petroleum concession, the Anglo-Persian Oil Company (APOC), whereby Persia received 16% of "net profits".
In 1921, a military "coup d'état"—"widely believed to be a British attempt to enforce, at least, the spirit of the Anglo-Persian agreement" effected with the "financial and logistical support of British military personnel"—permitted the political emergence of Reza Pahlavi, whom they enthroned as the "Shah of Iran" in 1925. The Shah modernized Persia to the advantage of the British; one result was the Persian Corridor railroad for British military and civil transport during World War II.
In the 1930s, the Shah tried to terminate the APOC concession, but Britain would not allow it. The concession was renegotiated on terms again favorable to the British. On 21 March 1935, Pahlavi changed the name of the country from Persia to Iran. The Anglo-Persian Oil Company was then renamed the Anglo-Iranian Oil Company (AIOC).
World War II.
In 1941, after the Nazi invasion of the USSR, the British and Commonwealth of Nations forces and the Red Army invaded Iran, to secure petroleum (cf. Persian Corridor) for the Soviet Union's effort against the Nazis on the Eastern Front and for the British elsewhere. Britain and the USSR deposed and exiled the pro-Nazi Shah Reza, and enthroned his 22-year-old son, Mohammad Reza Pahlavi, as the Shah of Iran.
The British secured the oilfields and the seaports.
During the war, Iran was used as a conduit for materiel to the USSR. US forces also entered the country replacing the British in operating the southern part of the Trans-Iranian Railway.
Post-World War II.
The western Allies withdrew from Iran after the end of the war. The Soviet Union remained and sponsored two "People's Democratic Republic"s within Iran's borders. The resulting crisis was resolved through diplomatic efforts in the new United Nations and US support for the Iranian army to reassert control over the breakaway areas. The Soviet-Iranian oil agreement was not ratified.
After the war, nationalist leaders in Iran became influential by seeking a reduction in long-term foreign interventions in their country—especially the oil concession which was very profitable for Britain and not very profitable to Iran. The British-controlled AIOC refused to allow its books to be audited to determine whether the Iranian government was being paid what had been promised. British intransigence irked the Iranian population.
U.S. objectives in the Middle East remained the same between 1947 and 1952 but its strategy changed. Washington remained "publicly in solidarity and privately at odds" with Britain, its World War II ally. Britain's empire was steadily weakening, and with an eye on international crises, the U.S. re-appraised its interests and the risks of being identified with British colonial interests. "In Saudi Arabia, to Britain's extreme disapproval, Washington endorsed the arrangement between ARAMCO and Saudi Arabia in the 50/50 accord that had reverberations throughout the region."
Britain faced the newly elected nationalist government in Iran where Mossadegh, with strong backing of the Iranian parliament, demanded more favorable concessionary arrangements, which Britain vigorously opposed.
The U.S. State Department not only rejected Britain's demand that it continue to be the primary beneficiary of Iranian oil reserves but "U.S. international oil interests were among the beneficiaries of the concessionary arrangements that followed nationalization."
U.S. reluctance to overthrow Prime Minister Mossadegh in 1951, when he was elected, faded 28 months later when Dwight D. Eisenhower was in the White House and John Foster Dulles took the helm at the State Department. "Anglo-American cooperation on that occasion brought down the Iranian prime minister and reinstated a U.S.-backed shah."
1950s.
In 1951, the AIOC's resistance to re-negotiating their petroleum concession—and increasing the royalty paid to Iran—created popular support for nationalising the company. In March, the pro-Western PM Ali Razmara was assassinated; the next month, the parliament legislated the petroleum industry's nationalisation, by creating the National Iranian Oil Company (NIOC). This legislation was guided by the Western-educated Dr. Mohammad Mosaddegh, then a member of the Iranian parliament and leader of the nationalisation movement; by May, the Shah had appointed Mosaddegh Prime Minister.
Mohammad Mosaddegh attempted to negotiate with the AIOC, but the company rejected his proposed compromise. Mosaddegh's plan, based on the 1948 compromise between the Venezuelan Government of Romulo Gallegos and Creole Petroleum, would divide the profits from oil 50/50 between Iran and Britain. Against the recommendation of the United States, Britain refused this proposal and began planning to undermine and overthrow the Iranian government.
That summer, American diplomat Averell Harriman went to Iran to negotiate an Anglo-Iranian compromise, asking the Shah's help; his reply was that "in the face of public opinion, there was no way he could say a word against nationalisation". Harriman held a press conference in Tehran, calling for reason and enthusiasm in confronting the "nationalisation crisis". As soon as he spoke, a journalist rose and shouted: "We and the Iranian people all support Premier Mosaddegh and oil nationalisation!" Everyone present began cheering and then marched out of the room; the abandoned Harriman shook his head in dismay.
The National Iranian Oil Company suffered decreased production, because of Iranian inexperience and the AIOC's orders that British technicians not work with them, thus provoking the Abadan Crisis that was aggravated by the Royal Navy's blockading its export markets to pressure Iran to not nationalise its petroleum. The Iranian revenues were greater, because the profits went to Iran's national treasury rather than to private, foreign oil companies. By September 1951, the British had virtually ceased Abadan oil field production, forbidden British export to Iran of key British commodities (including sugar and steel), and had frozen Iran's hard currency accounts in British banks.
The United Kingdom took its anti-nationalisation case against Iran to the International Court of Justice at The Hague; PM Mosaddegh said the world would learn of a "cruel and imperialistic country" stealing from a "needy and naked people". Representing the AIOC, the UK lost its case. In August 1952, Iranian Prime Minister Mosaddegh invited an American oil executive to visit Iran and the Truman administration welcomed the invitation. However, the suggestion upset British Prime Minister Winston Churchill who insisted that the U.S. not undermine his campaign to isolate Mosaddegh: "Britain was supporting the Americans in Korea, he reminded Truman, and had a right to expect Anglo-American unity on Iran."
In mid-1952, Britain's boycott of Iranian oil was devastatingly effective. British agents in Tehran "worked to subvert" the government of Mosaddegh, who sought help from President Truman and then the World Bank but to no avail. "Iranians were becoming poorer and unhappier by the day" and Mosaddegh's political coalition was fraying.
In the Majlis election in the spring of 1952, Mosaddegh "had little to fear from a free vote, since despite the country's problems, he was widely admired as a hero. A free vote, however, was not what others were planning. British agents had fanned out across the country, bribing candidates, and the regional bosses who controlled them. They hoped to fill the Majlis with deputies who would vote to depose Mosaddegh. It would be a coup carried out by seemingly legal means."
While the National Front, which often supported Mosaddegh won handily in the big cities, there was no one to monitor voting in the rural areas. Violence broke out in Abadan and other parts of the country where elections were hotly contested. Faced with having to leave Iran for The Hague where Britain was suing for control of Iranian oil, Mossadegh's cabinet voted to postpone the remainder of the election until after the return of the Iranian delegation from The Hague.
By mid-1953 a mass of resignations by Mossadegh's parliamentary supporters reduced parliament below its quorum. A referendum to dissolve parliament and give the prime minister power to make law was submitted to voters, and it passed with 99.9 percent approval, 2,043,300 votes to 1300 votes against.
While Mosaddegh dealt with political challenge, he faced another that most Iranians considered far more urgent. The British blockade of Iranian seaports meant that Iran was left without access to markets where it could sell its oil. The embargo had the effect of causing Iran to spiral into bankruptcy. Tens of thousands had lost their jobs at the Abadan refinery, and although most understood and passionately supported the idea of nationalisation, they naturally hoped that Mosaddegh would find a way to put them back to work. The only way he could do that was to sell oil."
Worried about Britain's other interests in Iran, and believing that Iran's nationalism was Soviet-backed, Britain persuaded Secretary of State John Foster Dulles that Iran was falling to the Soviets—effectively exploiting the American Cold War mindset. While President Harry S. Truman was busy fighting a war in Korea, he did not agree to overthrow the government of Prime Minister Mohammad Mosaddegh. However, in 1953, when Dwight D. Eisenhower became president, the UK convinced him to a joint coup d'état.
U.S. role.
Execution of Operation Ajax.
Having obtained the Shah's concurrence, the CIA executed the coup. Firmans (royal decrees) dismissing Mosaddegh and appointing Zahedi were drawn up by the coup plotters and signed by the Shah. On Saturday 15 August, Colonel Nematollah Nassiri, the commander of the Imperial Guard, delivered to Mosaddegh a firman from the Shah dismissing him. Mosaddegh, who had been warned of the plot (probably by the Tudeh party) rejected the firman as a forgery and had Nassiri arrested. Mosaddegh argued at his trial after the coup that under the Iranian constitutional monarchy, the Shah had no constitutional right to issue an order for the elected Prime Minister's dismissal without Parliament's consent. The action was publicized within Iran by the CIA and in the United States by "The New York Times". The Shah, fearing a popular backlash, fled to Rome, Italy. After a short exile in Italy, the CIA completed the coup against Mossadegh, and returned the Shah to Iran. Alan Dulles, the director of the CIA, flew back with the Shah from Rome to Teheran. Gen. Zahedi replaced the deposed Prime Minister Mosaddegh, who was arrested, tried, and originally sentenced to death. Mosaddegh's sentence was commuted to three years' solitary confinement in a military prison, followed by house arrest until his death.
As a condition for restoring the Anglo-Iranian Oil Company, the U.S. required removal of the AIOC's monopoly; five American petroleum companies, Royal Dutch Shell, and the Compagnie Française des Pétroles, were to draw Iran's petroleum after the successful coup d'état—Operation Ajax.
As part of that, the CIA organized anti-Communist guerrillas to fight the Tudeh Party if "they" seized power in the chaos of Operation Ajax. Per released National Security Archive documents, Undersecretary of State Walter Bedell Smith reported that the CIA had agreed with Qashqai tribal leaders, in south Iran, to establish a clandestine safe haven from which U.S.-funded guerrillas and spies could operate.
Operation Ajax's formal leader was senior CIA officer Kermit Roosevelt, Jr., while career agent Donald Wilber was the operational leader, planner, and executor of the deposition of PM Mosaddegh. The coup d'état depended on the impotent Shah's dismissing the popular and powerful Prime Minister and replacing him with Gen. Fazlollah Zahedi, with help from Col. Abbas Farzanegan—a man agreed upon by the British and Americans after determining his anti-Soviet politics.
The CIA sent Major general Norman Schwarzkopf, Sr. to persuade the exiled Shah to return to rule Iran. Schwarzkopf trained the security forces that would become known as SAVAK to secure the shah's hold on power.
The coup and CIA records.
The coup was carried out by the U.S. administration of Dwight D. Eisenhower in a covert action advocated by Secretary of State John Foster Dulles, and implemented under the supervision of his brother Allen Dulles, the Director of Central Intelligence. The coup was organized by the United States' CIA and the United Kingdom's MI6, two spy agencies that aided royalists and royalist elements of the Iranian army.
According to a heavily redacted CIA document released to the National Security Archive in response to a Freedom of Information request, "Available documents do not indicate who authorized CIA to begin planning the operation, but it almost certainly was President Eisenhower himself. Eisenhower biographer Stephen Ambrose has written that the absence of documentation reflected the President's style."
CIA officer Kermit Roosevelt, Jr., the grandson of former President Theodore Roosevelt, carried out the operation planned by CIA agent Donald Wilber. One version of the CIA history, written by Wilber, referred to the operation as TPAJAX.
During the coup, Roosevelt and Wilber, representatives of the Eisenhower administration, bribed Iranian government officials, reporters, and businessmen. They also bribed street thugs to support the Shah and oppose Mosaddegh. The deposed Iranian leader, Mosaddegh, was taken to jail and Iranian General Fazlollah Zahedi named himself prime minister in the new, pro-western government.

The British and American spy agencies returned the monarchy to Iran by installing the pro-western Mohammad Reza Pahlavi on the throne where his rule lasted 26 years. Pahlavi was overthrown in 1979. Masoud Kazemzadeh, associate professor of political science at the Sam Houston State University, wrote that Pahlavi was directed by the CIA and MI6, and assisted by high-ranking Shia clerics. He wrote that the coup employed mercenaries including "prostitutes and thugs" from Tehran's red light district.
The overthrow of Iran's elected government in 1953 ensured Western control of Iran's petroleum resources and prevented the Soviet Union from competing for Iranian oil. Some Iranian clerics cooperated with the western spy agencies because they were dissatisfied with Mosaddegh's secular government.
While the broad outlines of the Iran operation are known: the agency led a coup in 1953 that re-installed the pro-American Shah Mohammad Reza Pahlavi to the throne, where he remained until overthrown in 1979. "But the C.I.A.'s records were widely thought by historians to have the potential to add depth and clarity to a famous but little-documented intelligence operation," reporter Tim Weiner wrote in "The New York Times" 29 May 1997
"The Central Intelligence Agency, which has repeatedly pledged for more than five years to make public the files from its secret mission to overthrow the government of Iran in 1953, said today that it had destroyed or lost almost all the documents decades ago."
"A historian who was a member of the C.I.A. staff in 1992 and 1993 said in an interview today that the records were obliterated by 'a culture of destruction' at the agency. The historian, Nick Cullather, said he believed that records on other major cold war covert operations had been burned, including those on secret missions in Indonesia in the 1950s and a successful C.I.A.-sponsored coup in Guyana in the early 1960s.
'Iran—there's nothing', Mr. Cullather said. 'Indonesia—very little. Guyana—that was burned. 
Donald Wilber, one of the CIA officers who planned the 1953 coup in Iran, wrote an account titled, "Clandestine Service History Overthrow Of Premier Mossadeq of Iran: November 1952 – August 1953". Wilber said one goal of the coup was to strengthen the Shah.
In 2000, James Risen at The "New York Times" obtained the previously secret CIA version of the coup written by Wilber and summarized its contents, which includes the following.
In early August, the C.I.A. stepped up the pressure. Iranian operatives pretending to be Communists threatened Muslim leaders with "savage punishment if they opposed Mossadegh," seeking to stir anti-Communist sentiment in the religious community.
In addition, the secret history says, the house of at least one prominent Muslim was bombed by C.I.A. agents posing as Communists. It does not say whether anyone was hurt in this attack.
The agency was also intensifying its propaganda campaign. A leading newspaper owner was granted a personal loan of about $45,000, "in the belief that this would make his organ amenable to our purposes."
But the shah remained intransigent. In an 1 August meeting with General Norman Schwarzkopf, he refused to sign the C.I.A.-written decrees firing Mr. Mossadegh and appointing General Zahedi. He said he doubted that the army would support him in a showdown.
The National Security Archive at George Washington University contains the full account by Wilber, along with many other coup-related documents and analysis.
In a January, 1973 telephone conversation made public in 2009, U.S. President Richard Nixon told CIA Director Richard Helms, who was awaiting Senate confirmation to become the new U.S. Ambassador to Iran, that Nixon wanted Helms to be a "regional ambassador" to Persian Gulf oil states, and noted that Helms had been a schoolmate of Shah Reza Pahlavi.
U.S. motives.
Historians disagree on what motivated the United States to change its policy towards Iran and stage the coup. Middle East historian Ervand Abrahamian identified the coup d'état as "a classic case of nationalism clashing with imperialism in the Third World". He states that Secretary of State Dean Acheson admitted the Communist threat' was a smokescreen" in responding to President Eisenhower's claim that the Tudeh party was about to assume power.
 Throughout the crisis, the "communist danger" was more of a rhetorical device than a real issue—i.e. it was part of the cold-war discourse ...The Tudeh was no match for the armed tribes and the 129,000-man military. What is more, the British and Americans had enough inside information to be confident that the party had no plans to initiate armed insurrection. At the beginning of the crisis, when the Truman administration was under the impression a compromise was possible, Acheson had stressed the communist danger, and warned if Mosaddegh was not helped, the Tudeh would take over. The (British) Foreign Office had retorted that the Tudeh was no real threat. But, in August 1953, when the Foreign Office echoed the Eisenhower administration's claim that the Tudeh was about to take over, Acheson now retorted that there was no such communist danger. Acheson was honest enough to admit that the issue of the Tudeh was a smokescreen.
Abrahamian states that Iran's oil was the central focus of the coup, for both the British and the Americans, though "much of the discourse at the time linked it to the Cold War". Abrahamian wrote, "If Mosaddegh had succeeded in nationalizing the British oil industry in Iran, that would have set an example and was seen at that time by the Americans as a threat to U.S. oil interests throughout the world, because other countries would do the same." Mosaddegh did not want any compromise solution that allowed a degree of foreign control. Abrahamian said that Mosaddegh "wanted real nationalization, both in theory and practice".
Tirman points out that agricultural land owners were politically dominant in Iran, well into the 1960s and the monarch, Reza Pahlevi's aggressive land expropriation policies—to the benefit of himself and his supporters—resulted in the Iranian government being Iran's largest land owner. "The landlords and oil producers had new backing, moreover, as American interests were for the first time exerted in Iran. The Cold War was starting, and Soviet challenges were seen in every leftist movement. But the reformers were at root nationalists, not communists, and the issue that galvanized them above all others was the control of oil." The belief that oil was the central motivator behind the coup has been echoed in the popular media by authors such as Robert Byrd, Alan Greenspan, and Ted Koppel.
However, Middle East political scientist Mark Gasiorowski states that while, on the face of it, there is considerable merit to the argument that U.S. policymakers helped U.S. oil companies gain a share in Iranian oil production after the coup, "it seems more plausible to argue that U.S. policymakers were motivated mainly by fears of a communist takeover in Iran, and that the involvement of U.S. companies was sought mainly to prevent this from occurring. The Cold War was at its height in the early 1950s, and the Soviet Union was viewed as an expansionist power seeking world domination. Eisenhower had made the Soviet threat a key issue in the 1952 elections, accusing the Democrats of being soft on communism and of having "lost China." Once in power, the new administration quickly sought to put its views into practice."
Gasiorowski further states "the major U.S. oil companies were not interested in Iran at this time. A glut existed in the world oil market. The U.S. majors had increased their production in Saudi Arabia and Kuwait in 1951 in order to make up for the loss of Iranian production; operating in Iran would force them to cut back production in these countries which would create tensions with Saudi and Kuwaiti leaders. Furthermore, if nationalist sentiments remained high in Iran, production there would be risky. U.S. oil companies had shown no interest in Iran in 1951 and 1952. By late 1952, the Truman administration had come to believe that participation by U.S. companies in the production of Iranian oil was essential to maintain stability in Iran and keep Iran out of Soviet hands. In order to gain the participation of the major U.S. oil companies, Truman offered to scale back a large anti-trust case then being brought against them. The Eisenhower administration shared Truman's views on the participation of U.S. companies in Iran and also agreed to scale back the anti-trust case. Thus, not only did U.S. majors not want to participate in Iran at this time, it took a major effort by U.S. policymakers to persuade them to become involved."
In 2004, Gasiorowski edited a book on the coup arguing that "the climate of intense cold war rivalry between the superpowers, together with Iran's strategic vital location between the Soviet Union and the Persian Gulf oil fields, led U.S. officials to believe that they had to take whatever steps were necessary to prevent Iran from falling into Soviet hands." While "these concerns seem vastly overblown today" the pattern of "the 1945–46 Azerbaijan crisis, the consolidation of Soviet control in Eastern Europe, the communist triumph in China, and the Korean War—and with the Red Scare at its height in the United States" would not allow U.S. officials to risk allowing the Tudeh Party to gain power in Iran. Furthermore, "U.S. officials believed that resolving the oil dispute was essential for restoring stability in Iran, and after March 1953 it appeared that the dispute could be resolved only at the expense either of Britain or of Mosaddeq." He concludes "it was geostrategic considerations, rather than a desire to destroy Mosaddeq's movement, to establish a dictatorship in Iran or to gain control over Iran's oil, that persuaded U.S. officials to undertake the coup."
Faced with choosing between British interests and Iran, the U.S. chose Britain, Gasiorowski said. "Britain was the closest ally of the United States, and the two countries were working as partners on a wide range of vitally important matters throughout the world at this time. Preserving this close relationship was more important to U.S. officials than saving Mosaddeq's tottering regime." A year earlier, British Prime Minister Winston Churchill used Britain's support for the U.S. in the Cold War to insist the United States not undermine his campaign to isolate Mosaddegh. "Britain was supporting the Americans in Korea, he reminded Truman, and had a right to expect `Anglo-American unity` on Iran."
The two main winners of World War II who had been Allies during the war became superpowers and competitors as soon as the war ended, each with their own spheres of influence and client states. After the 1953 coup, Iran became one of the client states of the United States. In his earlier book, "U.S. Foreign Policy and the Shah: Building a Client State in Iran" Gasiorowski identifies the client states of the United States and of the Soviet Union between 1954–1977. Gasiorowski identified Guatemala, Nicaragua, Panama, Cambodia, Iran, Indonesia, Laos, Philippines, South Korea, South Vietnam, Taiwan as strong client states of the United States and identified those that were moderately important to the U.S. as Greece, Turkey, Bolivia, Brazil, Colombia, Costa Rica, Dominican Republic, Ecuador, El Salvador, Haiti, Honduras, Paraguay, Liberia, Zaire, Israel, Jordan, Tunisia, Pakistan and Thailand. He identified Argentina, Chile, Peru, Ethiopia and Japan as "weak" client states of the United States.
Gasiorowski identified Bulgaria, Czechoslovakia, East Germany, Hungary, Poland, Rumania, Cuba, Mongolia and North Vietnam as "strong client states" of the Soviet Union, and he identified Guinea, Somalia, Egypt, Syria, Afghanistan and North Korea as moderately important client states. Mali and South Yemen were classified as weak client states of the Soviet Union.
According to Kinzer, for most Americans, the crisis in Iran became just part of the conflict between Communism and "the Free world." "A great sense of fear, particularly the fear of encirclement, shaped American consciousness during this period. ... Soviet power had already subdued Latvia, Lithuania, Estonia. Communist governments were imposed on Bulgaria and Romania in 1946, Hungary and Poland in 1947, and Czechoslovakia in 1948. Albania and Yugoslavia also turned to communism. Greek communists made a violent bid for power. Soviet soldiers blocked land routes to Berlin for sixteen months. In 1949 the Soviet Union successfully tested a nuclear weapon. That same year, pro-Western forces in China lost their civil war to communists led by Mao Zedong. From Washington, it seemed that enemies were on the march everywhere." Consequently, "the United States, challenged by what most Americans saw as a relentless communist advance, slowly ceased to view Iran as a country with a unique history that faced a unique political challenge." Some historians including Douglas Little, Abbas Milani and George Lenczowski have echoed the view that fears of a communist takeover or Soviet influence motivated the U.S. to intervene.
Shortly before the overthrow of Mossadegh, Adolf A. Berle warned the U.S. State Department that U.S. "control of the Middle East was at stake, which, with its Persian Gulf oil, meant 'substantial control of the world.'"
U.S. media coverage.
When Mossadegh called for the dissolution of the Majlis in August 1953, the editors of the "New York Times" gave the opinion that: "A plebiscite more fantastic and farcical than any ever held under Hitler or Stalin is now being staged in Iran by Premier Mossadegh in an effort to make himself unchallenged dictator of the country."
A year after the coup, the "New York Times" wrote on 6 August 1954, that a new oil "agreement between Iran and a consortium of foreign oil companies" was "good news indeed".
"Costly as the dispute over Iranian oil has been to all concerned, the affair may yet be proved worthwhile if lessons are learned from it: Underdeveloped countries with rich resources now have an object lesson in the heavy cost that must be paid by one of their number which goes berserk with fanatical nationalism. It is perhaps too much to hope that Iran's experience will prevent the rise of Mossadeghs in other countries, but that experience may at least strengthen the hands of more reasonable and more far-seeing leaders. In some circles in Great Britain the charge will be pushed that American 'imperialism'—in the shape of the American oil firms in the consortium!—has once again elbowed Britain from a historic stronghold." 
Aftermath.
The coup has been said to have "left a profound and long-lasting legacy."
Blowback.
According to the history based on documents released to the National Security Archive and reflected in the book "Mohammad Mosaddeq and the 1953 Coup in Iran," edited by Mark J. Gasiorowski and Malcolm Byrne, the coup caused long-lasting damage to the U.S. reputation.
Quoting from Gasiorowski and Byrne, "Mohammad Mosaddeq and the 1953 Coup in Iran".
The authoritarian monarch installed in the coup appreciated the coup, Kermit Roosevelt wrote in his account of the affair. "'I owe my throne to God, my people, my army and to you!' By 'you' he shah meant me and the two countries—Great Britain and the United States—I was representing. We were all heroes."
On 16 June 2000, "The New York Times" published the secret CIA report, "Clandestine Service History, Overthrow Of Premier Mossadeq Of Iran, November 1952 – August 1953," partly explaining the coup from CIA agent Wilber's perspective. In a related story, "The New York Times" reporter James Risen penned a story revealing that Wilber's report, hidden for nearly five decades, had recently come to light.
In the summer of 2001, Ervand Abrahamian wrote in the journal "Science & Society" that Wilber's version of the coup was missing key information some of which was available elsewhere.

In a review of Tim Weiner's "Legacy of Ashes", historian Michael Beschloss wrote, "Mr. Weiner argues that a bad C.I.A. track record has encouraged many of our gravest contemporary problems... A generation of Iranians grew up knowing that the C.I.A. had installed the shah," Mr. Weiner notes. "In time, the chaos that the agency had created in the streets of Tehran would return to haunt the United States."
The administration of Dwight D. Eisenhower considered the coup a success, but, given its blowback, that opinion is no longer generally held, because of its "haunting and terrible legacy". In 2000, Madeleine Albright, U.S. Secretary of State, said that intervention by the U.S. in the internal affairs of Iran was a setback for democratic government. The coup d'état was "a critical event in post-war world history" that destroyed Iran's secular parliamentary democracy, by re-installing the monarchy of the Shah, Mohammad Reza Pahlavi, as an authoritarian ruler. The coup is widely believed to have significantly contributed to the 1979 Iranian Revolution, which deposed the "pro-Western" Shah and replaced the monarchy with an "anti-Western" Islamic Republic.
"For many Iranians, the coup demonstrated duplicity by the United States, which presented itself as a defender of freedom but did not hesitate to use underhanded methods to overthrow a democratically elected government to suit its own economic and strategic interests", the Agence France-Presse reported.
"The world has paid a heavy price for the lack of democracy in most of the Middle East. Operation Ajax taught tyrants and aspiring tyrants that the world's most powerful governments were willing to tolerate limitless oppression as long as oppressive regimes were friendly to the West and to Western oil companies. That helped tilt the political balance in a vast region away from freedom and toward dictatorship." The United States initially considered the coup to be a triumph of Cold War covert action, but given its blowback, Kinzer wrote that it is difficult to imagine an outcome "that would have produced as much pain and horror over the next half century as that produced by Operation Ajax" had "American and British intelligence officers not meddled so shamelessly in (Iran"s) domestic affairs."
United States Supreme Court Justice William O. Douglas, who visited Iran both before and after the coup, wrote that "When Mossadegh and Persia started basic reforms, we became alarmed. We united with the British to destroy him; we succeeded; and ever since, our name has not been an honored one in the Middle East."
Iran.
An immediate consequence of the coup d'état was the repression of all political dissent, especially the liberal and nationalist opposition umbrella group National Front as well as the (Communist) Tudeh party, and concentration of political power in the Shah and his courtiers.
The minister of Foreign Affairs and the closest associate of Mosaddegh, Hossein Fatemi, was executed by order of the Shah's military court by firing squad on 10 November 1954. According to Kinzer, "The triumphant Shah ordered the execution of several dozen military officers and student leaders who had been closely associated with Mohammad Mossadegh"
As part of the post-coup d'état political repression between 1953–1958, the Shah outlawed the National Front, and arrested most of its leaders. The Tudeh, however, bore the main brunt of the repression. The Shah's security forces arrested 4,121 Tudeh political activists including 386 civil servants, 201 college students, 165 teachers, 125 skilled workers, 80 textile workers, 60 cobblers, and 11 housewives. Forty were executed, another 14 died under torture and over 200 were sentenced to life imprisonment. The Shah's post-coup dragnet also captured 477 Tudeh members ("22 colonels, 69 majors, 100 captains, 193 lieutenants, 19 noncommissioned officers, and 63 military cadets") who were in the Iranian armed forces. After their presence was revealed, some National Front supporters complained that this Tudeh military network could have saved Mosaddegh. However, few Tudeh officers commanded powerful field units, especially tank divisions that might have countered the coup. Most of the captured Tudeh officers came from the military academies, police and medical corps. At least eleven of the captured army officers were tortured to death between 1953 and 1958.
After the 1953 coup, the Shah's government formed the SAVAK (secret police), many of whose agents were trained in the United States. The SAVAK was given a "loose leash" to torture suspected dissidents with "brute force" that, over the years, "increased dramatically".
Another effect was sharp improvement of Iran's economy; the British-led oil embargo against Iran ended, and oil revenue increased significantly beyond the pre-nationalisation level. Despite Iran not controlling its national oil, the Shah agreed to replacing the Anglo-Iranian Oil Company with a consortium—British Petroleum and eight European and American oil companies; in result, oil revenues increased from $34 million in 1954–1955 to $181 million in 1956–1957, and continued increasing, and the United States sent development aid and advisors.
In the 1970s the Shah's government increased taxes that foreign companies were obliged to pay from 50% to 80% and royalty payments from 12.5% to 20%. At the same time the price of oil reverted to Iranian control. Oil companies now only earned 22 cents per barrel of oil.
Jacob G. Hornberger, founder and president, of The Future of Freedom Foundation, said, "U.S. officials, not surprisingly, considered the operation one of their greatest foreign policy successes—until, that is, the enormous convulsion that rocked Iranian society with the violent ouster of the Shah and the installation of a virulently anti-American Islamic regime in 1979". According to him, "the coup, in essence, paved the way for the rise to power of the Ayatollah Ruhollah Khomeini and all the rest that's happened right up to 9/11 and beyond".
Internationally.
Kinzer wrote that the 1953 coup d'état was the first time the U.S. used the CIA to overthrow a democratically elected, civil government. The Eisenhower administration viewed Operation Ajax as a success, with "immediate and far-reaching effect. Overnight, the CIA became a central part of the American foreign policy apparatus, and covert action came to be regarded as a cheap and effective way to shape the course of world events"—a coup engineered by the CIA called Operation PBSUCCESS toppling the duly elected Guatemalan government of Jacobo Arbenz Guzmán, which had nationalised farm land owned by the United Fruit Company, followed the next year.
A pro-American government in Iran doubled the United States' geographic and strategic advantage in the Middle East, as Turkey, also bordering the USSR, was part of NATO.
In 2000 U.S. Secretary of State Madeleine K. Albright, acknowledged the coup's pivotal role in the troubled relationship and "came closer to apologizing than any American official ever has before".
A short account of 1953 Coup
Historical viewpoint in the Islamic Republic.
Men associated with Mossadegh and his ideals dominated Iran's first post-revolutionary government. The first prime minister after the Iranian revolution was Mehdi Bazargan, a close associate of Mossadegh. But with the subsequent rift between the conservative Islamic establishment and the secular liberal forces, Mossadegh's work and legacy has been largely ignored by the Islamic Republic establishment. However, Mosaddegh remains a popular historical figure among Iranian opposition factions. Mosaddegh's image is one of the symbols of Iran's opposition movement, also known as the Green Movement. Kinzer writes that Mosaddegh "for most Iranians" is "the most vivid symbol of Iran's long struggle for democracy" and that modern protesters carrying a picture of Mosaddegh is the equivalent of saying "We want democracy" and "No foreign intervention".
In the Islamic Republic, remembrance of the coup is quite different than that of history books published in the West, and follows the precepts of Ayatollah Khomeini that Islamic jurists must guide the country to prevent "the influence of foreign powers". According to historian Ervand Abrahamian, the government tries to ignore Mosaddegh as much as possible and allocates him only two pages in high school textbooks. "The mass media elevate Ayatollah Abol-Ghasem Kashani as the real leader of the oil nationalization campaign, depicting Mosaddegh as merely the ayatollah's hanger-on." This is despite the fact that Kashani came out against Mosaddegh by mid-1953 and "told a foreign correspondent that Mosaddegh had fallen because he had forgotten that the shah enjoyed extensive popular support." A month later, Kashani "went even further and declared that Mosaddegh deserved to be executed because he had committed the ultimate offense: rebelling against the shah, 'betraying' the country, and repeatedly violating the sacred law."
In the Islamic Republic of Iran, Kinzer's book "All the Shah's Men: An American Coup and the Roots of Middle East Terror" has been censored of descriptions of Ayatollah Abol-Ghasem Kashani's activities during the Anglo-American coup d'état. Mahmood Kashani, the son of Abol-Ghasem Kashani, "one of the top members of the current, ruling élite" whom the Iranian Council of Guardians has twice approved to run for the presidency, denies there was a coup d'état in 1953, saying Mosaddegh was obeying British plans to undermine the role of Shia clerics.
This allegation also is posited in the book "Khaterat-e Arteshbod-e Baznesheshteh Hossein Fardoust" (The Memoirs of Retired General Hossein Fardoust), published in the Islamic Republic and allegedly written by Hossein Fardoust, a former SAVAK officer. It claims that rather than being a mortal enemy of the British, Mohammad Mosaddegh always favored them, and his nationalisation campaign of the Anglo-Iranian Oil Company was inspired by "the British themselves". Scholar Ervand Abrahamian suggests that the fact that Fardoust's death was announced before publication of the book may be significant, as the Islamic Republic authorities may have forced him into writing such statements under duress.

1992 Los Angeles riots
The 1992 Los Angeles riots were a series of race riots that occurred over six days in the Los Angeles metropolitan area in California in April 1992. 
The riots started on April 29, 1992, after a jury trial resulted in the acquittal of four Los Angeles Police Department officers accused in the videotaped beating of motorist Rodney King following a high-speed police pursuit. Thousands of people throughout the Los Angeles metropolitan area rioted over the six days following the announcement of the verdict. Widespread looting, assault, arson and murder occurred during the riots, and estimates of property damages topped one billion dollars. The rioting ended after soldiers from the California Army National Guard, along with U.S. Marines from Camp Pendleton were called in to stop the rioting. In total, 53 people were killed during the riots and over two thousand people were injured.
Name.
The riots are also known as the Rodney King Riots, the South Central Riots, the 1992 Los Angeles Civil Disturbance, and the 1992 Los Angeles Civil Unrest. Among South Korean immigrants living in the Los Angeles metropolitan area, the 1992 Los Angeles Riots are referred to as "Sah-E-Goo", meaning literally "four-two-nine" in the Korean language, in reference to the date of which the rioting started, April 29, 1992.
Background.
On March 3, 1991, Rodney King and two passengers were driving west on the Foothill Freeway (I-210) through the Lake View Terrace neighborhood of Los Angeles. The California Highway Patrol (CHP) attempted to initiate a traffic stop. A high-speed pursuit ensued with speeds estimated at up to 115 mph first over freeways and then through residential neighborhoods. When King came to a stop, CHP Officer Timothy Singer and his wife, CHP Officer Melanie Singer, ordered the occupants under arrest.
After two passengers were placed in the patrol car, five white Los Angeles Police Department (LAPD) officers (Stacey Koon, Laurence Powell, Timothy Wind, Theodore Briseno, and Rolando Solano) attempted to subdue King, who came out of the car last. In a departure from the usual procedure, which is to tackle and cuff a suspect, King was tasered, kicked in the head, beaten with PR-24 batons for over one minute, then tackled and cuffed. The officers claimed that King was under the influence of PCP at the time of arrest, which caused him to be very aggressive and violent towards the officers. The video showed that he was crawling on the ground during the beating and that the police made no attempt to cuff him.
A subsequent test for the presence of PCP turned up negative. The incident was captured on a camcorder by resident George Holliday from his apartment in the vicinity. The tape was roughly ten minutes long. While the case was presented to the court, clips of the incident were not released to the public.
In a later interview, King, who was on parole from prison on a robbery conviction and who had past convictions for assault, battery and robbery, said that he had not surrendered earlier because he knew that an arrest for DUI would violate the terms of his parole.
The footage of King being beaten by police while lying on the ground became a focus for media attention and a rallying point for activists in Los Angeles and around the United States. Coverage was extensive during the initial two weeks after the incident: the "Los Angeles Times" published forty-three articles about the incident, "The New York Times" published seventeen articles, and the "Chicago Tribune" published eleven articles. Eight stories appeared on ABC News, including a sixty-minute special on "Primetime Live".
Charges and trial.
The Los Angeles District Attorney subsequently charged four police officers, including one sergeant, with assault and use of excessive force. Due to the heavy media coverage of the arrest, the trial received a change of venue from Los Angeles County to the politically conservative city of Simi Valley in neighboring Ventura County. The jury was composed of ten Caucasians, one Hispanic, and one Asian. The prosecutor, Terry White, was black.
On April 29, 1992, the seventh day of jury deliberations, the jury acquitted all four officers of assault and acquitted three of the four of using excessive force. The jury could not agree on a verdict for the fourth officer charged with using excessive force. The verdicts were based in part on the first three seconds of a blurry, 13-second segment of the video tape that, according to journalist Lou Cannon, was edited out by television news stations in their broadcasts.
During the first two seconds of videotape, in confirmation of claims by the police, the video showed King aggressing toward Laurence Powell. During the next one minute and 19 seconds, King is beaten continuously by the officers. The officers testified that they tried to physically restrain King prior to the starting point of the videotape but, according to the officers, King was able to physically throw them off himself.
Another theory offered by the prosecution for the officers' acquittal is that the jurors may have become desensitized to the violence of the beating, as the defense played the videotape repeatedly in slow motion, breaking it down until its emotional impact was lost.
Outside the Simi Valley courthouse where the acquittals were delivered, county sheriff's deputies protected Stacey Koon from angry protest on the way to his car. Director John Singleton, who was in the crowd at the courthouse, predicted, "By having this verdict, what these people done, they lit the fuse to a bomb."
Riots.
The riots, beginning the day of the verdicts, peaked in intensity over the next two days. A dusk-to-dawn curfew and deployment of the National Guard eventually worked to control the situation.
Fifty-three people died during the riots, including ten who were shot dead by police and military forces, with as many as 2,000 people injured. Estimates of the material losses vary between about $800 million and $1 billion. Approximately 3,600 fires were set, destroying 1,100 buildings, with fire calls coming once every minute at some points. Widespread looting also occurred. Stores owned by Korean and other Asian immigrants were widely targeted, although other stores owned by whites and blacks were targeted by rioters as well.
Many of the disturbances were concentrated in South Central Los Angeles, which was primarily composed of African American and Hispanic residents. Half of all riot arrestees and more than a third of those killed during the violence were Hispanic.
First day (Wednesday, April 29, 1992).
The acquittals of the four accused Los Angeles Police Department officers came at 3:15 pm local time. By 3:45, a crowd of more than 300 people had appeared at the Los Angeles County Courthouse protesting the verdicts passed down a half an hour earlier. Between 5 and 6 pm, a group of two dozen officers, commanded by Los Angeles Police officer, Lieutenant Michael Moulin, confronted a growing crowd at the intersection of Florence and Normandie in South Central Los Angeles. Outnumbered, the police officers retreated. By about 6:30 pm, a new group of protesters appeared at the Los Angeles Police Department's headquarters at Parker Center, and fifteen minutes later, the crowd at Florence and Normandie had started looting, attacking vehicles and people.
Attack on Reginald Denny.
At approximately 6:45 pm, Reginald Oliver Denny, a white truck driver who stopped at a traffic light at the intersection of Florence and Normandie Avenues, was dragged from his vehicle and severely beaten by a mob of local black residents as a TV news helicopter hovered above, piloted by reporter/pilot Bob Tur, who broadcast live pictures of the attack, including a concrete brick that was thrown by 'Football' Damian Williams that struck Denny in the temple, causing a near-fatal seizure. As Tur continued his reporting, it was clear that local police had deserted the city. 
Coincidentally, it was Tur's live reports that led to Denny being rescued by an unarmed, African American civilian named Bobby Green Jr. who, seeing the assault live on television, rushed to the scene and drove Denny to the hospital using the victim's own truck, which carried twenty-seven tons of sand. Denny had to undergo years of rehabilitative therapy, and his speech and ability to walk were permanently damaged. Although several other motorists were brutally beaten by the same mob, Denny remains the best-known victim of the riots because of the live television coverage. 
Fidel Lopez beating.
At the same intersection, just minutes after Denny was rescued, another beating was captured on video tape. Fidel Lopez, a self-employed construction worker and Guatemalan immigrant, was pulled from his truck and robbed of nearly $2,000. Damian Williams smashed his forehead open with a car stereo as another rioter attempted to slice his ear off. After Lopez lost consciousness, the crowd spray painted his chest, torso and genitals black.
Lopez survived the attack, undergoing extensive surgery to reattach his partially severed ear, and months of recovery.
Second day (Thursday, April 30).
Although the day began relatively quietly, by mid-morning on the second day violence appeared widespread and unchecked as heavy looting and fires were witnessed across Los Angeles County. Korean-Americans, seeing the police force's abandonment of Koreatown, organized armed security teams composed of store owners, who defended their livelihoods from assault by the mobs. Open gun battles were televised as Korean shopkeepers exchanged gunfire with armed looters.
Organized law-enforcement response began to come together by midday. Fire crews began to respond backed by police escort; California Highway Patrol reinforcements were airlifted to the city; and Los Angeles Mayor Tom Bradley announced a dusk-to-dawn curfew at 12:15 am. President George H. W. Bush spoke out against the rioting, stating that "anarchy" would not be tolerated. The California National Guard, which had been advised not to expect civil disturbance and had, as a result, loaned its riot equipment out to other law enforcement agencies, responded quickly by calling up about 2,000 soldiers, but could not get them to the city until nearly 24 hours had passed because of a lack of proper equipment, training, and available ammunition which had to be picked up from Camp Roberts, California (near Paso Robles). 
In an attempt to end hostilities, Bill Cosby spoke on the NBC affiliate television station KNBC and asked people to stop what they were doing and instead watch the final episode of "The Cosby Show".
Third day (Friday, May 1).
The third day was punctuated by live footage of Rodney King at an impromptu news conference in front of his lawyer's Los Angeles offices on Wilshire & Doheny, saying, "People, I just want to say, you know, can we all get along?" That morning, at 1:00 am, California Governor Pete Wilson had requested federal assistance, but it was not ready until Saturday, by which time the rioting and looting was under control. National Guard units (doubled to 4,000 troops) continued to move into the city in Humvees, eventually seeing 10,000 National Guard troops activated. Additionally, a varied contingent of 1,700 federal law-enforcement officers from different agencies from across the state began to arrive, to protect federal facilities and assist local police. As darkness fell, the main riot area was further hit by a power cut. 
Friday evening, U.S. President George H.W. Bush addressed the country, denouncing "random terror and lawlessness", summarizing his discussions with Mayor Bradley and Governor Wilson, and outlining the federal assistance he was making available to local authorities. Citing the "urgent need to restore order", he warned that the "brutality of a mob" would not be tolerated, and he would "use whatever force is necessary". He then turned to the Rodney King case and a more moderate tone, describing talking to his own grandchildren and pointing to the reaction of "good and decent policemen" as well as civil rights leaders. He said he had already directed the Justice Department to begin its own investigation, saying that "grand jury action is underway today" and that justice would prevail.
By this point, many entertainment and sports events were postponed or canceled. The Los Angeles Lakers hosted the Portland Trail Blazers in a basketball playoff game on the night the rioting started, but the following game was postponed until Sunday and moved to Las Vegas. The Los Angeles Clippers moved a playoff game against the Utah Jazz to nearby Anaheim. In baseball, the Los Angeles Dodgers postponed games for four straight days from Thursday to Sunday, including a whole 3-game series against the Montreal Expos (now Washington Nationals); all were made up as part of doubleheaders in July. In San Francisco, a city curfew due to unrest there forced the postponement of a May 1 San Francisco Giants home game against the Philadelphia Phillies.
The horse racing venues Hollywood Park Racetrack and Los Alamitos Race Course were also shut down. L.A. Fiesta Broadway, a major event in the Latino community, was not held in the first weekend in May as scheduled. In Music, Van Halen canceled two concert shows in Inglewood on Saturday and Sunday. Michael Bolton was scheduled to perform at the Hollywood Bowl for Sunday, but the concert was canceled. The World Wrestling Federation also canceled events on Friday and Saturday in the cities of Long Beach and Fresno.
The Southern California Rapid Transit District (now Los Angeles County Metropolitan Transportation Authority) suspended all bus service throughout the Los Angeles area. Some major freeways were closed down.
Fourth day (Saturday, May 2).
On the fourth day, 2,000 7th Infantry Division (L) 2nd BDE soldiers, and a company's worth of military policemen from Fort Ord, along with 1,500 U.S. Marines from Camp Pendleton, arrived to reinforce the California Army National Guard soldiers already in the city. This federal force took twenty-four hours to deploy to Huntington Park, about the same time it took for the California Army National Guard soldiers. This brought total troop strength associated with the effort to stop the breakdown in civil order to 13,500. U.S. military forces directly supported Los Angeles Police officers in restoring order and had a major effect of first containing, then stopping the violence. With most of the violence under control, 30,000 people attended a peace rally. On the same day, U.S. Justice Department announced it would begin a federal investigation of the Rodney King beating.
Fifth day (Sunday, May 3).
Overall quiet set in and Mayor Bradley assured the public that the crisis was, more or less, under control. In one incident, National Guardsmen shot and killed a motorist who tried to run them over at a barrier.
Sixth day (Monday, May 4).
Although Mayor Bradley lifted the curfew, signaling the official end of the riots, sporadic violence and crime continued for a few days afterward. Schools, banks, and businesses reopened. Federal troops did not stand down until May 9; the Army National Guard remained until May 14; and some soldiers remained as late as May 27.
Riots and Korean-Americans.
Korea-Americans in Los Angeles refer to the event as "Sa-E-Gu", meaning "four-two-nine" in the Korean language, in reference to the April 29, 1992, which was the day the riots started. The riots prompted various responses from Korean-Americans, including the formation of activist organizations such as the Association of Korean-American Victims, and increased efforts to build collaborative links with other ethnic groups.
During the riots, many Korean immigrants from the area rushed to Koreatown, after Korean-language radio stations called for volunteers to guard against rioters. Many were armed, with a variety of improvised weapons, shotguns, and semi-automatic rifles.
According to Professor Edward Park, director of the Asian Pacific American Studies Program at Loyola Marymount University, the 1992 violence stimulated a new wave of political activism among Korean-Americans, but it also split them into two camps. The liberals sought to unite with other minorities in Los Angeles to fight against racial oppression and scapegoating. The conservatives emphasized law and order and generally favored the economic and social policies of the Republican Party. The conservatives tended to emphasize the political differences between Koreans and other minorities, specifically blacks and Hispanics. One of the most iconic and controversial television images of the violence was a scene of two Korean merchants firing pistols repeatedly at roving looters. "The New York Times" said "that the image seemed to speak of race war, and of vigilantes taking the law into their own hands." The merchants, jewelry store and gun shop owner Richard Park and his gun store manager, David Joo, were reacting to the shooting of Mr. Park's wife and her sister by looters who converged on the shopping center where the shops were located. 
David Joo, a manager of the gun store, said, "I want to make it clear that we didn't open fire first. At that time, four police cars were there. Somebody started to shoot at us. The LAPD ran away in half a second. I never saw such a fast escape. I was pretty disappointed." Carl Rhyu, a participant in the Korean immigrants' armed response to the rioting, said, "If it was your own business and your own property, would you be willing to trust it to someone else? We are glad the National Guard is here. They're good backup. But when our shops were burning we called the police every five minutes; no response. At a shopping center several miles north of Koreatown, Jay Rhee, who estimated that he and others fired five hundred shots into the ground and air, said, "We have lost our faith in the police. Where were you when we needed you?"
One of the largest armed camps in Los Angeles' Koreatown, Koreatown was at the California Market. On the first night after the verdicts were returned in the trial of the four officers charged in the beating of Rodney King, Richard Rhee, the market owner, posted himself in the parking lot with about 20 armed employees. One year after the riots fewer than one in four damaged or destroyed businesses reopened, according to the survey conducted by the Korean-American Inter-Agency Council. According to a "Los Angeles Times" survey conducted eleven months after the riots, almost 40% of Korean-Americans said they were thinking of leaving Los Angeles. Before a verdict was issued in the new 1993 Rodney King federal civil rights trial against the four officers, Korean shop owners prepared for the worst as fear ran throughout the city, gun sales went up, virtually all of them by those of Korean descent, some merchants at flea markets removed their merchandise from their shelves, storefronts were fortified with extra Plexiglas and bars. Throughout the region, merchants readied to defend themselves as if on the eve of a war. College student Elizabeth Hwang spoke of the attacks on her parents' convenience store in 1992 and the fact that if trouble erupted following the 1993 trial, that they were armed with a Glock 17 pistol, a Beretta and a shotgun and they plan to barricade themselves in their store to fight off looters. Some Koreans formed armed self defence groups following the 1992 riots. Speaking just prior to the 1993 verdict, Mr. Yong Kim, leader of the Korea Young Adult Team of Los Angeles, which purchased five AK-47s, stated, "We made a mistake last year. This time we won't. I don't know why Koreans are always a special target for African-Americans, but if they are going to attack our community then we are going to pay them back."
Post-riot commentary.
In addition to the immediate trigger of the Rodney King verdicts, a range of other factors were cited as reasons for the unrest. Anger over Korean American shop-owner Soon Ja Du's weak sentence for fatally shooting a black teenager Latasha Harlins was pointed to as a potential reason for the riots, particularly for aggression toward Korean Americans. Publications such as "Newsweek" and "Time" suggested that the source of these racial antagonisms was derived from perceptions amongst blacks that Korean-American merchants were taking money out of their community and refusing to hire blacks to work in their shops. According to this view, these tensions were intensified when Du was sentenced to five years probation but no jail time after a jury convicted her of manslaughter.
Another explanation offered for the riots was the extremely high unemployment among the residents of South Central Los Angeles, which had been hit very hard by the nation-wide recession, and the high levels of poverty there. Articles in the "Los Angeles Times" and "The New York Times" linked the economic deterioration of South Central to the declining living conditions of the residents, and suggested that local resentments about these conditions helped to fuel the riots.
Social commentator Mike Davis pointed to the growing economic disparity in Los Angeles in the years leading up to the riots caused by corporate restructuring and government deregulation, with inner-city residents bearing the brunt of these changes. Such conditions engendered a widespread feeling of frustration and powerlessness in the urban populace, with the King verdicts eventually setting off their resentments in a violent expression of collective public protest. To Davis and other writers, the tensions witnessed between African-Americans and Korean-Americans during the unrest was as much to do with the economic competition forced on the two groups by wider market forces, as with either cultural misunderstandings or blacks angered about the killing of Harlins.
One of the more detailed analyses of the unrest was a study produced shortly after the riots by a Special Committee of the California Legislature, entitled "To Rebuild is Not Enough". After extensive research, the Committee concluded that the inner-city conditions of poverty, segregation, lack of educational and employment opportunities, police abuse and unequal consumer services created the underlying causes of the riots. It also pointed to changes in the American economy and the growing ethnic diversity of Los Angeles as important sources of urban discontent, which eventually exploded on the streets following the King verdicts. Another official report, "The City in Crisis", was initiated by the Los Angeles Board of Police Commissioners and made many of the same observations as the Assembly Special Committee about the growth of popular urban dissatisfaction leading up to the unrest.
In his public statements during the riots, civil rights activist and Baptist minister Jesse Jackson sympathized with the anger experienced by African-Americans regarding the verdicts in the King trial, and pointed to certain root causes of the disturbances. Although he suggested that the violence was not justified, he repeatedly emphasized that the riots were an inevitable result of the continuing patterns of racism, police brutality and economic despair suffered by inner-city residents — a tinderbox of seething frustrations which was eventually set off by the verdicts.
Democratic presidential candidate, Bill Clinton, argued likewise that the violence resulted from the breakdown of economic opportunities and social institutions in the inner city. He also berated both major political parties for failing to address urban issues, especially the Republican Administration for its presiding over "more than a decade of urban decay" generated by their spending cuts. He maintained that the King verdicts could not be avenged by the "savage behavior" of "lawless vandals". He also stated that people "are looting because ... hey do not share our values, and their children are growing up in a culture alien from ours, without family, without neighborhood, without church, without support."
African-American Congressional representative of South Central Los Angeles, Democrat Maxine Waters, said that the events in L.A. constituted a "rebellion" or "insurrection" caused by the underlying reality of poverty and despair existing in the inner city. This state of affairs, she asserted, were brought about by a government which had all but abandoned the poor through the loss of local jobs and by the institutional discrimination encountered by people of racial minorities, especially at the hands of the police and financial institutions.
Conversely, President Bush argued that the unrest was "purely criminal". Though he acknowledged that the King verdicts were plainly unjust, he maintained that "we simply cannot condone violence as a way of changing the system ... Mob brutality, the total loss of respect for human life was sickeningly sad ... What we saw last night and the night before in Los Angeles is not about civil rights. It's not about the great cause of equality that all Americans must uphold. It's not a message of protest. It's been the brutality of a mob, pure and simple."
Vice President Dan Quayle blamed the violence on a "Poverty of Values" –"I believe the lawless social anarchy which we saw is directly related to the breakdown of family structure, personal responsibility and social order in too many areas of our society" Similarly, the White House Press Secretary, Marlin Fitzwater, alleged that "many of the root problems that have resulted in inner city difficulties were started in the '60s and '70s and ... they have failed ... ow we are paying the price."
Several prominent writers expressed a similar "culture of poverty" argument. Writers in "Newsweek", for example, drew a distinction between the actions of the rioters in 1992 with those of the urban upheavals in the 1960s, arguing that "here the looting at Watts had been desperate, angry, mean, the mood this time was closer to a manic fiesta, a TV game show with every looter a winner."
Meanwhile, in an article published in "Commentary" entitled "How the Rioters Won", conservative columnist Midge Decter referred to African-American city youths and asked "ow is it possible to go on declaring that what will save the young men of South-Central L.A., and the young girls they impregnate, and the illegitimate babies they sire, is jobs? How is it possible to look at these boys of the underclass ... and imagine that they either want or could hold on to jobs?"
Media coverage.
Almost as soon as the disturbances broke out in South Central, local television news cameras were on the scene to record the events as they happened. Television coverage of the riots was near-continuous, starting with the beating of motorists at the intersection of Florence and Normandie broadcast live by television news pilot/reporter Bob Tur, and his camera operator, Marika Gerrard. By virtue of their extensive coverage, mainstream television stations provided a vivid, comprehensive and valuable record of the violence occurring on the streets of Los Angeles.
In part because of extensive media coverage of the Los Angeles riots, smaller but similar riots and other anti-police actions took place in other cities throughout the United States. The Emergency Broadcast System was also utilized during the rioting.
Aftermath.
In the aftermath of the riots, pressure mounted for a retrial of the officers, and federal charges of civil rights violations were brought against them. As the first anniversary of the acquittal neared, the city tensely awaited the decision of the federal jury; seven days of deliberations raised fears of further violence in the event of another "not guilty" verdict. 
The decision was read in an atypical 7:00 am Saturday court session on April 17, 1993. Two officers - Officer Laurence Powell and Sergeant Stacey Koon - were found guilty, while officers Theodore Briseno and Timothy Wind were acquitted. Mindful of accusations of sensationalist reporting in the wake of the first trial and the resulting chaos, media outlets opted for more sober coverage, which included calmer on-the-street interviews. Police were fully mobilized with officers on 12-hour shifts, convoy patrols, scout helicopters, street barricades, tactical command centers, and support from the National Guard and Marines.
All four of the officers involved have since quit or have been fired from the LAPD. Officer Theodore Briseno left the LAPD after being acquitted on federal charges. Officer Timothy Wind, who was also acquitted a second time, was fired after the appointment of Willie L. Williams as Chief of Police. Chief Williams' tenure was also short-lived. The Los Angeles Police Commission declined to renew his contract, citing Williams' failure to fulfill his mandate to create meaningful change in the department in the wake of the Rodney King disaster. Susan Clemmer, an officer who gave crucial testimony for the defense at the initial trial, committed suicide in July 2009 in the lobby of a Los Angeles Sheriff's Station. She rode in the ambulance with King and testified that he was laughing and spat blood on her uniform. She had remained in law enforcement and was a Sheriff's Detective at the time of her death.
Rodney King was awarded $3.8 million in damages from the City of Los Angeles for the attack. He invested most of this money in founding a record label, "Straight Alta-Pazz Records". The venture was unable to garner any success and soon folded. Since the arrest which culminated in his severe beating by the four police officers, King was arrested at least a further eleven times on a variety of charges, including domestic abuse and hit-and-run. King and his family moved from Los Angeles to Rialto, California, a suburb in San Bernardino County in an attempt to escape the fame and notoriety and to begin a new life. King and his family later returned to Los Angeles, where they ran a family-owned construction company. King, until his death on June 17, 2012, rarely discussed the incident or its aftermath, preferring to remain out of the spotlight. Renee Campbell, his most recent attorney, described King as "...simply a very nice man caught in a very unfortunate situation." 
Many Los Angeles residents were motivated to buy weapons for self-defense against further violence, though the 10-day waiting period in California law stymied those who wanted to purchase firearms while the riot was going on.
Nearly a third of the rioters arrested were released because police officers were unable to identify individuals in the sheer volume of the crowd. In one case, officers arrested around 40 people stealing from one store- while they were identifying them, a group of another 12 looters were brought in. With the groups mingled, charges could not be brought against individuals for stealing from specific stores, and the police were forced to release them all.

American Airlines Flight 77
American Airlines Flight 77 was a passenger flight which was hijacked by five al-Qaeda terrorists on September 11, 2001, as part of the September 11 attacks. They deliberately crashed it into the Pentagon near Washington, D.C., killing all 59 people on board plus the hijackers, as well as 125 people in the building. The aircraft involved, a Boeing 757-223, was flying American Airlines' daily scheduled morning transcontinental service from Washington Dulles International Airport, in Dulles, Virginia to Los Angeles International Airport in Los Angeles, California.
Less than 35 minutes into the flight, the hijackers stormed the cockpit and forced the passengers, crew, and pilots to the rear of the aircraft. Hani Hanjour, one of the hijackers who was trained as a pilot, assumed control of the flight. Unknown to the hijackers, passengers aboard were able to make telephone calls to loved ones and relay information on the hijacking.
The aircraft crashed into the western side of the Pentagon at 09:37 EDT. Dozens of people witnessed the crash and news sources began reporting on the incident within minutes. The impact severely damaged an area of the Pentagon and caused a large fire. At 10:10AM, a portion of the Pentagon collapsed; firefighters spent days trying to fully extinguish the blaze. The damaged sections of the Pentagon were rebuilt in 2002, with occupants moving back into the completed areas on August 15, 2002.
The 184 victims of the attack are memorialized in the Pentagon Memorial adjacent to the Pentagon. The park contains a bench for each of the victims, arranged according to their year of birth, ranging from 1930 (age 71) to 1998 (age 3).
Hijackers.
The hijackers on American Airlines Flight 77 were led by Hani Hanjour, who piloted the aircraft into the Pentagon. Hanjour first came to the United States in 1990. He trained at the CRM Airline Training Center in Scottsdale, Arizona, earning his FAA commercial pilot's certificate in April 1999. He had wanted to be a commercial pilot for the Saudi national airline but was rejected when he applied to the civil aviation school in Jeddah in 1999. Hanjour's brother later explained that, frustrated at not finding a job, Hanjour "increasingly turned his attention toward religious texts and cassette tapes of militant Islamic preachers". Hanjour left Saudi Arabia in late 1999, telling his family that he was going to the United Arab Emirates to work for an airline. Instead, Hanjour likely ended up in Afghanistan where Al Qaeda recruits were screened for special skills they may have. Already having selected the Hamburg Cell members, Al Qaeda leaders selected Hanjour to lead the fourth team of hijackers.
The CIA's unit dedicated to tracking Osama bin Laden, Alec Station, had discovered that two of the other hijackers, al-Hazmi and al-Mihdhar, had multiple entry visas to the United States well before 9/11. Two FBI agents inside the unit tried to alert FBI headquarters, but CIA officers rebuffed them.
In December 2000, Hanjour arrived in San Diego, joining "muscle" hijackers Nawaf al-Hazmi and Khalid al-Mihdhar, who had been there since January 2000. Soon after arriving, Hanjour and Hazmi left for Mesa, Arizona, where Hanjour began refresher training at Arizona Aviation. In April 2001, they relocated to Falls Church, Virginia, where they awaited the arrival of the remaining "muscle" hijackers. One of these men, Majed Moqed, arrived on May 2, 2001, with Flight 175 hijacker Ahmed al-Ghamdi from Dubai at Dulles International Airport and moved into an apartment with Hazmi and Hanjour.
On May 21, 2001, Hanjour rented a room in Paterson, New Jersey, where he stayed with other hijackers through the end of August. The last Flight 77 "muscle" hijacker, Salem al-Hazmi, arrived on June 29, 2001, with Flight 11 hijacker Abdulaziz al-Omari at John F. Kennedy International Airport from the United Arab Emirates and stayed with Hanjour. Hani Hanjour received ground instruction and did practice flights at Air Fleet Training Systems in Teterboro, New Jersey, and at Caldwell Flight Academy in Fairfield, New Jersey. Hanjour moved out of the room in Paterson and arrived at the Valencia Motel in Laurel, Maryland, on September 2, 2001. While in Maryland, Hanjour and fellow hijackers trained at the Gold's Gym in Greenbelt. On September 10, he completed a certification flight, using a terrain recognition system for navigation, at Congressional Air Charters in Gaithersburg, Maryland. On September 10, Nawaf al-Hazmi, accompanied by other hijackers, checked into the Marriott in Herndon, Virginia.
Suspected accomplices.
According to U.S. State Department cable of February 2010, the FBI has investigated another suspect, Mohammed al-Mansoori, who had associated with three Qatari citizens who had flown from Washington to London on the eve of the attacks, after allegedly surveying the World Trade Center and the White House. U.S. law enforcement officials said that the information about the four men was "just one of many leads that were thoroughly investigated at the time and never led to terrorism charges". An official added, however, that the three Qatari citizens have never been questioned by the FBI. Eleanor Hill, the former staff director for the congressional joint inquiry on the September 11 attacks, said the cable reinforces questions about the thoroughness of the FBI's investigation. She also said that the inquiry concluded that the hijackers had a support network that helped them in different ways. The three Qatari men were booked to fly from Los Angeles to Washington on September 10, 2001, on the same plane that was hijacked and piloted into the Pentagon on the following day, but did instead fly from Los Angeles to Qatar, via London. While the cable states that Mansoori would be currently under investigation, U.S. law enforcement officials said that there was no active investigation of him or of the Qatari citizens mentioned in the cable.
Flight.
The American Airlines Flight 77 aircraft was a Boeing 757-223 (registration number N644AA). The flight crew included pilot Charles Burlingame, First Officer David Charlebois, and flight attendants Michele Heidenberger, Jennifer Lewis, Kenneth Lewis, and Renee May. The capacity of the aircraft was 188 passengers, but with 58 passengers on September 11, the load factor was 33 percent. Tuesdays were the least-traveled day of the week, with the same load factor seen on Tuesdays in the previous three months for Flight 77.
Boarding and departure.
On the morning of September 11, 2001, the five hijackers arrived at Washington, D.C.'s Dulles International Airport. At 07:15, Khalid al-Mihdhar and Majed Moqed checked in at the American Airlines ticket counter for Flight 77, arriving at the passenger security checkpoint a few minutes later at 07:18. Both men set off the metal detector and were put through secondary screening. Moqed continued to set off the alarm, so he was searched with a hand wand. The Hazmi brothers checked in together at the ticket counter at 07:29. Hani Hanjour checked in separately and arrived at the passenger security checkpoint at 07:35. Hanjour was followed minutes later at the checkpoint by Salem and Nawaf al-Hazmi, who also set off the metal detector's alarm. The screener at the checkpoint never resolved what set off the alarm. As seen in security footage later released, Nawaf Hazmi appeared to have an unidentified item in his back pocket, but four-inch utility knives were nonetheless then permitted by the Federal Aviation Administration (FAA) as carry-on items. The passenger security checkpoint at Dulles International Airport was operated by Argenbright Security, under contract with United Airlines.
The hijackers were also all selected for extra screening of their checked bags. Hani Hanjour, Khalid al-Mihdhar, and Majed Moqed were chosen by the Computer Assisted Passenger Prescreening System criteria, while Nawaf al-Hazmi and Salem al-Hazmi were selected because they did not provide adequate identification and were deemed suspicious by the airline check-in agent. Hanjour, Mihdhar, and Nawaf al-Hazmi did not check any bags for the flight. Checked bags belonging to Moqed and Salem al-Hazmi were held until they boarded the aircraft. By 07:50, the five hijackers, carrying knives and box cutters, had made it through the airport security checkpoint.
Flight 77 was scheduled to depart for Los Angeles at 08:10; 58 passengers boarded through Gate D26, including the five hijackers. Excluding the hijackers, of the 59 other passengers and crew on board, there were 26 men, 22 women, and five children ranging in age from three to eleven. On the flight, Hani Hanjour was seated up front in 1B, while Salem and Nawaf al-Hazmi were seated in first class in seats 5E and 5F. Majed Moqed and Khalid al-Mihdhar were seated further back in 12A and 12B, in economy class. Flight 77 left the gate on time and took off from Runway 30 at Dulles at .
Hijacking.
The 9/11 Commission estimated that the flight was hijacked between 08:51 and 08:54, shortly after American Airlines Flight 11 struck the World Trade Center and not too long after United Airlines Flight 175 had just been hijacked. The last normal radio communications from the aircraft to air traffic control occurred at 08:50:51. Unlike the other three flights, there were no reports of anyone being stabbed or a bomb threat. At 08:54, the plane began to deviate from its normal, assigned flight path and turned south. The hijackers set the flight's autopilot heading for Washington, D.C. By 08:56, the flight was turned around, and the transponder had been disabled. The FAA was aware at this point that there was an emergency on board the airplane. By this time, American Airlines Flight 11 had already crashed into the North Tower of the World Trade Center, and United Airlines Flight 175 was known to have been hijacked and was within minutes of also striking the South Tower. After learning of this second hijacking involving an American Airlines aircraft and the hijacking involving United Airlines, American Airlines' Executive Vice President Gerard Arpey ordered a nationwide ground stop for the airline. The Indianapolis Air Traffic Control Center, as well as American Airlines dispatchers, made several failed attempts to contact the aircraft. At the time the airplane was hijacked, it was flying over an area of limited radar coverage. With air controllers unable to contact the flight by radio, an Indianapolis official declared that the Boeing 757 had possibly crashed at 09:09.
Two people on the aircraft made phone calls to contacts on the ground. At 09:12, flight attendant Renee May called her mother, Nancy May, in Las Vegas. During the call, which lasted nearly two minutes, May said her flight was being hijacked by six individuals and they had been moved to the rear of the airplane. May also asked her mother to contact American Airlines, which she and her husband promptly did; American Airlines was already aware of the hijacking. Between 09:16 and 09:26, passenger Barbara Olson called her husband, United States Solicitor General Theodore Olson and reported that the airplane had been hijacked and that the assailants had box cutters and knives. She reported that the passengers, and possibly the crew, had been moved to the back of the cabin and that the hijackers were unaware of her call. A minute into the conversation, the call was cut off. Theodore Olson contacted the command center at the Department of Justice, and tried unsuccessfully to contact Attorney General John Ashcroft. About five minutes later, Barbara Olson called again, told her husband that the "pilot" (possibly Hanjour on the cabin intercom) had announced the flight was hijacked, and asked "what do I tell the pilot to do?" Ted Olson asked her location and she reported the plane was flying over a residential area. He then informed her of the attacks on the World Trade Center. Soon afterward, the call cut off again.
An airplane was detected again by Dulles controllers on radar screens as it approached Washington, turning and descending rapidly. Controllers initially thought this was a military fighter, due to its high speed and maneuvering. Reagan Airport controllers then asked a passing Air National Guard Lockheed C-130 Hercules to identify and follow the aircraft. The pilot, Lt. Col. Steven O'Brien, told them it was a Boeing 757 or 767, and its silver fuselage meant it was probably an American Airlines jet. He had difficulty picking out the airplane in the "East Coast haze", but then saw a "huge" fireball, and initially assumed it had hit the ground. Approaching the Pentagon, he saw the impact site on the building's west side and reported to Reagan control, "Looks like that aircraft crashed into the Pentagon, sir".
Crash.
According to the 9/11 Commission Report, as Flight 77 was west-southwest of the Pentagon, it made a 330-degree turn. At the end of the turn, it was descending through , pointed toward the Pentagon and downtown Washington. Hani Hanjour advanced the throttles to maximum power and dived towards the Pentagon. While level above the ground and seconds from the crash, the wings knocked over five street lampposts and the right wing struck a portable generator, creating a smoke trail seconds before smashing into the Pentagon. Flight 77, flying at 530 mph (853 km/h, 237 m/s, or 460 knots) over the Navy Annex Building adjacent to Arlington National Cemetery, crashed into the western side of the Pentagon in Arlington County, Virginia, just south of Washington, D.C., at 09:37:46, killing all 53 passengers, five hijackers, and six crew. The plane hit the Pentagon at the first-floor level, and at the moment of impact, the airplane was rolled slightly to the left, with the right wing elevated. The front part of the fuselage disintegrated on impact, while the mid and tail sections moved for another fraction of a second, with tail section debris penetrating furthest into the building. In all, the airplane took eight-tenths of a second to fully penetrate into the three outermost of the building's five rings and unleashed a fireball that rose above the building.
At the time of the attacks, approximately 18,000 people worked in the Pentagon, which was 4,000 fewer than before renovations began in 1998. The section of the Pentagon, which had recently been renovated at a cost of $250 million, housed the Naval Command Center and other Pentagon offices, as well as some unoccupied offices. The crash and subsequent fire penetrated three outer ring sections of the western side. The outermost ring section was largely destroyed, and a large section collapsed. One hundred and twenty-five people in the Pentagon died in the attack.
In all, there were 189 deaths at the Pentagon site, including 125 in the Pentagon building in addition to the 64 on board the aircraft. Passenger Barbara Olson was en route to a taping of "Politically Incorrect". A group of children, their chaperones, and National Geographic Society staff members were also on board, embarking on an educational trip west to the Channel Islands National Marine Sanctuary near Santa Barbara, California. The fatalities at the Pentagon included 55 military personnel and 70 civilians. Of those 125 killed, 92 were on the first floor, 31 were on the second floor, and two were on the third. The Army suffered 75 fatalities—far more than any other branch. Another 106 injured were treated at area hospitals. Lieutenant General Timothy Maude, an Army Deputy Chief of Staff, was the highest-ranking military officer killed at the Pentagon, also killed was retired Rear Admiral Wilson Flagg, who was a passenger on the plane.
The Pentagon is bordered by Interstate 395 and Washington Boulevard, on the side where the impact occurred. Motorist Mary Lyman, who was on I-395, saw the airplane pass over at a "steep angle toward the ground and going fast" and then saw the cloud of smoke from the Pentagon. Omar Campo, another witness, was cutting the grass on the other side of the road when the airplane flew over his head. "I was cutting the grass and it came in screaming over my head. I felt the impact. The whole ground shook and the whole area was full of fire. I could never imagine I would see anything like that here". Afework Hagos, a computer programmer, was on his way to work and stuck in a traffic jam near the Pentagon when the airplane flew over. "There was a huge screaming noise and I got out of the car as the plane came over. Everybody was running away in different directions. It was tilting its wings up and down like it was trying to balance. It hit some lampposts on the way in." Daryl Donley witnessed the crash and took some of the first photographs after the crash.
"USA Today" reporter Mike Walter was driving on Washington Boulevard when he witnessed the crash, which he recounted, "I looked out my window and I saw this plane, this jet, an American Airlines jet, coming. And I thought, 'This doesn't add up, it's really low.' And I saw it. I mean it was like a cruise missile with wings. It went right there and slammed right into the Pentagon". Terrance Kean, who lived in a nearby apartment building, heard the noise of loud jet engines, glanced out his window, and saw a "very, very large passenger jet". He watched "it just plow right into the side of the Pentagon. The nose penetrated into the portico. And then it sort of disappeared, and there was fire and smoke everywhere." AP reporter Dave Winslow recounted, "I saw the tail of a large airliner ... It plowed right into the Pentagon." Tim Timmerman, who is a pilot himself, noticed American Airlines markings on the aircraft as he saw it hit the Pentagon. Other drivers on Washington Boulevard, Interstate 395, and Columbia Pike witnessed the crash, as did people in Pentagon City, Crystal City, and other nearby locations.
Former Georgetown University basketball coach John Thompson had originally booked a ticket on Flight 77. As he would tell the story many times in the following years, including a September 12, 2011 interview on Jim Rome's radio show, he had been scheduled to appear on that show on September 12, 2001. Thompson was planning to be in Las Vegas for a friend's birthday on September 13, and initially insisted on traveling to Rome's Los Angeles studio on the 11th. However, this did not work for the show, which wanted him to travel on the day of the show. After a Rome staffer personally assured Thompson that he would be able to travel from Los Angeles to Las Vegas immediately after the show, Thompson changed his travel plans. He felt the impact from the crash at his home near the Pentagon.
Rescue and recovery.
Rescue efforts began immediately after the crash. Almost all the successful rescues of survivors occurred within half an hour of the impact. Initially, rescue efforts were led by the military and civilian employees within the building. Within minutes, the first fire companies arrived and found these volunteers searching near the impact site. The firemen ordered them to leave as they were not properly equipped or trained to deal with the hazards. The Arlington County Fire Department (ACFD) assumed command of the immediate rescue operation within 10 minutes of the crash. ACFD Assistant Chief James Schwartz implemented an incident command system (ICS) to coordinate response efforts among multiple agencies. It took about an hour for the ICS structure to become fully operational. Firefighters from Fort Myer and Reagan National Airport arrived within minutes. Rescue and firefighting efforts were impeded by rumors of additional incoming planes. Chief Schwartz ordered two evacuations during the day in response to these rumors.
As firefighters attempted to extinguish the fires, they watched the building in fear of a structural collapse. One firefighter remarked that they "pretty much knew the building was going to collapse because it started making weird sounds and creaking". Officials saw a cornice of the building move and ordered an evacuation. Minutes later, at 10:10, the upper floors of the damaged area of the Pentagon collapsed. The collapse area was about at its widest point and at its deepest. This amount of time between impact and collapse allowed everyone on the fourth and fifth levels to evacuate safely before the structure collapsed. After the collapse, the interior fires intensified, spreading through all five floors. After 11:00, firefighters mounted a two-pronged attack against the fires. Officials estimated temperatures of up to . While progress was made against the interior fires by late afternoon, firefighters realized a flammable layer of wood under the Pentagon's slate roof had caught fire and begun to spread. Typical firefighting tactics were rendered useless by the reinforced structure as firefighters were unable to reach the fire to extinguish it. Firefighters instead made firebreaks in the roof on September 12 to prevent any further spreading. At 18:00 on the 12th, Arlington County issued a press release stating the fire was "controlled" but not fully "extinguished". Firefighters continued to put out smaller fires that ignited in the succeeding days.
Various pieces of aircraft debris were found within the wreckage at the Pentagon. While on fire himself, and escaping from the Navy Command Center, Lt. Kevin Shaeffer observed a chunk of the aircraft's nose cone and the nose landing gear in the service road between rings B and C. Early in the morning on Friday, September 14, Fairfax County Urban Search and Rescue Team members Carlton Burkhammer and Brian Moravitz came across an "intact seat from the plane's cockpit", while paramedics and firefighters located the two black boxes near the punch out hole in the A-E drive, nearly into the building. The cockpit voice recorder was too badly damaged and charred to retrieve any information, though the flight data recorder yielded useful information. Investigators also found a part of Nawaf al-Hazmi's driver's license in the North Parking Lot rubble pile. Personal effects belonging to victims were also found, and taken to Fort Myer.
Remains.
Army engineers determined by 5:30 p.m. on the first day that no one remained alive in the damaged section of the building. In the days after the crash, news reports emerged that up to 800 people had died. Army troops from Fort Belvoir were the first teams to survey the interior of the crash site and noted the presence of human remains. Federal Emergency Management Agency (FEMA) Urban Search and Rescue teams, including Fairfax County Urban Search and Rescue assisted the search for remains, working through the National Interagency Incident Management System (NIIMS). Kevin Rimrodt, a Navy photographer surveying the Navy Command Center after the attacks, remarked that "there were so many bodies, I'd almost step on them. So I'd have to really take care to look backwards as I'm backing up in the dark, looking with a flashlight, making sure I'm not stepping on somebody". Debris from the Pentagon were taken to the Pentagon's north parking lot for more detailed search for remains and evidence.
Remains that were recovered from the Pentagon were photographed, and turned over to the Armed Forces Medical Examiner office, located at Dover Air Force Base in Delaware. The medical examiner's office was able to identify remains belonging to 179 of the victims. Investigators eventually identified 184 of the 189 people who died in the attack. The remains of the five hijackers were identified through a process of elimination, and were turned over as evidence to the Federal Bureau of Investigation (FBI). On September 21, the ACFD relinquished control of the crime scene to the FBI. The Washington Field Office, National Capital Response Squad (NCRS), and the Joint Terrorism Task Force (JTTF) led the crime scene investigation at the Pentagon. By October 2, 2001, the search for evidence and remains was complete and the site was turned over to Pentagon officials. In 2002, the remains of 25 victims were buried collectively at Arlington National Cemetery, with a five-sided granite marker inscribed with the names of all the victims in the Pentagon. The ceremony also honored the five victims whose remains were never found.
Cockpit voice recorder.
At around 3:40 a.m on September 14, a paramedic and a firefighter who were searching through the debris of the impact site found two dark boxes, about by long. They called for an FBI agent, who in turn called for someone from the National Transportation Safety Board (NTSB). The NTSB employee confirmed that these were the flight recorders ("black boxes") from American Airlines Flight 77. Dick Bridges, deputy manager for Arlington County, Virginia, said the voice recorder was damaged on the outside and the flight data recorder was charred. But he said the FBI still was confident the data can be recovered from both. Bridges said the recorders were found "right where the plane came into the building."
Officials at both American Airlines and United Airlines said the black boxes aboard their destroyed aircraft were modern solid-state versions, which are more resistant to damage than the older magnetic tape recorders. The cockpit voice recorder was quickly transported to the NTSB lab in Washington, D.C., and its data was downloaded. Soon afterward, the FBI took charge of the box and its data. CBS News reported that "Preliminary information shows there is nothing that appears to be useful on the cockpit voice tape. The tape appears to be blank or erased." In its report on the CVR, the NTSB identified the unit as an L-3 Communications, Fairchild Aviation Recorders model A-100A cockpit voice recorder; a device which records on magnetic tape. The NTSB reported that "The majority of the recording tape was fused into a solid block of charred plastic." No usable segments of tape were found inside the recorder.
Continuity of operations.
At the moment of impact, Secretary of Defense Donald Rumsfeld was in his office on the other side of the Pentagon, away from the crash site. He ran to the site and assisted the injured. Rumsfeld then returned to his office, and went to a conference room in the Executive Support Center where he joined a secure videoteleconference with Vice President Dick Cheney and other officials. On the day of the attacks, Department of Defense officials considered moving command operations to Site R, a backup facility in Pennsylvania. Secretary of Defense Rumsfeld insisted he remain at the Pentagon, instead sending Deputy Secretary Paul Wolfowitz to Site R. The National Military Command Center (NMCC) continued to operate at the Pentagon, even with smoke getting into the facility. Engineers and building managers manipulated the ventilation and other building systems that still functioned to draw smoke out of the NMCC and bring in fresh air. During a press conference held inside the Pentagon at 18:42, Rumsfeld announced "The Pentagon's functioning. It will be in business tomorrow." Pentagon employees returned the next day to offices in areas of the Pentagon mostly unaffected. By the end of September, more workers returned to the lightly damaged areas of the Pentagon.
Aftermath.
Early estimates on rebuilding the damaged section of the Pentagon were that it would take three years to complete. However, the project moved forward at an accelerated pace and was completed by the one-year anniversary. The rebuilt section of the Pentagon includes a small indoor memorial and chapel at the point of impact. An outdoor memorial, designed by Julie Beckman and Keith Kaseman, was completed on schedule for its dedication on September 11, 2008.
Security camera video.
On May 16, 2006, the Department of Defense released filmed footage that was recorded by a security camera of American Airlines Flight 77 crashing into the Pentagon, with a plane visible in one frame, as a "thin white blur" and an explosion following. The images were made public in response to a December 2004 Freedom of Information Act request by Judicial Watch. Some still images from the video had previously been released and publicly circulated, but this was the first official release of the full video of the crash.
A nearby Citgo service station also had security cameras installed, but a video released on September 15, 2006, did not show the crash because the camera was pointed away from the crash site.
The Doubletree Hotel, located nearby in Crystal City, Virginia, also had a security camera video, and on December 4, 2006, the FBI released the video in response to a freedom of information lawsuit filed by Scott Bingham. The footage is "grainy and the focus is soft, but a rapidly growing tower of smoke is visible in the distance on the upper edge of the frame as the plane crashes into the building".
Memorials.
On September 12, 2002, Defense Secretary Donald Rumsfeld and General Richard Myers, Chairman of the Joint Chiefs of Staff, dedicated the Victims of Terrorist Attack on the Pentagon Memorial at Arlington National Cemetery. The memorial specifically honors the five individuals for whom no identifiable remains were found. This included Dana Falkenberg, age three, who was aboard American Airlines Flight 77 with her parents and older sister. However, a portion of the remains of 25 other victims are buried at the site. The memorial is a pentagonal granite marker high. On five sides of the memorial along the top are inscribed the words "Victims of Terrorist Attack on the Pentagon September 11, 2001". Aluminum plaques, painted black, are inscribed with the names of the 184 victims of the terrorist attack.
The site is located in Section 64, on a slight rise, which gives it a view of the Pentagon.
At the National September 11 Memorial, the names of the Pentagon victims are inscribed on the South Pool, on Panels S-1 and S-72 – S-76.

American Revolution
"In this article, inhabitants of the Thirteen Colonies of British America that supported the American Revolution are primarily referred to as "Americans," with occasional references to "Patriots," "Whigs," "Rebels" or "Revolutionaries." Colonists who supported the British in opposing the Revolution are usually referred to as "Loyalists" or "Tories." The geographical area of the thirteen colonies is often referred to simply as "America.""
The American Revolution was the political upheaval during the last half of the 18th century in which thirteen colonies in North America joined together to break free from the British Empire, combining to become the United States of America. They first rejected the authority of the Parliament of Great Britain to govern them from overseas without representation, and then expelled all royal officials. By 1774, each colony had established a Provincial Congress, or an equivalent governmental institution, to govern itself, but still within the empire. The British responded by sending combat troops to re-impose direct rule. Through the Second Continental Congress, the Americans managed the armed conflict against the British known as the American Revolutionary War (also: "American War of Independence", 1775–83). 
The British sent invasion armies and used their powerful navy to blockade the coast. George Washington became the American commander, working with Congress and the states to raise armies and neutralize the influence of Loyalists. Claiming the rule of George III of Great Britain was tyrannical and therefore illegitimate, Congress declared independence as a new nation in July 1776, when Thomas Jefferson wrote and the states unanimously ratified the United States Declaration of Independence. The British lost Boston in 1776, but then captured New York City. 
After a British army was captured by the American army at Saratoga, the French balanced naval power by entering the war in 1778 as allies of the United States. A combined American-French force captured a second British army at Yorktown in 1781, effectively ending the war. A peace treaty in 1783 confirmed the new nation's complete separation from the British Empire, and resulted in the United States taking possession of nearly all the territory east of the Mississippi River. 
The American Revolution was the result of a series of social, political, and intellectual transformations in early American society and government, collectively referred to as the "American Enlightenment". Americans rejected the oligarchies and aristocracies common in Europe at the time, championing instead the development of republicanism based on the Enlightenment understanding of liberalism. Among the significant results of the revolution was the creation of a democratically-elected representative government responsible to the will of the people. However, sharp political debates erupted over the appropriate level of democracy desirable in the new government, with a number of Founders fearing mob rule.
Many fundamental issues of national governance were settled with the ratification of the United States Constitution in 1788, which replaced the relatively weaker first attempt at a national government adopted in 1781, the "Articles of Confederation and Perpetual Union". In contrast to the loose confederation, the Constitution established a strong federated government. The United States Bill of Rights (1791), comprising the first ten constitutional amendments, quickly followed. It guaranteed many "natural rights" that were influential in justifying the revolution, and attempted to balance a strong national government with relatively broad personal liberties. The American shift to liberal republicanism, and the gradually increasing democracy, caused an upheaval of traditional social hierarchy and gave birth to the ethic that has formed a core of political values in the United States.
Origins.
The American Revolution was predicated by a number of ideas and events that, combined, led to a political and social separation of colonial possessions from the home nation and a coalescing of those former individual colonies into an independent nation.
Summary.
The American revolutionary era began in 1763, after a series of victories by British forces at the conclusion of the French and Indian War (also, "Seven Years War") ended the French military threat to British North American colonies. Adopting the policy that the colonies should pay a larger proportion of the costs associated with keeping them in the Empire, Britain imposed a series of direct taxes (later known as the "Stamp Act"), followed by other laws intended to demonstrate British authority, all of which proved extremely unpopular in America. Benjamin Franklin, appearing before the British Parliament testified "The Colonies raised, clothed, and paid, during the last war, near twenty-five thousand men, and spent many millions."
Because the colonies lacked elected representation in the governing British Parliament, many colonists considered the laws to be illegitimate and a violation of their rights as Englishmen. The opinion of the British Government, which was not unanimous, was that the colonies enjoyed "virtual representation."
In 1772, groups of colonists began to create "Committees of Correspondence", which would lead to their own Provincial Congresses in most of the colonies. In the course of two years, the Provincial Congresses or their equivalents rejected the Parliament and effectively replaced the British ruling apparatus in the former colonies, culminating in 1774 with the coordinating First Continental Congress. In response to protests in Boston over Parliament's attempts to assert authority, the British sent combat troops, dissolved local governments, and imposed direct rule by Royal officials. 
Consequently, the Colonies mobilized their militias, and fighting broke out in 1775. First ostensibly loyal to King George III and desiring to govern themselves while remaining in the empire, the repeated pleas by the First Continental Congress for royal intervention on their behalf with Parliament resulted in the declaration by the King that the states were "in rebellion", and the members of Congress were traitors. 
In 1776, representatives from each of the original 13 states voted unanimously in the Second Continental Congress to adopt a Declaration of Independence, which now rejected the British monarchy in addition to its Parliament, and established the sovereignty of the new nation external to the British Empire. The Declaration established the United States, which was originally governed as a loose confederation through a representative democracy selected by state legislatures (see "Second Continental Congress" and "Congress of the Confederation").
Ideology behind the Revolution.
The ideological movement known as the American Enlightenment was a critical precursor to the American Revolution. Chief among the ideas of the American Enlightenment were the concepts of liberalism, republicanism and fear of corruption. Collectively, the acceptance of these concepts by a growing number of American colonists began to foster an intellectual environment which would lead to a new sense of political and social identity.
Natural rights.
John Locke's (1632–1704) ideas on liberty greatly influenced the political thinking behind the revolution. John Locke's Two Treatises of Government, published in 1689, was especially influential. The theory of the "social contract" influenced the belief among many of the Founders that among the "natural rights" of man was the right of the people to overthrow their leaders, should those leaders betray the historic rights of Englishmen. In terms of writing state and national constitutions, the Americans heavily used Montesquieu's analysis of the "balanced" British Constitution.
Republicanism.
A motivating force behind the revolution was the American embrace of a political ideology called "republicanism", which was dominant in the colonies by 1775. The republicanism was inspired by the "country party" in Britain, whose critique of British government emphasized that corruption was a terrible reality in Britain. Americans feared the corruption was crossing the Atlantic; the commitment of most Americans to republican values and to their rights, energized the revolution, as Britain was increasingly seen as hopelessly corrupt and hostile to American interests. Britain seemed to threaten the established liberties that Americans enjoyed. The greatest threat to liberty was depicted as corruption—not just in London but at home as well. The colonists associated it with luxury and, especially, inherited aristocracy, which they condemned.
The Founding Fathers were strong advocates of republican values, particularly Samuel Adams, Patrick Henry, John Adams, Benjamin Franklin, Thomas Jefferson, Thomas Paine, George Washington, James Madison and Alexander Hamilton, which required men to put civic duty ahead of their personal desires. Men had a civic duty to be prepared and willing to fight for the rights and liberties of their countrymen and countrywomen. John Adams, writing to Mercy Otis Warren in 1776, agreed with some classical Greek and Roman thinkers in that "Public Virtue cannot exist without private, and public Virtue is the only Foundation of Republics." He continued: Adams quoted in Paul A. Rahe, "Republics Ancient and Modern: Classical Republicanism and the American Revolution. Volume: 2" (1994) P. 23.
 For women, "republican motherhood" became the ideal, exemplified by Abigail Adams and Mercy Otis Warren; the first duty of the republican woman was to instill republican values in her children and to avoid luxury and ostentation.
Fusing republicanism and liberalism.
While some republics had emerged throughout history, such as the Roman Republic of the ancient world, one based on liberal principles had never existed. Thomas Paine's best-seller pamphlet "Common Sense" appeared in January 1776, after the Revolution had started. It was widely distributed and loaned, and often read aloud in taverns, contributing significantly to spreading the ideas of republicanism and liberalism together, bolstering enthusiasm for separation from Britain, and encouraging recruitment for the Continental Army.
Paine provided a new and widely accepted argument for independence, by advocating a complete break with history. "Common Sense" is oriented to the future in a way that compels the reader to make an immediate choice. It offered a solution for Americans disgusted and alarmed at the threat of tyranny.
Impact of Great Awakening.
Dissenting (i.e. Protestant, non-Church of England) churches of the day were the "school of democracy.” President John Witherspoon of the College of New Jersey (now Princeton University) wrote widely circulated sermons linking the American Revolution to the teachings of the Hebrew Bible. Throughout the colonies, dissenting Protestant congregations (Congregationalist, Baptist, and Presbyterian) preached Revolutionary themes in their sermons, while most Church of England ministers preached loyalty to the King. Religious motivation for fighting tyranny reached across socioeconomic lines to encompass rich and poor, men and women, frontiersmen and townsmen, farmers and merchants.
The historian Bernard Bailyn argues that the evangelism of the era challenged traditional notions of natural hierarchy by teaching that the Bible taught all men are equal, so that the true value of a man lies in his moral behavior, not his class. Kidd argues that religious disestablishment, belief in a God as the guarantor of human rights, and shared convictions about sin, virtue, and divine providence worked together to unite rationalists and evangelicals and thus encouraged American defiance of the Empire.
Emphasizing the intense opposition to sending an Anglican bishop to the colonies, and anger at the pro-Catholic Quebec Act of 1774, Kidd argues that the reactions reflected the long-term influence of the Great Awakening, in terms of apocalyptic warnings, religious egalitarianism, and anti‐Catholicism. He said that the result was that by 1773, when British challenges to American's perceptions of their rights as Englishemen escalated, Patriots were prepared to defy British administrators.
Controversial British legislation.
The Revolution was in some ways incited by a number of pieces of legislation originating from the British Parliament that, for Americans, were illegitimate acts of a government that had no right to pass laws on Englishmen in the Americas who did not have elected representation in that government. For the British, policy makers saw these laws as necessary to rein in colonial subjects who, in the name of economic development that was designed to benefit the home nation, had been allowed near-autonomy for too long.
1733–1763: Navigation Acts, Molasses Act and Royal Proclamation.
The British Empire at the time operated under the mercantile system, where all trade was concentrated inside the Empire, and trade with other empires was forbidden. The goal was to enrich Britain—its merchants and its government. Whether the policy was good for the colonists was not an issue in London, but Americans became increasingly restive with mercantilist policies
Britain implemented mercantilism by trying to block American trade with the French, Spanish or Dutch empires using the Navigation Acts, which Americans avoided as often as they could. The royal officials responded to smuggling with open-ended search warrants (Writs of Assistance). In 1761, Boston lawyer James Otis argued that the writs violated the constitutional rights of the colonists. He lost the case, but John Adams later wrote, "Then and there the child Independence was born."
In 1762, Patrick Henry argued the Parson's Cause in the Colony of Virginia, where the legislature had passed a law and it was vetoed by the king. Henry argued, "that a King, by disallowing Acts of this salutary nature, from being the father of his people, degenerated into a Tyrant and forfeits all right to his subjects' obedience".
Following their victory in the French and Indian War in 1763, Great Britain took control of the French holdings in North America, outside the Caribbean. The British sought to maintain peaceful relations with those Indian tribes that had allied with the French, and keep them separated from the American frontiersmen. To this end, the Royal Proclamation of 1763 restricted settlement west of the Appalachian Mountains as this was designated an Indian Reserve. Disregarding the proclamation, some groups of settlers continued to move west and establish farms. The proclamation was soon modified and was no longer a hindrance to settlement, but the fact that it had been promulgated without their prior consultation angered the colonists.
1764–1766: More provocative legislation.
Britain did not expect the colonies to contribute to the interest or the retirement of debt incurred during its wars, but they did expect a portion of the expenses for colonial defense to be paid by the Americans. Estimating the expenses of defending the continental colonies and the British West Indies to be approximately £200,000 annually, the British goal after the end of this war was that the colonies would be taxed for £78,000 of this amount. The colonists objected chiefly on the grounds not that the taxes were high (they were low) but that they had no representation in the Parliament. Parliament insisted it had the right to levy any tax without colonial approval, to demonstrate that it had authority over the colonies.
Modern American economic historians have challenged the view that Britain was seeking to place a heavy new burden on the colonies and have suggested the real cost of defending the North American colonies from the possibility of invasion by France or Spain was £400,000, five times the maximum income from them. On the other hand, the colonists felt the heavy military presence as an unwelcome burden in other ways besides taxation. Perhaps, most notably, the British military was determined to carry on with requisitioning practices in the colonies in much the same way they had during the French and Indian War. This did not require any specific Parliamentary sanction – established law permitted commanders to acquire goods and livestock from local suppliers at prices the military deemed to be fair, but what had been an understandable and tolerated arrangement during wartime quickly became a serious irritant in the colonies once the hostilities with France were over.
The colonists did not object to the principle of contributing to the cost of their defense (colonial legislatures spent large sums raising and outfitting militias during the French and Indian War), but they disputed the need for the Crown to station regular British troops in North America. In the absence of a French threat, colonists believed the colonial militias (which were funded by taxes raised by colonial legislatures) to be sufficient to deal with any trouble with natives on the frontier. Officer positions were in high demand among the British aristocracy—the rank of captain or major sold for thousands of pounds, and could be resold once an officer purchased an even higher rank. 
The British wanted all the commissions for themselves, and were unwilling to commission colonial officers (who would pay nothing for their commissions) and further asserted that officers with colonial commissions must submit to the authority of any regular British officer, regardless of rank. This effectively negated the will or the legal authority of the colonies to contribute to defense through their militias. With some 1,500 well-connected British officers who would have become redundant in the aftermath of the Seven Years' War, London would have had to discharge them if they did not assign them to North America. Therefore the main reason for Parliament imposing taxes was to prove its supremacy, and the main use of the tax funds would be patronage for ambitious British officers. London responded that the colonists were "virtually represented"; but most Americans rejected this.
In 1764 Parliament enacted the Sugar Act and the Currency Act, further vexing the colonists. Protests led to a powerful new weapon, the systematic boycott of British goods. The following year, the British enacted the Quartering Acts, which required British soldiers to be quartered at the expense of residents in certain areas. Colonists objected to this, as well.
In 1765 the Stamp Act was the first direct tax levied on the colonies by British Prime Minister George Grenville and the Parliament. All official documents, newspapers, almanacs, and pamphlets— decks of playing cards—were required to have the stamps. The colonists still considered themselves loyal subjects of the British Crown, with the same historic rights and obligations as subjects in Britain.
Nevertheless, representatives of all 13 colonies protested vehemently, as popular leaders such as Patrick Henry in Virginia and James Otis in Massachusetts, rallied the people in opposition. A secret group, the "Sons of Liberty" formed in many towns and threatened violence if anyone sold the stamps, and no one did. 
In Boston, the Sons of Liberty burned the records of the vice-admiralty court and looted the home of the chief justice, Thomas Hutchinson. Several legislatures called for united action, and nine colonies sent delegates to the Stamp Act Congress in New York City in October 1765. Moderates led by John Dickinson drew up a "Declaration of Rights and Grievances" stating that taxes passed without representation violated their Rights of Englishmen. Colonists emphasized their determination by boycotting imports of British merchandise.
In London, the Rockingham government came to power and Parliament debated whether to repeal the stamp tax or send an army to enforce it. Benjamin Franklin made the case for repeal, explaining the colonies had spent heavily in manpower, money, and blood in defense of the empire in a series of wars against the French and Indians, and that further taxes to pay for those wars were unjust and might bring about a rebellion. Parliament agreed and repealed the tax, but in the Declaratory Act of March 1766 insisted that parliament retained full power to make laws for the colonies "in all cases whatsoever".
1767–1773: Townshend Acts and the Tea Act.
In 1767 the Parliament passed the Townshend Acts, which placed a tax on a number of essential goods including paper, glass, and tea. Angered at the tax increases, colonists organized a boycott of British goods. In Boston on March 5, 1770 a large mob gathered around a group of British soldiers. The mob grew more and more threatening, throwing snowballs, rocks and debris at the soldiers. One soldier was clubbed and fell. 
All but one of the soldiers fired into the crowd. 11 people were hit; three civilians were killed at the scene of the shooting, and two died after the incident. The event quickly came to be called the Boston Massacre. Although the soldiers were tried and acquitted (defended by John Adams), the widespread descriptions soon became propaganda to turn colonial sentiment against the British. This in turn began a downward spiral in the relationship between Britain and the Province of Massachusetts. 
In June 1772, in what became known as the "Gaspée" Affair, a British warship that had been vigorously enforcing unpopular trade regulations was burned by American patriots including John Brown. About a year later, private letters were published in which Massachusetts Governor Thomas Hutchinson called for the abridgement of colonial rights, and Lieutenant Governor Andrew Oliver called for the direct payment of colonial officials (until then the purview of the colonial assembly, and a means by which it controlled the governor). The furor over the affair contributed to Hutchinson's recall, and brought a conciliatory Benjamin Franklin firmly to the side of the colonists.
On December 16, 1773 a group of men, led by Samuel Adams and dressed to evoke American Indians, boarded the ships of the government-favored British East India Company and dumped an estimated £10,000 worth of tea from its holds (approximately £636,000 in 2008) into Boston Harbor. This event became known as the Boston Tea Party and remains a significant part of American patriotic lore.
1774–1775: Quebec Act and the Intolerable Acts.
The Quebec Act of 1774 extended Quebec's boundaries to the Ohio River, shutting out the claims of the 13 colonies. By then, however, the Americans had little regard for new laws from London; they were drilling militia and organizing for war.
The British government responded by passing several Acts which came to be known as the Intolerable Acts, which further darkened colonial opinion towards the British. They consisted of four laws enacted by the British parliament. The first was the Massachusetts Government Act, which altered the Massachusetts charter and restricted town meetings. The second Act, the Administration of Justice Act, ordered that all British soldiers to be tried were to be arraigned in Britain, not in the colonies. 
The third Act was the Boston Port Act, which closed the port of Boston until the British had been compensated for the tea lost in the Boston Tea Party (the British never received such a payment). The fourth Act was the Quartering Acts of 1774, which allowed royal governors to house British troops in the homes of citizens without requiring permission of the owner.
Lord North argued in 1775 for the British position that Englishmen paid on average 25 shillings annually in taxes whereas Americans paid only sixpence. The colonists countered that North's argument failed to take into consideration the taxes collected by colonial governments and allocated for local purposes. The colonists believed, especially considering the economic restraints the British were keen to enforce in the colonies, that any additional tax burden from London was excessive.
American political opposition.
American political opposition was initially through the colonial assemblies such as the Stamp Act Congress, which included representatives from across the colonies. In 1765 the Sons of Liberty were formed which used public demonstrations, violence and threats of violence to ensure that the British tax laws were unenforceable. While openly hostile to what they considered an oppressive Parliament acting illegally, colonists persisted in sending numerous petitions and pleas for intervention from a monarch to whom they still claimed loyalty. In late 1772 Samuel Adams in Boston set about creating new Committees of Correspondence, which linked Patriots in all 13 colonies and eventually provided the framework for a rebel government. In early 1773 Virginia, the largest colony, set up its Committee of Correspondence, on which Patrick Henry and Thomas Jefferson served.
A total of about 7000 to 8000 Patriots served on "Committees of Correspondence" at the colonial and local levels, comprising most of the leadership in their communities—the Loyalists were excluded. The committees became the leaders of the American resistance to British actions, and largely determined the war effort at the state and local level. When the First Continental Congress decided to boycott British products, the colonial and local Committees took charge, examining merchant records and publishing the names of merchants who attempted to defy the boycott by importing British goods.
They promoted patriotism and home manufacturing, advising Americans to avoid luxuries and lead more simple lives. The committees gradually extended their power over many aspects of American public life. They set up espionage networks to identify disloyal elements, displaced the royal officials, and helped topple the entire imperial system in each colony. In late 1774 in early 1775, they supervised the elections of provincial conventions, which took over the operation of colonial governments.
In response to the "Massachusetts Government Act", Massachusetts and other colonies formed local governments called Provincial Congresses. In 1774, the "First Continental Congress" convened, consisting of representatives from each of the Provincial Congresses or their equivalents, to serve as a vehicle for deliberation and collective action. Standing "Committees of Safety" were created by each Provincial Congress or equivalent for the enforcement of resolutions by the Committees of Correspondence, Provincial Congress, and the Continental Congress. Some British colonies in North America remained loyal to the Crown. These colonies included Quebec, Nova Scotia, Newfoundland in present-day Canada, the former Spanish colonies of West Florida and East Florida, and Bermuda.
Factions.
The population of the 13 Colonies was far from homogeneous, particularly in their political views and attitudes. Loyalties and allegiances varied widely not only within regions and communities, but also within families and sometimes shifted during the course of the Revolution.
King George III.
The war became a personal issue for the king, fueled by his growing belief that British leniency would be taken as weakness by the Americans. The king also sincerely believed he was defending Britain's constitution against usurpers, rather than opposing patriots fighting for their natural rights.
Patriots.
At the time, revolutionaries were called "Patriots", "Whigs", "Congress-men", or "Americans". They included a full range of social and economic classes, but were unanimous regarding the need to defend the rights of Americans and uphold the principles of republicanism in terms of rejecting monarchy and aristocracy, while emphasizing civic virtue on the part of the citizens.
Role of women.
Women contributed to the American Revolution in many ways, and were involved on both sides. While formal Revolutionary politics did not include women, ordinary domestic behaviors became charged with political significance as Patriot women confronted a war that permeated all aspects of political, civil, and domestic life. They participated by boycotting British goods, spying on the British, following armies as they marched, washing, cooking, and tending for soldiers, delivering secret messages, and in a few cases like Deborah Samson, fighting disguised as men. Above all, they continued the agricultural work at home to feed their families and the armies. They maintained their families during their husbands' absences and sometimes after their deaths.
American women were integral to the success of the boycott of British goods, as the boycotted items were largely household items such as tea and cloth. Women had to return to knitting goods, and to spinning and weaving their own cloth — skills that had fallen into disuse. In 1769, the women of Boston produced 40,000 skeins of yarn, and 180 women in Middletown, Massachusetts wove of cloth.
A crisis of political loyalties could disrupt the fabric of colonial America women’s social worlds: whether a man did or did not renounce his allegiance to the King could dissolve ties of class, family, and friendship, isolating women from former connections. A woman’s loyalty to her husband, once a private commitment, could become a political act, especially for women in America committed to men who remained loyal to the King. Legal divorce, usually rare, was granted to Patriot women whose husbands supported the King.
Class and psychology.
In terms of class, Loyalists tended to have longstanding social and economic connections to British merchants and government; for instance, prominent merchants in major port cities such as New York, Boston and Charleston tended to be Loyalists, as did men involved with the fur trade along the northern frontier. In addition, officials of colonial government and their staffs, those who had established positions and status to maintain, favored maintaining relations with Great Britain. They often were linked to British families in England by marriage as well.
By contrast, Patriots by number tended to be yeomen farmers, especially in the frontier areas of New York and the backcountry of Pennsylvania, Virginia and down the Appalachian mountains. They were craftsmen and small merchants. Leaders of both the Patriots and the Loyalists were men of educated, propertied classes. The Patriots included many prominent men of the planter class from Virginia and South Carolina, for instance, who became leaders during the Revolution, and formed the new government at the national and state levels.
To understand the opposing groups, historians have assessed evidence of their hearts and minds. In the mid-20th century, historian Leonard Woods Labaree identified eight characteristics of the Loyalists that made them essentially conservative; traits to those characteristic of the Patriots. Older and better established men, Loyalists tended to resist innovation. They thought resistance to the Crown—which they insisted was the only legitimate government—was morally wrong, while the Patriots thought morality was on their side.
Loyalists were alienated when the Patriots resorted to violence, such as burning houses and tarring and feathering. Loyalists wanted to take a centrist position and resisted the Patriots' demand to declare their opposition to the Crown. Many Loyalists, especially merchants in the port cities, had maintained strong and long-standing relations with Britain (often with business and family links to other parts of the British Empire).
Many Loyalists realized that independence was bound to come eventually, but they were fearful that revolution might lead to anarchy, tyranny or mob rule. In contrast, the prevailing attitude among Patriots, who made systematic efforts to use mob violence in a controlled manner, was a desire to seize the initiative. Labaree also wrote that Loyalists were pessimists who lacked the confidence in the future displayed by the Patriots.
Historians in the early 20th century, such as J. Franklin Jameson, examined the class composition of the Patriot cause, looking for evidence of a class war inside the revolution. In the last 50 years, historians have largely abandoned that interpretation, emphasizing instead the high level of ideological unity. Just as there were rich and poor Loyalists, the Patriots were a 'mixed lot', with the richer and better educated more likely to become officers in the Army.
Ideological demands always came first: the Patriots viewed independence as a means to gain freedom from British oppression and taxation and, above all, to reassert what they considered to be their rights as English subjects. Most yeomen farmers, craftsmen, and small merchants joined the Patriot cause to demand more political equality. They were especially successful in the Pennsylvania but less so in New England, where John Adams attacked Thomas Paine's "Common Sense" for the "absurd democratical notions" it proposed.
Loyalists.
While there is no way of knowing the numbers, historians have estimated that about 15–20% of the population remained loyal to the British Crown; these were known at the time as "Loyalists", "Tories", or "King's men". The Loyalists never controlled territory unless the British Army occupied it. Loyalists were typically older, less willing to break with old loyalties, often connected to the Church of England, and included many established merchants with strong business connections across the Empire, as well as royal officials such as Thomas Hutchinson of Boston.
The revolution sometimes divided families; for example, the Franklins. William Franklin, son of Benjamin Franklin and governor of the Province of New Jersey, remained Loyal to the Crown throughout the war; he never spoke to his father again. Recent immigrants who had not been fully Americanized were also inclined to support the King, such as recent Scottish settlers in the back country; among the more striking examples of this, see Flora MacDonald.
After the war, the great majority of the 450,000–500,000 Loyalists remained in America and resumed normal lives. Some, such as Samuel Seabury, became prominent American leaders. Estimates vary, but about 62,000 Loyalists relocated to Canada, and others to Britain (7,000) or to Florida or the West Indies (9,000). The exiles represented approximately 2% of the total population of the colonies. 
When Loyalists left the South in 1783, they took thousands of their slaves with them to the British West Indies. Before that, tens of thousands of slaves had escaped, disrupting agriculture particularly in South Carolina and Georgia. The British freed slaves of rebels who joined them.
Neutrals.
A minority of uncertain size tried to stay neutral in the war. Most kept a low profile, but the Quakers, especially in Pennsylvania, were the most important group to speak out for neutrality. As Patriots declared independence, the Quakers, who continued to do business with the British, were attacked as supporters of British rule, "contrivers and authors of seditious publications" critical of the revolutionary cause.
Other participants.
France.
In early 1776, France set up a major program of aid to the Americans, and the Spanish secretly added funds. Each country spent one million "livres tournaises" to buy munitions. A dummy corporation run by Pierre Beaumarchais concealed their activities. American rebels obtained some munitions through the Dutch Republic as well as French and Spanish ports in the West Indies.
Spain.
Spain did not officially recognize the U.S. but became an informal ally when it declared war on Britain on June 21, 1779. Bernardo de Gálvez y Madrid, general of the Spanish forces in New Spain, also served as governor of Louisiana. He led an expedition of colonial troops to force the British out of Florida and keep open a vital conduit for supplies.
Native Americans.
Most Native Americans rejected pleas that they remain neutral and supported the British Crown, both because of trading relationships and its efforts to prohibit colonial settlement west of the Appalachian Mountains. The great majority of the 200,000 Native Americans east of the Mississippi distrusted the colonists and supported the British cause, hoping to forestall continued colonial encroachment on their territories. Those tribes that were more closely involved in colonial trade tended to side with the revolutionaries, although political factors were important as well.
Although there was limited participation by Native American warriors except for those associated with four of the Iroquois nations in New York and Pennsylvania, the British provided Indians with funding and weapons to attack American outposts. Some Indians tried to remain neutral, seeing little value in joining a European conflict and fearing reprisals from whichever side they opposed. The Oneida and Tuscarora peoples of western New York supported the American cause.
The British provided arms to Indians, who were led by Loyalists in war parties to raid frontier settlements from the Carolinas to New York. They killed many scattered settlers, especially in Pennsylvania. In 1776 Cherokee war parties attacked American colonists all along the southern frontier of the uplands. While the Chickamauga Cherokee could launch raids numbering a couple hundred warriors, as seen in the Chickamauga Wars, they could not mobilize enough forces to fight a major invasion without the help of allies, most often the Creek.
Joseph Brant of the powerful Mohawk nation, part of the Iroquois Confederacy based in New York, was the most prominent Native American leader against the rebel forces. In 1778 and 1780, he led 300 Iroquois warriors and 100 white Loyalists in multiple attacks on small frontier settlements in New York and Pennsylvania, killing many settlers and destroying villages, crops and stores. The Seneca, Onondaga and Cayuga of the Iroquois Confederacy also allied with the British against the Americans.
In 1779 the Continentals retaliated with an American army under John Sullivan, which raided and destroyed 40 empty Iroquois villages in central and western New York. Sullivan's forces systematically burned the villages and destroyed about 160,000 bushels of corn that comprised the winter food supply. Facing starvation and homeless for the winter, the Iroquois fled to the Niagara Falls area and to Canada, mostly to what became Ontario. The British resettled them there after the war, providing land grants as compensation for some of their losses.
The British did not give up their forts in the West (what is now the Ohio to Wisconsin) until 1796; they kept alive the dream of forming a satellite Indian nation there, which they called a Neutral Indian Zone. That goal was one of the causes of the War of 1812.
African Americans.
Free blacks in the North and South fought on both sides of the Revolution, but most fought for the colonial rebels. Crispus Attucks, who died in a conflict in Boston in 1770, is considered the first martyr of the American Revolution. Both sides offered freedom and re-settlement to slaves who were willing to fight for them, especially targeting slaves whose owners supported the opposing cause.
Many African-American slaves became politically active during these years in support of the King, as they thought Great Britain might abolish slavery in the colonies. Tens of thousands used the turmoil of war to escape, and the southern plantation economies of South Carolina and Georgia especially were disrupted. During the Revolution, the British tried to turn slavery against the Americans, but historian David Brion Davis explains the difficulties with a policy of wholesale arming of the slaves: 
Davis underscored the British dilemma: "Britain, when confronted by the rebellious American colonists, hoped to exploit their fear of slave revolts while also reassuring the large number of slave-holding Loyalists and wealthy Caribbean planters and merchants that their slave property would be secure". The colonists accused the British of encouraging slave revolts.
American advocates of independence were commonly lampooned in Britain for what was termed their hypocritical calls for freedom, at the same time that many of their leaders were planters who held hundreds of slaves. Samuel Johnson snapped, "how is it we hear the loudest yelps for liberty among the drivers of the Negroes?" Benjamin Franklin countered by criticizing the British self-congratulation about "the freeing of one Negro" (Somersett) while they continued to permit the Slave Trade.
Phyllis Wheatley, a black poet who popularized the image of Columbia to represent America, came to public attention when her "Poems on Various Subjects, Religious and Moral" appeared in 1773.
During the war, slaves escaped from across New England and the mid-Atlantic area to British-occupied cities, such as New York. The effects of the war were more dramatic in the South. In Virginia the royal governor Lord Dunmore recruited black men into the British forces with the promise of freedom, protection for their families, and land grants. Tens of thousands of slaves escaped to British lines throughout the South, causing dramatic losses to slaveholders and disrupting cultivation and harvesting of crops. For instance, South Carolina was estimated to lose about 25,000 slaves, or one third of its slave population, to flight, migration or death. From 1770–1790, the black proportion of the population (mostly slaves) in South Carolina dropped from 60.5 percent to 43.8 percent; and in Georgia from 45.2 percent to 36.1 percent.
When the British evacuated its forces from Savannah and Charleston, it also gave transportation to 10,000 slaves, carrying through on its commitment to them. They evacuated and resettled more than 3,000 "Black Loyalists" from New York to Nova Scotia, Upper and Lower Canada. Others sailed with the British to England or were resettled in the West Indies of the Caribbean. More than 1200 of the Black Loyalists of Nova Scotia later resettled in the British colony of Sierra Leone, where they became leaders of the Krio ethnic group of Freetown and the later national government. Many of their descendants still live in Sierra Leone, as well as other African countries.
Some slaves understood Revolutionary rhetoric as promising freedom and equality. Both British and American governments made promises of freedom for service, and many slaves fought in one or the other armies. Starting in 1777, northern states started to abolish slavery, beginning with Vermont, which ended it under its new state constitution. By court cases, Massachusetts effectively ended slavery before the end of the century. Usually states instituted abolition on a gradual schedule with no government compensation of the owners, and many states, such as New York, New Jersey and Connecticut, required long apprenticeships of former slave children before they gained freedom and came of age as adults.
In the first two decades after the war, the legislatures of Virginia, Maryland and Delaware made it easier for slaveholders to manumit their slaves. Numerous slaveholders in the Upper South took advantage of the changes: the proportion of free blacks went from less than one percent before the war to more than 10 percent overall by 1810. In Virginia alone, the number of free blacks climbed: from less than one percent in 1782, to 4.2 percent in 1790, and 13.5 percent in 1810. In Delaware, three-quarters of blacks were free by 1810. 
After this time, few slaves were freed in the South, except those who were favorites or the master's children. The demand for slaves rose with the growth of cotton as a commodity crop, especially after the invention of the cotton gin, which enabled the widespread cultivation of short-staple cotton in the upland regions. Although the international slave trade was prohibited, the slave population in the United States increased by the formation of families and survival of children throughout the South. As the demand for slave labor in the Upper South decreased due to changes in crops, planters began selling their slaves to traders and markets to the Deep South in an internal slave trade; it would cause the forced migration of an estimated one million slaves during the following decades, breaking up countless families, as young males were most in demand.
Military hostilities begin.
The Battle of Lexington and Concord took place April 19, 1775, when the British sent a force of roughly 1000 troops to confiscate arms and arrest revolutionaries in Concord, Massachusetts. They clashed with the local militia, marking the first fighting of the American Revolutionary War. The news aroused the 13 colonies to call out their militias and send troops to besiege Boston. The Battle of Bunker Hill followed on June 17, 1775. While a British victory, it was at a great cost; about 1,000 British casualties from a garrison of about 6,000, as compared to 500 American casualties from a much larger force.
The Second Continental Congress convened in 1775, after the war had started. The Congress created the Continental Army and extended the Olive Branch Petition to the crown as an attempt at reconciliation. King George III refused to receive it, issuing instead the Proclamation of Rebellion, requiring action against the "traitors".
In the winter of 1775, the Americans invaded Canada. General Richard Montgomery captured Montreal but a joint attack on Quebec with the help of Benedict Arnold failed.
In March 1776, with George Washington as the commander of the new army, the Continental Army forced the British to evacuate Boston. The revolutionaries were now in full control of all 13 colonies and were ready to declare independence. While there still were many Loyalists, they were no longer in control anywhere by July 1776, and all of the Royal officials had fled.
Prisoners.
In August 1775, George III declared Americans in arms against royal authority to be traitors to the Crown. Although Lord Germain took a hard line the British generals on the scene never held treason trials; they treated captured soldiers as prisoners of war. The dilemma was that tens of thousands of Loyalists were under American control and American retaliation would have been easy. The British built much of their strategy around using these Loyalists.
After the surrender at Saratoga in October 1777, furthermore, there were thousands of British and Hessian soldiers in American hands. Therefore no Americans were put on trial for treason. The British maltreated the prisoners they held, resulting in more deaths to American sailors and soldiers than combat operations. At the end of the war, both sides released their surviving prisoners.
Finance.
Britain's war against the Americans, French and Spanish cost about £100 million. The Treasury borrowed 40% of the money it needed. Heavy spending brought France to the verge of bankruptcy and revolution, while the British had relatively little difficulty financing their war, keeping their suppliers and soldiers paid, and hiring tens of thousands of German soldiers.
Britain had a sophisticated financial system based on the wealth of thousands of landowners, who supported the government, together with banks and financiers in London. The efficient British tax system collected about 12 percent of the GDP in taxes during the 1770s.
In sharp contrast, Congress and the American states had no end of difficulty financing the war. In 1775 there was at most 12 million dollars in gold in the colonies, not nearly enough to cover current transactions, let alone on a major war. The British made the situation much worse by imposing a tight blockade on every American port, which cut off almost all imports and exports. One partial solution was to rely on volunteer support from militiamen, and donations from patriotic citizens.
Another was to delay actual payments, pay soldiers and suppliers in depreciated currency, and promise it would be made good after the war. Indeed, in 1783 the soldiers and officers were given land grants to cover the wages they had earned but had not been paid during the war. Not until 1781, when Robert Morris was named Superintendent of Finance of the United States, did the national government have a strong leader in financial matters.
Morris used a French loan in 1782 to set up the private Bank of North America to finance the war. Seeking greater efficiency, Morris reduced the civil list, saved money by using competitive bidding for contracts, tightened accounting procedures, and demanded the national government's full share of money and supplies from the confederated states.
Congress used four main methods to cover the cost of the war, which cost about 66 million dollars in specie (gold and silver). Congress made two issues of paper money, in 1775–1780, and in 1780–81. The first issue amounted to 242 million dollars. This paper money would supposedly be redeemed for state taxes, but the holders were eventually paid off in 1791 at the rate of one cent on the dollar. By 1780, the paper money was "not worth a Continental", as people said, and a second issue of new currency was attempted. 
The second issue quickly became nearly worthless—but it was redeemed by the new federal government in 1791 at 100 cents on the dollar. At the same time the states, especially Virginia and the Carolinas, issued over 200 million dollars of their own currency. In effect, the paper money was a hidden tax on the people, and indeed was the only method of taxation that was possible at the time. 
The skyrocketing inflation was a hardship on the few people who had fixed incomes—but 90 percent of the people were farmers, and were not directly affected by that inflation. Debtors benefited by paying off their debts with depreciated paper. The greatest burden was borne by the soldiers of the Continental Army, whose wages—usually in arrears—declined in value every month, weakening their morale and adding to the hardships suffered by their families.
Beginning in 1777, Congress repeatedly asked the states to provide money. But the states had no system of taxation either, and were little help. By 1780 Congress was making requisitions for specific supplies of corn, beef, pork and other necessities—an inefficient system that kept the army barely alive.
Starting in 1776, the Congress sought to raise money by loans from wealthy individuals, promising to redeem the bonds after the war. The bonds were in fact redeemed in 1791 at face value, but the scheme raised little money because Americans had little specie, and many of the rich merchants were supporters of the Crown. Starting in 1776, the French secretly supplied the Americans with money, gunpowder, and munitions in order to weaken its arch enemy, Great Britain. When France officially entered the war in 1778, the subsidies continued, and the French government, as well as bankers in Paris and Amsterdam loaned large sums to the American war effort. These loans were repaid in full in the 1790s.
Creating new state constitutions.
Following the Battle of Bunker Hill in June 1775, the Patriots had control of most of Massachusetts; the Loyalists suddenly found themselves on the defensive. In all 13 colonies, Patriots had overthrown their existing governments, closing courts and driving British governors, agents and supporters from their homes. They had elected conventions and "legislatures" that existed outside of any legal framework; new constitutions were used in each state to supersede royal charters. They declared they were states now, not colonies.
On January 5, 1776, New Hampshire ratified the first state constitution, six months before the signing of the Declaration of Independence. Then, in May 1776, Congress voted to suppress all forms of crown authority, to be replaced by locally created authority. Virginia, South Carolina, and New Jersey created their constitutions before July 4. Rhode Island and Connecticut simply took their existing royal charters and deleted all references to the crown.
In states where the less affluent had organized sufficiently to have significant power—especially Pennsylvania, New Jersey, and New Hampshire—the resulting constitutions embodied
Whether conservatives or radicals held sway in a state did not mean that the side with less power accepted the result quietly. The radical provisions of Pennsylvania's constitution lasted only 14 years. In 1790, conservatives gained power in the state legislature, called a new constitutional convention, and rewrote the constitution. The new constitution substantially reduced universal white-male suffrage, gave the governor veto power and patronage appointment authority, and added an upper house with substantial wealth qualifications to the unicameral legislature. Thomas Paine called it a constitution unworthy of America.
Independence and Union.
In April the North Carolina Provincial Congress issued the Halifax Resolves, explicitly authorizing its delegates to vote for independence. In May Congress called on all the states to write constitutions, and eliminate the last remnants of royal rule.
By June nine colonies were ready for independence; one by one the last four —Pennsylvania, Delaware, Maryland and New York — fell into line. Richard Henry Lee was instructed by the Virginia legislature to propose independence, and he did so on June 7, 1776. On the 11th a committee was created to draft a document explaining the justifications for separation from Britain. After securing enough votes for passage, independence was voted for on July 2. The Declaration of Independence, drafted largely by Thomas Jefferson and presented by the committee, was slightly revised and unanimously adopted by the entire Congress on July 4, marking the formation of a new sovereign nation, which called itself the United States of America.
The Second Continental Congress approved a new constitution, the "Articles of Confederation," for ratification by the states on November 15, 1777, and immediately began operating under their terms. The Articles were formally ratified on March 1, 1781. At that point, the Continental Congress was dissolved and on the following day a new government of the United States in Congress Assembled took its place, with Samuel Huntington as presiding officer.
Defending the Revolution.
British return: 1776–1777.
After Washington forced the British out of Boston in spring 1776, neither the British nor the Loyalists controlled any significant areas. The British, however, were massing forces at their naval base at Halifax, Nova Scotia. They returned in force in July 1776, landing in New York and defeating Washington's Continental Army at the Battle of Brooklyn in August, one of the largest engagements of the war. After the Battle of Brooklyn, the British requested a meeting with representatives from Congress to negotiate an end to hostilities. 
A delegation including John Adams and Benjamin Franklin met Howe on Staten Island in New York Harbor on September 11, in what became known as the Staten Island Peace Conference. Howe demanded a retraction of the Declaration of Independence, which was refused, and negotiations ended until 1781. The British then quickly seized New York City and nearly captured General Washington. They made the city their main political and military base of operations in North America, holding it until November 1783. New York City consequently became the destination for Loyalist refugees, and a focal point of Washington's intelligence network. 
The British also took New Jersey, pushing the Continental Army into Pennsylvania. In a surprise attack in late December 1776 Washington crossed the Delaware River back into New Jersey and defeated Hessian and British armies at Trenton and Princeton, thereby regaining New Jersey. The victories gave an important boost to pro-independence supporters at a time when morale was flagging, and have become iconic events of the war.
In 1777, as part of a grand strategy to end the war, the British sent an invasion force from Canada to seal off New England, which the British perceived as the primary source of agitators. In a major case of mis-coordination, the British army in New York City went to Philadelphia which it captured from Washington. The invasion army under Burgoyne waited in vain for reinforcements from New York, and became trapped in northern New York state. It surrendered after the Battle of Saratoga in October 1777. From early October 1777 until November 15 a pivotal siege at Fort Mifflin, Philadelphia, Pennsylvania distracted British troops and allowed Washington time to preserve the Continental Army by safely leading his troops to harsh winter quarters at Valley Forge.
American alliances after 1778.
The capture of a British army at Saratoga encouraged the French to formally enter the war in support of Congress, as Benjamin Franklin negotiated a permanent military alliance in early 1778, significantly becoming the first country to officially recognize the Declaration of Independence. On February 6, 1778, a Treaty of Amity and Commerce and a Treaty of Alliance were signed between the United States and France. William Pitt spoke out in parliament urging Britain to make peace in America, and unite with America against France, while other British politicians who had previously sympathised with colonial grievances now turned against the American rebels for allying with British international rival and enemy.
Later Spain (in 1779) and the Dutch (1780) became allies of the French, leaving the British Empire to fight a global war alone without major allies, and requiring it to slip through a combined blockade of the Atlantic. The American theater thus became only one front in Britain's war. The British were forced to withdraw troops from continental America to reinforce the valuable sugar-producing Caribbean colonies, which were considered more important.
Because of the alliance with France and the deteriorating military situation, Sir Henry Clinton, the British commander, evacuated Philadelphia to reinforce New York City. General Washington attempted to intercept the retreating column, resulting in the Battle of Monmouth Court House, the last major battle fought in the north. After an inconclusive engagement, the British successfully retreated to New York City. The northern war subsequently became a stalemate, as the focus of attention shifted to the smaller southern theater.
The British move South, 1778–1783.
The British strategy in America now concentrated on a campaign in the southern colonies. With fewer regular troops at their disposal, the British commanders saw the "southern strategy" as a more viable plan, as the south was perceived as being more strongly Loyalist, with a large population of recent immigrants as well as large numbers of slaves who might be captured or run away to join the British.
Beginning in late December 1778, the British captured Savannah and controlled the Georgia coastline. In 1780 they launched a fresh invasion and took Charleston as well. A significant victory at the Battle of Camden meant that royal forces soon controlled most of Georgia and South Carolina. The British set up a network of forts inland, hoping the Loyalists would rally to the flag.
Not enough Loyalists turned out, however, and the British had to fight their way north into North Carolina and Virginia, with a severely weakened army. Behind them much of the territory they had already captured dissolved into a chaotic guerrilla war, fought predominantly between bands of Loyalist and American militia, which negated many of the gains the British had previously made.
Yorktown 1781.
The British army under Cornwallis marched to Yorktown, Virginia where they expected to be rescued by a British fleet. The fleet showed up but so did a larger French fleet, so the British fleet after the Battle of the Chesapeake returned to New York for reinforcements, leaving Cornwallis trapped. In October 1781 under a combined siege by the French and Continental armies under Washington, the British surrendered their second invading army of the war.
The war winds down.
Support for the conflict had never been strong in Britain, where many sympathized with the rebels, but now it reached a new low. Although King George III personally wanted to fight on, his supporters lost control of Parliament, and no further major land offensives were launched in the American Theater.
Washington could not know that after Yorktown the British would not reopen hostilities. They still had 26,000 troops occupying New York City, Charleston and Savannah, together with a powerful fleet. The French army and navy departed, so the Americans were on their own in 1782–83. The treasury was empty, and the unpaid soldiers were growing restive, almost to the point of mutiny or possible "coup d'état". The unrest among officers of the Newburgh Conspiracy was personally dispelled by Washington in 1783, and Congress subsequently created the promise of a five years bonus for all officers.
Peace treaty.
The peace treaty with Britain, known as the Treaty of Paris, gave the U.S. all land east of the Mississippi River and south of the Great Lakes, though not including Florida (On September 3, 1783, Britain entered into a separate agreement with Spain under which Britain ceded Florida back to Spain.) The British abandoned the Indian allies living in this region; they were not a party to this treaty and did not recognize it until they were defeated militarily by the United States. Issues regarding boundaries and debts were not resolved until the Jay Treaty of 1795. Since the blockade was lifted and the old imperial restrictions were gone, American merchants were free to trade with any nation anywhere in the world, and their businesses flourished.
Impact on Britain.
Losing the war and the 13 colonies was a shock to Britain. The war revealed the limitations of Britain's fiscal-military state when it discovered it suddenly faced powerful enemies, with no allies, and dependent on extended and vulnerable transatlantic lines of communication. The defeat heightened dissension and escalated political antagonism to the King's ministers. Inside parliament, the primary concern changed from fears of an over-mighty monarch to the issues of representation, parliamentary reform, and government retrenchment. Reformers sought to destroy what they saw as widespread institutional corruption.
The result was a powerful crisis, 1776–1783. The peace in 1783 left France financially prostrate, while the British economy boomed thanks to the return of American business. The crisis ended after 1784 thanks to the King's shrewdness in outwitting Charles James Fox (the leader of the Fox-North Coalition), and renewed confidence in the system engendered by the leadership of the new Prime Minister, William Pitt. Historians conclude that loss of the American colonies enabled Britain to deal with the French Revolution with more unity and better organization than would otherwise have been the case.
Concluding the Revolution.
Creating a "more perfect union" and guaranteeing rights.
After the war finally ended in 1783, there was a period of prosperity, with the entire world at peace. The national government, still operating under the Articles of Confederation, was able to settle the issue of the western territories, which were ceded by the states to Congress. American settlers moved rapidly into those areas, with Vermont, Kentucky and Tennessee becoming states in the 1790s. 
However, the national government had no money to pay either the war debts owed to European nations and the private banks, or to pay Americans who had been given millions of dollars of promissory notes for supplies during the war. Nationalists, led by Washington, Alexander Hamilton and other veterans, feared that the new nation was too fragile to withstand an international war, or even internal revolts such as the Shays' Rebellion of 1786 in Massachusetts.
Calling themselves "Federalists," the nationalists convinced Congress to call the Philadelphia Convention in 1787. It adopted a new Constitution that provided for a much stronger federal government, including an effective executive in a check-and-balance system with the judiciary and legislature. After a fierce debate in the states over the nature of the proposed new government, the Constitution was ratified in 1788. The new government under President George Washington took office in New York in March 1789. As assurances to those who were cautious about federal power, amendments to the Constitution guaranteeing many of the inalienable rights that formed a foundation for the revolution were spearheaded in Congress by James Madison, and later ratified by the states in 1791.
National debt.
The national debt after the American Revolution fell into three categories. The first was the $12 million owed to foreigners—mostly money borrowed from France. There was general agreement to pay the foreign debts at full value. The national government owed $40 million and state governments owed $25 million to Americans who had sold food, horses, and supplies to the revolutionary forces. There were also other debts that consisted of promissory notes issued during the Revolutionary War to soldiers, merchants, and farmers who accepted these payments on the premise that the new Constitution would create a government that would pay these debts eventually.
The war expenses of the individual states added up to $114 million compared to $37 million by the central government. In 1790, at the recommendation of first Secretary of the Treasury Alexander Hamilton, Congress combined the remaining state debts with the foreign and domestic debts into one national debt totaling $80 million. Everyone received face value for wartime certificates, so that the national honor would be sustained and the national credit established.
Impressions the Revolution made.
Loyalist expatriation.
About 60,000 to 70,000 Loyalists left the newly founded republic; some left for Britain and the remainder, called United Empire Loyalists received British subsidies to resettle in British colonies in North America, especially Quebec (concentrating in the Eastern Townships), Prince Edward Island, and Nova Scotia. The new colonies of Upper Canada (now Ontario) and New Brunswick were created by Britain for their benefit. However, about 80% of the Loyalists stayed and became loyal citizens of the United States, and some of the exiles later returned to the U.S.
Interpretations.
Interpretations about the effect of the Revolution vary. Though contemporary participants referred to the events as "the revolution", at one end of the spectrum is the view that the American Revolution was not "revolutionary" at all, contending that it did not radically transform colonial society but simply replaced a distant government with a local one. More recent scholarship pioneered by historians such as Bernard Bailyn, Gordon Wood, and Edmund Morgan accepts the contemporary view of the participants that the American Revolution was a unique and radical event that produced deep changes and had a profound impact on world affairs, based on an increasing belief in the principles of the Enlightenment as reflected in how liberalism was understood during the period, and republicanism. These were demonstrated by a leadership and government that espoused protection of natural rights, and a system of laws chosen by the people.
As an example or inspiration.
After the Revolution, genuinely democratic politics became possible. The rights of the people were incorporated into state constitutions. Thus came the widespread assertion of liberty, individual rights, equality and hostility toward corruption which would prove core values of liberal republicanism to Americans. The greatest challenge to the old order in Europe was the challenge to inherited political power and the democratic idea that government rests on the consent of the governed. The example of the first successful revolution against a European empire, and the first successful establishment of a republican form of democratically elected government, provided a model for many other colonial peoples who realized that they too could break away and become self-governing nations with directly elected representative government.
The Dutch Republic, also at war with Britain at that time, was the next country after France to sign a treaty with the United States, on October 8, 1782. On April 3, 1783, Ambassador Extraordinary Gustaf Philip Creutz, representing King Gustav III of Sweden, and Benjamin Franklin, Minister Plenipotentiary of the United States of America, signed a Treaty of Amity and Commerce with the U.S.
The American Revolution was the first wave of the Atlantic Revolutions that took hold in the French Revolution, the Haitian Revolution, and the Latin American wars of independence. Aftershocks reached Ireland in the Irish Rebellion of 1798, in the Polish-Lithuanian Commonwealth, and in the Netherlands.
The Revolution had a strong, immediate impact in Great Britain, Ireland, the Netherlands, and France. Many British and Irish Whigs spoke in favor of the American cause. The Revolution, along with the Dutch Revolt (end of the 16th century) and the English Civil War (in the 17th century), was one of the first lessons in overthrowing an old regime for many Europeans who later were active during the era of the French Revolution, such as Marquis de Lafayette. The American Declaration of Independence had some impact on the French Declaration of the Rights of Man and the Citizen of 1789.
The spirit of the Declaration of Independence led to laws ending slavery in all the Northern states and the Northwest Territory, with New Jersey the last in 1804—long before the British Parliament acted in 1833 to abolish slavery in its colonies.

Nordic race
The Nordic race was one of the three sub-races into which the Caucasian race was divided by anthropologists using scientific racism in the first half of the 20th century. (The three sub-types being Nordic, Alpine and Mediterranean.) People of the Nordic type were described as having blond or brown hair, light colored eyes, fair skin and tall stature, and were considered to predominate in countries of Central and Northern Europe. The notion is today considered ideological rather than scientific by most.
Nordicism (also "Nordic theory") is an ideology of racial supremacy that claims that a Nordic race, within the greater Caucasian race, constituted a "master race".
This ideology was popular in the late-19th and early 20th centuries in some Central and Northern European countries as well as North America, and achieved mainstream success throughout Germany via National Socialism during the Third Reich.
Background ideas.
Attitudes in ancient Europe.
Most ancient writers were from the Southern European civilisations, and generally took the view that people living in the north of their lands were barbarians. Pale skin and light hair were described as signs of barbarism by Polemon of Laodicea in his book "Physiognomica". Pseudo-Aristotle noted differences between Greeks and the people of the north, believing that Greek superiority was visible in their medium skin tone, as opposed to pale northerners and dark southerners and Africans. Aristotle himself claimed that blue eyes had less liquid in them than darker eyes, and that they indicated poor eyesight, especially in daylight.
Despite this, Aphrodite was often depicted with blonde hair, as were deities associated with the sun.
Likewise, the Roman historian Tacitus idealized the Germanic tribes (which he considered autochthonous to their land) for qualities such as superior warlike ardor and chastity, in contrast to the Romans of his day - though his portrait is not unmixed - as he also portrays them as incurably lazy and addicted to gambling.
Many Romans believed that fair features were beautiful. Wealthy Romans paid for blond and red wigs made from the hair of captured Germanics or Celts.
Renaissance.
During the Renaissance, blonde hair, blue eyes, and pale skin were regularly portrayed in literature as signs of beauty and were associated with noble moral qualities. This imagery was largely aesthetic. It was not typically theorised in terms of racial difference, drawing instead on traditional symbolism of light as opposed to darkness.
Enlightenment.
From the 17th century onwards, as Central and Northern European countries became more powerful, and their people began to adapt such aesthetic traditions into arguments for their own superiority. Benjamin Franklin proposed a clear distinction between ""white"" Europeans and ""swarthy"" Europeans, stating that immigration to the newly-born United States should favour the ""white"" Saxons and Englishmen rather than the ""swarthy"", Germans (except the Saxons), Italians, French, Russians, Spaniards, and Swedes.
19th century racial thought.

Aryanism.
Such arguments became especially significant when allied to the theory of Aryanism in the mid-19th century. This theory held that native speakers of the Indo-European languages ("Aryans") are an innately superior branch of humanity, responsible for most of its greatest achievements.
Its principal proponent was Arthur de Gobineau in his "Essay on the Inequality of the Human Races" (1855). Though Gobineau did not equate Nordic peoples with Aryans, he argued that Germanic people were the best modern representatives of the Aryan race. Adapting the comments of Tacitus and other Roman writers, he argued that "pure" Northerners regenerated Europe after the Roman empire declined due to racial "dilution" of its leadership.
By the 1880s a number of linguists and anthropologists argued that the Aryans themselves had originated somewhere in northern Europe. Theodor Poesche proposed that the Aryans originated in the vast Rokitno, or Pinsk Marshes, then in the Russian Empire, now covering much of the southern part of Belarus and the north-west of the Ukraine, but it was Karl Penka who popularized the idea that the Aryans had emerged in Scandinavia and could be identified by the distinctive Nordic characteristics of blond hair and blue eyes.
The distinguished biologist Thomas Henry Huxley agreed with him, coining the term "Xanthochroi" to refer to fair-skinned Europeans, as opposed to darker Mediterranean peoples, whom Huxley called "Melanochroi". It was Huxley who also concluded that the Melanochroi (Peoples of the Mediterranean race), who he described as "dark whites", are of a mixture of the Xanthochroi and Australioids.
This distinction was repeated by Charles Morris in his book "The Aryan Race" (1888), which argued that the original Aryans could be identified by their blond hair and other Nordic features, such as dolichocephaly (long skull). The argument was given extra impetus by the French anthropologist Vacher de Lapouge in his book "L’Aryen", in which he argued that the "dolichocephalic-blond" peoples were natural leaders, destined to rule over more brachycephalic (short-skulled) peoples.
The philosopher Friedrich Nietzsche also referred in his writings to "blond beasts": amoral adventurers who were supposed to be the progenitors of creative cultures. In "On the Genealogy of Morals" (1887), he wrote, "In Latin malus ... could indicate the vulgar man as the dark one, especially as the black-haired one, as the pre-Aryan dweller of the Italian soil which distinguished itself most clearly through his colour from the blonds who became their masters, namely the Aryan conquering race."
Defining characteristics.
It was the Russian-born French anthropologist Joseph Deniker that initially proposed "Nordic" as a racial group. Deniker's use of "Nordique" was meant to simply translate as "Northern", and described what he called an "ethnic group" (a term that he coined).
He defined "nordique" by a set of physical characteristics: The concurrence of fair, somewhat wavy hair, light eyes, reddish skin, tall stature and a dolichocephalic skull. Of six 'Caucasian' groups Deniker accommodated four into secondary ethnic groups, all of which he considered intermediate to the Nordic: "Northwestern", "Sub-Nordic", "Vistula" and "Sub-Adriatic", respectively.
American economist William Z. Ripley purported to define scientifically a "Teutonic race" in his book "The Races of Europe" (1899). He divided Europeans into three main subcategories: Teutonic ("teutonisch"), Alpine and Mediterranean. According to Ripley the "Teutonic race" resided in Scandinavia, north Germany, Baltic states and East Prussia, north Poland, north Russia, Britain, Ireland, parts of Central and Southern Europe and was typified by "very light" hair, blue eyes, tall stature and a narrow, aquiline nose. Georges Vacher de Lapouge had called this race "Homo Europaeus". Madison Grant includes Northern Italy as an example of Nordics.
Madison Grant, in his book "The Passing of the Great Race", took up Ripley's classification. He described a "Nordic" or "Baltic" type: Madison Grant, ""The Passing of the Great Race"", Scribner's Sons, 1921, p. 167
According to Grant, the "Alpine race", shorter in stature, darker in colouring, with a rounder head, predominated in Central and Eastern Europe through to Turkey and the Eurasian steppes of Central Asia and Southern Russia. The "Mediterranean race", with dark hair and eyes, aquiline nose, swarthy complexion, moderate-to-short stature, and moderate or long skull was said to be prevalent in Southern Europe, the Middle East, and North Africa.
20th century.
By 1902 the German archaeologist Gustaf Kossinna claimed to have identified the original Aryans (Proto-Indo-Europeans) with the north German Corded Ware culture, an argument that gained in currency over the following two decades. He placed the Indo-European Urheimat in Schleswig-Holstein, arguing that they had expanded across Europe from there. By the early 20th century this theory was well established, though far from universally accepted. Sociologists were soon using the concept of a "blond race" to model the migrations of the supposedly more entrepreneurial and innovative components of European populations. As late as 1939 Carleton Coon wrote that "The Poles who came to the United States during the 19th century, and the early decades of the 20th, did not represent a cross-section of the Polish population, but a taller, blonder, longer-headed group than the Poles as a whole." The ""high brow""/""low brow"" distinction, derived from such theories, also became enshrined in language.
It was the already mentioned work of sociologist/economist William Z. Ripley which popularized the idea of three biological European races. Ripley borrowed Deniker's terminology of Nordic (he had previously used the term "Teuton"); his division of the European races relied on a variety of anthropometric measurements, but focused especially on their cephalic index and stature.
Compared to Deniker, Ripley advocated a simplified racial view and proposed a single "Teutonic" race linked to geographic areas where Nordic-like characteristics predominate, and contrasted these areas to the boundaries of two other types, "Alpine" and "Mediterranean", thus reducing the 'caucasoid branch of humanity' to three distinct groups.
By the early 20th century, Ripley's tripartite Nordic/Alpine/Mediterranean model was well established. Most nineteenth-century race-theorists like Arthur de Gobineau, Otto Ammon, Georges Vacher de Lapouge, and Houston Stewart Chamberlain preferred to speak of "Aryans," "Teutons," and "Indo-Europeans" instead of "Nordic Race". The British German racialist Houston Stewart Chamberlain considered the Nordic race to be made up of Celtic and Germanic peoples, as well as some Slavs. Chamberlain called those people "Celt-Germanic peoples", and his ideas would influence Adolf Hitler's Nazi ideology.
Only in the 1920s did a strong partiality for "Nordic" begin to reveal itself, and for a while the term was used almost interchangeably with Aryan. Later, however, "Nordic" would not be co-terminous with Aryan, Indo-European or Germanic.
For example, the later Nazi minister for Food, Richard Walther Darré, who had developed a concept of the German peasantry as Nordic race, used the term 'Aryan' to refer to the tribes of the Iranian plains.
The notion of a distinct northern European race was also rejected by several anthropologists on craniometric grounds. Rudolf Virchow attacked the claim following a study of craniometry, which gave surprising results according to contemporary scientific racist theories on the "Aryan race." During the 1885 Anthropology Congress in Karlsruhe, Virchow denounced the "Nordic mysticism," while Josef Kollmann, a collaborator of Virchow, stated that the people of Europe, be they German, Italian, English or French, belonged to a "mixture of various races," furthermore declaring that the "results of craniology" led to "struggle against any theory concerning the superiority of this or that European race".
Coon (1939).
Carleton Coon in his book of 1939 "The Races of Europe" subdivided the Nordic race into three main types, "Corded", "Danubian" and "Keltic", besides
a "Neo-Danubian" type and a variety of
Nordic types altered by Upper Palaeolithic or Alpine admixture.
"Exotic Nordics" are morphologically Nordic types that occur in places distant from the northwestern European center of Nordic concentration.
Coon takes the Nordics to be a partially depigmented branch of the greater Mediterranean racial stock. He suggests that the Nordic type emerged as a result of a mixture of "the Danubian Mediterranean strain with the later Corded element". Hence his two main Nordic types show Corded and Danubian predominance, respectively .
The third "Keltic" or "Hallstatt" type Coon takes to have emerged in the European Iron Age, in Central Europe, where it was subsequently mostly replaced, but "found a refuge in Sweden and in the eastern valleys of southern Norway."
Depigmentation theory.
Coon's (1939) theory that the Nordic race was a depigmentated variation of the greater Mediterranean racial stock was also supported by his mentor Earnest Albert Hooton who in the same year published "Twilight of Man", which notes: "The Nordic race is certainly a depigmented offshoot from the basic long-headed Mediterranean stock. It deserves separate racial classification only because its blond hair (ash or golden), its pure blue or gray eyes".
Nordicism.

Nordicists claimed that Nordics had formed upper tiers of ancient civilizations, even in the Mediterranean civilizations of antiquity, which had declined once this dominant race had been assimilated. Thus they argued that ancient evidence suggested that leading Romans like Nero, Sulla, and Cato were blond or red-haired
Some Nordicists admitted the Mediterranean race was superior to the Nordic in terms of artistic ability. However, the Nordic race was regarded as superior on the basis that, although Mediterranean peoples were culturally sophisticated, it was the Nordics who were alleged to be the innovators and conquerors, having an adventurous spirit that no other race could match.
The Alpine race was usually regarded as inferior to both the Nordic and Mediterranean races, making up the traditional peasant class of Europe while Nordics occupied the aristocracy and led the world in technology, and Mediterraneans were regarded as more imaginative.
Opponents of Nordicism rejected these arguments. The anti-Nordicist writer Giuseppe Sergi argued in his influential book "The Mediterranean Race" (1901) that there was no evidence that the upper tiers of ancient societies were Nordic, insisting that historical and anthropological evidence contradicted such claims. Sergi argued that Mediterraneans constituted "the greatest race in the world", with a creative edge absent in the Nordic race. According to him, they were the creators of all the major ancient civilizations, from Mesopotamia to Rome.
This argument was later repeated by C.G. Seligman, who wrote that "it must, I think, be recognized that the Mediterranean race has actually more achievement to its credit than any other". Even Carleton Coon insisted that among Greeks "the Nordic element is weak, as it probably has been since the days of Homer...It is my personal reaction to the living Greeks that their continuity with their ancestors of the ancient world is remarkable, rather than the opposite."
In the USA.
In the USA, the primary spokesman for Nordicism was the eugenicist Madison Grant. His 1916 book, "The Passing of the Great Race, or the Racial Basis of European History" about Nordicism was highly influential among racial thinking and government policy making.
Grant used the theory as justification for immigration policies of the 1920s, arguing that the immigrants from certain areas of Europe represented a lesser type of European and their numbers in the United States should not be increased. Grant and others urged this as well as the complete restriction of non-Europeans, such as the Chinese and Japanese.
Grant argued the Nordic race had been responsible for most of humanity's great achievements, and admixture was "race suicide" and unless eugenic policies were enacted, the Nordic race would be supplanted by inferior races. Future president Calvin Coolidge agreed, stating "Biological laws tell us that certain divergent people will not mix or blend. The Nordics propagate themselves successfully. With other races, the outcome shows deterioration on both sides."
The Immigration Act of 1924 was signed into law by President Coolidge. This was designed to reduce the number of immigrants from Southern Europe and Russia, exclude Asian immigrants altogether, and favor immigration from the British Isles, Germany, Poland, Sweden and Norway. THE IMMIGRATION ACT OF 1924
The spread of these ideas also affected popular culture. F. Scott Fitzgerald invokes Grant's ideas through a character in part of "The Great Gatsby", and Hilaire Belloc jokingly rhapsodied the "Nordic man" in a poem and essay in which he satirised the stereotypes of Nordics, Alpines and Mediterraneans.
Writers such as Jack London, Robert E. Howard, and H. P. Lovecraft reflected Nordicist ideas in their fictions.
Nordic thought in Germany.
In Germany, however, the influence of Nordicism remained powerful. There it was known under the term "Nordischer Gedanke" ("Nordic thought").
This phrase was coined by the German eugenicists Erwin Baur, Eugen Fischer and Fritz Lenz. It appeared in their 1921 work "Human Heredity", which insisted on the innate superiority of the Nordic race.
Adapting the arguments of Schopenhauer and others to Darwinian theory, they argued that the qualities of initiative and will-power identified by earlier writers had arisen from natural selection, because of the tough landscape in which Nordic peoples evolved. This had ensured that weaker individuals had not survived.
This argument was derived from earlier eugenicist and Social Darwinist ideas. According to the authors, the Nordic race arose in the ice age, from,
They went on to argue that "the original Indo-Germanic civilization" was carried by Nordic migrants as far as India, and that the physiognomy of upper-caste Indians "disclose a Nordic origin".
By this time, Germany was well-accustomed to theories of race and racial superiority due to the long presence of the Völkish movement, the philosophy that Germans constituted a unique people, or volk, linked by common blood. While Volkism was popular mainly among Germany's lower classes and was more a romanticized version of ethnic nationalism, Nordicism attracted German anthropologists and eugenicists.
Hans F. K. Günther, one of Fischer's students, first defined "Nordic thought" in his programmatic book "Der Nordische Gedanke unter den Deutschen". He became the most influential German in this field. His "Short Ethnology of the German People" (1929) was very widely circulated.
In his "Rassenkunde des deutschen Volkes" ("Race-Lore of the German Volk"), published 1922, Günther identified five principal European races instead of three, adding the East Baltic race and Dinaric race to Ripley's categories. He used the term Ostic instead of Alpine. He focused on their supposedly distinct mental attributes.
Günther criticised the Völkish idea, stating that the Germans were not racially unified, but were actually one of the most racially diverse peoples in Europe. Despite this, many Völkists who merged Völkism and Nordicism embraced Günther's ideas, most notably the Nazis.
Nazi Nordicism.
Adolf Hitler read "Human Heredity" shortly before he wrote "Mein Kampf", and called it scientific proof of the racial basis of civilization. Its arguments were also repeated by the Nazi ideologist Alfred Rosenberg, in his book "The Myth of the Twentieth Century" (1930).
Nazi racial theories, such as those of Julius Evola, held the Atlanteans to be a race of Nordic supermen, and Alfred Rosenberg wrote of a "Nordic-Atlantean" master race whose civilization was lost through inward corruption and betrayal. The Occult and Nazism Re-Examined. According to Rosenberg, the Nordic race had evolved in a now-lost landmass off the coast of Europe, perhaps mythical Atlantis, migrated through northern Europe and expanded further south, and as far as Iran and India where it founded the Aryan cultures of Zoroastrianism and Hinduism. Like Grant and others, he argued that the entrepreneurial energy of the Nordics had "degenerated" when they mixed with "inferior" peoples.
With the rise of Hitler, Nordic theory became the norm within German culture. In some cases the "Nordic" concept became an almost abstract ideal rather than a mere racial category. For example Hermann Gauch wrote in 1933 (in a book which was banned in the Third Reich) that the fact that "birds can be taught to talk better than other animals is explained by the fact that their mouths are Nordic in structure." He further claimed that in humans, "the shape of the Nordic gum allows a superior movement of the tongue, which is the reason why Nordic talking and singing are richer."
Such views were extreme, but more mainstream Nordic theory was institutionalized. Hans F. K. Günther, who joined the Nazi Party in 1932, was praised as a pioneer in racial thinking, a shining light of Nordic theory. Most official Nazi comments on the Nordic Race were based on Günther's works, and Alfred Rosenberg presented Günther with a medal for his work in anthropology.
Eugen Fischer and Fritz Lenz were also appointed to senior positions overseeing the policy of Racial Hygiene. Madison Grant's book was the first non-German book to be translated and published by the Nazi Reich press, and Grant proudly displayed to his friends a letter from Hitler claiming that the book was "his Bible."
The Nazi state used such ideas about the differences between European races as part of their various discriminatory and coercive policies which culminated in the Holocaust. Ironically, in Grant's first edition of his popular book, he classified the Germans as being primarily Nordic, but in his second edition, published after the USA had entered World War I, he had re-classified the now enemy power as being dominated by "inferior" Alpines.
Günther's work agreed with Grant's, and the German anthropologist frequently stated that the Germans are definitely not a fully Nordic people. Hitler himself was later to downplay the importance of Nordicism in public for this very reason. The standard tripartite model placed most of the population of Hitler's Germany in the Alpine category, especially after the Anschluss.
J. Kaup led a movement opposed to Günther. Kaup took the view that a German nation, all of whose citizens belonged to a "German race" in a populationist sense, offered a more convenient sociotechnical tool than Günther's concept of an ideal Nordic type to which only a very few Germans could belong.
Nazi legislation identifying the ethnic and "racial" affinities of the Jews reflects the populationist concept of race. Discrimination was not restricted to Jews who belonged to the "Oriental-Armenoid" race, but was directed against all members of the Jewish ethnic population.
The German Jewish journalist Kurt Caro (1905–1979) who emigrated to Paris in 1933 and served in the British army from 1943, published a book under the pseudonym Manuel Humbert claiming to unmask Hitler's "Mein Kampf" in which he stated the following racial composition of the Jewish population of Central Europe: 23,8% Lapponid race, 21,5% Nordic race,
20,3% Armenoid race, 18,4% Mediterranean race, 16,0% Oriental race.
By 1939 Hitler had abandoned Nordicist rhetoric in favour of the idea that the German people as a whole were united by distinct "spiritual" qualities. Nevertheless, Nazi eugenics policies continued to favor Nordics over Alpines and other racial groups, particularly during the war when decisions were being made about the incorporation of conquered peoples into the Reich.
In 1942 Hitler stated in private, Trevor-Roper, Hugh, "Hitler's Table Talk, 1941-44", 1973 edition, p. 475 (12 May 1942)
Hitler and Himmler planned to use the SS as the basis for the racial "regeneration" of Europe following the final victory of Nazism. The SS was to be a racial elite chosen on the basis of "pure" Nordic qualities.

Post-Nazi re-evaluation and decline of Nordicism.
Even before the rise of Nazism, Grant's concept of "race" lost favor in the USA in the polarizing political climate after World War I, including the Great Migration and the Great Depression. By the 1930s, criticism of the Nordicist model was growing in Britain and America. The British historian Arnold J. Toynbee in "A Study of History" (1934) argued that the most dynamic civilisations have arisen from racially mixed cultures. In southern Europe the theory understandably had less influence.
This required the abandonment of Grant's gradations of "white" in favour of the "One-drop theory"—which was embraced by white supremacists and black supremacists alike. Among the latter were Marcus Garvey, and, in part, W. E. B. Du Bois, at least in his later thought.
With the rise of Nazism many critics pointed to the flaws in the theory, repeating the arguments made by Sergi and others that the evidence of ancient Nordic achievement is thin when set against the civilizations of the Mediterranean and elsewhere. The equation of Nordic and Aryan identity was also widely criticised.

Some Lombard nationalists took it up in Italy, but even after the establishment of Benito Mussolini's fascist government racial theories were not prominent. Mussolini stated, "Nothing will ever make me believe that biologically pure races can be shown to exist."
After World War II, the categorization of peoples into "superior" and "inferior" groups fell even further out of political and scientific favor, eventually leading to the characterization of such theories as scientific racism. The tripartite subdivision of "Caucasians" into Nordic, Alpine and Mediterranean groups persisted among some scientists into the 1960s, notably in Carleton Coon's book "The Origin of Races" (1962).
Already race academics such as A. James Gregor were heavily criticizing Nordicism. In 1961 Gregor called it a "philosophy of despair", on the grounds that its obsession with purity doomed it to ultimate pessimism and isolationism.
As late as 1977 the Swedish author Bertil Lundman wrote a book "The Races And Peoples Of Europe" mentioning a "Nordid Race". The development of the Kurgan theory of Indo-European origins challenged the Nordicist equation of Aryan and Nordic identity, since it placed the earliest Indo-European speakers around central Asia and/or far-eastern Europe (although according the Kurgan hypothesis some Proto-Indo-Europeans "did" eventually migrate into Central and Northern Europe and become the ancestors of the Nordic peoples.)
The original German term used by Ripley, ""Theodiscus"", which is translated into English as "Teutonic", has fallen out of favour amongst German-speaking scholars, and is restricted to a somewhat ironical usage similar to the archaic "teutsch", if used at all. While the term is still present in English, which has retained it in some contexts as a translation of the traditional Latin "Teutonicus" (most notably the aforementioned Teutonic Order), it should not be translated into German as ""Teutonisch"" except when referring to the historical Teutones.
Depigmentation theory.
The depigmentation theory received notable support from later anthropologists, thus in 1947 Melville Jacobs noted: "To many physical anthropologists Nordic means a group with an especially high percentage of blondness, which represent a depigmentated Mediterranean". In her work "Races of Man" (1963, 2nd Ed. 1965) Sonia Mary Cole went further to argue that the Nordic race belongs to the "brunette Mediterrenean" Caucasoid division but that it differs only in its higher percentage of blonde hair and light eyes. The Harvard anthropologist Claude Alvin Villee, Jr. also was a notable proponent of this theory, writing: "The Nordic division, a partially depigmized branch of the Meditterranean group." "Collier's Encyclopedia" as late as 1984 contains an entry for this theory, citing anthropological support. Early 21st century genetic studies have provided new insights into the origins of Irish people as well as their neighbours from other parts of the British Isles. Correspondingly, researchers in the field have suggested that migrations from Prehistoric Iberia can be viewed as the primary source for their genetic material, having demonstrated marked similarities with modern representatives of the aforementioned time period in that of the Basque people. However, the majority of Irish males fall under the R1b sub-clade L-21, which is quite rare for Basques.
Forensic anthropology.
Some forensic scientists, pathologists and anthropologists up to the 1990s continued to use the tripartite division of Caucasoids: Nordic, Alpine, and Mediterranean, based on their cranial anthropometry. The anthropologist Wilton M. Krogman for example identified Nordic racial crania in her work "The Human Skeleton in Forensic Medicine" (1986) as being "dolichochranic". In his work "Forensic Pathology", published in 1991, Bernard Knight, a Professor of Forensic Pathology, also uses the tripartite model and identifies the Nordic race based on its dolichocephalic skull shape. Forensic anthropologists of the 21st century however no longer continue to use the tripartite division of Caucasoids, but instead only recognise Caucasoid, Negroid and Mongoloid through analysis of skeletal remains and not subraces of these racial groups.
21st century.
In the 21st century there is unanimous agreement among anthopologists and biologists that completely "pure" races do not and have not existed. Current views of European anthropologists on race: influence of educational and ideological background. In other words, there are not identifiable clades of humans that "exactly" correspond with any ethnic groups, although population genetics have identified some dominant clades "among" the ethno-linguistic groups. This opportunity for population genetics has reduced the degree of speculation about human prehistory and about the validity of early recorded history.
Genetic reality.
The emergence of population genetics further undermined the categorisation of Europeans into clearly defined racial groups. A 2007 study on the genetic history of Europe found that the most important genetic differentiation in Europe occurs on a line from the north to the south-east (northern Europe to the Balkans), with another east-west axis of differentiation across Europe, separating the "indigenous" Basques and Sami from other European populations. Despite these stratifications it noted the unusually high degree of European homogeneity: "there is low apparent diversity in Europe with the entire continent-wide samples only marginally more dispersed than single population samples elsewhere in the world."

Operation Wetback
Operation Wetback was a 1954 operation by the United States Immigration and Naturalization Service (INS) to remove illegal immigrants, mostly Mexican nationals from the southwestern United States.
History.
Burgeoning numbers of Mexican migrants prompted President Dwight D. Eisenhower to appoint General Joseph Swing as INS Commissioner. According to Attorney General Herbert Brownell, Jr., Eisenhower had a sense of urgency about illegal immigration upon taking office. In a letter to Senator J. William Fulbright, Eisenhower quoted a report in "The New York Times" that said, "The rise in illegal border-crossing by Mexican 'wetbacks' to a current rate of more than 1,000,000 cases a year has been accompanied by a curious relaxation in ethical standards extending all the way from the farmer-exploiters of this contraband labor to the highest levels of the Federal Government."
Operation Wetback in action.
The effort began in California and Arizona in 1954 and coordinated 1,075 Border Patrol agents, along with state and local police agencies. Tactics employed included going house to house in Mexican-American neighborhoods and citizenship checks during standard traffic stops. 
Some 750 agents targeted agricultural areas with a goal of 1,000 apprehensions per day. By the end of July, over 50,000 illegal aliens were caught in the two states. An estimated 488,000 illegal aliens are believed to have left voluntarily, for fear of being apprehended. By September, 80,000 had been taken into custody in Texas, and the INS estimated that 500,000 to 700,000 had left Texas of their own accord. To discourage illicit re-entry, buses and trains took many deportees deep within Mexican territory before releasing them.
Tens of thousands more were deported by two chartered ships: the "Emancipation" and the "Mercurio". The ships ferried them from Port Isabel, Texas, to Veracruz, Mexico, more than to the south. Some were taken as far as . Deportation by sea was ended after seven deportees jumped overboard from the "Mercurio" and drowned, provoking a mutiny that led to a public outcry in Mexico.
Civil rights violations.
There were widespread allegations of abuse against Mexicans and US citizens of Mexican descent, including harassment and beatings. 

Other Losses
Other Losses is a 1989 book by Canadian writer James Bacque, in which Bacque alleges that U.S. General Dwight Eisenhower intentionally caused the deaths by starvation or exposure of around a million German prisoners of war held in Western internment camps briefly after the Second World War. "Other Losses" charges that hundreds of thousands of German prisoners that had fled the Eastern front were designated as "Disarmed Enemy Forces" in order to avoid recognition under the third Geneva Convention, for the purpose of carrying out their deaths through disease or slow starvation. "Other Losses" cites documents in the U.S. National Archives and interviews with people who stated they witnessed the events. The book claims that there was a "method of genocide" in the banning of Red Cross inspectors, the returning of food aid, the policy regarding shelter building, and soldier ration policy.
The book has been extensively criticized by mainstream historians, with one stating that it "makes charges that are demonstrably absurd". Stephen Ambrose and seven other historians examined the book soon after its publication, and came to the conclusion that it was inaccurate and the product of conspiracy theory. Several historians, including the former senior historian of the United States Army Center of Military History, Colonel Ernest F. Fisher, who was involved in the 1945 investigations into the allegations of misconduct by U.S. troops in Germany and who wrote the book's foreword, argue that the claims are accurate.
Claims of "Other Losses".
Other Losses.
The title of "Other Losses" derives from a column of figures in weekly U.S. Army reports that Bacque states actually reflects a body count of German prisoners that died of slow starvation or diseases. The book states that Colonel Philip Lauben, chief of German Affairs Branch at SHAEF (Supreme Headquarters Allied Expeditionary Force), confirmed that "other losses" meant deaths and escapes, with escapes being a minor part. This is supported by a US Army document lodged in the US National Archives which "plainly states" that the "Other Loses" category of prisoners was for deaths and escapes. Bacque dismisses claims from his opponents that "other losses" meant transfers or discharges, as these are accounted for in other columns in the same tables. Furthermore, there is no separate column in which deaths were recorded.
The book refers to the Army Chief Historians report that was published in 1947; in the 20 pages dealing with the capture, transfer and discharge of prisoners, the report makes no mention of releasing prisoners without formal discharge. Furthermore, Bacque cites Army orders from Eisenhower himself (Disbandment Directive No. 1) stating that every prisoner leaving captivity had to have discharge papers.
Disarmed Enemy Forces designation.
"Other Losses" states that Eisenhower sought to sidestep the requirements of the Geneva Convention through the designation of these prisoners as Disarmed Enemy Forces (DEF), specifically stating that "in March, as Germany was being cracked ... a message was being signed and initialed by Eisenhower proposed a startling departure from the Geneva Convention (GC) — the creation of a new class of prisoners who would not be fed by the Army after the surrender of Germany."
The book states that, against the orders of his superiors, Eisenhower took 2 million additional prisoners after Germany's surrender that fell under the DEF designation. "Other Losses" states that the million soldiers it alleges died had fled the Eastern front and most likely ended up in Rheinwiesenlager prisoner transit camps run by United States and French forces where many such prisoners died of disease or starvation under the cover of the DEF designation.
The book cites orders from Eisenhower which stipulated that the Germans would be solely responsible for feeding and maintaining the DEFs, however he then prevented any aid from reaching them.
Number of prisoners who died.
"Other Losses" claims that nearly one million German prisoners died while being held by United States and French forces at the end of World War II. Specifically, it claims: "The victims undoubtedly number over 800,000, almost certainly over 900,000 and quite likely over a million. Their deaths were knowingly caused by army officers who had sufficient resources to keep the prisoners alive."
"Other Losses" contains an analysis of a medical record that it states supports the conclusion of a prisoner death rate of 30%. Bacque also referred to a 1950 report from the German Red Cross which stated that 1.5 million former German POWs were still officially listed as missing, fate unknown. When the KGB opened its archives in the 1990s, Bacque's estimates for the number of missing POWs that died in Soviet camps was found to be correct.
The book claims that approximately 15% of the deaths in the U.S. camps were from starvation or dehydration and that most deaths were caused by dysentery, pneumonia, or septicaemia, as a result of the unsanitary conditions and lack of medicine. "Other Losses" further claims that officers from the U.S. Medical Corps reported death rates far higher than they had ever seen before.
The book further states that Eisenhower's staff was complicit in the scheme. "Other Losses" also states that, in order to carry out his scheme, Eisenhower kept these prisoners in camps far longer than it was necessary It claims that, by the end of 1945, only 40% of prisoners had been released. "Other Losses" further characterizes the 22-volume German "Maschke" Commission report investigating the deaths of German prisoners as written by "client-academics" as part of a "cover up" of the deaths that "Other Losses" alleged occurred.
Treatment of prisoners.
"Other Losses" claims that the U.S. dismantled the German welfare agencies, including the German Red Cross, then dismissed the Swiss Government from its role as Protecting Power. No agencies were allowed to visit the camps or provide any assistance to the prisoners, including delegates from ICRC (International Committee of the Red Cross), which was a violation of the Geneva Convention. It further states that the only notable protest against this was from William Lyon Mackenzie King, Prime Minister of Canada.
Bacque states that the press was also prevented from visiting the camps, and therefore was unable to report on the state of the camps and the condition of the prisoners.
The book states that many of the U.S. camps consisted of open fields surrounded by barbed wire, with no shelter or toilet facilities. In these camps prisoners were forced to sleep on the ground in the open, though it claims that the U.S. Army had plenty of surplus tents which could have been issued. No supplies such as blankets were supplied to the prisoners, even though these were in good supply at various locations such as the depot at Naples. In a letter General Everett Hughes stated that there were "more stocks than we can ever use; stretch as far as eye can see."
The book quotes Dr. Konrad Adenauer (later Chancellor of Germany) stating that "The German prisoners have been penned up for weeks without any protection from the weather, without drinking water, without medical care. They are being held in a manner contrary to all humanitarian principles and flagrantly contrary to the Hague and Geneva Conventions."
Both J. P. Pradervand (ICRC French Delegation) and Henry Dunning (American Red Cross) sent letters to the State Department condemning the poor treatment of the German prisoners. Colonel Philip Lauben stated that "The Vosges was just one big death camp."
Prisoner totals.
The book claims that the U.S. Army employed a number of methods to reduce the number of prisoners officially on hand. One method was to accuse the Russians of taking far more prisoners than they reported. Another was the "midnight shift", whereby the opening balance of a given week was less than the closing balance of the previous week.
The book claims that a "Missing Million" prisoners exist in the difference in totals between two U.S. army reports (the last of the daily reports and the first of the weekly reports) issued on June 2, 1945. As a consequence of this, according to Quartermaster's reports the number of rations issued to the camps was reduced by 900,000.
After visiting many of the camps in August 1945, "Other Losses" states that General Robert Littlejohn (Quartermaster of the ETO) concluded that the U.S. Army was reporting 3.7 million prisoners while it actually possessed 5.2 million, thereby corroborating the conclusions made in a report three months earlier from General J. Lee (in charge of logistics for the ETO), which he had sent to SHAEF headquarters. "Other Losses" states that Littlejohn subsequently wrote in a report to Washington that because requisitions for supplies were based on these faulty numbers, 1.5 million prisoners were getting no food.
"Other Losses" states that, three years later, in 1948 the ICRC formally requested documents confirming the total number of prisoners in the U.S. Zone and was eventually told that 3.5 million were there, which omitted approximately 1.7 million from the actual number of 5,224,000.
Food shortage.
"Other Losses" explicates the 1944–1949 German food crisis to support the claims for a high mortality rate.
"Other Losses" concludes that the 1945 food crisis in Europe was contrived by Allied forces by the use of restrictive food import policy, including restrictions on Red Cross food deliveries, and other means. It claims that Eisenhower purposefully starved German prisoners given that "here was a lot more wheat available in the combined areas of western Germany, France, Britain, Canada and the USA than there had been in the same year in 1939." "Other Losses" states that, in May 1945, the ICRC had 100,000 tons of food in storage warehouses in Switzerland. The book claims that, when they tried to send train loads of this food into the U.S. Zone, the U.S. Army sent the trains back, saying their own warehouses were full. "Other Losses" states that this prompted Max Huber, head of the ICRC, to send a strong letter of protest to the State Department, in which he described the difficulties placed by SHAEF in the way of the ICRC efforts to provide aid. He said "Our responsibility for the proper use of relief supplies placed in our care is incompatible with a restriction to the fulfillment of orders which render us powerless to furnish relief which we ourselves judge necessary."
U.S. Army warehouses had 13.5 million Red Cross food parcels taken from the ICRC, which were never distributed. The book also states that German civilians were prevented from bringing food to the camps, and that Red Cross food parcels were confiscated by SHAEF, and the War Department banned them from being given to the men in the camps. The book states that Bacque found no evidence of a drastic food shortage in the U.S. Army —
Criticism of "Other Losses".
New Orleans panel conclusions regarding "Other Losses".
The New Orleans panel's book introduction concluded "hat Bacque is wrong on nearly every major and nearly all his minor charges seem to us to be overwhelmingly obvious. To sum up: Eisenhower was not a Hitler, he did not run death camps, German prisoners did not die by the hundreds of thousands, there was indeed a severe world food shortage in 1945, there was nothing sinister or secret about DEF designation or about the Other Losses column. Bacque's "Missing Million" were old and young boys in the militia dismissed early from the American camps; they were escapees from camps and POWs/DEFs transferred from camp to camp in Germany and Europe for various reasons."
Villa states that "James Bacque's "Other Losses" illustrates what happens when the context surrounding historical persons and important events is lost. The effect to give known facts a twist that seems dramatically new in important ways, but this is means appearance of originality is a little deceptive. For the most part, Bacque's book is not very original at all. When it seems so, the price is purchased at the price of accuracy." He further stated that "hose parts of Other Losses that might rise above a failing grade in an undergraduate term paper are not new. It has long been known that German prisoners of war suffered terribly at the end of World War II, that they died by the thousands after hostilities ceased in the European theater, and that many were required to work as forced laborers for the victors." The main lines of the story have long been known, written up for example in the extensive German "Maschke Commission" between 1962 and 1975. Villa states that Bacque only adds two "novel" propositions: first, that the number that died was in the hundreds of thousands, and seconds, that these deaths were the result of deliberate extermination on the part of Eisenhower. "The falsity of Bacque's charges can be easily demonstrated once the context, particularly the decision-making environment, is examined."
Bischoff concludes that just the application of common sense alone refutes many of the most "fantastical charges" of Bacque, such as asking the question "How could a single man order one million men killed without being caught in the heinous act? How could the bodies disappear without one soldier's coming forward in nearly fifty years to relieve his conscience? How could the Americans (almost one-third of whom are by ethnic background German) conspire for so long to cover up such a vast crime?"
In a 1989 "Time Magazine" book review, Ambrose did, however, apart from his criticisms of the book, concede that "We as Americans can't duck the fact that terrible things happened. And they happened at the end of a war we fought for decency and freedom, and they are not excusable."
"Other Losses" documentary evidence of deaths.
"Other Losses" claimed that "The victims undoubtedly number over 800,000, almost certainly over 900,000 and quite likely over a million. Their deaths were knowingly caused by army officers who had sufficient resources to keep the prisoners alive." "Other Losses" asserts that roughly a million German prisoners — the "Missing Million" — disappeared between two reports issued on June 2, 1945, with one (the last of the daily reports) totaling prisoners in the European Theater of Operations (ETO) in U.S. custody at 2,870,400, while the other (the first of the weekly reports) gives the figure as 1,836,000 prisoners in the Communication Zone (COM Z). As a consequence of this, according to Quartermaster Reports the number of rations issued to the camps was reduced by 900,000.
Historian Albert Cowdrey states that the reason for this is simply that COM Z is a subordinate of the ETO, and its figures omit prisoners held by other armies. In fact, Cowdrey states that the two documents further both cite exactly the same number of total prisoners in the ETO: 3,193,747. Cowdrey concludes "o judge by these documents, there was no Missing Million. There was not even a missing one."
The title of ""Other Losses"" derives from the heading of a column in weekly reports of the U.S. Army's theater provost marshal, which "Other Losses" states is actually a "body count" of dead prisoners. Cowdrey states that, in many cases, as explained by the footnotes in the very documents themselves, the "other losses" were transfers between zones and camps, which were regularly done for a variety of reasons, none of them sinister and all properly noted in the accompanying documents. Cowdrey further states that, not only are these figures many times mentioned in the footnotes, but they are also reflected in the actual increase and decrease in numbers of each camp in the individual army reports. Cowdrey concludes "it is unclear how Bacque could have failed either to see these documents or, if he saw them, to understand their significance to the book he was writing." In addition, while "Other Losses" asserts that these prisoners died of diseases or slow starvation, Cowdrey states that even a cursory glance at the figures shows that this would have been impossible, with figures varying between zero and over 189,000 from week to week.
The introduction to the book publishing many of the New Orleans panel papers also noted that Bacque ignored the greatest source of for the "other losses" column, an August 1945 Report of the Military Governor that states "An additional group of 664,576 are lists as " 'other losses' ", consisting largely of members of the Volkssturm Militia released without a formal charge." It stated that Bacque ignored this document despite its presence in the National Archives, the Eisenhower Library and elsewhere. It further stated the dismissal of the Volksstrum (mostly old men and boys) "accounts for most, quite probably all, of Bacque's 'Missing Million'". Bischoff notes that, in his later American edition of "Other Losses", Bacque discredits the document as a fake "with a further fantastic twist in his convoluted cycle of conspiracy theories, he claims that Eisenhower and the army 'camouflaged' dead POWs/DEFs by listing them as 'discharged Volkssturm.'" Even though Eisenhower himself did not write the document, Bacque concludes that it must have been "doctored".
Regarding prisoners in French custody, historian Rudiger Overmans states that, while the total number of prisoners dying in French custody might have exceeded the official statistic of 21,000, no evidence exists that it was hundreds of thousands of deaths higher than that figure, as Bacque claims. Overmans states that, in addition to the various problems with the Bacque's "death rate" calculations regarding the Rheinwiesenlager transit camps, he ignores that these camps were managed almost entirely by Germans and falsely claimed the no record existed of the handover of the camps to the French in June and July 1945, when detailed records of the handover exist. Overmans also said that Bacque incorrectly claimed that the United States did nothing to help with the French Rheinwiesenlager camps, when the United States engaged in a large operation to raise the caloric intake of those prisoners. Bacque's claims that the 167,000 in French camps that were "dus pour des raisons divers" (other losses) actually died in the winter of 1945-46 not only are not supported by the evidence, but they ignore French documents stating that that figure reflects the release of Volkssturm, women and the sick from those camps.
In addition, Overmans states that Bacque's claim that the 800,000 to 1,000,000 missing prisoners were originally German soldiers that fled from the east into western hands contradicts Soviet POW evidence "well established that we can exclude the idea of an extra million hiding somewhere in the figures." Overmans states that Bacque's claim that one million less prisoners were taken by the Soviet Union than thought produces absurd results, such as that only 100,000 total prisoners could have died in Soviet hands when it is well documented that this amount was exceeded by the dead prisoners from Stalingrad alone. In fact Bacque claimed that up to 500,000 of the missing prisoners were in Soviet camps. Post war Soviet POW evidence was discredited when the KGB opened its archives in the 1990s and an additional 356,687 German soldiers and 93,900 civilians previously recorded as missing were found to be listed as dying in the Soviet camps. Overmans also states that, did they as Bacque claims, flee to the American Rheinwiesenlager camps, they could have easily had contact with their relatives and that it is "quite inconceivable that these prisoners would not have been reported as missing by the their relatives." Moreover, Overmans states that the vast majority of this extra million would have been recorded in registrations that occurred in 1947-1948 and 1950, "but the registrations showed nothing of the kind." Overmans further states that, as evidence that Germans believed that missing veterans were mostly in the west, Bacque relies on a statement by Chancellor Adenauer that turns out in the minutes of the purported meeting to be a "statement related to a TASS report concerning the POWs in the Soviet Union. So much for Bacque's careful use of sources."
The plausibility of Eisenhower getting away with such atrocities.
Overmans states that, comporting with the most basic matters of common sense, "if indeed 726,000 soldiers had died in the American camps (Bacque's number excluding those who supposedly died in French custody or after discharge), what became of the bodies?" Given that the Rheinwiesenlager stretched along 200 kilometers of the Rhine river, "Bacque's 726,000 dead would mean roughly 3,600 dead per kilometer or 5,800 per mile – better than one corpse per foot. Yet despite the widespread construction work carried out after the war, not a single one of these legion of dead was found." However, the sites where the camps were located are considered war graves where excavation is officially forbidden making such research problematical.
Villa states that, by Bacque's reasoning, George C. Marshall, who gave SHAEF as much or more attention to detail than did Eisenhower, would be similarly guilty, perhaps more so under his reasoning, though "Bacque" who cares little for exploring the context, does not even raise the question." Villa states that "It is a virtual impossibility that Eisenhower could have executed an extermination policy on his own" and "a near absolute impossibility that Marshall would not have noticed it, let alone that he would ever have tolerated it" and "what about the scores of officers and millions of soldiers who served under Eisenhower?"
"Other Losses" explains that Eisenhower's staff must have been implicated, charging "squalor of the camps came from the moral squalor polluting the higher levels of the army." Villa states that "[perhaps realizing that he already has a thesis involving a massive American conspiracy, Bacque is careful to exclude British officers from any participation or even knowledge of the crime. Although in his vast indictment, Bacque has included virtually Eisenhower's entire staff, all the doctors and personnel running the camps, the press who failed to uncover the monstrous crime and a whole generation of knowing but silent Germans, he has included not a single Briton." Villa notes that Bacque ignores that SHAEF was a fully integrated Anglo-American command, and many of Eisenhower's top officers were Britons who would have also had to cover up the conspiracy. Villa states that Bacque did not even need to read books to realize this, "all he had to do was to look at the pictures: in slightly more than half the portraits contained therein, the staff officers wear British uniforms. Bacque, one understands, wants a villain in the piece. A complicated modern military bureaucracy such as SHAEF, is a tedious subject to study, unlikely to yield the insidious conspiracy apparently sought by this ex-publisher." Villa stated regarding the plausibility of the claims in "Other Losses" that "The impossibility of Bacque's selective crime thesis — an American but not a British crime — becomes all the more evident when one examines the basic decisions affecting occupation policy."
Regarding the impossibility of a conspiracy on the scale purported by Bacque, Villa states that "n truth, had Eisenhower committed the crimes Bacque alleges, someone surely would have gossiped, ratted, leaked, or even just hinted. None did. Not even Field Marshal Montgomery. Certainly, if there had been a holocaust, it could never have been covered up." Regarding the overall bureaucracy within which Eisenhower had to operate, Villa stated that "Although the average reader of "Other Losses" would never know it, there was a constellation of authorities to whom Eisenhower had to report his actions. Examining the situation as of May 8, 1945, when his murderous policy is said to have gone into full gear, no responsible historian could ignore the many limitations on Eisenhower's authority that made it impossible for him to carry out an independent policy in Germany."
"Other Losses" methodology.
Cowdrey stated that Bacque's methodology for determining just the "Other Losses" figures was also "slipshod", with Bacque filling gaps in the records where no "other losses" were recorded by "comput the number of deaths by applying the death rate given in Army statistics for another period to the known number of prisoners at hand." Cowdrey states that the "rate given in Army statistics" turned out to be a "rate invented by Bacque himself." Cowdrey states that, with regard to Bacque's attempt to analyze a U.S. Army hospital record document, Bacque not only missed an obvious typo throwing his calculations off by 10, but he also badly erred in the math used to tabulate purported death rates of 30%, which he attempts to use to support his claim that the "other losses" column in the weekly army reports reflects a body count. Cowdrey concludes that "the mathematical blunders of "Other Losses" are elementary. One turns from them feeling only embarrassment for the author who naively grounds his thesis upon them."
Historian Rolf Steininger stated that Bacque's claim that the failure to publish the 1960s and 1970s German Maschke Commission finding death figures to be a "cover up" contradicts that the entire 22 volume series was actually published in 1972 without any restrictions, to which only an oblique reference is made in an "Other Lossess" endnote. Steininger says that "Bacque himself is one of the mythmakers" and that, when Bacque attacks the Maschke Commission scholars as "client-academics", "he oversteps the bounds of mythmaking and enters the territory of libel." Historian Gunter Bischoff states that it is simply "outrageous to dismiss this vast and impressive body of scholarship as being designed to produce 'soothing conclusions' for the German public, as Bacque puts it."
Bischoff said that while "most scholarly reviewers of Bacque's book have pointed out that Bacque fails to establish the proper historical context", "worse, the historical records that Bacque did use are amateurishly misrepresented and often misleading or wrong. Once Bacque's endnotes are checked, frequent misreadings of documents are easily discernible." As an example, Bischoff states that Bacque charged that General Mark Clark's raising of caloric intake in the Ebensee camp was "trying to exculpate himself before history" of Eisenhower's scheme to exterminate Germans. Bischoff states that Bacque fails to tell his readers, first, that Ebensee was not even an Allied prisoner of war camp, but a camp for displaced persons that was actually housing Polish Jews liberated from a nearby concentration camp, second, that Clark raised the caloric intake levels in response to a report critical of the treatment of liberated Jews that had just been released and, third, that Eisenhower soon thereafter also raised the levels for his Jewish displaced persons in camps run by Eisenhower.
Oral histories.
Regarding oral histories, Bischoff concludes that "Bacque abuses the process through his highly selective presentation of oral histories and memoir literature." "Other Losses" cited Colonel Phillip S. Lauben as the source for the claim that the "other losses" weekly report column covered up deaths. The New Orleans panel noted that Lauben himself twice has since repudiated this. When describing his interview with Bacque, Lauben stated "I am 91 years old, legally blind, and my memory has lapsed to a point where it is quite unreliable ... Often during my talk with Mr. Bacque I reminded him that my memory has deteriorated badly during the 40 odd years since 1945. Mr. Bacque read to me the USFET POW figures for discharge and transfers to other national zones. It seemed to me that, after accounting for transfers and discharges, there was nothing left to make up the grand total except deaths and escapes. I.e.: the term OTHER LOSSES. I was mistaken ... many POWs were transferred from one U.S. Command to another U.S. Command. This left one with a loss and the other with a gain."
Bacque described his other witness, John Foster, as a camp guard "in charge of the work detail of fifty men, Germans and Americans, who did nothing all day but drag bodies out of the camp." Bischoff cites a researcher for the Canadian Broadcasting Corporation (CBC) who tracked down Foster who told the researcher that "he never was a member of a burial detail, he never buried a body in his life. And he's unaware of any such activity in any camps." When the CBC interviewer confronted Bacque with Foster's denial, Bacque responded "well, he's wrong. He's just wrong."
Bacque also interviewed Martin Brech, a U.S. soldier who was a guard at the Andernach camp. Brech discussed his experiences in detail, in which he witnessed the poor conditions in the camp, the large number of deaths, and the systematic starving of the prisoners. He said "The silence about this atrocity has pained me for forty-five years and I'm deeply grateful that James Bacque's 'Other Losses' has at last brought the truth to light."
Bacque states that he has received letters and phone calls from about 2,000 Germans who survived the camps, expressing gratitude that the truth about their experience has finally been published.
European food shortage.
Historian James Tent concludes that "James Bacque might be willing to relegate the world food shortage to the category of myth. Few others will do so. Perhaps he can try the interviewing techniques that he employed in "Other Losses" — namely putting words in the mouths of selective eyewitnesses." The introduction to the New Orleans panel's book concludes that Bacque's insistence not only defies common sense, but it would have shocked anyone in Europe in 1945. "Other Losses" states "There was a lot more wheat available in the combined areas of western Germany, France, Britain, Canada and the USA than there had been in the same year in 1939." Tent states that Bacque selectively cited diary entries and other sources to come to the conclusion of a food abundance and the lack of transportation problems. Tent further stated that Bacque's statements that the German population was 4% smaller in 1945 than in 1939 while mentioning only an "influx of refugees from the East", completely ignored that that "influx" consisted of a staggering 10 to 13 million Germans displaced from the east and south into Germany that had to be fed and housed. The panel introduction also stated that Bacque ignored the overriding reality that German agriculture had suffered extreme productivity decreases in 1944 and 1945, a shortage of synthetic fertilizers had developed after nitrogen and phosphate stocks were channeled into ammunition production, Tent stated that Bacque completely ignored that, because coal reserves had disappeared from the industrial pipeline, fertilizer plants and other food production facilities were inoperable, meaning that German farmers could expect little if any fertilizer over the next one to two years and that fuel was next to non-existent to power run-down farm equipment. In addition, the panel introduction said that Bacque ignored that the destroyed German transportation infrastructure created additional logistical nightmares, with railroad lines, bridges and terminals left in ruins, the turnaround time for railroad wagons was five times higher than the prewar average, and, of the 15,600 German locomotives, 38.6% were no longer operating and 31% were damaged.
The introduction to the panel's book also states that Bacque ignored that Eisenhower himself was the one warning his superiors about food shortages as early as February 1945 — months before the war had even ended — then again in May when Eisenhower requested food imports from the United States. Tent stated that Bacque also misleadingly cited only part of a June 1945 war report that 630,000 tons of imported wheat would meet the minimum German civilians minimum food requirements, leaving the reader thinking that the food shortage could easily be solved by United States shipments, without informing the reader of an accompanying report that the Allies brought in 600,000 tons of grain, and that it was quickly used up.
While "Other Losses" claims that the United States dismissed the Swiss Government from its role as a protecting power, Villa states that Bacque ignores that it was the Soviets that had vetoed permitting the continued existence of the German government in May 1945, leaving the Swiss no longer wanting to remain the protecting power because they no longer had a German government to which to report, and that the United Nations — including Canada — had concluded the same. Villa adds that, contrary to Bacque's implications, there is no evidence that Eisenhower would not have wanted the German government to continue operating under Doenitz' leadership in Flemsberg. Even with regard to the supposed Canadian protest, Villa states "this is another case of Bacque's outrageous editing of a document" with Bacque using ellipses to edit out of his quote of the document the key text stating "in the present unique situation there can be no protecting power for a Government which cannot exist."
Bischoff stated that, even in Bacque's later released American edition, "Bacque refuses to address the overwhelming evidence that there had been a great shortage of food in central Europe, beyond admitting that there was a food crisis in Germany in 1946" and "but again he turns the evidence on its head when he charges that 'Allied food policy longer does he heap the blame on the Americas alone, as in his Canadian edition deliberately hampered the Germans in attempting to feed themselves.'" Bischoff states "the opposite is true", citing the large amounts of U.S. Army GARDA Aid, without which "German and Austrian civilians would have had a much tougher time surviving the hunger months of 1945 and 1946."
"Other Losses" treatment of Eisenhower statements.
Bischoff and Ambrose stated that "Other Losses" states that of Eisenhower, "he felt ashamed that he bore a German name", citing Stephen Ambrose and Colonel Ernest Fisher, when what Ambrose said to Fischer was "It is rumored that Ike once said, 'I'm ashamed my name is Eisenhower,' but I've never seen it, never used it, and don't believe it." They concluded that "twisting of historical evidence — both primary and secondary — is not unusual in "Other Losses". In the end, Bacque usually resorts to conspiracy theories to salvage his outrageous charges." Regarding another example, Bischoff and Ambrose stated that "[one of Bacque's strongest quotations is a line from one of Eisenhower's letters to his wife, Mamie: 'God I hate the Germans.' Bacque seems not to understand that the words were appropriate to the subject, that Ike was by no means unique, and that John Eisenhower printed the letter in his book "Letters to Mamie", where Bacque found it, without embarrassment." They also stated that, when in 1943, when discussing that he had never been trained for such logistics when he faced a similar problem in Tunisia, Eisenhower stated "we should have killed more of them", which Bacque took seriously in "Other Losses" (it was also removed in 1969 from a report lest it offend Allies). POWs from Tunisia fared well after being shipped to the United States, where they were well fed in U.S. POW camps.
"Other Losses" discussion of DEF designations.
With regard to DEF designations, Historian Brian Loring Villa stated that Bacque ignores the 1943 debates of the European Advisory Commission (EAC) and the 1944 EAC's instruments of surrender, not picking up until the March 1945. "Other Losses" states that "in March, as Germany was being cracked ... a message was being signed and initialed by Eisenhower proposed a startling departure from the Geneva Convention(GC) — the creation of a new class of prisoners who would not be fed by the Army after the surrender of Germany. The message, dated March 10, reads: ... " "Other Losses" then quotes the cable from the third paragraph, which, Villa states, permits the casual reader to believe that Eisenhower invented the term "disarmed enemy forces", specifically omitting the other parts of the document referencing the EAC's draft surrender terms suggesting a designation to avoid the Geneva Convention categories, or the later use of the term "disarmed enemy forces." Villa states that, when the actual full correspondence is read, Eisenhower was merely proposing, in March 1945 with thousands of prisoners surrendering, to act on the surrender condition drafts worked out months earlier. Villa concludes that "ll Bacque had to do was look for the EAC draft surrender terms mentioned in the cable — these can readily be found in the standard collection of printed United States Diplomatic documents."
Villa further states that "Other Losses" wrongly cites a March CCS directive to Eisenhower, claiming that it directs Eisenhower to not take any prisoners after Victory in Europe (V-E) Day, when in fact, the directive states that those taken after V-E day should not be designated as "Prisoners of War" under the Geneva Convention. In fact, JCS 1067 required Eisenhower to continue to take prisoners after V-E Day. Moreover, if Bacque truly believes that Eisenhower was supposed to stop taking prisoners, Villa states that Bacque does not explain how Eisenhower could have gotten away with taking 2 million prisoners after this date without CCS action.
Villa also states that Bacque's assertion that the British rejected designations to not comply with the GC requirements are entirely unfounded and ignore that the British themselves requested that they be permitted to use such designations, with that request being granted by the CCS and used in surrenders to British troops. Villa states that Bacque also entirely ignores that it was the Soviets that had first raised issues about GC requirements in wartime conferences because they were not GC signatories, and as such, did not want condition surrender terms reflecting GC requirements. Villa stated that Bacque goes further regarding the Soviets, implying that the scale of Soviet gulags were a myth invented to cover up the American crime he asserts. Villa also stated that Bacque claims that Eisenhower initially underestimated the expected POW figures as part of his attempt to starve them, while in actuality, Eisenhower was desperately requesting to have food imports approved. "Other Losses" fails to cite JCS 1067, the primary restriction on food importation, even once in its notes. Villa also states that Bacque misrepresented a June 5, 1945 memorandum in a way that makes the reader believe that Eisenhower could have requisitioned additional food if he had wanted to, while the memorandum itself makes clear that Eisenhower had requested and was denied additional imports. Villa concludes: "Need it be added that anyone going back to the documents to find purported confessions of an extermination policy by one of Eisenhower's principal staff officers will find nothing even suggestive of it? Bacque has simply distorted the context beyond all recognition."
Other evidence for German POW deaths.
Several historians rebutting Bacque have argued that the missing POWs simply went home, that Red Cross food aid was sent to displaced civilians and that German POWs were fed the same rations that the U.S. Army was providing to the civilian population. U.S. and German sources estimate the number of German POWs who died in captivity at between 56,000 and 78,000, or about one percent of all German prisoners, which is roughly the same as the percentage of American POWs who died in German captivity. This is contradicted by a report into missing POWs commissioned in the 1950s by the West German Chancellor Konrad Adenauer, which found that 1.5 million German prisoners known to be alive in allied prison camps never came home, nor were their deaths recorded. The book "Other Losses" alleged 1.5 million prisoners were missing and estimated that up to 500,000 of these were in Soviet camps. When the KGB opened its archives in the 1990s, 356,687 German soldiers and 93,900 civilians previously recorded as missing were found to be listed in the Bulanov report as dying in the Soviet camps.
German POW expert Kurt W. Bohme noted that, of the 5 million prisoners in American hands, the European Theater of Operations provost marshall recorded a total of 15,285 prisoner deaths. In 1974, the German Red Cross reported that about 41,000 German MIAs were last reported in western Germany, which is also the location of the prisoner camps. It is reasonable to assume that some deaths in transit camps just before the end of the war went unreported in the chaos at the time. Historian Albert Cowdrey estimates that the total figure is unlikely to be above the aggregate of the recorded deaths and the MIAs, which together total 56,285. That maximum number would constitute approximately 1.1% of the 5 million total prisoners held by U.S. forces. That figure also is close to Bohme's estimate of 1% for deaths of prisoners held by the Western powers.
Many of these occurred in the initial Rheinwiesenlager transit camps. The German Maschke Commission which studied prisoner deaths in the 1960s and 1970s concluded that 557,000 prisoners lived in the Rheinwiesenlager camps. The official death toll for those camps was 3,053. The number registered by local Parish authorities was 5,311. The Maschke Commission noted that the largest claim was that "32,000 fatalities had been heard of", but the Masche Commission considered this account to be impossible, as was anything in excess of double the Parish authorities' figure.
While harsh treatment of prisoners occurred, no evidence exists that it was part of an organized systematic effort. Bohme concluded that Eisenhower and the U.S. Army had to improvise for months in taking care of the masses of prisoners to prevent a catastrophe: "In spite of all the misery that occurred behind the barbed wire, the catastrophe was prevented; the anticipated mass deaths did not happen."
The total death rates for United States-held prisoners is also far lower than those held by most countries throughout the war. In 1941 alone, two million of the 3.3 million German-held Soviet POWs — about 60% — died or were executed by the special SS "Action Groups" (Ensatzgruppen). By 1944, only 1.05 million of 5 million Soviet prisoners in German hands had survived. Of some 2–3 million German POWs in Russian hands, more than 1 million died. Of the 132,000 British and American POWs taken by the Japanese army, 27.6% died in captivity — the Bataan death march being the most notorious incident, producing a POw death rate of between 40 and 60%.
Regarding overall POW death rates, the death rates for German POWs held by Americans were lower than every other country except another Allied member, Britain. Using data from U.S. Army records, a number of historians, including Niall Ferguson, maintain that this is a gross overestimation. However, Ferguson states that "the mortality rate for German POW's in U.S. hands was more than 4 times higher than the rate for those who surrendered to the British", but that the United States total mortality rate was under 1% and better than every other country in World War II except for the British. Ferguson further claims that another advantage with surrendering to the British rather than the Americans was that besides treating German prisoners better than the U.S. did, the British were also less likely to hand German prisoners over to the Soviet Union. Large numbers of German prisoners were transferred between the Allies. The U.S gave 765,000 to France, 76,000 to Benelux countries, and 200,000 to the Soviet Union. The U.S. also chose to refuse to accept the surrender of German troops attempting to surrender in Saxony and Bohemia. These soldiers were instead handed over to the Soviet Union. (The Soviet Union in turn handed German prisoners over to other Eastern European nations, for example 70,000 to Poland) Death rates of German soldiers held prisoner in the Soviet Union was 35.8%.
Official claims that the German POW death rate was under 1% have been disputed. For comparison the British civilian post-war mortality rate was 1.2% while in America, where there were no food shortages, the U.S. civilian mortality rate did not fall below 1% until 1948. Anglo American troops held in German POW camps suffered a 4% mortality rate which was praised by the ICRC and credited to the German military ensuring that POWs continued to receive Red Cross food parcels despite their own food shortages in the final months of the war.
Conditions in some of the camps that housed captured German soldiers support claims for a higher mortality rate. Lt. Colonel Henry W. Allard, the commander in charge of the DEF camps in France, later stated "The standard of the PW (POW) camps in the ComZ (U.S. rear zone) in Europe compare as only slightly better, or even, with the living conditions of the Japanese PW camps our men tell us about".
The U.S. Army's surgeon general described some of the camps as resembling Andersonville Prison in 1864 and noted that the lack of food in some cases led to "extensive malnutrition".
Other related information.
American Treasury Secretary Henry Morgenthau, Jr. had written a book outlining the Morgenthau Plan, "Germany is Our Problem". In November 1945, General Dwight D. Eisenhower, at the time Military Governor of the U.S. Occupation Zone in Germany, approved the distribution of one thousand free copies of the book to American military officials in Germany. Historian Stephen Ambrose draws the conclusion that not only did Eisenhower approve of the plan, he had, in fact, contributed to it while it was being written. Eisenhower also clashed with General George S. Patton over the treatment of Germans, with Patton feeling that "It is no more possible for a man to be a civil servant in Germany and not have paid lip service to the Nazis than it is for a man to be a postmaster in America and not have paid at least lip service to the Democratic Party or the Republican Party when they are in power."
In response to suggestions from his own military government in Germany that the Potsdam agreement be interpreted less strictly as regards the lowering of the people's standards of living, Eisenhower in October 1945 stated his position to the press as " ... I say let Germany find out what it means to start a war."
In a chapter in a multi-author book published in 2003, Richard Dominic Wiggers argued that the Allies violated international law regarding the feeding of enemy civilians, they both directly and indirectly caused the unnecessary suffering and death of large numbers of civilians and POWs in occupied Germany, guided partly by a spirit of postwar vengeance when creating the circumstances that contributed to their deaths. Wiggers claimed that, throughout all of 1945, the Allies forces of occupation ensured that no international aid reached ethnic Germans. It was directed that all relief went to non-German displaced persons, liberated Allied POWs, and concentration camp inmates. Wiggers cited General Lucius Clay, then Deputy to General Eisenhower statement that: "I feel that the Germans should suffer from hunger and from cold as I believe such suffering is necessary to make them realize the consequences of a war which they caused ... this type of suffering should not extend to the point where it results in mass starvation and sickness."
Other sources on food distribution problems.
A comparative U.S. government study run by former U.S. President Herbert Hoover in 1945 and published in February 1947, found that the nutritional situation in many of Germany's neighbor states was close to pre-war levels, while the nutritional situation for certain population groups in Germany (mainly children and the elderly) was disastrously low.
Large quantities of food were being offered to Germany. However, due to allied restrictions on German trade all the offers were rejected and in one case, this resulted in Holland being forced to destroy a large proportion of their vegetable crop and as late as 1948 Swedish fishermen were still destroying their surplus catch or working only two days a week due to a lack of markets. By May 1945, the ICRC had 100,000 tons of food in storage warehouses in Switzerland and in August the Red Cross shipped 30,000 tons of high protein food parcels by rail to feed displaced persons in Germany but was forced to return them to storage where they eventually spoiled. A further 13.5 million Red Cross rations stockpiled in Europe were confiscated by the military and were never distributed. Senator Kenneth S. Wherry later complained about the "thousands upon thousands" of tons of rations spoiling amid a starving population. Max Huber, head of the International Red Cross, wrote a letter to the U.S. State Department in which he described the difficulties placed by SHAEF in the way of the ICRC efforts to provide aid. Huber received a letter in response, signed by Eisenhower, stating that giving Red Cross food to enemy personnel was forbidden. The refusal to distribute the aid has been explained by some modern historians such as Stephen Ambrose, as due to a need to stockpile food in expectation of a famine.
Lack of records.
There are no longer any surviving records showing which German POWs and Disarmed Enemy Forces were in U.S. custody prior to roughly September 1945. The early standard operating procedure for handling POWs and Disarmed Enemy Forces was to send a copy of the POW form to the Central Registry of War Criminals and Security Suspects (CROWCASS). However, this practice was apparently stopped as impractical, and all copies of the POW forms, roughly eight million, were destroyed. By way of contrast, the Soviet archives contain dossiers for every German POW they held, averaging around 15 pages for each.
References.
Primary
Secondary

Panama Canal Zone
The Panama Canal Zone () was a unorganized US territory located within the Republic of Panama, consisting of the Panama Canal and an area generally extending on each side of the centerline, but excluding Panama City and Colón, which otherwise would have been partly within the limits of the Canal Zone. Its border spanned two of Panama's provinces and was created on November 18, 1903, with the signing of the Hay–Bunau-Varilla Treaty. When reservoirs were created to assure a steady supply of water for the locks, those lakes were included within the Zone.
On February 26, 1904, the Isthmian Canal Convention was proclaimed. In it, the Republic of Panama granted to the United States in perpetuity the use, occupation, and control of a zone of land and land under water for the construction, maintenance, operation, sanitation, and protection of the canal. 
From 1903 to 1979 the territory was controlled by the United States, which had built the canal and financed its construction. From 1979 to 1999 the canal itself was under joint U.S.–Panamanian control. In 1977 the Torrijos-Carter Treaties established the neutrality of the canal.
Except during times of crisis or political tension, Panamanians could freely enter the Zone. In fact, normally anyone could walk across a street in Panama City and enter the jurisdiction. However, the 1903 treaty restricted the rights of Panamanians to buy at retail stores in the Zone.
During the period of US control of the Canal Zone, the territory, apart from the canal itself, was used mainly for military purposes; however, approximately 3,000 American civilians (called "Zonians") made up the core of permanent residents. US military usage ended when the zone was returned to Panamanian control. It has now been integrated into the economic development of Panama, and is a tourist destination of sorts, especially for visiting cruise ships.
Notable people born in the Panama Canal Zone include Richard Prince, Kenneth Bancroft Clark, Rod Carew, geologist Thomas H. Jordan, Edward A. Murphy, Jr., and John McCain, the Republican 2008 presidential candidate and US Senator from Arizona.
The largest US Army unit based in the Canal Zone was the 193rd Infantry Brigade (Light), a mixed parachute-infantry/air-assault-capable light infantry unit. It was honored in 1994 as the first major unit to deactivate in accordance with the Panama Canal Treaty of 1977 implementation plan. The brigade was reactivated in 2007, tasked with conducting basic combat training for new US Army recruits.
Documentary filmmaker Frederick Wiseman made a film about the Panama Canal Zone, entitled "Canal Zone", which was released and aired on PBS in 1977.
History.
Proposals for a canal.
Proposals for a canal across the Isthmus of Panama date back to 1529, soon after the Spanish conquest. Álvaro de Saavedra Cerón, one of the lieutenants of conquistador Vasco Núñez de Balboa, suggested four possible routes, one of which closely tracks the present-day canal. Saavedra believed that such a canal would make it easier for European vessels to reach Asia. Although King Carlos I was enthusiastic, and ordered preliminary works started, his officials in Panama soon realized that such an undertaking was beyond the capabilities of 16th-century technology. One official wrote to Carlos, "I pledge to Your Majesty that there is not a prince in the world with the power to accomplish this". The Spanish instead built a road across the isthmus. The road came to be crucial to Spain's economy as treasure obtained along the Pacific coast of South America was offloaded at Panama City and hauled through the jungle to the Atlantic port of Nombre de Dios (today Colón), and though additional canal building proposals were made throughout the 16th and 17th centuries, they came to naught.
The late 18th and early 19th centuries saw a number of canals built. The success of the Erie Canal in the United States and the collapse of the Spanish Empire in Latin America led to a surge of American interest in building an interoceanic canal. Beginning in 1826, American officials began negotiations with New Granada (present-day Colombia and Panama), hoping to gain a concession for the building of a canal. Jealous of their newly obtained independence and fearing that they would be dominated by an American presence, New Granadan officials declined American offers. The new nation was politically unstable, and Panama rebelled several times during the 19th century.
In 1836, US statesman Charles Biddle reached an agreement with the New Granadan government to replace the old road with an improved one or a railroad, running from Panama City on the Pacific coast to the Chagres River, where a steamship service would allow passengers and freight to continue to Colón. His agreement was repudiated by the Jackson administration, which wanted rights to build a canal. In 1841, with Panama in rebellion again, British interests secured a right-of-way over the isthmus from the insurgent regime, and occupied Nicaraguan ports that might have served as the Atlantic teminus of a canal. In 1846, the new US envoy to Bogotá, Benjamin Bidlack, was surprised when, soon after his arrival, the New Granadans proposed that the United States be the guarantor of the neutrality of the isthmus. The resulting Mallarino–Bidlack Treaty allowed the United States to intervene militarily to ensure that the interoceanic road (and when it was built, the Panama Railroad as well) would not be disrupted. New Granada hoped that other nations would sign similar treaties, but the one with the United States, which was ratified by the US Senate in June 1848 after considerable lobbying by New Granada, was the only one.
The treaty led the US government to contract for steamship service to Panama from ports on both coasts. When the California gold rush began in 1848, traffic through Panama greatly increased, and New Granada agreed to allow the Panama Railroad to be constructed by American interests. This first "transcontinental railroad" opened in 1850. There were riots in Panama CIty in 1856; several Americans were killed. US warships landed Marines, who occupied the railroad station and kept the railroad service from being interrupted by the unrest. The United States demanded compensation from New Granada, including a zone wide, to be governed by US officials and in which the United States might build any "railway or passageway" it desired. The demand was dropped in the face of resistance by New Granadan officials, who accused the United States of seeking a colony.
Through the remainder of the 19th century, the United States landed troops several times to preserve the railway connection. At the same time, it pursued a canal treaty with Colombia (as New Granada was renamed). One treaty, signed in 1868, was rejected by the Colombian Senate, which hoped for better terms from the incoming Grant administration. Under this treaty, the canal would have been in the middle of a 20-mile zone, under American management but Colombian sovereignty, and the canal would revert to Colombia in 99 years. The Grant administration did little to pursue a treaty, and in 1878, the concession to build the canal fell to a French firm. The French efforts eventually failed, but with Panama apparently unavailable, the United States considered possible canal sites in Mexico and Nicaragua.
The Spanish-American War of 1898 added new life to the canal debate. During the war, American warships in the Atlantic seeking to reach battle zones in the Pacific had been forced to round Cape Horn. Influential naval pundits, such as Captain Alfred Thayer Mahan, urged the construction of a Central American canal. In 1902, with the French efforts moribund, US President Theodore Roosevelt backed the Panama route, and Congress passed legislation authorizing him to purchase the French assets on the condition that an agreement was reached with Colombia. In March 1902, Colombia set its terms for such a treaty: Colombia was to be sovereign over the canal, which would be policed by Colombians paid for by the United States. The host nation would receive a larger percentage of the tolls than provided for in earlier draft treaties. The draft terms were quickly rejected by American officials. Roosevelt was in a hurry to secure the treaty; the Colombians, to whom the French property would revert in 1904, were not. Negotiations dragged on into 1903, during which time there was unrest in Panama CIty and Colón; the United States sent in Marines to guard the trains. Nevertheless, in early 1903, the United States and Colombia signed a treaty which, despite Colombia's previous objections, gave the United States a wide zone in which it could deploy troops with Colombian consent. On August 12, 1903, the Colombian Senate voted down the treaty, 24–0.
Roosevelt was angered by the Colombians' actions, especially when the Colombian Senate made a counteroffer that was more financially advantageous to Colombia. A Frenchman who had worked on his nation's canal efforts, Philippe Bunau-Varilla, represented Panamanian insurgents; he met with Roosevelt and with Secretary of State John Hay, who saw to it that his principals received covert support. When the revolution came in November 1903, the United States intervened to protect the rebels, who succeeded in taking over the province, declaring it independent as the Republic of Panama. Bunau-Varilla was initially the Panamanian representative in the United States, though he was about to be displaced by actual Panamanians, and hastily negotiated a treaty, giving the United States a zone wide and full authority to pass laws to govern that zone. The Panama Canal Zone (Canal Zone, or Zone) excluded Panama City and Colón,but included four offshore islands, and permitted the United States to add to the zone any additional lands needed to carry on canal operations. The Panamanians were minded to disavow the treaty, but Bunau-Varilla told the new government that if Panama did not agree, the United States would withdraw its protection and make the best terms it could with Colombia. The Panamanians agreed, even adding a provision to the new constitution, at US request, allowing the larger nation to intervene to preserve public order.
Construction years (1903–14).
The treaty was approved by the provisional Panamanian government on December 2, 1903, and by the US Senate on February 23, 1903. Under the treaty, the Panamanians received $10 million, much of which the United States required to be invested in that country, plus annual payments of $250,000; with those payments made, as well as for the purchase of the French company assets, the Canal Zone was formally turned over by Panama on May 4, 1904, when American officials reopened the Panama City offices of the canal company and raised the American flag.
Governance of the Canal Zone.
The canal was operated by the Panama Canal Company until 1979, when the Panama Canal Commission took over its governance until December 31, 1999. This situation was described as a cross between a colonial company enclave and a socialist government. Everyone worked for the Company or the government in one form or another. There were no independent stores, goods were brought in and sold at a series of stores run by the company, such as a commissary, housewares, and so forth. Although denied by the government, for many years there was blatant racism in the Zone, with "gold" and "silver" facilities separated largely on the basis of color.
The Canal Zone had its own police force (the Canal Zone Police), courts, and judges (the United States District Court for the Canal Zone). 
The head of the company was also the Governor of the Panama Canal Zone. Residents did not own their homes; instead, they rented houses assigned primarily based on seniority in the zone. When an employee moved away, the house would be listed and employees could apply for it. The utility companies were also managed by the company.
Tensions and the end of the Canal Zone.
In 1903, the United States, having failed to obtain from Colombia the right to build a canal across the Isthmus of Panama, which was part of that country, sent warships in support of Panamanian independence from Colombia. This being achieved, the new nation of Panama ceded to the Americans the rights they wanted in the Hay–Bunau-Varilla Treaty. Over time, though, the existence of the Canal Zone, a political exclave of the United States that cut Panama geographically in half and had its own courts, police, and civil government, became a cause of conflict between the two countries. Demonstrations occurred at the opening of the Bridge of the Americas in 1962 and serious rioting occurred in 1964. This led to the United States easing its controls in the Zone. For example, Panamanian flags were allowed to be flown alongside American ones. After extensive negotiations, the Canal Zone ceased to exist on October 1, 1979, in compliance with provisions of the Torrijos-Carter Treaties.
Lifestyle of residents.
Gold Roll and Silver Roll.
From its first days, the labor force in the Canal Zone (which was almost entirely publicly employed) was divided into a Gold Roll, upon which an employee's name was enrolled, and a Silver Roll. The origins of this system are unclear, but it was the practice on the 19th-century Panama Railroad to pay Americans in US gold and local workers in silver coin. Although some Canal Zone officials compared the Gold Roll to military officers and Silver Roll to enlisted men, the characteristic that determined on which roll an employee was placed was race. With very few exceptions, American and Northern European whites were placed on the Gold Roll, blacks and southern European whites on the Silver Roll. American blacks were generally not hired; black employees were from the Caribbean, often from Barbados. American whites seeking work as laborers, which were almost entirely Silver Roll positions, were discouraged from applying. In the early days of the system, bosses could promote exceptional workers from Silver to Gold, but this practice soon ceased as race came to be the determining factor. As a result of the initial policy, there were several hundred skilled blacks and southern Europeans on the Gold Roll. In November 1906, Chief Engineer John Stevens ordered that most blacks on the Gold Roll be placed on a silver roll instead (a few remained in such roles as teachers and postmasters); the following month the Canal Commission reported that the 3,700 Gold Roll employees were "almost all white Americans" and the 13,000 Silver Roll workers were "mostly aliens". On February 8, 1908, President Roosevelt ordered that no further non-Americans be placed on the Gold Roll. After Panamanians objected, the Gold Roll was reopened to them in December 1908; however, efforts to remove blacks and non-Americans from the Gold Roll continued.
Until 1918, when all employees began to be paid in US dollars, Gold Roll employees were paid in gold, in American currency, while their Silver Roll counterparts were paid in silver coin, initially in Colombian pesos. Through the years of canal construction, Silver Roll workers were paid with coins from various nations; in several years, coin was imported from the United States because of local shortages. Even after 1918, both the designations and the disparity in privileges lingered.
Community.
Housing and goods.
Canal Zone housing was constructed in the early days of construction, as part of Stevens' plans. Housing constructed for couples and families consisted of structures containing four two-story apartments. The units had corrugated-iron roofs, and were uniformly painted gray with white trim. Constructed of pine clapboard, they had long windows and high ceilings, allowing for air movement. Better-paid employees were entitled to more square feet of housing, the unit in which allowances were expressed. Initially, employees received one square foot per dollar of monthly salary. Stevens from the first encouraged Gold Roll employees to send for their wives and children; to encourage them to do so, wives were granted a housing allowance equal to their husband's, even if they were not employees. Bachelors mostly resided in hotel-like structures. The structures all had screened verandas and up-to-date plumbing. The government furnished power, water, coal for cooking, ice for iceboxes, lawn care, groundskeeping, garbage disposal, and, for bachelors only, maid service.
In the first days of the Canal Zone, the ICC provided no food, and workers had to fend for themselves, obtaining poor-quality food at inflated prices from Panamanian merchants. When Stevens arrived in 1905, he ordered food to be provided at cost, leading to the establishment of the Canal Zone Commissary. The functions of the Commissary quickly grew, generally against the will of the Panamanian government, which saw more and more goods and services provided in the Zone rather than in Panama. Merchants could not compete with the commissary's prices or quality; for example, it boasted that the meat it sold had been refrigerated every moment from the Chicago slaughterhouse to the moment it was passed to the consumer. By 1913, it consisted of 22 general stores, seven cigar stores, seventeen hostels, two hotels, and a mail-order division. It served high-quality meals at small expense to workers, and more expensive meals to upper-echelon Canal employees and others able to afford it.
The commissary was a source of friction between the Canal Zone and Panama for several other reasons. The commissary dominated sales of supplies to passing ships, and Panamanian merchants could make no sales within Canal Zone waters. The commissary was off-limits to Panamanians who were not resident in the Canal Zone or employed there, a restriction nominally for the benefit of Panamanian storekeepers, who feared the loss of trade. Panama had laws restricting imports from the Canal Zone, which were indifferently enforced. Goods from the commissary would sometimes show up in Panamanian stores and in vendor displays, where "Comisariato" goods were deemed of high quality.
Citizenship.
Although the Panama Canal Zone was legally an unincorporated US territory until the implementation of the Torrijos-Carter Treaties in 1979, questions arose almost from its inception as to whether the Zone was considered part of the United States for constitutional purposes, or, in the phrase of the day, whether the Constitution followed the flag. In 1901 the US Supreme Court had ruled in "Downes v. Bidwell" that unincorporated territories are not the United States. On July 28, 1904, Controller of the Treasury Robert Tracewell stated, "While the general spirit and purpose of the Constitution is applicable to the zone, that domain is not a part of the United States within the full meaning of the Constitution and laws of the country." Accordingly, the Supreme Court held in 1905 in "Rasmussen v. United States" that the full Constitution only applies for incorporated territories of the United States. This no man's land with regard to US citizenship was perpetuated until Congress passed legislation in 1937 that corrected this deficiency. The law is now codified under title 8, section 1403. It not only grants statutory and declaratory born citizenship to those born in the Canal Zone after February 26, 1904, of at least one US citizen parent, but also does so retroactively for all children born of at least one US citizen in the Canal Zone before the law's enactment.
In 2008, during a minor controversy over whether Canal Zone–born John McCain was legally eligible for the presidency, the US Senate passed a resolution putting the question to rest, declaring McCain a "natural born citizen" of the United States.
Townships and military installations.
The Canal Zone was generally divided into two sections, the Pacific Side and the Atlantic Side, with Gatun Lake separating them.
Postage stamps.
The Panama Canal Zone issued its own postage stamps from 1904 until October 25, 1978. After a transition period, Panama administered the stamps.

Philippines
The Philippines ( ), officially known as the Republic of the Philippines (), is a sovereign state in Southeast Asia in the western Pacific Ocean. To its north across the Luzon Strait lies Taiwan. West across the South China Sea sits Vietnam. The Sulu Sea to the southwest lies between the country and the island of Borneo, and to the south the Celebes Sea separates it from other islands of Indonesia. It is bounded on the east by the Philippine Sea. Its location on the Pacific Ring of Fire and its tropical climate make the Philippines prone to earthquakes and typhoons but have also endowed the country with natural resources and made it one of the richest areas of biodiversity in the world. An archipelago comprising 7,107 islands, the Philippines is categorized broadly into three main geographical divisions: Luzon, Visayas, and Mindanao. Its capital city is Manila.
With a population of more than 92 million people, the Philippines is the 7th most populated Asian country and the 12th most populated country in the world. An additional 12 million Filipinos live overseas. Multiple ethnicities and cultures are found throughout the islands. In prehistoric times, Negritos were some of the archipelago's earliest inhabitants. They were followed by successive waves of Austronesian peoples who brought with them influences from Malay, Hindu, and Islamic societies. Trade and subsequent Chinese settlement eventually introduced Chinese cultural influences which remain to this day.
The arrival of Ferdinand Magellan in 1521 marked the beginning of an era of Spanish interest and eventual colonization. In 1543, Spanish explorer Ruy López de Villalobos named the archipelago "Las Islas Filipinas" in honor of Philip II of Spain. Miguel López de Legazpi arrived in the Philippines in 1565 and consolidated Spanish rule in the islands, which remained a colony of Spain for more than 300 years.
Manila became the Asian hub of the Manila–Acapulco galleon fleet. As the 19th century gave way to the 20th, there followed in quick succession the Philippine Revolution, which spawned the short-lived First Philippine Republic; the Spanish-American War; and the Philippine–American War. In the aftermath, the United States emerged as the dominant power; aside from the period of Japanese occupation, the United States retained sovereignty over the islands until the end of World War II when the Philippines gained independence. Since then, the Philippines has had an often tumultuous experience with democracy, with popular "people power" movements overthrowing a dictatorship in one instance but also underlining the institutional weaknesses of its constitutional republic in others.
Etymology.
The name "Philippines" is derived from that of King Philip II of Spain. Spanish explorer Ruy López de Villalobos during his expedition in 1542 named the islands of Leyte and Samar "Felipinas" after the then Prince of Asturias. Eventually the name "Las Islas Filipinas" would be used to cover all the islands of the archipelago. Before that became commonplace, other names such as "Islas del Poniente" (Islands of the West) and Magellan's name for the islands "San Lázaro" were also used by the Spanish to refer to the islands.
The official name of the Philippines has changed several times in the course of the country's history. During the Philippine Revolution, the Malolos Congress proclaimed the establishment of the "República Filipina" or the "Philippine Republic". From the period of the Spanish-American War and the Philippine–American War until the Commonwealth period, American colonial authorities referred to the country as the "Philippine Islands", a translation of the Spanish name. During the American period, the name "Philippines" began to appear and it has since become the country's common name. Since independence, the official name of the country has been the "Republic of the Philippines".
History.
The metatarsal of Callao Man is reported to have been reliably dated by uranium-series dating to 67,000 years ago thereby replacing the Tabon Man of Palawan, carbon-dated to around 24,000 years ago, as the oldest human remains found in the archipelago. Negritos were among the archipelago's earliest inhabitants, but their appearance in the Philippines has not been reliably dated. There are several opposing theories regarding the origins of ancient Filipinos. F. Landa Jocano theorizes that the ancestors of the Filipinos evolved locally. Wilhelm Solheim's Island Origin Theory postulates that the peopling of the archipelago transpired via trade networks originating in the antediluvian Sundaland area around 48000 to 5000 BCE rather than by wide-scale migration. The Austronesian Expansion Theory states that Malayo-Polynesians coming from Taiwan began migrating to the Philippines around 4000 BCE, displacing earlier arrivals. Whatever the case, by 1000 BCE the inhabitants of the archipelago had developed into four kinds of social groups: hunter-gathering tribes, warrior societies, petty plutocracies, and maritime-centered harbor principalities.
Trade between the maritime-oriented peoples and other Asian countries during the subsequent period brought influences from Hinduism, Buddhism, and Islam. During this time there was no unifying political state encompassing the entire Philippine Archipelago. Instead, the islands were divided among competing thalassocracies ruled by various datus, rajahs, or sultans. These thalassocracies were composed of autonomous barangays which were independent to or allied with larger nations. Among them were the kingdoms of Maynila, Namayan, and Tondo, the confederation of Madyaas, the state of Ma-i, the rajahnates of Butuan and Cebu, and the sultanates of Maguindanao and Sulu. Some of these societies were part of the Malayan empires of Srivijaya, Majapahit, and Brunei. Islam was brought to the Philippines by traders and proselytizers from Malaysia and Indonesia. By the 15th century, Islam was established in the Sulu Archipelago and by 1565 had reached Mindanao, the Visayas, and Luzon.
In 1521, Portuguese explorer Ferdinand Magellan arrived in the Philippines and claimed the islands for Spain.
Colonization began when Spanish explorer Miguel López de Legazpi arrived from Mexico in 1565 and formed the first European settlements in Cebu. In 1571, after dealing with the local royal families in the wake of the Tondo Conspiracy and defeating the Chinese pirate warlord Limahong, the Spanish established Manila as the capital of the Spanish East Indies.
Spanish rule contributed significantly to bringing political unity to the archipelago. From 1565 to 1821, the Philippines was governed as a territory of the Viceroyalty of New Spain and then was administered directly from Madrid after the Mexican War of Independence. The Manila galleons linking Manila to Acapulco traveled once or twice a year between the 16th and 19th centuries. Trade introduced foods such as corn, tomatoes, potatoes, chili peppers, and pineapples from the Americas. Roman Catholic missionaries converted most of the lowland inhabitants to Christianity and founded schools, a university, and hospitals. While a Spanish decree introduced free public schooling in 1863, efforts in mass public education mainly came to fruition during the American period.
During its rule, the Spanish fought off various indigenous revolts and several external colonial challenges from Chinese pirates, the Dutch, and the Portuguese. In an extension of the fighting of the Seven Years' War, British forces under the command of Brigadier General William Draper and Rear-Admiral Samuel Cornish briefly occupied Manila. They found local allies like Diego and Gabriela Silang who took the opportunity to lead a revolt, but Spanish rule was eventually restored following the 1763 Treaty of Paris.
In the 19th century, Philippine ports were opened to world trade and shifts were occurring within Philippine society. Many Spaniards born in the Philippines ("criollos") and those of mixed ancestry ("mestizos") became wealthy. The influx of Spanish and Latino settlers secularized churches and opened up government positions traditionally held by Spaniards born in the Iberian Peninsula ("peninsulares"). The ideals of revolution also began to spread through the islands. "Criollo" dissatisfaction resulted in the revolt in Cavite El Viejo in 1872 that was a precursor to the Philippine Revolution.
Revolutionary sentiments were stoked in 1872 after three priests—Mariano Gómez, José Burgos, and Jacinto Zamora (collectively known as Gomburza)—were accused of sedition by colonial authorities and executed. This would inspire a propaganda movement in Spain, organized by Marcelo H. del Pilar, José Rizal, and Mariano Ponce, lobbying for political reforms in the Philippines. Rizal was eventually executed on December 30, 1896, on charges of rebellion. As attempts at reform were meeting with resistance, Andrés Bonifacio in 1892 established the secret society called the Katipunan, a society along the lines of the freemasons, which sought independence from Spain through armed revolt. Bonifacio and the Katipunan started the Philippine Revolution in 1896. A faction of the Katipunan, the Magdalo of Cavite province, eventually came to challenge Bonifacio's position as the leader of the revolution and Emilio Aguinaldo took over. In 1898, the Spanish-American War began in Cuba and reached the Philippines. Aguinaldo declared Philippine independence from Spain in Kawit, Cavite on June 12, 1898 and the First Philippine Republic was established the following year. Meanwhile, the islands were ceded by Spain to the United States for US$20 million in the 1898 Treaty of Paris. As it became increasingly clear the United States would not recognize the First Philippine Republic, the Philippine–American War broke out. It ended with American control over the islands which were then administered as an insular area.
In 1935, the Philippines was granted Commonwealth status. Plans for independence over the next decade were interrupted by World War II when the Japanese Empire invaded and established a puppet government. Many atrocities and war crimes were committed during the war such as the Bataan Death March and the Manila massacre that culminated during the Battle of Manila. Allied troops defeated the Japanese in 1945. By the end of the war it is estimated over a million Filipinos had died.
On July 4, 1946, the Philippines attained its independence.
Immediately after World War II, the Philippines faced a number of challenges. The country had to be rebuilt from the ravages of war. It also had to come to terms with Japanese collaborators. Meanwhile, disgruntled remnants of the Hukbalahap communist rebel army that had previously fought against and resisted the Japanese continued to roam the rural regions. This threat to the government was dealt with by Secretary of National Defense and later President Ramon Magsaysay, but sporadic cases of communist insurgency continued to flare up long afterward.
In 1965, Ferdinand Marcos was elected president. Nearing the end of his second term and constitutionally barred from seeking a third, he declared martial law on September 21, 1972. By using political divisions, the tension of the Cold War, and the specter of communist rebellion and Islamic insurgency as justifications, he governed by decree.
On August 21, 1983, Marcos' chief rival opposition leader Benigno "Ninoy" Aquino, Jr. ignored warnings and returned from exile in the United States. He was assassinated as he was taken off the plane at the Manila International Airport (now called the Ninoy Aquino International Airport in his memory). With political pressure building, Marcos eventually called for snap presidential elections in 1986. Corazon Aquino, Benigno's widow, was persuaded to become the presidential candidate and standard bearer of the opposition. The elections were widely considered rigged when Marcos was proclaimed the winner. This led to the People Power Revolution, instigated when two long-time Marcos allies—Armed Forces of the Philippines Vice Chief-of-Staff Fidel V. Ramos and Secretary of National Defense Juan Ponce Enrile—resigned and barricaded themselves in Camp Aguinaldo and Camp Crame. Exhorted by the Cardinal Archbishop of Manila Jaime Sin, people gathered in support of the rebel leaders and protested on Epifanio de los Santos Avenue (EDSA). In the face of mass protests and military defections, Marcos and his allies fled to Hawaii and into exile. Corazon Aquino was recognized as president.
The return of democracy and government reforms after the events of 1986 were hampered by national debt, government corruption, coup attempts, a persistent communist insurgency, and Islamic separatists. The economy improved during the administration of Fidel V. Ramos, who was elected president in 1992. However, the economic improvements were negated with the onset of the East Asian financial crisis in 1997. In 2001, amid charges of corruption and a stalled impeachment process, Ramos' successor Joseph Estrada was ousted from the presidency by the 2001 EDSA Revolution and replaced by Gloria Macapagal-Arroyo. Her administration that lasted 9 years was tied with graft and corruption and numerous political scandals. As a result of the May 2010 elections, Benigno "Noynoy" Aquino III was elected president.
Politics and government.
The Philippines has a democratic government. It is a constitutional republic with a presidential system. It is governed as a unitary state with the exception of the Autonomous Region in Muslim Mindanao which is largely free from the national government. The President functions as both head of state and head of government and is the commander-in-chief of the armed forces. The president is elected by popular vote for a single six-year term, during which he or she appoints and presides over the cabinet.
The bicameral Congress is composed of the Senate, serving as the upper house, with members elected to a six-year term, and the House of Representatives, serving as the lower house, with members elected to a three-year term. The senators are elected at large while the representatives are elected from both legislative districts and through sectoral representation.
The judicial power is vested in the Supreme Court, composed of a Chief Justice as its presiding officer and fourteen associate justices, all of whom are appointed by the President from nominations submitted by the Judicial and Bar Council.
There have been attempts to change the government to a federal, unicameral, or parliamentary government since the Ramos administration.
Security and defense.
Philippine defense is handled by the Armed Forces of the Philippines and is composed of three branches: the Air Force, the Army, and the Navy (including the Marine Corps). Civilian security is handled by Philippine National Police under the Department of the Interior and Local Government (DILG).
In the Autonomous Region in Muslim Mindanao, the largest separatist organization, the Moro National Liberation Front, is now engaging the government politically. Other more militant groups like the Moro Islamic Liberation Front, the communist New People's Army, and the Abu Sayyaf still roam the provinces, but their presence has decreased in recent years due to successful security provided by the Philippine government.
The Philippines has been an ally of the United States since World War II. A mutual defense treaty between the two countries was signed in 1951. The Philippines supported American policies during the Cold War and participated in the Korean and Vietnam wars. It was a member of the now dissolved SEATO, a group that was intended to serve a role similar to NATO and that included Australia, France, New Zealand, Pakistan, Thailand, the United Kingdom, and the United States. After the start of the War on Terror, the Philippines was part of the coalition that gave support to the United States in Iraq. The United States designated the country a major non-NATO ally. The Philippines is currently working to end its domestic insurgency with help from the United States.
International relations.
The Philippines' international relations are based on trade with other nations and the well-being of the 11 million overseas Filipinos living outside the country. As a founding and active member of the United Nations, the Philippines has been elected several times into the Security Council. Carlos P. Romulo was a former President of the United Nations General Assembly. The country is an active participant in the Human Rights Council as well as in peacekeeping missions, particularly in East Timor. 
In addition to membership in the United Nations, the country is also a founding and active member of ASEAN (Association of Southeast Asian Nations), an organization designed to strengthen relations and promote economic and cultural growth among states in the Southeast Asian region. It has hosted several summits and is an active contributor to the direction and policies of the bloc. The relations it currently enjoys with other Southeast Asian states are in contrast to its relations with them before the 1970s when it was one of the allies of the US Forces against, with then the North Vietnam and was heavily disputing Sabah with Malaysia; although, disagreements continue to exist due to the Spratly Islands.
The Philippines values its relations with the United States. It supported the United States during the Cold War and the War on Terror and is a major non-NATO ally. Despite this history of goodwill, controversies related to the presence of the now former U.S. military bases in Subic Bay and Clark and the current Visiting Forces Agreement have flared up from time to time. Japan, the biggest contributor of official development assistance to the country, is thought of as a friend. Although historical tensions still exist on issues such as the plight of comfort women, much of the animosity inspired by memories of World War II have faded.
Relations with other nations are generally positive. Shared democratic values ease relations with Western and European countries while similar economic concerns help in relations with other developing countries. Historical ties and cultural similarities also serve as a bridge in relations with Spain and Latin America. Despite issues such as domestic abuse and war affecting overseas Filipino workers and obstacles posed by Islamic insurgency in Mindanao, relations with Middle Eastern countries (including Egypt, Iran, Iraq, Libya, Saudi Arabia, and the United Arab Emirates) are friendly as seen in the continuous employment of more than two million overseas Filipinos living there.
With communism no longer the threat it once was, once hostile relations in the 1950s between the Philippines and the People's Republic of China have improved greatly. Issues involving Taiwan, the Spratly Islands, and concerns of expanding Chinese influence, however, still encourage a degree of carefulness. Recent foreign policy has been mostly about economic relations with its Southeast Asian and Asia-Pacific neighbors.
The Philippines is a member of the East Asia Summit (EAS), the Asia-Pacific Economic Cooperation (APEC), the Latin Union, the Group of 24, and the Non-Aligned Movement. It is also seeking to strengthen relations with Islamic countries by campaigning for observer status in the Organisation of Islamic Cooperation.
Administrative divisions.
The Philippines is divided into three island groups: Luzon, Visayas, and Mindanao. , these were divided into 17 regions, 80 provinces, 138 cities, 1,496 municipalities, and 42,025 barangays. In addition, Section 2 of Republic Act No. 5446 asserts that the definition of the territorial sea around the Philippine archipelago does not affect the claim over Sabah.
Geography.
The Philippines is an archipelago of 7,107 islands with a total land area, including inland bodies of water, of approximately . Its of coastline makes it the country with the 5th longest coastline in the world. It is located between 116° 40', and 126° 34' E. longitude and 4° 40' and 21° 10' N. latitude and is bordered by the Philippine Sea to the east, the South China Sea to the west, and the Celebes Sea to the south. The island of Borneo is located a few hundred kilometers southwest and Taiwan is located directly to the north. The Moluccas and Sulawesi are located to the south-southwest and Palau is located to the east of the islands.
Most of the mountainous islands are covered in tropical rainforest and volcanic in origin. The highest mountain is Mount Apo. It measures up to 2,954 meters (9,692 feet) above sea level and is located on the island of Mindanao. The Galathea Depth in the Philippine Trench is the deepest point in the country and the third deepest in the world. The trench is located in the Philippine Sea. The longest river is the Cagayan River in northern Luzon. Manila Bay, upon the shore of which the capital city of Manila lies, is connected to Laguna de Bay, the largest lake in the Philippines, by the Pasig River. Subic Bay, the Davao Gulf, and the Moro Gulf are other important bays. The San Juanico Strait separates the islands of Samar and Leyte but it is traversed by the San Juanico Bridge.
Situated on the western fringes of the Pacific Ring of Fire, the Philippines experiences frequent seismic and volcanic activity. The Benham Plateau to the east in the Philippine Sea is an undersea region active in tectonic subduction. Around 20 earthquakes are registered daily, though most are too weak to be felt. The last major earthquake was the 1990 Luzon earthquake. There are many active volcanoes such as the Mayon Volcano, Mount Pinatubo, and Taal Volcano. The eruption of Mount Pinatubo in June 1991 produced the second largest terrestrial eruption of the 20th century. Not all notable geographic features are so violent or destructive. A more serene legacy of the geological disturbances is the Puerto Princesa Subterranean River. The white sand beaches that make Boracay a popular vacation getaway are made of coral remnants.
Due to the volcanic nature of the islands, mineral deposits are abundant. The country is estimated to have the second-largest gold deposits after South Africa and one of the largest copper deposits in the world. It is also rich in nickel, chromite, and zinc. Despite this, poor management, high population density, and environmental consciousness have resulted in these mineral resources remaining largely untapped. Geothermal energy, however, is another product of volcanic activity that the country has harnessed more successfully. The Philippines is the world's second-biggest geothermal producer behind the United States, with 18% of the country's electricity needs being met by geothermal power.
Flora and fauna.
The Philippines' rainforests and its extensive coastlines make it home to a diverse range of birds, plants, animals, and sea creatures. It is one of the ten most biologically megadiverse countires and is at or near the top in terms of biodiversity per unit area. Around 1,100 land vertebrate species can be found in the Philippines including over 100 mammal species and 170 bird species not thought to exist elsewhere. Endemic species include the tamaraw of Mindoro, the Visayan spotted deer, the Philippine mouse deer, the Visayan warty pig, the Philippine flying lemur, and several species of bats.
The Philippines lacks large predators, with the exception of snakes, such as pythons and cobras, saltwater crocodiles and birds of prey, such as the national bird, known as the Philippine Eagle, which scientists suggest as the largest eagle in the world. The largest crocodile in captivity was captured in the southern island of Mindanao. Other native animals include the palm civet cat, the dugong, and the Philippine tarsier associated with Bohol. With an estimated 13,500 plant species in the country, 3,200 of which are unique to the islands, Philippine rainforests boast an array of flora, including many rare types of orchids and rafflesia. The narra is considered as the most important type of hardwood.
Philippine maritime waters encompass as much as 2.2 million square kilometers (850,000 square miles) producing unique and diverse marine life and is an important part of the Coral Triangle. There are 2,400 fish species and over 500 species of coral. The Apo Reef is the country's largest contiguous coral reef system and the second-largest in the world. Philippine waters also sustain the cultivation of pearls, crabs, and seaweeds.
Deforestation, often the result of illegal logging, is an acute problem in the Philippines. Forest cover declined from 70% of the country's total land area in 1900 to about 18.3% in 1999. Many species are endangered and scientists say that Southeast Asia, which the Philippines is part of, faces a catastrophic extinction rate of 20% by the end of the century. According to Conservation International, "the country is one of the few nations that is, in its entirety, both a hotspot and a megadiversity country, placing it among the top priority hotspots for global conservation."
Climate.
The Philippines has a tropical maritime climate and is usually hot and humid. There are three seasons: "tag-init" or "tag-araw", the hot dry season or summer from March to May; "tag-ulan", the rainy season from June to November; and "tag-lamig", the cool dry season from December to February. The southwest monsoon (from May to October) is known as the Habagat, and the dry winds of the northeast monsoon (from November to April), the Amihan. Temperatures usually range from 21°C (70°F) to 32°C (90°F) although it can get cooler or hotter depending on the season. The coolest month is January; the warmest is May.
The average yearly temperature is around 26.6°C (79.88°F). In considering temperature, location in terms of latitude and longitude is not a significant factor. Whether in the extreme north, south, east, or west of the country, temperatures at sea level tend to be in the same range. Altitude usually has more of an impact. The average annual temperature of Baguio at an elevation of 1,500 meters (4,900 feet) above sea level is 18.3°C (64.9°F), making it a popular destination during hot summers. Likewise, Tagaytay is a favored retreat.
Sitting astride the typhoon belt, most of the islands experience annual torrential rains and thunderstorms from July to October, with around nineteen typhoons entering the Philippine area of responsibility in a typical year and eight or nine making landfall. Annual rainfall measures as much as 5,000 millimeters (200 inches) in the mountainous east coast section but less than 1,000 millimeters (39 inches) in some of the sheltered valleys. The wettest known tropical cyclone to impact the archipelago was the July 1911 cyclone, which dropped over of rainfall within a 24-hour period in Baguio City. "Bagyo" is the local term for a tropical cyclone in the Philippines.
Economy.
The national economy of the Philippines is the 43rd largest in the world, with an estimated 2011 gross domestic product (nominal) of $224.754 billion, it is estimated that the country's rank will climb to the 18th spot by 2017 and 9th spot by 2050. Primary exports include semiconductors and electronic products, transport equipment, garments, copper products, petroleum products, coconut oil, and fruits. Major trading partners include the United States, Japan, China, Singapore, South Korea, the Netherlands, Hong Kong, Germany, Taiwan, and Thailand. Its unit of currency is the Philippine peso (₱ or PHP).
A newly industrialized country, the Philippine economy has been transitioning from one based on agriculture to one based more on services and manufacturing. Of the country's total labor force of around 38.1 million, the agricultural sector employs close to 32% but contributes to only about 13.8% of GDP. The industrial sector employs around 13.7% of the workforce and accounts for 30% of GDP. Meanwhile the 46.5% of workers involved in the services sector are responsible for 56.2% of GDP.
The unemployment rate as of July 2009 stands at around 7.6% and due to the global economic slowdown inflation as of September 2009 reads 0.70%. Gross international reserves as of July 2011 are $75.174 billion. In 2004, public debt as a percentage of GDP was estimated to be 74.2%; in 2008, 56.9%. Gross external debt has risen to $66.27 billion. The country is a net importer.
After World War II, the country was for a time regarded as the second wealthiest in East Asia, next only to Japan. However, by the 1960s its economic performance started being overtaken. The economy stagnated under the dictatorship of Ferdinand Marcos as the regime spawned economic mismanagement and political volatility. The country suffered from slow economic growth and bouts of economic recession. Only in the 1990s with a program of economic liberalization did the economy begin to recover.
The 1997 Asian Financial Crisis affected the economy, resulting in a lingering decline of the value of the peso and falls in the stock market. But the extent it was affected initially was not as severe as that of some of its Asian neighbors. This was largely due to the fiscal conservatism of the government, partly as a result of decades of monitoring and fiscal supervision from the International Monetary Fund (IMF), in comparison to the massive spending of its neighbors on the rapid acceleration of economic growth. There have been signs of progress since. In 2004, the economy experienced 6.4% GDP growth and 7.1% in 2007, its fastest pace of growth in three decades. Yet average annual GDP growth per capita for the period 1966–2007 still stands at 1.45% in comparison to an average of 5.96% for the East Asia and the Pacific region as a whole and the daily income for 45% of the population of the Philippines remains less than $2. Despite enjoying sustained economic growth during the first decade of the 21st century, , the country's economy remains smaller than those of its Southeast Asian neighbors Indonesia, Thailand, Malaysia, and Singapore in terms of GDP and GDP per capita (nominal).
Other incongruities and challenges exist. The economy is heavily reliant on remittances which surpass foreign direct investment as a source of foreign currency. Regional development is uneven with Luzon—Metro Manila in particular—gaining most of the new economic growth at the expense of the other regions, although the government has taken steps to distribute economic growth by promoting investment in other areas of the country. Despite constraints, service industries such as tourism and business process outsourcing have been identified as areas with some of the best opportunities for growth for the country. Goldman Sachs includes the country in its list of the "Next Eleven" economies. But China and India have emerged as major economic competitors.
Goldman Sachs estimates that by the year 2050, it will be the 14th largest economy in the world and one in its list of the Next Eleven economies. HSBC projects the Philippine economy to become the 16th largest economy in the world, 5th largest economy in Asia and the largest economy in the South East Asian region by 2050. 
The Philippines is a member of the World Bank, the International Monetary Fund, the World Trade Organization (WTO), the Asian Development Bank which is headquartered in Mandaluyong City, the Colombo Plan, and the G-77 among other groups and institutions.
Demographics.
Population in Philippines increased from 1990 to 2008 by approximately 28 million, a 45% growth in that time frame. The first official census in the Philippines was carried out in 1877 and recorded a population of 5,567,685. As of 2011, the Philippines has become the world's 12th most populous nation, with a population of over 94 million.
It is estimated that half of the population resides on the island of Luzon. The population growth rate between 1995 to 2000 of 3.21% decreased to an estimated 1.95% for the 2005 to 2010 period, but remains a contentious issue. The population's median age is 22.7 years with 60.9% aged from 15 to 64 years old. Life expectancy at birth is 71.94 years, 75.03 years for females and 68.99 years for males.
There are about 11 million Filipinos outside the Philippines. Since the liberalization of United States immigration laws in 1965, the number of people in the United States having Filipino ancestry has grown substantially. In 2007 there were an estimated 3.1 million. According to the United States Census Bureau, immigrants from the Philippines made up the second largest group after Mexico that sought family reunification. Some two million Filipinos work in the Middle East, with nearly a million in Saudi Arabia alone.
Ethnicity.
According to the 2000 census, 28.1% of Filipinos are Tagalog, 13.1% Cebuano, 9% Ilocano, 7.6% Bisaya/Binisaya, 7.5% Hiligaynon, 6% Bikol, 3.4% Waray, and 25.3% as "others", which can be broken down further to yield more distinct non-tribal groups like the Moro, the Kapampangan, the Pangasinense, the Ibanag, and the Ivatan. There are also indigenous peoples like the Igorot, the Lumad, the Mangyan, the Bajau, and the tribes of Palawan. Negritos, such as the Aeta and the Ati, are considered among the earliest inhabitants of the islands.
Filipinos generally belong to several Asian ethnic groups classified linguistically as part of the Austronesian or Malayo-Polynesian speaking people. It is believed that thousands of years ago Austronesian-speaking Taiwanese aborigines migrated to the Philippines from Taiwan, bringing with them knowledge of agriculture and ocean-sailing, eventually displacing the earlier Negrito groups of the islands. They were later supplanted by arrivals of Chinese and Japanese in the northern islands, and Malays and Arabs in the southern islands. Later arrivals during the colonial period include Indians, Spaniards, Americans, as well as other European peoples. Intermarriage between the groups is evident in the major cities and urban areas. Their descendants are known as mestizos. 
The two most important non-indigenous minorities include the Chinese and the Spaniards. Chinese Filipinos, mostly descended from immigrants from Fujian, China after 1898, number 2 million, although there is an estimated 28 million Filipinos who have partial Chinese ancestry, stemming from precolonial Chinese migrants. Meanwhile, the exact number of Spanish Filipinos remains unknown, but genetic studies extrapolated that 3.6% of all Filipinos have West European ancestry, most probably Spanish. Other significant minorities include Americans, mostly White, numbering 300,000 and Koreans, numbering 96,000.
Cities.
Metro Manila is the most populous of the twelve defined metropolitan areas in the Philippines and the 11th most populous in the world. As of the 2007 census, it had a population of 11,553,427, comprising 13% of the national population. Including suburbs in the adjacent provinces (Bulacan, Cavite, Laguna, and Rizal) of Greater Manila, the population is around 21 million.
Metro Manila's gross regional product is estimated as of July 2009 to be ₱468.4 billion (at constant 1985 prices) and accounts for 33% of the nation's GDP. In 2011, it ranked as the 28th wealthiest urban agglomeration in the world and the 2nd in Southeast Asia, according to PricewaterhouseCoopers. Cebu City in the Visayas and Davao City in Mindanao are other important urban centers.
Language.
"Ethnologue" lists 175 individual languages in the Philippines, 171 of which are living languages while 4 no longer have any known speakers. They are part of the Borneo–Philippines group of the Malayo-Polynesian languages, which is itself a branch of the Austronesian language family.
According to the 1987 Philippine Constitution, Filipino and English are the official languages. Filipino is a de facto version of Tagalog, spoken mainly in Metro Manila and other urban regions. Both Filipino and English are used in government, education, print, broadcast media, and business. The constitution designates regional languages such as Bicolano, Cebuano, Ilocano, Hiligaynon, Kapampangan, Pangasinan, Tagalog, and Waray-Waray as auxiliary official languages, and mandates that Spanish and Arabic shall be promoted on a voluntary and optional basis.
Other languages such as Aklanon, Boholano, Chavacano, Zamboangueño, Cuyonon, Ifugao, Itbayat, Ivatan, Kalinga, Kamayo, Kankana-ey, Kinaray-a, Maguindanao, Maranao, Masbatenyo, Romblomanon, Surigaonon, Tausug, Yakan, and several Visayan languages are prevalent in their respective provinces.
Religion.
The Philippines is a secular nation having a constitution separating the state and church. However, more than 90% of the population are Christians: about 80% belong to the Roman Catholic Church while 10% belong to other Christian denominations, such as the Iglesia ni Cristo, the Philippine Independent Church, the Seventh-day Adventist Church, United Church of Christ in the Philippines, and Jehovah's Witnesses. The Philippines is one of two predominantly Roman Catholic countries in Asia, the other being East Timor.
Between 5 and 10% of the population are Muslim, most of whom live in parts of Mindanao, Palawan, and the Sulu Archipelago—an area known as Bangsamoro or the Moro region. Some have migrated into urban and rural areas in different parts of the country. Most Muslim Filipinos practice Sunni Islam according to the Shafi'i school. Philippine traditional religions are still practiced by many aboriginal and tribal groups, often syncretized with Christianity and Islam. Animism, folk religion, and shamanism remain present as undercurrents of mainstream religion, through the "albularyo", the "babaylan", and the "manghihilot". Buddhism, Taoism, and Chinese folk religion, are dominant in Chinese communities. There are also followers of Hinduism, Sikhism, and Judaism and Baha'i.
Education.
The National Statistics Office reports a simple literacy rate of 93.4% and a functional literacy rate of 84.1% for 2003. Literacy is about equal for males and females. Spending for education is around 2.5% of GDP. According to the Department of Education, or DepEd, there were 44,846 elementary schools and 10,384 secondary schools registered for the school year 2009–2010 while the Commission on Higher Education (CHED) lists 2,180 higher education institutions, 607 of which are public and 1,573 private. Classes start in June and end in March. The majority of colleges and universities follow a semester calendar from June to October and November to March. There are a number of foreign schools with study programs. Republic Act No. 9155 gives the framework of basic education in the Philippines and provides for compulsory elementary education and free high school education.
Several government agencies are involved with education. The Department of Education covers elementary, secondary, and nonformal education; the Technical Education and Skills Development Authority (TESDA) administers the post-secondary middle-level education training and development; and the Commission on Higher Education (CHED) supervises the college and graduate academic programs and degrees as well as regulates standards in higher education. In 2004, madrasahs were mainstreamed in 16 regions nationwide mainly in Muslim areas in Mindanao under the auspices and program of the Department of Education. Public universities are all non-sectarian entities, and are further classified as State University and College (SUC) or Local College and University (LCU). SUCs are funded by the national government as determined by the Philippine Congress. The University of the Philippines is the national university of the Philippines.
Health.
Most of the national burden of health care is taken up by private health providers. In 2006, total expenditures on health represented 3.8% of GDP. 67.1% of that came from private expenditures while 32.9% was from government. External resources accounted for 2.9% of the total. Health expenditures represented about 6.1% of total government spending. Per capita total expenditure at average exchange rate was $52. The proposed national health budget for 2010 is ₱28 billion (about $597 million) or ₱310 ($7) per person. The government share of total spending on health has declined steadily, and with more people, there has been less to spend per person.
There are an estimated 90,370 physicians or 1 per every 833 people, 480,910 nurses, 43,220 dentists, and 1 hospital bed per every 769 people. Retention of skilled practitioners is a problem. 70% of nursing graduates go overseas to work. The country is the biggest supplier of nurses. In 2001 there were about 1,700 hospitals, of which about 40% were government-run and 60% private. Cardiovascular diseases account for more than 25% of all deaths. According to official estimates, 1,965 cases of human immunodeficiency virus (HIV) were reported in 2003, of which 636 had developed acquired immune deficiency syndrome (AIDS). Other estimates have as many as 12,000 people living with HIV/AIDS in 2005.
Infrastructure.
Transportation.
The transportation infrastructure in the country is relatively underdeveloped. Partly this is due to the mountainous terrain and the scattered geography of the islands, but it is also the result of the government's persistent underinvestment in infrastructure. In 2003, only 3.6% of GDP went to infrastructure development which was significantly lower than that of some of its neighbors. Consequently, while there are of roads in the country, only around 20% of the total is paved.
Nevertheless there are many ways to get around, especially in urban areas. Buses, jeepneys, taxis, and motorized tricycles are commonly available in major cities and towns. In 2007, there were about 5.53 million registered motor vehicles with registration increasing at an average annual rate of 4.55%. Train services are provided by three main railway networks that serve different areas of Metro Manila and parts of Luzon: the Manila Light Rail Transit System (LRT), the Manila Metro Rail Transit System (MRT), and the Philippine National Railways (PNR).
As an archipelago, inter-island travel via watercraft is often necessary. The busiest seaports are Manila, Cebu, Iloilo, Davao, Cagayan de Oro, and Zamboanga. Passenger ships and other sea vessels such as those operated by Superferry, Negros Navigation, and Sulpicio Lines serve Manila, with links to various cities and towns. In 2003, the Strong Republic Nautical Highway (SRNH), an integrated set of highway segments and ferry routes covering 17 cities was established.
Some rivers that pass through metropolitan areas, such as the Pasig River and Marikina River, have air-conditioned commuter ferries. The Pasig River Ferry Service has numerous stops in Manila, Makati, Mandaluyong, Pasig and Marikina. There are of navigable inland waterways.
There are 85 public airports in the country, and around 111 more that are private. The Ninoy Aquino International Airport (NAIA) is the main international airport. Other important airports include the Diosdado Macapagal International Airport, Mactan-Cebu International Airport, Francisco Bangoy International Airport and Zamboanga International Airport. Philippine Airlines, Asia's oldest commercial airline still operating under its original name, and Cebu Pacific, the leading low-cost airline, are the major airlines serving most domestic and international destinations.
Communications.
The Philippines has a sophisticated cellular phone industry and a high concentration of users. As of 2008, there are about 67.9 million cellular phone subscribers in the Philippines. Text messaging is a popular form of communication and has fostered a culture of quick greetings and forwarded jokes among Filipinos. In 2007, the nation sent an average of one billion SMS messages per day. Out of this growing number of avid text message senders, over five million of them use their cellular phones as virtual wallets, making it a leader among developing nations in providing financial transactions over cellular networks.
The Philippine Long Distance Telephone Company commonly known as PLDT is the leading telecommunications provider. It is also the largest company in the country. Its wholly owned subsidiaries Smart Communications and Piltel, along with Globe Telecom of the Ayala Group, BayanTel, and Sun Cellular are the major cellular service providers in the country.
There are approximately 383 AM and 659 FM radio stations and 297 television and 873 cable television stations. Estimates for internet penetration in the Philippines vary widely ranging from a low of 2.5 million to a high of 24 million people. Social networking and watching videos are among the most frequent internet activities.
Culture and society.
Philippine culture is a combination of Eastern and Western cultures. The Philippines exhibits aspects found in other Asian countries with a Malay heritage, yet its culture also displays a significant amount of Spanish and American influences. Traditional festivities known as "barrio fiestas" (district festivals) to commemorate the feast days of patron saints are common. The Moriones Festival and Sinulog Festival are a couple of the most well-known. These community celebrations are times for feasting, music, and dancing. Some traditions, however, are changing or gradually being forgotten due to modernization. The Bayanihan Philippine National Folk Dance Company has been lauded for preserving many of the various traditional folk dances found throughout the Philippines. They are famed for their iconic performances of Philippine dances such as the "tinikling" and "singkil" that both feature the use of clashing bamboo poles.
One of the most visible Hispanic legacies is the prevalence of Spanish names and surnames among Filipinos. However, a Spanish name and surname does not necessarily denote Spanish ancestry. This peculiarity, unique among the people of Asia, came as a result of a colonial decree, the Clavería edict, for the systematic distribution of family names and implementation of the Spanish naming system on the population. The names of many streets, towns, and provinces are also in Spanish. Spanish architecture has left an imprint in the Philippines in the way many towns were designed around a central square or "plaza mayor", but many of the buildings bearing its influence were demolished during World War II. Some examples remain, mainly among the country's churches, government buildings, and universities. Four Philippine baroque churches are included in the list of UNESCO World Heritage Sites: the San Agustín Church in Manila, the Paoay Church in Ilocos Norte, the Nuestra Señora de la Asunción (Santa María) Church in Ilocos Sur, and the Santo Tomás de Villanueva Church in Iloilo. Vigan in Ilocos Sur is also known for the many Hispanic-styled houses and buildings preserved there.
The common use of the English language is an example of the American impact on Philippine society. It has contributed to the ready acceptance and influence of American pop cultural trends. This affinity is seen in Filipinos' love of fast food, film, and music. Fast food outlets are found on many street corners. American global fast food chain stalwarts have entered the market, but local fast food chains like Goldilocks and most notably Jollibee, the leading fast food chain in the country, have emerged and compete successfully against their foreign rivals. Filipinos regularly listen to and watch contemporary American, Asian, and European music and film just as they enjoy Original Pilipino Music (also known as OPM) and local films.
Cuisine.
Philippine cuisine has evolved over several centuries from its Malayo-Polynesian origins to become a mixed cuisine with many Hispanic, Chinese, American, and other Asian influences that have been adapted to local ingredients and the Filipino palate to create distinctively Filipino dishes. Dishes range from the very simple, like a meal of fried salted fish and rice, to the elaborate, such as the "paellas" and "cocidos" created for fiestas. Popular dishes include "lechón", "adobo", "sinigang", "kare-kare", "tapa", crispy "pata", "pancit", "lumpia", and "halo-halo". Some common local ingredients used in cooking are calamondins, coconuts, "saba" (a kind of short wide plantain), mangoes, milkfish, and fish sauce. Filipino taste buds tend to favor robust flavors but the cuisine is not as spicy as those of its neighbors.
Unlike many of their Asian counterparts, Filipinos do not eat with chopsticks; they use Western cutlery. However, possibly due to rice being the primary staple food and the popularity of a large number of stews and main dishes with broth in Philippine cuisine, the main pairing of utensils seen at the Filipino dining table is that of spoon and fork, not knife and fork. The traditional way of eating with the hands known as "kamayan" is seen more often in less urbanized areas.
Mythology and literature.
Philippine mythology has been handed down primarily through the traditional oral folk literature of the Filipino people. While each unique ethnic group has its own stories and myths to tell, Hindu and Spanish influences can nonetheless be detected in many cases. Many of the Philippine mythical creatures are creation stories or stories about supernatural creatures, such as the "aswang", the "manananggal", the "diwata/engkanto", and nature. Some popular figures from Philippine mythologies are Maria Makiling, Lam-Ang, and the Sarimanok.
Philippine literature comprises works usually written in Filipino, Spanish, or English. Some of the most known were created in the 19th century. Francisco Balagtas the poet and playwright who wrote "Florante at Laura" is recognized as a preeminent writer in the Filipino language. José Rizal wrote the novels "Noli Me Tangere" ("Touch Me Not") and "El Filibusterismo" ("The Filibustering", also known as "The Reign of Greed") and is considered a national hero. His depiction of the injustices of Spanish rule, and his death by firing squad, inspired other Philippine revolutionaries to seek independence. In the 20th century, among those officially recognized as National Artists of the Philippines in literature are N.V.M. Gonzalez, Nick Joaquin, F. Sionil Jose, and Alejandro Roces.
Media.
Philippine media uses mainly Filipino and English. Other Philippine languages, including various Visayan languages are also used, especially in radio due to its ability to reach remote rural locations that might otherwise not be serviced by other kinds of media. The dominant television networks ABS-CBN, GMA and TV5 also have extensive radio presence.
The entertainment industry is vibrant and feeds broadsheets and tabloids with an unending supply of details about celebrities and sensationalist scandals du jour. Drama and fantasy shows are anticipated as are Latin telenovelas, Asianovelas, and anime. Daytime television is dominated by game shows, variety shows, and talk shows such as "Eat Bulaga" and "It's Showtime". Philippine cinema has a long history and is popular domestically, but has faced increasing competition from American, Asian and European films. Critically acclaimed directors and actors include Lino Brocka and Nora Aunor for films like "" ("Manila: In the Claws of Light") and "Himala" ("Miracle"). In recent years it has become common to see celebrities flitting between television and movies and then moving into politics provoking concerns.
Sports.
Various sports and pastimes are popular in the Philippines including basketball, boxing, cockfighting, volleyball, football, badminton, karate, taekwondo, billiards, ten-pin bowling, chess, and sipa. motocross, cycling, and mountaineering are also becoming popular. Basketball is played at both amateur and professional levels and is considered to be the most popular sport in the Philippines. In almost every corner of the cities, there is a basketball court.
The Philippines has participated in the Summer Olympic Games since 1924, making it the first country in Southeast Asia to compete and win a medal. The country had competed in every Summer Olympic Games since then, except when they participated in the American-led boycott of the 1980 Summer Olympics. The Philippines is also the first tropical nation to compete at the Winter Olympics.
Traditional Philippine games such as "luksung baka", "patintero", "piko", and "tumbang preso" are still played primarily as children's games among the youth. "Sungka" is a traditional native Philippine board game. Card games are popular during festivities, with some, including "pusoy" and "tong-its", being used as a form of illegal gambling. Mahjong is played in some Philippine communities. The yo-yo, a popular toy in the Philippines, was introduced in its modern form by Pedro Flores with its name from the Ilokano language.
"Arnis (Eskrima or Kali in some regions)" is the national martial art and sport. Today there are said to be almost as many Philippine fighting styles as there are islands in the Philippines. In 1972, the Philippine government included Filipino martial arts into the national sports arena. The Ministry of Education, Culture and Sports also incorporated them into the physical education curriculum for high school and college students.
Some Filipinos recognized for their achievements include Francisco Guilledo, Flash Elorde, and Manny Pacquiao in boxing; Paulino Alcántara in football (soccer); Carlos Loyzaga, Robert Jaworski, and Ramon Fernandez in basketball; Efren Reyes in billiards; Eugene Torre in chess; and Rafael Nepomuceno in bowling.

Antisemitism
Antisemitism (also spelled anti-semitism or anti-Semitism) is suspicion of, hatred toward, or discrimination against Jews for reasons connected to their Jewish heritage. Social scientists consider it a form of racism. In a 2005 U.S. governmental report, antisemitism is defined as "hatred toward Jews—individually and as a group—that can be attributed to the Jewish religion and/or ethnicity." A person who holds such views is called an "antisemite".
Antisemitism may be manifested in many ways, ranging from expressions of hatred of or discrimination against individual Jews to organized violent attacks by mobs, state police, or even military attacks on entire Jewish communities. Extreme instances of persecution include the pogroms which preceded the First Crusade in 1096, the expulsion from England in 1290, the massacres of Spanish Jews in 1391, the persecutions of the Spanish Inquisition, the expulsion from Spain in 1492, Cossack massacres in Ukraine, various pogroms in Russia, the Dreyfus affair, the Holocaust, official Soviet anti-Jewish policies and the Jewish exodus from Arab and Muslim countries.
While the term's etymology might suggest that antisemitism is directed against all Semitic peoples, the term was coined in the late 19th century in Germany as a more scientific-sounding term for "Judenhass" ("Jew-hatred"),
and that has been its normal use since then.
Etymology and usage.
Usage.
Despite the use of the prefix "anti-", the terms "Semitic" and "anti-Semitic" are not directly opposed to each other. "Antisemitism" refers specifically to prejudice against Jews alone and in general, despite the fact that there are other speakers of Semitic languages (e.g. Arabs, Ethiopians, or Assyrians) and that not all Jews speak a Semitic language.
The term "anti-Semitic" has been used on occasion to include bigotry against other Semitic-language peoples such as Arabs, but such usage is not widely accepted.
Both terms "anti-Semitism" and "antisemitism" are in common use. Some scholars favor the unhyphenated form "antisemitism" to avoid possible confusion involving whether the term refers specifically to Jews, or to Semitic-language speakers as a whole. For example, Emil Fackenheim supported the unhyphenated spelling, in order to "dispel[] the notion that there is an entity 'Semitism' which 'anti-Semitism' opposes."
Etymology.
Although Wilhelm Marr is generally credited with coining the word "anti-Semitism" (see below), Alex Bein writes that the word was first used in 1860 by the Austrian Jewish scholar Moritz Steinschneider in the phrase "anti-Semitic prejudices". Steinschneider used this phrase to characterize Ernest Renan's ideas about how "Semitic races" were inferior to "Aryan races." These pseudo-scientific theories concerning race, civilization, and "progress" had become quite widespread in Europe in the second half of the 19th century, especially as Prussian nationalistic historian Heinrich von Treitschke did much to promote this form of racism. He coined the term "the Jews are our misfortune" which would later be widely used by Nazis. In Treitschke's writings "Semitic" was synonymous with "Jewish", in contrast to its use by Renan and others.
In 1873 German journalist Wilhelm Marr published a pamphlet ""The Victory of the Jewish Spirit over the Germanic Spirit. Observed from a non-religious perspective."" (""Der Sieg des Judenthums über das Germanenthum. Vom nicht confessionellen Standpunkt aus betrachtet."") in which he used the word ""Semitismus"" interchangeably with the word "Judentum" to denote both "Jewry" (the Jews as a collective) and "jewishness" (the quality of being Jewish, or the Jewish spirit). Although he did not use the word "Antisemitismus" in the pamphlet, the coining of the latter word followed naturally from the word "Semitismus", and indicated either opposition to the Jews as a people, or else opposition to Jewishness or the Jewish spirit, which he saw as infiltrating German culture. In his next pamphlet, ""The Way to Victory of the Germanic Spirit over the Jewish Spirit"", published in 1880, Marr developed his ideas further and coined the related German word "Antisemitismus" – "antisemitism", derived from the word "Semitismus" that he had earlier used.
The pamphlet became very popular, and in the same year he founded the ""League of Antisemites"" (""Antisemiten-Liga""), the first German organization committed specifically to combatting the alleged threat to Germany and German culture posed by the Jews and their influence, and advocating their forced removal from the country.
So far as can be ascertained, the word was first widely printed in 1881, when Marr published ""Zwanglose Antisemitische Hefte,"" and Wilhelm Scherer used the term ""Antisemiten"" in the January issue of ""Neue Freie Presse"". The related word "semitism" was coined around 1885.
Definition.
Though the general definition of antisemitism is hostility or prejudice against Jews, and, according to Olaf Blaschke, become an 'umbrella term for negative stereotypes about Jews,' a number of authorities have developed more formal definitions. 
Holocaust scholar and City University of New York professor Helen Fein defines it as "a persisting latent structure of hostile beliefs towards Jews as a collective manifested in individuals as attitudes, and in culture as myth, ideology, folklore and imagery, and in actions – social or legal discrimination, political mobilization against the Jews, and collective or state violence – which results in and/or is designed to distance, displace, or destroy Jews as Jews." 
Elaborating on Fein's definition, Dietz Bering of the University of Cologne writes that, to antisemites, "Jews are not only partially but totally bad by nature, that is, their bad traits are incorrigible. Because of this bad nature: (1) Jews have to be seen not as individuals but as a collective. (2) Jews remain essentially alien in the surrounding societies. (3) Jews bring disaster on their 'host societies' or on the whole world, they are doing it secretly, therefore the antisemites feel obliged to unmask the conspiratorial, bad Jewish character."
For Sonja Weinberg, as distinct from economic and religious anti-Judaism, antisemitism in its modern form shows conceptual innovation, a resort to 'science' to defend itself, new functional forms and organisational differences. It was anti-liberal, racialist and nationalist. It promoted the myth that Jews conspired to 'judaise' the world; it served to consolidate social identity; it channeled dissatisfactions among victims of the capitalist system; and it was used as a conservative cultural code to fight emancipation and liberalism. 
Bernard Lewis defines antisemitism as a special case of prejudice, hatred, or persecution directed against people who are in some way different from the rest. According to Lewis, antisemitism is marked by two distinct features: Jews are judged according to a standard different from that applied to others, and they are accused of "cosmic evil." Thus, "it is perfectly possible to hate and even to persecute Jews without necessarily being anti-Semitic" unless this hatred or persecution displays one of the two features specific to antisemitism.
There have been a number of efforts by international and governmental bodies to define antisemitism formally. The U.S. Department of State defines antisemitism in its 2005 Report on Global Anti-Semitism as "hatred toward Jews—individually and as a group—that can be attributed to the Jewish religion and/or ethnicity."
In 2005, the European Monitoring Centre on Racism and Xenophobia (now Fundamental Rights Agency), then an agency of the European Union, developed a more detailed working definition, which states: "Antisemitism is a certain perception of Jews, which may be expressed as hatred toward Jews. Rhetorical and physical manifestations of antisemitism are directed toward Jewish or non-Jewish individuals and/or their property, toward Jewish community institutions and religious facilities." It adds "such manifestations could also target the state of Israel, conceived as a Jewish collectivity." It provides contemporary examples of antisemitism, which include: promoting the harming of Jews in the name of an ideology or religion; promoting negative stereotypes of Jews; holding Jews collectively responsible for the actions of an individual Jewish person or group; denying the Holocaust or accusing Jews or Israel of exaggerating it; and accusing Jews of dual loyalty or a greater allegiance to Israel than their own country. It also lists ways in which attacking Israel could be antisemitic, and that denying the Jews their right to self-determination is antisemitic, e.g. by claiming that the existence of a state of Israel is a racist endeavor, or applying double standards by requiring of Israel a behavior not expected or demanded of any other democratic nation, or holding Jews collectively responsible for actions of the State of Israel.
Evolution of usage.
In 1879, Wilhelm Marr founded the "Antisemiten-Liga" (Antisemitic League). Identification with antisemitism and as an antisemite was politically advantageous in Europe in the latter 19th century. For example, Karl Lueger, the popular mayor of fin de siècle Vienna, skillfully exploited antisemitism as a way of channeling public discontent to his political advantage. In its 1910 obituary of Lueger, "The New York Times" notes that Lueger was "Chairman of the Christian Social Union of the Parliament and of the Anti-Semitic Union of the Diet of Lower Austria. In 1895 A. C. Cuza organized the "Alliance Anti-semitique Universelle" in Bucharest. In the period before World War II, when animosity towards Jews was far more commonplace, it was not uncommon for a person, organization, or political party to self-identify as an antisemite or antisemitic.
In the aftermath of the Kristallnacht pogrom in 1938, German propaganda minister Goebbels announced: "The German people is anti-Semitic. It has no desire to have its rights restricted or to be provoked in the future by parasites of the Jewish race."
After the 1945 victory of the Allies over Nazi Germany, and particularly after the extent of the Nazi genocide of Jews became known, the term "antisemitism" acquired pejorative connotations. This marked a full circle shift in usage, from an era just decades earlier when "Jew" was used as a pejorative term. Yehuda Bauer wrote in 1984: "There are no antisemites in the world... Nobody says, 'I am antisemitic.'" You cannot, after Hitler. The word has gone out of fashion."
Forms.
It is often emphasized that there are different forms of antisemitism. René König mentions social antisemitism, economic antisemitism, religious antisemitism, and political antisemitism as examples. König points out that these different forms demonstrate that the "origins of antisemitic prejudices are rooted in different historical periods." König asserts that differences in the chronology of different antisemitic prejudices and the irregular distribution of such prejudices over different segments of the population create "serious difficulties in the definition of the different kinds of antisemitism." These difficulties may contribute to the existence of different taxonomies that have been developed to categorize the forms of antisemitism. The forms identified are substantially the same; it is primarily the number of forms and their definitions that differ. Bernard Lazare identifies three forms of antisemitism: Christian antisemitism, economic antisemitism, and ethnologic antisemitism.
Louis Harap separates "economic antisemitism" and merges "political" and "nationalistic" antisemitism into "ideological antisemitism". Harap also adds a category of "social antisemitism".
Cultural antisemitism.
Louis Harap defines cultural antisemitism as "that species of anti-Semitism that charges the Jews with corrupting a given culture and attempting to supplant or succeeding in supplanting the preferred culture with a uniform, crude, "Jewish" culture. Similarly, Eric Kandel characterizes cultural antisemitism as being based on the idea of “Jewishness” as a "religious or cultural tradition that is acquired through learning, through distinctive traditions and education." According to Kandel, this form of antisemitism views Jews as possessing "unattractive psychological and social characteristics that are acquired through acculturation." Niewyk and Nicosia characterize cultural antisemitism as focusing on and condemning "the Jews' aloofness from the societies in which they live."
An important feature of cultural antisemitism is that it considers the negative attributes of Judaism to be redeemable by education or religious conversion.
Religious antisemitism.
Religious antisemitism is also known as anti-Judaism. Under this version of antisemitism, attacks would often stop if Jews stopped practicing or changed their public faith, especially by conversion to the official or right religion, and sometimes, liturgical exclusion of Jewish converts (the case of Christianized "Marranos" or Iberian Jews in the late 15th century and 16th century convicted of secretly practising Judaism or Jewish customs).
Although the origins of antisemitism are rooted in the Judeo-Christian conflict, religious antisemitism, other forms of antisemitism have developed in modern times. Frederick Schweitzer asserts that, "most scholars ignore the Christian foundation on which the modern antisemitic edifice rests and invoke political antisemitism, cultural antisemitism, racism or racial antisemitism, economic antisemitism and the like." William Nichols draws a distinction between religious antisemitism and modern antisemitism based on racial or ethnic grounds: "The dividing line was the possibility of effective conversion . . . a Jew ceased to be a Jew upon baptism." From the perspective of racial antisemitism, however, "... the assimilated Jew was still a Jew, even after baptism ... . From the Enlightenment onward, it is no longer possible to draw clear lines of distinction between religious and racial forms of hostility towards Jews... Once Jews have been emancipated and secular thinking makes its appearance, without leaving behind the old Christian hostility towards Jews, the new term antisemitism becomes almost unavoidable, even before explicitly racist doctrines appear."
Economic antisemitism.
The underlying premise of economic antisemitism is that Jews perform harmful economic activities or that economic activities become harmful when they are performed by Jews.
Linking Jews and money underpins the most damaging and lasting Antisemitic canards. Antisemites claim that Jews control the world finances, a theory promoted in the fraudulent Protocols of the Elders of Zion, and later repeated by Henry Ford and his Dearborn Independent. In the modern era, such myths continue to be spread in books such as The Secret Relationship Between Blacks and Jews published by the Nation of Islam, and on the internet.
Derek Penslar writes that there are two components to the financial canards: 
Gerald Krefetz summarizes the myth as "control the banks, the money supply, the economy, and businesses – of the community, of the country, of the world". Krefetz gives, as illustrations, many slurs and proverbs (in several different languages) which suggest that Jews are stingy, or greedy, or miserly, or aggressive bargainers. During the nineteenth century, Jews were described as "scurrilous, stupid, and tight-fisted", but after the Jewish Emancipation and the rise of Jews to the middle- or upper-class in Europe were portrayed as "clever, devious, and manipulative financiers out to dominate [world finances".
Leon Poliakov asserts that economic antisemitism is not a distinct form of antisemitism, but merely a manifestation of theologic antisemitism (because, without the theological causes of the economic antisemitism, there would be no economic antisemitism). In opposition to this view, Derek Penslar contends that in the modern era, the economic antisemitism is "distinct and nearly constant" but theological antisemitism is "often subdued".
Racial antisemitism.
Racial antisemitism is prejudice against Jews as a racial/ethnic group, rather than Judaism as a religion.
Racial antisemitism is the idea that the Jews are a distinct and inferior race compared to their host nations. In the late 19th century and early 20th century, it gained mainstream acceptance as part of the eugenics movement, which categorized non-"Europeans" as inferior. It more specifically claimed that the "Nordic" Europeans were superior. Racial antisemites saw the Jews as part of a Semitic race and emphasized their "alien" extra-European origins and culture. They saw Jews as beyond redemption even if they converted to the majority religion. Anthropologists discussed whether the Jews possessed any Arabic-Armenoid, African-Nubian or Asian-Turkic ancestries.
Racial antisemitism replaced the hatred of Judaism with the hatred of Jews as a group. In the context of the Industrial Revolution, following the emancipation of the Jews, Jews rapidly urbanized and experienced a period of greater social mobility. With the decreasing role of religion in public life tempering religious antisemitism, a combination of growing nationalism, the rise of eugenics, and resentment at the socio-economic success of the Jews led to the newer, and more virulent, racist antisemitism.
According to William Nichols, religious antisemitism may be distinguished from modern antisemitism based on racial or ethnic grounds. "The dividing line was the possibility of effective conversion . . . a Jew ceased to be a Jew upon baptism." However, with racial antisemitism, "Now the assimilated Jew was still a Jew, even after baptism ... . From the Enlightenment onward, it is no longer possible to draw clear lines of distinction between religious and racial forms of hostility towards Jews... Once Jews have been emancipated and secular thinking makes its appearance, without leaving behind the old Christian hostility towards Jews, the new term antisemitism becomes almost unavoidable, even before explicitly racist doctrines appear."
In the early 19th century, a number of laws enabling emancipation of the Jews were enacted in Western European countries. The old laws restricting them to ghettos, as well as the many laws that limited their property rights, rights of worship and occupation, were rescinded. Despite this, traditional discrimination and hostility to Jews on religious grounds persisted and was supplemented by racial antisemitism, encouraged by the work of racial theorists such as Joseph Arthur de Gobineau and particularly his "Essay on the Inequality of the Human Race" of 1853–5.Nationalist agendas based on ethnicity, known as ethnonationalism, usually excluded the Jews from the national community as an alien race. Allied to this were theories of Social Darwinism, which stressed a putative conflict between higher and lower races of human beings. Such theories, usually posited by white Europeans, advocated the superiority of white Aryans to Semitic Jews.
Political antisemitism.
William Brustein defines political antisemitism as hostility toward Jews based on the belief that Jews seek national and/or world power." Yisrael Gutman characterizes political antisemitism as tending to "lay responsibility on the Jews for defeats and political economic crises" while seeking to "exploit opposition and resistance to Jewish influence as elements in political party platforms."
According to Viktor Karády, political antisemitism became widespread after the legal emancipation of the Jews and sought to reverse some of the consequences of that emancipation.
Apocalyptic antisemitism.
Adolf Hitler's millennial and messianic vision which culminated in the Holocaust is sometimes referred to as an "apocalyptic antisemitism".
Conspiracy theories.
Holocaust denial and Jewish conspiracy theories are also considered a form of antisemitism.
 Zoological conspiracy theories have been propagated by the Arab media and Arabic language websites, alleging a "Zionist plot" behind the use of animals to attack civilians or to conduct espionage.
New antisemitism.
Starting in the 1990s, some scholars have advanced the concept of New antisemitism, coming simultaneously from the left, the right, and radical Islam, which tends to focus on opposition to the creation of a Jewish homeland in the State of Israel, and argue that the language of anti-Zionism and criticism of Israel are used to attack the Jews more broadly. In this view, the proponents of the new concept believe that criticisms of Israel and Zionism are often disproportionate in degree and unique in kind, and attribute this to antisemitism. It is asserted that the new antisemitism deploys traditional antisemitic motifs, including older motifs such as the blood libel.
Critics of the concept view it as trivializing the meaning of antisemitism, and as exploiting antisemitism in order to silence debate and deflect attention from legitimate criticism of the State of Israel, and, by associating anti-Zionism with antisemitism, misused to taint anyone opposed to Israeli actions and policies.
History.
Chanes suggests that these six stages could be merged into three categories: "ancient antisemitism, which was primarily ethnic in nature; Christian antisemitism, which was religious; and the racial antisemitism of the nineteenth and twentieth centuries."
Ancient world.
The first clear examples of anti-Jewish sentiment can be traced back to Alexandria in the 3rd century BCE. Alexandria was home to the largest Jewish community in the world and the Septuagint, a Greek translation of the Hebrew Bible, was produced there. Manetho, an Egyptian priest and historian of that time, wrote scathingly of the Jews and his themes are repeated in the works of Chaeremon, Lysimachus, Poseidonius, Apollonius Molon, and in Apion and Tacitus. Agatharchides of Cnidus ridiculed the practices of the Jews and the "absurdity of their Law", making a mocking reference to how Ptolemy Lagus was able to invade Jerusalem in 320 BCE because its inhabitants were observing the "Shabbat". One of the earliest anti-Jewish edicts, promulgated by Antiochus IV Epiphanes in about 170–167 BCE, sparked a revolt of the Maccabees in Judea.
In view of Manetho's anti-Jewish writings, antisemitism may have originated in Egypt and been spread by "the Greek retelling of Ancient Egyptian prejudices". The ancient Jewish philosopher Philo of Alexandria describes an attack on Jews in Alexandria in 38 CE in which thousands of Jews died. The violence in Alexandria may have been caused by the Jews being portrayed as misanthropes. Tcherikover argues that the reason for hatred of Jews in the Hellenistic period was their separateness in the Greek cities, the "poleis". Bohak has argued, however, that early animosity against the Jews cannot be regarded as being anti-Judaic or antisemitic unless it arose from attitudes that were held against the Jews alone, and that many Greeks showed animosity toward any group they regarded as barbarians.
Statements exhibiting prejudice against Jews and their religion can be found in the works of many pagan Greek and Roman writers. Edward Flannery writes that it was the Jews' refusal to accept Greek religious and social standards that marked them out. Hecataetus of Abdera, a Greek historian of the early third century BCE, wrote that Moses "in remembrance of the exile of his people, instituted for them a misanthropic and inhospitable way of life." Manetho, an Egyptian historian, wrote that the Jews were expelled Egyptian lepers who had been taught by Moses "not to adore the gods." Edward Flannery describes antisemitism in ancient times as essentially "cultural, taking the shape of a national xenophobia played out in political settings."
There are examples of Hellenistic rulers desecrating the Temple and banning Jewish religious practices, such as circumcision, Shabbat observance, study of Jewish religious books, etc. Examples may also be found in anti-Jewish riots in Alexandria in the 3rd century BCE. Philo of Alexandria described an attack on Jews in Alexandria in 38 CE in which thousands of Jews died.
The Jewish diaspora on the Nile island Elephantine, which was founded by mercenaries, experienced the destruction of its temple in 410 BCE.
Relationships between the Jewish people and the occupying Roman Empire were at times antagonistic and resulted in several rebellions. According to Suetonius, the emperor Tiberius expelled from Rome Jews who had gone to live there. The 18th century English historian Edward Gibbon identified a more tolerant period in Roman-Jewish relations beginning in about 160 CE . However, when Christianity became the state religion of the Roman Empire, the state's attitude towards the Jews gradually worsened.
James Carroll asserted: "Jews accounted for 10% of the total population of the Roman Empire. By that ratio, if other factors such as pogroms and conversions had not intervened, there would be 200 million Jews in the world today, instead of something like 13 million."
Persecutions in the Middle Ages.
From the 9th century CE, the medieval Islamic world classified Jews (and Christians) as "dhimmi", and allowed them to practice their religion more freely than they could do in medieval Christian Europe. Under Islamic rule, there was a Golden age of Jewish culture in Spain that lasted until at least the 11th century, when several Muslim pogroms against Jews took place in the Iberian Peninsula; those that occurred in Córdoba in 1011 and in Granada in 1066. Several decrees ordering the destruction of synagogues were also enacted in Egypt, Syria, Iraq and Yemen from the 11th century. Jews were also forced to convert to Islam or face death in some parts of Yemen, Morocco and Baghdad several times between the 12th and 18th centuries. The Almohads, who had taken control of the Almoravids' Maghribi and Andalusian territories by 1147, were far more fundamentalist in outlook, and they treated the "dhimmis" harshly. Faced with the choice of either death or conversion, many Jews and Christians emigrated. Some, such as the family of Maimonides, fled east to more tolerant Muslim lands, while some others went northward to settle in the growing Christian kingdoms.
During the Middle Ages in Europe there was persecution against Jews in many places, with blood libels, expulsions, forced conversions and massacres. A main justification of prejudice against Jews in Europe was religious. The persecution hit its first peak during the Crusades. In the First Crusade (1096) flourishing communities on the Rhine and the Danube were destroyed. In the Second Crusade (1147) the Jews in Germany were subject to several massacres. The Jews were also subjected to attacks by the Shepherds' Crusades of 1251 and 1320. The Crusades were followed by expulsions, including, in 1290, the banishing of all English Jews; in 1396, the expulsion of 100,000 Jews in France; and in 1421, the expulsion of thousands from Austria. Many of the expelled Jews fled to Poland. In medieval and Renaissance Europe, a major contributor to the deepening of antisemitic sentiment and legal action among the Christian populations was the popular preaching of the zealous reform religious orders, the Franciscans (especially Bernardino of Feltre) and Dominicans (especially Vincent Ferrer), who combed Europe and promoted antisemitism through their often fiery, emotional appeals.
As the Black Death epidemics devastated Europe in the mid-14th century, annihilating more than half of the population, Jews were used as scapegoats. Rumors spread that they caused the disease by deliberately poisoning wells. Hundreds of Jewish communities were destroyed. Although Pope Clement VI tried to protect them by issuing the 6 July 1348, papal bull and an additional bull in 1348, several months later, 900 Jews were burned alive in Strasbourg, where the plague had not yet affected the city.
Seventeenth century.
During the mid-to-late 17th century the Polish-Lithuanian Commonwealth was devastated by several conflicts, in which the Commonwealth lost over a third of its population (over 3 million people), and Jewish losses were counted in hundreds of thousands. First, the Khmelnytsky Uprising when Bohdan Khmelnytsky's Cossacks massacred tens of thousands of Jews in the eastern and southern areas he controlled (today's Ukraine). The precise number of dead may never be known, but the decrease of the Jewish population during that period is estimated at 100,000 to 200,000, which also includes emigration, deaths from diseases and captivity in the Ottoman Empire, called "jasyr".
European immigrants to the United States brought antisemitism to the country as early as the 17th century. Peter Stuyvesant, the Dutch governor of New Amsterdam, implemented plans to prevent Jews from settling in the city. During the Colonial Era, the American government limited the political and economic rights of Jews. It was not until the Revolutionary War that Jews gained legal rights, including the right to vote. However, even at their peak, the restrictions on Jews in the United States were never as stringent as they had been in Europe.
Enlightenment.
In 1744, Frederick II of Prussia limited the number of Jews allowed to live in Breslau to only ten so-called "protected" Jewish families and encouraged a similar practice in other Prussian cities. In 1750 he issued the "Revidiertes General Privilegium und Reglement vor die Judenschaft": the "protected" Jews had an alternative to "either abstain from marriage or leave Berlin" (quoting Simon Dubnow). In the same year, Archduchess of Austria Maria Theresa ordered Jews out of Bohemia but soon reversed her position, on the condition that Jews pay for their readmission every ten years. This extortion was known as "malke-geld" (queen's money). In 1752 she introduced the law limiting each Jewish family to one son. In 1782, Joseph II abolished most of these persecution practices in his "Toleranzpatent", on the condition that Yiddish and Hebrew were eliminated from public records and that judicial autonomy was annulled. Moses Mendelssohn wrote that "Such a tolerance... is even more dangerous play in tolerance than open persecution."
In 1772, the empress of Russia Catherine II forced the Jews of the Pale of Settlement to stay in their shtetls and forbade them from returning to the towns that they occupied before the partition of Poland.
Islamic antisemitism in the nineteenth century.
Historian Martin Gilbert writes that it was in the 19th century that the position of Jews worsened in Muslim countries. Benny Morris writes that one symbol of Jewish degradation was the phenomenon of stone-throwing at Jews by Muslim children. Morris quotes a 19th century traveler: "I have seen a little fellow of six years old, with a troop of fat toddlers of only three and four, teaching to throw stones at a Jew, and one little urchin would, with the greatest coolness, waddle up to the man and literally spit upon his Jewish gaberdine. To all this the Jew is obliged to submit; it would be more than his life was worth to offer to strike a Mahommedan."
Secular or racial antisemitism.
In 1850 the German composer Richard Wagner published "Das Judenthum in der Musik" ("Jewishness in Music") under a pseudonym in the "Neue Zeitschrift für Musik". The essay began as an attack on Jewish composers, particularly Wagner's contemporaries (and rivals) Felix Mendelssohn and Giacomo Meyerbeer, but expanded to accuse Jews of being a harmful and alien element in German culture. Antisemitism can also be found in many of the Grimms' Fairy Tales by Jacob and Wilhelm Grimm, published from 1812 to 1857. It is mainly characterized by Jews being the villain of a story, such as in "The Good Bargain (Der gute Handel)" and "The Jew Among Thorns (Der Jude im Dorn)."
The Dreyfus Affair was an infamous antisemitic event of the late 19th century and early 20th century. Alfred Dreyfus, a Jewish artillery captain in the French army, was accused in 1894 of passing secrets to the Germans. As a result of these charges, Dreyfus was convicted and sentenced to life imprisonment on Devil's Island. The actual spy, Marie Charles Esterhazy, was acquitted. The event caused great uproar among the French, with the public choosing sides regarding whether Dreyfus was actually guilty or not. Émile Zola accused the army of polluting the French justice system. However, general consensus held that Dreyfus was guilty: 80% of the press in France condemned him. This attitude among the majority of the French population reveals the underlying antisemitism of the time period.
Adolf Stoecker (1835–1909), the Lutheran court chaplain to Kaiser Wilhelm I, founded in 1878 an antisemitic, antiliberal political party called The Christian Social Party (Germany). However, this party did not attract as many votes as the Nazi party, which flourished in part because of The Great Depression, which hit Germany especially hard during the early 1930s.
Some scholars view Karl Marx's essay "On The Jewish Question" as antisemitic, and he often used antisemitic epithets in his published and private writings. Marx's equation of Judaism with capitalism, together with his pronouncements on Jews, strongly influenced socialist movements and shaped their attitudes and policies toward the Jews. Marx's "On the Jewish Question" influenced National Socialist, as well as Soviet and Arab antisemites. Albert Lindemann and Hyam Maccoby have suggested that Marx was embarrassed by his Jewish background. 
Others argue that Marx consistently supported Prussian Jewish communities' struggles to achieve equal political rights. These scholars argue that "On the Jewish Question" is a critique of Bruno Bauer's arguments that Jews must convert to Christianity before being emancipated, and is more generally a critique of liberal rights discourses and capitalism. David McLellan and Francis Wheen argue that readers should interpret "On the Jewish Question" in the deeper context of Marx's debates with Bruno Bauer, author of "The Jewish Question", about Jewish emancipation in Germany. According to McLellan, Marx used the word "Judentum" colloquially, as meaning "commerce", arguing that Germans must be emancipated from the capitalist mode of production not Judaism or Jews in particular.
Twentieth century.
Between 1900 and 1924, approximately 1.75 million Jews migrated to America, the bulk from Eastern Europe. Before 1900 American Jews had always amounted to less than 1% of America's total population, but by 1930 Jews formed about 3.5%. This increase, combined with the upward social mobility of some Jews, contributed to a resurgence of antisemitism. In the first half of the 20th century, in the USA, Jews were discriminated against in employment, access to residential and resort areas, membership in clubs and organizations, and in tightened quotas on Jewish enrolment and teaching positions in colleges and universities. The lynching of Leo Frank by a mob of prominent citizens in Marietta, Georgia in 1915 turned the spotlight on antisemitism in the United States. The case was also used to build support for the renewal of the Ku Klux Klan which had been inactive since 1870.
At the beginning of the 20th century, the Beilis Trial in Russia represented incidents of blood-libel in Europe. Christians used allegations of Jews killing Christians as a justification for the killing of Jews.
Antisemitism in America reached its peak during the interwar period. The pioneer automobile manufacturer Henry Ford propagated antisemitic ideas in his newspaper "The Dearborn Independent" (published by Ford from 1919 to 1927). The radio speeches of Father Coughlin in the late 1930s attacked Franklin D. Roosevelt's New Deal and promoted the notion of a Jewish financial conspiracy. Some prominent politicians shared such views: Louis T. McFadden, Chairman of the United States House Committee on Banking and Currency, blamed Jews for Roosevelt's decision to abandon the gold standard, and claimed that "in the United States today, the Gentiles have the slips of paper while the Jews have the lawful money".
In the early 1940s the aviator Charles Lindbergh and many prominent Americans led The America First Committee in opposing any involvement in the war against Fascism. During his July 1936 visit to Germany, Lindbergh wrote letters saying that there was "more intelligent leadership in Germany than is generally recognized".
The German American Bund held parades in New York City during the late 1930s, where members wore Nazi uniforms and raised flags featuring swastikas alongside American flags. With the start of U.S. involvement in World War II most of the Bund's members were placed in internment camps, and some were deported at the end of the war.
Sometimes race riots, as in Detroit in 1943, targeted Jewish businesses for looting and burning.
In Germany the National Socialist regime of Adolf Hitler, which came to power on 30 January 1933, instituted repressive legislation denying the Jews basic civil rights. It instituted a pogrom on the night of 9–10 November 1938, dubbed "Kristallnacht", in which Jews were killed, their property destroyed and their synagogues torched. Antisemitic laws, agitation and propaganda were extended to Nazi-occupied Europe in the wake of conquest, often building on local antisemitic traditions. In the east the Third Reich forced Jews into ghettos in Warsaw, Krakow, Lvov, Lublin and Radom. After the invasion of Russia in 1941 a campaign of mass murder, conducted by the Einsatzgruppen, culminated between 1942 to 1945 in systematic genocide: the Holocaust. Eleven million Jews were targeted for extermination by the Nazis, and some six million were eventually killed.
Antisemitism was commonly used as an instrument for personal conflicts in Soviet Russia, starting from conflict between Joseph Stalin and Leon Trotsky and continuing through numerous conspiracy-theories spread by official propaganda. Antisemitism in the USSR reached new heights after 1948 during the campaign against the "rootless cosmopolitan" (euphemism for "Jew") in which numerous Yiddish-language poets, writers, painters and sculptors were killed or arrested. This culminated in the so-called Doctors' Plot (1952–1953). Similar antisemitic propaganda in Poland resulted in the flight of Polish Jewish survivors from the country.
After the war, the Kielce pogrom and "March 1968 events" in communist Poland represented further incidents of antisemitism in Europe. The anti-Jewish violence in postwar Poland has a common theme of blood-libel rumours.
In 1965 Pope Paul VI disbanded the cult of Simon of Trent, and the shrine erected to him was dismantled. He was removed from the Roman Catholic calendar of saints, and his future veneration was forbidden, though a handful of extremists still promote the Simon of Trent narrative as fact.
Current situation.
A March 2008 report by the U.S. State Department found that there was an increase in antisemitism across the world, and that both old and new expressions of antisemitism persist.
Causes.
Dean Phillip Bell documents and enumerates a number of categories of causes for anti-Jewish sentiment and behavior. Socio-psychological explanations focus on scapegoating via projection of guilt and displaced aggression. Ethnic explanations associate marginalization of Jews with perceived ethnic and cultural differences.
United States.
A 2007 survey by the Anti-Defamation League (ADL) concluded that 15% of Americans hold antisemitic views, which was in-line with the average of the previous ten years, but a decline from the 29% of the early sixties. The survey concluded that education was a strong predictor, “with most educated Americans being remarkably free of prejudicial views.” The belief that Jews have too much power was considered a common antisemitic view by the ADL. Other views indicating antisemitism, according to the survey, include the view that Jews are more loyal to Israel than America, and that they are responsible for the death of Christ. The survey found that antisemitic Americans are likely to be intolerant generally, e.g. regarding immigration and free-speech. The 2007 survey also found that 29% of foreign-born Hispanics and 32% of African-Americans hold strong antisemitic beliefs, three times more than the 10% for whites. 
In November 2005, the U.S. Commission on Civil Rights examined antisemitism on college campuses. It reported that "incidents of threatened bodily injury, physical intimidation or property damage are now rare", but antisemitism still occurs on many campuses and is a "serious problem." The Commission recommended that the U.S. Department of Education's Office for Civil Rights protect college students from antisemitism through vigorous enforcement of "Title VI" of the Civil Rights Act of 1964 and further recommended that Congress clarify that Title VI applies to discrimination against Jewish students.
On 19 September 2006, Yale University founded the Yale Initiative for the Interdisciplinary Study of Anti-Semitism (YIISA), the first North American university-based center for study of the subject, as part of its Institution for Social and Policy Studies. Director Charles Small of the Center cited the increase in antisemitism worldwide in recent years as generating a "need to understand the current manifestation of this disease". In June 2011, Yale voted to close this initiative. After carrying out a routine review, the faculty review committee said that the initiative had not met its research and teaching standards. Donald Green, who heads Yale’s Institution for Social and Policy Studies, the body under whose aegis the antisemitism initiative was run, said that it had not had many papers published in the relevant leading journals or attracted many students. As with other programs that had been in a similar situation, the initiative had therefore been cancelled. This decision has been criticized by figures such as former U.S. Commission on Civil Rights Staff Director Kenneth L. Marcus, who is now the director of the Initiative to Combat Anti-Semitism and Anti-Israelism in America’s Educational Systems at the Institute for Jewish and Community Research, and Deborah Lipstadt, who described the decision as "weird" and "strange." Antony Lerman has supported Yale's decision, describing the YIISA as a politicized initiative that was devoted to the promotion of Israel rather than to serious research on antisemitism.
A 2009 study published in "Boston Review" found that nearly 25% of non-Jewish Americans blamed Jews for the financial crisis of 2008–2009, with a higher percentage among Democrats than Republicans.
In August 2012, the California state assembly approved a non-binding resolution that "encourages university leaders to combat a wide array of anti-Jewish and anti-Israel actions," although the resolution "is purely symbolic and does not carry policy implications."
Latin America.
Venezuela.
In a 2009 news story, Michael Rowan and Douglas E. Schoen wrote, "In an infamous Christmas Eve speech several years ago, Chávez said the Jews killed Christ and have been gobbling up wealth and causing poverty and injustice worldwide ever since." Hugo Chávez stated that "world is for all of us, then, but it so happens that a minority, the descendants of the same ones that crucified Christ, the descendants of the same ones that kicked Bolívar out of here and also crucified him in their own way over there in Santa Marta, in Colombia. A minority has taken possession of all of the wealth of the world."
In February 2012, opposition candidate for the 2012 Venezuelan presidential election Henrique Capriles was subject to what foreign journalists characterized as vicious attacks by state-run media sources. The "Wall Street Journal" said that Capriles "was vilified in a campaign in Venezuela's state-run media, which insinuated he was, among other things, a homosexual and a Zionist agent". A 13 February 2012 opinion article in the state-owned Radio Nacional de Venezuela, titled "The Enemy is Zionism" attacked Capriles' Jewish ancestry and linked him with Jewish national groups because of a meeting he had held with local Jewish leaders, saying, "This is our enemy, the Zionism that Capriles today represents ... Zionism, along with capitalism, are responsible for 90% of world poverty and imperialist wars."
Europe.
According to a 2004 report from the Jerusalem Center for Public Affairs, antisemitism had increased significantly in Europe since 2000, with significant increases in verbal attacks against Jews and vandalism such as graffiti, fire bombings of Jewish schools, desecration of synagogues and cemeteries. Germany, France, Britain and Russia are the countries with the highest rate of antisemitic incidents in Europe. The Netherlands and Sweden have also consistently had high rates of antisemitic attacks since 2000.
Some claim that recent European antisemitic violence can actually be seen as a spill over from the long running Arab-Israeli conflict since the majority of the perpetrators are from the large Muslim immigrant communities in European cities. However, compared to France, the United Kingdom and much of the rest of Europe, in Germany Arab and pro-Palestinian groups are involved in only a small percentage of antisemitic incidents. According to "The Stephen Roth Institute for the Study of Contemporary Antisemitism and Racism", most of the more extreme attacks on Jewish sites and physical attacks on Jews in Europe come from militant Islamic and Muslim groups, and most Jews tend to be assaulted in countries where groups of young Muslim immigrants reside.
On 1 January 2006, Britain's chief rabbi, Lord Jonathan Sacks, warned that what he called a "tsunami of antisemitism" was spreading globally. In an interview with BBC Radio 4, Sacks said: "A number of my rabbinical colleagues throughout Europe have been assaulted and attacked on the streets. We've had synagogues desecrated. We've had Jewish schools burnt to the ground – not here but in France. People are attempting to silence and even ban Jewish societies on campuses on the grounds that Jews must support the state of Israel, therefore they should be banned, which is quite extraordinary because ... British Jews see themselves as British citizens. So it's that kind of feeling that you don't know what's going to happen next that's making ... some European Jewish communities uncomfortable."
Following an escalation in antisemitism in 2012, which included the deadly shooting of three children at a Jewish school in France, the European Jewish Congress demanded in July a more proactive response. EJC President Moshe Kantor explained, "We call on authorities to take a more proactive approach so there would be no reason for statements of regret and denunciation. All these smaller attacks remind me of smaller tremors before a massive earthquake. The Jewish community cannot afford to be subject to an earthquake and the authorities cannot say that the writing was not on the wall." He added that European countries should take legislative efforts to ban any form of incitement, as well as to equip the authorities with the necessary tools to confront any attempt to expand terrorist and violent activities against Jewish communities in Europe.
Germany.
The Interior Minister of Germany, Wolfgang Schäuble, points out the official policy of Germany: "We will not tolerate any form of extremism, xenophobia or anti-Semitism." Although the number of extreme right-wing groups and organisations grew from 141 (2001) to 182 (2006), especially in the formerly communist East Germany, Germany's measures against right-wing groups and antisemitism are effective, despite Germany having the highest rates of antisemitic acts in Europe. According to the annual reports of the Federal Office for the Protection of the Constitution the overall number of far-right extremists in Germany dropped during the last years from 49,700 (2001), 45,000 (2002), 41,500 (2003), 40,700 (2004), 39,000 (2005), to 38,600 in 2006. Germany provided several million Euros to fund "nationwide programs aimed at fighting far-right extremism, including teams of traveling consultants, and victims' groups."
In July 2012, two women were assaulted in Germany, sprayed with tear gas, and were shown a "Hitler salute," apparently because of a Star of David necklace that they wore.
In late August 2012, Berlin police investigated an attack on a 53-year-old rabbi and his 6-year-old daughter, allegedly by four Arab teens, after which the rabbi needed treatment for head wounds at a hospital. The police classified the attack as a hate crime. "Jüdische Allgemeine" reported that the rabbi was wearing a kippah and was approached by one of the teens, who asked the rabbi if he was Jewish. The teen then attacked the rabbi while yelling antisemitic comments, and threatened to kill the rabbi's daughter. Berlin’s mayor condemned the attack, saying that “Berlin is an international city in which intolerance, xenophobia and anti-Semitism are not being tolerated. Police will undertake all efforts to find and arrest the perpetrators.”
In October 2012, varius historians, including Dr. Julius H. Schoeps, a prominent German-Jewish historian and a member of the German Interior Ministry’s commission to combat antisemitism, charged the majority of Bundestag deputies with failing to understand antisemitism and the imperativeness of periodic legislative reports on German antisemitism. Schoeps cited various anti-Semitic statements by German parliament members as well. The report in question determined that 15% of Germans are anti-Semitic while over 20% espouse "latent anti-Semitism," but the report has been criticized for downplaying the sharpness of antisemitism in Germany, as well as for failing to examine anti-Israel media coverage in Germany.
The Netherlands.
Antisemitic incidents, from verbal abuse to violence, are reported, allegedly connected with Islamic youth, mostly boys of Moroccan descent. According to the Centre for Information and Documentation on Israel, a pro-Israel lobby group in the Netherlands, in 2009, the number of antisemitic incidents in Amsterdam, the city that is home to most of the approximately 40,000 Dutch Jews, was said to be doubled compared to 2008. In 2010, Raphaël Evers, an orthodox rabbi in Amsterdam, told the Norwegian newspaper aftenposten that Jews can no longer be safe in the city anymore due to the risk of violent assaults. "Jews no longer feel at home in the city. Many are considering aliyah to Israel."
United Kingdom.
In 2005, a group of British Members of Parliament set up an inquiry into antisemitism, which published its findings in 2006. Its report stated that "until recently, the prevailing opinion both within the Jewish community and beyond been that antisemitism had receded to the point that it existed only on the margins of society." It found a reversal of this progress since 2000. In his oral evidence, the Chief Rabbi stated: “If you were to ask me is Britain an antisemitic society, the answer is manifestly and obviously no. It is one of the least antisemitic societies in the world.” The inquiry set out to investigate the problem, identify the sources of contemporary antisemitism and make recommendations to improve the situation. It discussed the influence of the Israel-Palestine conflict and issues of anti-Israel sentiment versus antisemitism at length and noted "most of those who gave evidence were at pains to explain that criticism of Israel is not to be regarded in itself as antisemitic ... The Israeli government itself may, at times, have mistakenly perceived criticism of its policies and actions to be motivated by antisemitism." In November 2010, the BBC's investigative program "Panorama" reported that Saudi national textbooks advocating antisemitism were being used in Islamic religious programs attended by 5,000 British schoolchildren in the United Kingdom. In the textbooks, Jews were described as looking like monkeys and pigs, and said to be condemned to hellfire.
A report released in 2012 by the Community Security Trust, documenting antisemitic incidents from January–June 2012, revealed that the number of incidents rose in these months compared to incidents in 2011, with 299 cases deemed antisemitic. There was a significant rise in the number of antisemitic incidents in March 2012, apparently influenced by the antisemitic terrorist attack in Toulouse, France during that month by Mohammed Merah.
France.
France is home to the continent's largest Jewish community (about 600,000). Jewish leaders decry an intensifying antisemitism in France, mainly among Muslims of Arab or African heritage, but also growing among Caribbean islanders from former French colonies.
Former Interior Minister Nicolas Sarkozy denounced the killing of Ilan Halimi on 13 February 2006 as an antisemitic crime.
Jewish philanthropist Baron Eric de Rothschild suggests that the extent of antisemitism in France has been exaggerated. In an interview with "The Jerusalem Post" he says that "the one thing you can't say is that France is an anti-Semitic country."
In March 2012, Mohammed Merah opened fire at a Jewish school in Toulouse, killing a teacher and three children. A 8 year old girl was shot in the head at point blank range. President Nicolas Sarkozy said that it was "obvious" it was an antisemitic attack and that, "I want to say to all the leaders of the Jewish community, how close we feel to them. All of France is by their side." The Israeli Prime Minister condemned the "despicable anti-Semitic" murders. After a 32 hour siege and standoff with the police outside his house, and a French raid, Merah jumped off a balcony and was shot in the head and killed. Merah told police during the standoff that he intended to keep on attacking, and he loved death the way the police loved life. He also claimed connections with al-Qaeda.
4 months later, in July 2012, a French Jewish teenager wearing a "distinctive religious symbol" was the victim of a violent antisemitic attack on a train travelling between Toulouse and Lyon. The teen was first verbally harassed and later beaten up by two assailants. The French Jewish umbrella group, CRIF, called the attack “another development in the worrying trend of anti-Semitism in our country.”
Another incident in July 2012 dealt with the vandalism of the synagogue of Noisy-le-Grand of the Seine-Saint-Denis district in Paris. The synagogue was vandalized three times in a ten day period. Prayer books and shawls were thrown on the floor, windows were shattered, drawers were ransacked, and vandalized the walls, tables, clocks, and floors. The authorities were alerted of the incidents by the Bureau National de Vigilance Contr L’Antisemtisme (BNVCA), a French antisemitism watchdog group, which called for more measures to be taken to prevent future hate crimes. BNVCA President Sammy Ghozlan stated that, "Despite the measures taken, things persist, and I think that we need additional legislation, because the Jewish community is annoyed."
In August 2012, Abraham Cooper, the dean of the Simon Wiesenthal Center, met French Interior Minister Manuel Valls and reported that antisemitic attacks against French Jews increased by 40% since Merah's shooting spree in Toulouse. Cooper pressed Valls to take extra measures to secure the safety of French Jews, as well as to discuss strategies to foil an increasing trend of lone-wolf terrorists on the Internet.
Norway.
In 2010, the Norwegian Broadcasting Corporation after one year of research, revealed that antisemitism was common among some 8th, 9th, and 10th graders in Oslo's schools. Teachers at schools with large numbers of Muslims revealed that Muslim students often "praise or admire Adolf Hitler for his killing of Jews", that "Jew-hate is legitimate within vast groups of Muslim students" and that "Muslims laugh or command to stop when trying to educate about the Holocaust". Additionally, "while some students might protest when some express support for terrorism, none object when students express hate of Jews", saying that it says in "the Quran that you shall kill Jews, all true Muslims hate Jews". Most of these students were said to be born and raised in Norway. One Jewish father also stated that his child had been taken by a Muslim mob after school (though the child managed to escape), reportedly "to be taken out to the forest and hung because he was a Jew".
Norwegian Education Minister Kristin Halvorsen referred to the antisemitism reported in this study as being “completely unacceptable.” The head of a local Islamic council joined Jewish leaders and Halvorsen in denouncing such antisemitism.
In October 2012, the Organization for Security and Co-Operation in Europe issued a report regarding antisemitism in Norway, criticizing Norway for an increase in antisemitism in the country and blaming Norwegian officials for failing to address antisemitism. The OSCE also appealed to Norway to abolish a ban on Jewish ritual slaughter, which was in place since 1929, as an "important symbolic gesture."
Sweden.
After Germany and Austria, Sweden has the highest rate of antisemitic incidents in Europe, though the Netherlands has reported a higher rate of antisemitism in some years. A government study in 2006 estimated that 15% of Swedes agree with the statement: "The Jews have too much influence in the world today". 5% of the entire adult population, and 39% of the Muslim population, harbor strong and consistent antisemitic views. Former Prime Minister Göran Persson described these results as "surprising and terrifying". However, the Rabbi of Stockholm's Orthodox Jewish community, Meir Horden claimed that "It's not true to say that the Swedes are anti-Semitic. Some of them are hostile to Israel because they support the weak side, which they perceive the Palestinians to be."
In 2009, a synagoguage that served the Jewish community in Malmö was set ablaze. Jewish cemeteries were repeatedly desecrated, worshippers were abused while returning home from prayer, and masked men mockingly chanted "Hitler" in the streets. As a result of security concerns, Malmö's synagogue has guards and rocket-proof glass in the windows, and the Jewish kindergarten can only be reached through thick steel security doors.
In early 2010, the Swedish publication "The Local" published series of articles about the growing antisemitism in Malmö, Sweden. In an interview in January 2010, Fredrik Sieradzki of the Jewish Community of Malmö stated that "Threats against Jews have increased steadily in Malmö in recent years and many young Jewish families are choosing to leave the city. Many feel that the community and local politicians have shown a lack of understanding for how the city's Jewish residents have been marginalized." He also added that "right now many Jews in Malmö are really concerned about the situation here and don't believe they have a future here." The Local also reported that Jewish cemeteries and synagogues have repeatedly been defaced with antisemitic graffiti, and a chapel at another Jewish burial site in Malmö was firebombed in 2009. In 2009 the Malmö police received reports of 79 antisemitic incidents, which was twice the number of the previous year (2008). Fredrik Sieradzki, spokesman for the Malmö Jewish community, estimated that the already small Jewish population is shrinking by 5% a year. "Malmö is a place to move away from," he said, citing antisemitism as the primary reason.
In March 2010, Fredrik Sieradzk told "Die Presse", an Austrian Internet publication, that Jews are being "harassed and physically attacked" by "people from the Middle East," although he added that only a small number of Malmö's 40,000 Muslims "exhibit hatred of Jews." Sieradzk also stated that approximately 30 Jewish families have emigrated from Malmö to Israel in the past year, specifically to escape from harassment. Also in March, the Swedish newspaper "Skånska Dagbladet" reported that attacks on Jews in Malmö totaled 79 in 2009, about twice as many as the previous year, according to police statistics.
In October 2010, "The Forward" reported on the current state of Jews and the level of antisemitism in Sweden. Henrik Bachner, a writer and professor of history at the University of Lund, claimed that members of the Swedish Parliament have attended anti-Israel rallies where the Israeli flag was burned while the flags of Hamas and Hezbollah were waved, and the rhetoric was often antisemitic—not just anti-Israel. But such public rhetoric is not branded hateful and denounced. Charles Small, director of the Yale Initiative for the Interdisciplinary Study of Antisemitism, stated that "Sweden is a microcosm of contemporary anti-Semitism. It's a form of acquiescence to radical Islam, which is diametrically opposed to everything Sweden stands for." Per Gudmundson, chief editorial writer for "Svenska Dagbladet", has sharply criticized politicians who offer "weak excuses" for Muslims accused of anti-Semitic crimes. "Politicians say these kids are poor and oppressed, and we have made them hate. They are, in effect, saying the behavior of these kids is in some way our fault." Judith Popinski, an 86-year-old Holocaust survivor, stated that she is no longer invited to schools that have a large Muslim presence to tell her story of surviving the Holocaust. Popinski, who found refuge in Malmö in 1945, stated that, until recently, she told her story in Malmö schools as part of their Holocaust studies program, but that now, many schools no longer ask Holocaust survivors to tell their stories, because Muslim students treat them with such disrespect, either ignoring the speakers or walking out of the class. She further stated that "Malmö reminds me of the anti-Semitism I felt as a child in Poland before the war. I am not safe as a Jew in Sweden anymore."
In December 2010, the Jewish human rights organization Simon Wiesenthal Center issued a travel advisory concerning Sweden, advising Jews to express "extreme caution" when visiting the southern parts of the country due to an alleged increase in verbal and physical harassment of Jewish citizens in the city of Malmö.
Ilmar Reepalu, the mayor of Malmö for over 15 years, has been accused of failing to protect the Jewish community in Malmö, causing 30 Jewish families to leave the city in 2010, and more preparing to leave, which has left the possibility that Malmö's Jewish community will disappear soon. Critics of Reepalu say that his statements, such as antisemitism in Malmö actually being an "understandable" consequence of Israeli policy in the Middle East, have encouraged young Muslims to abuse and harass the Jewish community. In an interview with "the Sunday Telegraph" in February 2010, Reepalu said, "There haven't been any attacks on Jewish people, and if Jews from the city want to move to Israel that is not a matter for Malmö," which renewed concerns about Reepalu.
Middle East.
Robert Bernstein, founder of Human Rights Watch, says that antisemitism is "deeply ingrained and institutionalized" in "Arab nations in modern times."
In a 2011 survey by the Pew Research Center, all of the Muslim-majority Middle Eastern countries polled held strongly negative views of Jews. In the questionnaire, only 2% of Egyptians, 3% of Lebanese Muslims, and 2% of Jordanians reported having a positive view of Jews. Muslim-majority countries outside the Middle East held similarly negative views, with 4% of Turks and 9% of Indonesians viewing Jews favorably.
Edward Rothstein, cultural critic of "The New York Times", writes that some of the dialogue from Middle East media and commentators about Jews bear a striking resemblance to Nazi propaganda. According to Josef Joffe of "Newsweek", "anti-Semitism—the real stuff, not just bad-mouthing particular Israeli policies—is as much part of Arab life today as the hijab or the hookah. Whereas this darkest of creeds is no longer tolerated in polite society in the West, in the Arab world, Jew hatred remains culturally endemic."
In the Middle East, anti-Zionist propaganda frequently adopts the terminology and symbols of the Holocaust to demonize Israel and its leaders.
Muslim clerics in the Middle East have frequently referred to Jews as descendants of apes and pigs, which are conventional epithets for Jews and Christians.
Egypt.
In Egypt, Dar al-Fadhilah published a translation of Henry Ford's antisemitic treatise, "The International Jew", complete with distinctly antisemitic imagery on the cover.
On 5 May 2001, after Shimon Peres visited Egypt, the Egyptian "al-Akhbar" internet paper said that "lies and deceit are not foreign to Jews[...]. For this reason, Allah changed their shape and made them into monkeys and pigs."
In July 2012, Egypt's Al Nahar channel fooled actors into thinking they were on an Israeli television show and filmed their reactions to being told it was an Israeli television show. In response, some of the actors launched into antisemitic rants or dialogue, and many became violent. Actress Mayer El Beblawi said that "Allah did not curse the worm and moth as much as he cursed the Jews while actor Mahmoud Abdel Ghaffar launched into a violent rage and said, "You brought me someone who looks like a Jew... I hate the Jews to death" after finding out it was a prank.
Gaza & Palestinian Territories.
Mudar Zahran, a Palestinian, writing for the Hudson Institute says that "the Palestinians have been used as fuel for the new form of anti-Semitism; this has hurt the Palestinians and exposed them to unprecedented and purposely media-ignored abuse by Arab governments, including some of those who claim love for the Palestinians, yet in fact only bear hatred to Jews. This has resulted in Palestinian cries for justice, equality, freedom and even basic human rights being ignored while the world getting consumed with delegitimizing Israel from either ignorance or malice."
Iran.
President Mahmoud Ahmadinejad of Iran has frequently denied the Holocaust. For more information, please see this page.
In July, the winner of Iran's first annual International Wall Street Downfall Cartoon Festival, jointly sponsored by the semi-state-run Iranian media outlet Fars News, was an antisemitic cartoon depicting Jews praying before the New York Stock Exchange, which is made to look like the Western Wall. Other cartoons in the contest were antisemitic as well. The national director of the Anti-Defamation League, Abraham Foxman, condemned the cartoon, stating that "Here's the anti-Semitic notion of Jews and their love for money, the canard that Jews 'control' Wall Street, and a cynical perversion of the Western Wall, the holiest site in Judaism," and "Once again Iran takes the prize for promoting antisemitism."
Lebanon.
In 2004, Al-Manar aired a drama series, "The Diaspora", which observers allege is based on historical antisemitic allegations. BBC correspondents who have watched the program says it quotes extensively from the "Protocols of the Elders of Zion".
Saudi Arabia.
The website of the Saudi Arabian Supreme Commission for Tourism initially stated that Jews would not be granted tourist visas to enter the country.
The Saudi embassy in the U.S. distanced itself from the statement, which was later removed. Members of religions other than Islam, including Jews, are not permitted to practice their religion publicly in Saudi Arabia.
In 2001, Arab Radio and Television of Saudi Arabia produced a 30-part television miniseries entitled "Horseman Without a Horse", a dramatization of "The Protocols of the Elders of Zion". One Saudi Arabian government newspaper suggested that hatred of all Jews is justifiable.
Saudi textbooks vilify Jews (and Christians and non-Wahabi Muslims): according to the 21 May 2006 issue of "The Washington Post", Saudi textbooks claimed by them to have been sanitized of antisemitism still call Jews apes (and Christians swine); demand that students avoid and not befriend Jews; claim that Jews worship the devil; and encourage Muslims to engage in Jihad to vanquish Jews.
The Center for Religious Freedom of Freedom House analyzed a set of Saudi Ministry of Education textbooks in Islamic studies courses for elementary and secondary school students. The researchers found statements promoting hate of Christians, Jews, "polytheists" and other "unbelievers," including non-Wahhabi Muslims. The Protocols of the Elders of Zion was taught as historical fact. The texts described Jews and Christians as enemies of Muslim believers and the clash between them as an ongoing fight that will end in victory over the Jews. Jews were blamed for virtually all the "subversion" and wars of the modern world. A of Saudi Arabia's curriculum has been released to the press by the Hudson Institute.
The BBC aired a Panorama episode, entitled "A Question of Leadership", which reported that al-Sudais referred to Jews as "the scum of the human race" and "offspring of apes and pigs", and stated, "the worst [...] of the enemies of Islam are those [...] whom he [...] made monkeys and pigs, the aggressive Jews and oppressive Zionists and those that follow them [...] Monkeys and pigs and worshippers of false Gods who are the Jews and the Zionists." Abdul Rahman Al-Sudais is the leading imam of the Grand mosque located in the Islamic holy city of Mecca, Saudi Arabia. In another sermon, on 19 April 2002, he declared that Jews are "evil offspring, infidels, distorters of words, calf-worshippers, prophet-murderers, prophecy-deniers [... the scum of the human race whom Allah cursed and turned into apes and pigs [...]"
Asia.
Malaysia.
Although Malaysia presently has no Jewish population, the country has reportedly become an example of a phenomenon called “Anti-Semitism without Jews." 
In his treatise on Malay identity, "The Malay Dilemma," which was published in 1970, former Malaysian Prime Minister Mahathir Mohamad wrote: "The Jews are not only hooked-nosed ... but understand money instinctively. ... Jewish stinginess and financial wizardry gained them the economic control of Europe and provoked antisemitism which waxed and waned throughout Europe through the ages."
The Malay-language Utusan Malaysia daily stated in an editorial that Malaysians "cannot allow anyone, especially the Jews, to interfere secretly in this country's business... When the drums are pounded hard in the name of human rights, the pro-Jewish people will have their best opportunity to interfere in any Islamic country," the newspaper said. "We might not realize that the enthusiasm to support actions such as demonstrations will cause us to help foreign groups succeed in their mission of controlling this country." Prime Minister Najib Razak's office susbsequently issued a statement late Monday saying Utusan's claim did "not reflect the views of the government."
Turkey.
In recent decades, synagogues have been targeted in a number of terrorist attacks. In 2003, the Neve Shalom Synagogue was targeted in a car bombing, killing 21 Turkish Muslims and 6 Jews.
In June 2011, the "Economist" suggested that "The best way for Turks to promote democracy would be to vote against the ruling party". Not long after, the Turkish Prime Minister, Recep Tayyip Erdoğan, said that "The International media, as they are supported by Israel, would not be happy with the continuation of the AKP government". The "Hurriyet Daily News" quoted Erdoğan at the time as claiming "The Economist is part of an Israeli conspiracy that aims to topple the Turkish government".
Moreover, during Erdogan's tenure, Hitler's "Mein Kampf" has once again become a best selling book in Turkey. Prime Minister Erdogan called antisemitism a "crime against humanity." He also said that "as a minority, they're our citizens. Both their security and the right to observe their faith are under our guarantee."

Armenian Genocide
The Armenian Genocide (, ), also known as the Armenian Holocaust, the Armenian Massacres and, traditionally among Armenians, as the Great Crime (, ; English transliteration: Medz Yeghern + Yeghern/Crime) was the Ottoman government's systematic extermination of its minority Armenian subjects from their historic homeland in the territory constituting the present-day Republic of Turkey. It took place during and after World War I and was implemented in two phases: the wholesale killing of the able-bodied male population through massacre and forced labor, and the deportation of women, children, the elderly and infirm on death marches to the Syrian Desert . The total number of people killed as a result has been estimated at between 1 and 1.5 million. The Assyrians, the Greeks and other minority groups were similarly targeted for extermination by the Ottoman government, and their treatment is considered by many historians to be part of the same genocidal policy.
It is acknowledged to have been one of the first modern genocides, as scholars point to the organized manner in which the killings were carried out to eliminate the Armenians, and it is the second most-studied case of genocide after the Holocaust. The word "genocide" was coined in order to describe these events.
The starting date of the genocide is conventionally held to be April 24, 1915, the day when Ottoman authorities arrested some 250 Armenian intellectuals and community leaders in Constantinople. Thereafter, the Ottoman military uprooted Armenians from their homes and forced them to march for hundreds of miles, depriving them of food and water, to the desert of what is now Syria. Massacres were indiscriminate of age or gender, with rape and other sexual abuse commonplace. The majority of Armenian diaspora communities were founded as a result of the Armenian genocide.
The Republic of Turkey, the successor state of the Ottoman Empire, denies the word "genocide" is an accurate description of the events. In recent years, it has faced repeated calls to accept the events as genocide. To date, twenty countries have officially recognized the events of the period as genocide, and most genocide scholars and historians accept this view.
Background.
Life under Ottoman rule.
Armenia had come largely under Ottoman rule during the 15th and 16th centuries. The vast majority of Armenians, grouped together under the name Armenian "millet" (community) and led by their spiritual head, the Armenian Patriarch of Constantinople, were concentrated in the eastern provinces of the Ottoman Empire (commonly referred to as Western Armenia), although large communities were also found in the western provinces, as well as in the capital Constantinople. The Armenian community was made up of three religious denominations: the Armenian Apostolic to which the overwhelming majority of Armenians belonged, and the Armenian Catholic and Armenian Protestant communities. With the exception of the empire's urban centers and the extremely wealthy, Constantinople-based "Amira" class, a social elite whose members included the Duzians (Directors of the Imperial Mint), the Balyans (Chief Imperial Architects) and the Dadians (Superintendent of the Gunpowder Mills and manager of industrial factories), most Armenians — approximately 70% of their population — lived in poor and dangerous conditions in the rural countryside.
In addition to other legal limitations, Christians were not considered equals to Muslims: testimony against Muslims by Christians and Jews was inadmissible in courts of law; they were forbidden to carry weapons or ride atop horses; their houses could not overlook those of Muslims; and their religious practices were severely circumscribed (e.g., the ringing of church bells was strictly forbidden). Violation of these statutes could result in punishments ranging from the levying of exorbitant fines to execution.
Reform implementation, 1840s–80s.
Beginning in the mid-19th century, the three major European powers, Great Britain, France and Russia (known as the Great Powers), took issue with the Empire's treatment of its Christian minorities and increasingly pressured the Ottoman government (known as the Sublime Porte) to extend equal rights to all its citizens. Starting in 1839 and ending with the declaration of a constitution in 1876, the Ottoman government implemented a series of reforms, known as the Tanzimat, to improve the situation of minorities, although these were all largely abortive. The Muslims of the empire were loath to consider the Christians as their social equals. By the late 1870s, the Greeks, along with several other Christian nations in the Balkans, frustrated with their conditions, had, often with the help of the Powers, broken free of Ottoman rule. The Armenians remained, by and large, passive during these years, earning them the title of "millet-i sadika" or the "loyal millet."
In the mid-1860s and early 1870s, things began to change as an intellectual class began to emerge among Armenian society. Educated in the European university system or in American missionary schools in the Ottoman Empire, these Armenians began to question their second-class status in society and initiated a movement that asked for better treatment from their government. In one such instance, after amassing the signatures of peasants from Western Armenia, the Armenian Communal Council petitioned to the Ottoman government to redress the issues that the peasants complained about the most: "the looting and murder in Armenian towns by Kurds and Circassians, improprieties during tax collection, criminal behavior by government officials and the refusal to accept Christians as witnesses in trial." The Ottoman government considered these grievances and promised to punish those responsible, though no meaningful steps were ever taken.
Following the violent suppression of Christians in the uprisings in Bosnia and Herzegovina, Bulgaria and Serbia in 1875, the Great Powers invoked the 1856 Treaty of Paris by claiming that it gave them the right to intervene and protect the Ottoman Empire's Christian minorities. Under growing pressure, the government of Sultan Abdul Hamid II declared itself a constitutional monarchy with a parliament (which was almost immediately prorogued) and entered into negotiations with the powers. At the same time, the Armenian patriarchate of Constantinople, Nerses II, forwarded Armenian complaints of widespread "forced land seizure… forced conversion of women and children, arson, protection extortion, rape, and murder" to the Powers.
After the conclusion of the 1877–78 Russo-Turkish War, the Armenians began to look more toward the Russian Empire as the ultimate guarantors of their security. Nerses approached the Russian leadership during its negotiations with the Ottomans in San Stefano and in the eponymous treaty, convinced them to insert a clause, Article 16, stipulating that the Russian forces occupying the Armenian-populated provinces in the eastern Ottoman Empire would withdraw only with the full implementation of reforms. Great Britain was troubled with Russia's holding on to so much Ottoman territory and forced it to enter into new negotiations with the convening of the Congress of Berlin in June 1878. Armenians also entered into these negotiations and emphasized that they sought autonomy, not independence from the Ottoman Empire. They partially succeeded, as Article 61 of the Treaty of Berlin contained the same text as Article 16 but removed any mention that Russian forces would remain in the provinces; instead, the Ottoman government was periodically to inform the Great Powers of the progress of the reforms.
Armenian revolutionary movement.
As it turned out, the reforms were not forthcoming. Upset with this turn of events, a number of disillusioned Armenian intellectuals living in Europe and Russia decided to form political parties and societies dedicated to the betterment of their compatriots living inside the Ottoman Empire. In the last quarter of the 19th century, this movement came to be dominated by three parties: the Ramkavar (Constitutional-Democrat; Armenakan), Social Democrat Hunchakian Party, and the Armenian Revolutionary Federation (Dashnaktsutiun). While the parties differed somewhat in ideology, they were all committed to the same goal of seeing the social status of Armenians in the Ottoman Empire improve. Parallel to their efforts, another group of Armenians, seeing the futility of asking for reforms and the unwillingness of the European powers in pressuring the Ottoman government to implement reforms, were convinced that the only possibility of improving the plight of the Armenians was through self-defense.
Hamidian Massacres, 1894–96.
Since 1876, the Ottoman state had been led by Sultan Abdul Hamid II. From the beginning of the reform period after the signing of the Berlin treaty, Hamid II attempted to stall their implementation and asserted that Armenians did not make up a majority in the provinces and that Armenian reports of abuses were largely exaggerated or false. In 1890, Hamid II created a paramilitary outfit known as the "Hamidiye" which was made up of Kurdish irregulars who were tasked to "deal with the Armenians as they wished." As Ottoman officials intentionally provoked rebellions (often as a result of over-taxation) in Armenian populated towns, such as in Sasun in 1894 and Zeitun in 1895–96, these regiments were increasingly used to deal with the Armenians by way of oppression and massacre. In some instances, Armenians successfully fought off the regiments and brought the excesses to the attention of the Great Powers in 1895 who subsequently condemned the Porte.
The Powers forced Hamid to sign a new reform package designed to curtail the powers of the "Hamidiye" in October 1895 which, like the Berlin treaty, was never implemented. On October 1, 1895, 2,000 Armenians assembled in Constantinople to petition for the implementation of the reforms but Ottoman police units converged towards the rally and violently broke it up. Soon, massacres of Armenians broke out in Constantinople and then engulfed the rest of the Armenian-populated provinces of Bitlis, Diyarbekir, Erzerum, Harput, Sivas, Trabzon and Van. Estimates differ on how many Armenians were killed but European documentation of the violence, which became known as the Hamidian massacres, placed the figures from anywhere between 100–300,000 Armenians.
Although Hamid was never directly implicated in ordering the massacres, it is believed that they had his tacit encouragement approval. Frustrated with European indifference to the massacres, Armenians from the Dashnaktsutiun party seized the European-managed Ottoman Bank on August 26, 1896. This incident brought further sympathy for Armenians in Europe and was lauded by the European and American press, which vilified Hamid and painted him as the "great assassin" and "bloody Sultan." While the Great Powers vowed to take action and enforce new reforms, these never came into fruition due to conflicting political and economic interests.
Prelude to genocide.
The Young Turk Revolution of 1908.
On July 24, 1908, Armenians' hopes for equality in the empire brightened once more when a coup d'état staged by officers in the Turkish Third Army based in Salonika removed Abdul Hamid from power and restored the country to a constitutional monarchy. The officers were part of the Young Turk movement that wanted to reform administration of the decadent state of the Ottoman Empire and modernize it to European standards. The movement was an anti-Hamidian coalition made up of two distinct groups: the secular liberal constitutionalists and the nationalists; the former was more democratic and accepted Armenians into their wing whereas the latter was more intolerant in regard to Armenian-related issues and their frequent requests for European assistance. In 1902, during a congress of the Young Turks held in Paris, the heads of the liberal wing, Sabahheddin Bey and Ahmed Riza, partially persuaded the nationalists to include in their objectives to ensure some rights to all the minorities of the empire.
One of the numerous factions within the Young Turk movement was a secret revolutionary organization called The Committee of Union and Progress. It drew its proliferating membership from disaffected army officers based in Salonika and was behind a wave of mutinies against the central government. In 1908, elements of the Third Army and the Second Army Corps declared their opposition to the Sultan and threatened to march on the capital to depose him. Hamid, shaken by the wave of resentment, stepped down from power as Armenians, Greeks, Arabs, Bulgarians and Turks alike rejoiced in his dethronement.
The Adana Massacre of 1909.
A countercoup took place on April 13, 1909. Some Ottoman military elements, joined by Islamic theological students, aimed to return control of the country to the Sultan and the rule of Islamic law. Riots and fighting broke out between the reactionary forces and CUP forces, until the CUP was able to put down the uprising and court-martial the opposition leaders.
While the movement initially targeted the Young Turk government, it spilled over into pogroms against Armenians who were perceived as having supported the restoration of the constitution. When Ottoman Army troops were called in, many accounts record that instead of trying to quell the violence they actually took part in pillaging Armenian enclaves in Adana province. 15,000–30,000 Armenians were killed in the course of the "Adana Massacre".
The Balkan wars.
In 1912, the First Balkan War broke out and resulted in a defeat of the Ottoman Empire and the loss of 85% of its territory in Europe. Many in the empire saw their defeat as "Allah's divine punishment for a society that did not know how to pull itself together." The Turkish nationalist movement in the country gradually came to view Anatolia as their last refuge. That the Armenian population formed a significant minority in this region would figure prominently in the calculations of the Young Turks who would eventually carry out the Armenian Genocide.
An important consequence of the Balkan Wars was also the mass expulsion of Muslims (known as "muhajirs") from the Balkans. In fact, beginning in the mid-19th century, hundreds of thousands of Muslims, including Circassians and Chechens, were expelled or forced to flee from the Caucasus and the Balkans (Rumelia) as a result of the Russo-Turkish wars and the conflicts in the Balkans. Muslim society in the empire was incensed by this flood of refugees and overcome by a sense of revenge. A journal published in Constantinople expressed the mood of the times: "Let this be a warning...O Muslims, don't get comfortable! Do not let your blood cool before taking revenge." As many as 850,000 of these refugees were settled in areas where the Armenians were resident from the period of 1878–1904. The "muhajirs" resented the status of their relatively well-off neighbors and, as historian Taner Akçam and others have noted, the refugees would come to play a pivotal role in the killings of the Armenians and the confiscation of their properties during the genocide.
World War I.
On November 2, 1914, the Ottoman Empire entered World War I on the side of the Central Powers. The Middle Eastern theatre of World War I became the scene of action. The combatants were the Ottoman Empire, with some assistance from the other Central Powers, and primarily the British and the Russians among the Allies of World War I. The conflicts at the Caucasus Campaign, the Persian Campaign and the Gallipoli Campaign affected where the Armenian people lived in significant amounts. Before the declaration of war at the Armenian congress at Erzurum the Ottoman government requested the Ottoman Armenians to facilitate the conquest of Transcaucasia by inciting a rebellion with the Russian Armenians against the tsarist army in the event of a Caucasus front.
Battle of Sarikamish.
On December 24, 1914 Minister of War Enver Pasha developed a plan to encircle and destroy the Russian Caucasus Army at Sarikamish, to regain territories lost to Russia after the Russo-Turkish War of 1877–78. Enver Pasha's forces were routed at the Battle of Sarikamis, and almost completely destroyed.
In the summer of 1914, Armenian volunteer units were established under the Russian Armed forces. As the Russian Armenian conscripts had already been sent to the European Front, this force was uniquely established from Armenians that were not Russian or who were not obligated to serve. An Ottoman representative, Karekin Bastermadjian (Armen Karo), was also brought into to this force. Initially they had 20,000 men, but it was reported that their number subsequently increased. Returning to Constantinople, Enver publicly blamed his defeat on Armenians in the region having actively sided with the Russians.
Labor battalions, February 25.
On February 25, 1915, The War minister Enver Pasha sent an order to all military units that Armenians in the active Ottoman forces be demobilized and assigned to the unarmed Labour battalion (Turkish: "amele taburlari"). Enver Pasha explained this decision as "out of fear that they would collaborate with the Russians". As a tradition, the Ottoman Army drafted non-Muslim males only between the ages of 20 and 45 into the regular army. The younger (15–20) and older (45–60) non-Muslim soldiers had always been used as logistical support through the labor battalions. Before February, some of the Armenian recruits were utilized as laborers ("hamals"), though they would ultimately be executed.
Transferring Armenian conscripts from active field (armed) to passive, unarmed logistic section was an important aspect of the subsequent genocide. As reported in "The Memoirs of Naim Bey", the extermination of the Armenians in these battalions was part of a premeditated strategy on behalf of the Committee of Union and Progress. Many of these Armenian recruits were executed by local Turkish gangs.
Events at Van, April 1915.
On April 19, 1915, Jevdet Bey demanded that the city of Van immediately furnish him 4,000 soldiers under the pretext of conscription. However, it was clear to the Armenian population that his goal was to massacre the able-bodied men of Van so that there would be no defenders. Jevdet Bey had already used his official writ in nearby villages, ostensibly to search for arms, but in fact to initiate wholesale massacres. The Armenians offered five hundred soldiers and exemption money for the rest in order to buy time, but Djevdet accused Armenians of "rebellion" and asserted his determination to "crush" it at any cost. "If the rebels fire a single shot", he declared, "I shall kill every Christian man, woman, and" (pointing to his knee) "every child, up to here."
On April 20, 1915, the armed conflict of the Siege of Van began when an Armenian woman was harassed and the two Armenian men that came to her aid were killed by Ottoman soldiers. The Armenian defenders protected 30,000 residents and 15,000 refugees in an area of roughly one square kilometer of the Armenian Quarter and suburb of Aigestan with 1,500 ablebodied riflemen who were supplied with 300 rifles and 1,000 pistols and antique weapons. The conflict lasted until General Yudenich came to rescue them.
Similar reports reached Morgenthau from Aleppo and Van, prompting him to raise the issue in person with Talaat and Enver. As he quoted to them the testimonies of his consulate officials, they justified the deportations as necessary to the conduct of the war, suggesting that complicity of the Armenians of Van with the Russian forces that had taken the city justified the persecution of all ethnic Armenians.
Arrest and deportation of Armenian notables, April 1915.
On April 24, 1915, Red Sunday (), was the night on which the leaders of Armenians of the Ottoman capital, Constantinople, and later extending to other Ottoman centers were arrested and moved to two holding centers near Ankara by then minister of interior Mehmed Talaat Bey with his . These Armenians were later deported with the passage of Tehcir Law on 29 May 1915. The date 24 April, Genocide Remembrance Day, commemorates the Armenian notables deported from the Ottoman capital in 1915, as the precursor to the ensuing events.
On the night of April 24, 1915, the Ottoman government rounded up and imprisoned an estimated 250 Armenian intellectuals and community leaders. This date coincided with Allied troop landings at Gallipoli after unsuccessful Allied naval attempts to break through the Dardanelles to Constantinople in February and March 1915.
Triple Entente's reaction.
On May 24, 1915, the Triple Entente warned the Ottoman Empire that "In view of these new crimes of Turkey against humanity and civilization, the Allied Governments announce publicly to the Sublime Porte that they will hold personally responsible for these crimes all members of the Ottoman Government, as well as those of their agents who are implicated in such massacres."
Massacres.
Mass burnings.
Eitan Belkind was a Nili member, who infiltrated the Ottoman army as an official. He was assigned to the headquarters of Kamal Pasha. He claims to have witnessed the burning of 5,000 Armenians.
Lt. Hasan Maruf, of the Ottoman army, describes how a population of a village were taken all together, and then burned. The Commander of the Third Army Vehib's 12-page affidavit, which was dated 5 December 1918, was presented in the Trabzon trial series (March 29, 1919) included in the Key Indictment, reporting such a mass burning of the population of an entire village near Mush. that in Bitlis, Mus and Sassoun, "The shortest method for disposing of the women and children concentrated in the various camps was to burn them." And also that "Turkish prisoners who had apparently witnessed some of these scenes were horrified and maddened at remembering the sight. They told the Russians that the stench of the burning human flesh permeated the air for many days after."
Drowning.
Trabzon was the main city in Trabzon province; Oscar S. Heizer, the American consul at Trabzon, reports: "This plan did not suit Nail Bey... Many of the children were loaded into boats and taken out to sea and thrown overboard." The Italian consul of Trabzon in 1915, Giacomo Gorrini, writes: "I saw thousands of innocent women and children placed on boats which were capsized in the Black Sea." The Trabzon trials reported Armenians having been drowned in the Black Sea.
Hoffman Philip, the American Charge at Constantinople chargé d'affaires, writes: "Boat loads sent from Zor down the river arrived at Ana, one thirty miles away, with three fifths of passengers missing."
Use of poison and drug overdoses.
The psychiatrist Robert Jay Lifton writes in a parenthesis when introducing the crimes of Nazi doctors, "Perhaps Turkish doctors, in their participation in the genocide against the Armenians, come closest, as I shall later suggest."
Morphine overdose: During the Trabzon trial series of the Martial court, from the sittings between March 26 and May 17, 1919, the Trabzons Health Services Inspector Dr. Ziya Fuad wrote in a report that Dr. Saib caused the death of children with the injection of morphine. The information was allegedly provided by two physicians (Drs. Ragib and Vehib), both Dr. Saib's colleagues at Trabzons Red Crescent hospital, where those atrocities were said to have been committed.
Toxic gas: Dr. Ziya Fuad and Dr. Adnan, public health services director of Trabzon, submitted affidavits reporting cases in which two school buildings were used to organize children and send them to the mezzanine to kill them with toxic gas equipment.
Typhoid inoculation: The Ottoman surgeon, Dr. Haydar Cemal wrote "on the order of the Chief Sanitation Office of the Third Army in January 1916, when the spread of typhus was an acute problem, innocent Armenians slated for deportation at Erzican were inoculated with the blood of typhoid fever patients without rendering that blood ‘inactive’." Jeremy Hugh Baron writes: "Individual doctors were directly involved in the massacres, having poisoned infants, killed children and issued false certificates of death from natural causes. Nazim's brother-in-law Dr. Tevfik Rushdu, Inspector-General of Health Services, organized the disposal of Armenian corpses with thousands of kilos of lime over six months; he became foreign secretary from 1925 to 1938."
Deportations.
In May 1915, Mehmed Talaat Pasha requested that the cabinet and Grand Vizier Said Halim Pasha legalize a measure for relocation and settlement of Armenians to other places due to what Talaat Pasha called "the Armenian riots and massacres, which had arisen in a number of places in the country." However, Talaat Pasha was referring specifically to events in Van and extending the implementation to the regions in which alleged "riots and massacres" would affect the security of the war zone of the Caucasus Campaign. Later, the scope of the immigration was widened in order to include the Armenians in the other provinces.
On 13 September 1915, the Ottoman parliament passed the "Temporary Law of Expropriation and Confiscation", stating that all property, including land, livestock, and homes belonging to Armenians, was to be confiscated by the authorities.
With the implementation of Tehcir law, the confiscation of Armenian property and the slaughter of Armenians that ensued upon the law's enactment outraged much of the western world. While the Ottoman Empire's wartime allies offered little protest, a wealth of German and Austrian historical documents has since come to attest to the witnesses' horror at the killings and mass starvation of Armenians. In the United States, "The New York Times" reported almost daily on the mass murder of the Armenian people, describing the process as "systematic", "authorized" and "organized by the government." Theodore Roosevelt would later characterize this as "the greatest crime of the war."
Historian Hans-Lukas Kieser states that, from the statements of Talat Pasha it is clear that the officials were aware that the deportation order was genocidal. Another historian Taner Akçam states that the telegrams show that the overall coordination of the genocide was taken over by Talat Paşa.
Death marches.
The Armenians were marched out to the Syrian town of Deir ez-Zor and the surrounding desert. A good deal of evidence suggests that the Ottoman government did not provide any facilities or supplies to sustain the Armenians during their deportation, nor when they arrived. By August 1915, "The New York Times" repeated an unattributed report that "the roads and the Euphrates are strewn with corpses of exiles, and those who survive are doomed to certain death. It is a plan to exterminate the whole Armenian people."
Ottoman troops escorting the Armenians not only allowed others to rob, kill, and rape the Armenians, but often participated in these activities themselves. Deprived of their belongings and marched into the desert, hundreds of thousands of Armenians perished.
Similarly, Major General Friedrich Freiherr Kress von Kressenstein noted that "The Turkish policy of causing starvation is an all too obvious proof… for the Turkish resolve to destroy the Armenians."
Extermination camps.
It is believed that 25 major concentration camps existed, under the command of Şükrü Kaya, one of the right-hand men of Talaat Pasha. The majority of the camps were situated near Turkey's modern Iraqi and Syrian borders, and some were only temporary transit camps. Others, such as Radjo, Katma, and Azaz, are said to have been used only temporarily, for mass graves; these sites were vacated by autumn 1915. Some authors also maintain that the camps Lale, Tefridje, Dipsi, Del-El, and Ra's al-'Ayn were built specifically for those who had a life expectancy of a few days.
Relief.
The American Committee for Relief in the Near East is a relief organization established in 1915, just after the deportations, whose primary aim was to alleviate the suffering of the Armenian people. Henry Morgenthau played a key role in rallying support for the organization. Between 1915 and 1930, distributed humanitarian relief across a wide range of geographical locations. ACRNE eventually spent over ten times the initial estimate, see original estimate, that amount and helped an estimated close to 2,000,000 refugees.
In its first year, the ACRNE cared for 132,000 Armenian orphans from Tiflis, Yerevan, Constantinople, Sivas, Beirut, Damascus, and Jerusalem. A relief organization for refugees in the Middle East helped donate over $102 million (budget $117,000,000) value of dollar to Armenians both during and after the war.
Teshkilat-i Mahsusa.
The Committee of Union and Progress founded a "special organization" () that participated in the destruction of the Ottoman Armenian community. This organization adopted its name in 1913 and functioned like a special forces outfit, and it has been compared by some scholars to the Nazi Einsatzgruppen. Later in 1914, the Ottoman government influenced the direction the special organization was to take by releasing criminals from central prisons to be the central elements of this newly formed special organization. According to the Mazhar commissions attached to the tribunal as soon as November 1914, 124 criminals were released from Pimian prison. Little by little from the end of 1914 to the beginning of 1915, hundreds, then thousands of prisoners were freed to form the members of this organization. Later, they were charged to escort the convoys of Armenian deportees. Vehib Pasha, commander of the Ottoman Third Army, called those members of the special organization, the "butchers of the human species."
Trials.
Turkish courts-martial.
The term Three Pashas, which include Mehmed Talaat Pasha and Ismail Enver, refers to the triumvirate who had fled the Empire at the end of World War I. At the trials in Constantinople in 1919 they were sentenced to death in absentia. The courts-martial officially disbanded the CUP and confiscated its assets, and the assets of those found guilty. At least two of the three were later assassinated by Armenian vigilantes.
International trials.
Following the Mudros Armistice, the preliminary Peace Conference in Paris established "The Commission on Responsibilities and Sanctions" in January 1919, which was chaired by US Secretary of State Lansing. Based on the commission's work, several articles were added to the Treaty of Sèvres, and the acting government of the Ottoman Empire, Sultan Mehmed VI and Damat Adil Ferit Pasha, were summoned to trial. The Treaty of Sèvres (August 1920) planned a trial to determine those responsible for the "barbarous and illegitimate methods of warfare… offenses against the laws and customs of war and the principles of humanity". Article 230 of the Treaty of Sèvres required the Ottoman Empire "hand over to the Allied Powers the persons whose surrender may be required by the latter as being responsible for the massacres committed during the continuance of the state of war on territory which formed part of the Ottoman Empire on August 1, 1914."
Various Ottoman politicians, generals, and intellectuals were transferred to Malta, where they were held for some three years while searches were made of archives in Constantinople, London, Paris and Washington to investigate their actions. However, the Inter-allied tribunal attempt demanded by the Treaty of Sèvres never solidified and the detainees were eventually returned to Turkey in exchange for British citizens held by Kemalist Turkey.
Trial of Soghomon Tehlirian.
On March 15, 1921, former Grand Vizier Talaat Pasha was assassinated in the Charlottenburg District of Berlin, Germany, in broad daylight and in the presence of many witnesses. Talaat's death was part of ""Operation Nemesis"", the Armenian Revolutionary Federation's codename for their covert operation in the 1920s to kill the planners of the Armenian Genocide.
The subsequent trial of the assassin, Soghomon Tehlirian, had an important influence on Raphael Lemkin, a lawyer of Polish–Jewish descent who campaigned in the League of Nations to ban what he called "barbarity" and "vandalism". The term "genocide", created in 1943, was coined by Lemkin who was directly influenced by the massacres of Armenians during World War I.
Armenian population, deaths, survivors, 1914 to 1918.
While there is no consensus as to how many Armenians lost their lives during the Armenian Genocide, there is general agreement among western scholars that over 500,000 Armenians died between 1914 and 1918. Estimates vary between 600,000, to 1,500,000 (per Western scholars, Argentina, and other states). "Encyclopædia Britannica" references the research of Arnold J. Toynbee, an intelligence officer of the British Foreign Office, who estimated that 600,000 Armenians "died or were massacred during deportation" in the years 1915–16. According to the Ottoman Census in 1914 (before the genocide) the total Armenian population was 1,219,323.
Contemporaneous reports and reactions.
Hundreds of eyewitnesses, including the neutral United States and the Ottoman Empire's own allies, Germany and Austria-Hungary, recorded and documented numerous acts of state-sponsored massacres. Many foreign officials offered to intervene on behalf of the Armenians, including Pope Benedict XV, only to be turned away by Ottoman government officials who claimed they were retaliating against a pro-Russian insurrection. On May 24, 1915, the Triple Entente warned the Ottoman Empire that "In view of these new crimes of Turkey against humanity and civilization, the Allied Governments announce publicly to the Sublime Porte that they will hold personally responsible for these crimes all members of the Ottoman Government, as well as those of their agents who are implicated in such massacres."
The American Committee for Relief in the Near East (ACRNE, or "Near East Relief") was a charitable organization established to relieve the suffering of the peoples of the Near East. The organization was championed by Henry Morgenthau, Sr., American ambassador to the Ottoman Empire. Morgenthau's dispatches on the mass slaughter of Armenians galvanized much support for ACRNE.
The U.S. Mission in the Ottoman Empire.
The United States had several consulates throughout the Ottoman Empire, including locations in Edirne, Kharput, Samsun, Smyrna, Trebizond, Van, Constantinople, and Aleppo. The United States was officially a neutral party until it joined with the Allies in 1917. In addition to the consulates, there were also numerous Protestant missionary compounds established in Armenian-populated regions, including Van and Kharput. The events were reported regularly in newspapers and literary journals around the world.
On his return to the United States having served for thirty years as United States Consul and Consul General in the Near East, George Horton wrote his own account of "the Systematic Extermination of Christian Populations by Mohammedans and of the Culpability of Certain Great Powers; with the True Story of the Burning of Smyrna". Horton's account quotes numerous contemporary communications and eyewitness reports including eyewitness accounts of the massacre of Phocea in 1914 by a Frenchman and the Armenian massacres of 1914/15 by an American citizen and a German missionary.
Many Americans vocally spoke out against the genocide, including former president Theodore Roosevelt, rabbi Stephen Wise, William Jennings Bryan, and Alice Stone Blackwell. In the United States and the United Kingdom, children were regularly reminded to clean their plates while eating and to "remember the starving Armenians."
Ambassador Morgenthau's Story.
As the orders for deportations and massacres were enacted, many consular officials reported to the ambassador what they were witnessing. In his memoirs which he completed writing in 1918, Morgenthau wrote, "When the Turkish authorities gave the orders for these deportations, they were merely giving the death warrant to a whole race; they understood this well, and, in their conversations with me, they made no particular attempt to conceal the fact…" In memoirs and reports, their staff vividly described the brutal methods used by Ottoman forces and documented numerous instances of atrocities committed against the Christian minority.
Allied forces in the Middle East.
Winston Churchill described the massacres as an "administrative holocaust" and noted that "the clearance of the race from Asia Minor was about as complete as such an act, on a scale so great, could well be. […] There is no reasonable doubt that this crime was planned and executed for political reasons. The opportunity presented itself for clearing Turkish soil of a Christian race opposed to all Turkish ambitions, cherishing national ambitions that could only be satisfied at the expense of Turkey, and planted geographically between Turkish and Caucasian Moslems."
Arnold Toynbee: The Treatment of Armenians.
Arnold J. Toynbee published a widely studied book The treatment of Armenians in the Ottoman Empire in 1916. It was a collection of documents. Reacting to numerous eyewitness accounts, British politician Viscount Bryce and historian Toynbee compiled statements from survivors and eyewitnesses from other countries including Germany, Italy, the Netherlands, Sweden, and Switzerland, who similarly attested to the systematized massacring of innocent Armenians by Ottoman government forces.
The book has since been criticized as British wartime propaganda to build up sentiment against the Central Powers, but Bryce had submitted the work to scholars for verification before its publication. University of Oxford Regius Professor Gilbert Murray stated, "…the evidence of these letters and reports will bear any scrutiny and overpower any skepticism. Their genuineness is established beyond question." Other professors, including Herbert Fisher of Sheffield University and former American Bar Association president Moorfield Storey, came to the same conclusion.
Joint Austrian and German mission.
As allies during the war, the Imperial German mission in the Ottoman Empire included both military and civilian components. Germany had brokered a deal with the Sublime Porte to commission the building of a railroad stretching from Berlin to the Middle East, called the Baghdad Railway. Germany's diplomatic mission at the beginning of 1915 was led by Ambassador Baron Hans Freiherr von Wangenheim (who was later succeeded by Count Paul Wolff Metternich following his death in 1915). Like Morgenthau, von Wangenheim began to receive many disturbing messages from consul officials around the Ottoman Empire detailing the massacre of Armenians. From the province of Adana, Consul Eugene Buge reported that the CUP chief had sworn to kill and massacre any Armenians who survived the deportation marches. In June 1915, von Wangenheim sent a cable to Berlin reporting that Talat had admitted that the deportations were not "being carried out because of 'military considerations alone.'" One month later, he came to the conclusion that there "no longer was doubt that the Porte was trying to exterminate the Armenian race in the Turkish Empire."
When Wolff-Metternich succeeded von Wangenheim, he continued to dispatch similar cables: "The Committee demands the extirpation of the last remnants of the Armenians and the government must yield… A Committee representative is assigned to each of the provincial administrations… Turkification means license to expel, to kill or destroy everything that is not Turkish."
Another notable figure in the German military camp was Max Erwin von Scheubner-Richter, who documented various massacres of Armenians. He sent fifteen reports regarding "deportations and mass killings" to the German chancellery. His final report noted that fewer than 100,000 Armenians were left alive in the Ottoman Empire: the rest having been exterminated (). Scheubner-Richter also detailed the methods of the Ottoman government, noting its use of the Special Organization and other bureaucratized instruments of genocide.
I have lived in Turkey the larger part of my life… and I know the Armenians. I also know that both Armenians and Turks cannot live together in this country. One of these races has got to go. And I don't blame the Turks for what they are doing to the Armenians. I think that they are entirely justified. The weaker nation must succumb. The Armenians desire to dismember Turkey; they are against the Turks and the Germans in this war, and they therefore have no right to exist here.
In a genocide conference held in 2001, professor Wolfgang Wipperman of the Free University of Berlin introduced documents evidencing that the German High Command was aware of the mass killings at the time but chose not to interfere or speak out.
Photographs exist that may also suggest the Germans participated in the mass killing and some of the German witnesses to the Armenian holocaust would go on to play a role in the Nazi regime - Konstantin Freiherr von Neurath, for example, was attached to the Turkish 4th Army in 1915 with instructions to monitor "operations" against the Armenians who later became Hitler's foreign minister and "Protector of Bohemia and Moravia" during Reinhard Heydrich's terror in Czechoslovakia.
Armin T. Wegner.
German military medic Armin T. Wegner enrolled as a medic at the outbreak of World War I during the winter of 1914–15. He defied censorship in taking hundreds of photographs of Armenians being deported and subsequently starving in northern Syrian camps and in the deserts of Der Zor. Wegner was part of a German detachment under von der Goltz stationed near the Baghdad Railway in Mesopotamia. Wegner was eventually arrested by the Germans and recalled to Germany.
Wegner protested against the atrocities perpetrated in an open letter submitted to US President Woodrow Wilson at the peace conference of 1919. The letter made a case for the creation of an independent Armenian state. Also in 1919, Wegner published "The Road of No Return" ("Der Weg ohne Heimkehr"), a collection of letters he had written during what he deemed the "martyrdom" (German: "Martyrium") of the Armenians. A documentary film depicting Wegner's personal account of the Armenian Genocide through his own photographs called "Destination Nowhere: The Witness" and produced by Dr J Michael Hagopian premiered in Fresno on 25 April 2000. Prior to the release of the documentary he was honored at the Armenian Genocide Museum in Yerevan for championing the plight of Armenians throughout his life.
Russian military.
The Russian Empire's response to the bombardment of its Black Sea naval ports was primarily a land campaign through the Caucasus. Early victories against the Ottoman Empire from the winter of 1914 to the spring 1915 saw significant gains of territory, including relieving the Armenian bastion resisting in the city of Van in May 1915. The Russians also reported encountering the bodies of unarmed civilian Armenians as they advanced. In March 1916, the scenes they saw in the city of Erzerum led the Russians to retaliate against the Ottoman III Army whom they held responsible for the massacres, destroying it in its entirety.
Swedish Embassy and Military Attaché.
On August 9, 1915, Anckarsvärd dispatched yet another report, confirming his suspicions regarding the plans of the Turkish government, "It is obvious that the Turks are taking the opportunity to, now during the war, annihilate [utplåna] the Armenian nation so that when the peace comes no Armenian question longer exists."
When reflecting upon the situation in Turkey during the final stages of the war, Envoy Alhgren presented an analysis of the prevailing situation in Turkey and the hard times which had befallen the population. In explaining the increased living costs he identified a number of reasons: "obstacles for domestic trade, the almost total paralysing of the foreign trade and finally the strong decreasing of labour power, caused partly by the mobilisation but partly also by the extermination of the Armenian race af den armeniska rasen."
Wirsén, when writing his memoirs from his mission to the Balkans and Turkey, "Minnen från fred och krig" ("Memories from Peace and War"), dedicated an entire chapter to the Armenian genocide, entitled "Mordet på en nation" ("The Murder of a Nation"). Commenting on the interpretation that the deportations resulted from the purported collaboration of the Armenians with the Russians, Wirsen concludes that their subsequent deportations were nothing but a cover for their extermination.: "Officially, these had the goal to move the entire Armenian population to the steppe regions of Northern Mesopotamia and Syria, but in reality they aimed to exterminate the Armenians, whereby the pure Turkish element in Asia Minor would achieve a dominating position."
In conclusion, Wirsén made the following note: "The annihilation of the Armenian nation in Asia Minor must revolt all human feelings… The way the Armenian problem was solved was hair-raising. I can still see in front of me Talaat's cynical expression, when he emphasized that the Armenian question was solved."
Bodil Biørn.
In 1905 the missionary nurse Bodil Biørn (1871–1960) was sent to Armenia. First based in the town of Mezereh (now Elazig) and later in Mush, she worked for widows and orphaned children in cooperation with missionaries from the German Hülfsbund. She witnessed the massacres of 1915 in Mush and saw most of the children in her care murdered along with Armenian priests, teachers, and assistants. She barely escaped after 9 days on horseback but stayed on in the region for another 2 years under increasingly difficult working conditions. After a period at home she again went to Armenia and, until she retired in 1935, worked for Armenian refugees in Syria and Lebanon. Bodil Biørn was also an able photographer. Many of her photos are now in the WMF archive, which since the organisation was dissolved in 1982 has been preserved in the National Archives of Norway. In combination with her comments, written in her photo albums or on the back of the prints themselves, these photos bear strong witness of the atrocities that she saw.
Ottoman reactions.
Halil Paşa (Kut), uncle of Enver Paşa wrote "Armenian nations whom I tried to annihilate to the last member of them, because of trying erase us from history as prisoners of the enemy in the most horrible and painful days of my homeland…" in his memory.
In 1919, Ahmet Refik wrote "the Unionists (Committee of Union and Progress) wanted to remove the problem of Vilâyât-ı Sitte with annihilating Armenians" in his work entitled "İki Komite İki Kıtal".
Persia.
Throughout history, the nation of Persia (now known as Iran) has usually regarded itself as the protector of Armenian nation whom they considered as fellows due to their both belonging to the Aryan race. However, in this case, due to the weak central government in Tehran's inability to protect its territorial integrity, no resistance was offered by the mostly Islamic Persian troops when, after the withdrawal of Russian troops from the extreme northwest of Persia, Islamic Turks invaded the town of Salmas in northwestern Persia and tortured and massacred the Christian Armenian inhabitants in the cruelest possible manner.
Study of the Armenian Genocide.
The Armenian Genocide is widely corroborated by the international genocide scholars. The International Association of Genocide Scholars (IAGS), consisting of world's foremost experts on genocide, unanimously passed a formal resolution affirming the fact of the Armenian Genocide. According to IAGS, "Every book on comparative genocide studies in the English language contains a segment on the Armenian Genocide. Leading texts in the international law of genocide such as William Schabas's 'Genocide in International Law' cite the Armenian Genocide as presursor to the Holocaust and as a precedent for the law on crimes against humanity. Polish Jurist Raphael Lemkin, when he coined the term genocide in 1944, cited the Turkish extermination of the Armenians and the Nazi extermination of the Jews as defining examples of what he meant by genocide. The killings of Armenians is genocide as defined by the 1948 United Nations Convention on the Prevention and Punishment of the Crime of Genocide. 126 leading scholars of the holocaust including Elie Wiesel, and Yehuda Bauer placed a statement in the "New York Times" in June 2000 declaring the "inconstestable fact of the Armenian genocide" and urging western democracies to acknowledge it. "The Institute on the Holocaust and Genocide (Jerusalem), and the Institute for the Study of Genocide (NYC), have affirmed the historical fact of the Armenian Genocide." 
British historian Arnold J. Toynbee, whose 1917 report remains a critical primary source, changed his evaluation later in life, concluding, "These…Armenian political aspirations had not been legitimate...Their aspirations did not merely threaten to break up the Turkish Empire; they could not be fulfilled without doing grave injustice to the Turkish people itself."
For Turkish historians, supporting the national republican myth is essential to preserving Turkish national unity. The usual Turkish argument is that the deportations were necessary because the Armenians had allied themselves with the Russian army in wartime and that around 600,000 Armenians perished during the marches, largely due to isolated massacres, disease, or malnourishment. "There was no genocide committed against the Armenians in the Ottoman Empire before or during World War I." Genocide scholars Roger Smith, Eric Markusen, and Robert Jay Lifton wrote in "Professional Ethics and the Denial of the Armenian Genocide" (Holocaust and Genocide Studies): "Where scholars deny genocide in the face of decisive evidence ... they contribute to false consciousness that can have the most dire reverbrations. Their message, in effect, is ... mass murder requires no confrontation, no reflection, but should be ignored, glossed over." Some dissident historians and scholars in Turkey, including Yektan Türkyilmaz, have been trying to reclaim the Armenians as part of Ottoman and Turkish history and acknowledge the wrongs done to the Armenians as a condition for reconciliation with them on the basis of confidence in Turkish national unity.
Defining "genocide".
Law professor Raphael Lemkin, who coined the term "genocide" in 1943, has stated that he did so with the fate of the Armenians in mind, explaining that "it happened so many times… First to the Armenians, then after the Armenians, Hitler took action." Several international organizations have conducted studies of the events, each in turn determining that the term "genocide" aptly describes "the Ottoman massacre of Armenians in 1915–16." Among the organizations affirming this conclusion are the International Center for Transitional Justice, the International Association of Genocide Scholars, and the United Nations' Sub-Commission on Prevention of Discrimination and Protection of Minorities. One public figure who objected to the use of the term "genocide" was Israeli Foreign Minister Shimon Peres, who was subsequently rebutted by Dr Israel Charny, executive director of the Institute on the Holocaust and Genocide in Jerusalem.
In 2002, the International Center for Transitional Justice (ICTJ) was asked by the Turkish Armenian Reconciliation Commission to provide a report on the applicability of the Genocide Convention to the controversy. An independent legal counsel drafted memorandum for the ICTJ stated that in the opinion of the independent legal counsel "legal scholars as well as historians, politicians, journalists and other people would be justified in continuing to so describe events as genocide" and further that the Republic of Turkey was not liable for the event.
In 2005, the International Association of Genocide Scholars affirmed that scholarly evidence revealed the "Young Turk government of the Ottoman Empire began a systematic genocide of its Armenian citizens – an unarmed Christian minority population. More than a million Armenians were exterminated through direct killing, starvation, torture, and forced death marches." The IAGS also condemned Turkish attempts to deny the factual and moral reality of the Armenian Genocide. In 2007, the Elie Wiesel Foundation for Humanity] produced a letter signed by 53 Nobel Laureates re-affirming the Genocide Scholars' conclusion that the 1915 killings of Armenians constituted genocide.
While some consider denial to be a form of hate speech or politically minded historical revisionism, several western academics have expressed doubts as to the genocidal character of the events. The most important counterpoint may be that of British scholar Bernard Lewis. While he had once written of "the terrible holocaust of 1915, when a million and a half Armenians perished", he later came to believe that the term "genocide" was distinctly inaccurate, because the "tremendous massacres" were not "a deliberate preconceived decision of the Turkish government." This opinion has been joined by Guenter Lewy.
Academic views within the Republic of Turkey are often at odds with international consensus: this may partly stem from the fact that to acknowledge the Armenian genocide in Turkey carries with it a risk of criminal prosecution. Many Turkish intellectuals have been prosecuted for characterizing the massacres as genocide.
Bat Ye'or has suggested that "the genocide of the Armenians was a jihad." Ye'or holds jihad and what she calls "dhimmitude" to be among the "principles and values" that led to the Armenian Genocide. This perspective is challenged by Fà'iz el-Ghusein, a Bedouin Arab witness of the Armenian persecution, whose 1918 treatise aimed "to refute beforehand inventions and slanders against the Faith of Islam and against Moslems generally… the Armenians have suffered is to be attributed to the Committee of Union and Progress… [It has been due to their nationalist fanaticism and their jealousy of the Armenians, and to these alone; the Faith of Islam is guiltless of their deeds." Arnold Toynbee writes that "the Young Turks made Pan-Islamism and Turkish Nationalism work together for their ends, but the development of their policy shows the Islamic element receding and the Nationalist gaining ground." Toynbee, and various other sources, report that many Armenians were spared death by marrying into Turkish families or converting to Islam. El-Ghusein points out that many converts were put to death, concerned that Westerners would come to regard the "extermination of the Armenians" as "a black stain on the history of Islam, which ages will not efface." In one instance, when an Islamic leader appealed to spare Armenian converts to Islam, El-Ghusein quotes a government functionary as responding that "politics have no religion", before sending the converts to their deaths.
Noam Chomsky has suggested that, rather than the Armenian Genocide having been relegated to the periphery of public awareness, "more people are aware of the Armenian genocide during the First World War than are aware of the Indonesian genocide in 1965". Taner Akçam's "A Shameful Act" has contextualized the Armenian Genocide with the desperate Ottoman struggle at Gallipoli, suggesting that panic of imminent destruction caused Ottoman authorities to opt for deportation and extermination.
On October 10, 2009 in Zurich, despite overwhelming opposition by Armenians in Armenia and in the Diaspora, the Armenian government signed the Armenia-Turkey Protocols, one of the provisions of which stipulates the establishment of a research commission "to study the two country's historical grievances." The agreement must still be ratified by the parliaments of both countries in order to take effect.
Just a day before, on 9 October 2009 in London, Geoffrey Robertson QC, eminent jurist, barrister and judge, published a detailed legal opinion which comprehensively and methodically countered the British Government's reasons for not formally recognizing the Armenian Genocide.
Republic of Turkey and the Genocide.
According to Kemal Çiçek, the head of the Armenian Research Group at the Turkish Historical Society, in Turkey there is no official thesis on the Armenian issue. The Republic of Turkey's formal stance is that the deaths of Armenians during the "relocation" or "deportation" cannot aptly be deemed "genocide", a position that has been supported with a plethora of diverging justifications: that the killings were not deliberate or were not governmentally orchestrated, that the killings were justified because Armenians posed a Russian-sympathizing threat as a cultural group, that Armenians merely starved, or any of various characterizations recalling marauding "Armenian gangs." Some suggestions seek to invalidate the genocide on semantic or anachronistic grounds (the word "genocide" was not coined until 1943). Turkish World War I casualty figures are often cited to mitigate the effect of the number of Armenian dead.
According to the retired ambassador of Turkey to Germany and Spain; Volkan Vural, the Turkish state should apologize for what happened to the Armenians during the deportations of 1915 and what happened to the Greeks during Istanbul Pogrom He also states that, "I think that, the Armenian issue can be solved by politicians and not by historians. I don't believe that historical facts about this issue is not revealed. The historical facts are already known. The most important point here is that how this facts will be interpreted and will affect the future."
.
In 2007, Turkish Prime Minister Recep Tayyip Erdoğan issued a circular that calls the government institutions to use "1915 Events" (in Turkish, 1915 Olayları) phrase instead of the "so-called Armenian genocide" (in Turkish, sözde Ermeni soykırımı) phrase. 
Turkey has started an "Initiative to Resolve Armenian Allegations Regarding 1915", by using archives in Turkey, Armenia and other countries. Armenian president Robert Kocharian rejected this offer by saying, "It is the responsibility of governments to develop bilateral relations and we do not have the right to delegate that responsibility to historians. That is why we have proposed and propose again that, without pre-conditions, we establish normal relations between our two countries." Additionally, Turkish foreign minister of the time, Abdullah Gül, invited the United States and other countries to contribute to such a commission by appointing scholars to "investigate this tragedy and open ways for Turks and Armenians to come together". 
The Turkish government continues to protest against the formal recognition of the genocide by other countries and to dispute that there ever was a genocide.
Controversies.
Efforts by the Turkish government and its agents to quash mention of the genocide have resulted in numerous scholarly, diplomatic, political and legal controversies. Prosecutors acting on their own initiative have utilized Article 301 of the Turkish Penal Code prohibiting "insulting Turkishness" to silence a number of prominent Turkish intellectuals who spoke of atrocities suffered by Armenians in the last days of the Ottoman Empire (as of yet, most of these cases have been dismissed). These prosecutions have often been accompanied by hate campaigns and threats, as was the case for Hrant Dink, who was prosecuted three times for "denigrating Turkishness", and murdered in 2007. Later, photographs of the assassin being honored as a hero while in police custody, posing in front of the Turkish flag with grinning policemen, gave the academic community still more cause for pause with regard to engaging the Armenian issue. The leading lawyer behind the prosecutions, Kemal Kerinçsiz, is accused of plotting to overthrow the government as being a member of the alleged Ergenekon network.
In 1973 Turkey recalled its ambassador to France to protest the Genocide monument erected in Marseilles "to the memory of the 1.5 million Armenian victims of the genocide ordered by the Turkish rulers in 1915".
In 1982, the Israeli Foreign Ministry attempted to prevent an international conference on genocide, held in Tel Aviv, from including any mention of the Armenian Genocide. Several reports suggested that Turkey had warned that Turkish Jews might face "reprisals", if the conference permitted Armenian participation. This charge was "categorically denied" by Turkey; the Israeli Foreign Ministry supported Turkey in this protestation that there had been no threats against Jews, suggesting that its misgivings as to the genocide conference were based on considerations "vital to the Jewish nation."
In the same year (1982), the Institute of Turkish Studies in Washington, D.C. (ITS) was established by a $3 million grant from the Turkish Government. Israel Charny identifies ITS and some of its foremost deniers of the Armenian genocide, such as Stanford Shaw, Heath W. Lowry, and Justin McCarthy, as the Turkish government's principal agency in USA for promoting research on Turkey and the Ottoman Empire, but also denial of the Armenian Genocide.
A 1989 U.S. Senate proposal to recognize the Armenian Genocide stoked the ire of Turkey. The proposal occurred in the context of the publication of internal U.S. documents which laid out a State Department official's eyewitness report that "thousands and thousands of Armenians, mostly innocent and helpless women and children, were butchered", in the last days of the Ottoman Empire. Turkey responded by blocking United States Navy visits to Turkey and suspending some US military training facilities on Turkish territory. The American scholar who assembled the US archive documents for publication went into hiding after a series of anonymous threats.
In 1990, psychologist Robert Jay Lifton received a letter from the Turkish Ambassador to the United States, questioning his inclusion of references to the Armenian Genocide in one of his books. The ambassador inadvertently included a draft of the letter, presented by scholar Heath W. Lowry, advising the ambassador on how to prevent mention of the Armenian Genocide in scholarly works. In 1996, Lowry was named to a chair at Princeton University that had been financed by the Turkish government, sparking a debate on ethics in scholarship.
In 1993, Ragıp Zarakolu a Turkish human rights activist published the Turkish translation of the book called "History of the Genocide" written by Yves Ternon. The book was the first to be published in Turkey that openly acknowledged the event in 1915 as Genocide. Soon after its publication, he started to receive threats and eventually in 1994 the publishing firm of Ragıp Zorakolu was the target of a serious bomb attack.
During a February 2005 interview with "Das Magazin", novelist Orhan Pamuk made statements implicating Turkey in massacres against Armenians and persecution of the Kurds, declaring: "Thirty thousand Kurds and a million Armenians were killed in these lands and nobody but me dares to talk about it". Subjected to a hate campaign, he left Turkey, before returning in 2005 to defend his right to freedom of speech: "What happened to the Ottoman Armenians in 1915 was a major thing that was hidden from the Turkish nation; it was a taboo. But we have to be able to talk about the past". However, when asked about his speech on CNN TURK television, Pamuk stated that "I did not estimate the number of killed Armenians, I did not use the word genocide, I did say Armenians were killed, but I did not say Armenians were killed by Turks". Lawyers of two Turkish ultranationalist professional associations led by Kemal Kerinçsiz then brought criminal charges against Pamuk. However, on January 23, 2006 the charges of "insulting Turkishness" were dropped (for formal reasons without finding it necessary to judge on the essence of the case), a move welcomed by the EU. That the charges had been brought at all was still a matter of contention for European politicians.
According to some newly discovered documents that belonged to the interior minister of the Ottoman Empire, more than 970,000 Ottoman Armenians disappeared from official population records from 1915 through 1916. These documents have been published in a recent book titled "The Remaining Documents of Talat Pasha" (aka "Talat Pasha's Black Book") written by the Turkish journalist Murat Bardakçı. The book is a collection of documents and records that once belonged to Mehmed Talat, known as Talat Pasha, the primary architect of the Armenian deportations. The documents were given to Mr. Bardakçı by Mr Talat's widow, Hayriye Talat Bafralı, in 1983. According to the documents, the number of Armenians living in the Ottoman Empire before 1915 stood at 1,256,000. The number plunged to 284,157 two years later in 1917.
"BBC – Turkey threatens to expel 100,000 Armenians." "BBC News". March 17, 2010.
The answer to Erdoğan came from the Armenian Prime Minister; he said that this kind of threat reminded Armenians of the Armenian Genocide and neither did they improve relations between the two countries. The exact number of illegal Armenians in Turkey is unknown, but the estimation is only 12,000 – 13,000 contrary to number used by the Turkish prime minister.
Armenia and the Genocide.
Armenia has been involved in a protracted ethnic-territorial conflict with Azerbaijan, a Turkic state, since Azerbaijan became independent from the Soviet Union in 1991. The conflict has featured several pogroms, massacres, and waves of ethnic cleansing, by both sides. Some foreign policy observers and historians have suggested that Armenia and the Armenian diaspora have sought to portray the modern conflict as a continuation of the Armenian Genocide, in order to influence modern policy-making in the region. According to Thomas Ambrosio, the Armenian Genocide furnishes "a reserve of public sympathy and moral legitimacy that translates into significant political influence… to elicit congressional support for anti-Azerbaijan policies."
The rhetoric leading up to the onset of the conflict, which unfolded in the context of several pogroms of Armenians, was dominated by references to the Armenian Genocide, including fears that it would be, or was in the course of being, repeated. During the conflict, the Azeri and Armenian governments regularly accused each other of genocidal intent, although these claims have been treated skeptically by outside observers.
The worldwide recognition of the Genocide is a core aspect of Armenia's foreign policy and overarching grand strategy.
Recognition of the Genocide.
Council of Europe Parliamentary Assembly Resolution, April 24, 1998
""Today we commemorate the anniversary of what has been called the first genocide of the 20th century, and we salute the memory of the Armenian victims of this crime against humanity"".
As a response to the continuing denial of the Armenian Genocide by the Turkish State, many activists among Armenian Diaspora communities have pushed for formal recognition of the Armenian genocide from various governments around the world. 20 countries and 42 U.S. states have adopted resolutions acknowledging the Armenian Genocide as a "bona fide" historical event. On March 4, 2010, a US congressional panel narrowly voted that the incident was indeed genocide; within minutes the Turkish government issued a statement critical of "this resolution which accuses the Turkish nation of a crime it has not committed." The Armenian Assembly of America (AAA) and the single largest organisation with the AAA the Armenian National Committee of America (ANCA) have as their main lobbying agenda to press Congress and the President of the United States for an increase of economic aid for Armenia (already the second largest per capita after Israel) and the reduction economic and military assistance for Turkey. The efforts also include reaffirmation of a genocide by Ottoman Turkey in 1915.
Despite his previous public recognition and support of Genocide bills, as well as the election campaign promises to formally recognize the Armenian Genocide, the U.S. President, Barack Obama, although repeating that his views on the issue have not changed, has thus far abstained from using the term 'genocide'. On April 24 commemoration speeches President Obama has yet referred to the Armenian Genocide only by the Armenian synonym Metz Eghern ("Mec Eġeṙn").
Cultural loss.
The premeditated destruction of objects of Armenian cultural, religious, historical and communal heritage was yet another key purpose of both the genocide itself and the post-genocidal campaign of denial. Armenian churches and monasteries were destroyed or changed into mosques, Armenian cemeteries flattened, and, in several cities (e.g. Van), Armenian quarters were demolished.
Aside from the deaths, Armenians lost their wealth and property without compensation. Businesses and farms were lost, and all schools, churches, hospitals, orphanages, monasteries, and graveyards became Turkish state property. In January 1916, the Ottoman Minister of Commerce and Agriculture issued a decree ordering all financial institutions operating within the empire's borders to turn over Armenian assets to the government. It is recorded that as much as 6 million Turkish gold pounds were seized along with real property, cash, bank deposits, and jewelry. The assets were then funneled to European banks, including Deutsche and Dresdner banks.
After the end of World War I, Genocide survivors tried to return and reclaim their former homes and assets, but were driven out by the Ankara Government.
In 1914, the Armenian Patriarch in Constantinople presented a list of the Armenian holy sites under his supervision. The list contained 2,549 religious places of which 200 were monasteries while 1,600 were churches. In 1974 UNESCO stated that after 1923, out of 913 Armenian historical monuments left in Eastern Turkey, 464 have vanished completely, 252 are in ruins, and 197 are in need of repair (in stable conditions).
Armenian Genocide reparations.
Referring to the restitution for the damage caused to the Armenian nation due to the Genocide it can be stated that those could be of financial, estate or territorial nature alike, and may be claimed individually or collectively as well as by the State.
The grounds of the International Law.
The United Nations Basic Principles and Guidelines on the Right to Reparation for Victims of Gross Violations of Human Rights and International Humanitarian Law provide in part, that reparation may be claimed individually and where appropriate collectively, by the direct victims of violations of human rights and international humanitarian law, the immediate family, dependants or other persons or groups of persons closely connected with the direct victims.
According to Henry Theriault, while current members of Turkish society cannot be blamed morally for the destruction of Armenians, present-day Republic of Turkey, as successor state to the Ottoman Empire and as beneficiary of the wealth and land expropriations brought forth through the genocide, is responsible for reparations.
Particularly important are Principles 9 and 12 that state, that civil claims relating to reparations for gross violations of human rights and international humanitarian law shall not be subject to statutes of limitations (article 9), and that restitution shall be provided to re-establish the situation that existed prior to the violations of human rights or international humanitarian law. The restitution requires, "inter alia" – return to one's place of residence and restoration of property.
Professor of International Law of Geneva School of Diplomacy (J.D. – Harvard, Dr.phil. – Göttingen), former Secretary of the UN Human Rights Committee and former Chief of Petitions at the Office of the UN High Commissioner for Human Rights, Dr. Alfred de Zayas stated, that because of the continuing character of the crime of genocide in factual and legal terms, the remedy of restitution has not been foreclosed. Thus the survivors of the genocide against the Armenians, both individually and collectively, have standing to advance a claim for restitution. Whenever possible complete restitution or restoration to the previous condition should be granted. But where is not possible, relevant compensation may be substituted as a remedy.
In an article published in European Journal of International Law, Vahagn Avedian, rather leaving the limitations of the UN Genocide Convention, emphasizes the applicability of the then and now prevailing international laws, e.g. the Hague Conventions of 1899 and 1907, more specifically the Martens Clause, pertaining to the protection of civilian population, but also existing international laws on unlawful confiscation etc. Thus, the actions of the Turkish governments (the Ottoman, the insurgent nationalist movement as well as the succeeding republic), should be viewed from the perspective of Internationally Wrongful Acts. Avedian argues that: 
Sèvres Treaty.
Although there are different opinions on the legitimacy of the Treaty of Sèvres and its relativity to reparation claims, there are specialists who claim that some of its elements retain the force of law. In particular, the fixing of the proper borders of an Armenian state was undertaken pursuant to the treaty and determined by a binding arbitral award, regardless of whether the treaty was ultimately ratified. "The committee process determining the arbitral award was agreed to by the parties" and, according to international law, the resulting determination has legal force regardless of the ultimate fate of the treaty.
Lawsuits.
In July 2004, after California Legislature passed the Armenian Genocide Insurance Act, descendants of Armenian Genocide victims settled a case for about 2,400 life insurance policies from New York Life written on Armenians living in the Ottoman Empire. Around 1918, the Turkish government attempted to recover for the people it had killed with the argument that there are no identifiable heirs to the policy holders. The settlement provided $20 million, of which $11 million was for heirs of the Genocide victims.
Commemoration.
Memorials.
Over 135 memorials, spread across 25 countries, commemorate the Armenian Genocide.
In 1965, the 50th anniversary of the genocide, a 24-hour mass protest was initiated in Yerevan demanding recognition of the Armenian Genocide by Soviet authorities. The memorial was completed two years later, at Tsitsernakaberd above the Hrazdan gorge in Yerevan. The stele symbolizes the national rebirth of Armenians. Twelve slabs are positioned in a circle, representing 12 lost provinces in present day Turkey. At the center of the circle there is an eternal flame. Each April 24, hundreds of thousands of people walk to the genocide monument and lay flowers around the eternal flame.
Another memorial, in Alfortville, France, near Paris, was bombed on May 3, 1984, by a hit-team headed by Grey Wolves member Abdullah Çatlı and paid by the Turkish intelligence agency (MİT).
Representation in popular culture.
The earliest example of the Armenian genocide on art was a medal issued in St. Petersburg, signifying Russian sympathy for Armenian suffering. It was struck in 1915, as the massacres and deportations were still raging. Since then, dozens of medals in different countries have been commissioned to commemorate the event.
Several eyewitness accounts of the events were published, notably those of Swedish missionary Alma Johansson and U.S. Ambassador Henry Morgenthau, Sr. German medic Armin Wegner wrote several books about the events he witnessed while stationed in the Ottoman Empire. Years later, having returned to Germany, Wegner was imprisoned for opposing Nazism, and his books were burnt by the Nazis. Probably the best known literary work on the Armenian Genocide is Franz Werfel's 1933 "The Forty Days of Musa Dagh". It was a bestseller that became particularly popular among the youth of the Jewish ghettos during the Nazi era.
Kurt Vonnegut's 1988 novel "Bluebeard" features the Armenian Genocide as an underlying theme. Other novels incorporating the Armenian Genocide include Louis de Berniéres' "Birds without Wings", Edgar Hilsenrath's German-language "The Story of the Last Thought", and Polish Stefan Żeromski's 1925 "The Spring to Come". A story in Edward Saint-Ivan's 2006 anthology "The Black Knight's God" includes a fictional survivor of the Armenian Genocide.
The first film about the Armenian Genocide appeared in 1919, a Hollywood production titled "Ravished Armenia". It resonated with acclaimed director Atom Egoyan, influencing his 2002 "Ararat". There are also references in Elia Kazan's "America, America" and Henri Verneuil's "Mayrig". At the Berlin Film Festival of 2007 Italian directors Paolo and Vittorio Taviani presented another film about the events, based on Antonia Arslan's book, "La Masseria Delle Allodole" ("The Farm of the Larks"). Richard Kalinoski's play, "Beast on the Moon", is about two Armenian Genocide survivors.
The paintings of Armenian-American Arshile Gorky, a seminal figure of Abstract Expressionism, are considered to have been informed by the suffering and loss of the period. In 1915, at age 10, Gorky fled his native Van and escaped to Russian-Armenia with his mother and three sisters, only to have his mother die of starvation in Yerevan in 1919. His two "The Artist and His Mother" paintings are based on a photograph with his mother taken in Van. 
In 1975, famous French-Armenian singer Charles Aznavour recorded the song "Ils sont tombés" ("They Fell"), dedicated to the memory of Armenian Genocide victims.
American composer and singer Daniel Decker has achieved critical acclaim for his collaborations with Armenian composer Ara Gevorgyan. The song "Adana", named for the province of a 1909 pogrom of the Armenian people, tells the story of the Armenian Genocide. "Adana" has been translated into 17 languages and recorded by singers around the world.
The American band System of a Down, composed of four descendants of Armenian Genocide survivors, has promoted awareness of the Armenian Genocide through its lyrics, including P.L.U.C.K. and in concerts.
In late 2003, Diamanda Galás released the album "Defixiones, Will and Testament: Orders from the Dead", an 80-minute memorial tribute to the Armenian, Assyrian and Greek victims of the genocide in Turkey. "The performance is an angry meditation on genocide and the politically cooperative denial of it, in particular the Turkish and American denial of the Armenian, Assyrian, and Anatolian Greek genocides from 1914 to 1923".

Aryan invasion theory
The term Aryan invasion theory may refer to

Aryan race
The Aryan race is a concept historically influential in Western culture in the period of the late 19th century and early 20th century. It derives from the idea that the original speakers of the Indo-European languages and their descendants up to the present day constitute a distinctive race or subrace of the larger Caucasian race. Belief in the existence of an Aryan race is sometimes referred to as "Aryanism".
While originally meant simply as a neutral ethno-linguistic classification, it was later used for ideologically motivated racism in Nazi and neo-Nazi doctrine, as well as in occultism and white supremacism in particular.
Origin of the term.
The term "Aryan" originates from the Sanskrit word "ārya", in origin an ethnic self-designation, in Classical Sanskrit meaning "honourable, respectable, noble".
In the 18th century, the most ancient known Indo-European languages were those of the Indo-Iranians' ancestors. The word "Aryan" was therefore adopted to refer not only to the Indo-Iranian people, but also to native Indo-European speakers as a whole, including the Greeks, Latins, and Germans. It was soon recognised that Armenians, Balts, Celts, Albanians and Slavs also belonged to the same group. It was argued that all of these languages originated from a common root—now known as Proto-Indo-European—spoken by an ancient people. The ethnic group composed of the Proto-Indo-Europeans and their modern descendants was termed the "Aryans".
This usage was common in the late 19th and early 20th century. An example of an influential best-selling book that reflects this usage is the 1920 book "The Outline of History" by H. G. Wells. Wells wrote about the accomplishments of the Aryan people, stating how they "learned methods of civilization" while "Sargon II and Sardanapalus were ruling in Assyria and fighting with Babylonia and Syria and Egypt". As such, Wells suggested that the Aryans had eventually "subjugated the whole ancient world, Semitic, Aegean and Egyptian alike". In the 1944 edition of Rand McNally’s World Atlas, the Aryan race is depicted as being one of the ten major racial groupings of mankind. The science fiction author Poul Anderson (1926–2001), an anti-racist libertarian of Scandinavian ancestry, in his many novels, novellas, and short stories, consistently used the term "Aryan" as a synonym for "Indo-Europeans". He spoke of the "Aryan bird of prey" which impelled those of the Aryan race to take the lead in developing interstellar travel, colonize habitable planets in other planetary systems and become leading business entrepreneurs on the newly colonized planets.
The use of "Aryan" as a synonym for "Indo-European" or to a lesser extent for "Indo-Iranian", is regarded today by many as obsolete and politically incorrect, but may still occasionally appear in material based on older scholarship, or written by persons accustomed to older usage, such as in a 1989 article in "Scientific American" by Colin Renfrew in which he uses the word "Aryan" in its traditional meaning as a synonym for "Indo-European". However, the term Indo-Aryan is still commonly used to describe the Indic half of the Indo-Iranian languages, i.e. the family that includes Sanskrit and modern languages such as Hindi, Urdu and Bengali.
19th-century physical anthropology.
In 19th century physical anthropology, represented by some as being scientific racism, the "Aryan race" was defined as the subgroup of the Caucasian (or Europid) race consisting of the native speakers of Indo-European languages descended from the original Proto-Indo-Europeans, that in modern times reside in Northern India, Sri Lanka, Maldives, Pakistan, Gujarat, Maharashtra, Eastern India, Bangladesh, Nepal, Northeast India, Europe, Asian Russia, Anglo-America, Quebec, Southern South America, South Africa, Australia and New Zealand, Armenia, Iran, and in Afghanistan and Tadzhikistan, .
The original 19th-century and early 20th-century use of the term "Aryan" referred to "the early speakers of Proto-Indo European and their descendents". Max Müller is often identified as the first writer to speak of an Aryan "race" in English. In his "Lectures on the Science of Language" in 1861 he referred to Aryans as a "race of people". At the time, the term "race" had the meaning of "a group of tribes or peoples, an ethnic group".
When Müller's statement was interpreted to imply a biologically distinct sub-group of humanity, he soon clarified that he simply meant a line of descent, insisting that it was very dangerous to mix linguistics and anthropology. "The Science of Language and the Science of Man cannot be kept too much asunder ... I must repeat what I have said many times before, it would be wrong to speak of Aryan blood as of dolichocephalic grammar". He restated his opposition to this method in 1888 in his essay "Biographies of words and the home of the Aryas".
Müller was responding to the development of racial anthropology, and the influence of the work of Arthur de Gobineau who argued that the Indo-Europeans represented a superior branch of humanity. A number of later writers, such as the French anthropologist Vacher de Lapouge in his book "L'Aryen", argued that this superior branch could be identified biologically by using the cephalic index (a measure of head shape) and other indicators. He argued that the long-headed "dolichocephalic-blond" Europeans, characteristically found in northern Europe, were natural leaders, destined to rule over more "brachiocephalic" (short headed) peoples.
The division of the Caucasian race into Aryans, Semites and Hamites is in origin linguistic, not based on physical anthropology, the division in physical anthropology being that into Nordic, Alpine and Mediterranean. However, the linguistic classification of "Aryan" later became closely associated, and conflated, with the classification of "Nordic" among some archaeologists and anthropologists.
This claim became increasingly important during the 19th century. In the mid-19th century, it was commonly believed that the Aryans originated in the southwestern steppes of present-day Russia. However, by the late 19th century the steppe theory of Aryan origins was challenged by the view that the Aryans originated in ancient Germany or Scandinavia, or at least that in those countries the original Aryan ethnicity had been preserved. The German origin of the Aryans was especially promoted by the archaeologist Gustaf Kossinna, who claimed that the Proto-Indo-European peoples were identical to the Corded Ware culture of Neolithic Germany. This idea was widely circulated in both intellectual and popular culture by the early twentieth century, and is reflected in the concept of "Corded-Nordics" in Carleton S. Coon's 1939 "The Races of Europe".
Other anthropologists contested such claims. In Germany, Rudolf Virchow launched a study of craniometry, which prompted him to denounce "Nordic mysticism" in the 1885 Anthropology Congress in Karlsruhe, while Josef Kollmann, a collaborator of Virchow, stated in the same congress that the people of Europe, be they English, German, French, and Spaniard belonged to a "mixture of various races," furthermore declaring that the "results of craniology...against any theory concerning the superiority of this or that European race" to others.
Virchow's contribution to the debate sparked a controversy. Houston Stewart Chamberlain, a strong supporter of the theory of a superior Aryan race, attacked Josef Kollmann arguments in detail. While the "Aryan race" theory remained popular, particularly in Germany, some authors defended Virchow's perspective, in particular Otto Schrader, Rudolph von Jhering and the ethnologist Robert Hartmann (1831–1893), who proposed to ban the notion of "Aryan" from anthropology.
Indo-Aryan migration.
Models of the Indo-Aryan migration discuss scenarios of prehistoric migrations of the early Indo-Aryans to their historically attested areas of settlement in the northwest of the Indian subcontinent and from there further across all of North India. Claims of Indo-Aryan migration are primarily drawn from linguistic evidence but also from a multitude of data stemming from genetics,(although more recent genetic studies cast doubt on the certitude of earlier claims), Vedic religion, rituals, poetics as well as some aspects of social organization and chariot technology.
All discussion of historical Indo-Aryan migrations or Aryan and Dravidian races remains highly controversial in India to this day, and continues to affect political and religious debate. Some Dravidians, and supporters of the Dalit movement, most commonly Tamils, claim that the worship of Shiva is a distinct Dravidian religion going back to the Indus Civilization, to be distinguished from Brahminical "Aryan" Hinduism. In contrast, the Indian nationalist Hindutva movement argues that no Aryan invasion or migration ever occurred, asserting that Vedic beliefs emerged from the Indus Valley Civilisation, which pre-dated the supposed advent of the Indo-Aryans in India, and is identified as a likely candidate for a Proto-Dravidian culture.
Some Indians were also influenced by the debate about the Aryan race during the British Raj. The Indian nationalist V. D. Savarkar believed in the theory that an "Aryan race" migrated to India, but he didn't find much value in a racialized interpretation of the "Aryan race". Some Indian nationalists supported the British version of the theory because it gave them the prestige of common descent with the ruling British class.
Genetic anthropology of Indo-Aryan Migration.
In a major study (2009) using over 500,000 biallelic autosomal markers, Reich hypothesized that the modern Indian population was the result of admixture between two genetically divergent ancestral populations dating from the post-Holocene era. These two "reconstructed" ancient populations he termed "Ancestral South Indians" (ASI) and "Ancestral North Indians" (ANI). According to Reich: "ANI ancestry is significantly higher in Indo-European than Dravidian speakers, suggesting that the ancestral ASI may have spoken a Dravidian language before mixing with the ANI." Furthermore, Reich observes: "It is tempting to assume that the population ancestral to ANI and CEU spoke 'Proto-Indo-European', which has been reconstructed as ancestral to both Sanskrit and European languages, although we cannot be certain without a date for ANI–ASI mixture." 
Similarly, an earlier study conducted by Watkins et al. (2008) states:Genetic variation in South Indian castes: evidence from Y-chromosome, mitochondrial, and autosomal polymorphisms
Occultism.
Theosophy.
The Theosophical movement founded by Helena Blavatsky and Henry Olcott at the end of the nineteenth century took inspiration from Indian culture, in this case, perhaps, from the Hindu reform movement the Arya Samaj founded by Swami Dayananda.
Blavatsky used "Root Race" as a technical term to describe human evolution over the large time periods in her cosmology. However, she also claimed that there were modern non-Aryan peoples who were inferior to Aryans. She regularly contrasts "Aryan" with "Semitic" culture, to the detriment of the latter, asserting that Semitic peoples are an offshoot of Aryans who have become "degenerate in spirituality and perfected in materiality." She also states that some peoples are "semi-animal creatures". These latter include "the Tasmanians, a portion of the Australians and a mountain tribe in China." There are also "considerable numbers of the mixed Lemuro-Atlantean peoples produced by various crossings with such semi-human stocks -- e.g., the wild men of Borneo, the Veddhas of Ceylon, most of the remaining Australians, Bushmen, Negritos, Andaman Islanders, etc."
Despite this, Blavatsky's admirers claim that her thinking was not connected to fascist or racialist ideas, asserting that she believed in a Universal Brotherhood of humanity and wrote that "all men have spiritually and physically the same origin" and that "mankind is essentially of one and the same essence". On the other hand, in "The Secret Doctrine", Blavatsky states: "Verily mankind is 'of one blood,' but not of the same essence."
According to Blavatsky, "the MONADS of the lowest specimens of humanity (the "narrow-brained" savage South-Sea Islander, the African, the Australian) had no Karma to work out when first born as men, as their more favoured brethren in intelligence had".
The second subrace of the Fifth or Aryan root race, the Arabian, is regarded by Theosophists as one of the Aryan subraces. It is believed by Theosophists that the Arabians, although asserted in traditional Theosophy to be of Aryan (i.e., Indo-European) ancestry, adopted the Semitic language of the people around them who had migrated earlier from Atlantis (the fifth or (original) Semite subrace of the Atlantean root race). Theosophists assert that the Jews originated as an offshoot of the Arabian subrace in what is now Yemen about 30,000 BC. They migrated first to Somalia and then later to Egypt where they lived until the time of Moses. Thus, according to the teachings of Theosophy, the Jews are part of the Aryan race.
Samael Aun Weor published a book in 1967 retitled in 2008 "The Doomed Aryan Race" in which he asserted that the Aryan "Root Race" is doomed to be destroyed by hydrogen bombs unless the people of the Aryan race learn tantric yoga.
Ariosophy.
Guido von List (and his followers such as Lanz von Liebenfels) later took up some of Blavatsky's ideas, mixing her ideology with nationalistic and fascist ideas; this system of thought became known as Ariosophy. It was believed in Ariosophy that the Teutonics were superior to all other peoples because according to Theosophy the Teutonics or Nordics were the most recent subrace of the Aryan root race to have evolved. Such views also fed into the development of Nazi ideology. Theosophical publications such as "The Aryan Path" were strongly opposed to the Nazi usage, attacking racialism.
Nazism and Neo-Nazism.
Nazism.
The idea of the Northern origins of the Aryans was particularly influential in Germany. It was widely believed that the "Vedic Aryans" were ethnically identical to the Goths, Vandals and other ancient Germanic peoples of the "Völkerwanderung". This idea was often intertwined with antisemitic ideas. The distinctions between the "Aryan" and "Semitic" peoples were based on the aforementioned linguistic and ethnic history.
Semitic peoples came to be seen as a foreign presence within Aryan societies, and the Semitic peoples were often pointed to as the cause of conversion and destruction of social order and values leading to culture and civilization's downfall by proto-Nazi and Nazi theorists such as Houston Stewart Chamberlain and Alfred Rosenberg.
According to the adherents to Ariosophy, the Aryan was a "master race" that built a civilization that dominated the world from Atlantis about 10,000 years ago. This alleged civilization declined when other parts of the world were colonized after the 8000 BC destruction of Atlantis because the inferior races mixed with the Aryans but it left traces of their civilization in Tibet (via Buddhism), and even in Central America, South America, and Ancient Egypt. (The date of 8000 BC for the destruction of Atlantis in Ariosophy is 2,000 years later than the date of 10,000 BC given for this event in Theosophy.) These theories affected the more esotericist strand of Nazism.
A complete, highly speculative theory of Aryan and anti-Semitic history can be found in Alfred Rosenberg's major work, "The Myth of the Twentieth Century". Rosenberg's well-researched account of ancient history, melded with his racial speculations, proved to be very effective in spreading racialism among German intellectuals in the early twentieth century, especially after the First World War.
These and other ideas evolved into the Nazi use of the term "Aryan race" to refer to what they saw as being a master race, which was narrowly defined by the Nazis as being identical with the Nordic race, followed by other sub-races of the Aryan race. They worked to maintain the purity of this race through eugenics programs (including anti-miscegenation legislation, compulsory sterilization of the mentally ill and the mentally deficient, the execution of the institutionalized mentally ill as part of a euthanasia program).
Heinrich Himmler (the "Reichsführer" of the SS), the person ordered by Adolf Hitler to implement the Final Solution, or The Holocaust, told his personal masseur Felix Kersten that he always carried with him a copy of the ancient Aryan scripture, the Bhagavad Gita because it relieved him of guilt about what he was doing – he felt that like the warrior Arjuna, he was simply doing his duty without attachment to his actions.
Himmler was also interested in Buddhism and his institute "Ahnenerbe" sought to mix some traditions from Hinduism and Buddhism – Gautama Buddha's original name for the religion we now call "Buddhism" was "The Aryan Path". Himmler sent a 1939 German expedition to Tibet as part of his research into Aryan origins.
In 1936 biologists Julian Huxley and Alfred Court Haddon famously ridiculed the Nazi idea of the superior Aryan race, writing: 
Neo-Nazism.
Since the military defeat of Nazi Germany by the Allies in 1945, most neo-Nazis have expanded their concept of the Aryan race, moving from the Nazi concept that the purest Aryans were the Teutonics or Nordics of Northern Europe to the idea that the true Aryans are everyone descended from the Western or European branch of the Indo-European peoples because it is believed that they most closely resemble the original racial stock of the Proto-Indo-Europeans. Although admitting that those of the Eastern or Indo-Iranian branch of the Indo-European peoples are "Aryans" in name, it is felt that they are not really true Aryans because it is believed that the Iranian peoples are mostly too intermixed with the Arabs and Mongols, and the Indo-Aryans are mostly too intermixed with the Dravidians, to still be pure Aryans.
Moderate white nationalists who embrace what is called "Pan-Aryanism" want to establish a democratically governed "Aryan Federation." It is envisioned that the North American part of the "Aryan Federation" would be a new nation for Euro-Anglo Americans (European Americans and English Canadians) called "Vinland" which would include what is now the northern United States and all of Canada except Quebec, and which would use the Vinland flag.
On the other hand, according to Nicholas Goodrick-Clarke, many neo-Nazis want to establish an autocratic state modeled after Nazi Germany to be called the "Western Imperium". It is believed this proposed state would be able to attain world domination by combining the nuclear arsenals of the four major Aryan world powers, the United States, the United Kingdom, France, and Russia under a single military command.
This proposed state would be led by a "Führer"-like figure called the "Vindex", and would include all areas inhabited by the "Aryan race", as conceived by Neo-Nazis. Only those of the Aryan race would be full citizens of the state. The "Western Imperium" would embark on a vigorous and dynamic program of space exploration, followed by the creation by genetic engineering of a super race called Homo Galactica. The concept of the "Western Imperium" as outlined in the previous three sentences is based on the original concept of the "Imperium" as outlined in the 1947 book "Imperium: The Philosophy of History and Politics" by Francis Parker Yockey as further updated, extended and refined in the early 1990s in pamphlets published by David Myatt.
Tempelhofgesellschaft.
A neo-Nazi esoteric Nazi Gnostic sect headquartered in Vienna, Austria called the "Tempelhofgesellschaft", founded in the early 1990s, teaches a form of what it calls Marcionism. They distribute pamphlets claiming that the Aryan race originally came to Atlantis from the star Aldebaran.

Atomic bombings of Hiroshima and Nagasaki
The atomic bombings of the cities of Hiroshima and Nagasaki in Japan were conducted by the United States during the final stages of World War II in 1945. These two events represent the only use of nuclear weapons in war to date.
Following a firebombing campaign that destroyed many Japanese cities, the Allies prepared for a costly invasion of Japan. The war in Europe ended when Nazi Germany signed its instrument of surrender on 8 May, but the Pacific War continued. Together with the United Kingdom and the Republic of China, the United States called for a surrender of Japan in the Potsdam Declaration on 26 July 1945, threatening Japan with "prompt and utter destruction". The Japanese government ignored this ultimatum, and the United States deployed two nuclear weapons developed by the Manhattan Project. American airmen dropped Little Boy on the city of Hiroshima on 6 August 1945, followed by Fat Man over Nagasaki on 9 August.
Within the first two to four months of the bombings, the acute effects killed 90,000–166,000 people in Hiroshima and 60,000–80,000 in Nagasaki, with roughly half of the deaths in each city occurring on the first day. The Hiroshima prefecture health department estimated that, of the people who died on the day of the explosion, 60% died from flash or flame burns, 30% from falling debris and 10% from other causes. During the following months, large numbers died from the effect of burns, radiation sickness, and other injuries, compounded by illness. In a US estimate of the total immediate and short term cause of death, 15–20% died from radiation sickness, 20–30% from burns, and 50–60% from other injuries, compounded by illness. In both cities, most of the dead were civilians, although Hiroshima had a sizeable garrison.
On 15 August, six days after the bombing of Nagasaki, Japan announced its surrender to the Allies, signing the Instrument of Surrender on 2 September, officially ending World War II. The bombings led, in part, to post-war Japan's adopting Three Non-Nuclear Principles, forbidding the nation from nuclear armament. The role of the bombings in Japan's surrender and their ethical justification are still debated.
Background.
Pacific War.
In 1945, the Pacific War between the Empire of Japan and the Allies of World War II had entered its fourth year. World War II was not winding down. Instead, the fighting was being prosecuted with ever-increasing fury. Of the 1.25 million battle casualties incurred by the United States in World War II, including both soldiers killed in action and wounded in action, nearly one million occurred in the twelve month period from June 1944 to June 1945. December 1944 saw American battle casualties hit an all-time monthly high of 88,000 as a result of the German Ardennes Offensive.
In the Pacific during this period, the Allies captured the Mariana and Palau Islands, returned to the Philippines, and invaded Borneo. The policy of bypassing Japanese forces was abandoned. In order to free troops for use elsewhere, offensives were undertaken to reduce the Japanese forces remaining in Bougainville, New Guinea and the Philippines. In April 1945, American forces had landed on Okinawa, where heavy fighting would continue until June. Along the way, the ratio of Japanese deaths to American casualties dropped from 5 to 1 in the Philippines to 2 to 1 on Okinawa.
Preparations to invade Japan.
Even before the surrender of Nazi Germany on 8 May 1945, plans were already underway for the largest operation of the Pacific War, Operation Downfall, the invasion of Japan. The operation had two parts: Operations Olympic and Coronet. Set to begin in October 1945, Olympic involved a series of landings by the US Sixth Army intended to capture the southern third of the southernmost main Japanese island, Kyūshū. Operation Olympic was to be followed in March 1946 by Operation Coronet, the capture of the Kantō Plain, near Tokyo on the Japanese island of Honshū by the US First, Eighth and Tenth Armies. The target date was chosen to allow for Olympic to complete its objectives, troops to be redeployed from Europe, and the Japanese winter to pass.
Japan's geography made this invasion plan obvious to the Japanese as well; they were able to predict the Allied invasion plans accurately and thus adjust their defensive plan, Operation Ketsugō, accordingly. The Japanese planned an all-out defense of Kyūshū, with little left in reserve for any subsequent defense operations. Four veteran divisions were withdrawn from the Kwantung Army in Manchuria in March 1945 to strengthen the forces in Japan, and 45 new divisions were activated between February and May 1945. Most were immobile formations for coastal defence, but 16 were high quality mobile divisions. In all, there were 2.3 million Japanese Army troops prepared to defend the Japanese home islands, another 4 million Army and Navy employees, and a civilian militia of 28 million men and women. Casualty predictions varied widely, but were extremely high. The Vice Chief of the Imperial Japanese Navy General Staff, Vice Admiral Takijirō Ōnishi, predicted up to 20 million Japanese deaths.
A study from 15 June 1945 by the Joint War Plans Committee, who provided planning information to the Joint Chiefs of Staff, estimated that Olympic would result in between 130,000 and 220,000 US-casualties of which U.S. dead would be the range from 25,000 to 46,000. Delivered on 15 June 1945 after insight gained from the Battle of Okinawa, the study noted Japan's inadequate defenses due to the very effective sea blockade and the American firebombing campaign. The Chief of Staff of the United States Army, General of the Army George C. Marshall and General of the Army Douglas MacArthur signed documents agreeing with the Joint War Plans Committee estimate.
The Americans were alarmed by the Japanese build up, which was accurately tracked through Ultra intelligence. United States Secretary of War Henry Lewis Stimson was sufficiently concerned about high American estimates of probable casualties to commission his own study by Quincy Wright and William Shockley. Wright and Shockley spoke with Colonels James McCormack and Dean Rusk, and examined casualty forecasts by Michael DeBakey and Gilbert Beebe. Wright and Shockley estimated the invading Allies would suffer between 1.7 and 4 million casualties in such a scenario, of whom between 400,000 and 800,000 would be dead, while Japanese casualties would have been around 5 to 10 million.
Marshall began contemplating the use of a weapon which was "readily available and which assuredly can decrease the cost in American lives": poison gas. Quantities of phosgene, mustard gas, tear gas and cyanogen chloride were moved to Luzon from stockpiles in Australia and New Guinea in preparation for Operation Olympic, and General of the Army Douglas MacArthur ensured that Chemical Warfare Service units were trained in their use.
Air raids on Japan.
While the United States had developed plans for an air campaign against Japan prior to the Pacific War, the capture of Allied bases in the western Pacific in the first weeks of the conflict meant that this offensive did not begin until mid-1944 when the long-ranged Boeing B-29 Superfortress became ready for use in combat. Operation Matterhorn involved India-based B-29s staging through bases around Chengtu in China to make a series of raids on strategic targets in Japan between June 1944 and January 1945. This effort proved unsuccessful due to logistical difficulties with the remote location, technical problems with the new and advanced aircraft, unfavourable weather conditions, and ultimately enemy action.
USAAF Brigadier General Haywood S. Hansell determined that Guam, Tinian and Saipan in the Mariana Islands would better serve as B-29 bases, but they were in Japanese hands. Strategies were shifted to accommodate the air war, and the islands were captured between June and August 1944. Air bases were developed, and B-29 operations commenced from the Marianas in November 1944, greatly expanding the scope of the strategic bombing campaign against Japan.
These attacks initially targeted key industrial facilities, but from March 1945 they were frequently directed against urban areas. The capture of Okinawa in June 1945 provided airfields even closer to the Japanese mainland, allowing the bombing campaign to be escalated further. Over the next six months, the XXI Bomber Command fire-bombed 67 Japanese cities. The "Operation Meetinghouse" 9–10 March Bombing of Tokyo caused 80,000–100,000 casualties and destroyed of the city with 267,000 buildings–the deadliest of the war. Aircraft flying from Allied aircraft carriers and the Ryukyu Islands also regularly struck targets in Japan during 1945 in preparation for Operation Downfall.
The Japanese military was unable to stop the Allied attacks, and the country's civil defense preparations proved inadequate. From April 1945, the Japanese Army and Naval Air Forces stopped attempting to intercept the air raids in order to preserve fighter aircraft to counter the expected invasion. By mid-1945 the Japanese also only occasionally scrambled aircraft to intercept individual B-29s conducting reconnaissance sorties over the country in order to conserve supplies of fuel. By July 1945, the Japanese had stockpiled of avgas for the invasion of Japan.
Atomic bomb development.
Working in collaboration with the United Kingdom and Canada, with their respective projects Tube Alloys and Chalk River Laboratories, the Manhattan Project, under the direction of Major General Leslie Groves, of the U.S. Army Corps of Engineers, designed and built the first atomic bombs. Preliminary research began in 1939, originally in fear that the Nazi atomic bomb project would develop atomic weapons first. In May 1945, the defeat of Germany caused the focus to turn to use against Japan.
Two types of bombs were eventually devised by scientists and technicians at Los Alamos under American physicist Robert Oppenheimer. The Hiroshima bomb, known as Little Boy, was a gun-type fission weapon made with uranium-235, a rare isotope of uranium extracted in giant factories in Oak Ridge, Tennessee. The other was an implosion-type nuclear weapon using plutonium-239, a synthetic element created in nuclear reactors at Hanford, Washington. A test implosion weapon, the gadget, was detonated at Trinity Site, on 16 July 1945, near Alamogordo, New Mexico. The Nagasaki bomb, Fat Man was also an implosion device.
Preparations.
Organization and training.
The 509th Composite Group was constituted on 9 December 1944, and activated on 17 December 1944, at Wendover Army Air Field, Utah, commanded by Colonel Paul W. Tibbets. Tibbets was assigned to organize and command a combat group to develop the means of delivering an atomic weapon against targets in Germany and Japan. Because the flying squadrons of the group consisted of both bomber and transport aircraft, the group was designated as a "composite" rather than a "bombardment" unit.
Working with the Manhattan Project at Site Y in Los Alamos, New Mexico, Tibbets selected Wendover for his training base over Great Bend, Kansas, and Mountain Home, Idaho because of its remoteness. On 10 September 1944, the 393rd Bomb Squadron, a B-29 Superfortress unit, arrived at Wendover from the 504th Bombardment Group (Very Heavy) at Fairmont Army Air Base, Nebraska, where it had been in group training since 12 March. When its parent group deployed to the Mariana Islands in early November 1944, the squadron was assigned directly to the Second Air Force until creation of the 509th Composite Group. Originally consisting of twenty-one crews, fifteen were selected to continue training and were organized into three flights of five crews, lettered A, B, and C.
The 320th Troop Carrier Squadron, the other flying unit of the 509th, came into being because of the highly secret work of the group. The organization that was to become the 509th required its own transports for the movement of both personnel and materiel, resulting in creation of an ad hoc unit nicknamed "The Green Hornet Line". Crews for this unit were acquired from the six 393rd crews not selected to continue B-29 training, some of whom chose to remain with the 509th rather than be assigned to a replacement pool of the Second Air Force. They began using Curtiss C-46 Commandos and C-47 Skytrains already at Wendover, and after November 1944 flew five acquired C-54 Skymasters. The 320th Troop Carrier was formally activated at the same time as the group.
Other support units were activated at Wendover from personnel already present and working with its Project W-47, which was later superseded by Project Alberta, or in the 216th Base Unit, both of which were affiliated with the Project Y. The 390th Air Service Group was created as the command echelon for the 603rd Air Engineering Squadron, the 1027th Air Material squadron, and its own Air Base Support Squadron, but as these units became independent operationally, acted as the basic support unit for the entire 509th Composite Group in providing quarters, rations, medical care, postal service and other basic support functions. The 603rd Air Engineering Squadron was unique in that it provided depot-level B-29 maintenance in the field, obviating the necessity of sending aircraft back to the United States for major repairs. The 603rd made a number of modifications to the first contract order of Silverplate B-29s that were later incorporated as specifications for the combat models.
The 393rd Bomb Squadron began replacement of its original B-29s with modified Silverplate aircraft with the delivery of three new B-29s in mid-October 1944. These aircraft had extensive bomb bay modifications and a "weaponeer" station installed, but initial training operations identified numerous other modifications necessary to the mission, particularly in reducing the overall weight of the aircraft to offset the heavy loads it would be required to carry. Five more Silverplates were delivered in November and six in December, giving the group 14 for its training operations. In January and February 1945, 10 of the 15 crews under the command of the Group S-3 (operations officer) were assigned temporary duty at Batista Field, San Antonio de los Baños, Cuba, where they trained in long-range over-water navigation.
On 6 March 1945, the 1st Ordnance Squadron (Special, Aviation) was activated at Wendover, again from Army Air Forces personnel on hand or already at Los Alamos, and concurrent with the activation of Project Alberta. Its purpose was to provide trained personnel and special equipment to the group to enable it to assemble atomic weapons at its operating base, thereby allowing the weapons to be transported more safely in their component parts. A rigorous candidate selection process was used to recruit personnel, with reportedly an 80% "washout" rate, and those made a part of the unit were not permitted transfer until the end of the war, nor were they allowed to travel without escorts from Military Intelligence units.
With the addition of the 1st Ordnance Squadron to its roster, the 509th Composite Group had an authorized strength of 225 officers and 1,542 enlisted men, almost all of whom deployed to Tinian. The 320th Troop Carrier Squadron did not officially deploy but kept its base of operations at Wendover. In addition to its authorized strength, the 509th had attached to it on Tinian 51 civilian and military personnel of Project Alberta, known as the 1st Technical Detachment. There were two representatives from Washington, D.C., Brigadier General Thomas Farrell, the deputy commander of the Manhattan Project, and Rear Admiral William R. Purnell of the Military Policy Committee. They were on hand to decide higher policy matters on the spot. Along with Captain William S. Parsons, the commander of Project Alberta, they became known as the "Tinian Joint Chiefs".
The 509th began replacement of its 14 training Silverplates in February 1945 by transferring four to the 216th Base Unit. In April they began receiving Silverplates of the third modification increment and the remaining ten training B-29s were placed in storage. Each bombardier completed at least 50 practice drops of inert pumpkin bombs and Tibbets declared his group combat-ready. Preparation for Overseas Movement (POM) began in April.
Choice of targets.
General of the Army George Marshall, the Chief of Staff of the Army, asked Groves to nominate specific targets for bombing, subject to approval by himself and Secretary of War Henry L. Stimson. Groves formed a Target Committee in April 1945 chaired by himself, that included his deputy, Brigadier General Thomas Farrell; one of his staff, Major John A. Derry; Colonel William P. Fisher, Joyce C. Stearns and David M. Dennison from the USAAF; and scientists John von Neumann, Robert R. Wilson and William C. Penney from the Manhattan Project. The Target Committee met on 27 April; at Los Alamos on 10 May, where it was able to talk to the scientists and technicians there; and finally in Washington on 28 May, where it was briefed by Colonel Paul Tibbets and Commander Frederick L. Ashworth, and the Manhattan Project's scientific advisor, Richard C. Tolman.
These cities were largely untouched during the nightly bombing raids and the Army Air Force agreed to leave them off the target list so accurate assessment of the weapon could be made. Hiroshima was described as "an important army depot and port of embarkation in the middle of an urban industrial area. It is a good radar target and it is such a size that a large part of the city could be extensively damaged. There are adjacent hills which are likely to produce a focusing effect which would considerably increase the blast damage. Due to rivers it is not a good incendiary target." The US had previously dropped leaflets warning civilians of air raids on 35 Japanese cities, including Hiroshima and Nagasaki.
The goal of the weapon was to convince Japan to surrender unconditionally in accordance with the terms of the Potsdam Declaration. The Target Committee stated that "It was agreed that psychological factors in the target selection were of great importance. Two aspects of this are (1) obtaining the greatest psychological effect against Japan and (2) making the initial use sufficiently spectacular for the importance of the weapon to be internationally recognized when publicity on it is released. Kyoto had the advantage of being an important center for military industry, as well an intellectual center and hence better able to appreciate the significance of the weapon. The Emperor's palace in Tokyo has a greater fame than any other target but is of least strategic value."
Potsdam ultimatum.
On 26 July, Allied leaders issued the Potsdam Declaration outlining terms of surrender for Japan. It was presented as an ultimatum and stated that without a surrender, the Allies would attack Japan, resulting in "the inevitable and complete destruction of the Japanese armed forces and just as inevitably the utter devastation of the Japanese homeland". The atomic bomb was not mentioned in the communiqué. On 28 July Japanese papers reported that the declaration had been rejected by the Japanese government. That afternoon, Prime Minister Kantarō Suzuki declared at a press conference that the Potsdam Declaration was no more than a rehash ("yakinaoshi") of the Cairo Declaration and that the government intended to ignore it ("mokusatsu", "kill by silence"). The statement was taken by both Japanese and foreign papers as a clear rejection of the declaration. Emperor Hirohito, who was waiting for a Soviet reply to non-committal Japanese peace feelers, made no move to change the government position.
Under the 1943 Quebec Agreement with the United Kingdom, the United States had agreed that nuclear weapons would not be used against another country without mutual consent. In June 1945 the head of the British Joint Staff Mission, Field Marshal Sir Henry Maitland Wilson, agreed that the use of nuclear weapons against Japan would be officially recorded as a decision of the Combined Policy Committee. At Potsdam, Truman agreed to a request from the Prime Minister of the United Kingdom, Winston Churchill, that Britain be represented when the atomic bomb was dropped. William Penney and Group Captain Leonard Cheshire were sent to Tinian, but found that Major General Curtis LeMay would not let them accompany the mission. All they could do was send a strongly worded signal back to Wilson.
Hiroshima.
Hiroshima during World War II.
At the time of its bombing, Hiroshima was a city of both industrial and military significance. A number of military camps were located nearby, including the headquarters of Field Marshal Shunroku Hata's 2nd General Army Headquarters, which commanded the defense of all of southern Japan. His command consisted of some 400,000 men, most of whom were on Kyushu where an Allied invasion was correctly expected. Also present in Hiroshima was the headquarters of the Fifty-Ninth Army, and most of the 224th Division, a recently formed mobile unit. The city's air defenses comprised five batteries of anti-aircraft guns.
Hiroshima was a minor supply and logistics base for the Japanese military. The city was a communications center, a storage point, and an assembly area for troops. It was one of several Japanese cities left deliberately untouched by American bombing, allowing a pristine environment to measure the damage caused by the atomic bomb.
The center of the city contained several reinforced concrete buildings and lighter structures. Outside the center, the area was congested by a dense collection of small wooden workshops set among Japanese houses. A few larger industrial plants lay near the outskirts of the city. The houses were constructed of wood with tile roofs, and many of the industrial buildings were also built around wood frames. The city as a whole was highly susceptible to fire damage.
The population of Hiroshima had reached a peak of over 381,000 earlier in the war, but prior to the atomic bombing the population had steadily decreased because of a systematic evacuation ordered by the Japanese government. At the time of the attack, the population was approximately 340,000–350,000.
The bombing.
Hiroshima was the primary target of the first nuclear bombing mission on 6 August, with Kokura and Nagasaki as alternative targets. The 393d Bombardment Squadron B-29 "Enola Gay", piloted by Tibbets, took off from North Field airbase on Tinian, about six hours flight time from Japan. The "Enola Gay" (named after Tibbets' mother) was accompanied by two other B-29s. "The Great Artiste", commanded by Major Charles W. Sweeney, carried instrumentation, and a then-nameless aircraft later called "Necessary Evil", commanded by Captain George Marquardt, served as the photography aircraft.
After leaving Tinian the aircraft made their way separately to Iwo Jima where they rendezvoused at and set course for Japan. The aircraft arrived over the target in clear visibility at . Parsons, who was in command of the mission, armed the bomb during the flight to minimize the risks during takeoff. His assistant, Second Lieutenant Morris Jeppson, removed the safety devices 30 minutes before reaching the target area.
About an hour before the bombing, Japanese early warning radar detected the approach of some American aircraft headed for the southern part of Japan. An alert was given and radio broadcasting stopped in many cities, among them Hiroshima. At nearly 08:00, the radar operator in Hiroshima determined that the number of planes coming in was very small—probably not more than three—and the air raid alert was lifted. To conserve fuel and aircraft, the Japanese had decided not to intercept small formations. Hiroshima's anti-aircraft batteries were put on alert, but held their fire; because anti-aircraft guns caused significant collateral damage and casualties on the ground, the anti-aircraft gunners of all belligerents in the war were typically ordered to avoid firing on small numbers of enemy aircraft, especially if they were stationed in or near large population centers.
The normal radio broadcast warning was given to the people that it might be advisable to go to air-raid shelters if B-29s were actually sighted. However a reconnaissance mission was assumed because at 07:31 the first B-29 to fly over Hiroshima at had been the weather observation aircraft "Straight Flush" that sent a Morse code message to the "Enola Gay" indicating that the weather was good over the primary target. Because it then turned out to sea, the 'all clear' was sounded in the city. At 08:09 Colonel Tibbets started his bomb run and handed control over to his bombardier.
The release at 08:15 (Hiroshima time) went as planned, and the gravity bomb known as "Little Boy", a gun-type fission weapon with about of uranium-235, took 43 seconds to fall from the aircraft flying at to the predetermined detonation height about above the city. The "Enola Gay" traveled before it felt the shock waves from the blast.
Due to crosswind, it missed the aiming point, the Aioi Bridge, by approximately and detonated directly over Shima Surgical Clinic. It created a blast equivalent to . (The U-235 weapon was considered very inefficient, with only 1.7% of its material fissioning.) The radius of total destruction was about one mile (1.6 km), with resulting fires across . Americans estimated that of the city were destroyed. Japanese officials determined that 69% of Hiroshima's buildings were destroyed and another 6–7% damaged.
Some 70,000–80,000 people, or some 30% of the population of Hiroshima were killed by the blast and resultant firestorm, and another 70,000 injured. Over 90% of the doctors and 93% of the nurses in Hiroshima were killed or injured—most had been in the downtown area which received the greatest damage.
Japanese realization of the bombing.
The Tokyo control operator of the Broadcasting Corporation of Japan noticed that the Hiroshima station had gone off the air. He tried to re-establish his program by using another telephone line, but it too had failed. About 20 minutes later the Tokyo railroad telegraph center realized that the main line telegraph had stopped working just north of Hiroshima. From some small railway stops within of the city came unofficial and confused reports of a terrible explosion in Hiroshima. All these reports were transmitted to the headquarters of the Imperial Japanese Army General Staff.
Military bases repeatedly tried to call the Army Control Station in Hiroshima. The complete silence from that city puzzled the men at headquarters; they knew that no large enemy raid had occurred and that no sizable store of explosives was in Hiroshima at that time. A young officer of the Japanese General Staff was instructed to fly immediately to Hiroshima, to land, survey the damage, and return to Tokyo with reliable information for the staff. It was generally felt at headquarters that nothing serious had taken place and that the explosion was just a rumor.
The staff officer went to the airport and took off for the southwest. After flying for about three hours, while still nearly from Hiroshima, he and his pilot saw a great cloud of smoke from the bomb. In the bright afternoon, the remains of Hiroshima were burning. Their plane soon reached the city, around which they circled in disbelief. A great scar on the land still burning and covered by a heavy cloud of smoke was all that was left. They landed south of the city, and the staff officer, after reporting to Tokyo, immediately began to organize relief measures.
By 8 August 1945, newspapers in the US were reporting that broadcasts from Radio Tokyo had described the destruction observed in Hiroshima. "Practically all living things, human and animal, were literally seared to death", Japanese radio announcers said in a broadcast received by Allied sources.
Post-attack casualties.
According to the US Department of Energy the immediate effects of the blast killed approximately 70,000 people in Hiroshima. Estimates of total deaths by the end of 1945 from burns, radiation and related disease, the effects of which were aggravated by lack of medical resources, range from 90,000 to 166,000.
Some estimates state up to 200,000 had died by 1950, due to cancer and other long-term effects. Another study states that from 1950 to 2000, 46% of leukemia deaths and 11% of solid cancer deaths among bomb survivors were due to radiation from the bombs, the statistical excess being estimated to 200 leukemia and 1700 solid cancers. At least eleven known prisoners of war died from the bombing.
Survival of some structures.
Some of the reinforced concrete buildings in Hiroshima had been very strongly constructed because of the earthquake danger in Japan, and their framework did not collapse even though they were fairly close to the blast center. was the closest known survivor, who was in the basement of a reinforced concrete building (it remained as the "Rest House" after the war) only from ground zero (the hypocenter) at the time of the attack. was among the closest survivors to the hypocenter of the blast. She had been in the solidly built Bank of Hiroshima only from ground-zero at the time of the attack. Since the bomb detonated in the air, the blast was directed more downward than sideways, which was largely responsible for the survival of the "Prefectural Industrial Promotional Hall", now commonly known as the "Genbaku", or A-bomb Dome. This building was designed and built by the Czech architect Jan Letzel, and was only from ground zero. The ruin was named "Hiroshima Peace Memorial" and was made a UNESCO World Heritage site in 1996 over the objections of the United States and China, which expressed reservations on the grounds that other Asian nations were the ones who suffered the greatest loss of life and property, and a focus on Japan lacked historical perspective.
Events of 7–9 August.
After the Hiroshima bombing, Truman issued a statement announcing the use of the new weapon. He stated, "We may be grateful to Providence" that the German atomic bomb project had failed, and that the United States and its allies had "spent two billion dollars on the greatest scientific gamble in history—and won." Truman then warned Japan: 
The Japanese government still did not react to the Potsdam Declaration. Emperor Hirohito, the government, and the war council were considering four conditions for surrender: the preservation of the "kokutai" (Imperial institution and national polity), assumption by the Imperial Headquarters of responsibility for disarmament and demobilization, no occupation of the Japanese Home Islands, Korea, or Formosa, and delegation of the punishment of war criminals to the Japanese government.
The Soviet Foreign Minister Vyacheslav Molotov had informed Tokyo of the Soviet Union's unilateral abrogation of the Soviet–Japanese Neutrality Pact on 5 April. At two minutes past midnight on 9 August, Tokyo time, Soviet infantry, armor, and air forces had launched the Manchurian Strategic Offensive Operation. Four hours later, word reached Tokyo that the Soviet Union had declared war on Japan. The senior leadership of the Japanese Army began preparations to impose martial law on the nation, with the support of Minister of War Korechika Anami, in order to stop anyone attempting to make peace.
Nagasaki.
Nagasaki during World War II.
The city of Nagasaki had been one of the largest sea ports in southern Japan and was of great wartime importance because of its wide-ranging industrial activity, including the production of , ships, military equipment, and other war materials.
In contrast to many modern aspects of Hiroshima, almost all of the buildings were of old-fashioned Japanese construction, consisting of wood or wood-frame buildings with wood walls (with or without plaster) and tile roofs. Many of the smaller industries and business establishments were also situated in buildings of wood or other materials not designed to withstand explosions. Nagasaki had been permitted to grow for many years without conforming to any definite city zoning plan; residences were erected adjacent to factory buildings and to each other almost as closely as possible throughout the entire industrial valley.
Nagasaki had never been subjected to large-scale bombing prior to the explosion of a nuclear weapon there. On August 1, 1945, however, a number of conventional high-explosive bombs were dropped on the city. A few hit in the shipyards and dock areas in the southwest portion of the city, several hit the Mitsubishi Steel and Arms Works, and six bombs landed at the Nagasaki Medical School and Hospital, with three direct hits on buildings there. While the damage from these bombs was relatively small, it created considerable concern in Nagasaki and many people—principally school children—were evacuated to rural areas for safety, thus reducing the population in the city at the time of the nuclear attack. By early August the city was defended by four batteries of anti-aircraft guns and two searchlight batteries.
To the north of Nagasaki there was a camp holding British Commonwealth prisoners of war, some of whom were working in the coal mines and only found out about the bombing when they came to the surface.
The bombing.
Responsibility for the timing of the second bombing was delegated to Tibbets. Scheduled for 11 August against Kokura, the raid was moved earlier by two days to avoid a five day period of bad weather forecast to begin on 10 August. Three bomb pre-assemblies had been transported to Tinian, labeled F-31, F-32, and F-33 on their exteriors. On 8 August, a dress rehearsal was conducted off Tinian by Sweeney using "Bockscar" as the drop airplane. Assembly F-33 was expended testing the components and F-31 was designated for the August 9 mission.
On the morning of 9 August 1945, the B-29 Superfortress "Bockscar", flown by Sweeney's crew, carried Fat Man, with Kokura as the primary target and Nagasaki the secondary target. The mission plan for the second attack was nearly identical to that of the Hiroshima mission, with two B-29s flying an hour ahead as weather scouts and two additional B-29s in Sweeney's flight for instrumentation and photographic support of the mission. Sweeney took off with his weapon already armed but with the electrical safety plugs still engaged.
This time Penney and Cheshire were allowed to accompany the mission, flying as observers on the third plane, "Big Stink", which was flown by the group's Operations Officer, Major James I. Hopkins, Jr. Observers aboard the weather planes reported both targets clear. When Sweeney's aircraft arrived at the assembly point for his flight off the coast of Japan, "Big Stink" failed to make the rendezvous. "Bockscar" and the instrumentation plane circled for 40 minutes without locating Hopkins. Already 30 minutes behind schedule, Sweeney decided to fly on without Hopkins.
By the time they reached Kokura a half hour later, a 70% cloud cover had obscured the city, inhibiting the visual attack required by orders. After three runs over the city, and with fuel running low because a transfer pump on a reserve tank had failed before take-off, they headed for their secondary target, Nagasaki. Fuel consumption calculations made en route indicated that "Bockscar" had insufficient fuel to reach Iwo Jima and would be forced to divert to Okinawa. After initially deciding that if Nagasaki were obscured on their arrival the crew would carry the bomb to Okinawa and dispose of it in the ocean if necessary, the weaponeer, Navy Commander Frederick Ashworth, decided that a radar approach would be used if the target was obscured.
At about 07:50 Japanese time, an air raid alert was sounded in Nagasaki, but the "all clear" signal was given at 08:30. When only two B-29 Superfortresses were sighted at 10:53, the Japanese apparently assumed that the planes were only on reconnaissance and no further alarm was given.
A few minutes later at 11:00, "The Great Artiste", the support B-29 flown by Captain Frederick C. Bock, dropped instruments attached to three parachutes. These instruments also contained an unsigned letter to Professor Ryokichi Sagane, a nuclear physicist at the University of Tokyo who studied with three of the scientists responsible for the atomic bomb at the University of California, Berkeley, urging him to tell the public about the danger involved with these weapons of mass destruction. The messages were found by military authorities but not turned over to Sagane until a month later. In 1949, one of the authors of the letter, Luis Alvarez, met with Sagane and signed the document.
At 11:01, a last minute break in the clouds over Nagasaki allowed "Bockscar"'s bombardier, Captain Kermit Beahan, to visually sight the target as ordered. The Fat Man weapon, containing a core of about of plutonium, was dropped over the city's industrial valley. It exploded 43 seconds later at above the ground halfway between the Mitsubishi Steel and Arms Works in the south and the Mitsubishi-Urakami Ordnance Works (Torpedo Works) in the north. This was nearly northwest of the planned hypocenter; the blast was confined to the Urakami Valley and a major portion of the city was protected by the intervening hills. The resulting explosion had a blast yield equivalent to . The explosion generated heat estimated at and winds that were estimated at .
Casualty estimates for immediate deaths range from 40,000 to 75,000. Total deaths by the end of 1945 may have reached 80,000. At least eight known POWs died from the bombing and as many as 13 POWs may have died, including a British Commonwealth citizen, and seven Dutch POWs. One American POW, Joe Kieyoomia, was in Nagasaki at the time of the bombing but survived, reportedly having been shielded from the effects of the bomb by the concrete walls of his cell. The radius of total destruction was about , followed by fires across the northern portion of the city to south of the bomb. The Mitsubishi-Urakami Ordnance Works, the factory that manufactured the type 91 torpedoes released in the attack on Pearl Harbor, was destroyed in the blast. There is also a peace monument and Bell of Nagasaki in the Kokura.
Plans for more atomic attacks on Japan.
Groves expected to have another atomic bomb ready for use on 19 August, with three more in September and a further three in October. On 10 August, he sent a memorandum to Marshall in which he wrote that "the next bomb . . should be ready for delivery on the first suitable weather after 17 or 18 August." On the same day, Marshall endorsed the memo with the comment, "It is not to be released over Japan without express authority from the President."
There was already discussion in the War Department about conserving the bombs in production until Operation Downfall had begun. "The problem now August is whether or not, assuming the Japanese do not capitulate, to continue dropping them every time one is made and shipped out there or whether to hold them . . . and then pour them all on in a reasonably short time. Not all in one day, but over a short period. And that also takes into consideration the target that we are after. In other words, should we not concentrate on targets that will be of the greatest assistance to an invasion rather than industry, morale, psychology, and the like? Nearer the tactical use rather than other use."
Two more Fat Man assemblies were readied. The third core was scheduled to leave Kirtland Field for Tinian on 12 August, and Tibbets was ordered by Major General Curtis LeMay to return to Utah to collect it. Robert Bacher was packaging it in Los Alamos when he received word from Groves that the shipment was suspended.
Surrender of Japan and subsequent occupation.
Until 9 August the war council had still insisted on its four conditions for surrender. On that day Hirohito ordered Kido to "quickly control the situation ... because the Soviet Union has declared war against us." He then held an Imperial conference during which he authorized minister Tōgō to notify the Allies that Japan would accept their terms on one condition, that the declaration "does not compromise any demand which prejudices the prerogatives of His Majesty as a Sovereign ruler."
On 10 August the Japanese government presented a letter of protest for the atomic bombings to the government of the United States via the government of Switzerland. On 12 August the Emperor informed the imperial family of his decision to surrender. One of his uncles, Prince Asaka, then asked whether the war would be continued if the "kokutai" could not be preserved. Hirohito simply replied "Of course." As the Allied terms seemed to leave intact the principle of the preservation of the Throne, Hirohito recorded on 14 August his capitulation announcement which was broadcast to the Japanese nation the next day despite a short rebellion by militarists opposed to the surrender.
In his "Rescript to the soldiers and sailors" delivered on 17 August, he stressed the impact of the Soviet invasion and his decision to surrender, omitting any mention of the bombs.
During the year after the bombing, approximately 40,000 US troops occupied Hiroshima, while Nagasaki was occupied by 27,000 troops.
Depiction, public response and censorship.
During the war "annihilationist and exterminationalist rhetoric" was tolerated at all levels of US society; according to the UK embassy in Washington the Americans regarded the Japanese as "a nameless mass of vermin". Caricatures depicting Japanese as less than human, e.g. monkeys, were common. A 1944 opinion poll that asked what should be done with Japan found that 13% of the US public were in favor of "killing off" all Japanese: men, women, and children.
News of the atomic bombing was greeted enthusiastically in the US; a poll in "Fortune" magazine in late 1945 showed a significant minority of Americans wishing that more atomic bombs could have been dropped on Japan. The initial positive response was supported by the imagery presented to the public (mainly the powerful mushroom cloud) and the censorship of photographs that showed corpses of people incinerated by the blast as well as photos of maimed survivors. Wilfred Burchett was the first journalist to visit Hiroshima after the atom bomb was dropped, arriving alone by train from Tokyo on 2 September, the day of the formal surrender aboard the . His Morse code dispatch was printed by the "Daily Express" newspaper in London on 5 September 1945, entitled "The Atomic Plague", the first public report to mention the effects of radiation and nuclear fallout. His report is more fully recorded in his book, "Shadow of Hiroshima".
Burchett's reporting was unpopular with the U.S. military. U.S. censors killed a supporting story submitted by George Weller of the "Chicago Daily News", and accused Burchett of being under the sway of Japanese propaganda. William L. Laurence of "The New York Times" dismissed the reports on radiation sickness as Japanese efforts to undermine American morale, ignoring his own account of Hiroshima's radiation sickness published one week earlier. During the U.S. occupation of Japan, and under General MacArthur's orders, Burchett was for a time barred entrance to Japan. A member of the US Strategic Bombing Survey, Lieutenant Daniel McGovern, used a film crew to document the results. The film crew's work resulted in a three-hour documentary entitled "The Effects of the Atomic Bombs Against Hiroshima and Nagasaki". The documentary included images from hospitals showing the human effects of the bomb; it showed burned out buildings and cars, and rows of skulls and bones on the ground. When sent to the US, it was mentioned widely in the US press, then quietly suppressed and never shown. It was classified "top secret" for the next 22 years. During this time in America, it was a common practice for editors to keep graphic images of death out of films, magazines, and newspapers. The total of of footage filmed by Lieutenant Daniel McGovern's cameramen had not been fully aired . However, according to Greg Mitchell, with the 2004 documentary film Original Child Bomb, a small part of that footage managed to reach part of the American public "in the unflinching and powerful form its creators intended".
Imagery of the atomic bombings was suppressed in Japan during the occupation although some Japanese magazines had managed to publish images before the Allied occupation troops took control. The Allied occupation forces enforced censorship on anything "that might, directly or by inference, disturb public tranquility", and pictures of the effects on people on the ground were deemed inflammatory. A likely reason for the banning was that the images depicting burn victims and funeral pyres were similar to the widely circulated images taken in liberated Nazi concentration camps.
Motion picture company Nippon Eigasha started sending cameramen to Nagasaki and Hiroshima in September 1945. On 24 October 1945 a US military policeman stopped a Nippon Eigasha cameraman from continuing to film in Nagasaki. All Nippon Eigasha's reels were then confiscated by the American authorities. These reels were in turn requested by the Japanese government, declassified, and saved from oblivion. Some black-and-white motion pictures were released and shown for the first time to Japanese and American audiences in the years from 1968 to 1970.
Atomic Bomb Casualty Commission.
In the spring of 1948, the Atomic Bomb Casualty Commission (ABCC) was established in accordance with a presidential directive from Harry S. Truman to the National Academy of Sciences–National Research Council to conduct investigations of the late effects of radiation among the survivors in Hiroshima and Nagasaki.
Among the casualties were found many unintended victims, including Allied POWs, Korean and Chinese laborers, students from Malaya on scholarships, and some 3,200 Japanese American citizens.
One of the early studies conducted by the ABCC was on the outcome of pregnancies occurring in Hiroshima and Nagasaki, and in a control city, Kure located south from Hiroshima, in order to discern the conditions and outcomes related to radiation exposure. One author has claimed that the ABCC refused to provide medical treatment to the survivors for better research results. In 1975, the Radiation Effects Research Foundation was created to assume the responsibilities of ABCC.
Hibakusha.
The survivors of the bombings are called , a Japanese word that literally translates to "explosion-affected people." , 210,830 "hibakusha" were recognized by the Japanese government, most living in Japan. The government of Japan recognizes about 1% of these as having illnesses caused by radiation. The memorials in Hiroshima and Nagasaki contain lists of the names of the "hibakusha" who are known to have died since the bombings. Updated annually on the anniversaries of the bombings, the memorials record the names of almost 440,000 deceased "hibakusha"; 280,959 in Hiroshima and 158,754 in Nagasaki.
Double survivors.
People who suffered the effects of both bombings are known as "nijū hibakusha" in Japan. On 24 March 2009, the Japanese government officially recognized Tsutomu Yamaguchi (1916–2010) as a double "hibakusha". He was confirmed to be from ground zero in Hiroshima on a business trip when Little Boy was detonated. He was seriously burnt on his left side and spent the night in Hiroshima. He arrived at his home city of Nagasaki on 8 August, the day before Fat Man was dropped, and he was exposed to residual radiation while searching for his relatives. He was the first officially recognised survivor of both bombings. He died on 4 January 2010, at the age of 93, after a battle with stomach cancer.
The 2006 documentary "Twice Survived: The Doubly Atomic Bombed of Hiroshima and Nagasaki" documented 165 "nijū hibakusha", and was screened at the United Nations.
Korean survivors.
During the war, Japan brought as many as 670,000 Korean conscripts to Japan to work as forced labor. About 20,000 Koreans were killed in Hiroshima and another 2,000 died in Nagasaki. Perhaps one in seven of the Hiroshima victims was of Korean ancestry. A Korean prince of the Joseon Dynasty, Yi Wu, died from the Hiroshima bombing. For many years, Koreans had a difficult time fighting for recognition as atomic bomb victims and were denied health benefits. However, most issues have been addressed in recent years through lawsuits.
Debate over bombings.
The role of the bombings in Japan's surrender and the US's ethical justification for them has been the subject of scholarly and popular debate for decades. J. Samuel Walker wrote in an April 2005 overview of recent historiography on the issue, "the controversy over the use of the bomb seems certain to continue." He wrote that "The fundamental issue that has divided scholars over a period of nearly four decades is whether the use of the bomb was necessary to achieve victory in the war in the Pacific on terms satisfactory to the United States."
Supporters of the bombings generally assert that they caused the Japanese surrender, preventing massive casualties on both sides in the planned invasion of Japan. One figure of speech, "One hundred million of the Japanese Empire will die for the Emperor and Nation," served as a unifying slogan. Although some Japanese were taken prisoner, most fought until they were killed or committed suicide. Nearly 99% of the 21,000 defenders of Iwo Jima were killed, and the last Japanese soldiers did not surrender until November 1949. Of the 117,000 Japanese troops defending Okinawa in April–June 1945, 94% were killed. Supporters also point to an order given by the Japanese War Ministry on 1 August 1944, ordering the execution of Allied prisoners of war when the POW-camp was in the combat zone, so ""escapees from the camp may turn into a hostile fighting force"". As War Minister, Korechika Anami was opposed to the surrender. Immediately after Hiroshima, he commented, "I am convinced that the Americans had only one bomb, after all." Eventually, Anami's arguments were overcome when Emperor Hirohito directly requested an end to the war himself.
Those who oppose the bombings, among them many US military leaders as well as ex-president Herbert Hoover, argue that it was simply an extension of the already fierce conventional bombing campaign. This, together with the sea blockade and the collapse of Germany (with its implications regarding redeployment), would also have led to a Japanese surrender – so the atomic bombings were militarily unnecessary. On the contrary, according to Kyoko Iriye Selden, "The most influential text is Truman's 1955 "Memoirs", which states that the atomic bomb probably saved half a million US lives— anticipated casualties in an Allied invasion of Japan planned for November. Stimson subsequently talked of saving one million US casualties, and Churchill of saving one million American and half that number of British lives."
Scholars have pointed out various alternatives that could have ended the war just as quickly without an invasion, but these alternatives could have resulted in the deaths of many more Japanese.
As the United States dropped its atomic bombs on Hiroshima and Nagasaki in August 1945, 1.6 million Soviet troops launched a surprise attack on the Japanese forces occupying eastern Asia. "The Soviet entry into the war played a much greater role than the atomic bombs in inducing Japan to surrender because it dashed any hope that Japan could terminate the war through Moscow's mediation", said Japanese historian Tsuyoshi Hasegawa, whose recently published "Racing the Enemy: Stalin, Truman, and the Surrender of Japan" is based on recently declassified Soviet archives as well as US and Japanese documents.
Further reading.
There is an extensive body of literature concerning the bombings, the decision to use the bombs, and the surrender of Japan. The following sources provide a sampling of prominent works on this subject matter.

Battle of Cuito Cuanavale
The Battle of Cuito Cuanavale in 1987/88 was an important episode in the Angolan Civil War (1975 to 2002). Between 9 September and 7 October 1987, the Angolan Army (FAPLA), in an attempt to finally subdue the Angolan insurgent movement UNITA in south-eastern Angola, was decisively repelled in a series of battles at the Lomba River by the South African Army (SADF), which had once more intervened on UNITA’s behalf. With FAPLA retreating to their starting point at Cuito Cuanavale, the SADF and UNITA went on the offensive and started the siege by shelling Cuito with long-range artillery on 14 October. A major battle ensued and Angola, fearing a defeat, requested help from Cuba. With Cuban reinforcements, Cuito was held and the South African advance ended after six unsuccessful attempts to overcome the FAPLA-Cuban defences between 13 January and 23 March 1988. The SADF withdrew but continued to shell Cuito from a distance.
Background.
Independence from Portugal.
For 13 years until 1974, three armed groups fought for Angola's independence from Portugal: the leftist MPLA (with its armed wing FAPLA), led by Agostinho Neto; the conservative FNLA, led by Holden Roberto and supported by Mobutu Sese Seko of Zaïre; and UNITA, led by Jonas Savimbi (a former Maoist who broke away from the FNLA, later sponsored by the CIA and South Africa).
After the Carnation Revolution of April 1974 in Portugal, the new revolutionary government of Portugal let go of Portugal's African overseas possessions, including Angola. The Treaty of Alvor comprised a series of agreements between the three rebel factions and Portugal that were to pave the way to independence. Under its terms, a transitional government was formed, elections were scheduled for the end of the year, and 11 November 1975 was slated as Angola's independence day.
Fighting between the three rebel factions started soon after the transitional government took office on 31 January 1975, with each movement gaining control of their traditional areas of influence by mid-1975: The MPLA in the capital and central Angola, the FNLA in the north and UNITA in the south.
South Africa and Southwest Africa (Namibia).
Since the termination of the UN-mandate in 1966, South Africa had been illegally occupying Southwest Africa (Namibia), a territory adjoining Angola to the south, and extending apartheid rule. 1966 saw the beginning of the armed resistance by the Southwest African liberation movement SWAPO and South African counter insurgency. After Angola’s independence in 1975, SWAPO gained the support of the Angolan government and operated against the South African forces from bases in Southern Angola. Thus, in the Angolan civil war, UNITA had become a welcome and valuable ally to South Africa in its fight against SWAPO.
On 9 August the South African Army (SADF) secured the Ruacana hydro-electric complex on the border with Namibia after engineers were prevented from moving freely by an unruly and ill-disciplined UNITA force; on 14 October South Africa launched Operation Savanah in support of UNITA and FNLA advancing on Luanda and coming within 200 km of the city. The FNLA, supported by Zairian units, South Africans and Portuguese mercenaries advanced on Luanda from the east and got as far as Kifangondo. On 7 November Cuba launched Operation Carlota, intervening in favour of the MPLA (see Cuba in Angola) with up to 30.000 troops. This enabled the MPLA to hold Luanda and on 11 November Agostinho Neto proclaimed the independence of Angola.
Cold War.
The Angolan Civil War played out against the backdrop of the Cold War struggle between the Soviet Union and the United States. Both superpowers tried to influence the outcome of the civil war through proxies.
The African liberation movements, which also opposed apartheid in South Africa, found mainly support in socialist countries. Angola and SWAPO were basically supported by Cuba and the Soviet Union and some countries of the Eastern bloc while the West, foremost the United States supported South Africa, albeit clandestinely, and their ally, UNITA.
After the Cubans had helped the MPLA gain power in 1975 they found it necessary to stay in the country until conditions stabilized.
The Soviet Union and other Eastern Bloc countries supplied the Angolan army (FAPLA) with armament, advisors and specialized technical staff.
UNITA managed to rebound and, with South African and US support, posed a threat to the Angolan government. UNITA also received backing from the US allies, most notably in the form of Stinger missiles that helped repel the air superiority of the FAPLA forces. While the U.S. helped with money and weaponry, South Africa sent around 5000 troops in aid.
South Africa's interests lay in preventing the Angolan government from gaining control of south-eastern Angola and in UNITA keeping hold of the territory as a buffer zone. Angola bordered on South African occupied Namibia (at the time called South West Africa). UNITA and South African control of southern Angola would make it difficult for SWAPO to fight for Namibian independence from bases in Angola.
The South African government's strategic concern was to ensure continued UNITA control over regions bordering Namibia, so as to prevent the SWAPO guerrillas from receiving Angolan support and gaining a springboard in southern Angola from which to launch attacks into Southwest Africa. Its security strategy was shaped by the doctrines of pre-emptive interventionism and counter-revolutionary warfare.
After South Africa had been unable to prevent the leftist MPLA, which it viewed as a Soviet surrogate, from taking power in Angola in 1975, it regarded the country as a threat to its security. This view was only confirmed by the deployment of Cuban troops in Angola. Therefore the apartheid regime's goal was to overthrow and replace the MPLA-government in Luanda with a ‘friendly’ and anti-Communist one. It actively supported the "de facto" secession of Southern Angola and, in 1979, decided to install the UNITA as its "de facto" government. After South African operation "Protea" in August 1981, in which it occupied 50.000 km² of Cunene province, UNITA took effective administrative control of most of Cunene in January 1982.
"Operação Saludando Octubre" ("Operation Greeting October").
Because of UNITA’s continued insurgency, the central government never managed to gain control of the whole country; UNITA continued control much of south-eastern Angola. Whenever it was threatened, South Africa intervened on its behalf. South Africa itself continuously kept the whole southern border in Angola and, at times, up to 50.000 km² of Cunene province occupied and repeatedly undertook invasions and raids into the country.
In 1987, as part of the Angolan government's repeated campaigns against UNITA and for the control of south-eastern Angola, the Angolan army launched campaign "Operação Saludando Octubre" to drive UNITA forces from their stronghold cities of Mavinga, a former Portuguese military base and Jamba in the southeast of the country just above the Caprivi Strip. As in previous campaigns, planning and leadership was taken over by the Soviets and the higher ranks in the units were taken over by Soviet officers. Major-General Ryabchenko would command the Angolan forces in the battle. Soviet command did not include the Cuban forces in Angola and the Cubans initially did not actively engage in combat, but only took over support functions. FAPLA's equipment was upgraded including 150 T-55 and T-55B tanks and Mi-24 helicopters. The Soviets dismissed the advice of the Cubans, as in the campaigns before, who warned that the operation would create another opportunity for a South African intervention. It was decided to commence the attack from Cuito Cuanavale.
Taking notice of the massive military build-up, South Africa warned UNITA. The Angolan campaign was initially successful and made considerable gains into south-eastern Angola. The South African government became aware that UNITA would not be able to withhold the onslaught. On 15 June it decided to intervene and authorised covert support. On 4 August 1987 the SADF launched Operation Moduler which was to stop the Angolan advance on Mavinga to prevent a rout of UNITA. The SADF 61 Mechanized Battalion crossed into Angola from their base at the border town of Rundu.
Battle of the Lomba River.
In August the FAPLA 21st, 25th (both light infantry), 47th (armoured) and the 59th (mechanized) brigades (some sources also include the 16th brigade) of FAPLA, departed from the Cuito Cuanavale. They received air support from the airbase at Menongue, including MiG 23s deployed in a ground-attack role.
Facing them were the UNITA forces composed of the 3rd Regular, 5th Regular, 13th Semi-Regular and 275th Special Forces Battalions On 28 August they reached the northern banks of the Lomba River near Mavinga, where they were expected by the SADF.
In a series of bitter fights (Battle of the Lomba River II) between 9 September and 7 October, SADF and UNITA prevented the FAPLA, which suffered heavy losses, from crossing the river. The Soviets withdrew their advisors and left the FAPLA without senior leadership.
On 29 September, South African and UNITA forces, having gained the upper-hand, launched an offensive (Operation Hooper). On 3 October they attacked and annihilated a FAPLA-battalion on the southern banks of the Lomba River near Mavinga and two days later the Angolan army headed into a retreat over 190 km back to Cuito Cuanavale, which it desperately held on to.
If Cuito Cuanavale was lost by FAPLA, the next closest comparable outpost would be Menongue, 300 km from Mavinga and 500 km from UNITA's headquarters at Jamba. In pursuit of the retreating FAPLA units the SADF and UNITA started the siege of Cuito Cuanavale on 14 October with long-range shelling by 155 mm artillery from a distance of 30 to 40 km.
Cuito Cuanavale.
By November, the SADF had cornered the remnants of three FAPLA units on the east of the Cuito River, across from the town itself and was poised to destroy them.
The quite demoralised 59th FAPLA motorised infantry brigade, 21st and 25th FAPLA light infantry brigades, in positions near Tumpo and east of the Cuito River, were effectively cut off due to SADF artillery control of both the bridge and airstrip and to UNITA guerrilla control of the road from Menongue, which they had mined and were prepared to ambush. With no functioning armour or artillery remaining, the FAPLA-units faced annihilation.
On 15 November, the Angolan government requested urgent military assistance from Cuba.
Although not responsible for the dismal situation of the FAPLA Cuba felt impelled to intervene in order to prevent a total disaster for the Angolans. In Castro's view, a South African victory would have meant not only the capture of Cuito and the destruction of the best Angolan military formations, but, quite probably, the end of Angola's existence as an independent country. Thus, Fidel Castro responded immediately by sending — in what was called ""Maniobra XXXI Aniversario de las FAR"" — materiel and 15 000 elite troops, retaking the initiative from the Soviets.
The first Cuban reinforcements in Cuito arrived by helicopter on 5 December with about 160–200 technicians, advisers, officers, and special forces.
General Arnaldo Ochoa, a veteran of the 1976 Angola campaign and of tank battles in Ethiopia, was made overall commander of the forces on the government side. Ochoa and Castro were to have serious disagreements in the conduct of the war in Angola. These tensions were to have repercussions both during the war where Castro's interference with defense plans may have cost the Cubans dozens of lives and in the aftermath of Angolan hostilities a year later when Ochoa was arrested, tried and executed by firing squad after being found guilty of treason. General Cintras Frias was made commander at Cuito Cuanavale.
The Cuban's initial priority was securing Cuito Cuanavale, but while reinforcements were arriving at the besieged garrison they made preparations for a second front to the west of Cuito Cuanavale in Lubango where the SADF had been operating unhindered for 8 years.
On 25 November the UN Security Council demanded the SADF's unconditional withdrawal from Angola by 10 December, yet, without threatening any sanctions. Through December the situation for the besieged Angolans became critical as the SADF tightened the noose around Cuito Cuanavale. Observers expected it to fall into South African hands any time soon and UNITA prematurely announced the town had been taken.
As of 21 December the SADF planned the final assault "pick off" the FAPLA units which were still caught to the east of the Cuito river "before moving in to occupy the town if the conditions were favourable".
On 9 January the SADF destroyed the important bridge across the Cuito river using a smart bomb. The Cubans managed to construct a wooden footbridge in its place which they baptised "Patria o Muerte" (fatherland or death).) They partly buried disabled tanks so that their turrets could be used as fixed artillery pieces.
The SADF brought up reinforcements and then carried out, beginning 13 January until 23 March, the first of what would prove to be six major ground assaults on the entrenched FAPLA positions east of the river, none of which delivered tangible results. A large Cuban and FAPLA column was on the way from Menongue for the relief of Cuito Cuanavale, but progress in the rainy season was slow due to the need to clear the UNITA minefields and guard against possible ambushes. They did not reach Cuito Cuanavale in time to take part in the first engagement.
Although the first attack on 13 January 1988 was successful, spelling near disaster for a FAPLA brigade, the SADF unable to continue withdrew to its starting positions. A month later, on 14 February, the SADF withdrew from a second assault after successfully driving FAPLA-Cuban units off the Chambinga high ground. Close to a catastrophe, the FAPLA units east of the Cuito River withdrew to the Tumpo (river) triangle, a smaller area, ideally suited to defence. In a third assault on 19 February the SADF suffered a first major setback when it was repelled by FAPLA battalion north of the Dala river; unable to reach FAPLA's forward positions the SADF had to withdraw. In the following days the Cubans stepped up their air attacks against South African positions. On 25 February the FAPLA-Cubans repelled a fourth assault and the SADF had to return to its positions east of the Tumpo River. The failure of this attack "proved a turning point of the battle of Cuito Cuanavale, boosting FAPLA's flagging morale and bringing the South African advance to a standstill." A fifth SADF-attack was beaten back on 29 February delivering a third consecutive defeat. After some more preparation the South Africans launched their last and fourth unsuccessful attack on 23 March. As SADF-Colonel Jan Breytenbach wrote, the South African assault "was brought to a grinding and definite halt" by the combined Cuban and Angolan forces.
Eventually Cuban troop strength in Angola increased to about 55,000, with 40,000 deployed in the south. Due to the international arms embargo since 1977, South Africa’s aging air force was outclassed by sophisticated Soviet-supplied air defence systems and air-strike capabilities fielded by the Cubans and Angolans and it was unable to uphold the air supremacy it had enjoyed for years; its loss in turn proved to be critical to the outcome of the battle on the ground. The Cuito airstrip was kept in repair, but since it was under constant observation by the SADF artillery and air force it could not be safely used by fixed wing aircraft.
After the failed assault on 23 March 1988 under orders from Pretoria the SADF withdrew the bulk of their forces, initially leaving a 1,500-man "holding force" behind (Combat Group 20) to continue deception operations and lay mines in order to prevent or slow any FAPLA offensive operations. For months it continued to shell Cuito Cuanavale and the airstrip using their long-range G-5 artillery from a distance of 30 to 40 km.
 While the Cubans had purported to be moving south into Namibia according to comments from Castro they instead moved to cut off elements of the SADF. The SADF had left much of its powerful G-5 artillery units in place due to the difficulty in transporting during the rainy season. For whatever reasons—possibly not wanting to upset strategic negotiations, willingness to risk casualties or similar difficulties with mechanized forces—the Cubans did not attempt to take the SADF positions and settled for surrounding the small force.
With that manoeuvre, Fidel Castro increased the cost to South Africa of continuing to fight in Angola and placed Cuba in its most aggressive combat position of the war, thus fortifying his argument that Cubans were preparing to leave Angola with their opponents on the defensive.
Weapons.
The SADF used a mix of British, French, Israeli, captured Soviet and indigenously developed weaponry. Their allies, UNITA used a mix of Soviet and South African supplied weaponry. The United States covertly supplied UNITA guerillas with Stingers for anti-aircraft defense. The South Africans were hampered by United Nations Security Council Resolution 418, an international arms embargo that prevented them from acquiring materiel such as modern aircraft. The Cubans and FAPLA were armed with Soviet weaponry.
Trucks used by FAPLA
Engesa-15, Engesa-25, Engesa-50 (Brazilian)
Mercedes (West Germany)
Pegaso (Spain)
IFAW50 (GDR)
GAZ-66, ZIL-131, URAL-375/URAL-4320
GAZ-51 and GAZ-63 (were used by Cubans outside Cuito)
KAMAZ and ZIL-130 (civil trucks): ZIL-157 (all were used outside Cuito) 
Jeeps
UAZ-469
UAZ-69 (GAZ-69) (used by Cubans outside Cuito)
Niva
Land Rover 109
Land Rover 110
Land Rover Defender
Miniubuses
RAF-2203 and UAZ-452
Pistols
Walther P38
TT-33 (TT)
MP (Makarov)
APS (Stechkin)
Beretta 92
Aftermath.
In the aftermath of Cuito Cuanavale on the eve of the first round of peace talks in two years Castro ordered Cuban, FAPLA and SWAPO units under General Cintras Frías opened a second front to the west at Calueque (Lubango) with a force of 40,000 Cuban troops and a 30,000 of Angolan forces, and with support from MiG-23 fighter bombers. The first South African resistance was encountered near Calueque on 15 March, followed by three months of bloody clashes as the Cubans slowly progressed towards the Namibian border.
On 9 March 1988, the Angolans, now joined by the Cubans, entered into the first round of US-brokered peace negotiations. On 3 May 1988 the South Africans returned to the peace negotiations which they had abandoned two years before.
On 26 May, the chief of the SADF announced that heavily armed Cuban and SWAPO forces had moved south within of the Namibian border. The remaining SADF forces at Cuito Cuanavale Combat Group 20 was left in place to construct minefields and carry out deception operations in order to prevent a FAPLA offensive. A number of skirmishes occurred while the SADF forces were disengaging, most notably Operation Hilti/Excite. In response to this 32 Battalion inserted an intelligence team under the command of Capt. Herman Mulder, who set up a tactical HQ at Ruacana, supporting two teams doing reconnaissance south-each of Techipa along the Devangulu Mountains; with the second team operating in the Handa Rotunda area. After gathering the required intelligence Operation Hilti/Excite was initiated on 13 June with the deployment of one company from 61 Mechanised Infantry Battalion Group at Dongue, south-west of Xangongo. An attack was also launched against Ongiva by 32 Battalion. G5 and G2 artillery pieces were provided to 61 Mechanized Battalion and they engaged the Cuban 50th Division based at Ongiva. A fierce skirmish took place at Cuamato and 201 Battalion lost one vehicle but held the town on 24 June 1988. Operation Displace was launched and became the last significant hot engagement of the entire war at Techipa on 26 June. A running fire fight happened when a platoon from 32 Battalion was engaged in an action that took place over a distance. On 27 June 61 Mechanised Infantry Battalion engaged a Cuban tank squadron before they crossed the Cunene River back into Namibia. Cuban MiG-23s bombed Calueque Dam, causing the last South African loss of life in the conflict when they killed 10 soldiers from 8 SAI. Two MiG-23s were damaged by ground fire. On 8 June 1988, hoping to send a strong message to the Cubans that they would respond to any movement into South-West Africa the South African government called up 140,000 men of the reserves (Citizen Force). This was known as Operation Desert Fox and it consisted of 81 Armoured Brigade, which positioned itself on 30 July 1988 just south of Ruacana, tasked with the responsibility of neutralizing the very aggressive Cuban 50th Brigade if need be. The signing of the formal peace treaty at Ruacana on 22 August 1988 meant that Operation Desert Fox could be aborted.
By the end of May, Cuba had two divisions in south-western Angola. By June, they constructed two forward airbases at Cahama and Xangongo with which Cuban air power could be projected into Namibia. All of southern Angola was covered by a radar network and SA-8 air defence ending South African air superiority.
In June 1988, the Cubans prepared to advance on Calueque starting from Xangongo and Tchipa. In case of serious South African counter attacks, they were prepared to destroy the Ruacana reservoirs and transformers and attack South African bases in Namibia. The offensive started from Xangongo on June 23 immediately clashing with the SADF en route to Cuamato. An SADF screening force encountered the Cuban advance in a firefight resulting in the withdrawal of the SADF force and the decision of the FAPLA-Cubans to return to their base. On 26 June the SADF conducted Operation Excite to test Cuban forces in the area. The SADF sent up decoys to provoke SAM sites into revealing their positions and shelled Tchipa with long-range artillery effectively destroying the Cuban's ability to utilize their own artillery. A series of firefights ensued with SADF tanks launching a spoiling attack on the initial gathering armor forces then withdrawing fearing being overwhelmed by Cuban reinforcements.
Cuban MiGs carried out the attacks on the SADF positions around the Calueque dam, north of the Namibian border, also damaging the bridge and hydroelectric installations. The major force of the Cubans, still on the way, never saw action and returned to Tchipa. With the withdrawal of the SADF into Namibia an 27 June the hostilities ceased.
The South Africans, impressed by the suddenness and scale of the Cuban advance and believing that a major battle "involved serious risks" withdrew. For their part the Cubans were shocked at the heavy casualties they had suffered and put their troops on alert to expect a strong South African response. Five days later Pretoria ordered Combat Group 20 which was still operational east of Cuito Cuanavale to scale back to avoid any more casualties, effectively withdrawing from all fighting, and a SADF division was deployed in defence of Namibia's northern border.
At the bargaining table the South Africans agreed to withdraw from Angola by 1 September 1988 and to the implementation of Resolution 435 for Southwest Africa on 1 November, leading to the independence of Namibia. This agreement was based on intelligence that indicated the Soviet Union would no longer sustain surrogate forces in the Third World, and that Cuba was starting to take strain from the mounting casualties. The Cubans in return would pull troops out of Angola by 1 July 1991. A peace accord, mediated by Chester Crocker, was finally signed on 22 December 1988 in New York.
Nelson Mandela considered the FAPLA-Cuban success at Cuito and in Lubango a turning point in the Angolan civil war as well as in the struggle for Namibian independence. The battle at Cuito, raging for 6 months, was the biggest battle on African soil since World War II". 
Claims of victory in this battle have been made from all sides, depending on the military, political or moral point of view. According to veteran reporter Max du Preez, the SADF "fared a lot better than the Cubans expected or were later prepared to admit."
The war cost an estimated half a million lives and devastated Angola's infrastructure until the conflict finally ended after Savimbi was shot by government forces in 2002.
The Battle of Cuito Cuanavale is commemorated in several countries in Southern Africa. The 20th anniversary in 2008 was especially celebrated in Namibia.

Racial segregation
Racial segregation is the separation of humans into racial groups in daily life. It may apply to activities such as eating in a restaurant, drinking from a water fountain, using a public toilet, attending school, going to the movies, or in the rental or purchase of a home. Segregation itself is defined by the European Commission against Racism and Intolerance as "the act by which a (natural or legal) person separates other persons on the basis of one of the enumerated grounds without an objective and reasonable justification, in conformity with the proposed definition of discrimination. As a result, the voluntary act of separating oneself from other persons on the basis of one of the enumerated grounds does not constitute segregation". According to the UN Forum on Minority Issues, "The creation and development of classes and schools providing education in minority languages should not be considered impermissible segregation, if the assignment to such classes and schools is of a voluntary nature". 
Racial segregation is generally outlawed, but may exist through social norms, even when there is no strong individual preference for it, as suggested by Thomas Schelling's models of segregation and subsequent work. Segregation may be maintained by means ranging from discrimination in hiring and in the rental and sale of housing to certain races to vigilante violence (such as lynchings, e.g.) Generally, a situation that arises when members of different races mutually prefer to associate and do business with members of their own race would usually be described as "separation" or "de facto separation" of the races rather than "segregation". In the United States, legal segregation was required in some states and came with "anti-miscegenation laws" (prohibitions against interracial marriage). Segregation, however, often allowed close contact in hierarchical situations, such as allowing a person of one race to work as a servant for a member of another race. Segregation can involve separation of the races, and/or mandatory use of different institutions, such as schools and hospitals by people of different races.
Historical cases.
Racial segregation has appeared in all parts of the world where there are multiracial communities. Where racial amalgamation has occurred on a large scale, as in Hawaii and Brazil, there was no legal segregation, however, there has been occasional social discrimination.
A racial basis for the Indian caste system?
Indo-European-speaking nomadic groups from Europe, the Near East, Anatolia, and the Caucasus migrated to India. According to 19th century British historians, it was these "Aryans" who "invaded" India and established the caste system, an elitist act of social organization that (according to the British) separated the "light-skinned" Indo-Aryan conquerors from the "conquered dark-skinned" indigenous Dravidian tribes through enforcement of "racial endogamy". This claim was used by the British, defining themselves as "purely Aryan", to justify British Rule in India. Much of this was simply conjecture, fueled by British imperialism British policies of divide and rule as well as enumeration of the population into rigid categories during the tenure of British rule in India contributed towards the hardening of these segregated caste identities. Since the independence of India from British rule, the British fantasy of an "Aryan Invasion and subjugation of the dark skinned Dravidians in India" has become a staple polemic in South Asian geopolitics, including the propaganda of Indophobia in Pakistan. There is no decisive theory as to the origins of the caste system in India, and globally renowned historians and archaeologists like Jim Shaffer, J.P. Mallory, Edwin Bryant, and others, have disputed the claim of "Aryan Invasion". However, some leftist academics like Nirad C. Chaudhuri still maintain the old-style colonialist narrative that the Aryans were Germannic Europeans who invaded India and conspired to create the "caste system" and "Hinduism" in order to secure their position in the region against the so-called "aboriginals" 
Some researchers from India, Europe and the U.S. claim that genetic similarities to Europeans were more common in members of the higher ranks. Their findings, published in "Genome Research", claimed the idea that members of higher castes are more closely related to Europeans than are the lower castes. However, other researchers have criticized and contradicted this claim. A study by Joanna L. Mountain et al. of Stanford University had concluded that there was "no clear separation into three genetically distinct groups along caste lines", although "an inferred tree revealed some clustering according to caste affiliation". A 2006 study by Ismail Thanseem et al. of Centre for Cellular and Molecular Biology (India) concluded that the "lower caste groups might have originated with the hierarchical divisions that arose within the tribal groups with the spread of Neolithic agriculturalists, much earlier than the arrival of Aryan speakers", and "the Indo-Europeans established themselves as upper castes among this already developed caste-like class structure within the tribes." A 2006 genetic study by the National Institute of Biologicals in India, testing a sample of men from 32 tribal and 45 caste groups, concluded that the Indians have acquired very few genes from Indo-European speakers. More recent studies have also debunked the British claims that so-called "Aryans" and "Dravidians" have a "racial divide". A study conducted by the Centre for Cellular and Molecular Biology in 2009 (in collaboration with Harvard Medical School, Harvard School of Public Health and the Broad Institute of Harvard and MIT) analyzed half a million genetic markers across the genomes of 132 individuals from 25 ethnic groups from 13 states in India across multiple caste groups. The study establishes, based on the impossibility of identifying any genetic indicators across caste lines, that castes in South Asia grew out of traditional tribal organizations during the formation of Indian society, and was not the product of any mythical "Aryan Invasion" and "subjugation" of Dravidian people, unlike what British racial-revanchist and revisionist claims would have one believe.
Jewish segregation.
Jews in Europe generally were forced, by decree or by informal pressure, to live in highly segregated ghettos and shtetls. In 1204 the papacy required Jews to segregate themselves from Christians and to wear distinctive clothing. Forced segregation of Jews spread throughout Europe during the 14th and 15th centuries. In the Russian Empire, Jews were restricted to the so-called Pale of Settlement, the Western frontier of the Russian Empire corresponding roughly to the modern-day countries of Poland, Lithuania, Belarus, Moldova and Ukraine. By the early 20th century, the majority of European Jews lived in the Pale of Settlement.
Jewish population were confined to mellahs in Morocco beginning from the 15th century. In cities, a "mellah" was surrounded by a wall with a fortified gateway. In contrast, rural "mellahs" were separate villages inhabited solely by the Jews.
Lewis (1984), pp. 181–183
Canada.
In Canada, the Mohawk tribe of Kahnawake has been criticized for evicting non-Mohawks from the Mohawk reserve. Mohawks who marry outside of their race lose their right to live in their homelands. The Mohawk government claims that its policy of racially exclusive membership is for the preservation of its identity, but there is no exemption for those who adopt Mohawk language or culture. The policy is based on a 1981 moratorium which was made law in 1984. All interracial couples are sent eviction notices regardless of how long they have lived on the reserve. The only exemption is for interracial couples married before the 1981 moratorium.
Although some concerned Mohawk citizens have contested the racially-exclusive membership policy, the Canadian Human Rights Tribunal has ruled that the Mohawk government may adopt policies it deems necessary to ensure the survival of its people.
A long standing practice of segregation has also been imposed upon the commercial salmon fishery in British Columbia since 1992 when separate commercial fisheries were created for select aboriginal groups on three B.C. river systems. Canadians of other races who fish in the separate fisheries have been arrested, jailed and prosecuted. Although the fishermen who were prosecuted were successful at trial (see the decision in R. v. Kapp), the decision was overturned on appeal. On final appeal, the Supreme Court of Canada ruled in favour of the program on the grounds that segregation of this workplace is a step towards equality in Canada. Affirmative action programs in Canada are protected from equality rights challenges by s. 15(2) of the Canadian Charter of Rights and Freedoms. The segregation continues today though more than 35 percent of the fishermen in the B.C. commercial fishery are of aboriginal ancestry, yet Canadians of aboriginal ancestry comprise less than 4 percent of B.C.'s population.
Canada also systematically forced First Nations children to attend Canadian Indian residential school system in order to disconnect them from their indigenous language and culture.
Since the 1970s, there has only been a concern expressed by some academics that major Canadian cities are becoming more segregated on income and ethnic lines. Reports have indicated that the inner suburbs of post-merger Toronto and the southern bedroom communities of Greater Vancouver have become steadily more immigrant and visible minority dominated communities and have laged other neighbourhoods in average income. A CBC panel in Vancouver in 2012 discussed the growing public fear that the profileration of ethnic enclaves in Greater Vancouver (e.g. Han Chinese in Richmond, Punjabis Surrey) amounted to a type of [[self-segregation. In response to theses fears, many minority activists have pointed out that most Canadian neighbourhoods remain predominately White, and yet Whites are never accused of "self-segregation", rather the
China.
Tang dynasty.
Several laws enforcing racial segregation of foreigners from Chinese were passed by the Han chinese during the Tang dynasty. In 779 the Tang dynasty issued an edict which forced Uighurs to wear their ethnic dress, stopped them from marrying Chinese females, and banned them from pretending to be Chinese. Chinese disliked Uighurs because they practiced usury. The magristrate who issued the orders may have wanted to protect "purity" in Chinese custom. In 836 Lu Chun was appointed as governor of Canton, he was disgusted to find Chinese living with foreigners and intermarriage between Chinese and foreigners. Lu enforced separation, banning interracial marriages, and made it illegal for foreigners to own property. Lu Chun believed his principles were just and upright. The 836 law specifically banned Chinese from forming relationships with "Dark peoples" or "People of colour", which was used to describe foreigners, such as "Iranians, Sogdians, Arabs, Indians, Malays, Sumatrans", among others.
Qing dynasty.
The Qing Dynasty was founded not by the Han Chinese who form the majority of the Chinese population, but the Manchus, who are today an ethnic minority of China. The Manchus were keenly aware of their minority status and during the early eras of their reign, they implemented a strict policy of racial segregation between the Manchus and Han Chinese. This ethnic segregation had cultural and economic reasons: intermarriage was forbidden to keep up the Manchurian heritage and minimize sinicization. Han Chinese and Mongols were banned from settling in Manchuria.
The Qing Dynasty started colonizing Manchuria with Han Chinese later on in the dynasty's rule, but the Manchu area was still separated from modern-day Inner Mongolia by the Outer Willow Palisade, which kept the Manchu and the Mongols in the area separate.
The policy of segregation applied directly to the banner garrisons, most of which occupied a separate walled zone within the cities in which they were stationed. While the Manchus followed the governmental structure of the preceding Ming dynasty, their ethnic policy dictated that appointments were split between Manchu noblemen and Han Chinese officials who had passed the highest levels of the state examinations, and because of the small number of Manchus, this insured that a large fraction of them would be government officials.
England and Ireland.
Segregation may have existed in early Anglo-Saxon England, restricting intermarriage and resulting in the displacement of the native British population by Germanic incomers. According to research led by the University College London, Anglo-Saxon settlers enjoyed substantial social and economic advantages over Celtic Britons. However, Stephen Oppenheimer and Bryan Sykes argue that there was no population displacement, as the Anglo-Saxons had relatively little genetic impact on England. In 2002, the BBC used the headline "English and Welsh are races apart" to report a genetic survey of test subjects from market towns in England and Wales.
The Statutes of Kilkenny were a series of thirty-five acts passed at Kilkenny in 1366. They forbad the intermarriage between the native Irish and the English settlers in Ireland, the English fostering of Irish children, the English adoption of Irish children and use of Irish names and dress.
Germany.
In the early 14th century, some guilds in the cities of North-East Germany introduced statutes, under which persons of Wendish, i.e. Slavic, origin were forbidden from joining the guild. According to Wilhelm Raabe, ""down into the eighteenth century no German guild accepted a Wend.""
The ban of interracial marriage was part of the Nuremberg Laws enacted by the Nazis in Germany against the German Jewish community during the 1930s. The laws prohibited marriages between Jews and Aryan Germans, which were classified as different races.
Under the General Government of occupied Poland in 1940, the Nazis divided the population into different groups, each with different rights, food rations, allowed housing strips in the cities, public transportation, etc. In an effort to split Polish identity they attempted to establish ethnic divisions of Kashubians and Gorals (Goralenvolk), based on these groups' alleged "Germanic component".
During the 1930s and 1940s, Jews in Nazi-controlled states were made to wear yellow ribbons or stars of David, and were, along with Romas (Gypsies), discriminated against by the racial laws. Jewish doctors and professors were not allowed to treat Aryan (effectively, gentile) patients or teach Aryan pupils, respectively.
The Jews were not allowed to use any public transportation, besides the ferry, and were able to shop only from 3–5 pm in Jewish stores. After "Kristallnacht" ("The Night of Broken Glass"), the Jews were fined 1,000,000 marks for damages done by the Nazi troops and SS members.
Jews and Roma were subjected to genocide as "undesirable" "racial" groups in the Holocaust. The Nazis established ghettos to confine Jews and sometimes Romas into tightly packed areas of the cities of Eastern Europe, turning them into "de facto" concentration camps. The Warsaw Ghetto was the largest of these ghettos, with 400,000 people. The Ghetto Litzmannstadt was the second largest, holding about 160,000.
Between 1939 and 1945, at least 1.5 million Polish citizens were transported to the Reich for forced labour (in all, about 12 million forced laborers were employed in the German war economy inside the Nazi Germany). Although Nazi Germany also used forced laborers from Western Europe, Poles, along with other Eastern Europeans viewed as racially inferior, were subject to deeper discriminatory measures. They were forced to wear identifying red tags with "P"s sewn to their clothing, subjected to a curfew, and banned from public transportation.
While the treatment of factory workers or farm hands often varied depending on the individual employer, Polish laborers as a rule were compelled to work longer hours for lower wages than Western Europeans – in many cities, they were forced to live in segregated barracks behind barbed wire. Social relations with Germans outside work were forbidden, and sexual relations ("Rassenschande" or "racial defilement") were punishable by death.
Italy.
In 1938, the fascist regime led by Benito Mussolini introduced a series of laws instituting an official segregationist policy in the Italian Empire, especially aimed against the Jews. This policy enforced various segregationist norms, like the prohibition for Jews to teach or study in ordinary schools and universities, to own industries reputed of major national interest, to work as journalists, to enter the military, and to wed non-Jews.
Some of the immediate consequences of the introduction of the 'provvedimenti per la difesa della razza' (norms for the defence of the race) included many of the best Italian scientists leaving their job, or even Italy. Amongst these, world-renowned physicists Emilio Segrè, Enrico Fermi (whose wife was Jewish), Bruno Pontecorvo, Bruno Rossi, Tullio Levi-Civita, mathematicians Federigo Enriques and Guido Fubini and even the fascist propaganda director, art critic and journalist Margherita Sarfatti, who was one of Mussolini's mistresses. Rita Levi-Montalcini, who would successively win the Nobel Prize for Medicine, was forbidden to work at the university. Albert Einstein, upon approval of the racial law, resigned from honorary membership of the Accademia dei Lincei.
Later, Fascist Italy participated actively in the persecution of the Italian Jews, arresting and handing over tens of thousands of Jews to Nazi Germany. The persecution of the Jews ended in Southern Italy (controlled by the Kingdom of Italy) after the armistice with the Allies (8 September 1943), while in Central and Northern Italy (controlled by the Italian Social Republic, a puppet state of Nazi Germany led by Mussolini) the persecution continued until the definitive fall of Mussolini's regime (25 April 1945).
Latin America.
Spanish colonists created caste systems in Latin American countries based on classification by race and race mixture. An entire nomenclature developed, including the familiar terms "mulatto", "mestizo", and "zambo" (the latter the origin of "sambo"). The Spanish had practiced a form of caste system in Hispania prior to their expulsion of the Jews and Muslims. While many Latin American countries have long since rendered the system officially illegal through legislation, usually at the time of independence, prejudice based on degrees of perceived racial distance from European ancestry combined with one's socioeconomic status remain, an echo of the colonial caste system.
Norway.
On 16 May 1940 the "Administrasjonsrådet" asked Rikskommisariatet why radio receivers had been confiscated from Jews in Norway. That "Administrasjonsrådet" thereafter "quietly" accepted racial segregation between Norwegian citizens, has been claimed by Tor Bomann-Larsen. Furthermore he claimed that this segregation "created a precedent. 2 years later ( with "NS-styret" in the ministries of Norway) Norwegian police picked up those who had listened to the radios at the addresses where radios were previously confiscated from Jews. November 26, 1942 it was time for departure and extermination".
Rhodesia.
Following a dispute over the terms for the granting of full sovereignty, the British self-governing colony of Rhodesia, governed by a predominantly white minority government, unilaterally declared independence in 1965. Led by Prime Minister Ian Smith, it endured as an unrecognized state under white rule for the next 14 years, with majority rule coming in 1979 with the Internal Settlement between Smith's government and moderate black nationalists, the associated multiracial elections and the reconstitution of the country as Zimbabwe Rhodesia, with Bishop Abel Muzorewa at the helm of a coalition cabinet comprising 12 blacks and five whites. This new order also failed to gain legitimacy in the eyes of the world, and British control returned to the country in December 1979, following the Lancaster House Agreement. New elections were held in 1980, and Zimbabwe gained recognized independence in April 1980, with Robert Mugabe as prime minister. 
Laws enforcing segregation had been around before 1965, although many institutions simply ignored them. One highly publicized legal battle occurred in 1960 involving the opening of a new theatre that was to be open to all races; the proposed unsegregated restrooms at the newly-built Reps Theatre in 1959 caused an argument called "The Battle of the Toilets".
South Africa.
The Apartheid system enacted a nation-wide social policy "separate development" with the National Party victory in 1948, following the "colour bar"-discriminatory legislation dating back to the beginning of the Union of South Africa and the Boer republics before which, while repressive to black South Africans along with other minorities, had not gone nearly so far. 
Apartheid laws can be generally divided into following acts. Firstly, the Population Registration Act in 1950 classified residents in South Africa into four racial groups: "black", "white", "colored", and "Indian" and noted their racial identities on their identifications. Secondly, the Group Areas Act in 1950 assigned different regions according to different races. People were forced to live in their corresponding regions and the action of passing the boundaries without a permit was made illegal, extending pass laws that had already curtailed black movement. Thirdly, Under the Reservation of Separate Amenities Act in 1953, amenities in public area, like hospitals, universities and parks, were labeled separately according to particular races. What is more, the Bantu Education Act in 1953 segregated national education in South Africa as well.
Uprisings and protests against Apartheid appeared immediately when Apartheid arose. As early as 1949, the youth wing of the African National Congress (ANC) advocated the abolishment of Apartheid and suggested fighting against racial segregation by various methods. During the following decades, hundreds of anti-Apartheid actions occurred, including those of the Black Consciousness Movement, students’ protests, labor strikes, and church group activism etc. In 1994, Nelson Mandela won in the first multiracial democratic election in South Africa. His success fulfilled the ending of Apartheid in South African history.
United States.
After the Thirteenth Amendment abolished slavery in America, racial discrimination became regulated by the so-called Jim Crow laws, which mandated strict segregation of the races. Though such laws were instituted shortly after fighting ended in many cases, they only became formalized after the end of Republican-enforced Reconstruction in the 1870s and 80s during a period known as the nadir of American race relations. This legalized segregation lasted up to the mid 1960s.
While the U.S. Supreme Court majority in 1896 "Plessy" explicitly upheld only "separate but equal" facilities (specifically, transportation facilities), Justice John Marshall Harlan in his dissent protested that the decision was an expression of white supremacy; he predicted that segregation would "stimulate aggressions … upon the admitted rights of colored citizens," "arouse race hate" and "perpetuate a feeling of distrust between races. Feelings between whites and blacks were so tense, even the jails were segregated."
Institutionalized racial segregation was ended as an official practice by the efforts of such civil rights activists as Clarence M. Mitchell, Jr., Rosa Parks and Martin Luther King Jr., working during the period from the end of World War II through the passage of the Voting Rights Act and the Civil Rights Act of 1964 supported by President Lyndon B. Johnson. Many of their efforts were acts of non-violent civil disobedience aimed at disrupting the enforcement of racial segregation rules and laws, such as refusing to give up a seat in the black part of the bus to a white person (Rosa Parks), or holding sit-ins at all-white .
By 1968 all forms of segregation had been declared unconstitutional by the Supreme Court, and by 1970 support for formal legal segregation had dissolved. Brown v. Board of Education of Topeka, Kansas in 1954 outlawed segregation in public schools. The Fair Housing Act of 1968, administered and enforced by the Office of Fair Housing and Equal Opportunity, prohibited discrimination in the sale and rental of housing on the basis of race, color, national origin, religion, sex, familial status, and disability. Formal racial discrimination was illegal in school systems, businesses, the American military, other civil services and the government. Separate bathrooms, water fountains and schools all disappeared and the civil rights movement had the public's support.
Contemporary segregation.
Bahrain.
On 28 April 2007, the lower house of Bahraini Parliament passed a law banning unmarried migrant workers from living in residential areas. To justify the law MP Nasser Fadhala, a close ally of the government said "bachelors also use these houses to make alcohol, run prostitute rings or to rape children and housemaids". 
Sadiq Rahma, technical committee head, who is a member of Al Wefaq said: "The rules we are drawing up are designed to protect the rights of both the families and the Asian bachelors (..) these labourers often have habits which are difficult for families living nearby to tolerate (..) they come out of their homes half dressed, brew alcohol illegally in their homes, use prostitutes and make the neighbourhood dirty (..) these are poor people who often live in groups of 50 or more, crammed into one house or apartment," said Mr Rahma. "The rules also state that there must be at least one bathroom for every five people (..) there have also been cases in which young children have been sexually molested."
Bahrain Centre for Human Rights issued a press release condemning this decision as discriminatory and promoting negative racist attitudes towards migrant workers. Nabeel Rajab, then BCHR vice president, said: "It is appalling that Bahrain is willing to rest on the benefits of these people’s hard work, and often their suffering, but that they refuse to live with them in equality and dignity. The solution is not to force migrant workers into ghettos, but to urge companies to improve living conditions for workers – and not to accommodate large numbers of workers in inadequate space, and to improve the standard of living for them."
Fiji.
Two military coups in Fiji in 1987 removed a democratically elected government led by an Indo Fijian. The coup was supported principally by the Ethnic Fijian population. A new constitution was promulgated in 1990, establishing Fiji as a republic, with the offices of President, Prime Minister, two-thirds of the Senate, and a clear majority of the House of Representatives reserved for ethnic Fijians, Ethnic Fijian ownership of the land was also entrenched in the constitution.
Fiji's case is a situation of de facto ethnic segregation. Fiji has a long complex history with more than 3500 years as a divided tribal nation. Unification under the British rule as a colony for 96 years brought other racial groups, particularly immigrants from the Indian sub-continent.
India.
India has passed multiple laws to penalise the caste system present in the society. These laws have been enshrined in the Indian constitution.
Some activists consider that the Indian caste system is a form of racial discrimination. The participants of the United Nations Conference Against Racism in Durban, South Africa in March 2001, condemned discrimination due to the caste system, and tried to pass a resolution declaring that caste as a basis for the segregation and oppression of peoples in terms of their descent and occupation is a form of apartheid. However, no formal resolution was passed to that effect
Treatment of Dalits by members of some upper castes has been described by some authors as "India's hidden apartheid".
Controversy exists as to whether caste-based discrimination is equivalent to racial discrimination. Such allegations have been rejected by some scholars such as Andre Béteille, an Indian sociologist, who writes that treating caste as a form of racism is "politically mischievous" and worse, "scientifically nonsense" since there is no discernible difference in the racial characteristics between Brahmins and Scheduled Castes. While he admits the existence of caste-based discrimination, he writes that "Every social group cannot be regarded as a race simply because we want to protect it against prejudice and discrimination".
Pakistani-American sociologist Ayesha Jalal also rejects these allegations. In her book, "Democracy and Authoritarianism in South Asia", she writes that "As for Hinduism, the hierarchical principles of the Brahmanical social order have always been contested from within Hindu society, suggesting that equality has been and continues to be both valued and practiced."
Israel.
South African Archbishop the Nobel peace laureate Desmond Tutu said he was "very deeply distressed" by a visit to the Holy Land, adding that "it reminded me so much of what happened to us black people in South Africa".
Israeli Declaration of Independence proclaims equal rights to all citizens regardless of ethnicity, denomination or race. Israel has a substantial list of laws that demand racial equality (such as prohibition of discrimination, equality in Employment, libel based on race or ethnicity.). However due to many cultural differences, and animosity towards a minority perceived to wish to annihilate Israel, a system of passively co-existing communities, segregated along ethnic lines has emerged in Israel, with Arab-Israeli minority communities being left "marooned outside the mainstream". 
Support for segregation and suspicion of Arabs in Israel is on the rise. A 2007 poll commissioned by the Center Against Racism (2008) found a worsening of Jewish citizens' perceptions of their Arab counterparts: For instance, 75% of Israeli Jews would not agree to live in a building with Arab residents, 60% would not accept any Arab visitors at their homes, 40% believed that Arabs should be stripped of their right to vote, and 59% believe that the culture of Arabs is primitive.
Segregation of women in the Jewish orthodox and Muslim fundamentalist minorities in Israel is becoming more and more of a problem. 
In the Israeli-occupied territories the situation is different, Israeli Israeli Military Orders apply; ethnic segregation exists supposedly on grounds of security measures. In the Jewish settlements, Palestinians are welcome only as workforce; they are often mistreated, and occasionally suffer violence. On the other hand Jews are not welcome in a Palestinian controlled territory. In few rare occasions when Jews entered by mistake they were, lynched or taken hostage. Jews and/or Israelis are banned by law from entering Saudi Arabia unless approved by the king.
Malaysia.
Malaysia has an article in its constitution which distinctly segregates the ethnic Malays and indigenous peoples of Malaysia—i.e. bumiputra—from the non-Bumiputra such as the Chinese and the East Indians under the social contract, of which by law would guarantee the former certain special rights and privileges. To question these rights and privileges however is strictly prohibited under the Internal Security Act, legalised by the 10th Article(IV) of the Constitution of Malaysia. The privileges mentioned herein covers—few of which—the economical and education aspects of Malaysians, e.g. the Malaysian New Economic Policy; an economic policy recently criticised by Thierry Rommel—who headed a European Commission's delegation to Malaysia—as an excuse for "significant protectionism" and a quota maintaining higher access of Malays into public universities. This system of segregation is seen as a form of apartheid by its opponents.
Mauritania.
Slavery in Mauritania was finally criminalized in August 2007 It was already abolished in 1980 though it was still affecting the descendants of black Africans abducted into slavery before generations, who live now in Mauritania as "black Moors" or "haratin" and who partially still serve the "white Moors", or "bidhan" (the name means literally white-skinned people), as slaves. The number of slaves in the country was not known exactly, but is was estimated to be up to 600,000 men, women and children, or 20% of the population.
For centuries, the so-called Haratin lower class, mostly poor black Africans living in rural areas, have been considered natural slaves by white Moors of Arab/Berber ancestry. Many descendants of the Arab and Berber tribes today still adhere to the supremacist ideology of their ancestors. This ideology has led to oppression, discrimination and even enslavement of other groups in the region of Sudan and Western Sahara. In certain villages in Mauritania there are mosques for lighter-skinned nobles and mosques for black slaves, who are still buried in separate cemeteries.
United Arab Emirates.
There is considerable racial segregation in the United Arab Emirates, where there are areas that house large numbers of South Asian migrant workers (primarily Indian, as well as Pakistan, Bangladesh, Nepal, and Sri Lanka).
United Kingdom.
The United Kingdom has no legally sanctioned system of racial segregation and has a substantial list of laws that demand racial equality. However due to many cultural differences a system of passively co-existing communities, segregated along racial lines has emerged in parts of the United Kingdom, with minority communities being left "marooned outside the mainstream”.
The affected and ‘ghettoised’ communities are often largely representative of Pakistanis, Indians and other Sub-Continentals as well as Afro-Caribbeans and other blacks, with skin colour often being a determinant, although the percentage of The United Kingdom's working and poorer class is predominantly white. Such racial segregation has widely been thought to be the basis of growing ethnic tensions, a measurable deterioration in race relations in poorer areas, a deterioration of the standard of living and levels of education and employment among ethnic minorities in poorer areas as well as being a main precursor to recent race riots. Most British commentators claim it is false the riots were due to a breakdown of multiculturalism alone and instead is more likely to have been caused by other factors such as disillusioned youth, high unemployment and a growing attraction to 'gangsta' culture by a sizeable proportion of the youth, across all ethnicities, of The United Kingdom.
There may be some indication that such segregation, particularly in residential terms, seems to be the result of the unilateral ‘steering’ of ethnic groups into particular areas as well as a culture of vendor discrimination and distrust of ethnic minority clients by some estate agents and other property professionals. This may be indicative of a market preference amongst the more wealthy to reside in areas of less ethnic mixture; less ethnic mixture being perceived as increasing the value and desirability of a residential area. This is likely as other theories such as “ethnic self segregation” have sometimes been shown to be baseless, and a majority of ethnic respondents to a few surveys on the matter have been in favour of wider social and residential integration.
United States.
De facto segregation in the United States has increased since the civil rights era in the United States. The Supreme Court ruled in Milliken v. Bradley (1974) that de facto racial segregation was acceptable, as long as schools were not actively making policies for racial exclusion; since then, schools have been segregated due to myriad indirect factors.
Redlining is the practice of denying or increasing the cost of services, such as banking, insurance, access to jobs, access to health care, or even supermarkets to residents in certain, often racially determined, areas. The most devastating form of redlining, and the most common use of the term, refers to mortgage discrimination. Over the next twenty years, a succession of further court decisions and federal laws, including the "Home Mortgage Disclosure Act" and measure to end mortgage discrimination in 1975, would completely invalidate "de jure" racial segregation and discrimination in the U.S., although "de facto" segregation and discrimination have proven more resilient. According to the Civil Rights Project at Harvard University, the actual de facto desegregation of U.S. public schools peaked in the late 1980s; since that time, the schools have, in fact, become more segregated mainly due to the ethnic segregation of the nation with whites dominating the suburbs and minorities the urban centers. According to Rajiv Sethi, an economist at Columbia University, black-white segregation in housing is slowly declining for most metropolitan areas in the US Racial segregation or separation can lead to social, economic and political tensions. Thirty years (the year 2000) after the civil rights era, the United States remained in many areas a residentially segregated society, in which blacks, whites and Hispanics inhabit different neighborhoods of vastly different quality.
Dan Immergluck writes that in 2002 small businesses in black neighborhoods still received fewer loans, even after accounting for businesses density, businesses size, industrial mix, neighborhood income, and the credit quality of local businesses. Gregory D. Squires wrote in 2003 that it is clear that race has long affected and continues to affect the policies and practices of the insurance industry. Workers living in American inner-cities have a harder time finding jobs than suburban workers.
The desire of many whites to avoid having their children attend integrated schools has been a factor in white flight to the suburbs. A 2007 study in San Francisco showed that groups of homeowners of all races tended to self-segregate in order to be with people of the same education level and race. By 1990, the legal barriers enforcing segregation had been mostly replaced by decentralized racism, where whites pay more than blacks to live in predominantly white areas. Today, many whites are willing, and are able, to pay a premium to live in a predominantly white neighborhood. Equivalent housing in white areas commands a higher rent. These higher rents are largely attributable to exclusionary zoning policies that restrict the supply of housing. Regulations ensure that all housing units are expensive enough to prevent access by undesirable groups. By bidding up the price of housing, many white neighborhoods effectively shut out blacks, because blacks are unwilling, or unable, to pay the premium to buy entry into these expensive neighborhoods. Conversely, equivalent housing in black neighborhoods is far more affordable to those who are unable or unwilling to pay a premium to live in white neighborhoods. Through the 1990s, residential segregation remained at its extreme and has been called "hypersegregation" by some sociologists or "American Apartheid"
In February 2005, the U.S. Supreme Court ruled in "Johnson v. California" that the California Department of Corrections' unwritten practice of racially segregating prisoners in its prison reception centers – which California claimed was for inmate safety (gangs in California, as throughout the U.S., usually organize on racial lines)— is to be subject to strict scrutiny, the highest level of constitutional review.
Yemen.
In Yemen, the Arab elite practices an unofficial form of discrimination against the lower class Akhdam people.

Roswell UFO incident
The Roswell UFO Incident, also known simply as Roswell, was a report of an object that crashed near Roswell, New Mexico, in June or July 1947, allegedly an extra-terrestrial spacecraft and its alien occupants. Since the late 1970s the incident has been the subject of intense controversy and several conspiracy theories as to the true nature of the object that crashed. The United States Armed Forces maintains that what was recovered was debris from an experimental high-altitude surveillance balloon belonging to a classified program named "Mogul"; many UFO proponents maintain that an alien craft was found and its occupants were captured, and that the military then engaged in a cover-up. The incident has turned into a widely known pop culture phenomenon, making the name Roswell synonymous with UFOs. It is the most publicized and controversial of alleged UFO incidents.
On July 8, 1947, the Roswell Army Air Field (RAAF) public information officer Walter Haut in Roswell, New Mexico, issued a press release stating that personnel from the field's 509th Bomb Group had recovered a crashed "flying disk" from a ranch near Roswell, sparking intense media interest. The next day, the press reported that Commanding General of the Eighth Air Force Roger M. Ramey stated that, in fact, a radar-tracking balloon had been recovered by the RAAF personnel, not a "flying disc." A subsequent press conference was called, featuring debris said to be from the crashed object, which seemed to confirm the weather balloon description.
The incident was forgotten and almost completely ignored, even by UFO researchers, for more than 30 years. Then, in 1978, physicist and ufologist Stanton T. Friedman interviewed Major Jesse Marcel who was involved with the original recovery of the debris in 1947. Marcel expressed his belief that the military had covered up the recovery of an alien spacecraft. His story spread through UFO circles, being featured in some UFO documentaries at the time. In February 1980, "The National Enquirer" ran its own interview with Marcel, garnering national and worldwide attention for the Roswell incident.
Additional witnesses added significant new details, including claims of a huge military operation dedicated to recovering alien craft and aliens themselves, at as many as 11 crash sites, and alleged witness intimidation. In 1989, former mortician Glenn Dennis put forth a detailed personal account, wherein he claimed that alien autopsies were carried out at the Roswell base.
In response to these reports, and after congressional inquiries, the General Accounting Office launched an inquiry and directed the Office of the Secretary of the Air Force to conduct an internal investigation. The result was summarized in two reports. The first, released in 1995, concluded that the reported recovered material in 1947 was likely debris from a secret government program called Project Mogul, which involved high altitude balloons meant to detect sound waves generated by Soviet atomic bomb tests and ballistic missiles. The second report, released in 1997, concluded that reports of recovered alien bodies were likely a combination of innocently transformed memories of military accidents involving injured or killed personnel, innocently transformed memories of the recovery of anthropomorphic dummies in military programs like Project High Dive conducted in the 1950s, and hoaxes perpetrated by various witnesses and UFO proponents. The psychological effects of time compression and confusion about when events occurred explained the discrepancy with the years in question. These reports were dismissed by UFO proponents as being either disinformation or simply implausible. However, numerous high-profile UFO researchers discount the possibility that the incident had anything to do with aliens.
Contemporary accounts of materials found.
On June 14, 1947, William Ware "Mack" or "Mac" Brazel noticed some strange clusters of debris while working on the Foster homestead, where he was foreman, some north of Roswell. This date (or "about three weeks" before July 8) appeared in later stories featuring Brazel, but the initial press release from the Roswell Army Air Field said the find was "sometime last week," suggesting Brazel found the debris in early July. Brazel told the Roswell Daily Record that he and his son saw a "large area of bright wreckage made up of rubber strips, tinfoil, a rather tough paper and sticks." He paid little attention to it but returned on July 4 with his son, wife and daughter to gather up the material. Some accounts have described Brazel as having gathered some of the material earlier, rolling it together and stashing it under some brush. The next day, Brazel heard reports about "flying discs" and wondered if that was what he had picked up. On July 7, Brazel saw Sheriff Wilcox and "whispered kinda confidential like" that he may have found a flying disc. Another account quotes Wilcox as saying that Brazel reported the object on July 6.
Sheriff Wilcox called Roswell Army Air Field. Major Jesse Marcel and a "man in plainclothes" accompanied Brazel back to the ranch where more pieces were picked up. "spent a couple of hours Monday afternoon [July 7 looking for any more parts of the weather device", said Marcel. "We found a few more patches of tinfoil and rubber."
As described in the July 9, 1947, edition of the "Roswell Daily Record",
Colonel William H. Blanchard, commanding officer of the 509th, contacted General Roger M. Ramey of the Eighth Air Force in Fort Worth, Texas, and Ramey ordered the object be flown to Fort Worth Army Air Field. At the base, Warrant Officer Irving Newton confirmed Ramey’s preliminary opinion, identifying the object as being a weather balloon and its "kite," a nickname for a radar reflector used to track the balloons from the ground. Another news release was issued, this time from the Fort Worth base, describing the object as being a "weather balloon".
In Fort Worth, several news photographs were taken that day of debris said to be from the object.
Witness accounts emerge.
New witness accounts and the emergence of alien narratives.
In 1978, nuclear physicist and author Stanton T. Friedman interviewed Jesse Marcel, the only person known to have accompanied the Roswell debris from where it was recovered to Fort Worth where reporters saw material said to be part of the recovered object. Over the next few years, the accounts he and others gave elevated Roswell from a forgotten incident to perhaps the most famous UFO case of all time.
By the early 1990s, UFO researchers such as Friedman, William Moore, Karl T. Pflock, and the team of Kevin D. Randle and Donald R. Schmitt had interviewed several hundred people who had, or claimed to have had, a connection with the events at Roswell in 1947. Additionally, hundreds of documents were obtained via Freedom of Information Act requests, as were some apparently leaked by insiders, such as the disputed "Majestic 12" documents.
Their conclusions were that at least one alien craft had crashed in the Roswell vicinity, that aliens, some possibly still alive, were recovered, and that a massive cover-up of any knowledge of the incident was put in place.
Numerous books, articles, television specials and even a made-for-TV movie brought the 1947 incident fame and notoriety so that by the mid-1990s, strong majorities in polls, such as a 1997 CNN/"Time" poll, believed that aliens had visited earth and specifically that aliens had landed at Roswell and the government was covering up the fact.
A new narrative emerged, which was at strong odds with what was reported in 1947. This narrative evolved over the years from the time the first book on Roswell was published in 1980 as many new witnesses and accounts emerged, drawn out in part by publicity on the incident. Though skeptics had many objections to the plausibility of these accounts, it was not until 1994 and the publication of the first Air Force report on the incident that a strong counter-argument to the presence of aliens was widely publicized.
Numerous scenarios emerged from these authors as to what they felt were the true sequence of events, depending on which witness accounts were embraced or dismissed, and what the documentary evidence suggested. This was especially true in regards to the various claimed crash and recovery sites of alien craft, as various authors had different witnesses and different locations for these events.
What follows is accounts of the sequence of events according to some of the major books published on the subject.
"The Roswell Incident" (1980).
The first book on the subject, "The Roswell Incident" by Charles Berlitz and William L. Moore, was published in 1980. The authors at the time said they had interviewed more than ninety witnesses. Though uncredited, Stanton Friedman did substantial research for the book. The book featured accounts of debris described by Jesse Marcel as "nothing made on this earth." Additional accounts suggested that the material Marcel recovered had super-strength and other attributes not associated with anything known of terrestrial origin, and certainly not anything associated with a "weather balloon" which was the official description of the object. The book also introduced the contention that debris recovered by Marcel at the Foster ranch (visible in photographs showing Marcel posing with the debris) was substituted for debris from a weather device (visible in pictures with Gen. Ramey, Marcel and others) as part of a cover-up. The actual debris recovered from the ranch—which, the authors claimed, was from a crashed UFO—was not permitted a close inspection by the press. Also described were efforts by the military to discredit and "counteract the growing hysteria towards flying saucers". Additionally, various accounts of witness intimidation were included, in particular reports of the incarceration of Mac Brazel, who reported the debris in the first place. (These reports came from relatives and others as Brazel had died years earlier.)
A report of Roswell residents Dan Wilmot and his wife seeing an object "like two inverted saucers faced mouth to mouth" passing overhead on the evening of July 2 was included, as were other reports of mysterious objects seen flying overhead. The book also introduced an alien account by Barney Barnett who had died years earlier. Friends said he had on numerous occasions described the crash of a flying saucer and the recovery of alien corpses in the Socorro area, about west of the Foster ranch. He and a group of archaeologists who happened to be in the vicinity had stumbled upon an alien craft and its occupants on the morning of July 3, only to be led away by military personnel. Further accounts suggested that these aliens and their craft were shipped to Edwards Air Force Base (known then as Muroc Army Air Field) in California. The book suggested that either there were two crafts that crashed, or debris from the vehicle Barnett had described had landed on the Foster ranch after an explosion.
Marcel said he "heard about it on July 7" when the sheriff whom Brazel had called him, but also said that " Sunday, July 6, Brazel decided he had better go into town and report this to someone," who in turn called Marcel, suggesting, though not stating, that he was contacted July 6. In 1947, Marcel was quoted as saying he visited the ranch on Monday, July 7.
Marcel described returning to Roswell the evening of July 7 to find that news of the discovery of a flying disc had leaked out. Calls were made to his house, including a visit from a reporter, but he would not confirm the reports for the press. "The next morning, that written press release went out, and after that things really hit the fan."
The book suggested that the military orchestrated Brazel's testimony to make it appear a mundane object had landed on the ranch, though the book did not explicitly say that the military instructed Brazel to give a mid-June date for his discovery. "Brazel... to great pains to tell the newspaper people exactly what the Air Force had instructed him to say regarding how he had come to discover the wreckage and what it looked like ..."
"UFO Crash at Roswell" (1991).
In 1991, with the benefit of a decade of publicity on the incident and numerous new witness interviews, Kevin D. Randle and Donald R. Schmitt published "UFO Crash at Roswell".
Timelines were slightly altered. The date that Brazel reported the debris and Marcel went to the ranch was said to be Sunday, July 6, not the next day as some of the original accounts suggested, and "The Roswell Incident" had left unclear. Additionally, Marcel and an unidentified counter-intelligence agent spent the night at the ranch, something not mentioned previously. They gathered material on Monday, then Marcel dropped by his house on the way to the Roswell base in the early hours of Tuesday, July 8.
Significant new details emerged, including accounts of a "gouge... that extended four or five hundred feet" at the ranch and descriptions of an elaborate cordon and recovery operation. (Several witnesses in "The Roswell Incident" described being turned back from the Foster ranch by armed military police, but more extensive descriptions were lacking.)
The Barnett accounts were mentioned, though the dates and locations were changed from the accounts found in "The Roswell Incident". In this new account, Brazel is described as leading the Army to a second crash site on the ranch, where the Army was "horrified to find civilians Barnett there already."
New witness accounts added substantially to the reports of aliens and their recovery. Glenn Dennis had emerged as an important witness after calling the hotline when an episode of “Unsolved Mysteries” featured the Roswell incident in 1989. His descriptions of Roswell alien autopsies were the first to place alien corpses at the Roswell Army Air Base.
No mention, except in passing, was made of the claim found in "The Roswell Incident" that the Roswell aliens and their craft were shipped to Edwards Air Force Base. The book established a chain of events with alien corpses seen at a crash site, their bodies shipped to the Roswell base as witnessed by Dennis, and then flown to Fort Worth and finally to Wright Field in Dayton, Ohio, the last known location of the bodies (accounts assembled in part from the testimony of Frank Kaufmann and Capt. O. W. Henderson).
"Crash at Corona" (1992).
In 1992, "Crash at Corona", written by Stanton Friedman and Don Berliner, suggested a high-level cover-up of a UFO recovery, based on documents they obtained such as the Majestic 12 archive. These documents were anonymously dropped off at a UFO researcher’s house in 1984 and purported to be 1952 briefing papers for incoming President Dwight Eisenhower describing a high-level government agency whose purpose was to investigate aliens recovered at Roswell and to keep such information hidden from public view. Friedman had done much of the research for "The Roswell Incident" with William Moore, and "Crash at Corona" built on that research. The title contains Corona instead of Roswell as Corona is geographically closer to the Foster ranch crash site.
The time-line is largely the same as previously, with Marcel and Sheridan Cavitt, a counter-intelligence agent who was likely the "man in plainclothes" described by Brazel in 1947, visiting the ranch on Sunday, July 6. But the book says that Brazel was "taken into custody for about a week" and escorted into the offices of the Roswell Daily Record on July 10 where he gave an account he was told to give by the government.
A sign of the disputes between various researchers is on display as Friedman and Berliner move the Barnett account back to near Socorro and introduce a new eyewitness account of the site from Gerald Anderson who provided vivid descriptions of both a downed alien craft and four aliens, of which at least one was alive. The authors note that much of their evidence had been dismissed by "UFO Crash at Roswell" "without a solid basis" and that "a personality conflict between Anderson and Randle" meant that Friedman was the author who investigated his claim. The book, however, largely embraces the sequence of events from "UFO Crash at Roswell", where aliens are seen at the Roswell Army Air Field, based on the Dennis account, and then shipped off to Fort Worth and then Wright Field.
The book suggests as many as eight alien corpses were recovered from two crash sites: three dead and perhaps one alive from the Foster ranch, and three dead and one living from the Socorro site.
"The Truth about the UFO Crash at Roswell" (1994).
In 1994, Randle and Schmitt published a second book, "The Truth about the UFO Crash at Roswell". while restating much of the case as laid out in their earlier book, new and expanded accounts of aliens were included, and a new location for the recovery of aliens was detailed. Additionally, an almost completely new scenario as to the sequence of events was laid out.
For the first time, the object was said to have crashed on the evening of Friday, July 4 instead of Wednesday July 2, the date in all the previous books. Another important difference was the assertion that the alien recovery was well under way before Brazel went into Roswell with his news about debris on the Foster ranch. Indeed, several objects had been tracked by radar for a few days in the vicinity before one crashed. In all previous accounts, the military was made aware of the alleged alien crash only when Brazel came forward. Additionally, Brazel was said to have given his news conference on July 9, and his press conference and the initial news release announcing the discovery of a "flying disc" were all part of an elaborate ruse to shift attention away from the "true" crash site.
The book featured a new witness account describing an alien craft and aliens from Jim Ragsdale, at a new location just north of Roswell, instead of closer to Corona on the Foster ranch. Corroboration was given by accounts from a group of archaeologists. Five alien corpses were seen. While the Foster ranch was a source of debris as well, no bodies were recovered there.
Expanded accounts came from Dennis and Kaufmann. And a new account from Ruben Anaya described New Mexico Lieutenant Governor Joseph Montoya's claim that he saw alien corpses at the Roswell base.
More disagreement between Roswell researchers is on display in the book. A full chapter is devoted to dismissing the Barnett and Anderson accounts from Socorro, a central part of "Crash at Corona" and "The Roswell Incident". "...Barnett's story, and in fact, the Plains San Augustin, near Soccoro scenario, must be discarded", say the authors. An appendix is devoted to describing the Majestic 12 documents, another central part of "Crash at Corona", as a hoax.
The two Randle and Schmitt books remain highly influential in the UFO community, their interviews and conclusions widely reproduced on websites. Randle and Schmitt claimed to have "conducted more than two thousand interviews with more than five hundred people" during their Roswell investigations.
UFO community schism.
By the publication of "The Truth About the UFO Crash at Roswell" in 1994, a serious split had emerged within the UFO community as to the true sequence of the events and the locations of the alleged alien crash sites. The Center for UFO Studies (CUFOS) and the Mutual UFO Network (MUFON), two leading UFO societies, were at odds over the various scenarios presented by Randle/Schmitt and Friedman/Berliner, so much so that several conferences were held to try to resolve the differences. One of the issues under discussion was where, precisely, Barnett was when he saw the alien craft he was said to have encountered. A 1992 conference tried to achieve a consensus among the various scenarios as portrayed in "Crash at Corona" and "UFO Crash at Roswell", but the publication of "The Truth About the UFO Crash at Roswell" in 1994 "resolved" the Barnett problem by simply ignoring him and citing a new location for the alien craft recovery, including a new group of archaeologists not connected to the ones the Barnett story cited.
"Alien autopsy" footage.
Film footage claimed to have been taken by a U.S. military official shortly after the Roswell incident, and purportedly showing an alien autopsy, was released in 1995 by Ray Santilli, a London-based video entrepreneur. The footage caused an international sensation when it aired on television networks around the world. In 2006, Santilli admitted that the film was mostly a reconstruction but continued to claim that it was based on genuine footage now lost, and that some frames from the original remained. The story was retold in the comedy film "Alien Autopsy", released in 2006.
Air Force and skeptics respond to alien reports.
Air Force reports on the Roswell UFO incident.
In the mid-1990s, the United States Air Force issued two reports that, they said, accounted for the debris found and reported on in 1947, and that also accounted for the later reports of alien recoveries. The reports identified the debris as coming from a top secret government experiment called Project Mogul, which tested the feasibility of detecting Soviet nuclear tests and ballistic missiles with equipment on high-altitude balloons. Accounts of aliens were explained as resulting from misidentified military experiments that used anthropomorphic dummies, accidents involving injured or killed military personnel, and hoaxes perpetrated by various witnesses and UFO proponents.
The Air Force report formed a basis for a skeptical response to the claims many authors were making about the recovery of aliens, though skeptical researchers such as Philip J. Klass and Robert Todd had already been publishing articles for several years raising doubts about alien accounts before the Air Force issued its conclusions.
While books published into the 1990s suggested there was much more to the Roswell incident than the mere recovery of a weather balloon, skeptics, and even some social anthropologists instead saw the increasingly elaborate accounts as evidence of a myth being constructed. After the release of the Air Force reports in the mid-1990s, several books, such as Kal K. Korff's "The Roswell UFO Crash: What They Don't Want You To Know", published in 1997, built on the evidence presented in the reports to conclude "there is no credible evidence that the remains of an extraterrestrial spacecraft was involved."
Problems with witness accounts.
Hundreds of witnesses were interviewed by the various researchers, a seemingly impressive figure, but a comparable few were true "witnesses" who claimed to have actually seen debris or aliens, critics point out. Most "witnesses" were in fact repeating the claims of others, and their testimony would be inadmissible hearsay in an American court, says Korff. Of the 90 witnesses claimed to have been interviewed for "The Roswell Incident", says Korff, the testimony of only 25 appear in the book, and only seven actually saw the debris. Of these, five handled the debris.
Karl T. Pflock, in his 2001 book "Roswell: Inconvenient Facts and the Will to Believe", makes a similar point about Randle and Schmitt's "UFO Crash at Roswell." Some 271 people are listed in the book who were "contacted and interviewed" for the book, and this number does not include those who chose to remain anonymous, etc., meaning more than 300 "witnesses" were interviewed, a figure Pflock said the authors frequently cited. Of these 300-plus individuals, said Pflock, only 41 can be "considered genuine first- or second-hand witnesses to the events in and around Roswell or at the Fort Worth Army Air Field," and only 23 can be "reasonably thought to have seen physical evidence, debris recovered from the Foster Ranch." Of these, said Pflock, only seven have asserted anything suggestive of otherworldly origins for the debris.
As for the several accounts from those who claimed to have seen aliens, critics identified problems with these accounts ranging from the reliability of second-hand accounts (Pappy Henderson, General Exon, etc.), to serious credibility problems with witnesses making demonstrably false claims or multiple, contradictory accounts (Gerald Anderson, Glenn Dennis, Frank Kaufmann, Jim Ragsdale), to dubious death-bed "confessions" or accounts from elderly and easily confused witnesses (Maj. Edwin Easley, Lewis Rickett).
Pflock, writing in 2001, noted that only four people with firsthand knowledge of alien bodies were interviewed and identified by Roswell authors: Frank Kaufmann; Jim Ragsdale; Lt. Col. Albert Lovejoy Duran; Gerald Anderson. Duran is mentioned in a brief footnote in "The Truth About the UFO Crash at Roswell" and never again, while the other three all have serious credibility problems, said Pflock.
A basic problem with all the witness accounts, charge critics, is that they all came a minimum of 31 years after the events in question, and in many cases were recounted more than 40 years after the fact. Not only are memories this old of dubious reliability, say the critics, they were also subject to contamination from other accounts they may have heard.
Finally, the shifting claims of Jesse Marcel, whose suspicions that what he recovered in 1947 was "not of this world" sparked interest in the incident in the first place, cast serious doubt on the reliability of what he claimed, critics charge.
In "The Roswell Incident", Marcel stated: "Actually, this material may have "looked" like tinfoil and balsa wood, but the resemblance ended there." And, "They took one picture of me on the floor holding up some of the less-interesting metallic debris...The stuff in that one photo was pieces of the actual stuff we found. It was not a staged photo." Timothy Printy points out that the material Marcel positively identified as being part of what he recovered is material that skeptics and UFO advocates agree is debris from a balloon device.
After that fact was pointed out to him, Marcel changed his story to say that that material was not what he recovered. Skeptics like Robert G. Todd argue that Marcel had a history of embellishment and exaggeration, such as claiming to have been a pilot and having received five Air Medals for shooting down enemy planes, claims that were found to be false, and his evolving Roswell story was another instance of this.
Contradictory conclusions, questionable research, Roswell as a myth.
Critics point out that the large variety of claimed crash flights suggest events spanning many years have been incorporated into a single event and that many authors uncritically embrace anything that suggests aliens, even when accounts contradict each other. Said Karl Pflock, a one-time advocate of an alien incident at Roswell: "case for Roswell is a classic example of the triumph of quantity over quality. The advocates of the crashed-saucer tale... simply shovel everything that seems to support their view into the box marked 'Evidence' and say, 'See? Look at all this stuff. We "must" be right.' [emphasis in original Never mind the contradictions. Never mind the lack of independent supporting fact. Never mind the blatant absurdities."
Kal Korff suggests there are clear incentives for some to promote the idea of aliens at Roswell, while many researchers are not doing competent work: "UFO field is people who are willing to take advantage of the gullibility of others, especially the paying public. Let's not pull any punches here: The Roswell UFO myth has been very good business for UFO groups, publishers, for Hollywood, the town of Roswell, the media, and UFOlogy ... [The number of researchers who employ science and its disciplined methodology is appallingly small."
Gildenberg and others said that, when added up, there were as many as 11 reported alien recovery sites and these recoveries bore only a marginal resemblance to the event as initially reported in 1947 or recounted later by the initial witnesses. Some of these new accounts could have been confused accounts of the several known recoveries of injured and dead from four military plane crashes that occurred in the vicinity from 1948–50. Others could have been recoveries of test dummies, as suggested by the Air Force in their reports.
Charles Ziegler argued that the Roswell story has all the hallmarks of a traditional folk narrative. He identified six distinct narratives, starting with "The Roswell Incident" (1980) and a process of transmission via storytellers with a core story that was created from various witness accounts, and was shaped and molded by those who carry on the group's (the UFO community) tradition. Others were sought out to expand the core narrative, with those who give accounts not in line with the core beliefs repudiated or omitted by the "gatekeepers." Others retold the narratives in new forms, and the process would repeat.
Roswellian Syndrome.
"Incident"
The initial incident and reporting on July 8, 1947 
"Debunking"
Soon after the initial reports, the mysterious object was identified as a weather balloon, later confirmed to be a balloon array from Project Mogul which had gone missing in flight.
"Submergence"
The news story ended with the identification of the weather balloon. However, the event lingered on in the ‘fading and recreative memories of some of those involved’. Rumor and speculation simmered just below the surface in Roswell and became part of the culture at large. In time, UFOlogists arrived, asked leading questions and helped to spin a tale of crashed flying saucers and government conspiracy of cover-up.
"Mythologizing"
The most complex part of the syndrome. After the story submerged and over time, reemerged, it developed into an ever expanding and elaborate myth. The mythologizing process included exaggeration, faulty memory, folklore and deliberate hoaxing. The deliberate hoaxing, usually self-serving for personal gain or promotion (for example, promotion of the 1950 sci-fi movie The Flying Saucer) in turn fed the folklore. 
"Reemergence and Media Bandwagon Effect"
Publication of books such as ‘The Roswell Incident’ by Berlitz and Moore in 1980, television shows and other venues perpetuate the UFO crash and cover-up conspiracy beliefs that typically mirror and oscillate with public sentiment toward the US government.
The authors predicted that the Roswellian Syndrome would "play out again and again", not only in the Roswell story, but also in other UFO and conspiracy-theorized stories.
Developments since 1990s.
Pro-UFO advocates dismiss Roswell incident.
One of the immediate outcomes of the Air Force reports on the Roswell UFO incident was the decision by some prominent UFO researchers to view the Roswell incident as not involving any alien craft.
While the initial Air Force report was a chief reason for this, another was the release of secret documents from 1948 that showed that top Air Force officials did not know what the UFO objects being reported in the media were and their suspicion they might be Soviet spy vehicles.
In January 1997, Karl T. Pflock, one of the more prominent pro-UFO researchers, said “Based on my research and that of others, I'm as certain as it's possible to be without absolute proof that no flying saucer or saucers crashed in the general vicinity of Roswell or on the Plains of San Agustin in 1947. The debris found by Mac Brazel...was the remains of something very earthly, all but certainly something from the Top Secret Project Mogul...The formerly highly classified record of correspondence and discussions among top Air Force officials who were responsible for cracking the flying saucer mystery from the mid-1940s through the early 1950s makes it crystal clear that they didn't have any crashed saucer wreckage or bodies of saucer crews, but they were desperate to have such evidence ..."
Kent Jeffrey, who organized petitions to ask President Bill Clinton to issue an Executive Order to declassify any government information on the Roswell incident, similarly concluded that no such aliens were likely involved.
William L. Moore, one of the earliest proponents of the Roswell incident, said this in 1997: "After deep and careful consideration of recent developments concerning Roswell...I am no longer of the opinion that the extraterrestrial explanation is the best explanation for this event." Moore was co-author of the first book on Roswell, "The Roswell Incident".
Shoddy research revealed; witnesses suspected of hoaxes.
Around the same time, a serious rift between two prominent Roswell authors emerged. Kevin D. Randle and Donald R. Schmitt had co-authored several books on the subject and were generally acknowledged, along with Stanton Friedman, as the leading researchers into the Roswell incident. The Air Force reports on the incident suggested that basic research claimed to have been carried out was not carried out, a fact verified in a 1995 "Omni" magazine article. Additionally, Schmitt claimed he had a bachelor’s degree, a master’s degree and was in the midst of pursuing a doctorate in criminology. He also claimed to be a medical illustrator. When checked, it was revealed he was in fact a letter carrier in Hartford, Wisconsin, and had no known academic credentials. At the same time, Randle publicly distanced himself from Schmitt and his research. Referring to Schmitt’s investigation of witness Dennis’s accounts of a missing nurse at the Roswell base, he said: "The search for the nurses proves that he will lie about anything. He will lie to anyone ... He has revealed himself as a pathological liar ... I will have nothing more to do with him."
Additionally, several prominent witnesses were shown to be perpetrating hoaxes, or suspected of doing so. Frank Kaufmann, a major source of alien reports in the 1994 Randle and Schmitt book "The Truth About the UFO Crash at Roswell" and a witness whose testimony it was charged was “ignored” by the Air Force when compiling their reports, was shown, after his 2001 death, to have been forging documents and inflating his role at Roswell. Randle and Mark Rodeigher repudiated Kaufmann’s credibility in two 2002 articles.
Glenn Dennis, who testified that Roswell alien autopsies were carried out at the Roswell base and that he and others were the subjects of threats, was deemed one of the “least credible” Roswell witnesses by Randle in 1998. In Randle and Schmitt’s 1991 book "UFO Crash at Roswell", Dennis’s story was featured prominently. Randle said Dennis was not credible “for changing the name of the nurse once we had proved she didn't exist.” Dennis’s accounts were also doubted by researcher Pflock.
Photo analysis; documentaries; new claims.
UFO researcher David Rudiak, and others before him, claimed that a telegram that appears in one of the 1947 photos of balloon debris in Ramey's office contains text that confirms that aliens and a "disk" were found. Rudiak and some other examiners claim that when enlarged, the text on the paper General Ramey is holding in his hand includes key phrases "the victims of the wreck" and "in/on the 'disc'" plus other phrases seemingly in the context of a crashed vehicle recovery. However, pro-UFO interpretations of this document are disputed by other photoanalyses, such as one facilitated by researcher James Houran, Ph.D., that suggest the letters and words are indistinct. Other objections question the plausibility of a general allowing himself to be photographed holding such a document, raise issues with the format of the memo, and ponder the logic of Ramey having in his possession a document he, as Rudiak argued, has sent, which says "...the wreck you forwarded..." yet is supposedly addressed to the Headquarters of the Army Air Force in Washington, not the Roswell Army Air Field.
In 2002, the Sci-Fi Channel sponsored an excavation at the Brazel site in the hopes of uncovering any missed debris that the military failed to collect. Although these results have so far turned out to be negative, the University of New Mexico archaeological team did verify recent soil disruption at the exact location that some witnesses said they saw a long, linear impact groove. Gov. Bill Richardson of New Mexico, who headed the United States Department of Energy under President Clinton, apparently found the results provocative. In 2004, he wrote in a foreword to "The Roswell Dig Diaries", that "the mystery surrounding this crash has never been adequately explained—not by independent investigators, and not by the U.S. government."
On October 26, 2007, Richardson (at the time a candidate for the Democratic Party nomination for U.S. President) elaborated when he was asked about releasing government files on Roswell. Richardson responded that when he was a Congressman, he attempted to get information on behalf of his New Mexico constituents, but was told by both the Department of Defense and Los Alamos Labs that the information was classified. "That ticked me off," he said "The government doesn't tell the truth as much as it should on a lot of issues." He promised to work on opening the files if he were elected as President.
In October 2002 before airing its Roswell documentary, the Sci-Fi Channel also hosted a Washington UFO news conference. John Podesta, President Clinton's chief of staff, appeared as a member of the public relations firm hired by Sci-Fi to help get the government to open up documents on the subject. Podesta stated, "It is time for the government to declassify records that are more than 25 years old and to provide scientists with data that will assist in determining the true nature of the phenomena."
In February 2005, the ABC TV network aired a UFO special hosted by news anchor Peter Jennings. Jennings lambasted the Roswell case as a "myth ... without a shred of evidence." ABC endorsed the Air Force's explanation that the incident resulted solely from the crash of a Project Mogul balloon.
"Top Secret/Majic" (2005 edition).
Stanton T. Friedman continues to defend his view that the Majestic 12 documents, which describe a secret government agency hiding information on recovered aliens, are authentic. In an afterword dated April 2005 to a new edition of his book "Top Secret/Majic" (first published in 1996), he responds to more recent questions on their validity and concludes "I am still convinced Roswell really happened, that the Eisenhower Briefing Document [i.e., Majestic 12 ... others are the most important classified documents ever leaked to the public." 
"Witness to Roswell" (2007).
In June 2007, Donald Schmitt and his investigation partner Tom Carey published their first book together, "Witness to Roswell". In this book, they claim a "continuously growing roster of more than 600 people directly or indirectly associated with the events at Roswell who support the first account - that initial claim of the flying saucer recovery." New accounts of aliens or alien recoveries were described, including from Walter Haut who wrote the initial press release in 1947.
A new date was suggested for a crash of a mysterious object—the evening of Thursday, July 3, 1947. Also, unlike previous accounts, Brazel took debris to Corona, where he showed fragments to local residents in the local bar, hardware store and elsewhere, and to Capitan to the south, while portions of the object ended up at a 4 July rodeo. Numerous people are described as visiting the debris field and taking souvenirs before Brazel finally went to Roswell to report the find on July 6. Once the military was alerted to the debris, extensive efforts were undertaken to retrieve those souvenirs: "Ranch houses were and ransacked. The wooden floors of livestock sheds were pried loose plank by plank and underground cold storage fruit cellars were emptied of all their contents."
The subsequent events are related as per the sequence in previous books, except for a second recovery site of an alien body at the Foster ranch. This recovery near the debris field is the same site mentioned in 1991's "UFO Crash at Roswell". The authors suggest that Brazel discovered the second site some days after finding the debris field, and this prompted him to travel to Roswell and report his find to the authorities.
Neither Barnett nor the archaeologists are present at this body site. While noting the earlier "major problems" with Barnett's account, which caused Schmitt and previous partner Randle to omit Barnett's claim in 1994's "The Truth about the UFO Crash at Roswell", the new book further notes another site mentioned in the 1994 publication. This site closer to Roswell "turned out to be bogus, as it was based upon the testimony of a single, alleged eyewitness Kaufmann who himself was later discovered to have been a purveyor of false information." Jim Ragsdale, whose alien account opened that book and who was claimed to have been present along with some archaeologists, is not mentioned in the new book.
The book includes claims that Major Marcel saw alien bodies, a claim not present in the previous books mentioned. Two witnesses are cited who say Marcel briefly mentioned seeing bodies, one a relative and another a tech sergeant who worked with Marcel's intelligence team.
Much additional new testimony is presented to support notions that alien bodies were found at the Foster ranch and at another main crash site along with a craft, then processed at the base in a hangar and at the hospital, and finally flown out in containers, all under very tight security. The book suggests Brazel found "two or three alien bodies" about two miles east of the debris field and describes the rest of a stricken alien craft along with the remainder of the crew remaining airborne for some 30 more miles before crashing at another site about 40 miles north/northwest of Roswell (but not the same site described by Kaufmann). The authors claim to have located this final crash site in 2005 where "an additional two or three dead aliens and one live one were discovered by civilian archaeologists," but offer no more information about the new site.
Walter Haut, as the Roswell Army Air Field public affairs officer, had drafted the initial press release that went out over the news wires on the afternoon of July 8, 1947, announcing a "flying disc". This was the only direct involvement Haut had previously described in public statements and signed affidavits. The book presents a new affidavit that Haut signed in 2002 in which he claims much greater personal knowledge and involvement, including seeing alien corpses and craft, and involvement in a cover-up. Haut died in 2005.
Another new first-hand account from MP Elias Benjamin describes how he guarded aliens on gurneys taken to the Roswell base hospital from the same hangar. Similarly, family members of Miriam Bush, secretary to the chief medical officer at Roswell base, told of having been led into an examination room where alien corpses were laid out on gurneys. In both accounts, one of the aliens was said to be still alive. The book also recounted earlier testimony of the Anaya family about picking up New Mexico Lt. Governor Joseph Montoya at the base, and a badly shaken Montoya relating that he saw four alien bodies at the base hangar, one of them alive. Benjamin's and Bush's accounts, as do a few lesser ones, again place aliens at the Roswell base hospital, as had the Glenn Dennis story from almost 20 years before. The book notes that Dennis had been found to have told lies, and therefore is a supplier of unreliable testimony, but had nevertheless told others of incidents at the Roswell base long before it became associated with aliens in the late 1970s.
Walter Haut controversy.
The publishing of the Walter Haut affidavit in "Witness to Roswell", wherein Haut described a cover-up and seeing alien corpses, ignited a controversy in UFO circles. While many embraced his accounts as confirmation of the presence of aliens from a person who was known to have been on the base in 1947, others raised questions about the credibility of the accounts.
UFO researcher Dennis G. Balthaser, who along with fellow researcher Wendy Connors interviewed Haut on-camera in 2000, doubted that the same man he interviewed could have written the affidavit he signed. "2000 video shows a man that couldn't remember where he took basic training, names, dates, etc., while the 2002 affidavit is very detailed and precise with information Haut couldn't accurately remember 2 years after he was video taped." "Witness to Roswell" co-author Donald R. Schmitt, he notes, admitted that the affidavit was not written by Haut, but prepared for him to sign, based on statements Haut had made privately to Schmitt and co-author Tom Carey over a period of years. And further, notes Balthaser, neither he nor Carey were there when Haut signed the affidavit and the witness' name has not been revealed, casting doubt on the circumstances of the signing.
He had further questions about what he saw as problems with the 2002 account. If the cover-up was decided at a meeting at Roswell, he asked, "why was it necessary for Major Marcel to fly debris from Roswell to General Ramey’s office in Ft Worth, since they had all handled the debris in the meeting and apparently set up the cover-up operation?" He also wondered which Haut statements were true: a 1993 affidavit he signed, the 2000 video interview, or the 2002 affidavit.
Bill Birnes, writing for UFO Magazine, summarizes that whatever disagreements there are about the 2000 video and the 2002 affidavit, "I think Walter Haut's 2002 affidavit really says it all and agrees, on its material facts, with Walter's 2000 interview with Dennis Balthaser and Wendy Connors. Dennis said he agrees with me, too, on this point."
A comparison of the affidavit and interview shows that in both Haut said he saw a craft and at least one body in a base hangar and also attended a Roswell staff meeting where General Ramey was present and where Ramey put a cover-up into place.
Birnes also says that Carey told that while Haut may not have written the affidavit, "his statements were typed, shown to him for his review and agreement, and then affirmed by him in the presence of a witness... The fact that a notary was present and sealed the document should end any doubt as to the reality of its existence."
Julie Shuster, Haut's daughter and Director of the International UFO Museum in Roswell, said that Schmitt had written the affidavit based on years of conversations he and Carey had had with him. Writing in the September 2007 MUFON newsletter, she said she and Haut reviewed the document, that "he did not want to make any changes," and in the presence of two witnesses, a notary public from the museum and a visitor, both unidentified, he signed the affidavit.
UFO FBI document release, 2011.
In April 2011, the FBI posted a document from 1950 on their website written by agent Guy Hottel which discussed a report forwarded by an investigator from the Air Force of three alien craft and their occupants having been recovered in New Mexico. The memo stated that "three so-called flying saucers" were recovered, each circular in shape with raised centers, each about 50 feet in diameter. Three occupants of "human shape," each about three feet tall, were found in each craft, and all were dressed "in metallic cloth of a very fine texture." The memo said that reports were "high-powered radar" had affected the alien crafts' control systems, causing them to crash. No date was mentioned, though the memo was date-stamped March 22, 1950, and no location more specific than "New Mexico" was mentioned. The memo stated that "no further evaluation was attempted" by the person who supplied the information.
Numerous sources connected the memo to the Roswell UFO incident of 1947.
Other sources said the memo had been in the public domain for years and was revealed as a hoax as far back as 1952 in an article in True magazine. They said the hoax was perpetrated by several men who were peddling a device purported to be able to locate gold, oil, gas or anything their victims sought, based on supposed alien technology. The two men, Silas Newton and Leo A. Gebauer, were convicted of fraud in 1953.
"Area 51" (2011).
The book "" by Annie Jacobsen, based on interviews with scientists and engineers who worked in Area 51, dismisses the alien story. Instead, it suggests that Josef Mengele was recruited by the Soviet leader Joseph Stalin to produce "grotesque, child-size aviators" to be remotely piloted and landed in America to cause hysteria in the likeness of Orson Welles' 1938 radio drama "War of the Worlds", but that the aircraft crashed and the incident was hushed up by the Americans.
Jacobsen writes that the bodies found at the crash site were children. Grotesquely but similarly deformed, aged around 12, each under five feet tall, with large heads and abnormally shaped oversize eyes. They were neither aliens nor consenting airmen, but human guinea pigs. The book was sharply criticized for extensive errors in an essay by two scientists at the Federation of American Scientists.
Cultural influence.
The Roswell incident has become a popular subject of many science fiction movies, television series, video games, and books.
Film.
Kevin D. Randle and Donald R. Schmitt's 1991 nonfiction book "UFO Crash at Roswell" inspired the 1994 American television film "Roswell", which starred Martin Sheen and Kyle MacLachlan. The film depicts Major Jesse Marcel trying to discover the truth about strange debris found on a local rancher's field in Roswell in July 1947. The film received a Golden Globe Award nomination for Best Mini-Series or Motion Picture Made for Television, but did not win.
The 1996 science fiction film Independence Day featured a top secret underground facility at Area 51, which housed a recovered spacecraft and three alien bodies that had been stored there since the Roswell incident.
The 2008 science fiction film Indiana Jones and the Kingdom of the Crystal Skull begin in "Hanger 51" (an allusion to Area 51 and Hangar 18 within the base,) and had Dr. Jones lead Soviet agents to a mummified Alien body from the Roswell Site, contained in a chest labeled "Roswell, New Mexico. July, 1947", Jones stating that he was one of twenty-one experts taken in secret to the original Roswell crash to examine the unidentified body.
Literature.
Several novels have been written about the Roswell incident, including Whitley Strieber's "Majestic" (1989), Kevin D. Randle's "Operation Roswell" (2004), and Sonny Whitelaw's "" (2007), "The True Meaning of Smekday" by Adam Rex and "Gotcha Gas: Debacle Near Roswell" (2011), an historical parody by Banak and Weimer.
Television.
An American television series, "Roswell High", later renamed "Roswell", aired from 1999 to 2002, originally on The WB Television Network and later on UPN. Based on Melinda Metz's "Roswell High" children's book series, the program followed the lives of four extraterrestrials who had survived the Roswell crash and assumed the form of human teenagers.
An American animation series, "Futurama", has an episode called "Roswell That Ends Well". The episode contains jokes implying that Zoidberg was the alien found in Roswell on the famous date.
According to the episode "The Best Christmas Story Never Told" of the American television series "American Dad!", the extraterrestrial character Roger claims he has been on the planet for sixty years (accurate, at the time the episode aired), originally crashing "in Roswell in '47". 
The "" episode "" reveals that this incident was the unintentional crash of a Ferengi vessel from the 24th century, owned by main character Quark who was accompanied by his brother Rom, nephew Nog, and nemesis Odo.
The 1996-97 NBC television series "Dark Skies" featured an interpretation of the Roswell incident as the starting point of the super-secret government agency Majestic 12 which was involved in a covert war between humans and an alien conspiracy. In "Dark Skies", President Harry Truman was present at the Roswell site in 1947, when an alien representative demanded humanity's unconditional surrender. A fictional version of Jesse
Marcel, played by actor Richard Gilliland, appeared in several episodes of the series.
The 1998 - 2001 UPN television series "Seven Days" featured a top-secret government time travel project based on alien technology recovered from the Roswell crash site. One episode of the series featured an alien survivor of the UFO crash.
Comics, series and animation.
The comic book series "The Invisibles" (1994–2000), by Grant Morrison, made extensive use of the Roswell incident in its second volume. A humorous Bongo Comics series, called "Roswell, Little Green Man", ran from 1996 to 1999 and followed the misadventures of an extraterrestrial who survived from the craft. The graphic novel "Roswell, Texas" features an alternate history in which the site of the UFO crash was part of the still-independent republic of Texas.
In the anime, webcomic and manga "", the personification of America has an alien friend named Tony, who began living with him after the Roswell incident. In the 2007 American comic book "Atarian Conquest", an alien named Irvyll, rescued from Area 51 by his home race, claims to be the descendant of the aliens who "crashed in a nearby Eartian desert in the mid 1900's".
Music.
The 2004 album, The Crash of '47 from hard rock band Atomship is a direct reference to the Roswell incident.
The American band Foo Fighters takes its name from an old term for UFOs, specific to "that trailed the wings of fighter planes, and has named its record label Roswell Records. The band has performed concerts on the site of the Roswell Air Force Base and at the site of the crash. Foo Fighters frontman Dave Grohl is known for having an interest in supernatural phenomena.
Singer/songwriter John Stewart included a song called "Mac Brasel's (sic) Farm" on his 1997 album "Rough Sketches From Rt. 66."
Swedish Death Metal-Band Hypocrisy wrote a song called "Roswell 47", released on their 1996 album "Abducted".
Toys.
Two plastic kits of the Roswell ship were made by Testors, following the forensic reconstructions of Bill McDonald. One shows the crash site, and the other just the intact ship.

Russians
The Russian people (, "russkiye") are a predominantly East Slavic ethno-linguistic group native to Russia, with some significant Germanic and Finno-Ugric ancestry speaking the Russian language and primarily living in Russia and neighboring countries.
According to the 2010 census, ethnic Russians make up about 81% of the population of Russia.
Terminology.
There are two Russian words which are commonly translated into English as "Russians": "русские" ("russkiye"), which means "ethnic Russians" and "россияне" ("rossiyane"), which means "citizens of Russia". The first word refers to all ethnic Russians, indifferently of what country they live in (Russia, Ukraine, Latvia etc.), and does not include members of Russia's ethnic minorities. The second word refers to all people holding citizenship of Russia, indifferently of their ethnicity, and does not include ethnic Russians living outside of Russia. English translations do not always distinguish these two words.
Origins.
The modern Russian is formed from two groups, Northern and Southern, which were made up of Kriviches, Ilmen Slavs, Radimichs, Vyatiches and Severians East Slavic tribes. Genetic studies show that modern Russians do not differ significantly from Poles or Slovenians or Ukrainians. Some ethnographers, like Zelenin, affirm that Russians are more similar to Belarusians and Ukrainians than southern Russians to northern Russians. Russians in northern European Russia share moderate genetic similarities with Uralic peoples, who lived in modern north central European Russia and were partly assimilated by the Slavs as the Slavs migrated northeastwards. Among those peoples were Merya and Muromian.
Outside archaeological remains, little is known about the predecessors to Russians in general prior to 859 AD when the Primary Chronicle starts. It is thought that by 600 AD, the Slavs had split linguistically into southern, western, and eastern branches. The eastern branch was settled between the Southern Bug and the Dnieper Rivers in what is now Ukraine; from the 1st century AD through almost the millennium, they spread peacefully northward to the Baltic region, assimilating indigents and forming the Dregovich, Radimich and Vyatich Slavic tribes on the Baltic substratum, therefore having language features such as vowel reduction. Later, both Belarusians and South Russians formed themselves on this ethnic linguistic ground.
Since the 6th century, another group of Slavs moved from Pomerania to northeast of the Baltic Sea, where they encountered the Varangians of the Rus' Khaganate and established the important regional center of Novgorod. This is possibly why Russians are known in Finnic languages as Venedes, a name derived for West Slavs. The same Slavic ethnic population also settled the present-day Tver Oblast and the region of Beloozero. With the Uralic substratum, they formed Kriviches and Ilmen Slavs.
Genetics.
Russians show the characteristic R1a genes of paternal descent from a single male at 33.4% in North Russia to 49% in rest of Russia. Such large frequencies of R1a have been found only in Eastern Europe (Sorbs, Poles and Ukrainians; at about 50 to 65%), Central Asia and South Asia.
The percentages of Y-chromosome markers vary in ethnic Russian populations, and in different studies.
Haplogroup R1a (Y-DNA) – 19.8% to 62.7%, with an average of 46.7%
Haplogroup I (Y-DNA) – 0% to 26.8%, with an average of 17.6% (All regions), and 23.5% (Central and South Russia)
Haplogroup N (Y-DNA) – 5.4% to 53.7%, with averages of 21.6% (All regions), and 10% (Central and South Russia)
Haplogroup R1b (Y-DNA) – 0% to 14%, with an average of 5.8%
Emergence of Russian ethnicity.
According to some modern ethnologists, ethnic Russians originated from the earlier Rus' people and gradually evolved into a separate ethnicity from the western Rus peoples, who became known as the modern-day Belarusians and Ukrainians. Early ancestors of the Russians were East Slavic tribes migrating to the East European Plain in the early Middle Ages. Most prominent Slavic tribes in the area of what is now European Russia included Vyatichs, Krivichs, Radimichs, Severians and Ilmen Slavs. By the 11th century, East Slavs assimilated the Uralic tribes Merya and Muroma, and the Baltic tribe Eastern Galindae that inhabited the same area (now Central Russia).
Ethnic Russians were referred to as Great Russians (as opposed to the ethnonyms White Russian and Little Russian) and began to be recognized as a distinct ethnic group in the 15th century. At that time, during the consolidation of the Russian Tsardom as a regional power, they were referred to as Moscovites in the West. Between the 12th and 16th century, Russians known as Pomors migrated to northern Russia and settled the White Sea coasts. As a result of these migrations and Russian conquests, after the liberation from the Mongol Golden Horde domination during the 15th and 16th century, Russians settled the Volga, Urals and Northern Caucasus regions. Between the 17th and 19th century, migrants settled eastwards in the vast, sparsely inhabited areas of Siberia and the Russian Far East. The Cossack movement played a significant role in these territorial expansions and migrations.
Population.
Russians are the most numerous ethnic group in Europe and one of the largest in the world with a population of about 140 million people worldwide. Roughly 116 million ethnic Russians live in Russia and about 16 million more live in the neighboring countries. A significant number of Russians, around 4,6 million, live elsewhere in the world, mostly in the Americas and Western Europe, but also in other places of Eastern Europe, Asia and elsewhere.
Culture.
Russian culture started from that of East Slavs, who were largely polytheists, and had a specific way of life in the wooden areas of Eastern Europe. The Scandinavian Vikings, or "Varangians", also took part in the forming of Russian identity and state in the early Kievan Rus' period of the late 1st millennium AD. Rus' had accepted the Orthodox Christianity from the East Roman Empire in 988, and this largely defined the Russian culture of next millennium as the synthesis of Slavic and Byzantine cultures. After the fall of Constantinople in 1453, Russia remained the largest Orthodox nation in the world and claimed succession to the Byzantine legacy in the form of the Third Rome idea. At different points of its history, the country also was strongly influenced by the European Culture, and since Peter the Great reforms Russian culture largely developed in the context of the Western culture. For most of the 20th century, the Marxist ideology shaped the culture of the Soviet Union, where Russia, or Russian SFSR, was the largest and leading part.
Russian culture is extremely various and unique in many aspects. It has a rich history and can boast a long tradition of excellence in every aspect of arts, especially when it comes to literature and philosophy, classical music and ballet, architecture and painting, cinema and animation, which all had considerable influence on the world culture.
Russian literature is known for such notable writers as Aleksandr Pushkin, Leo Tolstoy, Fyodor Dostoyevsky, Anton Chekhov, Vladimir Mayakovsky, Boris Pasternak, Anna Akhmatova, Joseph Brodsky, Maxim Gorky, Vladimir Nabokov, Mikhail Sholokhov, Mikhail Bulgakov, Andrei Platonov, Aleksandr Solzhenitsyn, and Varlam Shalamov. Russians also gave the classical music world some very famous composers, including Piotr Ilyich Tchaikovsky and his contemporaries, the Mighty Handful, including Modest Mussorgsky and Nikolai Rimsky-Korsakov. In the 20th century Russian music was credited with such influential composers as Dmitri Shostakovich, Sergei Prokofiev, Sergei Rachmaninoff, Igor Stravinski, Georgy Sviridov, and Alfred Schnittke. Many more famous Russian people are associated with different aspects of culture.
Language.
Russian ( (·info), transliteration: "", ) is the most geographically widespread language of Eurasia and the most widely spoken of the Slavic languages. Russian belongs to the family of Indo-European languages and is one of three (or, according to some authorities, four) living members of the East Slavic languages, the others being Belarusian and Ukrainian.
Examples of Old East Slavonic are attested from the 10th century onwards, and while Russian preserves much of East Slavonic grammar and a Common Slavonic word base, modern Russian exhibits a large stock of borrowed international vocabulary for politics, science, and technology. Due to the status of the Soviet Union as a super power, Russian had great political importance in the 20th century, and is one of the official languages of the United Nations.
Russian has palatal secondary articulation of consonants, the so-called "soft" and "hard" sounds. This distinction is found in almost all consonant phonemes and is one of the most distinguishing features of the language. Another important aspect is the reduction of unstressed vowels, not entirely unlike a similar process present in most forms of English. Stress in Russian is generally quite unpredictable and can be placed on almost any syllable, one of the most difficult aspects for foreign language learners.
Religion.
Around 63% of the Russia's population identify themselves with Orthodox Christianity, most of whom belong to the Russian Orthodox Church, which played a vital role in the development of Russian national identity. In other countries Russian faithful usually belong to the local Orthodox congregations which either have a direct connection (like the Ukrainian Orthodox Church, autonomous from the Moscow Patriarchate) or historical origin (like the Orthodox Church in America or a Russian Orthodox Church Outside of Russia) with the Russian Orthodox Church.
Non-religious Russians may associate themselves with the Orthodox faith for cultural reasons. Some Russian people are Old Believers: a relatively small schismatic group of the Russian Orthodoxy that rejected the liturgical reforms introduced in the 17th century. Other schisms from Orthodoxy include Doukhobors which in the 18th century rejected secular government, the Russian Orthodox priests, icons, all church ritual, the Bible as the supreme source of divine revelation and the divinity of Jesus, and later emigrated into Canada. An even earlier sect were Molokans which formed in 1550 and rejected Czar's divine right to rule, icons, the Trinity as outlined by the Nicene Creed, Orthodox fasts, military service, and practices including water baptism.
Other world religions have negligible representation among ethnic Russians. The most prominent are Baptists with over 85,000 Russian adherents. Others are mostly Pentecostals, Evangelicals, Seventh-day Adventists, Lutherans and Jehovah's Witnesses.
Since the fall of the Soviet Union various new religious movements have sprung up and gathered a following among ethnic Russians. The most prominent of these are Rodnovery, the revival of the Slavic native religion also common to other Slavic nations, forms of autochthonous "Russian Vedism" and Hindu movements such as Krishnaism and the Hare Krishna. Another movement, very small in comparison to other new religions, is Vissarionism, a syncretic group with an Orthodox Christian background.
Russians outside of Russia.
Ethnic Russians historically migrated throughout the area of former Russian Empire and Soviet Union, sometimes encouraged to re-settle in borderlands by Tsarist and later Soviet government. On some occasions ethnic Russian communities, such as Lipovans who settled in the Danube delta or Doukhobors in Canada, emigrated as religious dissidents fleeing the central authority.
After the Russian Revolution and Russian Civil War starting in 1917, many Russians were forced to leave their homeland fleeing the Bolshevik regime, and millions became refugees. Many white émigrés were participants in the White movement, although the term is broadly applied to anyone who may have left the country due to the change in regime.
Today the largest ethnic Russian diasporas outside of Russia live in former Soviet states such as Ukraine (about 8 million), Kazakhstan (about 3.8 million), Belarus (about 785,000), Latvia (about 556,000) with the most Russian settlement out of the Baltic States which includes Lithuania and Estonia, Uzbekistan (about 650,000) and Kyrgyzstan (about 419,000).
Over a million Russian Jews emigrated to Israel during and after the Refusenik movements; some brought ethnic Russian relatives along with them. Out of more than one million Russian-speaking immigrants in Israel, about 300,000 are considered not Jewish according to the rabbinical commandments (but not all of them are ethnic Russians). There are also small Russian communities in the Balkans, Eastern and Central European nations such as Germany and Poland, as well Russians settled in China, Japan, South Korea, Latin America (i.e. Mexico, Brazil and Argentina) and Australia. These communities may identify themselves either as Russians or citizens of these countries, or both, to varying degrees.
People who had arrived in Latvia and Estonia during the Soviet era, including their descendants born in these countries, mostly Russians, became stateless after the dissolution of the Soviet Union and were provided only with an option to acquire naturalised citizenship. The language issue is still contentious, particularly in Latvia, where ethnic Russians have protested against plans to liquidate education in minority languages, including Russian. Since 1992, Estonia has naturalized some 137,000 residents of undefined citizenship, mainly ethnic Russians. 136,000, or 10 percent of the total population, remain without citizenship.
Both the European Union and the Council of Europe, as well as the Russian government, expressed their concern during the 1990s about minority rights in several countries, most notably Latvia and Estonia. In Moldova, the Transnistria region (where 30.4% of population is Russian) broke away from government control amid fears the country would soon reunite with Romania. In June 2006, Russian President Vladimir Putin announced the plan to introduce a national policy aiming at encouraging ethnic Russians to immigrate to Russia.
Significant numbers of Russians emigrated to Canada, Australia and the United States. Brighton Beach, Brooklyn and South Beach, Staten Island in New York City is an example of a large community of recent Russian and Jewish Russian immigrants. Other examples are Sunny Isles Beach, a northern suburb of Miami, and "Little Moscow" in Hollywood of the Los Angeles area.
At the same time, many ethnic Russians from former Soviet territories have emigrated to Russia itself since the 1990s. Many of them became refugees from a number of states of Central Asia and Caucasus (as well as from the separatist Chechen Republic), forced to flee during political unrest and hostilities towards Russians.
After the Russian Revolution in 1917, many Russians who were identified with the White army moved to China — most of them settling in Harbin and Shanghai. By the 1930s Harbin had 100,000 Russians. Many of these Russians had to move back to the Soviet Union after World War II. Today, a large group of people in northern China can still speak Russian as a second language.
Russians ("eluosizu") are one of the 56 ethnic groups officially recognized by the People's Republic of China (as "the Russ"); there are approximately 15,600 Russian Chinese living mostly in northern Xinjiang, and also in Inner Mongolia and Heilongjiang.
Notable achievements.
Various Russians have greatly contributed to the world of music, sports, science, technology and arts. Notable Russian scientists include Dmitri Mendeleev, Nikolay Bogolyubov, Andrei Kolmogorov, Ivan Pavlov, Nikolai Semyonov, Dmitri Ivanenko, Nikolai Lobachevsky, Alexander Lodygin, Alexander Popov (one of inventors of radio), Nikolai Zhukovsky, Alexander Prokhorov and Nikolay Basov (co-inventors of laser), Georgiy Gamov, Vladimir Zworykin, Lev Pontryagin, Sergei Sobolev, Pavel Yablochkov, Aleksandr Butlerov, Andrei Sakharov, Dmitry Ivanovsky, Sergey Korolyov and Mstislav Keldysh (creators of the Soviet space program), Aleksandr Lyapunov, Mikhail Dolivo-Dobrovolsky, Andrei Tupolev, Yuri Denisyuk (the first practicable method of holography), Mikhail Lomonosov, Vladimir Vernadsky, Pyotr Kapitsa, Igor Sikorsky, Ludvig Faddeev, Zhores Alferov, Konstantin Novoselov, Fyodor Shcherbatskoy, Nikolai Trubetzkoy etc.
The first man in space, Yuri Gagarin, was Russian, and the first artificial satellite to be put into outer space, Sputnik 1, was launched by the Soviet Union and was developed mainly by Sergey Korolyov who had a Russian father (his mother was Ukrainian).
Russian Literature representatives like Fyodor Dostoyevsky, Lev Tolstoy, Ivan Turgenev, Anton Chekhov, Alexander Pushkin, and many more, reached a high status in world literature. In the field of the novel, Tolstoy and Dostoyevsky, in particular, were important figures and have remained internationally renowned. Some scholars have described one or the other as the greatest novelist ever.
Russian composers who reached a high status in the world of music include Igor Stravinsky, Pyotr Ilyich Tchaikovsky, Dmitri Shostakovich, Nikolai Rimsky-Korsakov, Sergei Prokofiev, and Sergei Rachmaninoff.
Russian people played a crucial role in the victory over Nazi Germany in World War II. Russia's casualties in this war were the highest of all nations, and numbered more than 20 million dead (Russians composed 80% of the 26.6 million people lost by the USSR), which is about half of all World War II casualties and the vast majority of Allied casualties. According to the British historian Richard Overy, the Eastern Front included more combat than all the other European fronts combined. The Wehrmacht suffered 80% to 93% of all of its total World War II combat casualties on the Eastern Front.

Sanhedrin
The Sanhedrin (Hebrew: "sanhedrîn", , "synedrion", "sitting together," hence "assembly" or "council") was an assembly of seventy to seventy three people appointed in every city in the biblical Land of Israel. The Mishnah arrives at the number twenty-three based on an exegetical derivation: It must be possible for a "community" to vote for both conviction and exoneration (). The minimum size of a "community" is 10 (; i.e. the 10 spies). One more is required to achieve a majority (11–10), but a simple majority cannot convict (), and so an additional judge is required (12–10). Finally, a court should not have an even number of judges to prevent deadlocks; thus 23. This court delt with only religious matters. The Great Sanhedrin was made up of a Chief/Prince/Leader called "Nasi" (at some times this position may have been held by the "Kohen Gadol" or the High Priest), a vice chief justice ("Av Beit Din"), and sixty-nine general members. In the Second Temple period, the Great Sanhedrin met in the Hall of Hewn Stones in the Temple in Jerusalem. The court convened every day except festivals and Shabbos. In the late 3rd century, to avoid persecution, its authoritative decisions were issued under the name of "Beis HaMidrash".
The penultimate binding decision of the Sanhedrin was in 358, when the Hebrew Calendar was adopted. The "Sanhedrin" was dissolved after continued persecution by the Roman Empire. Over the centuries, there have been attempts to revive the institution, such as the Grand Sanhedrin convened by Napoleon Bonaparte and modern attempts in Israel.
The "Sanhedrin" is mentioned in the Gospels in relation to the Sanhedrin Trial of Jesus.
Early Sanhedrin.
The Hasmonean court in the Land of Israel, presided over by Alexander Jannaeus, king of Judea until 76 BC, followed by his wife, was called "Synhedrion" or "Sanhedrin." The exact nature of this early Sanhedrin is not clear. It may have been a body of sages and/or priests, or a political, legislative and judicial institution. Only after the destruction of the Second Temple was the Sanhedrin made up only of sages.
Great and Lesser Sanhedrin.
The Talmud (tractate Sanhedrin) identifies two classes of rabbinical courts called Sanhedrin, a Great Sanhedrin (בית דין הגדול) and a Lesser Sanhedrin (בית דין הקטן). Each city could have its own lesser Sanhedrin of 23 judges, but there could be only one Great Sanhedrin of 71, which among other roles acted as the Supreme Court, taking appeals from cases decided by lesser courts. The numbers of judges were predicated on eliminating the possibility of a tie and the last to cast their vote was the head of the court.
Function and procedures.
The Sanhedrin as a body claimed powers that lesser Jewish courts did not have. As such, they were the only ones who could try the king, extend the boundaries of the Temple and Jerusalem, and were the ones to whom all questions of law were finally put. Before 191 BC the High Priest acted as the "ex officio" head of the Sanhedrin, but in 191 BC, when the Sanhedrin lost confidence in the High Priest, the office of Nasi was created. After the time of Hillel the Elder (late 1st century BC and early 1st century AD), the Nasi was almost invariably a descendant of Hillel. The second highest-ranking member of the Sanhedrin was called the Av Beit Din, or "Head of the Court" (literally, Beit Din = "house of law"), who presided over the Sanhedrin when it sat as a criminal court.
The Sanhedrin met in a building known as the Hall of Hewn Stones ("Lishkat Ha-Gazith"), which has been placed by the Talmud and many scholars as built into the north wall of the Temple Mount, half inside the sanctuary and half outside, with doors providing access both to the Temple and to the outside. The name presumably arises to distinguish it from the buildings in the Temple complex used for ritual purposes, which had to be constructed of stones unhewn by any iron implements.
In some cases, it was only necessary for a 23-member panel (functioning as a Lesser Sanhedrin) to convene. In general, the full panel of 71 judges was only convened on matters of national significance (e.g., a declaration of war) or in the event that the 23-member panel could not reach a conclusive verdict.
By the end of the Second Temple period, the Sanhedrin reached its pinnacle of importance, legislating all aspects of Jewish religious and political life within the parameters laid down by Biblical and Rabbinic tradition.
After the destruction of the Second Temple in 70, the Sanhedrin was re-established in Yavneh with reduced authority. The imperial Roman government and legislation recognized it as the Palestinian Patriarchate, the ultimate authority in Jewish religious matters. The seat of the Patriarchate moved to Usha under the presidency of Gamaliel II in 80 CE. In 116 it moved back to Yavneh, and then again back to Usha. It moved in 140 to Shefaram under the presidency of Shimon ben Gamliel II, and to Beit Shearim and Sephoris in 163, under the presidency of Judah I. Finally, it moved to Tiberias in 193, under the presidency of Gamaliel III (193–230) ben Judah haNasi, where it became more of a consistory, but still retained, under the presidency of Judah II (230–270), the power of excommunication.
During the presidency of Gamaliel IV (270–290), due to Roman persecution, it dropped the name Sanhedrin; and its authoritative decisions were subsequently issued under the name of "Beth HaMidrash".
The failure to rebuild the Temple has been ascribed to the Galilee earthquake of 363, and to the Jews' ambivalence about the project. Sabotage is a possibility, as is an accidental fire. Divine intervention was the common view among Christian historians of the time. Julian's support of Jews, coming after the hostility of many earlier Emperors, meant that Jews called him "Julian the Hellene".
As a reaction to Julian's pro-Jewish stance, Theodosius I forbade the Sanhedrin to assemble and declared ordination illegal. Capital punishment was prescribed for any Rabbi who received ordination and complete destruction of the town where the ordination occurred.
However, since the Hebrew calendar was based on witnesses' testimony, that had become far too dangerous to collect, Hillel II recommended change to a mathematically based calendar that was adopted at a clandestine, and maybe final, meeting in 358. This marked the last universal decision made by that body.
Gamaliel VI (400–425) was the Sanhedrin's last president. With his death in 425, executed by Theodosius II for erecting new synagogues contrary to the imperial decree, the title Nasi, the last remains of the ancient Sanhedrin, became illegal. An imperial decree of 426 diverted the patriarchs' tax ("post excessum patriarchorum") into the imperial treasury
Archaeological findings.
In 2004, excavations in Tiberias conducted by the Israel Antiquities Authority uncovered a structure dating to the 3rd century CE that may have been the seat of the Sanhedrin when it convened in that city. At the time it was called Beit Hava'ad.
Revival attempts.
The Sanhedrin is traditionally viewed as the last institution that commanded universal Jewish authority among the Jewish people in the long chain of tradition from Moses until the present day. Since its dissolution in 358 by imperial decree, there have been several attempts to re-establish this body either as a self-governing body, or as a puppet of a sovereign government.
There are records of what may have been of attempts to reform the Sanhedrin in Arabia, in Jerusalem under the Caliph 'Umar, and in Babylon (Iraq), but none of these attempts were given any attention by Rabbinic authorities and little information is available about them.
Napoleon Bonaparte's "Grand Sanhedrin".
The "Grand Sanhedrin" was a Jewish high court convened by Napoleon I to give legal sanction to the principles expressed by the Assembly of Notables in answer to the twelve questions submitted to it by the government (see Jew. Encyc. v. 468, s.v. France).
On October 6, 1806, the Assembly of Notables issued a proclamation to all the Jewish communities of Europe, inviting them to send delegates to the Sanhedrin, to convene on October 20. This proclamation, written in Hebrew, French, German, and Italian, speaks in extravagant terms of the importance of this revived institution and of the greatness of its imperial protector. While the action of Napoleon aroused in many Jews of Germany the hope that, influenced by it, their governments also would grant them the rights of citizenship, others looked upon it as a political contrivance. When in the war against Prussia (1806–7) the emperor invaded Poland and the Jews rendered great services to his army, he remarked, laughing, "The sanhedrin is at least useful to me." David Friedländer and his friends in Berlin described it as a spectacle that Napoleon offered to the Parisians.
Modern attempts in Israel.
Since the dissolution of the Sanhedrin in 358, there has been no universally recognized authority within Jewish law. Maimonides (1135–1204) was one of the greatest scholars of the Middle Ages, and is arguably one of the most widely accepted scholars among the Jewish people since the closing of the Talmud in 500. Influenced by the rationalist school of thought and generally showing a preference for a natural (as opposed to miraculous) redemption for the Jewish people, Maimonides proposed a rationalist solution for achieving the goal of re-establishing the highest court in Jewish tradition and reinvesting it with the same authority it had in former years. There have been several attempts to implement Maimonides' recommendations, the latest being in modern times.
There have been rabbinical attempts to renew Semicha and re-establish a Sanhedrin by Rabbi Jacob Berab in 1538, Rabbi Yisroel Shklover in 1830, Rabbi Aharon Mendel haCohen in 1901, Rabbi Zvi Kovsker in 1940 and Rabbi Yehuda Leib Maimon in 1949.
In October 2004 (Tishrei 5765), a group of rabbis representing varied Orthodox communities in Israel undertook a ceremony in Tiberias, where the original Sanhedrin was disbanded, which is claimed to re-establish the body according to the proposal of Maimonides and the Jewish legal rulings of Rabbi Yosef Karo. The controversial attempt has been subject to debate within different Jewish communities.

Scientology
Scientology is a body of beliefs and related practices created by L. Ron Hubbard (1911–1986), starting in 1952, as a successor to his earlier self-help system, Dianetics. Hubbard characterized Scientology as a religion, and in 1953 incorporated the Church of Scientology in Camden, New Jersey.
Scientology teaches that people are immortal beings who have forgotten their true nature. Its method of spiritual rehabilitation is a type of counselling known as "auditing", in which practitioners aim to consciously re-experience painful or traumatic events in their past in order to free themselves of their limiting effects. Study materials and auditing courses are made available to members in return for specified donations. Scientology is legally recognized as a tax-exempt religion in the United States, Italy, South Africa, Australia, Sweden, New Zealand, Portugal and Spain; the Church of Scientology emphasizes this as proof that it is a bona fide religion. In other countries, notably Canada, France, Germany, and the United Kingdom, Scientology does not have comparable religious status.
A large number of organizations overseeing the application of Scientology have been established, the most notable of these being the Church of Scientology. Scientology sponsors a variety of social-service programs. These include the Narconon anti-drug program, the Criminon prison rehabilitation program, the Study Tech education methodology, the Volunteer Ministers, the World Institute of Scientology Enterprises, and a set of moral guidelines expressed in a booklet called "The Way to Happiness".
The Church of Scientology is one of the most controversial new religious movements to have arisen in the 20th century. It has often been described as a cult that financially defrauds and abuses its members, charging exorbitant fees for its spiritual services. In response, Scientologists have argued that theirs is a genuine religious movement that has been misrepresented, maligned and persecuted. The Church of Scientology has consistently used litigation against its critics, and its aggressiveness in pursuing its foes has been condemned as harassment."Oral Questions to the Minister of State for the Home Office, December 17, 1996" "Hansard", vol. 760, cols. 1392–1394 quote: "Baroness Sharples: Is my noble friend further aware that a number of those who have left the cult have been both threatened and harassed and many have been made bankrupt by the church?" Further controversy has focused on Scientology's belief that souls ("thetans") reincarnate and have lived on other planets before living on Earth, and that some of the related teachings are not revealed to practitioners until they have paid thousands of dollars to the Church of Scientology. Another controversial belief held by Scientologists is that the practice of psychiatry is destructive and abusive and must be abolished.
Etymology and earlier usage.
The word "Scientology" is a pairing of the Latin word "scientia" ("knowledge", "skill"), which comes from the verb "scīre" ("to know"), and the Greek λόγος "lógos" ("word" or "account ").
"Scientology", as coined by L. Ron Hubbard, comes from the Latin scio, which means "knowing, in the fullest meaning of the word" and the Greek word logos, which means "study of". Scientology is further defined as "the study and handling of the spirit in relationship to itself, universes, and other life." 
In 1901, Allen Upward coined "Scientology" "as a disparaging term, to indicate a blind, unthinking acceptance of scientific doctrine" according to the Internet Sacred Text Archive as quoted in the preface to Forgotten Books' recent edition of Upward's book, "The New Word: On the meaning of the word Idealist". Continuing to quote, the publisher writes "I'm not aware of any evidence that Hubbard knew of this fairly obscure book."
In 1934, philosopher Anastasius Nordenholz published a book that used the term to mean "science of science". It is also uncertain whether Hubbard was aware of this prior usage of the word.
History.
Dianetics.
Scientology was developed by L. Ron Hubbard as a successor to his earlier self-help system, Dianetics. Dianetics uses a counseling technique known as "auditing", developed by Hubbard to enable conscious recall of traumatic events in an individual's past. It was originally intended to be a new psychotherapy and was not expected to become the foundation for a new religion. Hubbard variously defined Dianetics as a spiritual healing technology and an organized science of thought. The stated intent of Dianetics is to free individuals of the influence of past traumas by systematic exposure and removal of the "engrams" these events have left behind, in a process called "clearing".
Hubbard, an American writer of pulp fiction, especially science fiction, first published his ideas on the human mind in the "Explorers Club Journal" and the May 1950 issue of "Astounding Science Fiction" magazine. The publication of Dianetics in May 1950 is considered by Scientologists a seminal event of the century. Two of Hubbard's key supporters at the time were John W. Campbell Jr., the editor of "Astounding Science Fiction", and Dr. Joseph A. Winter. Winter, hoping to have Dianetics accepted in the medical community, submitted papers outlining the principles and methodology of Dianetic therapy to the "Journal of the American Medical Association" and the "American Journal of Psychiatry" in 1949, but these were rejected.
May 1950 saw the publication of Hubbard's "". His book entered the "New York Times" best-seller list on June 18 and stayed there until December 24 of that year. Dianetics appealed to a broad range of people who used instructions from the book and applied the method to each other, becoming practitioners themselves. Hubbard found himself the leader of a growing Dianetics movement. He became a popular lecturer and established the Hubbard Dianetic Research Foundation in Elizabeth, New Jersey, where he trained his first Dianetics counselors or "auditors".
Dianetics soon met with criticism. Morris Fishbein, the editor of the "Journal of the American Medical Association" and well-known at the time as a debunker of quack medicine, dismissed Hubbard's book. An article in Newsweek stated that "the dianetics concept is unscientific and unworthy of discussion or review". In January 1951, the New Jersey Board of Medical Examiners instituted proceedings against the Hubbard Dianetic Research Foundation for teaching medicine without a license, which eventually led to that foundation's bankruptcy.
Some practitioners of Dianetics reported experiences which they believed had occurred in past lives, or previous incarnations. In early 1951, reincarnation became a subject of intense debate within Dianetics. Campbell and Winter, who was still hopeful of winning support for Dianetics from the medical community, championed a resolution to ban the topic. But Hubbard decided to take the reports of past life events seriously and postulated the existence of the "thetan", a concept similar to the soul. This was an important factor in the transition from secular Dianetics to the religion of Scientology.
Also in 1951, Hubbard introduced the "electropsychometer" (E-meter for short), a kind of galvanometer, as an auditing aid. Based on a design by Hubbard, the device is held by Scientologists to be a useful tool in detecting changes in a person's state of mind.
Publishers Weekly gave a plaque posthumously to L. Ron Hubbard commemorating the appearance of Dianetics on its bestseller list for one hundred consecutive weeks. One scholar has called Dianetics the bestselling non-Christian religious book of the century.
The Church of Scientology.
In 1952, Hubbard built on the existing framework set forth in "Dianetics", and published a new set of teachings as "Scientology, a religious philosophy." In December 1953, Hubbard incorporated three churches – a "Church of American Science", a "Church of Scientology" and a "Church of Spiritual Engineering" – in Camden, New Jersey. On February 18, 1954, with Hubbard's blessing, some of his followers set up the first local Church of Scientology, the Church of Scientology of California, adopting the "aims, purposes, principles and creed of the Church of American Science, as founded by L. Ron Hubbard." The movement spread quickly through the United States and to other English-speaking countries such as Britain, Ireland, South Africa and Australia. The second local Church of Scientology to be set up, after the one in California, was in Auckland, New Zealand. In 1955, Hubbard established the Founding Church of Scientology in Washington, D.C. In 1957, the Church of Scientology of California was granted tax-exempt status by the United States Internal Revenue Service (IRS), and so, for a time, were other local churches. In 1958 however, the IRS started a review of the appropriateness of this status. In 1959, Hubbard moved to England, remaining there until the mid-1960s.
The Church experienced further challenges. The United States Food and Drug Administration (FDA) began an investigation concerning the claims the Church of Scientology made in connection with its E-meters. On January 4, 1963, they raided offices of the Church of Scientology and seized hundreds of E-meters as illegal medical devices. The devices have since been required to carry a disclaimer saying that they are a purely religious artifact.
In the mid-sixties, the Church of Scientology was banned in several Australian states, starting with Victoria in 1965. The ban was based on the Anderson Report, which found that the auditing process involved "command" hypnosis, in which the hypnotist assumes "positive authoritative control" over the patient. On this point the report stated,  The Australian Church was forced to operate under the name of the "Church of the New Faith" as a result, the name and practice of Scientology having become illegal in the relevant states. Several years of court proceedings aimed at overturning the ban followed.
In the course of developing Scientology, Hubbard presented rapidly changing teachings that were often self-contradictory. For the inner cadre of Scientologists in that period, involvement depended not so much on belief in a particular doctrine but on unquestioning faith in Hubbard. In 1966, Hubbard stepped down as executive director of Scientology to devote himself to research and writing. The following year, he formed the Sea Organization or Sea Org, which was to develop into an elite group within Scientology. The Sea Org was based on three ships, the "Diana", the "Athena", and the "Apollo", which served as the flag ship. One month after the establishment of the Sea Org, Hubbard announced that he had made a breakthrough discovery, the result of which were the "OT III" materials purporting to provide a method for overcoming factors inhibiting spiritual progress. These materials were first disseminated on the ships, and then propagated by Sea Org members reassigned to staff Advanced Organizations on land.
In 1967, the IRS removed Scientology's tax-exempt status, asserting that its activities were commercial and operated for the benefit of Hubbard, rather than for charitable or religious purposes. The decision resulted in a process of litigation that would be settled in the Church's favour a quarter of a century later, the longest case of litigation in IRS history.
In 1979, as a result of FBI raids during Operation Snow White, eleven senior people in the church's Guardian's Office were convicted of obstructing justice, burglary of government offices, and theft of documents and government property. In 1981, Scientology took the German government to court for the first time.
On January 1, 1982, Scientology established the Religious Technology Center (RTC) to oversee and ensure the standard application of Scientology technology.
On November 11, 1982, the Free Zone was established by former top Scientologists in disagreement with RTC. The Free Zone Association was founded and registered under the laws of Germany, and believes that the Church of Scientology has departed from its original philosophy.
In 1983, in a unanimous decision, the High Court of Australia recognized Scientology as a religion in Australia, overturning restrictions that had limited activities of the church after the Anderson Report.
On January 24, 1986, L. Ron Hubbard died at his ranch near San Luis Obispo, California, and David Miscavige became the head of the organization.
Starting in 1991, persons connected with Scientology filed fifty lawsuits against the Cult Awareness Network (CAN), a group that had been critical of Scientology. Although many of the suits were dismissed, one of the suits filed against the Cult Awareness Network resulted in $2 million in losses for the network. Consequently, the organization was forced to go bankrupt. In 1996, Steven L. Hayes, a Scientologist, purchased the bankrupt Cult Awareness Network's logo and appurtenances. A new Cult Awareness Network was set up with Scientology backing, which operates as an information and networking center for non-traditional religions, referring callers to academics and other experts.
In a 1993 U.S. lawsuit brought by the Church of Scientology against Steven Fishman, a former member of the Church, Fishman made a court declaration which included several dozen pages of formerly secret esoterica detailing aspects of Scientologist cosmogony. As a result of the litigation, this material, normally strictly safeguarded and used only in Scientology's more advanced "OT levels", found its way onto the Internet. This resulted in a battle between the Church of Scientology and its online critics over the right to disclose this material, or safeguard its confidentiality. The Church of Scientology was forced to issue a press release acknowledging the existence of this cosmogony, rather than allow its critics "to distort and misuse this information for their own purposes." Even so, the material, notably the story of Xenu, has since been widely disseminated and used to caricature Scientology, despite the Church's vigorous program of copyright litigation.
Recognition as a religion.
[[File:ScientologyCenter1.jpg|thumb|upright|A Scientology Center
on Hollywood Boulevard in Hollywood, Los Angeles, California]]
In December 1993, the Church of Scientology experienced a major breakthrough in its ongoing legal battles when the IRS granted full tax exemption to all Scientology Churches, missions and organizations. Based on the IRS exemptions, the U.S. State Department formally criticized Germany for discriminating against Scientologists and began to note Scientologists' complaints of harassment in its annual human rights reports, as well as the annual International Religious Freedom Reports it has released from 1999 onwards.
In 1997, an open letter to then-German Chancellor Helmut Kohl, published as a newspaper advertisement in the "International Herald Tribune", drew parallels between the "organized oppression" of Scientologists in Germany, and the treatment of Jews in 1930s' Nazi Germany. The letter was signed by Dustin Hoffman, Goldie Hawn and a number of other Hollywood celebrities and executives. Commenting on the matter, a spokesman for the U.S. Department of State said that Scientologists were discriminated against in Germany, but condemned the comparisons to the Nazis' treatment of Jews as extremely inappropriate, as did a United Nations Special Rapporteur.
In 2000, the Italian Supreme Court ruled that Scientology is a religion for legal purposes. In recent years, religious recognition has also been obtained in other countries, including Sweden, Spain, Portugal, Slovenia, Croatia and Hungary, as well as Kyrgyzstan and the Republic of China (Taiwan). Other countries, notably Canada, France, Germany, Greece, Belgium and the United Kingdom, refuse to grant Scientology religious recognition.
Membership statistics.
In 2005, the Church of Scientology stated its worldwide membership to be eight million, although that number included people who took only the introductory course and did not continue on. In 2007 a Church official claimed 3.5 million members in the United States, but a 2001 survey conducted by the City University of New York found only 55,000 people in the United States who claimed to be Scientologists. Worldwide, some observers believe a reasonable estimate of Scientology's core practicing membership ranges between 100,000 and 200,000, mostly in the U.S., Europe, South Africa and Australia. In 2008, the American Religious Identification Survey found that the number of American Scientologists had dropped to 25,000. 
Scientologists tend to disparage general religious surveys on the grounds that many members maintaining cultural and social ties to other religious groups will, when asked their religion, answer with their traditional and more socially acceptable affiliation. The Church of Scientology claims to be the fastest growing religious movement on earth. On the other hand, religious scholar J. Gordon Melton has said that the church's estimates of its membership numbers are significantly exaggerated.
Beliefs and practices.
According to Scientology, its beliefs and practices are based on rigorous research, and its doctrines are accorded a significance equivalent to that of scientific laws. "Scientology works 100 percent of the time when it is properly applied to a person who sincerely desires to improve his life", the Church of Scientology says. Conversion is held to be of lesser significance than the practical application of Scientologist methods. Adherents are encouraged to validate the value of the methods they apply through their personal experience. Hubbard himself put it this way: "For a Scientologist, the final test of any knowledge he has gained is, 'did the data and the use of it in life actually improve conditions or didn't it?
Body and Spirit.
Scientology beliefs revolve around the "thetan", the individualized expression of the cosmic source, or life force, named after the Greek letter theta (θ). The thetan is the true identity of a person – an intrinsically good, omniscient, non-material core capable of unlimited creativity.
In the primordial past, thetans brought the material universe into being largely for their own pleasure. The universe has no independent reality, but derives its apparent reality from the fact that most thetans agree it exists. Thetans fell from grace when they began to identify with their creation, rather than their original state of spiritual purity. Eventually they lost their memory of their true nature, along with the associated spiritual and creative powers. As a result, thetans came to think of themselves as nothing but embodied beings.
Thetans are reborn time and time again in new bodies through a process called "assumption" which is analogous to reincarnation. Like Hinduism, Scientology posits a causal relationship between the experiences of earlier incarnations and one's present life, and with each rebirth, the effects of the "MEST" universe (MEST here stands for matter, energy, space, and time) on the thetan become stronger.
In simple terms, however, there are a number of basic concepts that underpin all beliefs and practices of the Church of Scientology: the reality of spirit; the nature of mind; and the path to salvation. Scientologists maintain that by understanding these principles, and by applying the techniques developed by L. Ron Hubbard, not only will the individual person find infinite and ultimate fulfillment, but the world will eventually be cleansed of all the prevents such fulfillment -- crime, drugs, prejudice and warfare. 
Emotions and the mind.
Scientology presents two major divisions of the mind. The "reactive mind" is thought to absorb all pain and emotional trauma, while the "analytical mind" is a rational mechanism which is responsible for consciousness. The reactive mind stores mental images which are not readily available to the analytical (conscious) mind; these are referred to as "engrams". Engrams are painful and debilitating; as they accumulate, people move further away from their true identity. To avoid this fate is Scientology's basic goal. Dianetic auditing is one way by which the Scientologist may progress toward the "Clear" state, winning gradual freedom from the reactive mind's engrams, and acquiring certainty of his or her reality as a thetan.
Scientology uses an emotional classification system called the "tone scale". The tone scale is a tool used in counseling; Scientologists maintain that knowing a person's place on the scale makes it easier to predict his or her actions and assists in bettering her or his condition.
Survival and ethics.
Scientology emphasizes the importance of survival, which it subdivides into eight classifications that are referred to as "dynamics". An individual's desire to survive is considered to be the first dynamic, while the second dynamic relates to procreation and family. The remaining dynamics encompass wider fields of action, involving groups, mankind, all life, the physical universe, the spirit, and the Infinity, often associated with the Supreme Being. The optimum solution to any problem is held to be the one that brings the greatest benefit to the greatest number of dynamics.
Scientology teaches that spiritual progress requires and enables the attainment of high ethical standards. In Scientology, rationality is stressed over morality. Actions are considered ethical if they promote survival across all eight dynamics, thus benefiting the greatest number of people or things possible while harming the fewest.
ARC and KRC triangles.
The ARC and KRC triangles are concept maps which show a relationship between three concepts to form another concept. These two triangles are present in the Scientology symbol. The lower triangle, the ARC triangle, is a summary representation of the knowledge the Scientologist strives for. It encompasses "Affinity" (affection, love or liking), "Reality" (consensual reality) and "Communication" (the exchange of ideas). Scientologists believe that improving one of the three aspects of the triangle "increases the level" of the other two, but Communication is held to be the most important. The upper triangle is the KRC triangle, the letters KRC positing a similar relationship between "Knowledge", "Responsibility" and "Control".
Among Scientologists, the letters ARC are used as an affectionate greeting in personal communication, for example at the end of a letter. Social problems are ascribed to breakdowns in ARC – in other words, a lack of agreement on reality, a failure to communicate effectively, or a failure to develop affinity. These can take the form of "overts" – harmful acts against another, either intentionally or by omission – which are usually followed by "withholds" – efforts to conceal the wrongdoing, which further increase the level of tension in the relationship.
Social and antisocial personalities.
While Scientology states that many social problems are the unintentional results of people's imperfections, it asserts that there are also truly malevolent individuals. Hubbard believed that approximately 80 percent of all people are what he called "social personalities"people who welcome and contribute to the welfare of others. The remaining 20 percent of the population, Hubbard thought, were "suppressive persons". According to Hubbard, only about 2.5 percent of this 20 percent are hopelessly antisocial personalities; these make up the small proportion of truly dangerous individuals in humanity: "the Adolf Hitlers and the Genghis Khans, the unrepentant murderers and the drug lords." Scientologists believe that any contact with suppressive or antisocial individuals has an adverse effect on one's spiritual condition, necessitating disconnection.
In Scientology, defectors who turn into critics of the movement are declared suppressive persons, and the Church of Scientology has a reputation for moving aggressively against such detractors. A Scientologist who is actively in communication with a suppressive person and as a result shows signs of antisocial behaviour is referred to as a "Potential Trouble Source".
Auditing.
Scientology asserts that people have hidden abilities which have not yet been fully realized. It is believed that increased spiritual awareness and physical benefits are accomplished through counseling sessions referred to as "auditing". Through auditing, it is said that people can solve their problems and free themselves of engrams. This restores them to their natural condition as thetans and enables them to be "at cause" in their daily lives, responding rationally and creatively to life events rather than reacting to them under the direction of stored engrams. Accordingly, those who study Scientology materials and receive auditing sessions advance from a status of "Preclear" to "Clear" and "Operating Thetan". Scientology's utopian aim is to "clear the planet", a world in which everyone has cleared themselves of their engrams.
Auditing is a one-on-one session with a Scientology counselor or "auditor." It bears a superficial similarity to confession or pastoral counseling, but the auditor records and stores all information received and does not dispense forgiveness or advice the way a pastor or priest might do. Instead, the auditor's task is to help a person discover and understand engrams, and their limiting effects, for him- or herself. Most auditing requires an E-meter, a device that measures minute changes in electrical resistance through the body when a person holds electrodes (metal "cans"), and a small current is passed through them. Scientology asserts that watching for changes in the E-meter's display helps locate engrams. Once an area of concern has been identified, the auditor asks the individual specific questions about it, in order to help him or her eliminate the engram, and uses the E-meter to confirm that the engram's "charge" has been dissipated and the engram has in fact been cleared. As the individual progresses, the focus of auditing moves from simple engrams to engrams of increasing complexity. At the more advanced OT auditing levels, Scientologists perform solo auditing sessions, acting as their own auditors.
The "Bridge to Total Freedom".
Spiritual development within Scientology is accomplished by studying Scientology materials. Scientology materials (called "Technology" or "Tech" in Scientology jargon) are structured in sequential levels (or "gradients"), so that easier steps are taken first and greater complexities are handled at the appropriate time. This process is sometimes referred to as moving along the "Bridge to Total Freedom", or simply "the Bridge". It has two sides: "training" and "processing". Training means education in the principles and practices of auditing. Processing is personal development through participation in auditing sessions.
The Church of Scientology believes in the principle of reciprocity, involving give-and-take in every human transaction. Accordingly, members are required to make donations for study courses and auditing as they move up the Bridge, the amounts increasing as higher levels are reached. Participation in higher-level courses on the Bridge may cost several thousand dollars, and Scientologists usually move up the Bridge at a rate governed by their income.
Space opera and confidential materials.
The Church of Scientology holds that at the higher levels of initiation ("OT levels"), mystical teachings are imparted that may be harmful to unprepared readers. These teachings are kept secret from members who have not reached these levels. The Church states that the secrecy is warranted to keep its materials' use in context, and to protect its members from being exposed to materials they are not yet prepared for.
These are the OT levels, the levels above "Clear", whose contents are guarded within Scientology. The OT level teachings include accounts of various cosmic catastrophes that befell the thetans. Hubbard described these early events collectively as "space opera".
In the OT levels, Hubbard explains how to reverse the effects of past-life trauma patterns that supposedly extend millions of years into the past. Among these advanced teachings is the story of Xenu (sometimes Xemu), introduced as the tyrant ruler of the "Galactic Confederacy." According to this story, 75 million years ago Xenu brought billions of people to Earth in spacecraft resembling Douglas DC-8 airliners, stacked them around volcanoes and detonated hydrogen bombs in the volcanoes. The thetans then clustered together, stuck to the bodies of the living, and continue to do this today. Scientologists at advanced levels place considerable emphasis on isolating body thetans and neutralizing their ill effects.
The material contained in the OT levels has been characterized as bad science fiction by critics, while others claim it bears structural similarities to gnostic thought and ancient Hindu beliefs of creation and cosmic struggle. J. Gordon Melton suggests that these elements of the OT levels may never have been intended as descriptions of historical events, and that, like other religious mythology, they may have their truth in the realities of the body and mind which they symbolize. He adds that on whatever level Scientologists might have received this mythology, they seem to have found it useful in their spiritual quest.
Excerpts and descriptions of OT materials were published online by a former member in 1995 and then circulated in mainstream media. This occurred after the teachings were submitted as evidence in court cases involving Scientology, thus becoming a matter of public record. There are eight publicly known OT levels, OT I to VIII. The highest level, OT VIII, is disclosed only at sea, on the Scientology cruise ship "Freewinds". It has been rumored that additional OT levels, said to be based on material written by Hubbard long ago, will be released at some appropriate point in the future.
A large Church of Spiritual Technology symbol carved into the ground at Scientology's Trementina Base is visible from the air. Washington Post reporter Richard Leiby wrote, "Former Scientologists familiar with Hubbard’s teachings on reincarnation say the symbol marks a 'return point' so loyal staff members know where they can find the founder’s works when they travel here in the future from other places in the universe."
Ceremonies.
In Scientology, ceremonies for events such as weddings, child naming, and funerals are observed. Friday services are held to commemorate the completion of a person's religious services during the prior week. Ordained Scientology ministers may perform such rites. However, these services and the clergy who perform them play only a minor role in Scientologists' religious lives.
Influences.
The general orientation of Hubbard's philosophy owes much to Will Durant, author of the popular 1926 classic "The Story of Philosophy"; "Dianetics" is dedicated to Durant. Hubbard's view of a mechanically functioning mind in particular finds close parallels in Durant's work on Spinoza.
Sigmund Freud's psychology, popularized in the 1930s and 1940s, was a key contributor to the Dianetics therapy model, and was acknowledged unreservedly as such by Hubbard in his early works. Hubbard never forgot meeting Cmdr. Joseph Cheesman Thompson, a U.S. Navy officer who studied with Freud, when he was 12 years old, and when writing to the American Psychological Association in 1949, he stated that he was conducting research based on the "early work of Freud".
Another major influence was Alfred Korzybski's General Semantics. Hubbard was friends with fellow science fiction writer A. E. van Vogt, who explored the implications of Korzybski's non-Aristotelian logic in works such as "The World of Null-A", and Hubbard's view of the "reactive mind" has clear and acknowledged parallels with Korzybski's thought; in fact, Korzybski's "anthropometer" may have been what inspired Hubbard's invention of the E-meter.
Beyond that, Hubbard himself named a great many other influences in his own writing – in "Scientology 8-8008", for example, these include philosophers from Anaxagoras and Aristotle to Herbert Spencer and Voltaire, physicists and mathematicians like Euclid and Isaac Newton, as well as founders of religions such as Buddha, Confucius, Jesus and Mohammed – but there is little evidence in Hubbard's writings that he studied these figures to any great depth.
As noted, there are elements of Eastern religions evident in Scientology, in particular the concepts of karma, as present in Hinduism and in Jainism, and dharma. In addition to the links to Hindu texts, Hubbard tried to connect Scientology with Taoism and Buddhism. Scientology has been said to share features with Gnosticism as well.
In the 1940s, Hubbard was in contact with Jack Parsons, a rocket scientist and member of the Ordo Templi Orientis then led by Aleister Crowley, and there have been suggestions that this connection influenced some of the ideas and symbols of Scientology. Religious scholars like Gerald Willms and J. Gordon Melton have pointed out that Crowley's teachings bear little if any resemblance to Scientology doctrine.
Organization.
There are a considerable number of Scientology organizations (or "orgs") which generally support one of the following three aims: enabling Scientology practice and training, promoting the wider application of Scientology technology, or campaigning for social change. These organizations are supported by a three-tiered hierarchical structure comprising lay practitioners, staff and, at the top of the hierarchy, members of the so-called Sea Organization or "Sea Org". The Sea Org, comprising over 5,000 members, has been compared to the monastic orders found in other religions; it is composed of the most dedicated adherents, who work for nominal compensation and symbolically express their religious commitment by signing a billion-year contract.
The internal structure of Scientology organizations is strongly bureaucratic, with detailed coordination of activities and collection of "stats" – or statistics, to measure organizational and individual performance. Organizational operating budgets are performance-related and subject to frequent reviews. Scientology has an internal justice system (the "Ethics" system) designed to deal with unethical or antisocial behavior. Ethics officers are present in every org; they are tasked with ensuring correct application of Scientology technology and deal with violations such as non-compliance with standard procedures or any other behavior adversely affecting an org's performance, ranging from errors and misdemeanors to crimes and suppressive acts, as defined by internal documents.
A controversial part of the Scientology justice system is the Rehabilitation Project Force (RPF). When a Sea Org member is accused of a violation, such as lying, sexual misconduct, dereliction of duty, or failure to comply with Church policy, a Committee of Evidence examines the case. If the charge is substantiated, the individual may accept expulsion from the Sea Org or participate in the RPF to become eligible to rejoin the Sea Org. The RPF involves a daily regimen of five hours of auditing or studying, eight hours of work, often physical labor, such as building renovation, and at least seven hours of sleep. Douglas E. Cowan and David G. Bromley state that scholars and observers have come to radically different conclusions about the RPF and whether it is "voluntary or coercive, therapeutic or punitive".
Practice and training organizations.
Many Scientologists' first contact with Scientology is through local informal groups and field auditors practicing Dianetics counseling. In addition to these, Scientology operates hundreds of Churches and Missions around the world. This is where Scientologists receive introductory training, and it is at this local level that most Scientologists participate. Churches and Missions are licensed franchises; they offer services for a fee, and return a proportion of their income to the mother church. They are also required to adhere to the standards established by the Religious Technology Center (RTC), which supervises the application of Scientology tech, owns the trademarks and service marks of Scientology, and collaborates with the Commodore's Messenger Organization to administer and control the various corporate entities within Scientology. The RTC's Chairman is David Miscavige, who, while not the titular head of the Church of Scientology, is believed to be the most powerful person in the Scientology movement.
Once an individual has reached "Clear" and wishes to proceed further, he or she can take OT auditing and coursework with Advanced Organizations located in Los Angeles, Sydney, East Grinstead and Copenhagen. Beyond OT V, the Flag Service Organization in Clearwater, Florida, offers the auditing and course work for OT levels VI and VII, while OT VIII is offered only by the Flag Ship Service Organization aboard the Scientology ship "Freewinds". Since 1981, all of these Churches and organizations have been united under the Church of Scientology International umbrella organization, with the Sea Org providing staff for all levels above the local Churches and Missions.
In 2012, the Ideal Center of Scientology for the Middle East opened in a refurbished historic building in Jaffa, Israel.
Technology application organizations.
A number of Scientology organizations specialize in promoting the use of Scientology technology as a means to solve social problems.
The Church of Scientology has also instituted a Volunteer Ministers program to provide disaster relief; for example, Volunteer Ministers were active in the aftermath of 9/11, providing food and water and applying Scientology methods such as "Assists" to people in acute emotional distress. The Scientology Volunteer Ministers also used the "assist" to help Haiti quake victims. The Volunteer Ministers have also been sent to the site of relief efforts in Southeast Asia in the wake of the December 2004 tsunami and to London Underground stations that were attacked in the 7 July 2005 London bombings. Eight hundred were sent to New Orleans and the Gulf Coast following Hurricane Katrina.
Social reform organizations.
Some Scientology organizations are focused on bringing about social change. One of these is the Citizens Commission on Human Rights (CCHR). Founded in 1969, it has a long history of opposing psychiatric practices such as lobotomy, electric shock treatment and the use of mood-altering drugs. The psychiatric establishment rejected Hubbard's theories in the early 1950s. Ever since, Scientology has argued that psychiatry suffers from the fundamental flaw of ignoring humanity's spiritual dimension, and that it fails to take into account Hubbard's insights about the nature of the mind. Scientology holds psychiatry responsible for a great many wrongs in the world, saying it has at various times offered itself as a tool of political suppression and "that psychiatry spawned the ideology which fired Hitler's mania, turned the Nazis into mass murderers, and created the Holocaust." In recent years, the CCHR has conducted high-profile campaigns against Ritalin, given to children to control hyperactivity, and Prozac, a commonly used antidepressant. Neither drug was taken off the market as a result of the campaign, but Ritalin sales decreased, and Prozac suffered bad press.
The main other organization in this field is the National Commission on Law Enforcement and Social Justice, devoted to combating what it describes as abusive practices by government and police agencies, especially Interpol.
Free Zone and Independent Scientologists.
Although "Scientology" is most often used as shorthand for the Church of Scientology, a number of groups practice Scientology and Dianetics outside of the official Church. These groups, collectively known as the Free Zone or as Independent Scientologists, consist of both former members of the official Church of Scientology, as well as entirely new members. Capt. Bill Robertson, a former Sea Org member, was a primary instigator of the movement in the early 1980s. The Church labels these groups as "squirrels" in Scientology jargon, and often subjects them to considerable legal and social pressure. More recently, high-profile defectors Mark Rathbun and Mike Rinder have championed the cause of Independent Scientologists wishing to practice Scientology outside of the Church.
Dispute of religion status.
Scientology status by country.
The Church of Scientology has pursued an extensive public relations campaign for the recognition of Scientology as a religion in the various countries in which it exists. Opinions around the world still differ on whether Scientology is to be recognized as a religion or not, and Scientology has often encountered opposition due to its strong-arm tactics directed against critics and members wishing to leave the organization. A number of governments now view the Church as a religious organization entitled to protections and tax relief, while others continue to view it as a pseudoreligion or cult. The differences between these classifications have become a major problem when discussing religions in general and Scientology specifically.
Scientology is officially recognized as a religion in the United States. Recognition came in 1993, when the Internal Revenue Service (IRS) stated that "is operated exclusively for religious and charitable purposes."
The "New York Times" noted in this connection that the Church of Scientology had funded a campaign which included a whistle-blower organization to publicly attack the IRS, as well as the hiring of private investigators to look into the private lives of IRS officials. In 1991, Miscavige, the highest-ranking Scientology leader, arranged a meeting with Fred T. Goldberg Jr., the Commissioner of the Internal Revenue Service at the time.
The meeting was an "opportunity for the church to offer to end its long dispute with the agency, including the dozens of suits brought against the IRS." The committee met several times with the Scientology legal team and "was persuaded that those involved in the Snow White crimes had been purged, that church money was devoted to tax-exempt purposes and that, with Mr. Hubbard's death, no one was getting rich from Scientology." In August 1993, a settlement was reached; the church would receive its tax-exempt status and end its legal assault on the IRS and its personnel. The church was required only to resubmit new applications for exemption to the IRS exempt organizations division; the division was told "not to consider any substantive matters" because those issues had been resolved by the committee. The secret agreement was announced on Oct 13, 1993, with the IRS refusing to disclose any of the terms or the reasoning behind its decision. Both the IRS and Scientology rejected any allegations of foul play or undue pressure having been brought to bear upon IRS officials, insisting that the decision had been based on the merits of the case. IRS officials "insisted that Scientology's tactics had not affected the decision" and that "ultimately the decision was made on a legal basis". Miscavige claims that the IRS’s examination of Scientology was the most exhaustive review of any non-profit organization in history. 
Elsewhere, Scientology has been able to obtain religious recognition in such countries as Australia, Portugal, Spain, Slovenia, Sweden, Croatia, Hungary and Kyrgyzstan. In New Zealand, the Inland Revenue Department classified the Church of Scientology as a charitable organization and stated that its income would be tax exempt. It has gained judicial recognition in Italy, and Scientology officials have won the right to perform marriages in South Africa.
Scientology has so far failed to win religious recognition in Canada. In the UK, the Charity Commission for England and Wales ruled in 1999 that Scientology was not a religion and refused to register the Church as a charity, although a year later, it was recognized as a not-for-profit body in a separate proceeding by the UK Revenue and Customs and exempted from UK value added tax. 
Since 1997 Germany has considered Scientology to be in conflict with the principles of the nation's constitution. It is seen as an anticonstitutional sect and a new version of political extremism and because there is "evidence for intentions agains the free democratic basic order" it is observed by the Federal Office for the Protection of the Constitution. Germany will continue to monitor Scientology's activities in the country, despite continued objection from Scientology which cites such monitoring as abuse of freedom of religion. France and Belgium have not recognized Scientology as a religion, and Stephen A. Kent, writing in 2001, noted that no such recognition had been obtained in Ireland, Luxembourg, Israel or Mexico either. The Belgian State Prosecution Service has recommended that various individuals and organizations associated with Scientology should be prosecuted. An administrative court is to decide if charges will be pressed. In Greece, Scientology is not recognized as a religion by the Greek government, and multiple applications for religious status have been denied, for example in 2000 and 2003.
Scholarly views on Scientology's status as a religion.
Scientology is a religion of significance to scholars.While acknowledging that a number of his colleagues accept Scientology as a religion, sociologist and professor Stephen A. Kent wrote: "Rather than struggling over whether or not to label Scientology as a religion, I find it far more helpful to view it as a multifaceted transnational corporation, only "one" element of which is religious" in the original. Kent also holds that the US government sees Scientology not as a religion, but as a charitable organization due to its religious claims.
David G. Bromley of Virginia Commonwealth University characterizes Scientology as "a 'quasi-religious therapy' that resembles Freudian 'depth psychology' while also drawing upon Buddhism, Hinduism and Gnosticism."
Dr. Frank K. Flinn, adjunct professor of religious studies at Washington University in St. Louis wrote, "it is abundantly clear that Scientology has both the typical forms of ceremonial and celebratory worship and its own unique form of spiritual life." Flinn further states that religion requires "beliefs in something transcendental or ultimate, practices (rites and codes of behavior) that re-inforce those beliefs and, a community that is sustained by both the beliefs and practices", all of which are present within Scientology.
Using the synonym of alternative religions, Barrett (1998:237) and Hunt (2003:195) place Scientology in the sociological grouping of personal development movements together with the Neurolinguistic Programming, Emin, and Insight. According to Religious Studies professor Mary Farrell Benarowski, Scientology describes itself as drawing on science, religion, psychology and philosophy but "had been claimed by none of them and repudiated, for the most part, by all."
Describing the variety of scholarly opinions in existence, David G. Bromley and Douglas E. Cowan stated in 2006 that "Overall, however, most scholars have concluded that Scientology falls within the category of religion for the purposes of academic study, and a number have defended the Church in judicial and political proceedings on this basis." Bromley and Cowan noted in 2008 that Scientology's attempts "to gain favor with new religion scholars" had often been problematic.
On the cultural significance of Scientology as a religion and providing a different scholarly perspective, Roland Robertson, a sociologist and theorist of globalization says, "New Religious Movements such as Scientology are contributing to globalization at the level or focal point of the self and the newly thematized extra societal aspect of self, humanity."
Religious scholar J. Gordon Melton asserts, "The Church of Scientology is very much a religion in the fullest sense of the word." 
According to Jacob Neusner, editor of "World Religions in America", "Scientology contains religious practices and rituals, as well as moral principles and standards for ethical conduct, all aimed at the redemption and salvation of humanity. This religion is supported by a community of believers, including highly dedicated ordained clergy, and their activities are organized socially much like other, more traditional American religions." Neusner also argues, "Scientology contains the same elements of most other religions, including myths, scriptures, doctrines, worship, sacred practices and rituals, moral and ethical expectations, a community of believers, clergy, and ecclesiastic organizations." 
Scientology as a commercial venture.
While NRM scholars have generally accepted the religious nature of Scientology, media reports have tended to express the opinion that "Scientology is a business, often given to criminal acts, and sometimes masquerading as a religion." During his lifetime, Hubbard was accused of using religion as a façade for Scientology to maintain tax-exempt status and avoid prosecution for false medical claims. The IRS cited a statement frequently attributed to Hubbard that the way to get rich was to found a religion. According to scholar J. Gordon Melton, the supposed statement is actually unsubstantiated, although several of Hubbard's science fiction colleagues do recall Hubbard raising the topic in conversation.
Hubbard grew up in a climate that was very critical of organized religion, and frequently quoted anti-religious sentiments in his early lectures. The scholar Marco Frenschkowski (University of Mainz) has stated that it was not easy for Hubbard "to come to terms with the spiritual side of his own movement. Hubbard did not want to found a religion: he discovered that what he was talking about in fact was religion. This mainly happened when he had to deal with apparent memories from former lives. He had to defend himself about this to his friends." Frenschkowski allows that there naturally were practical considerations about "how to present Scientology to the outside world", but dismisses the notion that presentation as a religion was just an expedient pretense, pointing to many passages in Hubbard's works that document his struggle with this issue. Drawing parallels to similar struggles for identity in other religious movements such as Theosophy and Transcendental Meditation, Frenschkowski sees in Hubbard's lectures "the case of a man whose background was non-religious and who nevertheless discovers that his ideas somehow oscillate between 'science' (in a very popular sense), 'religion' and 'philosophy', and that these ideas somehow fascinate so many people that they start to form a separate movement. As in the case of similar movements, it was quite unclear to Hubbard in the beginning what Scientology would become."
The Church of Scientology denounces the idea of Hubbard starting a religion for personal gain as an unfounded rumor. The Church also suggests that the origin of the rumor was a quote by George Orwell which had been misattributed to Hubbard. Robert Vaughn Young, who left the Church in 1989 after being its spokesman for twenty years, suggested that reports of Hubbard making such a statement could be explained as a misattribution of Orwell, despite having encountered three of Hubbard's associates from his science fiction days who remembered Hubbard making statements of that sort in person. It was Young who by a stroke of luck came up with the "Orwell quote": "but I have always thought there might be a lot of cash in starting a new religion, and we'll talk it over some time" It appears in a letter by George Orwell (signed Eric Blair) to a friend Jack Common, dated 16-February-38 (February 16, 1938), and was published in "Collected Essays, Journalism and Letters of George Orwell", vol. 1. In 2006, Rolling Stone's Janet Reitman writes Hubbard said the same thing to science fiction writer Lloyd Eshbach, a fact quoted in Eshbach's autobiography.
Scientology maintains strict control over the use of its symbols, icons, and names. It claims copyright and trademark over its "Scientology cross", and its lawyers have threatened lawsuits against individuals and organizations who have published the image in books and on Web sites. Because of this, it is very difficult for individual groups to attempt to publicly practice Scientology on their own, independent of the official Church of Scientology. Scientology has filed suit against a number of individuals who have attempted to set up their own auditing practices, using copyright and trademark law to shut these groups down.
The Church of Scientology and its many related organizations have amassed considerable real estate holdings worldwide, likely in the hundreds of millions of dollars. Scientology encourages existing members to "sell" Scientology to others by paying a commission to those who recruit new members. Scientology franchises, or missions, must pay the Church of Scientology roughly 10% of their gross income. On that basis, it is likened to a pyramid selling scheme. While introductory courses do not cost much, courses at the higher levels may cost several thousand dollars each. As a rule, the great majority of members proceeds up the bridge in a steady rate commensurate with their income. Most recently the Italian Supreme Court agreed with the American IRS that the church's financial system is analogous to the practices of other groups and not out of line with its religious purposes. 
In conjunction with the Church of Scientology's request to be officially recognized as a religion in Germany, around 1996 the German state Baden-Württemberg conducted a thorough investigation regarding the group's activities within Germany. The results of this investigation indicated that at the time of publication, Scientology's main sources of revenue ("Haupteinnahmequellen der SO") were from course offerings and sales of their various publications. Course offerings ranged from (German Marks) DM 182.50 to about DM 30,000the equivalent today of approximately $119 to $19,560 USD. Revenue from monthly, bi-monthly, and other membership offerings could not be estimated in the report, but was nevertheless placed in the millions. Defending its practices against accusations of profiteering, the Church has countered critics by drawing analogies to other religious groups who have established practices such as tithing, or require members to make donations for specific religious services.
Controversies.
Of the many new religious movements to appear during the 20th century, the Church of Scientology has, from its inception, been one of the most controversial, coming into conflict with the governments and police forces of several countries (including the United States, the United Kingdom, Canada, France and Germany). It has been one of the most litigious religious movements in history, filing countless lawsuits against governments, organizations and individuals.
Reports and allegations have been made, by journalists, courts, and governmental bodies of several countries, that the Church of Scientology is an unscrupulous commercial enterprise that harasses its critics and brutally exploits its members. "Time" magazine published an article in 1991 which described Scientology as "a hugely profitable global racket that survives by intimidating members and critics in a Mafia-like manner."
Due to these allegations, a considerable amount of investigation has been aimed at the Church, by groups ranging from the media to governmental agencies.
Scientology social programs such as drug and criminal rehabilitation have likewise drawn both support and criticism.
Professor of sociology Stephen A. Kent says "Scientologists see themselves as possessors of doctrines and skills that can save the world, if not the galaxy." As stated in Scientology doctrine: "The whole agonized future of this planet, every man, woman and child on it, and your own destiny for the next endless trillions of years depend on what you do here and now with and in Scientology."
Scientology and the Internet.
In the 1990s, Scientology representatives began to take action against increased criticism of Scientology on the Internet. The organization says that the actions taken were to prevent distribution of copyrighted Scientology documents and publications online, fighting what it refers to as "copyright terrorists".
In January 1995, Church lawyer Helena Kobrin attempted to shut down the newsgroup alt.religion.scientology by sending a control message instructing Usenet servers to delete the group. In practice, this rmgroup message had little effect, since most Usenet servers are configured to disregard such messages when sent to groups that receive substantial traffic, and newgroup messages were quickly issued to recreate the group on those servers that did not do so. However, the issuance of the message led to a great deal of public criticism by free-speech advocates. Among the criticism raised, one suggestion is that Scientology's true motive is to suppress the free speech of its critics.
The Church also began filing lawsuits against those who posted copyrighted texts on the newsgroup and the World Wide Web, and lobbied for tighter restrictions on copyrights in general. The Church supported the controversial Sonny Bono Copyright Term Extension Act as well as the even more controversial Digital Millennium Copyright Act. Some of the DMCA's provisions (notably the Online Copyright Infringement Liability Limitation Act) were heavily influenced by Church litigation against US Internet service providers over copyrighted Scientology materials that had been posted or uploaded through their servers.
Beginning in the middle of 1996 and ensuing for several years, the newsgroup was attacked by anonymous parties using a tactic dubbed "sporgery" by some, in the form of hundreds of thousands of forged spam messages posted on the group. Some investigators said that some spam had been traced to Church members. Former Scientologist Tory Christman later asserted that the Office of Special Affairs had undertaken a concerted effort to destroy alt.religion.scientology through these means; the effort failed.
On January 14, 2008, a video produced by the Church of Scientology featuring an interview with Tom Cruise was leaked to the Internet and uploaded to YouTube.
The Church of Scientology issued a copyright violation claim against YouTube requesting the removal of the video. Subsequently, the group Anonymous voiced its criticism of Scientology and began attacking the Church. Calling the action by the Church of Scientology a form of Internet censorship, participants of Anonymous coordinated Project Chanology, which consisted of a series of denial-of-service attacks against Scientology websites, prank calls, and black faxes to Scientology centers. On January 21, 2008, Anonymous announced its intentions via a video posted to YouTube entitled "Message to Scientology", and a press release declaring a "war" against both the Church of Scientology and the Religious Technology Center.
In the press release, the group stated that the attacks against the Church of Scientology would continue in order to protect the freedom of speech, and end what they saw as the financial exploitation of church members.
On January 28, 2008, an Anonymous video appeared on YouTube calling for protests outside Church of Scientology centers on February 10, 2008. According to a letter Anonymous e-mailed to the press, about 7,000 people protested in more than 90 cities worldwide. Many protesters wore masks based on the character V from "V for Vendetta" (who was influenced by Guy Fawkes) or otherwise disguised their identities, in part to protect themselves from reprisals from the Church of Scientology.
Many further protests have followed since then in cities around the world.
The Arbitration Committee of the Wikipedia internet encyclopedia decided in May 2009 to restrict access to its site from Church of Scientology IP addresses, to prevent self-serving edits by Scientologists. A "host of anti-Scientologist editors" were topic-banned as well. The committee concluded that both sides had "gamed policy" and resorted to "battlefield tactics", with articles on living persons being the "worst casualties".
Scientology and hypnosis.
Scientology literature states that L. Ron Hubbard demonstrated his professional expertise in hypnosis by "discovering" the Dianetic engram. Hubbard was said to be an accomplished hypnotist, and close acquaintances such as Forrest Ackerman (Hubbard's literary agent) and A. E. van Vogt (an early supporter of Dianetics) witnessed repeated demonstrations of his hypnotic skills.
Auditing confidentiality.
During the auditing process, the auditor may collect personal information from the person being audited. Auditing records are referred to within Scientology as "preclear folders". The Church of Scientology has strict codes designed to protect the confidentiality of the information contained in these folders. However, people leaving Scientology know that the Church is in possession of very personal information about them, and that the Church has a history of attacking and psychologically abusing those who leave it and become critics. On December 16, 1969, a Guardian's Office order (G. O. 121669) by Mary Sue Hubbard authorized the use of auditing records for purposes of "internal security." Some former members have said that while they were still in the Church, they combed through information obtained in auditing sessions to see if it could be used for smear campaigns against critics.
Celebrities.
Hubbard envisaged that celebrities would have a key role to play in the dissemination of Scientology, and in 1955 launched "Project Celebrity", creating a list of 63 famous people that he asked his followers to target for conversion to Scientology. Former silent-screen star Gloria Swanson and jazz pianist Dave Brubeck were among the earliest celebrities attracted to Hubbard's teachings.
Today, Scientology operates eight churches that are designated "Celebrity Centers", the largest of these being the one in Hollywood. Celebrity Centers are open to the general public, but are primarily designed to minister to celebrity Scientologists. Entertainers such as John Travolta, Kirstie Alley, Lisa Marie Presley, Nancy Cartwright, Jason Lee, Isaac Hayes, Edgar Winter, Tom Cruise, Chick Corea and Leah Remini have generated considerable publicity for Scientology.

Silesia
Silesia ( or ; ; ; Silesian German: "Schläsing"; ; Silesian: "Ślůnsk" ; ) is a historical region of Central Europe located mostly in Poland, with smaller parts also in the Czech Republic, and Germany.
Silesia is rich in mineral and natural resources and includes several important industrial areas. Silesia's largest city and historical capital is Wrocław . Other large cities are Opole, Gliwice, Katowice in Poland; Ostrava; Opava in the Czech Republic; and Görlitz in Germany. Its main river is the Oder.
Silesia's borders and national affiliation have changed radically over time, both when it was a hereditary possession of noble houses and after the rise of modern nation-states. The first known states to hold power there were those of Greater Moravia at end of 9th century and Bohemia early in the 10th century. In the 10th century Silesia was incorporated into the early Polish state, but it later broke into independent duchies, coming under increasing Czech and German influence. It came under the rule of the Crown of Bohemia, which passed to the Austrian Habsburg Monarchy in 1526. Most of Silesia was conquered by Prussia in 1742, later becoming part of the German Empire, the Weimar Republic and Nazi Germany up to 1945. After World War I the easternmost part of this region was awarded to Poland by the victorious Allies after rebellions by Silesian Polish people and a plebiscite. After World War II the bulk of Silesia was transferred to Polish jurisdiction and became part of Poland. The remaining small parts of Silesia mostly went to Czechoslovakia after World War I, and are part of the Czech Republic.
Most inhabitants of Silesia today speak the national languages of their respective countries (Polish, Czech, German). There is an ongoing debate whether a local Silesian speech should be considered a Polish dialect or a separate language. There also exists a Silesian German or Lower Silesian language, although this form of German is almost extinct.
Etymology.
The names of Silesia in the different languages most likely share their etymology—Latin and English: "Silesia"; Polish: "Śląsk"; Old Polish: "Ślążsk"; Silesian: "Ślůnsk"; German: "Schlesien"; Silesian German: "Schläsing"; Czech: "Slezsko"; Slovak: "Sliezsko"; Kashubian: "Sląsk"; Upper Sorbian: "Šleska"; Lower Sorbian: "Šlazyńska". The names all relate to the name of a river (now Ślęza) and mountain (Mount Ślęża) in mid-southern Silesia. The mountain served as a holy place in prehistoric times.
"Ślęża" is listed as one of the numerous Pre-Indo-European topographic names in the region (see old European hydronymy).
According to Polish Slavists M. Rudnicki, T. Lehr-Splawinski, S Rospond and historian W. Semkowicz, demonstrate the name ‘Ślęża’ or ‘Ślęż’ (translated in Latin "Silesia’’, in Silesian "Ślunsk", in German "Schlesien") has direct relation with the old–Slavic words "ślęg" or "śląg" , what means dampness, moisture or humidity. The above Polish scientists reject the German hypothesis of ethnic origin of name "Śląsk" from the name of tribe Silings.
According to some etymology the Slavic name derives from the Germanic ethnonym Silingi. This etymology is preferred by some German authors.
History.
Silesia has historically been an ethnically diverse region. In the fourth century BC Celts entered Silesia settling around the Mount Ślęża near the modern Wrocław, Oława and Strzelin. Germanic tribes were first recorded within Silesia in the first century. Slavic peoples arrived in this territory around the Seventh century. In the early ninth century the Slavic settlement stabilized. Local Slavs started to erect boundary structures like the Silesian Przesieka and the Silesia Walls. In those days the eastern border of Silesian settlement was situated to the west of the Bytom, and east from Racibórz and Cieszyn. East from this line dwelled a closely related Slav tribe, the Vistulans. Their northern border was in the valley of the Barycz river, north of which dwelled Polans.
The first known states in Silesia were Greater Moravia and Bohemia. In the tenth century, the Polish ruler Mieszko I of the Piast dynasty incorporated Silesia into the Polish state. During the Fragmentation of Poland, Silesia, as well as the rest of the country, was divided among many independent duchies ruled by various Silesian dukes. During this time, German cultural and ethnic influence increased as a result of immigration from German-speaking parts of the Holy Roman Empire. In 1178, parts of the Duchy of Kraków around Bytom, Oświęcim, Chrzanów and Siewierz were transferred to the Silesian Piasts, yet their population was of Vistulan and not of Silesian descent.
Between 1289 and 1292, Bohemian king Wenceslaus II became suzerain of some Upper Silesian duchies. It wasn't however until 1335 when Polish kings renounced their hereditary rights to Silesia. The province became part of the Bohemian Crown under the Holy Roman Empire, and passed with that crown to the Habsburg Monarchy of Austria in 1526. 
In the 15th century there were several border changes of the province. First of all parts of the territories that were transferred to the Silesian Piasts in 1178, were bought by the Polish kings in the second half of the 15th century (the Duchy of Oświęcim in 1457 and the Duchy of Zator in 1494). The Bytom area however remained in the possession of the Silesian Piasts, even though it was a part of the Diocese of Kraków. Secondly the Duchy of Crossen was inherited by Margraviate of Brandenburg in 1476 and, with the renunciation by King Ferdinand I and estates of Bohemia in 1538, it became an integral part of Brandenburg.
In 1742, most of Silesia was seized by King Frederick the Great of Prussia in the War of the Austrian Succession and subsequently made the Prussian Province of Silesia. Consequently, Silesia became part of the German Empire when it was proclaimed in 1871.
After World War I, Upper Silesia was contested by Germany and the newly-independent Second Polish Republic. The League of Nations organized a plebiscite to decide the issue in 1921. It resulted in 60% votes being cast for Germany and 40% for Poland. Following the third Silesian Uprising (1921), however, the easternmost portion of Upper Silesia (including Katowice), with a majority ethnic Polish population, was awarded to Poland, where it was formed into the Silesian Voivodeship. The Prussian Province of Silesia within Germany was then divided into the provinces of Lower Silesia and Upper Silesia. Meanwhile Austrian Silesia, the small portion of Silesia retained by Austria after the Silesian Wars, was mostly awarded to the new Czechoslovakia (becoming known as Czech Silesia), although most of Cieszyn and territory to the east of it went to Poland (see Zaolzie).
Polish Silesia was among the first regions invaded during Germany's 1939 attack on Poland. One of the goals of Nazi occupation, particularly the occupation of Upper Silesia, was to expel the Polish Silesian population. German repatriation of Poles in Upper Silesia was made a priority for two crucial reasons. First, Nazi Germany was resentful over the loss of Silesia after the uprisings of the early 1920s and wished to regain the region for its natural resource wealth and strategically important locomotive network. Second, the Nazi war machine needed more members. Those repatriated as German were immediately subject to military service, thus bolstering the German Army's numbers. As for the non-German speaking Polish population of Silesia, they were reduced to a lower worker class status and were oftentimes severely mistreated by their new German overlords. This treatment would be addressed by the Poles years later.
In 1945, Silesia and its population went through another traumatic change. The German expulsion of Poles from Silesia was echoed by Polish expulsion of Germans. The Potsdam Conference of 1945 concluded that the Oder-Neisse would be the official border between Germany and Poland. Millions of German Silesians were evicted from their homes and replaced by Poles from the East. Furthermore, the newly formed Polish United Workers' Party created a Ministry of the Recovered Territories that claimed half of the available arable land for state-run collectivized farms. Many Silesian residents not only resented the Germans for their invasion in 1939, but now also the newly formed Polish communist government for their population shifting and interference in agricultural, as well as industrial, affairs.
The administrative division of Silesia within Poland has changed several times since 1945. Since 1999 it has been divided between Lower Silesian Voivodeship, Opole Voivodeship, Silesian Voivodeship and Lubusz Voivodeship. Czech Silesia is now part of the Czech Republic, forming the Moravian-Silesian Region and the northern part of the Olomouc Region. Germany retains the Silesia-Lusatia region ("Niederschlesien-Oberlausitz" or "Schlesische Oberlausitz") west of the Neisse, which is part of the federal state of Saxony.
Geography.
Most of Silesia is relatively flat, although its southern border is generally mountainous. It is primarily located in a swath running along both banks of the upper and middle Oder (Odra) river, but it extends eastwards to the upper Vistula river. The region also includes many tributaries of the Oder, including the Bóbr (and its tributary the Kwisa), the Barycz and the Nysa Kłodzka. The Sudeten mountains run along most of the southern edge of the region, though at its south-eastern extreme it reaches the Silesian Beskids and Moravian-Silesian Beskids, which belong to the Carpathian range.
Historically, Silesia was bounded to the west by the Kwisa and Bóbr rivers, while the territory west of the Kwisa was in Upper Lusatia (earlier "Milsko"). However, because part of Upper Lusatia was included in the Province of Silesia in 1815, in Germany Görlitz, Niederschlesischer Oberlausitzkreis and neighbouring areas are considered parts of historical Silesia. Those districts, along with Poland's Lower Silesian Voivodeship and parts of Lubusz Voivodeship, make up the geographic region of Lower Silesia.
Silesia has undergone a similar notional extension at its eastern extreme. Historically it extended only as far as the Brynica river, which separates it from Zagłębie Dąbrowskie in the Lesser Poland region. However to many Poles today, Silesia ("Śląsk") is understood to cover all of the area around Katowice, including Zagłębie. This interpretation is given official sanction in the use of the name Silesian Voivodeship ("województwo śląskie") for the province covering this area. In fact the word "Śląsk" in Polish (when used without qualification) now commonly refers exclusively to this area (also called "Górny Śląsk" or Upper Silesia).
As well as the Katowice area, historical Upper Silesia also includes the Opole region (Poland's Opole Voivodeship) and Czech Silesia. Czech Silesia consists of a part of the Moravian-Silesian Region and the Jeseník District in the Olomouc Region.
Natural resources.
Silesia is a resource-rich and populous region.
Since the middle of the 18th century, coal has been mined. The industry grew during German rule and peaked in the 1970s under the People's Republic of Poland. During this period Silesia became one of the world's largest producers of coal, with a record tonnage in 1979. Coal mining declined during the next two decades but has increased again following the end of Communist rule.
There are 41 coal mines in Silesia, most forming part of the Gornoslaskie Zaglebie Weglowe coalfield which lies in the Silesian Upland. The field has an area of about 4,500 km2. Deposits in Lower Silesia have proven to be difficult to exploit and the area's unprofitable mines were closed in 2000. In 2008 an estimated 35 billion tonnes of lignite reserves was found near Legnica, making them some of the largest in the world.
From the fourth century BC iron ore has been mined in the upland areas of Silesia. The same period saw lead, copper, silver and gold mining. Zinc, cadmium, arsenic, and uranium have also been mined in the region. Lower Silesia features large copper mining and processing between the cities of Legnica, Głogów, Lubin and Polkowice.
The region is known for stone quarrying specifically in the Swietokrzyskie Mountains and in the Lublin Upland primarily to produce limestone, marl, marble, and basalt.
The region also has a thriving agricultural sector, which produces cereals (wheat, rye, barley, oats, corn), potatoes, rapeseed, sugar beets and others. Milk production is well developed. The Opole Silesia has for decades occupied the top spot in Poland for their indices of effectiveness of agricultural land use.
Mountainous parts of southern Silesia feature many significant and attractive tourism destinations (e.g., Karpacz, Szczyrk, Wisła). Silesia is generally well forested. This is because greenness is generally highly desirable by the local population, particularly in the highly industrialized parts of Silesia.
Demographics.
Modern Silesia is inhabited by Poles, Germans, Czechs and Silesians. The last Polish census of 2002 showed that the Silesians are the largest national minority in Poland, Germans being the second; both groups are located mostly in Upper Silesia. The Czech part of Silesia is inhabited by Czechs, Moravians, Silesians and Poles.
Before the Second World War, Silesia was inhabited mostly by Germans and Poles, with a Czech and Jewish minority. In 1905, a census showed that 75% of the population were Germans and 25% Poles. The German population tended to be based in the urban centres and in the rural areas to the north and west, whilst the Polish population was generally rural and in the east.
Silesia's Jewish community, who were concentrated around Breslau and Upper Silesia, numbered 48,003 (1.1% of the population) in 1890, decreasing to 44,985 persons (0.9%) by 1910. In Polish East Upper Silesia the number of Jews was around 90,000-100,000.
After the German invasion of Poland in 1939, the Jewish population of Silesia was either placed in ghettos or expelled to the General Government. Those sent to ghettos would from 1942 be expelled to concentration and work camps. In August 1942 10,000 to 13,000 Silesian Jews were killed at Auschwitz. There were seventy thousand Jews in Lower Silesia at the end of the war.
The majority of Germans fled or were expelled from the present-day Polish and Czech parts of Silesia during and after World War II. From June 1945 to January 1947, 1.77 million Germans were expelled from Lower Silesia, and 310,000 from Upper Silesia. Today, most German Silesians and their descendants live in the territory of the Federal Republic of Germany, many of them in the Ruhr area working as miners, like their ancestors in Silesia. In order to smooth their integration into West German society after 1945, they were placed into officially recognized organizations, like the Landsmannschaft Schlesien, with financing from the federal Western German budget. One of its most notable but controversial spokesmen was the CDU politician Herbert Hupka. Prevailing public opinion in Germany is that these organisations will achieve reconciliation with the Polish Silesians, which is gradually occurring.
The expulsion of Germans led to widespread underpopulation. The population of the town of Glogau fell from 33,500 to 5,000, and from 1939 to 1966 the population of Wrocław fell by 25%. Attempts to repopulate Silesia proved unsuccessful in the 1940s and 1950s, and it was not until the late 1970s that Silesia's population reached pre-war levels.
Cities.
The following table lists the cities in Silesia with a population greater than 100,000 (2006) 

Slavery
Slavery is a system under which people are treated as property to be bought and sold, and are forced to work. Slaves can be held against their will from the time of their capture, purchase or birth, and deprived of the right to leave, to refuse to work, or to demand compensation. Historically, slavery was institutionally recognized by many societies; in more recent times slavery has been outlawed in most societies but continues through the practices of debt bondage, indentured servitude, serfdom, domestic servants kept in captivity, certain adoptions in which children are forced to work as slaves, child soldiers, and forced marriage. There are more slaves in the early 21st century than at any previous time but opponents hope slavery can be eradicated within 30 years.
Slavery predates written records and has existed in many cultures. The number of slaves today remains as high as 12 million to 27 million. Most are debt slaves, largely in South Asia, who are under debt bondage incurred by lenders, sometimes even for generations. Human trafficking is primarily used for forcing women and children into sex industries.
In pre-industrial societies, slaves and their labour were economically extremely important. Slaves and serfs made up around three-quarters of the world's population at the beginning of the 19th century.
In modern mechanised societies, there is less need for sheer massive manpower; Norbert Wiener wrote that "mechanical labor has most of the economic properties of slave labor, though ... it does not involve the direct demoralizing effects of human cruelty."
Etymology.
The English word "slave" comes from Old French "sclave", from the Medieval Latin "sclavus", from the Byzantine Greek σκλάβος.
The word σκλάβος, in turn, comes from the ethnonym "Slav", because in some wars in early mediaeval times many Slavs were captured and enslaved. An older theory connected it to the Greek verb "skyleúo" 'to strip a slain enemy'.
Types.
Chattel slavery.
Chattel slavery, so named because people are treated as the personal property, chattels, of an owner and are bought and sold as commodities, is the original form of slavery. When taking these chattels across national borders it is referred to as human trafficking especially when these slaves provide sexual services.
Bonded labor.
Debt bondage or bonded labor occurs when a person pledges himself or herself against a loan. The services required to repay the debt, and their duration, may be undefined. Debt bondage can be passed on from generation to generation, with children required to pay off their parents' debt. It is the most widespread form of slavery today.
Forced labor.
Forced labor occurs when an individual is forced to work against his or her will, under threat of violence or other punishment, with restrictions on their freedom. It is also used to describe all types of slavery and may also include institutions not commonly classified as slavery, such as serfdom, conscription and penal labor.
History.
Early history.
Evidence of slavery predates written records, and has existed in many cultures. Prehistoric graves from about 8000 BC in Lower Egypt suggest that a Libyan people enslaved a San-like tribe. Slavery is rare among hunter-gatherer populations, as it is a system of social stratification. Mass slavery also requires economic surpluses and a high population density to be viable. Due to these factors, the practice of slavery would have only proliferated after the invention of agriculture during the Neolithic Revolution about 11,000 years ago.
In the earliest known records slavery is treated as an established institution. The Code of Hammurabi (ca. 1760 BC), for example, prescribed death for anyone who helped a slave to escape or who sheltered a fugitive. The Hebrew Bible refers uncritically to slavery as an established institution.
Slavery was known in almost every ancient civilization, and society, including Sumer, Ancient Egypt, Ancient China, the Akkadian Empire, Assyria, Ancient India, Ancient Greece, the Roman Empire, the Islamic Caliphate, the Hebrews in Palestine, and the pre-Columbian civilizations of the Americas. Such institutions included debt-slavery, punishment for crime, the enslavement of prisoners of war, child abandonment, and the birth of slave children to slaves.
Classical Antiquity.
Records of slavery in Ancient Greece go as far back as Mycenaean Greece. It is certain that Classical Athens had the largest slave population, with as many as 80,000 in the 6th and 5th centuries BC; two to four-fifths of the population were slaves. As the Roman Republic expanded outward, entire populations were enslaved, thus creating an ample supply from all over Europe and the Mediterranean. Greeks, Illyrians, Berbers, Germans, Britons, Thracians, Gauls, Jews, Arabs, and many more were slaves used not only for labour, but also for amusement (e. g. gladiators and sex slaves). This oppression by an elite minority eventually led to slave revolts (see Roman Servile Wars); the Third Servile War led by Spartacus being the most famous and severe. By the late Republican era, slavery had become a vital economic pillar in the wealth of Rome, as well as a very significant part of Roman society. At the least, some 25% of the population of Ancient Rome was enslaved. According to some scholars, slaves represented 35% or more of
Italy's population. In the city of Rome alone, under the Roman Empire, there were about 400,000 slaves. During the millennium from the emergence of the Roman Empire to its eventual decline, at least 100 million people were captured or sold as slaves throughout the Mediterranean and its hinterlands.
Middle Ages.
Medieval Europe.
The early medieval slave trade was mainly confined to the South and East: the Byzantine Empire and the Muslim world were the destinations, pagan Central and Eastern Europe, along with the Caucasus and Tartary, were important sources. Viking, Arab, Greek and Jewish merchants (known as Radhanites) were all involved in the slave trade during the Early Middle Ages. The trade in European slaves reached a peak in the 10th century following the Zanj rebellion which dampened the use of African slaves in the Arab world.
Medieval Spain and Portugal were the scene of almost constant Muslim invasion of the predominantly Christian area. Periodic raiding expeditions were sent from Al-Andalus to ravage the Iberian Christian kingdoms, bringing back booty and slaves. In raid against Lisbon, Portugal in 1189, for example, the Almohad caliph Yaqub al-Mansur took 3,000 female and child captives, while his governor of Córdoba, in a subsequent attack upon Silves, Portugal in 1191, took 3,000 Christian slaves. From the 11th to the 19th century, North African Barbary Pirates engaged in "Razzias", raids on European coastal towns, to capture Christian slaves to sell at slave markets in places such as Algeria and Morocco.
At the time of the "Domesday Book", compiled in 1086, nearly 10% of the English population were slaves. Slavery in early medieval Europe was so common that the Roman Catholic Church repeatedly prohibited it — or at least the export of Christian slaves to non-Christian lands was prohibited at e. g. the Council of Koblenz (922), the Council of London (1102), and the Council of Armagh (1171). In 1452, Pope Nicholas V issued the papal bull Dum Diversas, granting the kings of Spain and Portugal the right to reduce any "Saracens, pagans and any other unbelievers" to perpetual slavery, legitimizing the slave trade as a result of war. The approval of slavery under these conditions was reaffirmed and extended in his Romanus Pontifex bull of 1455. However, Pope Paul III forbade enslavement of the native Americans in 1537 in his papal bull Sublimus Dei. Dominican friars who arrived at the Spanish settlement at Santo Domingo strongly denounced the enslavement of the local native Americans. Along with other priests, they opposed their treatment as unjust and illegal in an audience with the Spanish king and in the subsequent royal commission.
The Byzantine-Ottoman wars and the Ottoman wars in Europe brought large numbers of slaves into the Islamic world. From the mid to late 14th, through early 18th centuries, the Ottoman devşirme–janissary system enslaved and forcibly converted to Islam an estimated 500,000 to one million non–Muslim (primarily Balkan Christian) adolescent males. After the Battle of Lepanto approximately 12,000 Christian galley slaves were freed from the Ottoman fleet. A few years later Cervantes, who later wrote the famous book Don Quixote, was captured by corsairs and enslaved in Algiers, attempted to escape and was eventually ransomed; he wrote about the plight of Christian slaves in his fiction. Eastern Europe suffered a series of Tatar invasions, the goal of which was to loot and capture slaves into "jasyr". Seventy-five Crimean Tatar raids were recorded into Poland–Lithuania between 1474–1569. There were more than 100,000 Russian captives in the Kazan Khanate alone in 1551.
Approximately 10–20% of the rural population of Carolingian Europe consisted of slaves. In Western Europe slavery largely disappeared by the later Middle Ages. The trade of slaves in England was made illegal in 1102, although England went on to become very active in the lucrative Atlantic slave trade from the seventeenth to the early nineteenth century. Thralldom in Scandinavia was finally abolished in the mid-14th century. Slavery persisted longer in Eastern Europe. Slavery in Poland was forbidden in the 15th century; in Lithuania, slavery was formally abolished in 1588; they were replaced by the second serfdom. In Kievan Rus and Muscovy, the slaves were usually classified as kholops.
Islamic world.
In early Islamic states of the western Sudan, including Ghana (750–1076), Mali (1235–1645), Segou (1712–1861), and Songhai (1275–1591), about a third of the population were enslaved.
Ibn Battuta tells us several times that he was given or purchased slaves. The great 14th-century scholar Ibn Khaldun, wrote: "the Black nations are, as a rule, submissive to slavery, because (Blacks) have little that is (essentially) human and possess attributes that are quite similar to those of dumb animals". Slaves were purchased or captured on the frontiers of the Islamic world and then imported to the major centers, where there were slave markets from which they were widely distributed. In the 9th and 10th centuries, the black Zanj slaves may have constituted at least a half of the total population in lower Iraq. At the same time, many tens of thousands of slaves in the region were also imported from Central Asia and the Caucasus. Many slaves were taken in the wars with the Christian nations of medieval Europe.
Modern history.
Europe.
David P. Forsythe wrote: "In 1649 up to three-quarters of Muscovy's peasants, or 13 to 14 million people, were serfs whose material lives were barely distinguishable from slaves. Perhaps another 1.5 million were formally enslaved, with Russian slaves serving Russian masters. " Slavery remained a major institution in Russia until 1723, when Peter the Great converted the household slaves into house serfs. Russian agricultural slaves were formally converted into serfs earlier in 1679. Russia's more than 23 million privately-held serfs were freed from their lords by an edict of Alexander II in 1861. State-owned serfs were emancipated in 1866.
During the Second World War (1939–1945) Nazi Germany effectively enslaved many people, both those considered undesirable and citizens of countries they conquered.
Africa.
In Senegambia, between 1300 and 1900, close to one-third of the population was enslaved. In Sierra Leone in the 19th century about half of the population consisted of enslaved people.
In the 19th century at least half the population was enslaved among the Duala of the Cameroon, the Igbo and other peoples of the lower Niger, the Kongo, and the Kasanje kingdom and Chokwe of Angola. Among the Ashanti and Yoruba a third of the population consisted of enslaved people.
The population of the Kanem (1600–1800) was about a third-enslaved. It was perhaps 40% in Bornu (1580–1890). Between 1750 and 1900 from one- to two-thirds of the entire population of the Fulani War states consisted of slaves.
The population of the Sokoto caliphate formed by Fulanis and Hausas in northern Nigeria and Cameroon was half-slave in the 19th century. Between 65% to 90% population of Arab-Swahili Zanzibar was enslaved. The Swahili-Arab slave trade reached its height about 150 years ago, when, for example, approximately 20,000 slaves were considered to be carried yearly from Nkhotakota on Lake Malawi to Kilwa. Roughly half the population of Madagascar was enslaved.
According to the "Encyclopedia of African History", "It is estimated that by the 1890s the largest slave population of the world, about 2 million people, was concentrated in the territories of the Sokoto Caliphate. The use of slave labor was extensive, especially in agriculture. " The Anti-Slavery Society estimated there were 2 million slaves in Ethiopia in the early 1930s out of an estimated population of between 8 and 16 million.
Hugh Clapperton in 1824 believed that half the population of Kano were enslaved people. W. A. Veenhoven wrote: "The German doctor, Gustav Nachtigal, an eye-witness, believed that for every slave who arrived at a market three or four died on the way ... Keltie ("The Partition of Africa", London, 1920) believes that for every slave the Arabs brought to the coast at least six died on the way or during the slavers' raid. Livingstone puts the figure as high as ten to one. "
One of the most famous slave traders on the East African coast was Tippu Tip, who was himself the grandson of an enslaved African. The "prazeros" slave traders, descendants of Portuguese and Africans, operated along the Zambezi. North of the Zambezi, the waYao and Makua people played a similar role as professional slave raiders and traders. The Nyamwezi slave traders operated further north under the leadership of Msiri and Mirambo.
Asia.
In Constantinople about one-fifth of the population consisted of slaves. It has been estimated that some 200,000 slaves – mainly Circassians – were imported into the Ottoman Empire between 1800 and 1909. As late as 1908, women slaves were still sold in the Ottoman Empire. A slave market for captured Russian and Persian slaves was centred in the Central Asian khanate of Khiva. In the early 1840s, the population of the Uzbek states of Bukhara and Khiva included about 900,000 slaves. Darrel P. Kaiser wrote, "Kazakh-Kirghiz tribesmen kidnapped 1573 settlers from colonies settlements in Russia in 1774 alone and only half were successfully ransomed. The rest were killed or enslaved. "
According to Sir Henry Bartle Frere (who sat on the Viceroy's Council), there were an estimated 8 or 9 million slaves in India in 1841. About 15% of the population of Malabar were slaves. Slavery was abolished in British India by the Indian Slavery Act V. of 1843.
In East Asia, the Imperial government formally abolished slavery in China in 1906, and the law became effective in 1910. Slave rebellion in China at the end of the 17th and the beginning of the 18th century was so extensive that owners eventually converted the institution into a female-dominated one. The Nangzan in Tibetan history were, according to Chinese sources, hereditary household slaves.
Indigenous slaves existed in Korea. Slavery was officially abolished with the Gabo Reform of 1894 but continued in reality until 1930. During the Joseon Dynasty (1392–1910) about 30% to 50% of the Korean population were slaves. In late 16th century Japan slavery as such was officially banned, but forms of contract and indentured labor persisted alongside the period penal codes' forced labor.
In Southeast Asia, a quarter to a third of seventeenth- to twentieth-century populations in some areas of Thailand and Burma were slaves. The hill tribe people in Indochina were "hunted incessantly and carried off as slaves by the Siamese (Thai), the Anamites (Vietnamese), and the Cambodians. " A Siamese military campaign in Laos in 1876 was described by a British observer as having been "transformed into slave-hunting raids on a large scale". The census, taken in 1879, showed that 6% of the population in the Malay sultanate of Perak were slaves. Enslaved people made up about two-thirds of the population in part of North Borneo in the 1880s.
Americas.
Slavery in the Americas had a contentious history, dating back at least to the Aztecs, and played a major role in the history and evolution of some countries, triggering at least one revolution and one civil war, as well as numerous rebellions. Other Amerindians, such as the Inca of the Andes, the Tupinambá of Brazil, the Creek of Georgia, and the Comanche of Texas, also owned slaves.
Slavery was prominent in Africa, across the Atlantic Ocean from the Americas, long before the beginnings of the transatlantic slave trade. The maritime town of Lagos, Portugal, Europe, was the first slave market created in Portugal (one of the earliest colonizers of the Americas) for the sale of imported African slaves – the "Mercado de Escravos", opened in 1444. In 1441, the first slaves were brought to Portugal from northern Mauritania.
By 1552 black African slaves made up 10 percent of the population of Lisbon. In the second half of the 16th century, the Crown gave up the monopoly on slave trade and the focus of European trade in African slaves shifted from import to Europe to slave transports directly to tropical colonies in the Americas – in the case of Portugal, especially Brazil. In the 15th century one-third of the slaves were resold to the African market in exchange of gold.
Spain had to fight against the relatively powerful civilizations of the New World. The Spanish conquest of the indigenous peoples in the Americas included using the Natives as forced labour, part of the wider Atlantic slave trade. The Spanish colonies were the first Europeans to use African slaves in the New World on islands such as Cuba and Hispaniola.
Bartolomé de Las Casas a 16th-century Dominican friar and Spanish historian participated in campaigns in Cuba (at Bayamo and Camagüey) and was present at the massacre of Hatuey; his observation of that massacre led him to fight for a social movement away from the use of natives as slaves and towards the importation of African Blacks as slaves. Also, the alarming decline in the native population had spurred the first royal laws protecting the native population (Laws of Burgos, 1512–1513).
The first African slaves arrived in Hispaniola in 1501. In 1518, Charles I of Spain agreed to ship slaves directly from Africa. England played a prominent role in the Atlantic slave trade. The "slave triangle" was pioneered by Francis Drake and his associates. A black man named Anthony Johnson of Virginia first introduced permanent black slavery in the 1650s by becoming the first holder in America of permanent black slaves. By 1750, slavery was a legal institution in all of the 13 American colonies, and the profits of the slave trade and of West Indian plantations amounted to 5% of the British economy at the time of the Industrial Revolution.
The Transatlantic slave trade peaked in the late 18th century, when the largest number of slaves were captured on raiding expeditions into the interior of West Africa. These expeditions were typically carried out by African kingdoms, such as the Oyo empire (Yoruba), the Ashanti Empire, the kingdom of Dahomey, and the Aro Confederacy. Europeans rarely entered the interior of Africa, due to fierce African resistance. The slaves were brought to coastal outposts where they were traded for goods.
An estimated 12 million Africans arrived in the Americas from the 16th to the 19th centuries. Of these, an estimated 645,000 were brought to what is now the United States. The usual estimate is that about 15 per cent of slaves died during the voyage, with mortality rates considerably higher in Africa itself in the process of capturing and transporting indigenous peoples to the ships. Approximately 6 million black Africans were killed by others in tribal wars.
The white citizens of Virginia decided to treat the first Africans in Virginia as indentured servants. Over half of all European immigrants to Colonial America during the 17th and 18th centuries arrived as indentured servants. In 1655, John Casor, a black man, became the first legally recognized slave in the present United States. According to the 1860 U. S. census, 393,975 individuals, representing 8% of all US families, owned 3,950,528 slaves. One-third of Southern families owned slaves.
The largest number of slaves were shipped to Brazil. In the Spanish viceroyalty of New Granada, corresponding mainly to modern Panama, Colombia, and Venezuela, the free black population in 1789 was 420,000, whereas African slaves numbered only 20,000. Free blacks also outnumbered slaves in Brazil. In Cuba, by contrast, free blacks made up only 15% in 1827; and in the French colony of Saint-Domingue (present-day Haiti) it was a mere 5% in 1789. Some half-million slaves, most of them born in Africa, worked the booming plantations of Saint-Domingue.
Author Charles Rappleye argued that
Although the trans-Atlantic slave trade ended shortly after the American Revolution, slavery remained a central economic institution in the Southern states of the United States, from where slavery expanded with the westward movement of population. Historian Peter Kolchin wrote, "By breaking up existing families and forcing slaves to relocate far from everyone and everything they knew" this migration "replicated (if on a reduced level) many of horrors" of the Atlantic slave trade.
Historian Ira Berlin called this forced migration the Second Middle Passage. Characterizing it as the "central event" in the life of a slave between the American Revolution and the Civil War, Berlin wrote that whether they were uprooted themselves or simply lived in fear that they or their families would be involuntarily moved, "the massive deportation traumatized black people, both slave and free. "
By 1860, 500,000 slaves had grown to 4 million. As long as slavery expanded, it remained profitable and powerful and was unlikely to disappear. Although complete statistics are lacking, it is estimated that 1,000,000 slaves moved west from the Old South between 1790 and 1860.
Most of the slaves were moved from Maryland, Virginia, and the Carolinas. Michael Tadman, in a 1989 book "Speculators and Slaves: Masters, Traders, and Slaves in the Old South", indicates that 60–70% of interregional migrations were the result of the sale of slaves. In 1820 a child in the Upper South had a 30% chance to be sold south by 1860.
Middle East.
According to Robert Davis between 1 million and 1.25 million Europeans were captured by Barbary pirates and sold as slaves in North Africa and Ottoman Empire between the 16th and 19th centuries. There was also an extensive trade in Christian slaves in the Black Sea region for several centuries until the Crimean Khanate was destroyed by the Russian Empire in 1783. In the 1570s close to 20,000 slaves a year were being sold in the Crimean port of Kaffa. The slaves were captured in southern Russia, Poland-Lithuania, Moldavia, Wallachia, and Circassia by Tatar horsemen in a trade known as the "harvesting of the steppe". In Podolia alone, about one-third of all the villages were destroyed or abandoned between 1578 and 1583. Some researchers estimate that altogether more than 3 million people were captured and enslaved during the time of the Crimean Khanate. It is estimated that up to 75% of the Crimean population consisted of slaves or
freedmen.
The Arab slave trade lasted more than a millennium. As recently as the early 1960s, Saudi Arabia's slave population was estimated at 300,000. Along with Yemen, the Saudis abolished slavery only in 1962. Slaves in the Arab World came from many different regions, including Sub-Saharan Africa (mainly "Zanj"), the Caucasus (mainly Circassians), Central Asia (mainly Tartars), and Central and Eastern Europe (mainly "Saqaliba").
Under Omani Arabs Zanzibar became East Africa's main slave port, with as many as 50,000 enslaved Africans passing through every year during the 19th century. Some historians estimate that between 11 and 18 million African slaves crossed the Red Sea, Indian Ocean, and Sahara Desert from 650 AD to 1900 AD. Eduard Rüppell described the heavy mortality of the enslaved Sudanese before reaching Egypt: "after the Daftardar bey's 1822 campaign in the southern Nuba mountains, nearly 40,000 slaves were captured. However, through bad treatment, disease and desert travel barely 5000 made it to Egypt. "
Central and Eastern European slaves were generally known as Saqaliba (i. e., Slavs). The Moors, starting in the 8th century, also raided coastal areas around the Mediterranean and Atlantic Ocean, and became known as the Barbary pirates. It is estimated that they captured 1.25 million white slaves from Western Europe and North America between the 16th and 19th centuries. The mortality rate was very high. For instance, when plague broke out in Algiers' overcrowded slave pens in 1662, some said that it carried off 10,000–20,000 of the city's 30,000 captives.
Present day.
The number of slaves today remains as high as 12 million to 27 million, even though slavery is now outlawed in all countries. Several estimates of the number of slaves in the world have been provided. According to a broad definition of slavery used by Kevin Bales of Free the Slaves (FTS), an advocacy group linked with Anti-Slavery International, there were 27 million people in slavery in 1999, spread all over the world. In 2005, the International Labour Organization provided an estimate of 12.3 million forced labourers in the world. Siddharth Kara has also provided an estimate of 28.4 million slaves at the end of 2006 divided into the following three categories: bonded labour/debt bondage (18.1 million), forced labour (7.6 million), and trafficked slaves (2.7 million). Kara provides a dynamic model to calculate the number of slaves in the world each year, with an estimated 29.2 million at the end of 2009.
Examples of modern slavery are numerous. In 2008, the Nepalese government abolished the Haliya system of forced labour, freeing about 20,000 people. An estimated 40 million people in India, most of them Dalits or "untouchables", are bonded workers, working in slave-like conditions in order to pay off debts. Though slavery was officially abolished in China in 1910, the practice continues unofficially in some regions of the country. In June and July 2007, 550 people who had been enslaved by brick manufacturers in Shanxi and Henan were freed by the Chinese government. Among those rescued were 69 children. In response, the Chinese government assembled a force of 35,000 police to check northern Chinese brick kilns for slaves, sent dozens of kiln supervisors to prison, punished 95 officials in Shanxi province for dereliction of duty, and sentenced one kiln foreman to death for killing an enslaved worker. The North Korean government operates six large political prison camps, where political prisoners and their families (around 200,000 people) in lifelong detention are subjected to hard slave labor, torture and inhumane treatment. In Brazil more than 5,000 slaves were rescued by authorities in 2008 as part of a government initiative to eradicate slavery. Poverty has forced at least 225,000 Haitian children to work as restavecs (unpaid household servants); the United Nations considers this to be a modern-day form of slavery. 
In Mauritania, the last country to abolish slavery (in 1981), it is estimated that up to 600,000 men, women and children, or 20% of the population, are enslaved with many used as bonded labour. Slavery in Mauritania was criminalized in August 2007. The Middle East Quarterly reports that slavery is still endemic in Sudan. In Niger, slavery is also a current phenomenon. A Nigerien study has found that more than 800,000 people are enslaved, almost 8% of the population. Niger officially abolished slavery in 2003. Many pygmies in the Republic of Congo and Democratic Republic of Congo belong from birth to Bantus in a system of slavery. Some tribal sheiks in Iraq still keep blacks, called "Abd", which means servant or slave in Arabic, as slaves. Child slavery has commonly been used in the production of cash crops and mining. According to the U. S. Department of State, more than 109,000 children were working on cocoa farms alone in Côte d'Ivoire (Ivory Coast) in "the worst forms of child labor" in 2002.
Trafficking in human beings (also called human trafficking) is one method of obtaining slaves. Victims are typically recruited through deceit or trickery (such as a false job offer, false migration offer, or false marriage offer), sale by family members, recruitment by former slaves, or outright abduction. Victims are forced into a "debt slavery" situation by coercion, deception, fraud, intimidation, isolation, threat, physical force, debt bondage or even force-feeding with drugs of abuse to control their victims. "Annually, according to U. S. Government-sponsored research completed in 2006, approximately 800,000 people are trafficked across national borders, which does not include millions trafficked within their own countries. Approximately 80 percent of transnational victims are women and girls and up to 50 percent are minors, " reports the U. S. Department of State in a 2008 study.
While the majority of trafficking victims are women, and sometimes children, who are forced into prostitution (in which case the practice is called sex trafficking), victims also include men, women and children who are forced into manual labour. Due to the illegal nature of human trafficking, its exact extent is unknown. A U. S. Government report published in 2005, estimates that 600,000 to 800,000 people worldwide are trafficked across borders each year. This figure does not include those who are trafficked internally. Another research effort revealed that between 1.5 million and 1.8 million individuals are trafficked either internally or internationally each year, 500,000 to 600,000 of whom are sex trafficking victims.
Abolitionism.
Slavery has existed, in one form or another, through the whole of recorded human history — as have, in various periods, movements to free large or distinct groups of slaves.
The Greek Stoics advocated the brotherhood of humanity and the natural equality of all human beings, and consistently critiqued slavery as against the law of nature. Emperor Wang Mang abolished slave trading (although not slavery) in China in 9 CE.
The Spanish colonization of the Americas sparked a discussion about the right to enslave native Americans. A prominent critic of slavery in the Spanish New World colonies was Bartolomé de las Casas, who opposed the enslavement of Native Americans, and later also of Africans in America.
One of the first protests against the enslavement of Africans came from German and Dutch Quakers in Pennsylvania in 1688. One of the most significant milestones in the campaign to abolish slavery throughout the world occurred in England in 1772, with British judge Lord Mansfield, whose opinion in Somersett's Case was widely taken to have held that slavery was illegal in England. This judgement also laid down the principle that slavery contracted in other jurisdictions (such as the American colonies) could not be enforced in England. In 1777, Vermont became the first portion of what would become the United States to abolish slavery (at the time Vermont was an independent nation). In 1794, under the Jacobins, Revolutionary France abolished slavery. There were celebrations in 2007 to commemorate the 200th anniversary of the Abolition of the slave trade in the United Kingdom through the work of the British Anti-Slavery Society.
William Wilberforce received much of the credit although the groundwork was an anti-slavery essay by Thomas Clarkson. Wilberforce was also urged by his close friend, Prime Minister William Pitt the Younger, to make the issue his own, and was also given support by reformed Evangelical John Newton. The Slave Trade Act was passed by the British Parliament on March 25, 1807, making the slave trade illegal throughout the British Empire, Wilberforce also campaigned for abolition of slavery in the British Empire, which he lived to see in the Slavery Abolition Act 1833. After the 1807 act abolishing the slave trade was passed, these campaigners switched to encouraging other countries to follow suit, notably France and the British colonies. In 1839, the world's oldest international human rights organization, Anti-Slavery International, was formed in Britain by Joseph Sturge, which campaigned to outlaw slavery in other countries.
Between 1808 and 1860, the British West Africa Squadron seized approximately 1,600 slave ships and freed 150,000 Africans who were aboard. Action was also taken against African leaders who refused to agree to British treaties to outlaw the trade, for example against "the usurping King of Lagos", deposed in 1851. Anti-slavery treaties were signed with over 50 African rulers.
In the United States, abolitionist pressure produced a series of small steps towards emancipation. After January 1, 1808, the importation of slaves into the United States was prohibited, but not the internal slave trade, nor involvement in the international slave trade externally. Legal slavery persisted; and those slaves already in the U. S. were legally emancipated only in 1863. Many American abolitionists took an active role in opposing slavery by supporting the Underground Railroad. Violence soon erupted, with the anti-slavery forces led by John Brown, and Bleeding Kansas, involving anti-slavery and pro-slavery settlers, became a symbol for the nationwide clash over slavery. By 1860 the total number of slaves reached almost four million, and the American Civil War, beginning in 1861, led to the end of slavery in the United States.
In 1863 Lincoln issued the Emancipation Proclamation, which freed slaves held in the Confederate States; the 13th Amendment to the U. S. Constitution (1865) prohibited slavery throughout the country.
In the 1860s, David Livingstone's reports of atrocities within the Arab slave trade in Africa stirred up the interest of the British public, reviving the flagging abolitionist movement. The Royal Navy throughout the 1870s attempted to suppress "this abominable Eastern trade", at Zanzibar in particular. In 1905, the French abolished indigenous slavery in most of French West Africa.
Groups such as the American Anti-Slavery Group, Anti-Slavery International, Free the Slaves, the Anti-Slavery Society, and the Norwegian Anti-Slavery Society continue to campaign to rid the world of slavery.
Legal actions.
In November 2006, the International Labour Organization announced it will be seeking "to prosecute members of the ruling Myanmar junta for crimes against humanity" over the continuous unfree labour of its citizens by the military at the International Court of Justice. According to the International Labor Organization (ILO), an estimated 800,000 people are subject to forced labour in Myanmar.
The Ecowas Court of Justice is hearing the case of Hadijatou Mani in late 2008, where Ms. Mani hopes to compel the government of Niger to end slavery in its jurisdiction. Cases brought by her in local courts have failed so far.
Economics.
Economists have attempted to model the circumstances under which slavery (and variants such as serfdom) appear and disappear. One observation is that slavery becomes more desirable for landowners where land is abundant but labour is scarce, such that rent is depressed and paid workers can demand high wages. If the opposite holds true, then it becomes more costly for landowners to have guards for the slaves than to employ paid workers who can only demand low wages due to the amount of competition. Thus, first slavery and then serfdom gradually decreased in Europe as the population grew, but were reintroduced in the Americas and in Russia as large areas of new land with few people became available. In his books, "" and "Without Consent or Contract: the Rise and Fall of American Slavery, " Robert Fogel maintains that slavery was in fact a profitable method of production, especially on bigger plantations growing cotton that fetched high prices in the world market. It gave whites in the South higher average incomes than those in the North, but most of the money was spent on buying slaves and plantations.
Slavery is more common when the labour done is relatively simple and thus easy to supervise, such as large scale growing of a single crop. It is much more difficult and costly to check that slaves are doing their best and with good quality when they are doing complex tasks. Therefore, slavery was seen as the most efficient method of production for large scale crops like sugar and cotton, whose output was based on economies of scale. This enabled a gang system of labor to be prominent on large plantations where field hands were monitored and worked with factory-like precision. Each work gang was based on an internal division of labor that not only assigned every member of the gang to a precise task but simultaneously made his or her performance dependent on the actions of the others. The hoe hands chopped out the weeds that surrounded the cotton plants as well as excessive sprouts. The plow gangs followed behind, stirring the soil near the rows of cotton plants and tossing it back around the plants. Thus, the gang system worked like an early version of the assembly line later to be found in factories.
Critics since the 18th century have argued that slavery tends to retard technological advancement, since the focus is on increasing the number of slaves doing simple tasks rather than upgrading the efficiency of labour. Because of this, theoretical knowledge and learning in Greece—and later in Rome—was not applied to ease physical labour or improve manufacturing.
Adam Smith made the argument that free labor was economically better than slave labor, and argued further that slavery in Europe ended during the Middle Ages, and then only after both the church and state were separate, independent and strong institutions, that it is nearly impossible to end slavery in a free, democratic and republican forms of governments since many of its legislators or political figures were slave owners, and would not punish themselves, and that slaves would be better able to gain their freedom when there was centralized government, or a central authority like a king or the church. Similar arguments appear later in the works of Auguste Comte, especially when it comes to Adam Smith's belief in the separation of powers or what Comte called the "separation of the spiritual and the temporal" during the Middle Ages and the end of slavery, and Smith's criticism of masters, past and present. As Smith stated in the Lectures on Jurisprudence, "The great power of the clergy thus concurring with that of the king set the slaves at liberty. But it was absolutely necessary both that the authority of the king and of the clergy should be great. Where ever any one of these was wanting, slavery still continues. "
The weighted average global sales price of a slave is calculated to be approximately $340, with a high of $1,895 for the average trafficked sex slave, and a low of $40 to $50 for debt bondage slaves in part of Asia and Africa.
Worldwide slavery is a criminal offense but slave owners can get very high returns for their risk. According to researcher Siddharth Kara, the profits generated worldwide by all forms of slavery in 2007 were $91.2 billion. That is second only to drug trafficking in terms of global criminal enterprises. The weighted average annual profits generated by a slave in 2007 was $3,175, with a low of an average $950 for bonded labor and $29,210 for a trafficked sex slave. Approximately forty percent of all slave profits each year are generated by trafficked sex slaves, representing slightly more than 4 percent of the world's 29 million slaves.
Robert E. Wright has developed a model that helps to predict when firms (individuals, companies) will be more likely to use slaves rather than wage workers, indentured servants, family members, or other types of laborers.
Apologies.
On May 21, 2001, the National Assembly of France passed the Taubira law, recognizing slavery as a crime against humanity. Apologies on behalf of African nations, for their role in trading their countrymen into slavery, remain an open issue since slavery was practiced in Africa even before the first Europeans arrived and the Atlantic slave trade was performed with a high degree of involvement of several African societies. The black slave market was supplied by well-established slave trade networks controlled by local African societies and individuals. Indeed, as already mentioned in this article, slavery persists in several areas of West Africa until the present day.

Several historians have made important contributions to the global understanding of the African side of the Atlantic slave trade. By arguing that African merchants determined the assemblage of trade goods accepted in exchange for slaves, many historians argue for African agency and ultimately a shared responsibility for the slave trade.
The issue of an apology is linked to reparations for slavery and is still being pursued by a number of entities across the world. For example, the Jamaican Reparations Movement approved its declaration and action Plan.
In September 2006, it was reported that the UK government might issue a "statement of regret" over slavery. This was followed by a "public statement of sorrow" from Tony Blair on November 27, 2006, and a formal apology on March 14, 2007.
On February 25, 2007 the state of Virginia resolved to 'profoundly regret' and apologize for its role in the institution of slavery. Unique and the first of its kind in the U. S., the apology was unanimously passed in both Houses as Virginia approached the 400th anniversary of the founding of Jamestown, where the first slaves were imported into North America in 1619.
Liverpool, which was a large slave trading port, apologized in 1999. On August 24, 2007, Mayor Ken Livingstone of London, United Kingdom apologized publicly for Britain's role in colonial slave trade. "You can look across there to see the institutions that still have the benefit of the wealth they created from slavery, " he said pointing towards the financial district. He claimed that London was still tainted by the horrors of slavery. Specifically, London outfitted, financed, and insured many of the ships, which helped fund the building of London's docks. Jesse Jackson praised Livingstone, and added that reparations should be made, one of his common arguments.
On July 30, 2008, the United States House of Representatives passed a resolution apologizing for American slavery and subsequent discriminatory laws. In June 2009, the US Senate passed a resolution apologizing to African-Americans for the "fundamental injustice, cruelty, brutality, and inhumanity of slavery".
Reparations.
There have been movements to achieve reparations for those formerly held as slaves, or sometimes their descendants. Claims for reparations for being held in slavery are handled as a civil law matter in almost every country. This is often decried as a serious problem, since former slaves' relative lack of money means they often have limited access to a potentially expensive and futile legal process. Mandatory systems of fines and reparations paid to an as yet undetermined group of claimants from fines, paid by unspecified parties, and collected by authorities have been proposed by advocates to alleviate this "civil court problem. " Since in almost all cases there are no living ex-slaves or living ex-slave owners these movements have gained little traction. In nearly all cases the judicial system has ruled that the statute of limitations on these possible claims has long since expired.
Other uses of the term.
The word "slavery" is often used as a pejorative to describe any activity in which one is coerced into performing.

World War I
World War I (WWI) was a global war centred in Europe that began on 28 July 1914 and lasted until 11 November 1918. It was predominantly called the World War or the Great War from its occurrence until the start of World War II in 1939, and the First World War or World War I thereafter. It involved all the world's great powers, which were assembled in two opposing alliances: the Allies (based on the Triple Entente of the United Kingdom, France and Russia) and the Central Powers (originally centred around the Triple Alliance of Germany, Austria-Hungary and Italy; but, as Austria–Hungary had taken the offensive against the agreement, Italy did not enter into the war). These alliances both reorganised (Italy fought for the Allies) and expanded as more nations entered the war. Ultimately more than 70 million military personnel, including 60 million Europeans, were mobilised in one of the largest wars in history. More than 9 million combatants were killed, largely because of technological advancements that led to enormous increases in the lethality of weapons without corresponding improvements in protection or mobility. It was the sixth-deadliest conflict in world history, subsequently paving the way for various political changes such as revolutions in many of the nations involved.
Long-term causes of the war included the imperialistic foreign policies of the great powers of Europe, including the German Empire, the Austro-Hungarian Empire, the Ottoman Empire, the Russian Empire, the British Empire, the French Republic, and Italy. The assassination on 28 June 1914 of Archduke Franz Ferdinand of Austria, the heir to the throne of Austria-Hungary, by a Yugoslav nationalist in Sarajevo, Bosnia and Herzegovina was the proximate trigger of the war. It resulted in a Habsburg ultimatum against the Kingdom of Serbia. Several alliances formed over the previous decades were invoked, so within weeks the major powers were at war; via their colonies, the conflict soon spread around the world.
On 28 July, the conflict opened with the Austro-Hungarian invasion of Serbia, followed by the German invasion of Belgium, Luxembourg and France; and a Russian attack against Germany. After the German march on Paris was brought to a halt, the Western Front settled into a static battle of attrition with a trench line that changed little until 1917. In the East, the Russian army successfully fought against the Austro-Hungarian forces but was forced back from East Prussia and Poland by the German army. Additional fronts opened after the Ottoman Empire joined the war in 1914, Italy and Bulgaria in 1915 and Romania in 1916. The Russian Empire collapsed in March 1917, and Russia left the war after the October Revolution later that year. After a 1918 German offensive along the western front, the Allies drove back the German armies in a series of successful offensives and United States forces began entering the trenches. Germany, which had its own trouble with revolutionaries at this point, agreed to a cease-fire on 11 November 1918, later known as Armistice Day. The war had ended in victory for the Allies.
Events on the home fronts were as tumultuous as on the battle fronts, as the participants tried to mobilize their manpower and economic resources to fight a total war. By the end of the war, four major imperial powers—the German, Russian, Austro-Hungarian and Ottoman empires—ceased to exist. The successor states of the former two lost a great amount of territory, while the latter two were dismantled entirely. The map of central Europe was redrawn into several smaller states. The League of Nations was formed in the hope of preventing another such conflict. The European nationalism spawned by the war and the breakup of empires, the repercussions of Germany's defeat and problems with the Treaty of Versailles are agreed to be factors contributing to World War II.
Names.
In Canada, "Maclean's Magazine" in October 1914 said, "Some wars name themselves. This is the Great War." A history of the origins and early months of the war published in New York in late 1914 was titled "The World War". During the Interwar period, the war was most often called the "World War" and the "Great War" in English-speaking countries.
After the onset of the Second World War in 1939, the terms "World War I" or "the First World War" became standard, with British and Canadian historians favouring the "First World War", and Americans "World War I". Both of these terms had also been used during the Interwar period. The term "First World War" was first used in September 1914 by the German philosopher Ernst Haeckel, who claimed that "there is no doubt that the course and character of the feared 'European War' ... will become the first world war in the full sense of the word." "The First World War" was also the title of a 1920 history by the officer and journalist Charles à Court Repington.
Background.
In the 19th century, the major European powers had gone to great lengths to maintain a balance of power throughout Europe, resulting by 1900 in a complex network of political and military alliances throughout the continent. These had started in 1815, with the Holy Alliance between Prussia, Russia, and Austria. Then, in October 1873, German Chancellor Bismarck negotiated the League of the Three Emperors (German: "Dreikaiserbund") between the monarchs of Austria–Hungary, Russia and Germany. This agreement failed because Austria–Hungary and Russia could not agree over Balkan policy, leaving Germany and Austria–Hungary in an alliance formed in 1879, called the Dual Alliance. This was seen as a method of countering Russian influence in the Balkans as the Ottoman Empire continued to weaken. In 1882, this alliance was expanded to include Italy in what became the Triple Alliance.
After 1870, European conflict was averted largely through a carefully planned network of treaties between the German Empire and the remainder of Europe orchestrated by Bismarck. He especially worked to hold Russia at Germany's side to avoid a two-front war with France and Russia. When Wilhelm II ascended to the throne as German Emperor ("Kaiser"), Bismarck was compelled to retire and his system of alliances was gradually de-emphasised. For example, the Kaiser refused to renew the Reinsurance Treaty with Russia in 1890. Two years later, the Franco-Russian Alliance was signed to counteract the force of the Triple Alliance. In 1904, the United Kingdom signed a series of agreements with France, the Entente Cordiale, and in 1907, the United Kingdom and Russia signed the Anglo-Russian Convention. While these agreements did not formally ally the United Kingdom with France or Russia, they made British entry into any future conflict involving France or Russia probable, and the system of interlocking bilateral agreements became known as the Triple Entente.
German industrial and economic power had grown greatly after unification and the foundation of the Empire in 1871. From the mid-1890s on, the government of Wilhelm II used this base to devote significant economic resources to building up the "Kaiserliche Marine" (Imperial German Navy), established by Admiral Alfred von Tirpitz, in rivalry with the British Royal Navy for world naval supremacy. As a result, each nation strove to out-build the other in terms of capital ships. With the launch of in 1906, the British Empire expanded on its significant advantage over its German rival. The arms race between Britain and Germany eventually extended to the rest of Europe, with all the major powers devoting their industrial base to producing the equipment and weapons necessary for a pan-European conflict. Between 1908 and 1913, the military spending of the European powers increased by 50 percent.
Austria-Hungary precipitated the Bosnian crisis of 1908–1909 by officially annexing the former Ottoman territory of Bosnia and Herzegovina, which it had occupied since 1878. This angered the Kingdom of Serbia and its patron, the Pan-Slavic and Orthodox Russian Empire. Russian political manoeuvring in the region destabilised peace accords that were already fracturing in what was known as "the powder keg of Europe".
In 1912 and 1913 the First Balkan War was fought between the Balkan League and the fracturing Ottoman Empire. The resulting Treaty of London further shrank the Ottoman Empire, creating an independent Albanian State while enlarging the territorial holdings of Bulgaria, Serbia, Montenegro, and Greece. When Bulgaria attacked both Serbia and Greece on 16 June 1913, it lost most of Macedonia to Serbia and Greece and Southern Dobruja to Romania in the 33-day Second Balkan War, further destabilising the region.
On 28 June 1914, Gavrilo Princip, a Bosnian Serb student and member of Young Bosnia, assassinated the heir to the Austro-Hungarian throne, Archduke Franz Ferdinand of Austria in Sarajevo, Bosnia. This began a month of diplomatic manoeuvring among Austria-Hungary, Germany, Russia, France, and Britain called the July Crisis. Wanting to finally end Serbian interference in Bosnia, Austria-Hungary delivered the July Ultimatum to Serbia, a series of ten demands intentionally made unacceptable, intending to provoke a war with Serbia. When Serbia agreed to only eight of the ten demands, Austria-Hungary declared war on 28 July 1914. Strachan argues, "Whether an equivocal and early response by Serbia would have made any difference to Austria-Hungary's behaviour must be doubtful. Franz Ferdinand was not the sort of personality who commanded popularity, and his demise did not cast the empire into deepest mourning".
The Russian Empire, unwilling to allow Austria–Hungary to eliminate its influence in the Balkans, and in support of its longtime Serb protégés, ordered a partial mobilisation one day later. The German Empire mobilized on 30 July 1914, ready to apply the "Schlieffen Plan" which planned a quick, massive invasion of France to eliminate the French army, then to turn east against Russia. The French cabinet resisted to the military pressure on immediate mobilisation, and ordered its troops to withdraw 10 km from the border to avoid any incident. France mobilized only on the evening of August 2nd, when Germany invaded Belgium and attacked French troops. Germany declared war on Russia on the same day. The United Kingdom declared war on Germany on 4 August 1914, following an "unsatisfactory reply" to the British ultimatum that Belgium must be kept neutral.
Theatres of conflict.
Opening hostilities.
Confusion among the Central Powers.
The strategy of the Central Powers suffered from miscommunication. Germany had promised to support Austria-Hungary's invasion of Serbia, but interpretations of what this meant differed. Previously tested deployment plans had been replaced early in 1914, but the replacements had never been tested in exercises. Austro-Hungarian leaders believed Germany would cover its northern flank against Russia. Germany, however, envisioned Austria-Hungary directing most of its troops against Russia, while Germany dealt with France. This confusion forced the Austro-Hungarian Army to divide its forces between the Russian and Serbian fronts.
On 9 September 1914, the "Septemberprogramm", a possible plan which detailed Germany's specific war aims and the conditions that Germany sought to force on the Allied Powers, was outlined by German Chancellor Theobald von Bethmann-Hollweg. It was never officially adopted.
African campaigns.
Some of the first clashes of the war involved British, French, and German colonial forces in Africa. On 7 August, French and British troops invaded the German protectorate of Togoland. On 10 August, German forces in South-West Africa attacked South Africa; sporadic and fierce fighting continued for the rest of the war. The German colonial forces in German East Africa, led by Colonel Paul Emil von Lettow-Vorbeck, fought a guerrilla warfare campaign during World War I and only surrendered two weeks after the armistice took effect in Europe.
Serbian campaign.
Austria invaded and fought the Serbian army at the Battle of Cer and Battle of Kolubara beginning on 12 August. Over the next two weeks Austrian attacks were thrown back with heavy losses, which marked the first major Allied victories of the war and dashed Austro-Hungarian hopes of a swift victory. As a result, Austria had to keep sizable forces on the Serbian front, weakening its efforts against Russia. Serbia’s defeat of the Austro-Hungarian invasion of 1914 counts among the major upset victories of the last century.
German forces in Belgium and France.
At the outbreak of the First World War, the German army (consisting in the West of seven field armies) carried out a modified version of the Schlieffen Plan, designed to quickly attack France through neutral Belgium before turning southwards to encircle the French army on the German border.. Since France had declared that it would "keep full freedom of acting in case of a war between Germany and Russia", Germany had to expect the possibility of an attack on two fronts. To such a scenario the Schlieffen Plan stated that Germany must try to defeat France quickly (as had happened in the Franco-Prussian War of 1870-71). It further suggested that to repeat a fast victory in the west, Germany should not attack through Alsace-Lorraine (which had a direct border west of the river Rhine), the idea was instead to try to in a hurry cut Paris of from the English Channel (independent of Great Britain). Then the armies should be moved over to the east to meet Russia. Russia was believed to need a long time of preparations before they could become a real threat to the Central Powers.
Germany wanted free escort through Belgium (and originally Holland as well, which though Kaiser Wilhelm II rejected) to meet France by its borders. The answer from the neutral Belgium was of course "no". Then Germany needed to invade Belgium instead, since this was the only existing plan in case of a two-front war for Germany. However also France wanted to move their troops into Belgium, but Belgium originally rejected this "suggestion" as well, in hope of avoiding any war on Belgian soil. In the end, after the German invasion, Belgium did though try to join their army with the French (but a large part of the Belgian army retreated to Antwerp where they were forced to surrender when all hope of help was out). 
The plan called for the right flank of the German advance to converge on Paris, and initially the Germans were successful, particularly in the Battle of the Frontiers (14–24 August). By 12 September, the French, with assistance from the British forces, halted the German advance east of Paris at the First Battle of the Marne (5–12 September), and pushed the German forces some 50 km back. The last days of this battle signified the end of mobile warfare in the west. The French offensive into Southern Alsace, launched on 20th August with the Battle of Mulhouse, had limited success.
In the east, only one field army, the 8th was rapidly moved by rail across the German Empire. This army was led by general Paul von Hindenburg from being a reserve army in the west they defended East Prussia, after the (from German point of view) surprisingly early Russian invasion with two armies. Germany defeated Russia in a series of battles collectively known as the First Battle of Tannenberg (17 August – 2 September). But the failed Russian invasion most probably caused the German attack in the west to a sudden stop and tactical defeat by the French Army at Marne. The German soldiers had become tired and the reserve forces had been moved to meet the Russian invasion. The German General Staff under general Helmuth von Moltke the Younger had also foreseen that the use of fast troop transports by rail did not work as expected outside the German Empire. The Central Powers were denied a quick victory in France and forced to fight a war on two fronts. The German army had fought its way into a good defensive position inside France and had permanently incapacitated 230,000 more French and British troops than it had lost itself. Despite this, communications problems and questionable command decisions cost Germany the chance of early victory.
Asia and the Pacific.
New Zealand occupied German Samoa (later Western Samoa) on 30 August 1914. On 11 September, the Australian Naval and Military Expeditionary Force landed on the island of Neu Pommern (later New Britain), which formed part of German New Guinea. On 28 October, the cruiser "SMS Emden" sunk the Russian cruiser Zhemchug in the Battle of Penang. Japan seized Germany's Micronesian colonies and, after the Siege of Tsingtao, the German coaling port of Qingdao in the Chinese Shandong peninsula. Within a few months, the Allied forces had seized all the German territories in the Pacific; only isolated commerce raiders and a few holdouts in New Guinea remained.
Western Front.
Trench warfare begins (1914–1915).
Military tactics before World War I had failed to keep pace with advances in technology. These advances allowed for impressive defence systems, which out-of-date military tactics could not break through for most of the war. Barbed wire was a significant hindrance to massed infantry advances. Artillery, vastly more lethal than in the 1870s, coupled with machine guns, made crossing open ground extremely difficult. The Germans introduced poison gas; it soon became used by both sides, though it never proved decisive in winning a battle. Its effects were brutal, causing slow and painful death, and poison gas became one of the most-feared and best-remembered horrors of the war. Commanders on both sides failed to develop tactics for breaching entrenched positions without heavy casualties. In time, however, technology began to produce new offensive weapons, such as the tank. 
After the First Battle of the Marne (5–12 September 1914), both Entente and German forces began a series of outflanking manoeuvres, in the so-called "Race to the Sea". Britain and France soon found themselves facing entrenched German forces from Lorraine to Belgium's coast. Britain and France sought to take the offensive, while Germany defended the occupied territories. Consequently, German trenches were much better constructed than those of their enemy; Anglo-French trenches were only intended to be "temporary" before their forces broke through German defences. 
Both sides tried to break the stalemate using scientific and technological advances. On 22 April 1915 at the Second Battle of Ypres, the Germans (violating the Hague Convention) used chlorine gas for the first time on the Western Front. Algerian troops retreated when gassed and a six-kilometre (four-mile) hole opened in the Allied lines that the Germans quickly exploited, taking Kitcheners' Wood, before Canadian soldiers closed the breach. Tanks were first used in combat by the British during the Battle of Flers-Courcelette (part of the wider Somme offensive) on 15 September 1916 with only partial success; the French introduced the revolving turret of the Renault FT in late 1917; the Germans employed captured Allied tanks and small numbers of their own design.
Trench warfare continues (1916–1917).
Neither side proved able to deliver a decisive blow for the next two years. Around 1.1 to 1.2 million soldiers from the British and Dominion armies were on the Western Front at any one time. A thousand battalions, occupying sectors of the line from the North Sea to the Orne River, operated on a month-long four-stage rotation system, unless an offensive was underway. The front contained over of trenches. Each battalion held its sector for about a week before moving back to support lines and then further back to the reserve lines before a week out-of-line, often in the Poperinge or Amiens areas.
Throughout 1915–17, the British Empire and France suffered more casualties than Germany, because of both the strategic and tactical stances chosen by the sides. Strategically, while the Germans only mounted a single main offensive at Verdun, the Allies made several attempts to break through German lines. 
On 1 July 1916, the British Army endured the bloodiest day in its history, suffering 57,470 casualties, including 19,240 dead, on the first day of the Battle of the Somme. Most of the casualties occurred in the first hour of the attack. The entire Somme offensive cost the British Army almost half a million men.
Protracted German action at Verdun throughout 1916, combined with the bloodletting at the Somme (July and August 1916), brought the exhausted French army to the brink of collapse. Futile attempts at frontal assault came at a high price for both the British and the French "poilu" and led to widespread mutinies in 1917, after the costly Nivelle Offensive (April and May 1917).
Tactically, German commander Erich Ludendorff's doctrine of "elastic defence" was well suited for trench warfare. This defence had a lightly defended forward position and a more powerful main position farther back beyond artillery range, from which an immediate and powerful counter-offensive could be launched.
Ludendorff wrote on the fighting in 1917, 
On the battle of the Menin Road Ridge, Ludendorff wrote, 
In the 1917 Battle of Arras, the only significant British military success was the capture of Vimy Ridge by the Canadian Corps under Sir Arthur Currie and Julian Byng. The assaulting troops could – for the first time – overrun, rapidly reinforce, and hold the ridge defending the coal-rich Douai plain.
Naval war.
At the start of the war, the German Empire had cruisers scattered across the globe, some of which were subsequently used to attack Allied merchant shipping. The British Royal Navy systematically hunted them down, though not without some embarrassment from its inability to protect Allied shipping. For example, the German detached light cruiser SMS "Emden", part of the East-Asia squadron stationed at Tsingtao, seized or destroyed 15 merchantmen, as well as sinking a Russian cruiser and a French destroyer. However, most of the German East-Asia squadron—consisting of the armoured cruisers and , light cruisers and and two transport ships—did not have orders to raid shipping and was instead underway to Germany when it met British warships. The German flotilla and sank two armoured cruisers at the Battle of Coronel, but was almost destroyed at the Battle of the Falkland Islands in December 1914, with only "Dresden" and a few auxiliaries escaping, but at the Battle of Más a Tierra these too were destroyed or interned.
Soon after the outbreak of hostilities, Britain began a naval blockade of Germany. The strategy proved effective, cutting off vital military and civilian supplies, although this blockade violated accepted international law codified by several international agreements of the past two centuries. Britain mined international waters to prevent any ships from entering entire sections of ocean, causing danger to even neutral ships. Since there was limited response to this tactic, Germany expected a similar response to its unrestricted submarine warfare.
The 1916 Battle of Jutland (German: "Skagerrakschlacht", or "Battle of the Skagerrak") developed into the largest naval battle of the war, the only full-scale clash of battleships during the war, and one of the largest in history. It took place on 31 May – 1 June 1916, in the North Sea off Jutland. The Kaiserliche Marine's High Seas Fleet, commanded by Vice Admiral Reinhard Scheer, squared off against the Royal Navy's Grand Fleet, led by Admiral Sir John Jellicoe. The engagement was a stand off, as the Germans, outmanoeuvred by the larger British fleet, managed to escape and inflicted more damage to the British fleet than they received. Strategically, however, the British asserted their control of the sea, and the bulk of the German surface fleet remained confined to port for the duration of the war.
German U-boats attempted to cut the supply lines between North America and Britain. The nature of submarine warfare meant that attacks often came without warning, giving the crews of the merchant ships little hope of survival. The United States launched a protest, and Germany changed its rules of engagement. After the sinking of the passenger ship RMS "Lusitania" in 1915, Germany promised not to target passenger liners, while Britain armed its merchant ships, placing them beyond the protection of the "cruiser rules" which demanded warning and placing crews in "a place of safety" (a standard which lifeboats did not meet). Finally, in early 1917 Germany adopted a policy of unrestricted submarine warfare, realising the Americans would eventually enter the war. Germany sought to strangle Allied sea lanes before the U.S. could transport a large army overseas, but could maintain only five long-range U-boats on station, to limited effect.
The U-boat threat lessened in 1917, when merchant ships began travelling in convoys, escorted by destroyers. This tactic made it difficult for U-boats to find targets, which significantly lessened losses; after the hydrophone and depth charges were introduced, accompanying destroyers might attack a submerged submarine with some hope of success. Convoys slowed the flow of supplies, since ships had to wait as convoys were assembled. The solution to the delays was an extensive program to build new freighters. Troopships were too fast for the submarines and did not travel the North Atlantic in convoys. The U-boats had sunk more than 5,000 Allied ships, at a cost of 199 submarines.
World War I also saw the first use of aircraft carriers in combat, with HMS "Furious" launching Sopwith Camels in a successful raid against the Zeppelin hangars at Tondern in July 1918, as well as blimps for antisubmarine patrol.
Southern theatres.
War in the Balkans.
Faced with Russia, Austria-Hungary could spare only one-third of its army to attack Serbia. After suffering heavy losses, the Austrians briefly occupied the Serbian capital, Belgrade. A Serbian counterattack in the battle of Kolubara, however, succeeded in driving them from the country by the end of 1914. For the first ten months of 1915, Austria-Hungary used most of its military reserves to fight Italy. German and Austro-Hungarian diplomats, however, scored a coup by persuading Bulgaria to join in attacking Serbia. The Austro-Hungarian provinces of Slovenia, Croatia and Bosnia provided troops for Austria-Hungary, invading Serbia as well as fighting Russia and Italy. Montenegro allied itself with Serbia.
Serbia was conquered in a little more than a month, as the Central Powers, now including Bulgaria, sent in 600,000 troops. The Serbian army, fighting on two fronts and facing certain defeat, retreated into northern Albania (which they had invaded at the beginning of the war). The Serbs suffered defeat in the Battle of Kosovo. Montenegro covered the Serbian retreat towards the Adriatic coast in the Battle of Mojkovac in 6–7 January 1916, but ultimately the Austrians conquered Montenegro, too. The surviving 70,000 Serbian soldiers were evacuated by ship to Greece.
In late 1915, a Franco-British force landed at Salonica in Greece, to offer assistance and to pressure the government to declare war against the Central Powers. Unfortunately for the Allies, the pro-German King Constantine I dismissed the pro-Allied government of Eleftherios Venizelos, before the Allied expeditionary force could arrive. The friction between the king of Greece and the Allies continued to accumulate with the National Schism, which effectively divided Greece between regions still loyal to the king and the new provisional government of Venizelos in Salonica. After intensive diplomatic negotiations and an armed confrontation in Athens between Allied and royalist forces (an incident known as Noemvriana) the king of Greece resigned, and his second son Alexander took his place. Venizelos returned to Athens on 29 May 1917 and Greece, now unified, officially joined the war on the side of the Allies. The entire Greek army was mobilized and began to participate in military operations against the Central Powers on the Macedonian front.
After conquest, Serbia was divided between Austro-Hungary and Bulgaria. In 1917 the Serbs launched the Toplica Uprising and liberated for a short time the area between the Kopaonik mountains and the South Morava river. The uprising was crushed by joint efforts of Bulgarian and Austrian forces at the end of March 1917.
The Macedonian Front in the beginning was mostly static. French and Serbian forces retook limited areas of Macedonia by recapturing Bitola on 19 November 1916 as a result of the costly Monastir Offensive which brought stabilization of the front.
Serbian and French troops finally made a breakthrough, after most of the German and Austro-Hungarian troops had withdrawn. This breakthrough was significant in defeating Bulgaria and Austro-Hungary, which led to the final victory of WWI. The Bulgarians suffered their only defeat of the war at the Battle of Dobro Pole but days later, they decisively defeated British and Greek forces at the Battle of Doiran, avoiding occupation. After Serbian breakthrough of Bulgarian lines, Bulgaria capitulated on 29 September 1918. Hindenburg and Ludendorff concluded that the strategic and operational balance had now shifted decidedly against the Central Powers and a day after the Bulgarian collapse, during a meeting with government officials, insisted on an immediate peace settlement.
The disappearance of the Macedonian front meant that the road to Budapest and Vienna was now opened for the 670,000-strong army of general Franchet d'Esperey as the Bulgarian surrender deprived the Central Powers of the 278 infantry battalions and 1,500 guns (the equivalent of some 25 to 30 German divisions) that were previously holding the line. The German high command responded by sending only seven infantry and one cavalry division but these forces were far from enough for a front to be reestablished.
Ottoman Empire.
The Ottoman Empire joined the Central Powers in the war, the secret Ottoman-German Alliance having been signed in August 1914. It threatened Russia's Caucasian territories and Britain's communications with India via the Suez Canal. The British and French opened overseas fronts with the Gallipoli (1915) and Mesopotamian campaigns. In Gallipoli, the Ottoman Empire successfully repelled the British, French, and Australian and New Zealand Army Corps (ANZACs). In Mesopotamia, by contrast, after the disastrous Siege of Kut (1915–16), British Imperial forces reorganised and captured Baghdad in March 1917.
Further to the west, the Suez Canal was successfully defended from Ottoman attacks in 1915 and 1916; in August a joint German and Ottoman force was defeated at the Battle of Romani by the Anzac Mounted and the 52nd (Lowland) Infantry Divisions. Following this victory, a British Empire Egyptian Expeditionary Force advanced across the Sinai Peninsula, pushing Ottoman forces back in the Battle of Magdhaba in December and the Battle of Rafa on the border between the Egyptian Sinai and Ottoman Palestine in January 1917.
Russian armies generally had the best of it in the Caucasus. Enver Pasha, supreme commander of the Ottoman armed forces, was ambitious and dreamed of re-conquering central Asia and areas that had been lost to Russia previously. He was, however, a poor commander. He launched an offensive against the Russians in the Caucasus in December 1914 with 100,000 troops; insisting on a frontal attack against mountainous Russian positions in winter, he lost 86% of his force at the Battle of Sarikamish.
General Yudenich, the Russian commander from 1915 to 1916, drove the Turks out of most of the southern Caucasus with a string of victories. In 1917, Russian Grand Duke Nicholas assumed command of the Caucasus front. Nicholas planned a railway from Russian Georgia to the conquered territories, so that fresh supplies could be brought up for a new offensive in 1917. However, in March 1917 (February in the pre-revolutionary Russian calendar), the Czar was overthrown in the February Revolution and the Russian Caucasus Army began to fall apart.
Instigated by the Arab bureau of the British Foreign Office, the Arab Revolt started with the help of Britain in June 1916 at the Battle of Mecca, led by Sherif Hussein of Mecca, and ended with the Ottoman surrender of Damascus. Fakhri Pasha, the Ottoman commander of Medina, resisted for more than two and half years during the Siege of Medina.
Along the border of Italian Libya and British Egypt, the Senussi tribe, incited and armed by the Turks, waged a small-scale guerrilla war against Allied troops. The British were forced to dispatch 12,000 troops to oppose them in the Senussi Campaign. Their rebellion was finally crushed in mid-1916.
Italian participation.
Italy had been allied with the German and Austro-Hungarian Empires since 1882 as part of the Triple Alliance. However, the nation had its own designs on Austrian territory in Trentino, Istria, and Dalmatia. Rome had a secret 1902 pact with France, effectively nullifying its alliance. At the start of hostilities, Italy refused to commit troops, arguing that the Triple Alliance was defensive and that Austria–Hungary was an aggressor. The Austro-Hungarian government began negotiations to secure Italian neutrality, offering the French colony of Tunisia in return. The Allies made a counter-offer in which Italy would receive the Southern Tyrol, Julian March and territory on the Dalmatian coast after the defeat of Austria-Hungary. This was formalised by the Treaty of London. Further encouraged by the Allied invasion of Turkey in April 1915, Italy joined the Triple Entente and declared war on Austria-Hungary on 23 May. Fifteen months later Italy declared war on Germany.
Militarily, the Italians had numerical superiority. This advantage, however, was lost, not only because of the difficult terrain in which fighting took place, but also because of the strategies and tactics employed. Field Marshal Luigi Cadorna, a staunch proponent of the frontal assault, had dreams of breaking into the Slovenian plateau, taking Ljubljana and threatening Vienna. Cadorna's plan did not take into account the difficulties of the rugged Alpine terrain, or the technological changes that created trench warfare, giving rise to a series of bloody and inconclusive stalemated offensives.
On the Trentino front, the Austro-Hungarians took advantage of the mountainous terrain, which favoured the defender. After an initial strategic retreat, the front remained largely unchanged, while Austrian Kaiserschützen and Standschützen engaged Italian Alpini in bitter hand-to-hand combat throughout the summer. The Austro-Hungarians counterattacked in the Altopiano of Asiago, towards Verona and Padua, in the spring of 1916 ("Strafexpedition"), but made little progress.
Beginning in 1915, the Italians under Cadorna mounted eleven offensives on the Isonzo front along the Isonzo River, northeast of Trieste. All eleven offensives were repelled by the Austro-Hungarians, who held the higher ground. In the summer of 1916, the Italians captured the town of Gorizia. After this minor victory, the front remained static for over a year, despite several Italian offensives. In the autumn of 1917, thanks to the improving situation on the Eastern front, the Austro-Hungarian troops received large numbers of reinforcements, including German Stormtroopers and the elite Alpenkorps. 
The Central Powers launched a crushing offensive on 26 October 1917, spearheaded by the Germans. They achieved a victory at Caporetto. The Italian Army was routed and retreated more than to reorganise, stabilising the front at the Piave River. Since in the Battle of Caporetto the Italian Army had heavy losses, the Italian Government called to arms the so-called '"99 Boys" ("Ragazzi del '99"): that is, all males who were 18 years old. In 1918, the Austro-Hungarians failed to break through, in a series of battles on the Piave River, and were finally decisively defeated in the Battle of Vittorio Veneto in October of that year. From 5–6 November 1918, Italian forces were reported to have reached Lissa, Lagosta, Sebenico, and other localities on the Dalmatian coast. By the end of hostilities in November 1918, the Italian military had seized control of the entire portion of Dalmatia that had been guaranteed to Italy by the London Pact. In 1918, Admiral Enrico Millo declared himself Italy's Governor of Dalmatia. Austria-Hungary surrendered in early November 1918.
Romanian participation.
Romania had been allied with the Central Powers since 1882. When the war began, however, it declared its neutrality, arguing that because Austria-Hungary had itself declared war on Serbia, Romania was under no obligation to join the war. When the Entente Powers promised Romania large territories of eastern Hungary (Transylvania and Banat) that had a large Romanian population in exchange for Romania's declaring war on the Central Powers, the Romanian government renounced its neutrality, and on 27 August 1916 the Romanian Army launched an attack against Austria-Hungary, with limited Russian support. The Romanian offensive was initially successful, pushing back the Austro-Hungarian troops in Transylvania, but a counterattack by the forces of the Central Powers drove back the Russo-Romanian forces. As a result of the Battle of Bucharest the Central Powers occupied Bucharest on 6 December 1916. Fighting in Moldova continued in 1917, resulting in a costly stalemate for the Central Powers. Russian withdrawal from the war in late 1917 as a result of the October Revolution meant that Romania was forced to sign an armistice with the Central Powers on 9 December 1917.
In January 1918, Romanian forces established control over Bessarabia as the Russian Army abandoned the province. Although a treaty was signed by the Romanian and the Bolshevik Russian government following talks from 5–9 March 1918 on the withdrawal of Romanian forces from Bessarabia within two months, on 27 March 1918 Romania attached Bessarabia to its territory, formally based on a resolution passed by the local assembly of the territory on the unification with Romania.
Romania officially made peace with the Central Powers by signing the Treaty of Bucharest on 7 May 1918. Under that treaty, Romania was obliged to end war with the Central Powers and make small territorial concessions to Austria-Hungary, ceding control of some passes in the Carpathian Mountains, and grant oil concessions to Germany. In exchange, the Central Powers recognised the sovereignty of Romania over Bessarabia. The treaty was renounced in October 1918 by the Alexandru Marghiloman government, and Romania nominally re-entered the war on 10 November 1918. The next day, the Treaty of Bucharest was nullified by the terms of the Armistice of Compiègne. Total Romanian deaths from 1914 to 1918, military and civilian, within contemporary borders, were estimated at 748,000.
The role of India.
Contrary to British fears of a revolt in India, the outbreak of the war saw an unprecedented outpouring of loyalty and goodwill towards the United Kingdom. Indian political leaders from the Indian National Congress and other groups were eager to support the British war effort since they believed that strong support for the war effort would further the cause of Indian Home Rule. The Indian Army in fact outnumbered the British Army at the beginning of the war; about 1.3 million Indian soldiers and labourers served in Europe, Africa, and the Middle East, while both the central government and the princely states sent large supplies of food, money, and ammunition. In all, 140,000 men served on the Western Front and nearly 700,000 in the Middle East. Casualties of Indian soldiers totalled 47,746 killed and 65,126 wounded during World War I.
The suffering engendered by the war as well as the failure of the British government to grant self-government to India after the end of hostilities bred disillusionment and fuelled the campaign for full independence that would be led by Mohandas Karamchand Gandhi and others.
Eastern Front.
Initial actions.
While the Western Front had reached stalemate, the war continued in East Europe. Initial Russian plans called for simultaneous invasions of Austrian Galicia and German East Prussia. Although Russia's initial advance into Galicia was largely successful, it was driven back from East Prussia by Hindenburg and Ludendorff at Tannenberg and the Masurian Lakes in August and September 1914. Russia's less developed industrial base and ineffective military leadership was instrumental in the events that unfolded. By the spring of 1915, the Russians had retreated into Galicia, and in May the Central Powers achieved a remarkable breakthrough on Poland's southern frontiers. On 5 August they captured Warsaw and forced the Russians to withdraw from Poland.
Russian Revolution.
Despite the success of the June 1916 Brusilov Offensive in eastern Galicia, dissatisfaction with the Russian government's conduct of the war grew. The offensive's success was undermined by the reluctance of other generals to commit their forces to support the victory. Allied and Russian forces were revived only temporarily by Romania's entry into the war on 27 August. German forces came to the aid of embattled Austro-Hungarian units in Transylvania, and Bucharest fell to the Central Powers on 6 December. Meanwhile, unrest grew in Russia, as the Tsar remained at the front. Empress Alexandra's increasingly incompetent rule drew protests and resulted in the murder of her favourite, Rasputin, at the end of 1916.
In March 1917, demonstrations in Petrograd culminated in the abdication of Tsar Nicholas II and the appointment of a weak Provisional Government which shared power with the Petrograd Soviet socialists. This arrangement led to confusion and chaos both at the front and at home. The army became increasingly ineffective.
Discontent and the weaknesses of the Provisional Government led to a rise in popularity of the Bolshevik Party, led by Vladimir Lenin, which demanded an immediate end to the war. The successful armed uprising by the Bolsheviks of November was followed in December by an armistice and negotiations with Germany. At first the Bolsheviks refused the German terms, but when German troops began marching across the Ukraine unopposed, the new government acceded to the Treaty of Brest-Litovsk on 3 March 1918. The treaty ceded vast territories, including Finland, the Baltic provinces, parts of Poland and Ukraine to the Central Powers. Despite this enormous apparent German success, the manpower required for German occupation of former Russian territory may have contributed to the failure of the Spring Offensive and secured relatively little food or other materiel.
With the adoption of the Treaty of Brest-Litovsk, the Entente no longer existed. The Allied powers led a small-scale invasion of Russia, partly to stop Germany from exploiting Russian resources and, to a lesser extent, to support the "Whites" (as opposed to the "Reds") in the Russian Civil War. Allied troops landed in Arkhangelsk and in Vladivostok.
Central Powers proposal for starting peace negotiations.
In December 1916, after ten brutal months of the Battle of Verdun and a successful offensive against Romania, the Germans attempted to negotiate a peace with the Allies. Soon after, U.S. President Woodrow Wilson attempted to intervene as a peacemaker, asking in a note for both sides to state their demands. Lloyd George's War Cabinet considered the German offer to be a ploy to create divisions amongst the Allies. After initial outrage and much deliberation, they took Wilson's note as a separate effort, signalling that the U.S. was on the verge of entering the war against Germany following the "submarine outrages". While the Allies debated a response to Wilson's offer, the Germans chose to rebuff it in favour of "a direct exchange of views". Learning of the German response, the Allied governments were free to make clear demands in their response of 14 January. They sought restoration of damages, the evacuation of occupied territories, reparations for France, Russia and Romania, and a recognition of the principle of nationalities. This included the liberation of Italians, Slavs, Romanians, Czecho-Slovaks, and the creation of a "free and united Poland". On the question of security, the Allies sought guarantees that would prevent or limit future wars, complete with sanctions, as a condition of any peace settlement. The negotiations failed and the Entente powers rejected the German offer, because Germany did not state any specific proposals. To Wilson, the Entente powers stated that they would not start peace negotiations until the Central powers evacuated all occupied Allied territories and provided indemnities for all damage which had been done.
1917–1918.
Developments in 1917.
Events of 1917 proved decisive in ending the war, although their effects were not fully felt until 1918.
The British naval blockade began to have a serious impact on Germany. In response, in February 1917, the German General Staff convinced Chancellor Theobald von Bethmann-Hollweg to declare unrestricted submarine warfare, with the goal of starving Britain out of the war. German planners estimated that unrestricted submarine warfare would cost Britain a monthly shipping loss of 600,000 tons. The General Staff acknowledged that the policy would almost certainly bring the United States into the conflict, but calculated that British shipping losses would be so high that they would be forced to sue for peace after 5 to 6 months, before American intervention could make an impact. In reality, tonnage sunk rose above 500,000 tons per month from February to July. It peaked at 860,000 tons in April. After July, the newly re-introduced convoy system became extremely effective in reducing the U-boat threat. Britain was safe from starvation while German industrial output fell, and the United States troops joined the war in large numbers far earlier than Germany had anticipated.
On 3 May 1917, during the Nivelle Offensive, the weary French 2nd Colonial Division, veterans of the Battle of Verdun, refused their orders, arriving drunk and without their weapons. Their officers lacked the means to punish an entire division, and harsh measures were not immediately implemented. Then, mutinies afflicted an additional 54 French divisions and saw 20,000 men desert. The other Allied forces attacked but sustained tremendous casualties. However, appeals to patriotism and duty, as well as mass arrests and trials, encouraged the soldiers to return to defend their trenches, although the French soldiers refused to participate in further offensive action. Robert Nivelle was removed from command by 15 May, replaced by General Philippe Pétain, who suspended bloody large-scale attacks.
The victory of Austria–Hungary and Germany at the Battle of Caporetto led the Allies at the Rapallo Conference to form the Supreme War Council to coordinate planning. Previously, British and French armies had operated under separate commands.
In December, the Central Powers signed an armistice with Russia. This released large numbers of German troops for use in the west. With German reinforcements and new American troops pouring in, the outcome was to be decided on the Western Front. The Central Powers knew that they could not win a protracted war, but they held high hopes for success based on a final quick offensive. Furthermore, the leaders of the Central Powers and the Allies became increasingly fearful of social unrest and revolution in Europe. Thus, both sides urgently sought a decisive victory.
Ottoman Empire conflict in 1917.
In March and April 1917 at the First and Second Battles of Gaza, German and Ottoman forces stopped the advance of the Egyptian Expeditionary Force which had begun in August 1916 at Romani. At the end of October the Sinai and Palestine Campaign resumed, when General Edmund Allenby's XXth Corps, XXI Corps and Desert Mounted Corps won the Battle of Beersheba. Two Ottoman armies were defeated a few weeks later at the Battle of Mughar Ridge, and early in December Jerusalem was captured following another Ottoman defeat at the Battle of Jerusalem (1917). About this time Friedrich Freiherr Kress von Kressenstein was relieved of his duties as the Eighth Army's commander, replaced by Djevad Pasha, and a few months later the commander of the Ottoman Army in Palestine, Erich von Falkenhayn, was replaced by Otto Liman von Sanders.
Entry of the United States.
Non-intervention.
At the outbreak of the war the United States pursued a policy of non-intervention, avoiding conflict while trying to broker a peace. When a German U-boat sank the British liner RMS "Lusitania" on 7 May 1915 with 128 Americans among the dead, President Woodrow Wilson insisted that "America is too proud to fight" but demanded an end to attacks on passenger ships. Germany complied. Wilson unsuccessfully tried to mediate a settlement. However, he also repeatedly warned that the U.S.A. would not tolerate unrestricted submarine warfare, in violation of international law. Former president Theodore Roosevelt denounced German acts as "piracy". Wilson was narrowly reelected in 1916 as his supporters emphasized "he kept us out of war".
In January 1917, Germany resumed unrestricted submarine warfare, realizing it would mean American entry. The German Foreign Minister, in the Zimmermann Telegram, invited Mexico to join the war as Germany's ally against the United States. In return, the Germans would finance Mexico's war and help it recover the territories of Texas, New Mexico, and Arizona. Wilson released the Zimmerman note to the public, and Americans saw it as "casus belli"—a cause for war. Wilson called on antiwar elements to end all wars, by winning this one and eliminating militarism from the globe. He argued that the war was so important that the U.S. had to have a voice in the peace conference.
U.S. declaration of war on Germany.
After the sinking of seven U.S. merchant ships by submarines and the publication of the Zimmerman telegram, Wilson called for war on Germany, which the U.S. Congress declared on 6 April 1917.
First active U.S. participation.
The United States was never formally a member of the Allies but became a self-styled "Associated Power". The United States had a small army, but, after the passage of the Selective Service Act, it drafted 2.8 million men, and by summer 1918 was sending 10,000 fresh soldiers to France every day. In 1917, the U.S. Congress gave U.S. citizenship to Puerto Ricans when they were drafted to participate in World War I, as part of the Jones Act. Germany had miscalculated, believing it would be many more months before American soldiers would arrive and that their arrival could be stopped by U-boats.
The United States Navy sent a battleship group to Scapa Flow to join with the British Grand Fleet, destroyers to Queenstown, Ireland, and submarines to help guard convoys. Several regiments of U.S. Marines were also dispatched to France. The British and French wanted U.S. units used to reinforce their troops already on the battle lines and not waste scarce shipping on bringing over supplies. The U.S. rejected the first proposition and accepted the second. General John J. Pershing, American Expeditionary Forces (AEF) commander, refused to break up U.S. units to be used as reinforcements for British Empire and French units. As an exception, he did allow African-American combat regiments to be used in French divisions. The Harlem Hellfighters fought as part of the French 16th Division, earning a unit Croix de Guerre for their actions at Chateau-Thierry, Belleau Wood, and Sechault. AEF doctrine called for the use of frontal assaults, which had long since been discarded by British Empire and French commanders because of the large loss of life.
Austrian offer of separate peace.
In 1917, Emperor Charles I of Austria secretly attempted separate peace negotiations with Clemenceau, with his wife's brother Sixtus in Belgium as an intermediary, without the knowledge of Germany. When the negotiations failed, his attempt was revealed to Germany, resulting in a diplomatic catastrophe.
German Spring Offensive of 1918.
German General Erich Ludendorff drew up plans (codenamed Operation Michael) for the 1918 offensive on the Western Front. The Spring Offensive sought to divide the British and French forces with a series of feints and advances. The German leadership hoped to strike a decisive blow before significant U.S. forces arrived. The operation commenced on 21 March 1918 with an attack on British forces near Amiens. German forces achieved an unprecedented advance of .
British and French trenches were penetrated using novel infiltration tactics, also named "Hutier" tactics, after General Oskar von Hutier. Previously, attacks had been characterised by long artillery bombardments and massed assaults. However, in the Spring Offensive of 1918, Ludendorff used artillery only briefly and infiltrated small groups of infantry at weak points. They attacked command and logistics areas and bypassed points of serious resistance. More heavily armed infantry then destroyed these isolated positions. German success relied greatly on the element of surprise.
The front moved to within of Paris. Three heavy Krupp railway guns fired 183 shells on the capital, causing many Parisians to flee. The initial offensive was so successful that Kaiser Wilhelm II declared 24 March a national holiday. Many Germans thought victory was near. After heavy fighting, however, the offensive was halted. Lacking tanks or motorised artillery, the Germans were unable to consolidate their gains. This situation was not helped by the supply lines now being stretched as a result of their advance. The sudden stop was also a result of the four Australian Imperial Force (AIF) divisions that were "rushed" down, thus doing what no other army had done: stopping the German advance in its tracks. During that time the first Australian division was hurriedly sent north again to stop the second German breakthrough.
General Foch pressed to use the arriving American troops as individual replacements. Pershing sought instead to field American units as an independent force. These units were assigned to the depleted French and British Empire commands on 28 March. A Supreme War Council of Allied forces was created at the Doullens Conference on 5 November 1917. General Foch was appointed as supreme commander of the allied forces. Haig, Petain, and Pershing retained tactical control of their respective armies; Foch assumed a coordinating rather than a directing role, and the British, French, and U.S. commands operated largely independently.
Following Operation Michael, Germany launched Operation Georgette against the northern English Channel ports. The Allies halted the drive after limited territorial gains by Germany. The German Army to the south then conducted Operations Blücher and Yorck, pushing broadly towards Paris. Operation Marne was launched on 15 July, attempting to encircle Reims and beginning the Second Battle of the Marne. The resulting counterattack, starting the Hundred Days Offensive, marked the first successful Allied offensive of the war.
By 20 July the Germans were back across the Marne at their Kaiserschlacht starting lines, having achieved nothing. Following this last phase of the war in the West, the German Army never regained the initiative. German casualties between March and April 1918 were 270,000, including many highly trained storm troopers.
Meanwhile, Germany was falling apart at home. Anti-war marches became frequent and morale in the army fell. Industrial output was 53 percent of 1913 levels.
Ottoman Empire conflict 1918.
Early in 1918 the front line was extended into the Jordan Valley which continued to be occupied, following the First Transjordan and the Second Transjordan attack by British Empire forces in March and April 1918, into the summer. During March, most of the Egyptian Expeditionary Force's British infantry and Yeomanry cavalry were sent to fight on the Western Front as a consequence of the Spring Offensive. They were replaced by Indian Army units. During several months of reorganisation and training during the summer, a number of attacks were carried out on sections of the Ottoman front line. These pushed the front line north to more advantageous positions in preparation for an attack and to acclimatise the newly arrived Indian Army infantry. It was not until the middle of September that the integrated force was ready for large-scale operations.
The reorganised Egyptian Expeditionary Force, with an additional mounted division broke Ottoman forces at the Battle of Megiddo in September 1918. In two days the British and Indian infantry supported by a creeping barrage broke the Ottoman front line and captured the headquarters of the Eighth Army (Ottoman Empire) at Tulkarm, the continuous trench lines at Tabsor, Arara and the Seventh Army (Ottoman Empire) headquarters at Nablus. The Desert Mounted Corps rode through the break in the front line created by the infantry and during virtually continuous operations by Australian Light Horse, British mounted Yeomanry, Indian Lancers and New Zealand Mounted Rifle brigades. On the Jezreel Valley they captured Nazareth, Afulah and Beisan, Jenin, along with Haifa on the Mediterranean coast and Daraa east of the Jordan River on the Hejaz railway. Samakh and Tiberias on the Sea of Galilee, were captured on the way northwards to Damascus. Meanwhile Chaytor's Force of Australian light horse, New Zealand mounted rifles, Indian, British West Indies and Jewish infantry captured the crossings of the Jordan River, Es Salt, Amman and at Ziza most of the Fourth Army (Ottoman Empire). The Armistice of Mudros, signed at the end of October ended hostilities with the Ottoman Empire when fighting was continuing north of Aleppo.
New states under war zone.
In the late spring of 1918, three new states were formed in the South Caucasus: the Democratic Republic of Armenia, the Azerbaijan Democratic Republic, and the Democratic Republic of Georgia, which declared their independence from the Russian Empire. Two other minor entities were established, the Centrocaspian Dictatorship and South West Caucasian Republic (the former was liquidated by Azerbaijan in the autumn of 1918 and the latter by a joint Armenian-British task force in early 1919). With the withdrawal of the Russian armies from the Caucasus front in the winter of 1917–18, the three major republics braced for an imminent Ottoman advance, which commenced in the early months of 1918. Solidarity was briefly maintained when the Transcaucasian Federative Republic was created in the spring of 1918 but collapsed in May, when the Georgians asked and received protection from Germany and the Azerbaijanis concluded a treaty with the Ottoman Empire that was more akin to a military alliance. Armenia was left to fend for itself and struggled for five months against the threat of a full-fledged occupation by the Ottoman Turks.
Allied victory: summer and autumn 1918.
The Allied counteroffensive, known as the Hundred Days Offensive, began on 8 August 1918. The Battle of Amiens developed with III Corps British Fourth Army on the left, the French First Army on the right, and the Australian and Canadian Corps spearheading the offensive in the centre through Harbonnières. It involved 414 tanks of the Mark IV and Mark V type, and 120,000 men. They advanced into German-held territory in just seven hours. Erich Ludendorff referred to this day as the "Black Day of the German army".
The Australian-Canadian spearhead at Amiens, a battle that was the beginning of Germany's downfall, helped pull forward the British armies to the north and the French armies to the south. On the British Fourth Army front at Amiens, after an advance as far as , German resistance stiffened, and the battle there concluded. But the French Third Army lengthened the Amiens front on 10 August, when it was thrown in on the right of the French First Army, and advanced , liberating Lassigny in fighting which lasted until 16 August. South of the French Third Army, General Charles Mangin (The Butcher) drove his French Tenth Army forward at Soissons on 20 August to capture eight thousand prisoners, two hundred guns, and the Aisne heights overlooking and menacing the German position north of the Vesle. Another "Black day", as described by Erich Ludendorff.
Meanwhile General Byng of the British Third Army, reporting that the enemy on his front was thinning in a limited withdrawal, was ordered to attack with 200 tanks towards Bapaume, opening the Battle of Albert, with specific orders "To break the enemy's front, in order to outflank the enemy's present battle front" (opposite the British Fourth Army at Amiens). Allied leaders had now realised that to continue an attack after resistance had hardened was a waste of lives, and it was better to turn a line than to try to roll over it. They began to undertake attacks in quick order to take advantage of successful advances on the flanks, then broke them off when each attack lost its initial impetus.
The British Third Army's front north of Albert progressed after stalling for a day against the main resistance line to which the enemy had withdrawn. Rawlinson's British Fourth Army was able to push its left flank forward between Albert and the Somme, straightening the line between the advanced positions of the Third Army and the Amiens front, which resulted in recapturing Albert at the same time. On 26 August the British First Army on the left of the Third Army was drawn into the battle, extending it northward to beyond Arras. The Canadian Corps, already back in the vanguard of the First Army, fought its way from Arras eastward astride the heavily defended Arras-Cambrai area before reaching the outer defences of the Hindenburg Line, breaching them on the 28 and 29 August. Bapaume fell on 29 August to the New Zealand Division of the Third Army, and the Australians, still leading the advance of the Fourth Army, were again able to push forward at Amiens to take Peronne and Mont Saint-Quentin on 31 August. Further south, the French First and Third Armies had slowly fought forward while the Tenth Army, which had by now crossed the Ailette and was east of the Chemin des Dames, neared the Alberich position of the Hindenburg Line. During the last week of August the pressure along a front against the enemy was heavy and unrelenting. From German accounts, "Each day was spent in bloody fighting against an ever and again on-storming enemy, and nights passed without sleep in retirements to new lines." Even to the north in Flanders the British Second and Fifth Armies during August and September were able to make progress, taking prisoners and positions that had previously been denied them.
On 2 September the Canadian Corps' outflanking of the Hindenburg line, with the breaching of the Wotan Position, made it possible for the Third Army to advance, which sent repercussions all along the Western Front. That same day Oberste Heeresleitung (OHL) had no choice but to issue orders to six armies to withdraw back into the Hindenburg Line in the south, behind the Canal du Nord on the Canadian-First Army's front and back to a line east of the Lys in the north. This ceded without a fight the salient seized the previous April. According to Ludendorff "We had to admit the necessity ...to withdraw the entire front from the Scarpe to the Vesle."
In nearly four weeks of fighting beginning 8 August, over 100,000 German prisoners were taken, 75,000 by the BEF and the rest by the French. As of "The Black Day of the German Army", the German High Command realised the war was lost and made attempts to reach a satisfactory end. The day after that battle Ludenforff told Colonel Mertz: "We cannot win the war any more, but we must not lose it either." On 11 August he offered his resignation to the Kaiser, who refused it, replying, "I see that we must strike a balance. We have nearly reached the limit of our powers of resistance. The war must be ended." On 13 August at Spa, Hindenburg, Ludendorff, the Chancellor, and Foreign Minister Hintz agreed that the war could not be ended militarily, and on the following day the German Crown Council decided that victory in the field was now most improbable. Austria and Hungary warned that they could only continue the war until December, and Ludendorff recommended immediate peace negotiations, to which the Kaiser responded by instructing Hintz to seek the mediation of the Queen of the Netherlands. Prince Rupprecht warned Prince Max of Baden: "Our military situation has deteriorated so rapidly that I no longer believe we can hold out over the winter; it is even possible that a catastrophe will come earlier." On 10 September Hindenburg urged peace moves to Emperor Charles of Austria, and Germany appealed to the Netherlands for mediation. On 14 September Austria sent a note to all belligerents and neutrals suggesting a meeting for peace talks on neutral soil, and on 15 September Germany made a peace offer to Belgium. Both peace offers were rejected, and on 24 September OHL informed the leaders in Berlin that armistice talks were inevitable.
September saw the Germans continuing to fight strong rear-guard actions and launching numerous counterattacks on lost positions, but only a few succeeded, and then only temporarily. Contested towns, villages, heights, and trenches in the screening positions and outposts of the Hindenburg Line continued to fall to the Allies, with the BEF alone taking 30,441 prisoners in the last week of September. Further small advances eastward would follow the Third Army's victory at Ivincourt on 12 September, the Fourth Army's at Epheny on 18 September, and the French gain of Essigny-le-Grand a day later. On 24 September a final assault by both the British and French on a front would come within of St. Quentin. With the outposts and preliminary defensive lines of the Siegfried and Alberich Positions eliminated, the Germans were now completely back in the Hindenburg Line. With the Wotan position of that line already breached and the Siegfried position in danger of being turned from the north, the time had now come for an Allied assault on the whole length of the line.
The Allied attack on the Hindenburg Line, begun on 26 September, included U.S. soldiers. The still-green American troops suffered problems coping with supply trains for large units on a difficult landscape. The following week cooperating French and American units broke through in Champagne at the Battle of Blanc Mont Ridge, forcing the Germans off the commanding heights, and closing towards the Belgian frontier. The last Belgian town to be liberated before the armistice was Ghent, which the Germans held as a pivot until the Allies brought up artillery. The German army had to shorten its front and use the Dutch frontier as an anchor to fight rear-guard actions.
When Bulgaria signed a separate armistice on 29 September, the Allies gained control of Serbia and Greece. Ludendorff, having been under great stress for months, suffered something similar to a breakdown. It was evident that Germany could no longer mount a successful defence.
Meanwhile, news of Germany's impending military defeat spread throughout the German armed forces. The threat of mutiny was rife. Admiral Reinhard Scheer and Ludendorff decided to launch a last attempt to restore the "valour" of the German Navy. Knowing the government of Prince Maximilian of Baden would veto any such action, Ludendorff decided not to inform him. Nonetheless, word of the impending assault reached sailors at Kiel. Many, refusing to be part of a naval offensive which they believed to be suicidal, rebelled and were arrested. Ludendorff took the blame; the Kaiser dismissed him on 26 October. The collapse of the Balkans meant that Germany was about to lose its main supplies of oil and food. Its reserves had been used up, even as U.S. troops kept arriving at the rate of 10,000 per day.
Having suffered over 6 million casualties, Germany moved towards peace. Prince Maximilian of Baden took charge of a new government as Chancellor of Germany to negotiate with the Allies. Telegraphic negotiations with President Wilson began immediately, in the vain hope that he would offer better terms than the British and French. Instead Wilson demanded the abdication of the Kaiser. There was no resistance when the Social Democrat Philipp Scheidemann on 9 November declared Germany to be a republic. Imperial Germany was dead; a new Germany had been born: the Weimar Republic.
Armistices and capitulations.
The collapse of the Central Powers came swiftly. Bulgaria was the first to sign an armistice, on 29 September 1918 at Saloniki. On 30 October, the Ottoman Empire capitulated at Moudros (Armistice of Mudros).
On 24 October, the Italians began a push which rapidly recovered territory lost after the Battle of Caporetto. This culminated in the Battle of Vittorio Veneto, which marked the end of the Austro-Hungarian Army as an effective fighting force. The offensive also triggered the disintegration of the Austro-Hungarian Empire. During the last week of October, declarations of independence were made in Budapest, Prague, and Zagreb. On 29 October, the imperial authorities asked Italy for an armistice. But the Italians continued advancing, reaching Trento, Udine, and Trieste. On 3 November Austria–Hungary sent a flag of truce to ask for an Armistice. The terms, arranged by telegraph with the Allied Authorities in Paris, were communicated to the Austrian commander and accepted. The Armistice with Austria was signed in the Villa Giusti, near Padua, on 3 November. Austria and Hungary signed separate armistices following the overthrow of the Habsburg Monarchy.
Following the outbreak of the German Revolution of 1918–1919, a republic was proclaimed on 9 November. The Kaiser fled to the Netherlands. 
On 11 November at 5:00 am, an armistice with Germany was signed in a railroad carriage at Compiègne. At 11 am on 11 November 1918 — "the eleventh hour of the eleventh day of the eleventh month" — a ceasefire came into effect. During the six hours between the signing of the armistice and its taking effect, opposing armies on the Western Front began to withdraw from their positions, but fighting continued along many areas of the front, as commanders wanted to capture territory before the war ended. Canadian Private George Lawrence Price was shot by a German sniper at 10:57 and died at 10:58. American Henry Gunther was killed 60 seconds before the armistice came into force while charging astonished German troops who were aware the Armistice was nearly upon them. The last British soldier to die was Pte George Edwin Ellison. The last casualty of the war was a German, Lieutenant Thomas, who, after 11 am, was walking towards the line to inform Americans who had not yet been informed of the Armistice that they would be vacating the buildings behind them. The occupation of the Rhineland took place following the Armistice. The occupying armies consisted of American, Belgian, British and French forces.
Allied superiority and the stab-in-the-back legend, November 1918.
In November 1918 the Allies had ample supplies of men and materiel to invade Germany. Yet at the time of the armistice, no Allied force had crossed the German frontier; the Western Front was still almost from Berlin; and the Kaiser's armies had retreated from the battlefield in good order. These factors enabled Hindenburg and other senior German leaders to spread the story that their armies had not really been defeated. This resulted in the stab-in-the-back legend, which attributed Germany's defeat not to its inability to continue fighting (even though up to a million soldiers were suffering from the 1918 flu pandemic and unfit to fight), but to the public's failure to respond to its "patriotic calling" and the supposed intentional sabotage of the war effort, particularly by Jews, Socialists, and Bolsheviks.
Treaty of Versailles, June 1919.
A formal state of war between the two sides persisted for another seven months, until the signing of the Treaty of Versailles with Germany on 28 June 1919. However, the American public opposed ratification of the treaty, mainly because of the League of Nations the treaty created; the U.S. did not formally end its involvement in the war until the Knox–Porter Resolution was signed in 1921. After the Treaty of Versailles, treaties with Austria, Hungary, Bulgaria, and the Ottoman Empire were signed. However, the negotiation of the latter treaty with the Ottoman Empire was followed by strife (the Turkish War of Independence), and a final peace treaty between the Allied Powers and the country that would shortly become the Republic of Turkey was not signed until 24 July 1923, at Lausanne.
Some war memorials date the end of the war as being when the Versailles Treaty was signed in 1919, which was when many of the troops serving abroad finally returned to their home countries; by contrast, most commemorations of the war's end concentrate on the armistice of 11 November 1918. Legally, the formal peace treaties were not complete until the last, the Treaty of Lausanne, was signed. Under its terms, the Allied forces divested Constantinople on 23 August 1923.
Technology.
The First World War began as a clash of 20th-century technology and 19th-century tactics, with the inevitably large ensuing casualties. By the end of 1917, however, the major armies, now numbering millions of men, had modernised and were making use of telephone, wireless communication, armoured cars, tanks, and aircraft. Infantry formations were reorganised, so that 100-man companies were no longer the main unit of manoeuvre; instead, squads of 10 or so men, under the command of a junior NCO, were favoured.
Artillery also underwent a revolution. In 1914, cannons were positioned in the front line and fired directly at their targets. By 1917, indirect fire with guns (as well as mortars and even machine guns) was commonplace, using new techniques for spotting and ranging, notably aircraft and the often overlooked field telephone. Counter-battery missions became commonplace, also, and sound detection was used to locate enemy batteries.
Germany was far ahead of the Allies in utilising heavy indirect fire. The German Army employed 150 and 210 mm howitzers in 1914, when typical French and British guns were only 75 and 105 mm. The British had a 6 inch (152 mm) howitzer, but it was so heavy it had to be hauled to the field in pieces and assembled. Germans also fielded Austrian 305 mm and 420 mm guns, and already by the beginning of the war had inventories of various calibers of "Minenwerfer" ideally suited for trench warfare.
Much of the combat involved trench warfare, in which hundreds often died for each yard gained. Many of the deadliest battles in history occurred during the First World War. Such battles include Ypres, the Marne, Cambrai, the Somme, Verdun, and Gallipoli. The Germans employed the Haber process of nitrogen fixation to provide their forces with a constant supply of gunpowder, despite the British naval blockade. Artillery was responsible for the largest number of casualties and consumed vast quantities of explosives. The large number of head wounds caused by exploding shells and fragmentation forced the combatant nations to develop the modern steel helmet, led by the French, who introduced the Adrian helmet in 1915. It was quickly followed by the Brodie helmet, worn by British Imperial and U.S. troops, and in 1916 by the distinctive German "Stahlhelm", a design, with improvements, still in use today.
The widespread use of chemical warfare was a distinguishing feature of the conflict. Gases used included chlorine, mustard gas and phosgene. Few war casualties were caused by gas, as effective countermeasures to gas attacks were quickly created, such as gas masks. The use of chemical warfare and small-scale strategic bombing were both outlawed by the 1907 Hague Conventions, and both proved to be of limited effectiveness, though they captured the public imagination.
The most powerful land-based weapons were railway guns weighing hundreds of tons apiece. These were nicknamed Big Berthas, even though the namesake was not a railway gun. Germany developed the Paris Gun, able to bombard Paris from over , though shells were relatively light at 94 kilograms (210 lb). While the Allies also had railway guns, German models severely out-ranged and out-classed them.
Aviation.
Fixed-wing aircraft were first used militarily by the Italians in Libya on 23 October 1911 during the Italo-Turkish War for reconnaissance, soon followed by the dropping of grenades and aerial photography the next year. By 1914 their military utility was obvious. They were initially used for reconnaissance and ground attack. To shoot down enemy planes, anti-aircraft guns and fighter aircraft were developed. Strategic bombers were created, principally by the Germans and British, though the former used Zeppelins as well. Towards the end of the conflict, aircraft carriers were used for the first time, with HMS "Furious" launching Sopwith Camels in a raid to destroy the Zeppelin hangars at Tondern in 1918.
Manned observation balloons, floating high above the trenches, were used as stationary reconnaissance platforms, reporting enemy movements and directing artillery. Balloons commonly had a crew of two, equipped with parachutes, so that if there was an enemy air attack the crew could parachute to safety. (At the time, parachutes were too heavy to be used by pilots of aircraft (with their marginal power output), and smaller versions were not developed until the end of the war; they were also opposed by British leadership, who feared they might promote cowardice.) 
Recognised for their value as observation platforms, balloons were important targets of enemy aircraft. To defend them against air attack, they were heavily protected by antiaircraft guns and patrolled by friendly aircraft; to attack them, unusual weapons such as air-to-air rockets were even tried. Thus, the reconnaissance value of blimps and balloons contributed to the development of air-to-air combat between all types of aircraft, and to the trench stalemate, because it was impossible to move large numbers of troops undetected. The Germans conducted air raids on England during 1915 and 1916 with airships, hoping to damage British morale and cause aircraft to be diverted from the front lines, and indeed the resulting panic led to the diversion of several squadrons of fighters from France.
Improvements in naval technology during World War I.
Germany deployed U-boats (submarines) after the war began. Alternating between restricted and unrestricted submarine warfare in the Atlantic, the Kaiserliche Marine employed them to deprive the British Isles of vital supplies. The deaths of British merchant sailors and the seeming invulnerability of U-boats led to the development of depth charges (1916), hydrophones (passive sonar, 1917), blimps, hunter-killer submarines (HMS "R-1", 1917), forward-throwing anti-submarine weapons, and dipping hydrophones (the latter two both abandoned in 1918). To extend their operations, the Germans proposed supply submarines (1916). Most of these would be forgotten in the interwar period until World War II revived the need.
Improvements in ground warfare technology in World War I.
Trenches, machine guns, air reconnaissance, barbed wire, and modern artillery with fragmentation shells helped bring the battle lines of World War I to a stalemate. The British and the French sought a solution with the creation of the tank and mechanised warfare. The British first tanks were used during the Battle of the Somme on 15 September 1916. Mechanical reliability was an issue, but the experiment proved its worth. Within a year, the British were fielding tanks by the hundreds, and they showed their potential during the Battle of Cambrai in November 1917, by breaking the Hindenburg Line, while combined arms teams captured 8000 enemy soldiers and 100 guns. Meanwhile the French introduced the first tanks with rotating turred, the Renault FT-A7, which became a decisive tool of the victory. The conflict also saw the introduction of Light automatic weapons and submachine guns, such as the Lewis Gun, the Browning automatic rifle, and the Bergmann MP18.
Flamethrowers and subterranean transport.
Another new weapon, the flamethrower, was first used by the German army and later adopted by other forces. Although not of high tactical value, the flamethrower was a powerful, demoralising weapon that caused terror on the battlefield. It was a dangerous weapon to wield, as its heavy weight made operators vulnerable targets.
Trench railways evolved to supply the enormous quantities of food, water, and ammunition required to support large numbers of soldiers in areas where conventional transportation systems had been destroyed. Internal combustion engines and improved traction systems for automobiles and trucks/lorries eventually rendered trench railways obsolete.
War crimes.
Genocide and ethnic cleansing.
The ethnic cleansing of the Ottoman Empire's Armenian population, including mass deportations and executions, during the final years of the Ottoman Empire is considered genocide. The Ottomans saw the entire Armenian population as an enemy that had chosen to side with Russia at the beginning of the war. In early 1915, a number of Armenians joined the Russian forces, and the Ottoman government used this as a pretext to issue the Tehcir Law (Law on Deportation). This authorized the deportation of the Armenians from eastern provinces of the Empire to Syria between 1915 and 1917. The exact number of deaths is unknown: while Balakian gives a range of 250,000 to 1.5 million for the deaths of Armenians, the International Association of Genocide Scholars estimates over 1 million. The government of Turkey has consistently rejected charges of genocide, arguing that those who died were victims of inter-ethnic fighting, famine, or disease during the First World War. Other ethnic groups were similarly attacked by the Ottoman Empire during this period, including Assyrians and Greeks, and some scholars consider those events to be part of the same policy of extermination.
Russian Empire.
Many pogroms accompanied the Russian Revolution of 1917 and the ensuing Russian Civil War. 60,000–200,000 civilian Jews were killed in the atrocities throughout the former Russian Empire.
"Rape of Belgium".
The German invaders treated any resistance—such as sabotaging rail lines—as illegal and immoral, and shot the offenders and burned buildings in retaliation. In addition they tended to suspect most civilians to be potential "franc-tireurs", and accordingly took and sometimes killed hostages among the civilian population. The German army executed over 6,500 French and Belgian civilians between August and November 1914, usually in near-random large-scale shootings of civilians ordered by junior German officers. The German Army destroyed 15,000–20,000 buildings—most famously the university library at Louvain—and generated a refugee wave of over a million people. Over half the German regiments in Belgium were involved in major incidents. Thousands of workers were shipped to Germany to work in factories. British propaganda dramatizing the "Rape of Belgium" attracted much attention in the U.S., while Berlin said it was legal and necessary because of the threat of "franc-tireurs" (guerrillas) like those in France in 1870. The British and French magnified the reports and disseminated them at home and in the U.S., where they played a major role in dissolving support for Germany.
Soldiers' experiences.
The soldiers of the war were initially volunteers, except for those of Italy, but increasingly were conscripted into service. Britain's Imperial War Museum has collected more than 2,500 recordings of soldiers' personal accounts, and selected transcripts, edited by military author Max Arthur, have been published. The Museum believes that historians have not taken full account of this material, and accordingly has made the full archive of recordings available to authors and researchers. Surviving veterans, returning home, often found that they could only discuss their experiences amongst themselves. Grouping together, they formed "veterans' associations" or "Legions".
Prisoners of war.
About 8 million men surrendered and were held in POW camps during the war. All nations pledged to follow the Hague Conventions on fair treatment of prisoners of war. POWs' rate of survival was generally much higher than that of their peers at the front. Individual surrenders were uncommon; large units usually surrendered en masse. At the Battle of Tannenberg 92,000 Russians surrendered. When the besieged garrison of Kaunas surrendered in 1915, some 20,000 Russians became prisoners. Over half of Russian losses (as a proportion of those captured, wounded, or killed) were to prisoner status; for Austria-Hungary 32%, for Italy 26%, for France 12%, for Germany 9%; for Britain 7%. Prisoners from the Allied armies totalled about 1.4 million (not including Russia, which lost 2.-3.5 million men as prisoners.) From the Central Powers about 3.3 million men became prisoners.
Germany held 2.5 million prisoners; Russia held 2.9 million; while Britain and France held about 720,000. Most were captured just prior to the Armistice. The U.S. held 48,000. The most dangerous moment was the act of surrender, when helpless soldiers were sometimes gunned down. Once prisoners reached a camp, conditions were, in general, satisfactory (and much better than in World War II), thanks in part to the efforts of the International Red Cross and inspections by neutral nations. However, conditions were terrible in Russia: starvation was common for prisoners and civilians alike; about 15–20% of the prisoners in Russia died. In Germany, food was scarce, but only 5% died.
The Ottoman Empire often treated POWs poorly. Some 11,800 British Empire soldiers, most of them Indians, became prisoners after the Siege of Kut in Mesopotamia in April 1916; 4,250 died in captivity.
Although many were in very bad condition when captured, Ottoman officers forced them to march to Anatolia. A survivor said: "We were driven along like beasts; to drop out was to die." The survivors were then forced to build a railway through the Taurus Mountains.
In Russia, when the prisoners from the Czech Legion of the Austro-Hungarian army were released in 1917, they re-armed themselves and briefly became a military and diplomatic force during the Russian Civil War.
While the Allied prisoners of the Central Powers were quickly sent home at the end of active hostilities, the same treatment was not granted to Central Power prisoners of the Allies and Russia, many of whom served as forced labor, e.g., in France until 1920. They were released only after many approaches by the Red Cross to the Allied Supreme Council. German prisoners were still being held in Russia as late as 1924.
Military attachés and war correspondents.
Military and civilian observers from every major power closely followed the course of the war. Many were able to report on events from a perspective somewhat akin to modern "embedded" positions within the opposing land and naval forces. These military attachés and other observers prepared voluminous first-hand accounts of the war and analytical papers.
For example, former U.S. Army Captain Granville Fortescue followed the developments of the Gallipoli Campaign from an embedded perspective within the ranks of the Turkish defenders; and his report was passed through Turkish censors before being printed in London and New York. However, this observer's role was abandoned when the U.S. entered the war, as Fortescue immediately re-enlisted, sustaining wounds at Forest of Argonne in the Meuse-Argonne Offensive, September 1918.
In-depth observer narratives of the war and more narrowly focused professional journal articles were written soon after the war; and these post-war reports conclusively illustrated the battlefield destructiveness of this conflict. This was not the first time the tactics of entrenched positions for infantry defended with machine guns and artillery became vitally important. The Russo-Japanese War had been closely observed by military attachés, war correspondents and other observers; but, from a 21st century perspective, it is now apparent that a range of tactical lessons were disregarded or not used in the preparations for war in Europe and throughout the Great War.
Support and opposition to the war.
Support.
In the Balkans, Yugoslav nationalists such as the leader Ante Trumbić in the Balkans strongly supported the war, desiring the freedom of Yugoslavs from Austria-Hungary and other foreign powers and the creation of an independent Yugoslavia. The Yugoslav Committee was formed in Paris on 30 April 1915 but shortly moved its office to London; Trumbić led the Committee.
In the Middle East, Arab nationalism soared in Ottoman territories in response to the rise of Turkish nationalism during the war, with Arab nationalist leaders advocating the creation of a pan-Arab state. In 1916, the Arab Revolt began in Ottoman-controlled territories of the Middle East in an effort to achieve independence.
Italian nationalism was stirred by the outbreak of the war and was initially strongly supported by a variety of political factions. One of the most prominent and popular Italian nationalist supporters of the war was Gabriele d'Annunzio, who promoted Italian irredentism and helped sway the Italian public to support intervention in the war. The Italian Liberal Party under the leadership of Paolo Boselli promoted intervention in the war on the side of the Allies and utilised the Dante Aligheri Society to promote Italian nationalism.
A number of socialist parties initially supported the war when it began in August 1914. But European socialists split on national lines, with the concept of class conflict held by radical socialists such as Marxists and syndicalists being overborne by their patriotic support for war. Once the war began, Austrian, British, French, German, and Russian socialists followed the rising nationalist current by supporting their countries' intervention in the war.
Italian socialists were divided on whether to support the war or oppose it; some were militant supporters of the war, including Benito Mussolini and Leonida Bissolati. However, the Italian Socialist Party decided to oppose the war after anti-militarist protestors were killed, resulting in a general strike called Red Week. The Italian Socialist Party purged itself of pro-war nationalist members, including Mussolini. Mussolini, a syndicalist who supported the war on grounds of irredentist claims on Italian-populated regions of Austria-Hungary, formed the pro-interventionist "Il Popolo d'Italia" and the "Fasci Riviluzionario d'Azione Internazionalista" ("Revolutionary Fasci for International Action") in October 1914 that later developed into the "Fasci di Combattimento" in 1919, the origin of fascism. Mussolini's nationalism enabled him to raise funds from Ansaldo (an armaments firm) and other companies to create "Il Popolo d'Italia" to convince socialists and revolutionaries to support the war.
In April 1918 the Rome Congress of Oppressed Nationalities met, including Czechoslovak, Italian, Polish, Transylvanian, and Yugoslav representatives who urged the Allies to support national self-determination for the peoples residing within Austria-Hungary.
Opposition.
The trade union and socialist movements had long voiced their opposition to a war, which they argued would mean only that workers would kill other workers in the interest of capitalism. Once war was declared, however, many socialists and trade unions backed their governments. Among the exceptions were the Bolsheviks, the Socialist Party of America, and the Italian Socialist Party, and individuals such as Karl Liebknecht, Rosa Luxemburg, and their followers in Germany. There were also small anti-war groups in Britain and France.
Benedict XV, elected to the papacy less than three months into World War I, made the war and its consequences the main focus of his early pontificate. In stark contrast to his predecessor, five days after his election he spoke of his determination to do what he could to bring peace. His first encyclical, Ad Beatissimi Apostolorum, given 1 November 1914, was concerned with this subject. Seen as being biased in favour of the other and resented for weakening national morale, Benedict XV found his abilities and unique position as a religious emissary of peace ignored by the belligerent powers.
The 1915 Treaty of London between Italy and the Triple Entente included secret provisions whereby the Allies agreed with Italy to ignore papal peace moves towards the Central Powers. Consequently, the publication of Benedict's proposed seven-point Peace Note of August 1917 was roundly ignored by all parties except Austria-Hungary.
In Britain, in 1914, the Public Schools Officers' Training Corps annual camp was held at Tidworth Pennings, near Salisbury Plain. Head of the British Army Lord Kitchener was to review the cadets, but the imminence of the war prevented him. General Horace Smith-Dorrien was sent instead. He surprised the two-or-three thousand cadets by declaring (in the words of Donald Christopher Smith, a Bermudian cadet who was present), "that war should be avoided at almost any cost, that war would solve nothing, that the whole of Europe and more besides would be reduced to ruin, and that the loss of life would be so large that whole populations would be decimated. In our ignorance I, and many of us, felt almost ashamed of a British General who uttered such depressing and unpatriotic sentiments, but during the next four years, those of us who survived the holocaust—probably not more than one-quarter of us—learned how right the General's prognosis was and how courageous he had been to utter it." Voicing these sentiments did not hinder Smith-Dorien's career, or prevent him from doing his duty in World War I to the best of his abilities.
Many countries jailed those who spoke out against the conflict. These included Eugene Debs in the United States and Bertrand Russell in Britain. In the U.S., the Espionage Act of 1917 and Sedition Act of 1918 made it a federal crime to oppose military recruitment or make any statements deemed "disloyal". Publications at all critical of the government were removed from circulation by postal censors, and many served long prison sentences for statements of fact deemed unpatriotic.
A number of nationalists opposed intervention, particularly within states that the nationalists were hostile to. Although the vast majority of Irish people consented to participate in the war in 1914 and 1915, a minority of advanced Irish nationalists staunchly opposed taking part. The war began amid the Home Rule crisis in Ireland that had resurfaced in 1912, and by July 1914 there was a serious possibility of an outbreak of civil war in Ireland. Irish nationalists and Marxists attempted to pursue Irish independence, culminating in the Easter Rising of 1916, with Germany sending 20,000 rifles to Ireland in order to stir unrest in the United Kingdom. The UK government placed Ireland under martial law in response to the Easter Rising, although once the immediate threat of revolution had dissipated the authorities did try to make concessions to nationalist feeling.
Other opposition came from conscientious objectors – some socialist, some religious – who refused to fight. In Britain 16,000 people asked for conscientious objector status. Some of them, most notably prominent peace activist Stephen Henry Hobhouse, refused both military and alternative service. Many suffered years of prison, including solitary confinement and bread and water diets. Even after the war, in Britain many job advertisements were marked "No conscientious objectors need apply".
The Central Asian Revolt started in the summer of 1916, when the Russian Empire government ended its exemption of Muslims from military service.
In 1917, a series of mutinies in the French army led to dozens of soldiers being executed and many more imprisoned.
In Milan in May 1917, Bolshevik revolutionaries organised and engaged in rioting calling for an end to the war, and managed to close down factories and stop public transportation. The Italian army was forced to enter Milan with tanks and machine guns to face Bolsheviks and anarchists, who fought violently until 23 May when the army gained control of the city. Almost 50 people (including three Italian soldiers) were killed and over 800 people arrested.
The Conscription Crisis of 1917 in Canada erupted when conservative Prime Minister Robert Borden brought in compulsory military service over the objection of French-speaking Quebecers. Out of approximately 625,000 Canadians who served, about 60,000 were killed and another 173,000 wounded.
In 1917, Emperor Charles I of Austria secretly entered into peace negotiations with the Allied powers, with his brother-in-law Sixtus as intermediary, without the knowledge of his ally Germany. He failed, however, because of the resistance of Italy.
In September 1917, Russian soldiers in France began questioning why they were fighting for the French at all and mutinied. In Russia, opposition to the war led to soldiers also establishing their own revolutionary committees, which helped foment the October Revolution of 1917, with the call going up for "bread, land, and peace". The Bolsheviks agreed to a peace treaty with Germany, the peace of Brest-Litovsk, despite its harsh conditions.
In northern Germany, the end of October 1918, saw the beginning of the German Revolution of 1918–1919. Units of the German Navy refused to set sail for a last, large-scale operation in a war which they saw as good as lost; this initiated the uprising. The sailors' revolt which then ensued in the naval ports of Wilhelmshaven and Kiel spread across the whole country within days and led to the proclamation of a republic on 9 November 1918 and shortly thereafter to the abdication of Kaiser Wilhelm II.
Conscription.
As the war slowly turned into a war of attrition, conscription was implemented in some countries. This issue was particularly explosive in Canada and Australia. In the former it opened a political gap between French Canadians, who believed their true loyalty should be to Canada and not to the British Empire, and members of the Anglophone majority, who saw the war as a duty to both Britain and Canada. Prime Minister Robert Borden pushed through a Military Service Act, provoking the Conscription Crisis of 1917. In Australia, a sustained pro-conscription campaign by Prime Minister Billy Hughes caused a split in the Australian Labor Party, so Hughes formed the Nationalist Party of Australia in 1917 to pursue the matter. Nevertheless, the labour movement, the Catholic Church, and Irish nationalist expatriates successfully opposed Hughes' push, which was rejected in two plebiscites.
Conscription put into uniform nearly every physically fit man in Britain, six of ten million eligible. Of these, about 750,000 lost their lives and 1,700,000 were wounded. Most deaths were to young unmarried men; however, 160,000 wives lost husbands and 300,000 children lost fathers.
Aftermath.
Health and economic effects.
No other war had changed the map of Europe so dramatically. Four empires disappeared: the German, Austro-Hungarian, Ottoman, and Russian. Four dynasties, together with their ancillary aristocracies, all fell after the war: the Hohenzollerns, the Habsburgs, the Romanovs, and the Ottomans. Belgium and Serbia were badly damaged, as was France, with 1.4 million soldiers dead, not counting other casualties. Germany and Russia were similarly affected.
The war had profound economic consequences. Of the 60 million European soldiers who were mobilised from 1914 to 1918, 8 million were killed, 7 million were permanently disabled, and 15 million were seriously injured. Germany lost 15.1% of its active male population, Austria–Hungary lost 17.1%, and France lost 10.5%. About 750,000 German civilians died from starvation caused by the British blockade during the war. By the end of the war, famine had killed approximately 100,000 people in Lebanon. The best estimates of the death toll from the Russian famine of 1921 run from 5 million to 10 million people. By 1922, there were between 4.5 million and 7 million homeless children in Russia as a result of nearly a decade of devastation from World War I, the Russian Civil War, and the subsequent famine of 1920–1922. Numerous anti-Soviet Russians fled the country after the Revolution; by the 1930s the northern Chinese city of Harbin had 100,000 Russians. Thousands more emigrated to France, England, and the United States.
In Australia the effects of the war on the economy were no less severe. The then Prime Minister Hughes wrote to the British Prime Minister Lloyd George, "You have assured us that you cannot get better terms. I much regret it, and hope even now that some way may be found of securing agreement for demanding reparation commensurate with the tremendous sacrifices made by the British Empire and her Allies." Australia received ₤5,571,720 war reparations but the direct cost of the war to Australia had been ₤376,993,052, and by the mid-1930s repatriation pensions, war gratuities, interest and sinking fund charges were ₤831,280,947. Of about 416,000 Australian who served, about 60,000 were killed and another 152,000 were wounded.
Diseases flourished in the chaotic wartime conditions. In 1914 alone, louse-borne epidemic typhus killed 200,000 in Serbia. From 1918 to 1922, Russia had about 25 million infections and 3 million deaths from epidemic typhus. Whereas before World War I Russia had about 3.5 million cases of malaria, its people suffered more than 13 million cases in 1923. In addition, a major influenza epidemic spread around the world. Overall, the 1918 flu pandemic killed at least 50 million people.
Lobbying by Chaim Weizmann and fear that American Jews would encourage the USA to support Germany culminated in the British government's Balfour Declaration of 1917, endorsing creation of a Jewish homeland in Palestine. A total of more than 1,172,000 Jewish soldiers served in the Allied and Central Power forces in World War I, including 275,000 in Austria-Hungary and 450,000 in Czarist Russia.
The social disruption and widespread violence of the Revolution of 1917 and the ensuing Russian Civil War sparked more than 2,000 pogroms in the former Russian Empire, mostly in the Ukraine. An estimated 60,000–200,000 civilian Jews were killed in the atrocities.
In the aftermath of World War I, Greece fought against Turkish nationalists led by Mustafa Kemal, a war which resulted in a massive population exchange between the two countries under the Treaty of Lausanne. According to various sources, several hundred thousand Pontic Greeks died during this period.
Peace treaties and national boundaries.
After the war, the Paris Peace Conference imposed a series of peace treaties on the Central Powers. The 1919 Treaty of Versailles officially ended the war. Building on Wilson's 14th point, the Treaty of Versailles also brought into being the League of Nations on 28 June 1919.
In signing the treaty, Germany acknowledged responsibility for the war, and agreed to pay enormous war reparations and award territory to the victors. The "Guilt Thesis" became a controversial explanation of later events among analysts in Britain and the United States. The Treaty of Versailles caused enormous bitterness in Germany, which nationalist movements, especially the Nazis, exploited with a conspiracy theory they called the "Dolchstosslegende" (Stab-in-the-back legend). The Weimar Republic lost the former colonial possessions and was saddled with accepting blame for the war, as well as paying punitive reparations for it. Unable to pay them with exports (as a result of territorial losses and postwar recession), Germany did so by borrowing from the United States. Runaway inflation in the 1920s contributed to the economic collapse of the Weimar Republic, and the payment of reparations was suspended in 1931 following the Stock Market Crash of 1929 and the beginnings of the Great Depression worldwide.
Austria–Hungary was partitioned into several successor states, including Austria, Hungary, Czechoslovakia, and Yugoslavia, largely but not entirely along ethnic lines. Transylvania was shifted from Hungary to Greater Romania. The details were contained in the Treaty of Saint-Germain and the Treaty of Trianon. As a result of the Treaty of Trianon, 3.3 million Hungarians came under foreign rule. Although the Hungarians made up 54% of the population of the pre-war Kingdom of Hungary, only 32% of its territory was left to Hungary. Between 1920 and 1924, 354,000 Hungarians fled former Hungarian territories attached to Romania, Czechoslovakia, and Yugoslavia.
The Russian Empire, which had withdrawn from the war in 1917 after the October Revolution, lost much of its western frontier as the newly independent nations of Estonia, Finland, Latvia, Lithuania, and Poland were carved from it. Bessarabia was re-attached to Greater Romania, as it had been a Romanian territory for more than a thousand years.
The Ottoman Empire disintegrated, and much of its non-Anatolian territory was awarded to various Allied powers as protectorates. The Turkish core was reorganised as the Republic of Turkey. The Ottoman Empire was to be partitioned by the Treaty of Sèvres of 1920. This treaty was never ratified by the Sultan and was rejected by the Turkish republican movement, leading to the Turkish Independence War and, ultimately, to the 1923 Treaty of Lausanne.
Legacy.
The first tentative efforts to comprehend the meaning and consequences of modern warfare began during the initial phases of the war, and this process continued throughout and after the end of hostilities.
Memorials.
Memorials were erected in thousands of villages and towns. Close to battlefields, those buried in improvised burial grounds were gradually moved to formal graveyards under the care of organisations such as the Commonwealth War Graves Commission, the American Battle Monuments Commission, the German War Graves Commission, and Le Souvenir français. Many of these graveyards also have central monuments to the missing or unidentified dead, such as the Menin Gate memorial and the Thiepval Memorial to the Missing of the Somme.
On 3 May 1915, during the Second Battle of Ypres, Lieutenant Alexis Helmer was killed. At his graveside, his friend John McCrae, M.D., of Guelph, Ontario, Canada, wrote the memorable poem "In Flanders Fields" as a salute to those who perished in the Great War. Published in "Punch" on 8 December 1915, it is still recited today, especially on Remembrance Day and Memorial Day.
Liberty Memorial in Kansas City, Missouri, is a United States memorial dedicated to all Americans who served in World War I. The site for the Liberty Memorial was dedicated on 1 November 1921. On this day, the supreme Allied commanders spoke to a crowd of more than 100,000 people. It was the only time in history these leaders were together in one place. In attendance were Lieutenant General Baron Jacques of Belgium; General Armando Diaz of Italy; Marshal Ferdinand Foch of France; General Pershing of the United States; and Admiral D. R. Beatty of Great Britain. After three years of construction, the Liberty Memorial was completed and President Calvin Coolidge delivered the dedication speech to a crowd of 150,000 people in 1926.
Liberty Memorial is also home to The National World War I Museum, the only museum dedicated solely to World War I in the United States.
Cultural memory.
These beliefs did not become widely shared because they offered the only accurate interpretation of wartime events. In every respect, the war was much more complicated than they suggest. In recent years, historians have argued persuasively against almost every popular cliché of the First World War. It has been pointed out that, although the losses were devastating, their greatest impact was socially and geographically limited. The many emotions other than horror experienced by soldiers in and out of the front line, including comradeship, boredom, and even enjoyment, have been recognised. The war is not now seen as a 'fight about nothing', but as a war of ideals, a struggle between aggressive militarism and more or less liberal democracy. It has been acknowledged that British generals were often capable men facing difficult challenges, and that it was under their command that the British army played a major part in the defeat of the Germans in 1918: a great forgotten victory.
Though these historians have discounted as "myths" these perceptions of the war, they are common. They have dynamically changed according to contemporary influences, reflecting in the 1950s perceptions of the war as 'aimless' following the contrasting Second World War and emphasising conflict within the ranks during times of class conflict in the 1960s. The majority of additions to the contrary are often rejected.
Social trauma.
The social trauma caused by unprecedented rates of casualties manifested itself in different ways, which have been the subject of subsequent historical debate. Some people were revolted by nationalism and its results, and began to work towards a more internationalist world, supporting organisations such as the League of Nations. Pacifism became increasingly popular. Others had the opposite reaction, feeling that only strength and military might could be relied upon in a chaotic and inhumane world. Anti-modernist views were an outgrowth of the many changes taking place in society.
The experiences of the war led to a collective trauma shared by many from all participating countries. The optimism of "la belle époque" was destroyed, and those who had fought in the war were referred to as the Lost Generation. For years afterwards, people mourned the dead, the missing, and the many disabled. Many soldiers returned with severe trauma, suffering from shell shock (also called neurasthenia, a condition related to posttraumatic stress disorder). Many more returned home with few after-effects; however, their silence about the war contributed to the conflict's growing mythological status. In the United Kingdom, mass mobilisation, large casualty rates, and the collapse of the Edwardian era made a strong impression on society. Though many participants did not share in the experiences of combat or spend any significant time at the front, or had positive memories of their service, the images of suffering and trauma became the widely shared perception. Such historians as Dan Todman, Paul Fussell, and Samuel Heyns have all published works since the 1990s arguing that these common perceptions of the war are factually incorrect.
Discontent in Germany.
The rise of Nazism and fascism included a revival of the nationalist spirit and a rejection of many post-war changes. Similarly, the popularity of the Stab-in-the-back legend (German: "Dolchstoßlegende") was a testament to the psychological state of defeated Germany and was a rejection of responsibility for the conflict. This conspiracy theory of betrayal became common, and the German populace came to see themselves as victims. The "Dolchstoßlegende"'s popular acceptance in Germany played a significant role in the rise of Nazism. A sense of disillusionment and cynicism became pronounced, with nihilism growing. Many believed the war heralded the end of the world as they had known it because of the high fatalities among a generation of men, the dissolution of governments and empires, and the collapse of capitalism and imperialism.
Communist and socialist movements around the world drew strength from this theory and enjoyed a new level of popularity. These feelings were most pronounced in areas directly or harshly affected by the war. Out of German discontent with the still controversial Treaty of Versailles, Adolf Hitler was able to gain popularity and power. World War II was in part a continuation of the power struggle never fully resolved by the First World War; in fact, it was common for Germans in the 1930s and 1940s to justify acts of international aggression because of perceived injustices imposed by the victors of the First World War. American historian William Rubinstein wrote that:Rubinstein, W. D. (2004). "Genocide: a history". Pearson Education. p.7. ISBN 0-582-50601-8
The establishment of the modern state of Israel and the roots of the continuing Israeli-Palestinian Conflict are partially found in the unstable power dynamics of the Middle East which resulted from World War I. Prior to the end of the war, the Ottoman Empire had maintained a modest level of peace and stability throughout the Middle East. With the fall of the Ottoman government, power vacuums developed and conflicting claims to land and nationhood began to emerge. The political boundaries drawn by the victors of the First World War were quickly imposed, sometimes after only cursory consultation with the local population. In many cases, these continue to be problematic in the 21st-century struggles for national identity. While the dissolution of the Ottoman Empire at the end of World War I was pivotal in contributing to the modern political situation of the Middle East, including the Arab-Israeli conflict, the end of Ottoman rule also spawned lesser known disputes over water and other natural resources.
Views in the United States.
U.S. intervention in the war, as well as the Wilson administration itself, became deeply unpopular. This was reflected in the U.S. Senate's rejection of the Versailles Treaty and membership in the League of Nations. In the interwar era, a consensus arose that U.S. intervention had been a mistake, and the Congress passed laws in an attempt to preserve U.S. neutrality in any future conflict. Polls taken in 1937 and the opening months of World War II established that nearly 60% regarded intervention in WWI as a mistake, with only 28% opposing that view. But, in the period between the fall of France and the attack on Pearl Harbor, public opinion changed dramatically and, for the first time, a narrow plurality rejected the idea that the war had been a mistake.
New national identities.
Poland reemerged as an independent country, after more than a century. As a "minor Entente nation" and the country with the most casualties per capita, the Kingdom of Serbia and its dynasty became the backbone of the new multinational state, the Kingdom of Serbs, Croats and Slovenes (later renamed Yugoslavia). Czechoslovakia, combining the Kingdom of Bohemia with parts of the Kingdom of Hungary, became a new nation. Russia became the Soviet Union and lost Finland, Estonia, Lithuania, and Latvia, which became independent countries. The Ottoman Empire was soon replaced by Turkey and several other countries in the Middle East.
In the British Empire, the war unleashed new forms of nationalism. In Australia and New Zealand the Battle of Gallipoli became known as those nations' "Baptism of Fire". It was the first major war in which the newly established countries fought, and it was one of the first times that Australian troops fought as Australians, not just subjects of the British Crown. Anzac Day, commemorating the Australian and New Zealand Army Corps, celebrates this defining moment.
After the Battle of Vimy Ridge, where the Canadian divisions fought together for the first time as a single corps, Canadians began to refer to theirs as a nation "forged from fire". Having succeeded on the same battleground where the "mother countries" had previously faltered, they were for the first time respected internationally for their own accomplishments. Canada entered the war as a Dominion of the British Empire and remained so, although it emerged with a greater measure of independence. When Britain declared war in 1914 the dominions were automatically at war; at the conclusion, Canada, Australia, New Zealand, and South Africa were individual signatories of the Treaty of Versailles.
Economic effects.
One of the most dramatic effects of the war was the expansion of governmental powers and responsibilities in Britain, France, the United States, and the Dominions of the British Empire. In order to harness all the power of their societies, governments created new ministries and powers. New taxes were levied and laws enacted, all designed to bolster the war effort; many have lasted to this day. Similarly, the war strained the abilities of some formerly large and bureaucratised governments, such as in Austria–Hungary and Germany; however, any analysis of the long-term effects were clouded by the defeat of these governments.
Gross domestic product (GDP) increased for three Allies (Britain, Italy, and U.S.), but decreased in France and Russia, in neutral Netherlands, and in the three main Central Powers. The shrinkage in GDP in Austria, Russia, France, and the Ottoman Empire reached 30 to 40%. In Austria, for example, most pigs were slaughtered, so at war's end there was no meat.
In all nations the government's share of GDP increased, surpassing fifty percent in both Germany and France and nearly reaching that level in Britain. To pay for purchases in the United States, Britain cashed in its extensive investments in American railroads and then began borrowing heavily on Wall Street. President Wilson was on the verge of cutting off the loans in late 1916, but allowed a great increase in U.S. government lending to the Allies. After 1919, the U.S. demanded repayment of these loans. The repayments were, in part, funded by German reparations, which, in turn, were supported by American loans to Germany. This circular system collapsed in 1931 and the loans were never repaid. In 1934, Britain owed the US $4.4 billion of World War I debt.
Macro- and micro-economic consequences devolved from the war. Families were altered by the departure of many men. With the death or absence of the primary wage earner, women were forced into the workforce in unprecedented numbers. At the same time, industry needed to replace the lost labourers sent to war. This aided the struggle for voting rights for women. 
World War I further compounded the gender imbalance, adding to the phenomenon of surplus women. The deaths of nearly one million men during the war increased the gender gap by almost a million; from 670,000 to 1,700,000. The number of unmarried women seeking economic means grew dramatically. In addition, demobilisation and economic decline following the war caused high unemployment. The war increased female empolyment, however the return of demoblised men displaced many from the workforce, as did the closure of many of the wartime factories. Hence women who had worked during the war found themselves struggling to find jobs and those approaching working age were not offered the opportunity.
In Britain, rationing was finally imposed in early 1918, limited to meat, sugar, and fats (butter and oleo), but not bread. The new system worked smoothly. From 1914 to 1918 trade union membership doubled, from a little over four million to a little over eight million. Work stoppages and strikes became frequent in 1917–1918 as the unions expressed grievances regarding prices, alcohol control, pay disputes, fatigue from overtime and working on Sundays, and inadequate housing.
Britain turned to her colonies for help in obtaining essential war materials whose supply had become difficult from traditional sources. Geologists such as Albert Ernest Kitson were called upon to find new resources of precious minerals in the African colonies. Kitson discovered important new deposits of manganese, used in munitions production, in the Gold Coast.
Article 231 of the Treaty of Versailles (the so-called "war guilt" clause) declared Germany and its allies responsible for all "loss and damage" suffered by the Allies during the war and provided the basis for reparations. The total reparations demanded was 132 billion gold marks, which was far more than the total German gold or foreign exchange. The economic problems that the payments brought, and German resentment at their imposition, are usually cited as one of the more significant factors that led to the end of the Weimar Republic and the beginning of the dictatorship of Adolf Hitler. After Germany's defeat in World War II, payment of the reparations was not resumed. There was, however, outstanding German debt that the Weimar Republic had used to pay the reparations. Germany finished paying off the reparations in October 2010.

Tiananmen Square protests of 1989
The Tiananmen Square protests of 1989, also known as the June Fourth Incident in Chinese, were a series of popular demonstrations in and near Tiananmen Square in Beijing beginning on 15 April 1989. The protests ended with military suppression on 4 June, an event initially labeled and still widely known as the Tiananmen Square Massacre or Tiananmen Massacre. However, secret US Embassy cables obtained by Wikileaks and reported on by the Daily Telegraph "partly confirm the Chinese government's account of the early hours of June 4, 1989, which has always insisted that soldiers did not massacre demonstrators inside Tiananmen Square. Instead, the cables show that Chinese soldiers opened fire on protesters outside the centre of Beijing, as they fought their way towards the square from the west of the city." 
In the late 1970s, the Chinese leadership of Deng Xiaoping abandoned Maoist-style planned collectivist economics, and embraced market-oriented reforms. Due to the rapid pace of change, by the late 1980s, grievances over inflation, limited career prospects for students, and corruption of the party elite were growing rapidly. Communist governments were also losing legitimacy around the world, particularly in Eastern Europe. In April 1989, triggered by the death of deposed Communist Party General Secretary Hu Yaobang, a liberal reformer, mass gatherings and protests took place in and around Tiananmen Square. At its height, some half a million protesters assembled there. The demonstrations, consisting of local working residents as well as students, called for government accountability, freedom of the press, freedom of speech, and the restoration of workers' control over industry. Peaceful protests also occurred in other cities, such as Shanghai and Wuhan, while looting and rioting broke out in Xi'an and Changsha.
The movement lasted for about seven weeks. The government initially attempted to appease the protesters through concessions, but a student-led hunger strike galvanized support for the demonstrators around the country. Ultimately, Deng Xiaoping and other party elders resolved to use force to suppress the movement. Party authorities declared martial law on 20 May. Military convoys entered Beijing on the evening of 3–4 June. Under strict orders to clear the Square by dawn, the People's Liberation Army pushed through makeshift blockades set up by demonstrators in western Beijing on their way to Tiananmen Square. The PLA used live fire to clear their path of protesters. The exact number of civilian deaths is not known, and the majority of estimates range from several hundred to thousands.
Internationally, the Chinese government was widely condemned for the use of force against the protesters. Western governments imposed economic sanctions and arms embargoes. Following 4 June, the government conducted widespread arrests of protesters and their supporters, cracked down on other protests around China, expelled foreign journalists and strictly controlled coverage of the events in the domestic press. Officials deemed sympathetic to the protests were demoted or purged. General Secretary Zhao Ziyang, who was considered too sympathetic to the movement, was ousted in a party leadership reshuffle. The aftermath of the protests strengthened the power of orthodox Communist hardliners, and delayed further market reforms until Deng Xiaoping's 1992 southern tour. To this day, the government of the People's Republic of China continues to suppress public mention or discussion about the protests.
Name.
In the Chinese language, the incident is most commonly known as the June Fourth Incident. Colloquially, often a simple June Fourth () is used. The nomenclature of the former is consistent with the customary names of the other two great protests that occurred in Tiananmen Square: the May Fourth Movement of 1919, and the April Fifth Movement of 1976. "June Fourth" refers to the day on which the People's Liberation Army cleared Tiananmen Square of protesters, although actual operations began on the evening of 3 June. Some use the "June Fourth" designation solely to refer to the killings carried out by the Army, while others use it to refer to the entire movement. Names such as June Fourth Movement () and 89 Democracy Movement () are used to describe the event in its entirety.
In Chinese dissident circles and among people of the movement, it is commonly referred to as June Fourth Massacre () and June Fourth Crackdown (). To bypass internet censorship in China, which uniformly considers all the above-mentioned names too 'sensitive' for search engines and public forums, alternative names have sprung up to describe the events on the internet, such as May 35th, VIIV (Roman numerals for 6 and 4) and "Eight Squared" (i.e. 82 = 64).
The government of the People's Republic of China have used numerous names for the event since 1989, gradually reducing the intensity of terminology applied. As the events were unfolding, it was labelled a "Counterrevolutionary Riot", which was later changed to simply "Riot", followed by "Political Storm", and finally the leadership settled on the more neutralized phrase "Political Storm between Spring and Summer of 1989," which it uses to this day.
In English, the terms Tiananmen Square Protests or Tiananmen Square Crackdown are often used to describe the series of events. The term Tiananmen Square Massacre was also commonly used by the media, but journalistic use has waned in recent years. This is because much of the violence did not actually happen in Tiananmen, but outside the square in the city of Beijing near the Muxidi area. The term also gives a misleading impression that demonstrations only happened in Beijing, when in fact they occurred in many cities throughout China.
Background.
Challenges with reform.
At the Third Plenum of the Eleventh Communist Party Congress in 1978, the Chinese leadership initiated a series of economic and political reforms, which led to the gradual implementation of a market economy and some political liberalization that relaxed the system set up by Mao Zedong. These reforms were generally successful in the early years and well received by the public. However, the pace of political reform was slow, as corruption and nepotism pervaded the shift toward a free-market economy.
The state-mandated pricing system, in place since the 1950s, had long kept prices stable at low levels that reduced incentives to increase production. The initial reforms created a two-tier system where some prices were fixed while others were allowed to fluctuate. In a market with chronic shortages, this allowed people with powerful connections to buy goods at low prices and sell at market prices. In addition, the money supply had expanded too fast. At least a third of factories were unprofitable. The government tightened the money supply in 1988, leaving much of the economy without loans.
Following the 1988 Beidaihe meeting, the party leadership under Deng Xiaoping agreed to a transition to a market-based price system. News of the relaxation of price controls triggered waves of cash withdrawals, buying and hoarding all over China. The government panicked and rescinded the price reforms in less than two weeks, but its impact was pronounced for a much longer period of time. Inflation soared. Official indices report a Consumer Price Index increase of 30% in Beijing between 1987–88, leading to panic among salaried workers that they could no longer afford staple goods. Moreover, in the new market economy, unprofitable state-owned enterprises were pressured to cut costs. The "iron rice bowl", i.e., job security and a host of social benefits that come with it, ranging from medical care to subsidized housing, were at risk for a vast segment of the population.
Social disenfranchisement and legitimacy crisis.
Reformist leaders envisioned in 1978 that intellectuals would play a leading role in guiding the country through reforms, but this did not happen as planned. Despite the opening of new universities and increased enrollment, the state-directed education system did not adequately prepare for increasing market demand in the areas of agriculture, light industry, services, and foreign investment. The job market was especially limited for students specializing in social sciences and the humanities. Moreover, private companies no longer needed to accept students assigned to them by the state, and many high-paying jobs were offered on the basis of nepotism and favoritism. Gaining a good state-assigned placement meant navigating a highly inefficient bureaucracy that gave power to officials who had little expertise in their area of jurisdiction. Facing a dismal job market and limited chances of going abroad, intellectuals and students had a greater vested interest in political issues. Small-scale study groups, such as the "Democracy Salon" and the ""Caodi" Salon", began appearing on Beijing university campuses. These organizations motivated the students to get involved politically.
At the same time, the party's nominally socialist ideology faced a legitimacy crisis as it gradually adopted capitalist practices. Private enterprise gave rise to profiteers who took advantage of lax regulations, and who often flaunted their wealth in front of the 'have-nots' of society. Popular discontent was brewing over the lack of fairness in wealth distribution. Greed, not skill, appeared to be the most crucial success factor. There was widespread public disillusionment over the country's future. People wanted change, yet the power to define 'the correct path' continued to rest solely in the hands of the state.
Devising an appropriate response to the problems created by reforms opened a rift in the Chinese leadership. The reformers ("the right", led by Hu Yaobang) favoured political liberalization and a plurality of ideas as a channel to voice popular discontent, and supported further reforms. The conservatives ("the left", led by Chen Yun) said that the reforms had gone too far, and advocated for a return to greater state control to ensure social stability and to better align with the party's socialist ideology. Both sides needed the backing of paramount leader Deng Xiaoping to carry out important policy decisions.
1986 student demonstrations.
In the summer of 1986, astrophysics professor Fang Lizhi, who had returned from a tenure at Princeton University, began a personal tour around universities in China, speaking about liberty, human rights, and separation of powers. He became immensely popular and his recorded speeches were widely circulated among students. In response, Deng Xiaoping warned that Fang was worshipping Western lifestyles, capitalism, and multi-party systems, while undermining China's socialist ideology, traditional values, and the party's leadership.
Inspired by Fang and other 'people-power' movements around the world, in December 1986, student demonstrators staged protests against the slow pace of reform. The issues were wide-ranging, and included demands for economic liberalization, democracy, and rule of law. While the protests were initially contained in Hefei, where Fang lived, it quickly spread to Beijing and other major cities. The central leadership was alarmed by the protests, and accused the students of fomenting Cultural Revolution-style turmoil.
General Secretary Hu Yaobang was blamed for taking a soft attitude and mishandling the protests, thus undermining social stability. He was denounced thoroughly by conservatives. Hu was forced to resign as General Secretary on 16 January 1987. Following his resignation, the party began the "Anti Bourgeois Liberalization Campaign", taking aim at Hu, political liberalization, and Western-inspired ideas in general. The Campaign put a stop to student protests and tightened the political environment, but Hu remained popular with progressives within the party, intellectuals, and students.
Protest development.
Death of Hu Yaobang.
When Hu Yaobang suddenly died of a heart attack on 15 April 1989, students reacted strongly. Hu's death provided the initial impetus for students to gather in large numbers. In university campuses, many posters appeared eulogizing Hu, calling for a reversal of Hu's legacy. Within days, most posters were writing about broader political issues, such as freedom of the press, democracy, and corruption.
Small spontaneous gatherings to mourn Hu began on 15 April around Monument to the People's Heroes at Tiananmen Square. On the same day, many students at Peking University (PKU) and Tsinghua University erected shrines, and joined the gathering in Tiananmen Square in a piecemeal fashion. Organized student gatherings also began on a small scale in Xi'an and Shanghai on 16 April. On 17 April, students at the China University of Political Science and Law (CUPL) made a large wreath to commemorate Hu Yaobang. Its laying-party was on 17 April and a larger-than-expected crowd assembled. At five p.m., 500 CUPL students reached the eastern gate of the Great Hall of the People, near Tiananmen Square, to mourn Hu. The gathering featured speakers from various backgrounds giving public orations commemorating Hu and discussing social problems. However, it was soon deemed obstructive to the operation of the Great Hall, so police intervened and attempted to disperse the students by persuasion.
On the morning of 18 April, students remained in the Square. Some gathered around the Monument to the People's Heroes singing patriotic songs and listening to impromptu speeches by student organizers, others gathered at the Great Hall. Meanwhile, a few thousand students gathered at Xinhua Gate, the entrance to Zhongnanhai, the seat of the party leadership, where they demanded dialogue with the leadership. Police restrained the students from entering the compound. Students then staged a sit-in.
On 20 April, most students had been persuaded to leave Xinhua Gate. To disperse about 200 students that remained, police employed batons; minor clashes were reported. Many students felt they were abused by the Police, and rumours about police brutality spread quickly. The Xinhua Gate incident angered students on campus, where those who were not hitherto politically active decided to join the protests. Also on this date, a group of workers calling themselves the “Beijing Workers’ Autonomous Federation” issued two handbills challenging the central leadership.
Hu's state funeral took place on 22 April. On the evening of 21 April, some 100,000 students marched on Tiananmen Square, ignoring orders from Beijing municipal authorities that the Square was to be closed off for the funeral. The funeral, which took place inside the Great Hall and attended by the leadership, was broadcast live to the students. General Secretary Zhao Ziyang delivered the eulogy. The funeral seemed rushed, and only lasted 40 minutes, as emotions ran high in the Square. Students wept.
Security cordoned off the east entrance to the Great Hall, but several students pressed forward. Three of these students knelt on the steps of the Great Hall to present a petition and demanded to see Premier Li Peng. However, no leaders emerged from the Great Hall, leaving the students disappointed and angry; some called for a class boycott.
From 21 to 23 April, students began organizing under the banners of formal organizations. On 23 April, the "Beijing Autonomous University Students Union" ("the Union") was formed. It elected CUPL student Zhou Yongjun as chair; Wang Dan and Wu'erkaixi also emerged as leaders. From this vantage point, the Union called for a general class boycott at all Beijing universities. Such an independent organization operating outside of party jurisdiction alarmed the leadership.
On 22 April, near dusk, serious rioting broke out in Changsha and Xi'an. In Xi'an, arson from rioters destroyed cars and houses, and looting occurred in shops near the city's Xihua Gate. In Changsha, 38 stores were ransacked by looters. Over 350 people were arrested in both cities. In Wuhan, university students organized protests against the provincial government. As the situation became more volatile nationally, Zhao Ziyang called numerous meetings of the Politburo Standing Committee (PSC). Zhao stressed three points: discourage students from further protests and ask them to go back to class, use all measures necessary to combat rioting, and open forms of dialogue with students at different levels of government. Premier Li Peng called upon Zhao to condemn protestors and recognize the need to take more serious action. Zhao dismissed Li's views. Despite calls for him to remain in Beijing, Zhao left for a scheduled state visit to North Korea on 23 April.
Turning point: 26 April Editorial.
Zhao's departure to North Korea left Li Peng as the acting executive authority in Beijing. On 24 April, Li Peng and the PSC met with Beijing Party Secretary Li Ximing and mayor Chen Xitong to gauge the situation at the Square. The municipal officials wanted a quick resolution to the crisis, and framed the protests as a conspiracy to overthrow China's political system and major party leaders, including Deng Xiaoping. In Zhao's absence, the PSC agreed that firm action against protesters must be taken. On the morning of 25 April, President Yang Shangkun and Premier Li Peng met with Deng at the latter's residence. Deng endorsed a hardline stance and said an appropriate 'warning' must be disseminated via mass media to curb further demonstrations. The meeting firmly established the first official evaluation of the protests from the leadership, and highlighted Deng's having 'final say' on important issues. Li Peng subsequently ordered Deng's views to be drafted as a communique and issued to all high-level Communist Party officials in an effort to mobilize the party apparatus against protesters.
On 26 April, the party's official newspaper "People's Daily" issued a front-page editorial titled "It is necessary to take a clear-cut stand against disturbances." It accused "extremely small segments of opportunists" of plotting to overthrow the Communist Party and the political system. The statement enraged students, who interpreted it as a direct indictment on the protests and its cause. The editorial backfired. Instead of scaring students into submission, it antagonized the students against the state. The editorial proved to be a major sticking point for the remainder of the protests. It evoked memories of the 1976 Tiananmen Incident: an event that was initially branded an anti-government conspiracy with much the same language as the 26 April Editorial but was later rehabilitated as "patriotic" under Deng's leadership.
Organized by the Union, on 27 April some 50,000-100,000 students from all Beijing universities marched through the streets of the capital to Tiananmen Square, breaking through lines set up by police, and receiving widespread public support along the way, particularly from factory workers. The student leaders, eager to show the patriotic nature of the movement, also toned down anti-Communist slogans, choosing to present a message of "anti-corruption, anti-cronyism" but "pro-party". In a twist of irony, student factions who genuinely called for the overthrow of the Communist Party gained traction as a result of the 26 April Editorial.
The stunning success of the March forced the government into making concessions and meeting with student representatives. On 29 April, State Council spokesman Yuan Mu met with appointed representatives of government-sanctioned student associations. While the talks discussed a wide range of issues, including the editorial, the Xinhua Gate incident, and freedom of the press, they achieved few substantive results. Independent student leaders such as Wuer Kaixi refused to attend.
The government's tone grew increasingly conciliatory as Zhao Ziyang returned from Pyongyang on 30 April and resumed his executive authority. In Zhao's view, the hardliner approach had proven to be useless, and concession was the only alternative. Zhao asked that the press be opened to report the movement positively, and delivered two sympathetic speeches on 3–4 May. In the speeches, Zhao said that the student's concerns about corruption were legitimate, and that the student movement was patriotic in nature. The speeches essentially negated the message presented by 26 April Editorial. While some 100,000 students marched on the streets of Beijing on 4 May to commemorate the May Fourth Movement and repeat demands from earlier marches, many students were satisfied with the government's concessions. On 4 May, all Beijing universities except PKU and BNU announced the end of the class boycott. Subsequently, the majority of students began to lose interest in the movement.
Protests escalate.
Preparing for dialogue.
The leadership was divided on how to respond to the movement as early as mid-April. After Zhao Ziyang's return from North Korea, the divisions intensified. Those who supported continued dialogue and a soft approach with students rallied behind Zhao Ziyang, while hardliner conservatives who opposed the movement rallied behind Premier Li Peng. Zhao and Li clashed at a PSC meeting on 1 May. Li maintained that the need for stability overrides all else, while Zhao said that the party should show support for increased democracy and transparency. Zhao pushed the case for further dialogue.
In preparation for dialogue, the Autonomous Student Union elected representatives to a formal Dialogue Delegation. However, the Union leaders were reluctant to let the Delegation unilaterally take control of the movement. Facing internal discord and declining engagement from the student body at large, a group of charismatic leaders, including Wang Dan and Wu'erkaixi, called for more radical measures to regain momentum. They believed that the government's 'dialogue' was merely a way to trick the students into submission. They began mobilizing students for a hunger strike on 11 May.
Hunger strikes begin.
Students began the hunger strike on 13 May, two days prior to the highly publicized state visit by Soviet leader Mikhail Gorbachev. Knowing that the welcoming ceremony for Gorbachev was scheduled to be held on the Square, student leaders wanted to use the hunger strike there as a bargaining chip to force the government into meeting their demands. Moreover, the hunger strike gained widespread sympathy from the population at large and earned the student movement the moral high ground that it sought. By the afternoon of 13 May, some 300,000 were gathered at the Square.
Inspired by the course of events in Beijing, protests and strikes began at universities in other cities, with many students traveling to Beijing to join the demonstration. Generally, the demonstration at Tiananmen Square was well-ordered, with daily marches of students from various Beijing-area colleges displaying their solidarity with the class boycott and with the demands of the protest. The students sang "The Internationale", the world socialist anthem, on their way to, and within, the square.
Afraid that the movement would now spin out of control, Deng Xiaoping asked that the Square be cleared for the Gorbachev visit. Executing Deng's request, Zhao used a soft approach, and directed his subordinates to coordinate negotiations with students immediately. Zhao believed he could appeal to the students' patriotism, and that the students understood signs of internal turmoil during the Sino-Soviet summit would embarrass the nation (not just the government). On the morning of 13 May, Yan Mingfu, head of the Party's United Front, called an emergency meeting, gathering prominent student leaders and intellectuals, including Liu Xiaobo, Chen Ziming and Wang Juntao. Yan said the government was prepared to hold immediate dialogue with student representatives, but that the Tiananmen welcoming ceremony for Gorbachev would be cancelled whether the students withdraw or not - in effect removing the bargaining power the students thought they possessed. The announcement sent the student leadership into disarray.
Gorbachev visit.
Press restrictions were loosened significantly during early to mid May. State media began broadcasting footage sympathetic to protesters and the movement, including the hunger strikers. On 14 May, intellectuals led by Dai Qing gained permission from Hu Qili to bypass government censorship and air the progressive views of the nation's intellectuals on "Guangming Daily". The intellectuals then issued an urgent appeal for the students to leave the Square. Many students, however, believed that the intellectuals were speaking for the government, and refused to budge. That evening, formal negotiations took place between government representatives led by Yan Mingfu and student representatives led by Shen Tong and Xiang Xiaoji. Yan affirmed the patriotic nature of the student movement and pleaded for the students to withdraw from the Square. While Yan's apparent sincerity for compromise satisfied some students, the meeting grew increasingly chaotic as competing student factions relayed uncoordinated and incoherent demands to the leadership. Shortly after student leaders learned that the event had not been broadcast nationally as promised, the meeting fell apart. Yan then personally went to the Square to appeal to the students, even offering himself to be held hostage. He also took the student's plea to Li Peng the next day, asking Li to consider formally retracting the 26 April Editorial and branding the movement as "patriotic and democratic." Li dismissed the idea.
The students remained in the Square during the Gorbachev visit; his welcoming ceremony was held at the airport. The Sino-Soviet summit, the first of its kind in some thirty years, marked the normalization of Sino-Soviet relations, and was seen as a breakthrough of tremendous historical significance for China's leaders. That the smooth proceedings of this event had been derailed by the student movement embarrassed the leadership and drove many moderates onto a more 'hardliner' path. The summit between Deng and Gorbachev took place at the Great Hall amidst the backdrop of commotion and protest in the Square. When Gorbachev met with Zhao on 16 May, Zhao told the Soviet leader, and by extension the international press, that Deng was still the 'paramount authority' in China. Deng felt that this remark was Zhao's attempt to shift blame for mishandling the movement to him. The statement marked a decisive split between the country's two most senior leaders.
Gathering momentum.
The hunger strike galvanized support for the students and aroused sympathy across the country. Around a million Beijing residents from all walks of life demonstrated in solidarity on 17–18 May. These included PLA personnel, police officers, and lower party officials. Many grassroots Party and Youth League organizations, as well as government-sponsored labour unions, encouraged their membership to demonstrate. In addition, several of China's non-Communist parties sent a letter to Li Peng in support of students. The Chinese Red Cross issued a special notice and sent in a large number of personnel to provide medical services to the hunger strikers on the Square. After the departure of Mikhail Gorbachev, many foreign journalists remained in the Chinese capital to cover the protests, giving the movement international spotlight. Western governments urged Beijing to exercise restraint. 
The movement, on the wane by the end of April, now regained momentum that seemed unstoppable. By 17 May, as students from across the country poured into the capital to join the movement, protests of varying size were occurring in some 400 Chinese cities. Students demonstrated at local party branches in Fujian, Hubei, and Xinjiang. Without a clear position from the Beijing leadership, local authorities did not know how to respond. Since the demonstrations now incorporated a wide range of social groups with varying grievances, it became increasingly unclear with whom the government could negotiate, and what exactly the demands were. For its part, the government remained indecisive on how to deal with the situation, as its authority and legitimacy gradually eroded, with the hunger strikers now occupying moral high ground. These combined circumstances put immense pressure on the authorities to act, and martial law was discussed as a viable response.
Since the situation seemed intractable, the weight of taking decisive action fell on paramount leader Deng Xiaoping. On 17 May, a PSC meeting was called at Deng's residence. At the meeting, Zhao Ziyang's concessions-based strategy was criticized. Li Peng and Deng asserted that by making a conciliatory speech on 4 May, Zhao exposed divisions within the top leadership and emboldened the students. Deng warned that if Beijing is not pacified quickly, the country risked civil war and another Cultural Revolution; his views were echoed by the party elders. Deng then moved to declare martial law as a show of the government's no-tolerance stance. To justify martial law, the demonstrators were described as tools of "bourgeois liberalism" advocates who were pulling the strings behind the scenes, as well as tools of elements within the party who wished to further their personal ambitions.
On the evening of 17 May, the PSC met at Zhongnanhai to finalize plans for martial law. Zhao announced to the body that he was ready to "take a leave", citing he could not bring himself to carry out martial law. Hu Qili also voiced his reluctance. While Li Peng and Yao Yilin both supported declaring martial law, Qiao Shi was ambivalent. Qiao said that while he opposed further concessions, he did not see martial law as a practical way to resolve the matter. The elders in attendance at the meeting, Bo Yibo and Yang Shangkun, urged the PSC to follow Deng's orders. Zhao did not consider the inconclusive PSC vote to have legally binding implications on martial law; Yang, in his capacity as Vice-Chairman of the Central Military Commission, went on to mobilize the military to move into the capital. 
Li Peng met with students for the first time on 18 May in an attempt to placate public concern over the hunger strike. During the talks, student leaders once again demanded that the government rescind the 26 April Editorial and affirm the student movement as "patriotic". Li Peng said the government's main concern was sending hunger strikers to hospital. The discussions yielded little substantive results, but gained student leaders prominent airtime on national television.

In the early morning of 19 May, Zhao Ziyang went to Tiananmen in what became his political swan song. He was accompanied by Wen Jiabao. Li Peng also went to the Square, but left shortly thereafter. At 4:50 am Zhao made a speech with a bullhorn to a crowd of students, urging the students to end the hunger strike. He told the students that they were still young and urged them to stay healthy and not to sacrifice themselves without due concern for their futures. Zhao's emotional speech was applauded by some students. It would be his last public appearance.
Outside of Beijing.
University students in Shanghai also took to the streets to commemorate the death of Hu Yaobang and protest against certain policies of the government. In many cases, these were supported by the universities' Party committees. Jiang Zemin, then-Municipal Party Secretary, addressed the student protesters in a bandage and 'expressed his understanding', as he was a former student agitator before 1949. At the same time, he moved swiftly to send in police forces to control the streets and to purge Communist Party leaders who had supported the students.
On 19 April, the editors of the "World Economic Herald", a magazine close to reformists, decided to publish a commemorative section on Hu. Inside was an article by Yan Jiaqi, which commented favourably on the Beijing student protests, and called for a reassessment of Hu's 1987 purge. Sensing the conservative political trends in Beijing, Jiang Zemin demanded that the article be censored. Many newspapers were printed with a blank page. Jiang then suspended Qin Benli. His decisive action earned accolades from party elders, who praised Jiang's loyalty.
In Hong Kong, on 27 May, over 300,000 people gathered at Happy Valley Racecourse for a gathering called "Democratic songs dedicated for China." Many Hong Kong celebrities sang songs and expressed their support for the students in Beijing. The following day, a procession of 1.5 million people, one fourth of Hong Kong's population, led by Martin Lee, Szeto Wah and other organization leaders, paraded through Hong Kong Island. Across the world, especially where ethnic-Chinese lived, people gathered and protested. Many governments, including those of the United States and Japan, issued travel warnings to China.
Military action.
Martial law.
On 19 May, the PSC met with military leaders and party elders. Deng presided over the meeting and said that martial law was the only option. At the meeting Deng declared that he was 'mistaken' in choosing Hu Yaobang and Zhao Ziyang as his successors, and resolved to remove Zhao from his position. Deng also vowed to deal resolutely with Zhao's supporters and begin propaganda work. 
The Chinese government declared martial law on 20 May, and deployed People's Liberation Army (PLA) forces in three to four major vehicle convoys to Beijing. Their entry into the city was blocked at its suburbs by throngs of protesters. Tens of thousands of demonstrators surrounded military vehicles, preventing them from either advancing or retreating. Protesters lectured soldiers and appealed to them to join their cause; they also provided soldiers with food, water, and shelter. Seeing no way forward, the authorities ordered the army to withdraw on 24 May. All government forces retreated to bases outside the city. While the Army's retreat was initially seen as 'turning the tide' in favour of protesters, in reality mobilization took place across the country for a final assault; every Military Region (MR) deployed soldiers in the outskirts of Beijing except for the Capital MR itself. Some units arrived by air, while others arrived at Shahe railway station in suburban Beijing. Guangzhou's civil aviation authorities put regular airline tickets on hold to prepare for transporting military units.
At the same time, internal divisions intensified within the student movement itself. By late May, the students became increasingly disorganized with no clear leadership or unified course of action. Moreover, Tiananmen Square was overcrowded and facing serious hygiene problems. Hou Dejian suggested an open election of the student leadership to speak for the movement, but was met with opposition. Meanwhile, Wang Dan moderated his position, ostensibly sensing the impending military action and consequences, and advocated for a temporary withdraw from Tiananmen Square to re-group on campus, but this was opposed by 'hardliner' student factions who wanted to hold the Square. The increasing internal friction would lead to struggles for control of the loudspeakers in the middle of the square in a series of 'mini-coups': whoever controlled the loudspeakers was 'in charge' of the movement. Some students would wait at the train station to greet arrivals of students from other parts of the country in an attempt to enlist factional support.
1 and 2 June.
For the party leadership, the days leading up to 4 June were crucial in their decision making. The leadership agreed that it was necessary to end the “turmoil,” and that the students occupying the Square should return to their campuses. However, they struggled with the idea of using force. In order to carry out the clearing of the Square, the members of the Politburo needed to agree that using martial law to restore order was the only option. On 1 June Li Peng issued a report titled “On the True Nature of the Turmoil”, which was circulated to every member of the Politburo. The report aimed to persuade the Politburo of the necessity and legality of clearing Tiananmen Square by referring to the protestors as terrorists and counterrevolutionaries. The report stated that turmoil was continuing to grow, the students had no plans to leave, and they were gaining popular support.
Further justification for martial law came in the form of a report submitted by the Ministry of State Security (MSS) to the party leadership, which emphasized the infiltration of bourgeois liberalism into China and the negative effect that the West – particularly the United States – had on the students. The MSS expressed its belief that American forces had intervened in the student movement in hopes of overthrowing the Communist Party. The report created a sense of urgency within the party, and provided justification for military action. In conjunction with the plan to clear the Square by force, the Politburo received word from the martial law troops headquarters stating that the troops were ready to help stabilize the capital, and that they understood the necessity and legality of martial law to overcome the turmoil.
On 2 June, the movement saw an increase in action and protest, solidifying the CPC’s decision that it was time to act. Protests broke out as newspapers published articles that called for the students to leave Tiananmen Square and end the movement. Many of the students in the Square were not willing to leave and were outraged by the articles. They were also outraged by "Beijing Daily’s" 1 June article “Tiananmen, I Cry for You”, written by a fellow student who had become disillusioned with the movement, as he thought it was chaotic and disorganized. In response to the articles, thousands of students lined the streets of Beijing to protest against leaving the Square.
On 2 June, three intellectuals, Liu Xiaobo, Zhou Duo, Gao Xin, and a Taiwanese singer Hou Dejian declared a second hunger strike because they wanted to revive the pro-democracy movement. After weeks of occupying the Square, the students were tired, and internal rifts opened between moderate and hardliner student groups. In their declaration speech, the hunger strikers openly criticized the government’s suppression of the movement to remind the students that their cause was worth fighting for, and pushed them to continue their occupation of the Square.
During a meeting on 2 June, the party formally moved to clear the Square by force. Records from this meeting indicate that the Party Elders (Deng, Li Xiannian, Yang Shangkun, Peng Zhen and Wang Zhen) agreed with the PSC that the Square needed to be cleared as quickly as possible. They also agreed that the Square needed to be cleared as peacefully as possible, but if protesters did not cooperate, the troops were authorized to use force to complete the job. In preparation for clearing the Square, martial law troops moved into Beijing. On the morning of 2 June, newspapers reported that troops were positioned in ten key areas in the city. Around midnight of 2 June an order went out to the remaining martial law troops to move to designated areas. After finalizing the decision to clear the Square, the CPC intended to act quickly. On the evening of 2 June, there were reports that a police Jeep ran into four civilians, killing three, and injuring the other. This incident sparked fear that the army and the police were trying to advance into Tiananmen Square. Student leaders issued emergency orders for the students to set up roadblocks at major intersections to prevent the advance of the large numbers of armed troops that were attempting to infiltrate the Square. In the early hours of 3 June, the first reports of violence on both sides were reported.
3 and 4 June: Military advances to Tiananmen Square.
Soldiers and tanks from the 27th and 38th Armies of the People's Liberation Army were sent to take control of Beijing and clear Tiananmen Square. The 27th Army was commanded by a relative of Yang Shangkun. Intelligence reports also indicated that 27th and 38th units were brought in from outside provinces because the PLA troops were considered to be sympathetic to demonstrators. Reports described the 27th as having been responsible for most civilian deaths and suggested that elements of the 27th established defensive positions in Beijing, potentially to defend against attacks by other military units. There were rumours at the time that high-ranking officials sympathised with the pro-democracy protesters and reports of defiance among other troops. Major General Xu Qinxian, commander of the 38th Army, shocked the top leadership when he refused a verbal order from General Li Laizhu to send the 38th in to clear the square; Xu had insisted on a written order. Xu was immediately removed from command and was later jailed for five years and expelled from the Party.
As word spread that hundreds of thousands of troops were advancing from all four directions, residents flooded the streets to block them. As they had done two weeks earlier, people set up barricades at major intersections. At about 10:30 pm, near the Muxidi apartment buildings (home to high-level Party officials and their families), the army began firing live bullets at protestors, killing many. 
Some sources say that protesters first threw rocks and Molotov cocktails at police and army vehicles and lit many vehicles on fire in the streets all around Tiananmen, some with their occupants still inside them. There were reports of soldiers being burned alive in their armoured personnel carriers while others were beaten to death. Therefore, soldiers responded by opening fire on protesters. Soldiers raked apartment buildings in the area with gunfire, and some people inside or on their balconies were shot.
The reporting of Timothy Brook and others say that the army was ordered to get to the Square by midnight. Getting desperate, because they were unable to move forward, it was decided by unknown officials to use whatever means were necessary, and the army therefore opened fire on the civilians blocking their way. John Pomfret, reporter from the Washington Post, concluded later that "Deng and the Party elders made the decision that, because they believed this was a nationwide counterrevolutionary movement similar to what was happening in the Soviet Union, they needed to make a bloody stand to cower their population back into submission." The first rounds caught the civilians by surprise and at first they did not believe the army was using live ammunition. Live ammunition, however, did not drive the people from the streets.
As the army advanced towards the square, a battle raged in the surrounding streets. The army attempted to clear the streets using tear gas and gunfire. Protesters had blocked the slowly advancing army by constructing barricades of vehicles, and "in other cases army is breaking though human barriers and they protestors have to be shot." Many injured citizens were saved by rickshaw drivers who ventured into the no-man's-land between the soldiers and crowds and carried the wounded off to hospitals. During the military action, many people wore black armbands in protest against the government, crowding boulevards or congregating by smoking barricades. In several cases, soldiers were pulled from tanks, beaten and killed by protesters.
Meanwhile, the PLA systematically established checkpoints around the city, chasing after protesters and blocking off the university district.
Within the Square itself, there was a debate between those who wished to withdraw peacefully, including Han Dongfang, and those who wished to stand within the square, such as Chai Ling.
At about 1:00 am, the army finally reached Tiananmen Square and waited for orders from the government. The soldiers had been told not to open fire, but they had also been told that they must clear the square by 6:00 a.m.–-no exceptions. They made a final offer of amnesty if the few thousand remaining students would leave. About 4:00 am, student leaders put the matter to a vote: Leave the square, or stay and face the consequences. 
The remaining students, numbering a few hundred, left the square under the military's watch before dawn.
Armored personnel carriers (APCs) rolled up the roads, firing ahead and off to the sides. BBC reporter Kate Adie spoke of "indiscriminate fire" within the square. Eyewitness reporter Charlie Cole also saw Chinese soldiers firing Type 56 rifles into the crowd near an APC which had just been torched.
Students who sought refuge in buses were pulled out by groups of soldiers and beaten with heavy sticks. Some students attempting to leave the square were beaten. Leaders of the protest inside the square, where some had attempted to erect flimsy barricades ahead of the APCs, were said to have "implored" the students not to use weapons (such as Molotov cocktails) against the oncoming soldiers. Meanwhile, many students apparently were shouting, "Why are you killing us?" Around 4:30 am on 4 June, tanks smashed into the square, crushing vehicles and people with their treads, according to Cole. By 5:40 am 4 June, the Square had been cleared. Later accounts by foreign journalists reported few casualties during the Square-clearing process itself, citing that much of the killings happened in the Muxidi area on the way to the Square but not inside it.
On the morning of 5 June, protesters, parents of the injured and dead, workers and infuriated residents tried to enter the blockaded square but were shot at by the soldiers. The soldiers shot them in the back when they were running away. These actions were repeated several times.
After order was restored in Beijing on 4 June, protests continued in other cities of mainland China for several days. There were large protests in Hong Kong, where people again wore black in solidarity with the demonstrators in Beijing. There were protests in Guangzhou, and large-scale protests in Shanghai with a general strike. There were also protests in other countries, many adopting the use of black armbands as well. According to Amnesty International at least 300 people were killed in Chengdu on 5 June. Troops in Chengdu used concussion grenades, truncheons, knives and electric cattle prods against civilians. Hospitals were ordered to not accept students and on the second night the ambulance service was stopped by police.
By and large, the government regained control in the week following the military's seizure of the Square. A political purge followed in which officials responsible for organizing or condoning the protests were removed, and protest leaders jailed.
Number of deaths.
The number of dead and wounded remains unclear because of the large discrepancies between the different estimates, which range from several hundred to several thousand. Some of the early estimates were based on reports of a casualty figure of 2,600 from the Chinese Red Cross. PBS Foundation claim the official Chinese government figure is 241 dead, including soldiers, and 7,000 wounded.
Nicholas D. Kristof of "The New York Times" wrote that due to the lack of physical evidence it is impossible to determine the actual number of casualties, but that "it seems plausible that about fifty soldiers and policemen were killed, along with 400 to 800 civilians."
The Chinese government has maintained that there were no deaths within the Square itself. Jay Mathews, former Beijing bureau chief for the Washington Post said "as far as can be determined from the available evidence, no one died that night in Tiananmen Square". Videos taken there at the time recorded the sound of gunshots but there is no video showing anyone being shot. The State Council claimed 5,000 PLA and 2,000 civilians wounded. Yuan Mu, the spokesman of the State Council, said that about 300 soldiers and civilians died, including 23 students from universities in Beijing, along with a number of people he described as "ruffians". According to Chen Xitong, then Beijing mayor, 200 civilians and several dozen soldiers died. Other sources stated that 3,000 civilians and 6,000 soldiers were injured.
According to "The Washington Post" first Beijing bureau chief, Jay Mathews: "A few people may have been killed by random shooting on streets near the square, but all verified eyewitness accounts say that the students who remained in the square when troops arrived were allowed to leave peacefully. Hundreds of people, most of them workers and passersby, did die that night, but in a different place and under different circumstances." US ambassador James Lilley's account of the massacre notes that US State Department diplomats witnessed Chinese troops opening fire on unarmed people and based on visits to hospitals around Beijing a minimum of hundreds had been killed.
General consensus has emerged that much of the shooting took place outside of the Square; thus a count of deaths within the Square is not reflective of the scale of violence that took place. In addition, the Army reportedly fired on students after they left the Square, especially in the area near the Beijing concert hall.
Reactions.
Shanghai.
On 5 June, students marched very quickly on the streets and stopped traffic using roadblocks. Factory workers skipped work and railway traffic was also blocked. Public transport was also suspended early in the morning. According to the British Broadcasting Corporation “ten thousand staff members and workers could not get to work on time”.
The next day, The Shanghai Municipal Government sent out 6,500 people to remove the roadblocks. According to reports, “At 8:45 pm the number 161 train from Beijing ran over nine people who had gathered at the spectacle of a blocked locomotive. Five of them died. By 10 pm more than thirty thousand people had gathered at the scene, interrupting rail traffic and creating a disturbance. Protesters beat up the train engineer, set fire to railcars, and prevented fire trucks from entering the site”.
On 7 June,“At Tongji University, East China Normal University, and Shanghai Polytechnic University, students stormed school auditoriums and classroom buildings, where they erected biers” (meaning a coffin along with its stand). More and more students erected roadblocks and interrupted traffic, and approximately 3,000 students left campus.
On the evening of 7 June, Shanghai Mayor Zhu Rongji gave a televised speech, in which he stated “As mayor, I solemnly declare that neither the Party Committee nor the Municipal Government has considered calling in the army. We have never envisaged military control or martial law; we seek only to stabilize Shanghai, to steady the situation, to insist on production, and to ensure normal life”.
Xi’an.
On 5 and 6 June, students marched, set up roadblocks, and stopped workers from entering factories. By 8 June, provincial authorities said that the city had stabilized and called for “restraint of rioters and avoidance of face-to-face confrontation or any escalation of conflict”.
Wuhan.
On 5 June, approximately 20,000 students from the University of DongJin marched to Tiananmen Square. Some also blocked the “Yangtze River Railway bridge for eight hours, and another four thousand massed in the square in front of the railway station”. The next day, students continued demonstrating in the streets and stopped traffic. About one thousand students “staged a sit-in on the railroad tracks”. Rail traffic on the Beijing-Guangzhou and Wuhan-Dalian lines was interrupted. The students also urged workers from major enterprises to go on strike.
On the early morning of 7 June students used buses to block traffic; “They held a memorial at Dadongmen and roadblocks were erected at intersections”. A small group of students stopped a freight train and “poured gasoline over the freight cars but were stopped in the nick of time by arriving police”. The situation in the city was tense and residents “withdrew cash and began panic buying”.
Nanjing.
On 5, 6 and 7 June, students marched, made speeches, blocked traffic and tried to stop workers from working. On 7 June, “Around 7 am more than four hundred students from four colleges including Hehai University, blocked the Yangtze River bridge with four buses, allowing only mail trucks and ice deliveries to pass”. In the early evening traffic was still blocked. Students from schools including Nanjing University set up “roadblocks at the Zhongyangmen Railway Bridge; not a single train could pass through from 8:40 am until 4 pm, when the students were finally persuaded to evacuate”. Traffic resumed by the end of the day.
On 8 June, students from Nanjing University and Hehai University “retook an overpass one kilometer from the Nanjing Railway Station, halting traffic”. Students also staged “a sit-in at the south end of the highway section of the Nanjing Yangtze River Bridge and at the Zhongyangmen section of the Beijing Shanghai rail line”. The Jiangsu Provincial Party informed the students that the situation was way out of control, and stated that Public Security would punish the people responsible.
Deng addresses the Army.
On 9 June, Deng Xiaoping appeared in public for the first time since the protests began. He started his speech to a group of generals in Beijing by recognizing the “martyrs” (PLA soldiers who had died). Deng stated that the goal of the movement was to overthrow the Party and the state. “Their goal is to establish a totally Western-dependent bourgeois republic,” Deng said of the protesters. Deng argued that protesters had complained about corruption to cover their real motive, which was to replace the socialist system.
He said that "the entire imperialist Western world plans to make all socialist countries discard the socialist road and then bring them under the monopoly of international capital and onto the capitalist road".
International reaction.
The events at Tiananmen were the first of their type shown in detail on Western television. The Chinese government's response was denounced, particularly by Western governments and media. Criticism came from both Western and Eastern Europe, North America, Australia and some east Asian and Latin American countries. Notably, many Asian countries remained silent throughout the protests; the government of India responded to the massacre by ordering the state television to pare down the coverage to the barest minimum, so as not to jeopardize a thawing in relations with China, and to offer political empathy for the events. North Korea, Cuba, Czechoslovakia, and East Germany, among others, supported the Chinese government and denounced the protests. Overseas Chinese students demonstrated in many cities in Europe, America, the Middle East and Asia.
Aftermath.
Arrests of student leaders.
Wu Guoguang, former aide to Zhao Ziyang was quoted as saying that the account of 38th Army commander Maj. Gen. Xu's revealed for the first time that the Central Military Commission issued verbal orders fearing written records of the crackdown would go down in history; he said this suggested they knew the action was unlawful. Chinese authorities summarily tried and executed many of the workers they arrested in Beijing. In contrast, the students – many of whom came from relatively affluent backgrounds and were well-connected – received much lighter sentences. Wang Dan, the student leader who topped the most wanted list, spent seven years in prison. Many of the students and university staff implicated were permanently politically stigmatized, some never to be employed again. Some dissidents were able to escape to the United States, the United Kingdom, France, and other Western nations under Operation Yellowbird that was organized from Hong Kong, a British territory at the time.
Smaller protest actions continued in other cities for a few days. Some university staff and students who had witnessed the killings in Beijing organised or spurred commemorative events upon their return to school. At Shanghai's prestigious Jiaotong University, for example, the party secretary organised a public commemoration event, with engineering students producing a large metal wreath. However, these commemorations were quickly put down, with those responsible being put to death by firing squad.
During and after the demonstration, the authorities attempted to arrest and prosecute the student leaders of the Chinese democracy movement, notably Wang Dan, Chai Ling, Zhao Changqing and Wuer Kaixi. Wang Dan was arrested, convicted and sent to prison, then allowed to emigrate to the United States on the grounds of medical parole. As a lesser figure in the demonstrations, Zhao was released after six months in prison. However, he was once again incarcerated for continuing to petition for political reform in China. Wuer Kaixi escaped to Taiwan. He is married and holds a job as a political commentator on Taiwanese national radio. Chai Ling escaped to France, and then to the United States. In a public speech given at the University of Michigan in November 2007, Wang Dan commented on the current status of former student leaders: Chai Ling started a hi-tech company in the US, while Li Lu became an investment banker in Wall Street and started a company. Wang Dan said his plan was to find an academic job in the US after receiving his PhD from Harvard University. Chai Ling has since started the non-profit organization 'All Girls Allowed,' devoted to helping women in China and to fighting China's One Child Policy.
Chen Ziming and Wang Juntao were arrested in late 1989 for their involvement in the 1989 Tiananmen Square protests. Chinese authorities alleged they were the “black hands” behind the movement. Both Chen and Wang rejected the allegations made against them. They were put on trial in 1990 and sentenced to 13 years in prison.
High-level political changes.
To purge sympathizers of Tiananmen demonstrators, the Communist Party initiated a one and half year long program similar to Anti-Rightist Movement. It aimed to "deal strictly with those inside the party with serious tendencies toward bourgeois liberalization". Four million people were reportedly investigated for their role in the protests. More than 30,000 communist officers were deployed to assess political reliability of more than one million government officials. The authorities arrested tens if not hundreds of thousands of people across the country. Some were seized in broad daylight while they walked in the street; others were arrested at night. Many were jailed or sent to labor camps. They were often denied access to see their families and often put in cells so crowded that not everyone had space to sleep. Dissidents shared cells with murderers and rapists, and torture was not uncommon.
The Party leadership expelled Zhao Ziyang from the Politburo Standing Committee of the Communist Party of China (PSC), because he opposed martial law, and Zhao remained under house arrest until his death. Hu Qili, a PSC member who opposed the martial law but abstained from voting, was also removed from the committee. He was, however, able to retain his party membership, and after "changing his opinion", was reassigned as deputy minister of Machine-Building and the Electronics Industry. Another reform-minded Chinese leader, Wan Li, was also put under house arrest immediately after he stepped out of his plane at Beijing Capital International Airport upon returning from his shortened trip abroad; the authorities declared his detention to be on health grounds. When Wan Li was released from his house arrest after he finally "changed his opinion" he, like Qiao Shi, was transferred to a different position with equal rank but a mostly ceremonial role. Several Chinese ambassadors abroad claimed political asylum.
The event elevated Jiang Zemin – then Party Secretary of Shanghai – to become the General Secretary of the Communist Party of China. Jiang's decisive actions in Shanghai, in closing down reform-leaning publications and preventing deadly violence, won him support from party elders in Beijing. Members of the government prepared a white paper explaining the government's viewpoint on the protests. An anonymous source within the PRC government smuggled the document out of China, and Public Affairs published it in January 2001 as the "Tiananmen Papers".
Media and discourse.
The suppression on 4 June marked the end of a period of relative press freedom in China, and media workers—both foreign and domestic—faced heightened restrictions and punishment in the aftermath of the crackdown. State media mostly gave reports sympathetic to the students in the immediate aftermath. As a result, those responsible were all later removed. Two news anchors who reported this event on 4 June in the daily "Xinwen Lianbo" broadcast on China Central Television were fired because they displayed sad emotions. Wu Xiaoyong, the son of former foreign minister Wu Xueqian was removed from the English Program Department of Chinese Radio International, ostensibly for his sympathies towards protesters. Editors and other staff at "People's Daily", including director Qian Liren and Editor-in-Chief Tan Wenrui, were also sacked because of reports in the paper which were sympathetic towards the protesters. Several editors were arrested, with Wu Xuecan, who organised the publication of an unauthorised Extra edition, sentenced to four years' imprisonment.
Several foreign journalists who had covered the crackdown were expelled in the weeks that followed, while others were harassed by authorities or blacklisted from reentering the country. In Shanghai, foreign consulates were told that the safety of journalists who failed to heed newly enacted reporting guidelines could not be guaranteed. For instance, some of the authors of the film "River Elegy" were arrested, and some of the authors fled mainland China. Gifford concluded that "China the concept, China the empire, China the construct of two thousand years of imperial thinking" has forbidden and may always forbid "independent thinking" as that would lead to the questioning of China's political system. Gifford added that people born after 1970 had "near-complete depoliticization" while older intellectuals no longer focus on political change and instead focus on economic reform.
Impact.
Domestic political trends.
The protests led to a strengthened role for the state. In its aftermath, many of the freedoms introduced during the 1980s were rescinded, as the party returned to a conventional Leninist mold and re-established firm control over the press, publishing, and mass media. The protests were also a blow to the 'separation of powers' model, whereby the positions of President, Premier, and the General Secretary were intended to be different people following 1982 to prevent the excesses of Mao-style personal rule. However, when President Yang Shangkun openly split with General Secretary Zhao Ziyang over the use of force, official policy became inconsistent and incoherent, significantly impeding the exercise of power. Following the protests, to avoid another open split within the leadership, the roles of General Secretary, President, and Central Military Commission Chairman were all consolidated into the same person, Jiang Zemin (and by extension his successor, Hu Jintao).
In 1989, neither the Chinese military nor the Beijing police had sufficient anti-riot gear, such as rubber bullets and tear gas. After the Tiananmen Square protests, riot police in Chinese cities were equipped with non-lethal equipment for riot control. The protests led to increased spending on internal security and expanded the role of the People's Armed Police in suppressing urban protests.
Effect on economic reform.
The aftermath of the protests saw the resurgence of conservative attitudes towards reform among policymakers, intended to slow the rapid changes that were said to have contributed to the causes of the protest. Deng Xiaoping, the "architect" of the reform policy, saw his influence significantly reduced following the protests, forcing him into making concessions with socialist hardliners. In dismissing Zhao Ziyang, who shared Deng's vision for economic reform but disagreed with him over politics, Deng had lost the foremost champion of his own economic vision. Facing pressure from the conservative camp, Deng distanced himself from the affairs of state.
These slow pace of reform was met with stiff resistance from provincial governors and broke down completely in the early 1990s as a result of the dissolution of the Soviet Union and Deng's Southern Tour of 1992, designed by the ailing but influential leader as a means to reinstate his economic reform agenda. On the tour, Deng criticized the leftist hardliners that had gained power following the protests, and praised entrepreneurship and other market-driven policies. Initially ignored by Beijing, the Chinese Politburo eventually sided with Deng and economic reforms again gained prominence.
Hong Kong.
In Hong Kong, the Tiananmen square protests led to fears that the PRC would renege on its commitments under one country, two systems following the impending handover in 1997. In response, Governor Chris Patten attempted to expand the franchise for the Legislative Council of Hong Kong, which led to friction with Beijing. There have been large candlelight vigils attended by tens of thousands in Hong Kong every year since 1989 and these vigils have continued following the transfer of power to the PRC in 1997. Many Hong Kongers see the continued protests as a symbol of the territory's autonomy and freedom from the interference from Beijing on political issues. For many Hong Kongers, Tiananmen served as a turning point for when they lost trust of the Beijing government. The event, coupled with general uncertainty over the status of Hong Kong after the transfer of sovereignty, led to a sizeable exodus of Hong Kong people to Western countries such as Canada and Australia prior to 1997.
International trade.
There was a significant impact on the Chinese economy after the incident. Foreign loans to China were suspended by the World Bank, Asian Development Bank, and foreign governments; tourism revenue decreased from US$2.2 billion to US$1.8 billion; foreign direct investment commitments were cancelled and there was a rise in defense spending from 8.6% in 1986, to 15.5% in 1990, reversing a previous 10 year decline. Chinese Premier Li Peng visited the United Nations Security Council on 31 January 1992, and argued that the economic and arms embargoes on China were a violation of national sovereignty.
International image.
The Tiananmen Square protests damaged the reputation of China internationally, particularly in the West. Western media covering the Sino-Soviet Summit in May were in an excellent position to cover some of the military action live. Protesters seized this opportunity to create signs and banners designed for international television audiences. Indecision within the Chinese government over how to handle media coverage of the events also meant a relatively liberal environment for both domestic and foreign journalists for a significant portion of the protests.
All international networks were eventually ordered to cease broadcasts from the city during the military action, with the government shutting down satellite transmissions. Broadcasters attempted to defy these orders by reporting via telephone. Footage was quickly smuggled out of the country. The only network which was able to record shots during the night of 4 June was Televisión Española of Spain (TVE). During the military action, some foreign journalists faced harassment from authorities. CBS correspondent Richard Roth and his cameraman were taken into custody while filing a report from the Square via mobile phone. 
Images of the protests would strongly shape Western views and policy toward China in the next two decades. Of particular significance was the image of "Tank Man", the unknown rebel who became immortalized in the West as a symbol of civil resistance against a repressive regime. There was considerable sympathy for the protests among Chinese students in the West. China's image as a country undergoing modernizing reforms and an ally against the Soviet Union was replaced by that of a repressive authoritarian regime. The protests were frequently invoked to argue against trade liberalization with mainland China and by the United States' Blue Team as evidence that China was a threat to world peace and US interests.
Among overseas Chinese students, the Tiananmen Square protests triggered the formation of Internet news services such as the China News Digest and the NGO China Support Network. In the aftermath of Tiananmen, organizations such as the China Alliance for Democracy and the Independent Federation of Chinese Students and Scholars were formed, although these organizations would have limited political impact beyond the mid-1990s.
"Tank Man".
The suppression of the protest was immortalized in Western media by the famous video footage and photographs of a lone man in a white shirt standing in front of a column of tanks which were attempting to drive out of Tiananmen Square. The iconic photo that would eventually make its way around the world was taken on 5 June on Chang'an Avenue. As the tank driver attempted to go around him, the "Tank Man" moved into the tank's path. He continued to stand defiantly in front of the tanks for some time, then climbed up onto the turret of the lead tank to speak to the soldiers inside. After returning to his position in front of the tanks, the man was pulled aside by a group of people.
What happened to the "Tank Man" following the demonstration is not known. Some say he was pulled away and went into hiding, others say he was executed by the authorities. "Time Magazine" dubbed him "The Unknown Rebel" and later named him one of the . In an interview with U.S. media, then Chinese President Jiang Zemin said he did not think the man was killed.
Continuing issues.
Censorship.
The Communist Party of China (CPC) forbids discussion of the Tiananmen Square protests, and has taken measures to block or censor information. Textbooks have little, if any, information related to the protests.
Following the protests, officials banned controversial films and books, and shut down a large number of newspapers. Within a year, 12 percent of all newspapers, 8 percent of publishing companies, 13 percent of social science periodicals and more than 150 films were banned or shut down. In addition, the government also announced it had seized 32 million contraband books and 2.4 million video and audio cassettes. Access to media and internet resources on the subject are restricted or blocked by censors.
The party’s official stance towards the incident is that the use of force was necessary in order to control a 'political disturbance' and helped to ensure the stability necessary for economic success. Chinese leaders, including general secretaries Jiang Zemin and Hu Jintao, reiterate this line when asked about the question by foreign press.
Public memory of the Tiananmen Square protests has been suppressed by the authorities since 1989. Print media containing reference to the protests must be consistent with the government’s version of events. Presently, many Chinese citizens are reluctant to speak about the protests due to potential repercussions. However, some individuals do speak out, such as Ding Zilin of the Tiananmen Mothers organization. Youth in China are generally unaware of the events that took place, and cannot recognize symbols such as tank man, or even the date 4 June itself.
Internet searches of '4 June' or 'Tiananmen Square' return censored results or cuts the server connection temporarily. Specific web pages with select keywords are censored, while other websites, such as those of overseas Chinese democracy movements, are blocked wholesale. The censorship, however, has been inconsistent - with many sites being blocked, unblocked, and re-blocked over the years, including YouTube, Wikipedia, and Flickr. In addition, the policy is much more stringent with Chinese-language sites than foreign-language ones. In January 2006, Google agreed to censor their mainland China site to remove information about Tiananmen and other subjects considered 'sensitive' by the authorities. Google withdrew its cooperation on censorship in January 2010.
Leading up to and during the event's 20th anniversary on 4 June 2009, party authorities increased security around the square. Members of the Public Security Bureau and the People’s Armed Police were present at the square in uniform along with several hundred plain-clothes officers. Journalists were denied entry to the Square. Those who attempted to film at the Square or interview dissidents were briefly detained. The anniversary also saw the shut down of global social-networking sites in China, as well as increased policing of dissidents. No protests were to be tolerated on this occasion.
Censorship does not apply to Hong Kong and Macau; the two special administrative regions enjoy a high degree of autonomy and people enjoy freedom of speech and assembly.
EU and US arms embargo.
The European Union and United States embargo on armament sales to the PRC, put in place as a result of the violent suppression of the Tiananmen Square protests, remains in place today. The PRC has been calling for a lift of the ban for years and has had a varying amount of support from EU members. Since 2004, China has portrayed the ban as "outdated", and damaging to China-EU relations. In early 2004, French President Jacques Chirac spearheaded a movement within the EU to lift the ban, which was supported by German Chancellor Gerhard Schröder. However, the passing of the Anti-Secession Law of the People's Republic of China in March 2005 increased tensions between mainland China and Taiwan, damaging attempts to lift the ban, and several EU Council members retracted their support for a lift of the ban. Moreover, Schroder's successor Angela Merkel opposed lifting the ban. Members of the U.S. Congress had also proposed restrictions on the transfer of military technology to the EU if the latter lifted the ban. The UK also opposed the lifting of the embargo when it took charge of the EU presidency in July 2005. The election of José Manuel Barroso as European Commission President also made a lifting of the ban more difficult, because Barroso is a critic of China's human rights record.
In addition, the European Parliament has consistently opposed the lifting of the arms embargo to the PRC. Though its agreement is not necessary for lifting the ban, many argue it reflects the will of the European people better as it is the only directly elected European body. The European Parliament has repeatedly opposed any lifting of the arms embargo on the PRC. The arms embargo has limited China's options from where it may seek military hardware. Among the sources that were sought included the former Soviet bloc that it had a strained relationship with as a result of the Sino-Soviet split. Other willing suppliers have previously included Israel and South Africa, but American pressure has restricted this co-operation.
Compensation.
Over the years some Chinese citizens have called for a reassessment of the protests and compensation from the government to victims’ families. One group in particular, Tiananmen Mothers, seeks compensation, vindication for victims and the right to receive donations from within the mainland and abroad. Zhang Shijun, a former soldier who was involved in the military crackdown, had published an open letter to President Hu Jintao seeking to have the government reevaluate its position on the protests. He was subsequently arrested and taken from his home.
Although the Chinese government never officially acknowledged wrongdoing when it came to the incident, in April 2006 a payment was made to the mother of one of the victims, the first publicized case of the government offering redress to a Tiananmen-related victim's family. The payment was termed a "hardship assistance", given to Tang Deying (唐德英) whose son, Zhou Guocong () died at the age of 15 while in police custody in Chengdu on 6 June 1989, two days after the Chinese Army dispersed the Tiananmen protesters. She was reportedly paid CNY70,000 (approximately $10,250 USD). This has been welcomed by various Chinese activists, but was regarded by some as a measure to maintain social stability and not believed to herald a changing of the Party's official position.
United Nations report.
The State party should conduct a full and impartial investigation
into the suppression of the Democracy Movement in Beijing in June
1989, provide information on the persons who are still detained from
that period, inform the family members of their findings, offer apologies
and reparation as appropriate and prosecute those found responsible for
excessive use of force, torture and other illtreatment.
In December 2009 the Chinese Government responded to the Committee’s recommendations. It stated that the government had closed the case concerning the “political turmoil in the spring and summer of 1989." It also stated that the “practice of the past 20 years has made it clear that the timely and decisive measures taken by the Chinese Government at the time were necessary and correct." It claimed that the labelling of the “incident as ‘the Democracy Movement’” is a “distortion of the nature of the incident." According to the Chinese Government these observations were “inconsistent with the Committee’s responsibilities."
Cultural references.
Songs.
This event has inspired many references in music. In May 1989, Hong Kong artistes (including Andy Lau, Sally Yeh, Roman Tam, Andy Hui, Maria Cordero) gathered to record the song "For Liberty" (為自由) in support of the protesters.
The second music video for Michael Jackson's song "They Don't Care About Us" contains a video clip of the Tank Man. In their Rome concert on 4 June 1989, British rock band The Cure, dedicated their last encore, "Faith," to "everyone that died today in China." In the same year, Joan Baez's song "China" from her album "Speaking of Dreams" commemorated the event. The second-last historical reference cited in Billy Joel's "We Didn't Start the Fire", released in September 1989, is "China's under martial law". Leonard Cohen's song "Democracy" from his 1992 album "The Future" states that democracy is coming "from those nights in Tiananmen Square".
Progressive rock group Marillion wrote a song titled "The King of Sunset Town" that uses imagery from Tiananmen Square, such as the line "a puppet king on the Fourth of June." American rock band The Hooters referred to the event in their hit song "500 Miles", which is an updated version of the 1960s folk song. The third verse begins with words: "A hundred tanks along the square, One man stands and stops them there, Someday soon the tide'll turn and I'll be free."
Canadian industrial music group Skinny Puppy's song "Tin Omen" is about the incident. Its title is a play on words.
American thrash metal band Slayer released a song "Blood Red" on their album "Seasons in the Abyss", which was inspired by Tiananmen Square. Similarly, Testament's "Seven Days of May" protested the Beijing massacre. System of a Down's "Hypnotize" on their 2005 album of the same name mentioned Tiananmen Square. Brazilian metal band Sepultura mentions Tiananmen Square in their song "Refuse/Resist" from their 1993 album "Chaos A.D."; the music video for the song features Tank Man.
"Shiny Happy People" by R.E.M. is supposedly an ironic reference to a piece of roughly translated Chinese propaganda regarding the massacre, two years before the song was released.
In 1990 the song "Blood Is On the Square" by Philip and Teresa Morgan about Tiananmen protests was released.
American songwriter Mary Chapin Carpenter references the event in her song "4 June 1989", released in 2010 on the album "The Age of Miracles". In 1992, Roger Waters released "Amused to Death", an album which included the song "Watching TV", a rumination on the Western response to the protests in Tiananmen. In 1996, a song called "The Tiananmen Man", based on the picture of the Tank Man, appeared on Nevermore's second album "The Politics of Ecstasy".
Television.
A primetime special hosted by Tom Brokaw honored both the Tiananmen Square pro-democracy demonstrations in Beijing and the fall of the Berlin Wall in that momentous year for human rights around the world, 1989.
CNN news anchor Kyra Phillips drew criticism in March 2006 when she compared the 2006 youth protests in France, in which it was later determined that no one was killed, to the Tiananmen Square protests, saying "Sort of brings back memories of Tiananmen Square, when you saw these activists in front of tanks." CNN's Chris Burns told French Foreign Minister Philippe Douste-Blazy that her comments were "regrettable" and would receive some disciplinary actions.
In April 2006, the PBS series "Frontline" produced an episode titled "The Tank Man", which examined his role in the 1989 Tiananmen Square Protests and the change that has overtaken the PRC economically and politically since.
On 3 June 2009 the BBC aired the documentary "Kate Adie returns to Tiananmen", in which reporter Kate Adie revisits China and recalls the events she witnessed in 1989.
Paintings and movies.
"Execution", a painting inspired by the event, became the most expensive Chinese contemporary art work sold in 2007.
The movie "Rapid Fire", starring Brandon Lee, depicts images of the Tiananmen Square killings. In the movie, Brandon Lee's character is the son of a US government employee who died in the Tiananmen Square massacre. "Summer Palace" (2006) by Chinese director Lou Ye contains re-enacted scenes from Beijing streets during the days of the protests in Tiananmen Square. The movie was banned from public viewing.

Trail of Tears
The Trail of Tears is a name given to the forced relocation and movement of Native American nations from southeastern parts of the United States following the Indian Removal Act of 1830. The removal included many members of the Cherokee, Muscogee (Creek), Seminole, Chickasaw, and Choctaw nations, among others in the United States, from their homelands to Indian Territory (eastern sections of the present-day state of Oklahoma). The phrase originated from a description of the removal of the Choctaw Nation in 1831. Many Native Americans suffered from exposure, disease and starvation en route to their destinations. Many died, including 4,000 of the 15,000 relocated Cherokee.
In 1831, the Cherokee, Chickasaw, Choctaw, Muscogee-Creek, and Seminole (sometimes collectively referred to as the Five Civilized Tribes) were living as autonomous nations in what would be called the American Deep South. The process of cultural transformation (proposed by George Washington and Henry Knox) was gaining momentum, especially among the Cherokee and Choctaw. Andrew Jackson continued and renewed the political and military effort for the removal of the Native Americans from these lands with the passage of the Indian Removal Act of 1830.
In 1831 the Choctaw were the first to be removed, and they became the model for all other removals. After the Choctaw, the Seminole were removed in 1832, the Creek in 1834, then the Chickasaw in 1837, and finally the Cherokee in 1838. After removal, some Native Americans remained in their ancient homelands - the Choctaw are found in Mississippi, the Seminole in Florida, the Creek in Alabama, and the Cherokee in North Carolina. A limited number of non-native Americans (including African-Americans - usually as slaves) also accompanied the Native American nations on the trek westward. By 1837, 46,000 Native Americans from these southeastern states had been removed from their homelands thereby opening for predominantly white settlement.
The fixed boundaries of these autonomous tribal nations, comprising large areas of the United States, were subject to continual cession and annexation prior to 1830, in part due to pressure from squatters and the threat of military force in the newly declared U.S. territories -- federally administered regions whose boundaries supervened upon the Native treaty claims. As these territories became U.S. states, state governments sought to dissolve the boundaries of the Indian nations within their borders, which were independent of state jurisdiction, and to expropriate the land therein. These pressures were magnified by U.S. population growth and the expansion of slavery in the South.
Legal background.
The territorial boundaries claimed as sovereign and controlled by the Native American nations living in what was then known as the Indian Territories—the portion of the early United States east of the Mississippi River not yet claimed or allotted to become Oklahoma -- were fixed and determined by national treaties with the United States Federal government under terms recognizing these entities as dependent but internally sovereign, or autonomous nations under the sole jurisdiction of the Federal government.
While retaining their tribal governance, which included a constitution or official council in tribes such as the Iroquois and Cherokee, many portions of the southeastern Native American nations had become partially or completely economically integrated into the economy of the region. This included the plantation economy in states such as Georgia, and the possession of slaves. These slaves were also forcibly relocated during the process of removal. A similar process had occurred earlier in the territories controlled by the Confederacy of the Six Nations in what is now upstate New York prior to the British invasion and subsequent U.S. annexation of the Iroquois nation.
Under the history of U.S. treaty law, the territorial boundaries claimed by Federally recognized tribes received the same status under which the Southeastern tribal claims were recognized; until the following establishment of reservations of land, determined by the Federal government, which were ceded to the remaining tribes by "de jure" treaty, in a process that often entailed forced relocation. The establishment of the Indian Territory and the dissolution of Indian territories east of the Mississippi anticipated the establishment of the U.S. Indian reservation system, which was subsequently imposed on remaining Indian lands.
The statutory argument for Native American sovereignty persisted until the Supreme Court ruled in "Cherokee Nation v. Georgia" (1831), that ("e.g.") the Cherokees were not a sovereign and independent nation, and therefore not entitled to a hearing before the court. However, in "Worcester v. Georgia" (1832), the court re-established limited internal sovereignty under the sole jurisdiction of the Federal government, in a ruling that both opposed the subsequent forced relocation and set the basis for modern U.S. case law.
While the latter ruling was famously defied by Jackson, the actions of the Jackson administration were not isolated because state and federal officials had violated treaties without consequence, often attributed to military exigency, as the members of individual Native American nations were not automatically United States citizens and were rarely given standing in any U.S. court. 
Compounding this was the fact that while citizenship tests existed for Native Americans living in newly annexed areas before and after forced relocation, individual U.S. states did not recognize tribal land claims, only individual title under State law, and distinguished between the rights of white and non-white citizens, who often had limited standing in court; and Indian removal was carried out under U.S. military jurisdiction, often by state militias. As a result, individual Native Americans who could prove U.S. citizenship were nevertheless displaced from newly annexed areas. The military actions and subsequent treaties enacted by the Jackson and Van Buren administrations pursuant to the 1830 law are widely considered to have directly caused the expulsion or death of a substantial part of the Native Americans then living in the southeastern United States.
Choctaw voluntary removal.
[[File:George-W-Harkins.jpg|upright|left|thumb|In 1832 a young 22-year-old Harkins wrote the
Secretary of War Lewis Cass appointed George Gaines to manage the removals. Gaines decided to remove Choctaws in three phases starting in 1831 and ending in 1833. The first was to begin on November 1, 1831 with groups meeting at Memphis and Vicksburg. A harsh winter would batter the emigrants with flash floods, sleet, and snow. Initially the Choctaws were to be transported by wagon but floods halted them. With food running out, the residents of Vicksburg and Memphis were concerned. Five steamboats (the Walter Scott, the Brandywine, the Reindeer, the Talma, and the Cleopatra) would ferry Choctaws to their river-based destinations. The Memphis group traveled up the Arkansas for about to Arkansas Post. There the temperature stayed below freezing for almost a week with the rivers clogged with ice, so there would be no travel for weeks. Food rationing consisted of a handful of boiled corn, one turnip, and two cups of heated water per day. Forty government wagons were sent to Arkansas Post to transport them to Little Rock. When they reached Little Rock, a Choctaw chief (thought to be Thomas Harkins or Nitikechi) quoted to the Arkansas Gazette that the removal was a ""trail of tears and death"." The Vicksburg group was led by an incompetent guide and was lost in the Lake Providence swamps.
Alexis de Tocqueville, the French philosopher, witnessed the Choctaw removals while in Memphis, Tennessee in 1831,
Nearly 17,000 Choctaws made the move to what would be called Indian Territory and then later Oklahoma. About 2,500–6,000 died along the trail of tears. Approximately 5,000–6,000 Choctaws remained in Mississippi in 1831 after the initial removal efforts. The Choctaws who chose to remain in newly formed Mississippi were subject to legal conflict, harassment, and intimidation. The Choctaws "have had our habitations torn down and burned, our fences destroyed, cattle turned into our fields and we ourselves have been scourged, manacled, fettered and otherwise personally abused, until by such treatment some of our best men have died." The Choctaws in Mississippi were later reformed as the Mississippi Band of Choctaw Indians and the removed Choctaws became the Choctaw Nation of Oklahoma.
Seminole resistance.
The U.S. acquired Florida from Spain via the Adams-Onís Treaty and took possession in 1821. In 1832 the Seminoles were called to a meeting at Payne's Landing on the Ocklawaha River. The treaty negotiated called for the Seminoles to move west, if the land were found to be suitable. They were to be settled on the Creek reservation and become part of the Creek tribe, who considered them deserters; some of the Seminoles had been derived from Creek bands but also from other tribes. Those among the tribe who once were members of Creek bands did not wish to move west to where they were certain that they would meet death for leaving the main band of Creek Indians. The delegation of seven chiefs who were to inspect the new reservation did not leave Florida until October 1832. After touring the area for several months and conferring with the Creeks who had already settled there, the seven chiefs signed a statement on March 28, 1833 that the new land was acceptable. Upon their return to Florida, however, most of the chiefs renounced the statement, claiming that they had not signed it, or that they had been forced to sign it, and in any case, that they did not have the power to decide for all the tribes and bands that resided on the reservation. The villages in the area of the Apalachicola River were more easily persuaded, however, and went west in 1834. On December 28, 1835 a group of Seminoles and blacks ambushed a U.S. Army company marching from Fort Brooke in Tampa to Fort King in Ocala. Out of 110 army troops, only three survived. This came to be known as the Dade Massacre.
As the realization that the Seminoles would resist relocation sank in, Florida began preparing for war. The St. Augustine Militia asked the War Department for the loan of 500 muskets. Five hundred volunteers were mobilized under Brig. Gen. Richard K. Call. Indian war parties raided farms and settlements, and families fled to forts, large towns, or out of the territory altogether. A war party led by Osceola captured a Florida militia supply train, killing eight of its guards and wounding six others. Most of the goods taken were recovered by the militia in another fight a few days later. Sugar plantations along the Atlantic coast south of St. Augustine were destroyed, with many of the slaves on the plantations joining the Seminoles.
Other warchiefs such as Halleck Tustenuggee, Jumper, and Black Seminoles Abraham and John Horse continued the Seminole resistance against the army. The war ended, after a full decade of fighting, in 1842. The U.S. government is estimated to have spent about $20,000,000 on the war, at the time an astronomical sum, and equal to $ today. Many Indians were forcibly exiled to Creek lands west of the Mississippi; others retreated into the Everglades. In the end, the government gave up trying to subjugate the Seminole in their Everglades redoubts and left fewer than 100 Seminoles in peace. However, other scholars state that at least several hundred Seminoles remained in the Everglades after the Seminole Wars.
As a result of the Seminole Wars, the surviving Seminole band of the Everglades claims to be the only Federally recognized tribe which never relinquished sovereignty or signed a peace treaty with the United States.
Creek dissolution.
After the War of 1812, some Muscogee leaders such as William McIntosh signed treaties that ceded more land to Georgia. The 1814 signing of the Treaty of Fort Jackson signaled the end for the Creek Nation and for all Indians in the South. Friendly Creek leaders, like Selocta and Big Warrior, addressed Sharp Knife (the Indian nickname for Andrew Jackson) and reminded him that they keep the peace. Nevertheless, Jackson retorted that they did not "cut (Tecumseh's) throat" when they had the chance, so they must now cede Creek lands. Jackson also ignored Article 9 of the Treaty of Ghent that restored sovereignty to Indians and their nations.
"Jackson opened this first peace session by faintly acknowledging the help of the friendly Creeks. That done, he turned to the Red Sticks and admonished them for listening to evil counsel. For their crime, he said, the entire Creek Nation must pay. He demanded the equivalent of all expenses incurred by the United States in prosecuting the war, which by his calculation came to of land."
- Robert V. Remini, "Andrew Jackson"
Eventually, the Creek Confederacy enacted a law that made further land cessions a capital offense. Nevertheless, on February 12, 1825, McIntosh and other chiefs signed the Treaty of Indian Springs, which gave up most of the remaining Creek lands in Georgia. After the U.S. Senate ratified the treaty, McIntosh was assassinated on May 13, 1825, by Creeks led by Menawa.
The Creek National Council, led by Opothle Yohola, protested to the United States that the Treaty of Indian Springs was fraudulent. President John Quincy Adams was sympathetic, and eventually the treaty was nullified in a new agreement, the Treaty of Washington (1826). Writes historian R. Douglas Hurt: "The Creeks had accomplished what no Indian nation had ever done or would do again — achieve the annulment of a ratified treaty." However, Governor Troup of Georgia ignored the new treaty and began to forcibly remove the Indians under the terms of the earlier treaty. At first, President Adams attempted to intervene with federal troops, but Troup called out the militia, and Adams, fearful of a civil war, conceded. As he explained to his intimates, "The Indians are not worth going to war over."
Although the Creeks had been forced from Georgia, with many Lower Creeks moving to the Indian Territory, there were still about 20,000 Upper Creeks living in Alabama. However, the state moved to abolish tribal governments and extend state laws over the Creeks. Opothle Yohola appealed to the administration of President Andrew Jackson for protection from Alabama; when none was forthcoming, the Treaty of Cusseta was signed on March 24, 1832, which divided up Creek lands into individual allotments. Creeks could either sell their allotments and received funds to remove to the west, or stay in Alabama and submit to state laws. Land speculators and squatters began to defraud Creeks out of their allotments, and violence broke out, leading to the so-called "Creek War of 1836". Secretary of War Lewis Cass dispatched General Winfield Scott to end the violence by forcibly removing the Creeks to the Indian Territory west of the Mississippi River.
Chickasaw monetary removal.
Unlike other tribes who exchanged land grants, the Chickasaw received financial compensation from the United States for their lands east of the Mississippi River. In 1836, the Chickasaws had reached an agreement to purchase land from the previously removed Choctaws after a bitter five-year debate. They paid the Choctaws $530,000 (equal to $ today) for the westernmost part of the Choctaw land. The first group of Chickasaws moved in 1837 and was led by John M. Millard. The Chickasaws gathered at Memphis on July 4, 1837, with all of their assets—belongings, livestock, and slaves. Once across the Mississippi River, they followed routes previously established by the Choctaws and the Creeks. Once in Indian Territory, the Chickasaws merged with the Choctaw nation. After several decades of mutual distrust, they regained nationhood.
Cherokee forced relocation.
In 1838, the Cherokee people were forcibly removed from their lands in the Southeastern United States to the Indian Territory (present day Oklahoma) in the Western United States, which resulted in the deaths of approximately 4,000 Cherokees. In the Cherokee language, the event is called "Nu na da ul tsun yi"—“the Place Where They Cried”. The Cherokee Trail of Tears resulted from the enforcement of the Treaty of New Echota, an agreement signed under the provisions of the Indian Removal Act of 1830, which exchanged Native American land in the East for lands west of the Mississippi River, but which was never accepted by the elected tribal leadership or a majority of the Cherokee people.
Tensions between Georgia and the Cherokee Nation were brought to a crisis by the discovery of gold near Dahlonega, Georgia, in 1829, resulting in the Georgia Gold Rush, the first gold rush in U.S. history. Hopeful gold speculators began trespassing on Cherokee lands, and pressure began to mount on the Georgia government to fulfill the promises of the "Compact of 1802".
When Georgia moved to extend state laws over the Cherokee lands in 1830, the matter went to the U.S. Supreme Court. In "Cherokee Nation v. Georgia" (1831), the Marshall court ruled that the Cherokee Nation was not a sovereign and independent nation, and therefore refused to hear the case. However, in "Worcester v. Georgia" (1832), the Court ruled that Georgia could not impose laws in Cherokee territory, since only the national government — not state governments — had authority in Indian affairs.
Jackson had no desire to use the power of the national government to protect the Cherokees from Georgia, since he was already entangled with states’ rights issues in what became known as the nullification crisis. With the Indian Removal Act of 1830, the U.S. Congress had given Jackson authority to negotiate removal treaties, exchanging Indian land in the East for land west of the Mississippi River. Jackson used the dispute with Georgia to put pressure on the Cherokees to sign a removal treaty.
Nevertheless, the treaty, passed by Congress by a single vote, and signed into law by President Andrew Jackson, was imposed by his successor President Martin Van Buren who allowed Georgia, Tennessee, North Carolina, and Alabama an armed force of 7,000 made up of militia, regular army, and volunteers under General Winfield Scott to round up about 13,000 Cherokees into concentration camps at the U.S. Indian Agency near Cleveland, Tennessee before being sent to the West. Most of the deaths occurred from disease, starvation and cold in these camps. Their homes were burned and their property destroyed and plundered. Farms belonging to the Cherokees for generations were won by white settlers in a lottery. After the initial roundup, the U.S. military still oversaw the emigration until they met the forced destination. Private John G. Burnett later wrote, "Future generations will read and condemn the act and I do hope posterity will remember that private soldiers like myself, and like the four Cherokees who were forced by General Scott to shoot an Indian Chief and his children, had to execute the orders of our superiors. We had no choice in the matter."
In the winter of 1838 the Cherokee began the thousand-mile march with scant clothing and most on foot without shoes or moccasins. The march began in Red Clay, Tennessee, the location of the last Eastern capital of the Cherokee Nation. The Cherokee were given used blankets from a hospital in Tennessee where an epidemic of small pox had broken out. Because of the diseases, the Indians were not allowed to go into any towns or villages along the way; many times this meant traveling much farther to go around them. After crossing Tennessee and Kentucky, they arrived in Southern Illinois at Golconda about the 3rd of December 1838. Here the starving Indians were charged a dollar a head (equal to $ today) to cross the river on "Berry's Ferry" which typically charged twelve cents, equal to $ today. They were not allowed passage until the ferry had serviced all others wishing to cross and were forced to take shelter under "Mantle Rock," a shelter bluff on the Kentucky side, until "Berry had nothing better to do". Many died huddled together at Mantle Rock waiting to cross. Several Cherokee were murdered by locals. The killers filed a lawsuit against the U.S. Government through the courthouse in Vienna, suing the government for $35 a head (equal to $ today) to bury the murdered Cherokee.
"There is the coldest weather in Illinois I ever experienced anywhere. The streams are all frozen over something like thick. We are compelled to cut through the ice to get water for ourselves and animals. It snows here every two or three days at the fartherest. We are now camped in Mississippi swamp from the river, and there is no possible chance of crossing the river for the numerous quantity of ice that comes floating down the river every day. We have only traveled on the last month, including the time spent at this place, which has been about three weeks. It is unknown when we shall cross the river..."
Removed Cherokees initially settled near Tahlequah, Oklahoma. When signing the Treaty of New Echota in 1835 Major Ridge said "I have signed my death warrant." The resulting political turmoil led to the killings of Major Ridge, John Ridge, and Elias Boudinot; of the leaders of the Treaty Party, only Stand Watie escaped death. The population of the Cherokee Nation eventually rebounded, and today the Cherokees are the largest American Indian group in the United States.
There were some exceptions to removal. Perhaps 100 Cherokees evaded the U.S. soldiers and lived off the land in Georgia and other states. Those Cherokees who lived on private, individually owned lands (rather than communally owned tribal land) were not subject to removal. In North Carolina, about 400 Cherokees, known as the Oconaluftee Cherokee, lived on land in the Great Smoky Mountains owned by a white man named William Holland Thomas (who had been adopted by Cherokees as a boy), and were thus not subject to removal. Added to this were some 200 Cherokee from the Nantahala area allowed to stay in the Qualla Boundary after assisting the U.S. Army in hunting down and capturing the family of the old prophet, "Tsali". (Tsali faced a firing squad.) These North Carolina Cherokees became the Eastern Band of the Cherokee Nation.
Trail of Tears National Historic Trail.
In 1987, about of trails were authorized by Federal law to mark the removal of seventeen detachments of the Cherokee people. Called the "Trail of Tears National Historic Trail," it traverses portions of nine states and includes land and water routes.
Terminology of forced relocation.
The latter forced relocations have sometimes been referred to as a "death march", in particular with reference to the Cherokee march across the Midwest in 1838, which occurred on a predominantly land route. It was later described as an act of genocide by Alfred Cave in 2003.
Tribesmen who had means initially conducted their own removal. Contingents that were led by conductors from the U.S. Army included those led by Edward Deas, who was claimed to be a sympathizer for the Cherokee plight. The largest death toll from the Cherokee forced relocation comes from the period after the May 23, 1838 deadline. This was at the point when the remaining Cherokee were rounded into camps and pressed into oversized detachments, often over 700 in size (larger than Little Rock or Memphis at that time). Communicable diseases spread quickly through these closely quartered groups, killing many. These contingents were among the last to move, but following the same routes the others had taken; the areas they were going through had been depleted of supplies due to the vast numbers that had gone before them. The marchers were subject to extortion and violence along the route. In addition, these final contingents were forced to set out during the hottest and coldest months of the year, killing many. Exposure to the elements, disease and starvation, harassment by local frontiersmen, and insufficient rations similarly killed up to one-third of the Choctaw and other nations on the march. 
It has also been claimed by descendants of the survivors that the term "Trail of Tears" referred to the tears of those who "witnessed" the suffering of the marchers, and that the Native Americans themselves marched in silence.
There exists some debate among historians and the affected tribes as to whether the term "Trail of Tears" should be used to refer to the entire history of forced relocations from the United States east of the Mississippi into Indian Territory (as was the stated U.S. policy), or to the Five Tribes described above, to the route of the land march specifically, or to specific marches in which the remaining holdouts from each area were rounded up.

TWA Flight 800
Trans World Airlines Flight 800 (TWA 800), a Boeing 747-131, exploded and crashed into the Atlantic Ocean near East Moriches, New York, on July 17, 1996, at about 20:31 EDT, 12 minutes after takeoff from John F. Kennedy International Airport, killing all 230 people on board. TWA 800 was the second-deadliest U.S. aviation accident after American Airlines Flight 191 until American Airlines Flight 587, which also took off from JFK Airport two months after the September 11 attacks. It remains the third-deadliest aviation accident to occur in U.S. territory. TWA 800 was a scheduled international passenger flight from New York to Rome, with a stopover in Paris.
While accident investigators from the National Transportation Safety Board (NTSB) traveled to the scene, arriving the following morning, there was much initial speculation that a terrorist attack was the cause of the crash. Consequently, the Federal Bureau of Investigation (FBI) initiated a parallel criminal investigation. Sixteen months later the FBI announced that no evidence had been found of a criminal act and closed its active investigation.
The four-year NTSB investigation concluded with the approval of the Aircraft Accident Report on August 23, 2000, ending the most extensive, complex, and costly air disaster investigation in United States history. The report's conclusion was that the probable cause of the accident was an explosion of flammable fuel/air vapors in a fuel tank, and, although it could not be determined with certainty, the most likely cause of the explosion was a short circuit. As a result of the investigation, new requirements were developed for aircraft to prevent future fuel tank explosions.
Many TWA Flight 800 alternative theories exist, the most prevalent being that a missile strike from a terrorist or U.S. Navy vessel caused the crash, and is the subject of a government coverup.
Accident flight.
The accident airplane, registration N93119, was manufactured by Boeing in July 1971, and purchased new by TWA. The aircraft had completed 16,869 flights with 93,303 hours of operation. On the day of the accident the airplane departed Athens, Greece, as TWA Flight 881, and arrived at the gate at John F. Kennedy International Airport (JFK) about 16:38. The aircraft was refueled, and there was a crew change; the new flight crew consisted of Captain Ralph G. Kevorkian, Captain/Check Airman Steven E. Snyder and Flight Engineer/Check Airman Richard G. Campbell (all with more than 30 years employment at TWA), and Flight Engineer Trainee Oliver Krick, who was starting the sixth leg of his initial operating experience training.
Because of technical problems with the thrust reverser sensors during the landing of TWA 881 at JFK, prior to flight 800 the ground-maintenance crew locked-out the thrust reverser for engine #3 (treated as a minimum equipment list item). In addition, severed cables for the engine #3 thrust reverser were replaced. During refueling of the aircraft, the volumetric shutoff (VSO) control was believed to have been triggered before the tanks were full. To continue the pressure fueling, a TWA mechanic overrode the automatic VSO by pulling the volumetric fuse and an overflow circuit breaker. Maintenance records indicate that the airplane had numerous VSO-related maintenance writeups in the weeks before the accident.
TWA 800 was scheduled to depart JFK for Paris around 19:00, but the flight was delayed until 20:02
by a disabled piece of ground equipment and a passenger/baggage mismatch. After the owner of the baggage in question was confirmed to be on board, the flight crew prepared for departure and the aircraft pushed back from gate 27 at the TWA Flight Center.
TWA 800 then received a series of heading changes and generally increasing altitude assignments as it climbed to its intended cruising altitude. Weather in the area was light winds with scattered clouds, and there were dusk lighting conditions. The last radio transmission from the airplane occurred at 20:30 when the flight crew received and then acknowledged instructions from Boston Air Route Traffic Control Center (ARTCC) to climb to . The last recorded radar transponder return from the airplane was recorded by the Federal Aviation Administration (FAA) radar site at Trevose, Pennsylvania at 20:31:12.
Thirty-eight seconds later, the captain of an Eastwind Airlines Boeing 737 reported to Boston ARTCC that he "just saw an explosion out here," adding, "we
just saw an explosion up ahead of us here...about 16,000 feet [4,900m] or something like that, it just went down into the water." Subsequently, many air traffic control facilities in the New York/Long Island area received reports of an explosion from other pilots operating in the area. Many witnesses in the vicinity of the crash stated that they saw or heard explosions, accompanied by a large fireball or fireballs over the ocean, and observed debris, some of which was burning, falling into the water.
Although individuals in various civilian, military and police vessels reached the crash site and searched for survivors within minutes of the initial water impact, no survivors were found, making TWA 800 the second deadliest aircraft accident in the United States at that time.
Initial investigation.
The NTSB was notified about 20:50 the day of the accident; a full go-team was assembled in Washington, D.C. and arrived on scene early the next morning. Meanwhile, initial witness descriptions led many to believe the cause of the crash was a bomb or missile attack. The NTSB does not investigate criminal activity. In past investigations, once it was established that a crash was, in fact, a criminal act, the FBI had become the lead federal investigative body, with the NTSB providing any requested support. In the case of TWA 800, the FBI initiated a parallel criminal investigation alongside the NTSB's accident investigation.
Search and recovery operations.
Search and recovery operations were conducted by federal, state, and local agencies, as well as government contractors. Remote-operated vehicles (ROVs), side-scan sonar, and laser line-scanning equipment were used to search for and investigate underwater debris fields. Victims and wreckage were recovered by Scuba divers and ROVs; later scallop trawlers were used to recover wreckage embedded in the ocean floor. In one of the largest diver-assisted salvage operations ever conducted, often working in very difficult and dangerous conditions, over 95% of the airplane wreckage was eventually recovered. The search and recovery effort identified three main areas of wreckage underwater. The yellow zone, red zone, and green zone contained wreckage from front, center, and rear sections of the airplane, respectively. The green zone with the aft portion of the aircraft was located the furthest along the flight path.
Pieces of wreckage were transported by boat to shore and then by truck to leased hangar space at the former Grumman Aircraft facility in Calverton, New York for storage, examination, and reconstruction. This facility became the command center and headquarters for the investigation. NTSB and FBI personnel were present to observe all transfers to preserve the evidentiary value of the wreckage. The Cockpit Voice Recorder and Flight Data Recorder were recovered by U.S. Navy divers a week after the accident; they were immediately shipped to the NTSB laboratory in Washington, D.C., for readout. The victims were transported to the Suffolk County Medical Examiner's Office in Hauppauge, New York.
Tensions in the investigation.
Relatives of TWA 800 passengers and crew, as well as the media, gathered at a Ramada Plaza Hotel near JFK. Many waited until the remains of their family members had been recovered, identified and released. Grief turned to anger at TWA's delay in confirming the passenger list, conflicting information from agencies and officials, and mistrust of the recovery operation's priorities. Although NTSB vice chairman Robert Francis stated that all bodies were being retrieved as soon as they were spotted, and that wreckage was being recovered only if divers believed that victims were hidden underneath, many families were suspicious that investigators were not being truthful, or withholding information.
Much anger and political pressure was also directed at Suffolk County Medical Examiner Dr. Charles V. Wetli as recovered bodies backlogged at the morgue. Under constant and considerable pressure to identify victims with minimal delay, pathologists worked non-stop. Since the primary objective was to identify all remains rather than performing a detailed forensic autopsy, the thoroughness of the examinations was highly variable. Ultimately, remains of all 230 victims were recovered and identified, the last over 10 months later.
With lines of authority unclear, differences in agendas and culture between the FBI and NTSB resulted in discord. The FBI, from the start assuming that a criminal act had occurred, saw the NTSB as indecisive. Expressing frustration at the NTSB's unwillingness to speculate on a cause, one FBI agent described the NTSB as "No opinions. No nothing". Meanwhile the NTSB was required to refute or play down speculation about conclusions and evidence, frequently supplied to reporters by law enforcement officials and politicians.
Witness interviews.
Many witnesses to the accident had seen a "streak of light" that was usually described as ascending, moving to a point where a large fireball appeared, with several witnesses reporting that the fireball split in two as it descended toward the water. There was intense public interest in these witness reports and much speculation that the reported streak of light was a missile that had struck TWA 800, causing the airplane to explode. These witness accounts were a major reason for the initiation and duration of the FBI's criminal investigation.
Approximately 80 FBI agents conducted interviews with potential witnesses daily. No verbatim records of the witness interviews were produced; instead, the agents who conducted the interviews wrote summaries that they then submitted. Witnesses were not asked to review or correct the summaries. Included in some of the witness summaries were drawings or diagrams of what the witness observed.
Within days of the crash the NTSB announced its intent to form its own witness group and to interview witnesses to the crash. However, after the FBI raised concerns about non-governmental parties in the NTSB's investigation having access to this information and possible prosecutorial difficulties resulting from multiple interviews of the same witness, the NTSB deferred and initially neither interviewed nor re-interviewed witnesses to the crash.
Further investigation and analysis.
Examination of the Cockpit Voice Recorder (CVR) and Flight Data Recorder data showed a normal takeoff and climb, with the aircraft in normal flight before both abruptly stopped at 20:31:12. A noise recorded on the last few tenths of a second of the CVR was similar to the last noises recorded from other airplanes, that had experienced in-flight breakups. This, together with the distribution of wreckage and witness reports, all indicated a catastrophic in-flight breakup of TWA 800.
Possible causes of the in-flight breakup.
Investigators considered several possible causes for the structural breakup: structural failure and decompression, detonation of a high-energy explosive device, such as a missile warhead exploding upon impact with the airplane or bomb exploding inside the airplane, or a fuel/air explosion in the center wing fuel tank.
Structural failure and decompression.
Close examination of the wreckage revealed no evidence of structural faults such as fatigue, corrosion or mechanical damage that could have caused the in-flight breakup. It was also suggested that the breakup could have been initiated by an in-flight separation of the forward cargo door; however, all evidence indicated that the door was closed and locked at impact. The NTSB concluded that "the in-flight breakup of TWA flight 800 was not initiated by a preexisting condition resulting in a structural failure and decompression."
Live missile or bomb detonation.
A review of recorded data from long-range and airport surveillance radars revealed multiple contacts of airplanes/objects in TWA 800's vicinity at the time of the accident. None of these contacts intersected TWA 800's position at any time. Attention was drawn to data from the Islip, New York, ARTCC facility that showed three tracks in the vicinity of TWA 800 that did not appear in any of the other radar data. None of these sequences intersected TWA 800's position at any time either. All the reviewed radar data showed no radar returns consistent with a missile or other projectile traveling toward TWA 800.
The NTSB addressed allegations that the Islip radar data showed groups of military surface targets converging in a suspicious manner in an area around the accident, and that a 30-knot radar track, never identified and 3 nmi from the crash site, was involved in foul play, as evidenced by its failure to divert from its course and assist with the search and rescue operations. Military records examined by the NTSB showed no military surface vessels within 15 nmi of TWA 800 at the time of the accident. In addition, the records indicated that the closest area scheduled for military use and prohibited to civilian air traffic at the time of the accident, warning area W-387A/B, was 160 nmi south.
The NTSB reviewed the 30-knot target track to try to determine why it did not divert from its course and proceed to the area where the TWA 800 wreckage had fallen. TWA 800 was behind the target, and with the likely forward-looking perspective of the target's occupant(s), the occupants would not have been in a position to observe the aircraft's breakup and/or subsequent explosions/fireball(s). Additionally, it was unlikely that the occupants of the target track would have been able to hear the explosions over the sound of its engines and the noise of the hull traveling through water, even more so if the occupants were in an enclosed bridge or cabin. Further, review of the Islip radar data for other similar summer days and nights in 1999 indicated that the 30-knot track was consistent with normal commercial fishing, recreational, and/or cargo vessel traffic.
Trace amounts of explosive residue were detected on three samples of material from three separate locations of the recovered airplane wreckage (described by the FBI as a piece of canvas-like material and two pieces of a floor panel). These samples were submitted to the FBI's laboratory in Washington, D.C., which determined that one sample contained traces of cyclotrimethylenetrinitramine (RDX), another nitroglycerin, and the third a combination of RDX and pentaerythritol tetranitrate (PETN); these findings received much media attention at the time. In addition, the backs of several damaged passenger seats were observed to have an unknown red/brown-shaded substance on them. However, according to the seat manufacturer, the locations and appearance of this substance were consistent with adhesive used in the construction of the seats, and additional laboratory testing by NASA identified the substance as being consistent with adhesives.
Further examination of the airplane structure, seats, and other interior components found no damage typically associated with a high-energy explosion of a bomb or missile warhead ("severe pitting, cratering, petalling, or hot gas washing"). This included the pieces on which trace amounts of explosives were found. Of the 5 percent of the fuselage that was not recovered, none of the missing areas were large enough to have covered all the damage that would have been caused by the detonation of a bomb or missile. None of the victims' remains showed any evidence of injuries that could have been caused by high-energy explosives.
The NTSB considered the possibility that the explosive residue was due to contamination from the aircraft's use in 1991 transporting troops during the Gulf War or its use in a dog-training explosive detection exercise about one month before the accident. However, testing conducted by the FAA's Technical Center indicated that residues of the type of explosives found on the wreckage would dissipate completely after 2 days of immersion in sea water (almost all recovered wreckage was immersed longer than 2 days). The NTSB concluded that it was "quite possible" that the explosive residue detected was transferred from military ships or ground vehicles, or the clothing and boots of military personnel, onto the wreckage during or after the recovery operation and was not present when the aircraft crashed into the water.
Although it was unable to determine the exact source of the trace amounts of explosive residue found on the wreckage, the lack of any other corroborating evidence associated with a high-energy explosion led the NTSB to conclude that "the in-flight breakup of TWA flight 800 was not initiated by a bomb or missile strike."
Fuel/air explosion in the center wing fuel tank.
In order to evaluate the sequence of structural breakup of the airplane, the NTSB formed the Sequencing Group, which examined individual pieces of the recovered structure, two-dimensional reconstructions or layouts of sections of the airplane, and various-sized three-dimensional reconstructions of portions of the airplane. In addition, the locations of pieces of wreckage at the time of recovery and differences in fire effects on pieces that are normally adjacent to each other were evaluated. The Sequencing Group concluded that the first event in the breakup sequence was a fracture in the wing center section of the aircraft, caused by an "overpressure event" in the center wing fuel tank (CWT). An overpressure event was defined as a rapid increase in pressure resulting in failure of the structure of the CWT.
Because there was no evidence that a high-energy explosive device detonated in this (or any other) area of the airplane, this overpressure event could only have been caused by a fuel/air explosion in the CWT. Although only a small amount of fuel was present in the CWT of TWA 800, tests recreating the conditions of the flight showed the remaining fuel/air vapor to be flammable. A major reason for the flammability of the fuel/air vapor in the CWT of the 747 was the large amount of heat generated and transferred to the CWT by air conditioning packs located directly below the tank; with the CWT temperature raised to a sufficient level, a single ignition source could cause an explosion.
Computer modeling and scale model testing were used to predict and demonstrate how an explosion would progress in a 747 CWT. During this time, quenching was identified as an issue, where the explosion would extinguish itself as it passed through the complex structure of the CWT. Because the research data regarding quenching was limited, a complete understanding of quenching behavior was not possible, and the issue of quenching remained unresolved.
In order to better determine whether a fuel/air vapor explosion in the CWT would generate sufficient pressure to break apart the fuel tank and lead to the destruction of the airplane, tests were conducted in July and August 1997, using a retired Air France 747 at Bruntingthorpe Airfield, England. These tests simulated a fuel/air explosion in the CWT by igniting a propane/air mixture; this resulted in the failure of the tank structure due to overpressure. While the NTSB acknowledged that the test conditions at Bruntingthorpe were not fully comparable to the conditions that existed on TWA 800 at the time of the accident, previous fuel explosions in the CWTs of commercial airliners such as Avianca Flight 203 and Philippine Airlines Flight 143 confirmed that a CWT explosion could break apart the fuel tank and lead to the destruction of an airplane.
Ultimately, based on "the accident airplane's breakup sequence; wreckage damage characteristics; scientific tests and research on fuels, fuel tank explosions, and the conditions in the CWT at the time of the accident; and analysis of witness information," the NTSB concluded that "the TWA flight 800 in-flight breakup was initiated by a fuel/air explosion in the CWT."
In-flight breakup sequence and crippled flight.
[[File:Slide0045 image013.PNG|thumbnail|right|An NTSB investigator uses the recovered TWA 800 wreckage to illustrate the breakup sequence.
"Video: Part 1, Part 2 (RealMedia format)"]]
Recovery locations of the wreckage from the ocean (the red, yellow, and green zones) clearly indicated that: (1) the red area pieces (from the forward portion of the wing center section and a ring of fuselage directly in front) were the earliest pieces to separate from the airplane; (2) the forward fuselage section departed simultaneously with or shortly after the red area pieces, landing relatively intact in the yellow zone; (3) the green area pieces (wings and the aft portion of the fuselage) remained intact for a period after the separation of the forward fuselage, and impacted the water in the green zone.
Fire damage and soot deposits on the recovered wreckage indicated that some areas of fire existed on the airplane as it continued on in crippled flight after the loss of the forward fuselage. After about 34 seconds (based on information from witness documents), the outer portions of both the right and left wings failed, likely causing fuel-fed fires that were the beginning of the fireball described by witnesses. Shortly after, the left wing separated from what remained of the main fuselage, which resulted in further development of the fuel-fed fireballs as the pieces of wreckage fell to the ocean.
Only the FAA radar facility in North Truro, Massachusetts, using specialized processing software from the United States Air Force 84th Radar Evaluation Squadron, was capable of estimating the altitude of TWA 800 after it lost power after the CWT explosion. However, because of accuracy limitations, this radar data could not be used to determine whether the aircraft climbed after the nose separated. Instead, the NTSB conducted a series of computer simulations to examine the flightpath of the main portion of the fuselage. Hundreds of simulations were run using various combinations of possible times the nose of TWA 800 separated (the exact time was unknown), different models of the behavior of the crippled aircraft (the aerodynamic properties of the aircraft without its nose could only be estimated), and longitudinal radar data (the recorded radar tracks of the east/west position of TWA 800 from various sites differed). These simulations indicated that after the loss of the forward fuselage the remainder of the aircraft continued on in crippled flight, then pitched up while rolling to the left (north), climbing to a maximum altitude between and from its last recorded altitude, .
Analysis of reported witness observations.
At the start of FBI's investigation, because of the possibility that international terrorists might have been involved, assistance was requested from the Central Intelligence Agency (CIA). CIA analysts, relying on sound-propagation analysis, were able to conclude that the witnesses could not be describing a missile approaching an intact aircraft, but were seeing a trail of burning fuel coming from the aircraft after the initial explosion. This conclusion was reached after calculating how long it took for the sound of the initial explosion to reach the witnesses, and using that to correlate the witness observations with the accident sequence. In all cases the witnesses could not be describing a missile approaching an intact aircraft, as the plane had already exploded before their observations began.
As the investigation progressed, the NTSB decided to form a witness group to more fully address the accounts of witnesses. From November 1996, through April 1997, this group reviewed witness documents on loan from the FBI (with personal information redacted), and conducted interviews with crewmembers from a New York Air National Guard HH-60 helicopter and C-130 airplane, as well as a U.S. Navy P-3 airplane that were flying in the vicinity of TWA 800 at the time of the accident.
In February 1998, the FBI, having closed its active investigation, agreed to fully release the witness documents to the NTSB. With access to these documents no longer controlled by the FBI, the NTSB formed a second witness group to review the documents. Because of the amount of time that had elapsed (about 21 months) before the NTSB received information about the identity of the witnesses, the witness group chose not to re-interview most of the witnesses, but instead to rely on the original FBI documents as the best available evidence of the observations initially reported by the witnesses. However, despite the two and a half years that had elapsed since the accident, the witness group did interview the captain of Eastwind Airlines flight 507, who was the first to report the explosion of TWA 800, because of his vantage point and experience as an airline pilot.
The NTSB's review of the released witness documents determined that they contained 736 witness accounts, of which 258 were characterized as "streak of light" witnesses ("an object moving in the sky...variously described a point of light, fireworks, a flare, a shooting star, or something similar.") The NTSB Witness Group concluded that the streak of light reported by witnesses might have been the actual airplane during some stage of its flight before the fireball developed, noting that most of the 258 streak of light accounts were generally consistent with the calculated flightpath of the accident airplane after the CWT explosion.
However, 38 witnesses described a streak of light that ascended vertically, or nearly so, and these accounts "seem to be inconsistent with the accident airplane's flightpath." In addition, 18 witnesses reported seeing a streak of light that originated at the surface, or the horizon, which did not "appear to be consistent with the airplane's calculated flightpath and other known aspects of the accident sequence." Regarding these differing accounts, the NTSB noted that based on their experience in previous investigations "witness reports are often inconsistent with the known facts or with other witnesses' reports of the same events." The interviews conducted by the FBI focused on the possibility of a missile attack; suggested interview questions given to FBI agents such as "Where was the sun in relation to the aircraft and the missile launch point?" and "How long did the missile fly?" could have biased interviewees' responses in some cases. The NTSB concluded that given the large number of witnesses in this case, they "did not expect all of the documented witness observations to be consistent with one another." and "did not view these apparently anomalous witness reports as persuasive evidence that some witnesses might have observed a missile."
After missile visibility tests were conducted in April 2000, at Eglin Air Force Base, Fort Walton Beach, Florida, the NTSB determined that if witnesses had observed a missile attack they would have seen: (1) a light from the burning missile motor ascending very rapidly and steeply for about 8 seconds; (2) the light disappearing for up to 7 seconds; (3) upon the missile striking the aircraft and igniting the CWT another light, moving considerably more slowly and more laterally than the first, for about 30 seconds; (4) this light descending while simultaneously developing into a fireball falling toward the ocean. None of the witness documents described such a scenario.
Because of their unique vantage points and/or the level of precision and detail provided in their accounts, five witness accounts generated special interest: the pilot of Eastwind Airlines flight 507, the crew members in the HH-60 helicopter, a streak-of-light witness aboard US Airways flight 217, a land witness on the Beach Lane Bridge in Westhampton Beach, New York as well as a witness on a boat near Great Gun Beach. Advocates of a missile-attack scenario asserted that some of these witnesses observed a missile; however, analysis demonstrated that the observations were not consistent with a missile attack on TWA 800, but instead were consistent with these witnesses having observed some part of the in-flight fire and breakup sequence after the CWT explosion.
The NTSB concluded that "the witness observations of a streak of light were not related to a missile and that the streak of light reported by most of these witnesses was burning fuel from the accident airplane in crippled flight during some portion of the post-explosion, preimpact breakup sequence". The NTSB further concluded that "the witnesses' observations of one or more fireballs were of the airplane's burning wreckage falling toward the ocean".
Possible ignition sources of the center wing fuel tank.
In an attempt to determine what ignited the inflammable fuel/air vapor in the CWT and caused the explosion, the NTSB evaluated numerous potential ignition sources. All but one were considered very unlikely to have been the source of ignition.
Missile fragment or small explosive charge.
Although the NTSB had already reached the conclusion that a missile strike did not cause the structural failure of the airplane, the possibility that a missile could have exploded close enough to TWA 800 for a missile fragment to have entered the CWT and ignited the fuel/air vapor, yet far enough away not to have left any damage characteristic of a missile strike was considered. Computer simulations using missile performance data simulated a missile detonating in a location such that a fragment from the warhead could penetrate the CWT. Based on these simulations the NTSB concluded that it was "very unlikely" that a warhead detonated in such a location where a fragment could penetrate the CWT, but no other fragments impact the surrounding airplane structure leaving distinctive impact marks.
Similarly, the investigation considered the possibility that a small explosive charge placed on the CWT could have been the ignition source. Testing by the NTSB and the British Defence Evaluation and Research Agency demonstrated that when metal of the same type and thickness of the CWT was penetrated by a small charge, there was petalling of the surface where the charge was placed, pitting on the adjacent surfaces, and visible hot gas washing damage in the surrounding area. Since none of the recovered CWT wreckage exhibited these damage characteristics, and none of the areas of missing wreckage were large enough to encompass all the expected damage, the investigation concluded that this scenario was "very unlikely."
Other potential sources.
The NTSB also investigated whether the fuel/air mixture in the CWT could have been ignited by lightning strike, meteor strike, auto-ignition or hot surface ignition, a fire migrating to the CWT from another fuel tank via the vent system, an uncontained engine failure, a turbine burst in the air conditioning packs beneath the CWT, a malfunctioning CWT jettison/override pump, a malfunctioning CWT scavenger pump, or static electricity. After analysis the investigation determined that these potential sources were "very unlikely" to have been the source of ignition.
Fuel quantity indication system.
The FAA and airplane manufacturers had assumed that a combustible fuel/air mixture would exist at all times in fuel tanks; consequently, airplane designers attempted to eliminate all possible sources of ignition in the fuel tanks. The primary means of ensuring this were to protect all devices from intrusion of vapor and to keep voltages and currents being used by the Fuel Quantity Indication System (FQIS) very small. In the case of the 747-100 series, the only wiring located inside the CWT was wiring associated with the FQIS.
In order for the FQIS to be the ignition source, a transfer of higher than normal voltage to the FQIS needed to have occurred, as well as some mechanism whereby the excess energy was released by the FQIS wiring into the CWT. While the NTSB determined that factors suggesting the likelihood of a short circuit event existed, they added that "neither the release mechanism nor the location of the ignition inside the CWT could be determined from the available evidence." Nonetheless, the NTSB concluded that "the ignition energy for the CWT explosion most likely entered the CWT through the FQIS wiring."
Though the FQIS itself was designed to prevent danger from its normal operation by minimizing voltages and currents, the innermost tube of the FQIS compensator showed damage similar to that of the compensator tube that was the ignition source for the surge tank fire that destroyed a 747 near Madrid in 1976. This was not considered "proof" of a source of ignition. There was evidence of arcing in a wire bundle that included FQIS wiring that connected with the Center Wing Tank. There was also arcing evidenced on two wires sharing a cable raceway with FQIS wiring at station 955.
The Captain's Cockpit Voice Recorder channel showed two "dropouts" of background power harmonics in the second before the recording ended (with the separation of the nose). This might well be the signature of an arc on cockpit wiring adjacent to the FQIS wiring. The captain commented on the "crazy" readings of the number 4 engine fuel flow gauge about 2-1/2 minutes before the CVR recording ended. Finally, the Center Wing Tank fuel quantity gauge was recovered and indicated 640 pounds instead of the 300 pounds that had been loaded into that tank. Experiments showed that applying power to a wire leading to the fuel quantity gauge can cause the digital display to change by several hundred pounds before the circuit breaker trips. Thus the gauge anomaly could have been caused by a short to the FQIS wiring. The NTSB concluded that the most likely source of sufficient voltage to cause ignition was a short from damaged wiring, or within electrical components of the FQIS. As not all components and wiring were recovered, it was not possible to pin-point the source of the necessary voltage.
Conclusions.
During the course of its investigation, and in its final report, the NTSB issued fifteen safety recommendations, mostly covering fuel tank and wiring-related issues. Among the recommendations was that significant consideration should be given to the development of modifications such as nitrogen-inerting systems for new airplane designs and, where feasible, for existing airplanes.
Alternative theories.
The NTSB's conclusions about the cause of the TWA 800 disaster took four years and one month to be published. The FBI's earliest investigations and interviews, later used by the NTSB, were performed under the assumption of a missile attack, a fact noted in the NTSB's final report. Six months into the investigation, the NTSB's chairman, Jim Hall, was quoted as saying, "All three theories—a bomb, a missile or mechanical failure—remain." Speculation was fueled in part by early descriptions, visuals, and eyewitness accounts of this jet disaster, including a sudden explosion and trails of fire in the sky; particularly, trails of fire moving in an upward direction.
The two most prevalent specific theories around TWA 800 are that of a terrorist bomb on board, or a missile striking the plane (attributed by some to American armed forces and by others to non-state actors). Those supporting these alternative explanations for the crash typically claim that the NTSB's explanation was created as a cover-up; that the NTSB did not investigate sufficiently; or that the NTSB did not have all the evidence it should have had to reach the correct conclusion.
Aftermath.
Many users of the Internet responded to the incident. The resulting web traffic set records for Internet activity in 1996. CNN's traffic quadrupled to 3.9 million hits per day. After the flight crashed, the website of "The New York Times" had its traffic increase to one and one half million hits per day, an increase by half of its previous rate. In 1996 few U.S. government websites were updated daily; the United States Navy's website regarding the crash was constantly updated and had detailed information about the salvage of the crash site.
International Memorial.
The TWA Flight 800 International Memorial was dedicated in a parcel immediately adjoining the main pavilion at Smith Point County Park in Shirley, New York, on July 14, 2004. Funds for the memorial were raised by the Families of TWA Flight 800 Association. David Busch of Busch Associates PC Bay Shore, New York designed the memorial. The memorial includes landscaped grounds, flags from the 14 countries of the victims, and a curved black granite memorial with the names engraved on one side and an illustration on the other of a wave releasing 230 seagulls into the sky. In July 2006 an abstract design of a high lighthouse in black granite designed by Harry Edward Seaman, who had lost his cousin in the crash, was added. The lighthouse sits above a tomb holding many of the victims' personal belongings.
The wreckage is now permanently stored in an NTSB facility in Ashburn, Loudoun County, Virginia that was custom built for the purpose. The reconstructed aircraft is used to train accident investigators. On July 17, 2008 the Secretary of Transportation visited the facility and announced a final rule designed to prevent more accidents caused by explosions in fuel tanks. The NTSB first recommended such a rule just five months after the Flight 800 accident and thirty-three years after a similar recommendation issued by the Civil Aeronautics Board Bureau of Safety on December 17, 1963, nine days after the crash of Pan Am Flight 214. In 2009 Boeing advised the FAA that its new Boeing 787 Dreamliner could not meet the new safety standards. The FAA proposed to relax the safeguards for preventing sparks inside the fuel tank, calling them "impractical."

Feminism
Feminism is a collection of movements and ideologies aimed at defining, establishing, and defending equal political, economic, and social rights for women. In addition, feminism seeks to establish equal opportunities for women in education and employment. A feminist is "an advocate or supporter of the rights and equality of women".
Feminist theory, which emerged from these feminist movements, aims to understand the nature of gender inequality by examining women's social roles and lived experience; it has developed theories in a variety of disciplines in order to respond to issues such as the social construction of sex and gender. Some of the earlier forms of feminism have been criticized for taking into account only white, middle-class, educated perspectives. This led to the creation of ethnically specific or multiculturalist forms of feminism.
Feminist activists campaign for women's rights – such as in contract law, property, and voting – while also promoting bodily integrity, autonomy, and reproductive rights for women. Feminist campaigns have changed societies, particularly in the West, by achieving women's suffrage, gender neutrality in English, equal pay for women, reproductive rights for women (including access to contraceptives and abortion), and the right to enter into contracts and own property. Feminists have worked to protect women and girls from domestic violence, sexual harassment, and sexual assault. They have also advocated for workplace rights, including maternity leave, and against forms of discrimination against women. Feminism is mainly focused on women's issues, but because feminism seeks gender equality, some feminists argue that men's liberation is a necessary part of feminism, and that men are also harmed by sexism and gender roles.
Theory.
Feminist theory is the extension of feminism into theoretical or philosophical fields. It encompasses work in a variety of disciplines, including anthropology, sociology, economics, women's studies, literary criticism, art history, psychoanalysis and philosophy. Feminist theory aims to understand gender inequality and focuses on gender politics, power relations, and sexuality. While providing a critique of these social and political relations, much of feminist theory also focuses on the promotion of women's rights and interests. Themes explored in feminist theory include discrimination, stereotyping, objectification (especially sexual objectification), oppression, and patriarchy.
In the field of literary criticism, Elaine Showalter describes the development of feminist theory as having three phases. The first she calls "feminist critique", in which the feminist reader examines the ideologies behind literary phenomena. The second Showalter calls "gynocriticism", in which the "woman is producer of textual meaning". The last phase she calls "gender theory", in which the "ideological inscription and the literary effects of the sex/gender system are explored".
This was paralled in the 1970s by French feminists, who developed the concept of "écriture féminine" (which translates as female, or feminine writing). Helene Cixous argues that writing and philosophy are "" and along with other French feminists such as Luce Irigaray emphasize "writing from the body" as a subversive exercise. The work of the feminist psychoanalyst and philosopher, Julia Kristeva, has influenced feminist theory in general and feminist literary criticism in particular. However, as the scholar Elizabeth Wright points out, "none of these French feminists align themselves with the feminist movement as it appeared in the Anglophone world".
Movements and ideologies.
Many overlapping feminist movements and ideologies have developed over the years.
Political movements.
Some branches of feminism closely track the political leanings of the larger society, such as liberalism and conservatism, or focus on the environment. Liberal feminism seeks individualistic equality of men and women through political and legal reform without altering the structure of society. Radical feminism considers the male-controlled capitalist hierarchy as the defining feature of women's oppression and the total uprooting and reconstruction of society as necessary. Conservative feminism is conservative relative to the society in which it resides. Libertarian feminism conceives of people as self-owners and therefore as entitled to freedom from coercive interference. Separatist feminism does not support heterosexual relationships. Lesbian feminism is thus closely related. Other feminists criticize separatist feminism as sexist. Ecofeminists see men's control of land as responsible for the oppression of women and destruction of the natural environment; ecofeminism has been criticised for focusing too much on a mystical connection between women and nature.
Materialist ideologies.
Rosemary Hennessy and Chrys Ingraham say that materialist feminisms grew out of western marxist thought and have inspired a number of different (but overlapping) movements, all of which are involved in a critique of capitalism and are focussed on ideology's relationship to women. Marxist feminism argues that capitalism is the root cause of women's oppression, and that discrimination against women in domestic life and employment is an effect of capitalist ideologies. Socialist feminism distinguishes itself from Marxist feminism by arguing that women's liberation can only be achieved by working to end both the economic and cultural sources of women's oppression. Anarcha-feminists believe that class struggle and anarchy against the state require struggling against patriarchy, which comes from involuntary hierarchy.
Black and postcolonial ideologies.
Sara Ahmed argues that Black and Postcolonial feminisms pose a challenge "to some of the organizing premises of Western feminist thought." During much of its history, feminist movements and theoretical developments were led predominantly by middle-class white women from Western Europe and North America. However women of other races have proposed alternative feminisms. This trend accelerated in the 1960s with the civil rights movement in the United States and the collapse of European colonialism in Africa, the Caribbean, parts of Latin America, and Southeast Asia. Since that time, women in developing nations and former colonies and who are of colour or various ethnicities or living in poverty have proposed additional feminisms. Womanism emerged after early feminist movements were largely white and middle-class. Postcolonial feminists argue that colonial oppression and Western feminism marginalized postcolonial women but did not turn them passive or voiceless. Third-world feminism is closely related to postcolonial feminism. These ideas also correspond with ideas in African feminism, motherism, Stiwanism, negofeminism, femalism, transnational feminism, and Africana womanism.
Social constructionist ideologies.
In the late twentieth century various feminists began to argue that gender roles are socially constructed, and that it is impossible to generalize women's experiences across cultures and histories.
Post-structural feminism draws on the philosophies of post-structuralism and deconstruction in order to argue that the concept of gender is created socially and culturally through discourse. Postmodern feminists also emphasize the social construction of gender and the discursive nature of reality, however as Pamela Abbot et al. note, a postmodern approach to feminism highlights "the existence of multiple truths (rather than simply men and women's standpoints)."
Cultural movements.
Riot grrrl (or riot grrl) is an underground feminist punk movement that started in the 1990s and is often associated with third-wave feminism. It was grounded in the DIY philosophy of punk values. Riot grrls took an anti-corporate stance of self-sufficiency and self-reliance. Riot grrrl's emphasis on universal female identity and separatism often appears more closely allied with second-wave feminism than with the third wave. The movement encouraged and made "adolescent girls’ standpoints central," allowing them to express themselves fully. Lipstick feminism is a cultural feminist movement that attempts to respond to the backlash of second-wave radical feminism of the 1960s and 1970s by reclaiming symbols of "feminine" identity such as make-up, suggestive clothing and having a sexual allure as valid and empowering personal choices.
Visual arts movement.
The feminist art movement refers to the efforts and accomplishments of feminists internationally to make art that reflects women's lives and experiences, as well as to change the foundation for the production and reception of contemporary art. It also sought to bring more visibility to women within art history and art practice. Corresponding with general developments within feminism, and often including such self-organizing tactics as the consciousness-raising group, the movement began in the 1960s and flourished throughout the 1970s. Jeremy Strick, director of the Museum of Contemporary Art in Los Angeles, described the feminist art movement as "the most influential international movement of any during the postwar period", and Peggy Phelan says that it "brought about the most far-reaching transformations in both artmaking and art writing over the past four decades". Judy Chicago, who with a team of 129 created "The Dinner Party", said in 2009 to "ARTnews", "There is still an institutional lag and an insistence on a male Eurocentric narrative. We are trying to change the future: to get girls and boys to realize that women's art is not an exception—it's a normal part of art history."
Feminism and sexuality.
Over the course of the 1970s, a large variety of influential women accepted lesbianism and bisexuality as part of feminism. As a result, a significant proportion of feminists favoured this view, however, others considered sexuality irrelevant to the attainment of other goals. Sexuality, sexual representation, sadomasochism, the role of transwomen in the lesbian community, and other sexual issues arose within acrimonious feminist debates known as the feminist sex wars.
Sex industry.
Opinions on the sex industry are diverse. Feminists are generally either critical of it (seeing it as exploitative, a result of patriarchal social structures and reinforcing sexual and cultural attitudes that are complicit in rape and sexual harassment) or supportive of at least parts of it (arguing that some forms of it can be a medium of feminist expression and a means of women taking control of their sexuality).
Pornography.
The "Feminist Sex Wars" is a term for the acrimonious debates within the feminist movement in the late 1970s through the 1980s around the issues of feminism, sexuality, sexual representation, pornography, sadomasochism, the role of transwomen in the lesbian community, and other sexual issues. The debate pitted anti-pornography feminism against sex-positive feminism, and parts of the feminist movement were deeply divided by these debates.
Prostitution and trafficking.
Feminists' views on prostitution vary, but many of these perspectives can be loosely arranged into an overarching standpoint that is generally either critical or supportive of prostitution and sex work. Anti-prostitution feminists are strongly opposed to prostitution, as they see the practice as a form of violence against and exploitation of women, and a sign of male dominance over women. Feminists who hold such views on prostitution include Kathleen Barry, Melissa Farley, Julie Bindel, Sheila Jeffreys, Catharine MacKinnon and Laura Lederer; the European Women's Lobby has also condemned prostitution as "an intolerable form of male violence".
Other feminists hold that prostitution and other forms of sex work can be valid choices for women and men who choose to engage in it. In this view, prostitution must be differentiated from forced prostitution, and feminists should support sex worker activism against abuses by both the sex industry and the legal system. The disagreement between these two feminist stances was particularly contentious, and may be comparable to the feminist sex wars of the late twentieth century.
Feminism and science.
Sandra Harding says that the "moral and political insights of the women's movement have inspired social scientists and biologists to raise critical questions about the ways traditional researchers have explained gender, sex and relations within and between the social and natural worlds." Some feminists, such as Ruth Hubbard and Evelyn Fox Keller, criticize traditional scientific discourse as being historically biased towards a male perspective. A part of the feminist research agenda is the examination of the ways in which power inequities are created and/or reinforced in scientific and academic institutions. Physicist Lisa Randall, appointed to a task force at Harvard by then-president Lawrence Summers after his controversial discussion of why women may be underrepresented in science and engineering, said, "I just want to see a whole bunch more women enter the field so these issues don't have to come up anymore."
Lynn Hankinson Nelson notes that feminist empiricists argue that there are fundamental differences between the experiences of men and women, thus they seek to obtain knowledge through the examination of the experiences of women, and attempt to "uncover the consequences of omitting, misdescribing, or devaluing them" for account of human experience. Other feminist scientists eschew objectivity in favor of self-reflexivity and the agenda of helping women. Also, part of the feminist research agenda is the uncovering of ways in which power inequities are created and/or reinforced in society and in scientific and academic institutions.
One criticism of feminist epistemology is that it allows social and political values to influence its findings. Susan Haack also points out that feminist epistemology reinforces traditional stereotypes about women's thinking (as intuitive and emotional, etc.), Meera Nanda further cautions that this may in fact trap women within "traditional gender roles and help justify patriarchy".
Biology and gender.
Modern feminist science challenges the biological essentialist view of gender. However, it is increasingly interested in the study of biological sex differences and their effect on human behavior. For example, Anne Fausto-Sterling's book, "Myths of Gender", explores the assumptions embodied in scientific research that purports to support a biologically essentialist view of gender. For example, in "Delusions of Gender" Cordelia Fine argues that there is currently no scientific evidence for innate biological differences between men and women's minds, and that cultural and societal beliefs contribute to commonly perceived sex differences.
Feminist culture.
Architecture.
Gender-based inquiries into and conceptualization of architecture have also come about, leading to feminism in modern architecture. Piyush Mathur coined the term "archigenderic". Claiming that "architectural planning has an inextricable link with the defining and regulation of gender roles, responsibilities, rights, and limitations", Mathur came up with that term "to explore...the meaning of 'architecture' in terms of gender" and "to explore the meaning of 'gender' in terms of architecture".
Art.
According to the Tate Collection, feminist art can "be defined as art by women artists made consciously in the light of developments in feminist art theory since about 1970."
Literature.
The feminist movement produced both feminist fiction and non-fiction, and created new interest in women's writing. It also prompted a general reevaluation of women's historical and academic contributions in response to the belief that women's lives and contributions have been underrepresented as areas of scholarly interest. Much of the early period of feminist literary scholarship was given over to the rediscovery and reclamation of texts written by women. Studies like Dale Spender's "Mothers of the Novel" (1986) and Jane Spencer's "The Rise of the Woman Novelist" (1986) were ground-breaking in their insistence that women have always been writing. Commensurate with this growth in scholarly interest, various presses began the task of reissuing long-out-of-print texts. Virago Press began to publish its large list of 19th and early-20th-century novels in 1975 and became one of the first commercial presses to join in the project of reclamation. In the 1980s Pandora Press, responsible for publishing Spender's study, issued a companion line of 18th-century novels by written by women. More recently, Broadview Press continues to issue 18th- and 19th-century novels, many hitherto out of print, and the University of Kentucky has a series of republications of early women's novels.
The widespread interest in women's writing is related to a general reassessment and expansion of the literary canon. Interest in post-colonial literatures, gay and lesbian literature, writing by people of colour, working people's writing, and the cultural productions of other historically marginalized groups has resulted in a whole scale expansion of what is considered "literature," and genres hitherto not regarded as "literary," such as children's writing, journals, letters, travel writing, and many others are now the subjects of scholarly interest. Most genres and sub-genres have undergone a similar analysis, so that one now sees work on the "female gothic" or women's science fiction.
According to Elyce Rae Helford "Science fiction and fantasy serve as important vehicles for feminist thought, particularly as bridges between theory and practice." Feminist science fiction is sometimes taught at the university level to explore the role of social constructs in understanding gender. Notable texts of this kind are Ursula K. Le Guin's "The Left Hand of Darkness" (1969), Joanna Russ' "The Female Man" (1970), Octavia Butler's "Kindred" (1979) and Margaret Atwood's "Handmaid's Tale" (1985).
Music.
Women's music (or womyn's music or wimmin's music) is the music by women, for women, and about women. The genre emerged as a musical expression of the second-wave feminist movement as well as the labor, civil rights, and peace movements. The movement was started by lesbians such as Cris Williamson, Meg Christian, and Margie Adam, African-American women activists such as Bernice Johnson Reagon and her group Sweet Honey in the Rock, and peace activist Holly Near. Women's music also refers to the wider industry of women's music that goes beyond the performing artists to include studio musicians, producers, sound engineers, technicians, cover artists, distributors, promoters, and festival organizers who are also women.
Feminism became a principal concern of musicologists in the 1980s. Prior to this, in the 1970s, musicologists were beginning to discover women composers and performers, and had begun to review concepts of canon, genius, genre and periodization from a feminist perspective. In other words, the question of how women musicians fit into traditional music history was now being asked.
Through the 1980s and 1990s, this trend continued as musicologists like Susan McClary, Marcia Citron and Ruth Solie began to consider the cultural reasons for the marginalizing of women from the received body of work. Concepts such as music as gendered discourse; professionalism; reception of women's music; examination of the sites of music production; relative wealth and education of women; popular music studies in relation to women's identity; patriarchal ideas in music analysis; and notions of gender and difference are among the themes examined during this time.
Relationship to political movements.
Feminism had complex interactions with the major political movements of the twentieth century.
Socialism.
Since the late nineteenth century some feminists have allied with socialism, whereas others have criticized socialist ideology for being insufficiently concerned about women's rights. August Bebel, an early activist of the German Social Democratic Party, published his work "Die Frau und der Sozialismus", juxtaposing the struggle for equal rights between sexes with social equality in general. In 1907 there was an International Conference of Socialist Women in Stuttgart where suffrage was described as a tool of class struggle. Clara Zetkin of the Social Democratic Party of Germany called for women's suffrage to build a ""socialist order, the only one that allows for a radical solution to the women's question"".
In Britain, the women's movement was allied with the Labour party. In the U.S., Betty Friedan emerged from a radical background to take leadership. Radical Women is the oldest socialist feminist organization in the U.S. and is still active. During the Spanish Civil War, Dolores Ibárruri ("La Pasionaria") led the Communist Party of Spain. Although she supported equal rights for women, she opposed women fighting on the front and clashed with the anarcha-feminist Mujeres Libres.
Fascism.
Like socialism, fascism has been prescribed dubious stances on feminism by its practitioners and by women's groups. Amongst other demands concerning social reform presented in the Fascist manifesto in 1919 was expanding the suffrage to all Italian citizens of age 18 and above, including women (accomplished only in 1946, after the defeat of fascism) and eligibility for all to stand for office from age 25. This demand was particularly championed by special Fascist women's auxiliary groups such as the "fasci femminilli" and only partly realized in 1925, under pressure from Prime Minister Benito Mussolini's more conservative coalition partners.
Cyprian Blamires states that although feminists were among those who opposed the rise of Adolf Hitler, feminism has a complicated relationship with the Nazi movement as well, which saw several vocal female supporters as well as women's groups. While Nazis glorified traditional notions of patriarchal society and its role for women, they claimed to recognize women's equality in employment. However, Hitler and Benito Mussolini declared themselves as opposed to feminism, and after the rise of Nazism in Germany in 1933, there was a rapid dissolution of the political rights and economic opportunities that feminists had fought for during the prewar period and to some extent during the 1920s. Georges Duby et al. note that in practice fascist society was hierarchical and emphasized male virility, with women maintaining a largely subordinate position. Blamires also notes that Neofascism has since the 1960s been hostile towards feminism and advocates that women accept "their traditional roles".
Civil rights movement and anti-racism.
The civil rights movement has influenced and informed the feminist movement and vice versa. Many Western feminists adapted the language and theories of black equality activism and drew parallels between women's rights and the rights of non-white people. Despite the connections between the women's and civil rights movements, some tension arose during the late 1960s and early 1970s as non-white women argued that feminism was predominantly white and middle class, and did not understand and was not concerned with race issues. Similarly, some women argued that the civil rights movement had sexist elements and did not adequately address minority women's concerns. These criticisms created new feminist social theories about the intersections of racism, classism, and sexism, and new feminisms, such as black feminism and Chicana feminism.
History.
Depending on historical moment, culture and country, feminists around the world have had different causes and goals. Most western feminist historians assert that all movements that work to obtain women's rights should be considered feminist movements, even when they did not (or do not) apply the term to themselves. Other historians assert that the term should be limited to the modern feminist movement and its descendants. Those historians use the label "protofeminist" to describe earlier movements.
The history of the modern western feminist movements is divided into three "waves". Each wave dealt with different aspects of the same feminist issues. The first wave comprised women's suffrage movements of the nineteenth and early twentieth centuries, promoting women's right to vote. The second wave was associated with the ideas and actions of the women's liberation movement beginning in the 1960s. The second wave campaigned for legal and social equality for women. The third wave is a continuation of, and a reaction to, the perceived failures of second-wave feminism, beginning in the 1990s.
Nineteenth and early twentieth centuries.
First-wave feminism was a period of activity during the nineteenth century and early twentieth century. In the UK and US, it focused on the promotion of equal contract, marriage, parenting, and property rights for women. By the end of the nineteenth century, activism focused primarily on gaining political power, particularly the right of women's suffrage, though some feminists were active in campaigning for women's sexual, reproductive, and economic rights as well.
Women's suffrage was achieved in Britain's Australasian colonies at the close of the 19th century, with the self-governing colonies of New Zealand and South Australia granting women the right to vote in 1893 and 1895 respectively. It was followed by Australia permitting women to stand for parliamentary office and granting women the right to vote.
In Britain the Suffragettes and the Suffragists campaigned for the women's vote, and in 1918 the Representation of the People Act was passed granting the vote to women over the age of 30 who owned houses. In 1928 this was extended to all women over twenty-one. In the U.S., notable leaders of this movement included Lucretia Mott, Elizabeth Cady Stanton, and Susan B. Anthony, who each campaigned for the abolition of slavery prior to championing women's right to vote. These women were influenced by the Quaker theology of spiritual equality, which asserts that men and women are equal under God. In the United States, first-wave feminism is considered to have ended with the passage of the Nineteenth Amendment to the United States Constitution (1919), granting women the right to vote in all states. The term "first wave" was coined retroactively to categorize these western movements after the term "second-wave feminism" began to be used to describe a newer feminist movement that focused as much on fighting social and cultural inequalities as political inequalities.
During the late Qing period and reform movements such as the Hundred Days' Reform, Chinese feminists called for women's liberation from traditional roles and Neo-Confucian gender segregation. Later, the Chinese Communist Party created projects aimed at integrating women into the workforce, and claimed that the revolution had successfully achieved women's liberation.
In 1899, Qasim Amin, considered the "father" of Arab feminism, wrote "The Liberation of Women", which argued for legal and social reforms for women. Hoda Shaarawi founded the Egyptian Feminist Union in 1923, and became its president and a symbol of the Arab women's rights movement. Arab feminism was closely connected with Arab nationalism.
The Iranian Constitutional Revolution in 1905 triggered the Iranian women's movement, which aimed to achieve women's equality in education, marriage, careers, and legal rights. However, during the Iranian revolution of 1979, many of the rights that women had gained from the women's movement were systematically abolished, such as the Family Protection Law.
In France, women obtained the right to vote only with the Provisional Government of the French Republic of 21 April 1944. The Consultative Assembly of Algiers of 1944 proposed on 24 March 1944 to grant eligibility to women but following an amendment by Fernand Grenier, they were given full citizenship, including the right to vote. Grenier's proposition was adopted 51 to 16. In May 1947, following the November 1946 elections, the sociologist Robert Verdier minimized the "gender gap," stating in "Le Populaire" that women had not voted in a consistent way, dividing themselves, as men, according to social classes. During the baby boom period, feminism waned in importance. Wars (both World War I and World War II) had seen the provisional emancipation of some, individual, women, but post-war periods signaled the return to conservative roles.
Mid-twentieth century.
French philosopher Simone de Beauvoir provided a Marxist solution and an existentialist view on many of the questions of feminism with the publication of "Le Deuxième Sexe" (The Second Sex) in 1949. The book expressed feminists' sense of injustice. Second-wave feminism is a feminist movement beginning in the early 1960s and continuing to the present; as such, it coexists with third-wave feminism. Second wave feminism is largely concerned with issues of equality other than suffrage, such as ending discrimination.
Second-wave feminists see women's cultural and political inequalities as inextricably linked and encourage women to understand aspects of their personal lives as deeply politicized and as reflecting sexist power structures. The feminist activist and author Carol Hanisch coined the slogan "The Personal is Political", which became synonymous with the second wave.
Second and third-wave feminism in China has been characterized by a re-examination of women's roles during the communist revolution and other reform movements, and new discussions about whether women's equality has actually been fully achieved.
In 1956, President Gamal Abdel Nasser of Egypt initiated "state feminism", which outlawed discrimination based on gender and granted women's suffrage, but also blocked political activism by feminist leaders. During Sadat's presidency, his wife, Jehan Sadat, publicly advocated for further women's rights, though Egyptian policy and society began to move away from women's equality with the new Islamist movement and growing conservatism. However, some activists proposed a new feminist movement, Islamic feminism, which argues for women's equality within an Islamic framework.
In Latin America, revolutions brought changes in women's status in countries such as Nicaragua, where feminist ideology during the Sandinista Revolution aided women's quality of life but fell short of achieving a social and ideological change.
Late twentieth and early twenty-first centuries.
In the early 1990s in the USA, third-wave feminism began as a response to perceived failures of the second wave and to the backlash against initiatives and movements created by the second wave. Third-wave feminism seeks to challenge or avoid what it deems the second wave's essentialist definitions of femininity, which, they argue, over-emphasize the experiences of upper middle-class white women. Third-wave feminists often focus on "micro-politics" and challenge the second wave's paradigm as to what is, or is not, good for women, and tend to use a post-structuralist interpretation of gender and sexuality. Feminist leaders rooted in the second wave, such as Gloria Anzaldua, bell hooks, Chela Sandoval, Cherrie Moraga, Audre Lorde, Maxine Hong Kingston, and many other black feminists, sought to negotiate a space within feminist thought for consideration of race-related subjectivities.
Since the 1980s standpoint feminists have argued that the feminist movement should address global issues (such as rape, incest, and prostitution) and culturally specific issues (such as female genital mutilation in some parts of Africa and the Middle East and glass ceiling practices that impede women's advancement in developed economies) in order to understand how gender inequality interacts with racism, homophobia, classism and colonization in a "matrix of domination." Third-wave feminism also contains internal debates between difference feminists, who believe that there are important differences between the sexes, and those who believe that there are no inherent differences between the sexes and contend that gender roles are due to social conditioning.
The term post-feminism is used to describe a range of viewpoints reacting to feminism since the 1980s. While not being "anti-feminist", post-feminists believe that women have achieved second wave goals while being critical of third wave feminist goals. The term was first used to describe a backlash against second-wave feminism, but it is now a label for a wide range of theories that take critical approaches to previous feminist discourses and includes challenges to the second wave's ideas. Other post-feminists say that feminism is no longer relevant to today's society. Amelia Jones has written that the post-feminist texts which emerged in the 1980s and 1990s portrayed second-wave feminism as a monolithic entity.
Societal impact.
The feminist movement has effected change in Western society, including women's suffrage; greater access to education; more nearly equitable pay with men; the right to initiate divorce proceedings; the right of women to make individual decisions regarding pregnancy (including access to contraceptives and abortion); and the right to own property.
Civil rights.
From the 1960s on, the campaign for women's rights was met with mixed results in the U.S. and the U.K. Other countries of the EEC agreed to ensure that discriminatory laws would be phased out across the European Community.
Some feminist campaigning also helped reform attitudes to child sexual abuse. The view that young girls cause men to have sexual intercourse with them was replaced by that of men's responsibility for their own conduct, the men being adults.
In the U.S., the National Organization for Women (NOW) began in 1966 to seek women's equality, including through the Equal Rights Amendment (ERA), which did not pass, although some states enacted their own. Reproductive rights in the U.S. centered on the court decision in "Roe" v. "Wade" enunciating a woman's right to choose whether to carry a pregnancy to term. Western women gained more reliable birth control, allowing family planning and careers. The movement started in the 1910s in the U.S. under Margaret Sanger and elsewhere under Marie Stopes. In the final three decades of the 20th century, Western women knew a new freedom through birth control, which enabled women to plan their adult lives, often making way for both career and family.
The division of labor within households was affected by the increased entry of women into workplaces in the 20th century. Sociologist Arlie Russell Hochschild found that, in two-career couples, men and women, on average, spend about equal amounts of time working, but women still spend more time on housework, although Cathy Young responded by arguing that women may prevent equal participation by men in housework and parenting.
In international law, the "Convention on the Elimination of All Forms of Discrimination Against Women" (CEDAW) is an international convention adopted by the United Nations General Assembly and described as an international bill of rights for women. It came into force in those nations ratifying it.
Language.
Gender-neutral language is a description of language usages which are aimed at minimizing assumptions regarding the biological sex of human referents. The advocacy of gender-neutral language reflects, at least, two different agendas: one aims to clarify the "inclusion" of both sexes or genders (gender-inclusive language); the other proposes that gender, as a category, is rarely worth marking in language (gender-neutral language). Gender-neutral language is sometimes described as "non-sexist language" by advocates and "politically correct language" by opponents.
Theology.
Feminist theology is a movement that reconsiders the traditions, practices, scriptures, and theologies of religions from a feminist perspective. Some of the goals of feminist theology include increasing the role of women among the clergy and religious authorities, reinterpreting male-dominated imagery and language about God, determining women's place in relation to career and motherhood, and studying images of women in the religion's sacred texts. The Christian bible refers to women in authority in Genesis 3:16 and 1 Tim 2:11–13. 
Christian feminism is a branch of feminist theology which seeks to interpret and understand Christianity in light of the equality of women and men, and that this interpretation is necessary for a complete understanding of Christianity. While there is no standard set of beliefs among Christian feminists, most agree that God does not discriminate on the basis of sex, and are involved in issues such as the ordination of women, male dominance and the balance of parenting in Christian marriage, claims of moral deficiency and inferiority of women compared to men, and the overall treatment of women in the church.
Islamic feminists advocate women's rights, gender equality, and social justice grounded within an Islamic framework. Advocates seek to highlight the deeply rooted teachings of equality in the Quran and encourage a questioning of the patriarchal interpretation of Islamic teaching through the Quran, "hadith" (sayings of Muhammad), and "sharia" (law) towards the creation of a more equal and just society. Although rooted in Islam, the movement's pioneers have also utilized secular and Western feminist discourses and recognize the role of Islamic feminism as part of an integrated global feminist movement.
Jewish feminism is a movement that seeks to improve the religious, legal, and social status of women within Judaism and to open up new opportunities for religious experience and leadership for Jewish women. The main issues for early Jewish feminists in these movements were the exclusion from the all-male prayer group or "minyan", the exemption from positive time-bound "mitzvot", and women's inability to function as witnesses and to initiate divorce.
Secular or atheist feminists have engaged in feminist criticism of religion, arguing that many religions have oppressive rules towards women and misogynistic themes and elements in religious texts.
Patriarchy.
Patriarchy is a social system in which the role of the male as the primary authority figure is central to social organization, and where fathers hold authority over women, children, and property. It implies the institutions of male rule and privilege, and is dependent on female subordination. Most forms of feminism characterize patriarchy as an unjust social system that is oppressive to women. As the feminist and political theorist Carole Pateman writes: "The patriarchal construction of the difference between masculinity and femininity is the political difference between freedom and subjection." In feminist theory the concept of patriarchy often includes all the social mechanisms that reproduce and exert male dominance over women. Feminist theory typically characterizes patriarchy as a social construction, which can be overcome by revealing and critically analyzing its manifestations. Some radical feminists have proposed that because patriarchy is too deeply rooted in society, separatism is the only viable solution. Other feminists have criticized these radical feminist views as being anti-men, though some radical feminists reject this portrayal of their views. Societal tension caused by second-wave feminism gave rise to backlash in the form of anti-feminist men's movements, such as Masculism, though today some see masculism as a complementary movement that does not oppose feminism.
Men and masculinity.
Feminist theory has explored the social construction of masculinity and its implications for the goal of gender equality. The social construct of masculinity is seen by feminism as problematic because it associates males with aggression and competition, and reinforces patriarchal and unequal gender relations. The patriarchal concept of masculinity is also seen as harmful to men by narrowing their life choices, limiting their sexuality, and blocking full emotional connections with women and other men. Some feminists are engaged with men's issues activism, such as bringing attention to male rape and spousal battery and addressing negative social expectations for men.
Male participation in feminism is encouraged by feminists and is seen as an important strategy for achieving full societal commitment to gender equality. Many male feminists and pro-feminists are active in both women's rights activism, feminist theory, and masculinity studies. However, some argue that while male engagement with feminism is necessary, it is problematic due to the ingrained social influences of patriarchy in gender relations. The consensus today in feminist and masculinity theories is that both genders can and should cooperate to achieve the larger goals of feminism.
Reactions.
Different groups of people have responded to feminism, and both men and women have been among its supporters and critics. Among American university students, for both men and women, support for feminist ideas is more common than self-identification as a feminist. The US media tends to portray feminism negatively and feminists "are less often associated with day-to-day work/leisure activities of regular women."
Pro-feminism.
Pro-feminism is the support of feminism without implying that the supporter is a member of the feminist movement. The term is most often used in reference to men who are actively supportive of feminism. The activities of pro-feminist men's groups include anti-violence work with boys and young men in schools, offering sexual harassment workshops in workplaces, running community education campaigns, and counseling male perpetrators of violence. Pro-feminist men also are involved in men's health, activism against pornography including anti-pornography legislation, men's studies, and the development of gender equity curricula in schools. This work is sometimes in collaboration with feminists and women's services, such as domestic violence and rape crisis centers.
Anti-feminism.
Anti-feminism is opposition to feminism in some or all of its forms.
In the nineteenth century, anti-feminism was mainly focused on opposition to women's suffrage. Later, opponents of women's entry into institutions of higher learning argued that education was too great a physical burden on women. Other anti-feminists opposed women's entry into the labor force, or their right to join unions, to sit on juries, or to obtain birth control and control of their sexuality.
Some people have opposed feminism on the grounds that they believe it is contrary to traditional values or religious beliefs. These anti-feminists argue, for example, that social acceptance of divorce and non-married women is wrong and harmful, and that men and women are fundamentally different and thus their different traditional roles in society should be maintained. Other anti-feminists oppose women's entry into the workforce, political office, and the voting process, as well as the lessening of male authority in families.
Writers such as Camille Paglia, Christina Hoff Sommers, Jean Bethke Elshtain, Elizabeth Fox-Genovese and Daphne Patai oppose some forms of feminism, though they identify as feminists. They argue, for example, that feminism often promotes misandry and the elevation of women's interests above men's, and criticize radical feminist positions as harmful to both men and women. Daphne Patai and Noretta Koertge argue that the term "anti-feminist" is used to silence academic debate about feminism.

France
France ( or ; ), officially the French Republic ( ), is a unitary semi-presidential republic in Western Europe with several overseas territories and islands. Metropolitan France extends from the Mediterranean Sea to the English Channel and the North Sea, and from the Rhine to the Atlantic Ocean. From its shape, it is often referred to in French as "" ("The Hexagon").
France is the largest country in Western Europe and the third-largest in Europe as a whole. It possesses the second-largest exclusive economic zone in the world. Over the past 500 years, France has been a major power with strong cultural, economic, military, and political influence in Europe and around the world. France has its main ideals expressed in the 18th-century Declaration of the Rights of Man and of the Citizen. From the 17th to the early 20th century, France built the second-largest colonial empire of the time, ruling large portions of first North America and India and then Northwest and Central Africa; Madagascar; Indochina and southeast China; and many Caribbean and Pacific Islands.
France is a developed country: it possesses the world's fifth-largest and Europe's second-largest economy by nominal GDP; it is the world's ninth-largest by GDP at purchasing power parity. France is the wealthiest nation in Europe – and the fourth-wealthiest in the world – in aggregate household wealth. French citizens enjoy a high standard of living, high public education level, and one of the world's longest life expectancies. France has been listed as the world's "best overall health care" provider by the World Health Organization. It is the most-visited country in the world, receiving 79.5 million foreign tourists annually.
France has the world's fifth-largest nominal military budget, as well as (in terms of personnel) the largest military in the EU, the third-largest deployable force in NATO, and the 26th-largest military in the world. France also possesses the third-largest stockpile of nuclear weapons in the world – with around 300 active warheads – and the world's second-largest diplomatic corps (behind the United States). France is a founding member of the United Nations, one of the five permanent members of the UN Security Council, and a member of the Francophonie, the G8, G20, NATO, OECD, WTO, and the Latin Union. It is also a founding and leading member state of the European Union and the largest EU state by area. In 2011, France was listed 20th on the Human Development Index and, in 2010, 24th on the Corruption Perceptions Index.
Etymology.
The name "France" comes from the Latin "", which means "country of the Franks". There are various theories as to the origin of the name of the Franks. One is that it is derived from the Proto-Germanic word "frankon" which translates as "javelin" or "lance" as the throwing axe of the Franks was known as a francisca. Another proposed etymology is that in an ancient Germanic language, Frank means "free" as opposed to slave.
History.
Prehistory.
The oldest traces of human life in what is now France date from approximately 1,800,000 years ago. Men were then confronted by a hard and variable climate, marked by several glacial eras which modified their framework of life and led them to a nomadic life of hunters-gatherers. France counts a large number of decorated caves from the upper Paleolithic era, including one of the most famous and best preserved: Lascaux (Dordogne, approximately 18,000 BC).
At the end of the Last glacial period (10,000 BC), the climate softened and from approximately 7,000 BC, this part of Western Europe entered the Neolithic era and its inhabitants became sedentary. After a strong demographic and agricultural development between the 4th and 3rd millennia, metallurgy appeared at the end of the 3rd millennium, initially with the work of gold, copper and bronze, and later with iron. France counts numerous megalithic sites from the Neolithic period, including the exceptionally dense Carnac stones site (Morbihan, approximately 3,300 BC).
Gaul.
In 600 BC, Ionian Greeks, originating from Phocaea, founded the colony of Massalia (present-day Marseille), on the shores of the Mediterranean Sea, making it the oldest city of France. At the same time, some Gallic Celtic tribes penetrated some parts of the current territory of France, but this occupation spread in the rest of France only between the 5th and 3rd century BC.
The concept of Gaul emerged at that time; it corresponds to the territories of Celtic settlement ranging between the Rhine, the Atlantic Ocean, the Pyrenees and the Mediterranean Sea. The borders of modern France are approximately the same as those of ancient Gaul, which was inhabited by Celtic "Gauls". Gaul was then a prosperous country, of which the southernmost part was heavily subject to Greek and Roman influences. However, around 390 BC, the Gallic chieftain Brennus and his troops made their way to Italy through the Alps, defeated the Romans in the Battle of the Allia, and besieged and ransomed Rome.
The Gallic invasion left Rome weakened and encouraged several subdued Italian tribes to rebel. One by one, over the course of the next 50 years, these tribes were defeated and brought back under Roman dominion. The Gauls continued to harass the region until 345 BC, when they entered into a formal peace treaty with Rome. But the Romans and the Gauls would maintain an adversarial relationship for the next several centuries and the Gauls would remain a threat in Italia.
Around 125 BC, the south of Gaul was conquered by the Romans, who called this region "" ("Roman Province"), which over time evolved into the name Provence in French. Brennus' siege of Rome was still remembered by Romans, when Julius Caesar conquered the remainder of Gaul and overcame a revolt carried out by the Gallic chieftain Vercingetorix in 52 BC.
Gaul was divided by Augustus into Roman provinces, the principal ones being Gallia Narbonensis in the south, Gallia Aquitania in the south-west, Gallia Lugdunensis in the center and Gallia Belgica in the north. Many cities were founded during the Gallo-Roman period, including Lugdunum (present-day Lyon), which is considered to be the capital of the Gauls. These cities were built in the traditional Roman style, with a forum, a theatre, a circus, an amphitheatre and thermal baths. The Gauls mixed with Roman settlers and eventually adopted Roman speech (Latin, from which the French language evolved) and Roman culture. The Roman polytheism merged with the Gallic paganism into the same syncretism.
Around the 3rd century AD, Roman Gaul underwent a serious crisis with its "limes" (fortified borders protecting the Empire) crossed on several occasions by Barbarians. The weakness of the central imperial power, at this time, led Gallo-Roman leaders to proclaim the independence of the short-lived Gallic Empire, which ended with the Battle of Châlons in 274, which saw Gaul reincorporated in the Roman Empire.
Nevertheless, the situation improved in the first half of the 4th century, which was a period of revival and prosperity for Roman Gaul. In 312, the emperor Constantin I converted to Christianity. Christians, persecuted until then, multiplied across the entire Roman Empire. But, from the second half of the 4th century, the Barbarian Invasions started again, and Germanic tribes, such as the Vandals, Suebi and Alans crossed the Rhine and settled in Gaul, Spain and other parts of the collapsing Roman Empire.
Francia.
At the end of the Antiquity period, ancient Gaul was divided into several Germanic kingdoms (Early Francia (North), Alamannia (North-East), Burgundia (East), Septimania (South), Visigothic Aquitania (South East)) and a remaining Gallo-Roman territory, known as the Kingdom of Syagrius (West). Simultaneously, Celtic Britons, fleeing the Anglo-Saxon invasion of "Britannia", settled the western part of Armorica (far West of Gaul). As a result, the Armorican peninsula was renamed Brittany, Celtic culture was revived and independent petty kingdoms arose in this region.
The pagan Franks, from whom the ancient name of "Francie" was derived, originally settled the northern part of Gaul, but under Clovis I conquered most of the other kingdoms in northern and central Gaul. In 498, Clovis I was the first Germanic conqueror after the fall of the Roman Empire to convert to Catholic Christianity, rather than Arianism; thus France was given the title "Eldest daughter of the Church" (') by the papacy, and the French kings would be called "the Most Christian Kings of France" (').
The Franks embraced the Christian Gallo-Roman heritage and ancient Gaul was eventually renamed "Francia" ("Land of the Franks"). The Germanic Franks adopted Romanic languages, except in northern Gaul where Roman settlements were less dense and where Germanic languages emerged. Clovis made Paris his capital and established the Merovingian dynasty, but his kingdom would not survive his death. The Franks treated land purely as a private possession and divided it among their heirs, so four kingdoms emerged from Clovis's: Paris, Orléans, Soissons, and Rheims. The last Merovingian kings, sometimes referred as "Rois fainéants" ("lazy kings"), effectively lost power to their mayors of the palace. One mayor of the palace, Charles Martel, defeated a Muslim invasion force from Hispania at the Battle of Tours (732) and earned respect and power within the Frankish kingdoms. His son, Pepin the Short, eventually seized the crown of Francia from the weakened Merovingians and founded the Carolingian dynasty. Pepin's son, Charlemagne, reunited the Frankish kingdoms and built a vast empire across Western and Central Europe.
Proclaimed Holy Roman Emperor by Pope Leo III and thus establishing in earnest the French government's longtime historical association with the Roman Catholic Church, Charlemagne tried to revive the Western Roman Empire and its cultural grandeur, from his Palace of Aachen. The efficient administration of this immense empire was ensured by high-level civil servants, carrying the, then non-hereditary, titles of counts (in charge of a County), marquis (in charge of a March), dukes (military commanders), etc.
Charlemagne's son, Louis I (emperor 814–840), kept the empire united; however, this Carolingian Empire would not survive his death. In 843, under the Treaty of Verdun, the empire was divided between Louis' three sons, with East Francia going to Louis the German, Middle Francia to Lothair I, and West Francia to Charles the Bald. Western Francia approximated the area occupied by, and was the precursor, to modern France.
During the course of the 9th and 10th centuries, continually threatened by Viking invasions, France became a very decentralised state: the nobility's titles and lands became hereditary, and the authority of the king became more religious than secular and thus was less effective and constantly challenged by powerful noblemen. Thus was established feudalism in France. Over time, some of the king's vassals would grow so powerful that they often posed a threat to the king. For example, after the Battle of Hastings in 1066, the Duke of Normandy added "King of England" to his titles, becoming both the vassal to (as Duke of Normandy) and the equal of (as king of England) to the king of France.
Kingdom of France.
The Carolingian dynasty ruled France until 987, when Hugh Capet, Duke of France and Count of Paris, was crowned King of the Franks. His descendants the Capetians, the House of Valois, and the House of Bourbon progressively unified the country through wars and dynastic inheritance into the Kingdom of France, which was fully declared in 1190 by Philip II Augustus. French knights took an active part in many of the Crusades that were fought between 1095 and 1291 to restore Christian control over the Holy Land. Crusaders were so predominately French that the word "crusader" in the Arabic language is simply known as "" or "The Franks" and Old French became the "lingua franca" of the Kingdom of Jerusalem.
The Albigensian Crusade was launched in 1209 to eliminate the heretical Cathars in the south-western area of modern-day France. In the end, the Cathars were exterminated and the autonomous County of Toulouse was annexed into the kingdom of France. Later Kings expanded their territory to cover over half of modern continental France, including most of the North, Centre and West of France. Meanwhile, the royal authority became more and more assertive, centred around a hierarchically conceived society distinguishing nobility, clergy, and commoners.
Charles IV (The Fair) died without an heir in 1328. Under the rules of the Salic law adopted in 1316, the crown of France could not pass to a woman nor could the line of kinship pass through the female line. Accordingly, the crown passed to Philip of Valois, a cousin of Charles, rather than through the female line to Charles' nephew, Edward, who would soon become Edward III of England. During the reign of Philip of Valois, the French monarchy reached the height of its medieval power.
However, Philip's seat on the throne was contested by Edward III of England and in 1337, on the eve of the first wave of the Black Death, England and France went to war in what would become known as the Hundred Years' War. The exact boundaries changed greatly with time, but French landholdings of the English Kings remained extensive for decades.
With charismatic leaders, such as Joan of Arc and La Hire, strong French counterattacks won back all English continental territories, except Calais, which was captured in 1558 by the French. Like the rest of Europe, France was struck by the Black Death. Around 1340, France had a population of approximately 17 million, which by the end of the pandemic had declined by about one-half.
The French Renaissance saw a long set of wars, known as the Great Italian Wars, between the Kingdom of France and the powerful Holy Roman Empire. It also saw the first standardization of the French language, which would become the official language of France and the language of Europe's aristocracy. French explorers, such as Jacques Cartier or Samuel de Champlain, claimed lands in the Americas for France, paving the way for the expansion of the First French colonial empire.
The rise of Protestantism in Europe led France to a civil war known as the French Wars of Religion, where, in the most notorious incident, thousands of Huguenots were murdered in the St. Bartholomew's Day massacre of 1572. The Wars of Religion were ended by Henry IV's Edict of Nantes, which granted some freedom of religion to the Huguenots. Henry IV was later murdered by a Catholic fanatic and Huguenot rebellions persisted until the 18th century.
Under Louis XIII, the energetic actions of Cardinal Richelieu reinforced the centralization of the state, the royal power and French dominance in Europe, foreshadowing the reign of Louis XIV. During Louis XIV's minority and the regency of Queen Anne and Cardinal Mazarin, a period of trouble known as the Fronde occurred in France, which was at that time at war with Spain. This rebellion was driven by the great feudal lords and sovereign courts as a reaction to the rise of royal power in France.
The monarchy reached its peak during the 17th century and the reign of Louis XIV. By turning powerful feudal lords into courtiers at the Palace of Versailles, Louis XIV's personal power became unchallenged. Remembered for his numerous wars, he made France the leading European power of the time. At this time, France possessed the largest population in Europe (see Demographics of France) and had tremendous influence over European politics, economy, and culture. French became the most-used language in diplomacy, science, literature and international affairs, and remained so until the 20th century. In addition, France obtained many overseas possessions in the Americas, Africa and Asia. Louis XIV also revoked the Edict of Nantes, forcing thousands of Huguenots to exile.
Under Louis XV, France lost New France and most of its Indian possessions after its defeat in the Seven Years' War, which ended in 1763. Its continental territory kept growing, however, with notable acquisitions such as Lorraine (1766) and Corsica (1770). An unpopular king, Louis XV's weak rule, his ill-advised financial, political and military decisions, and his debauchery discredited the monarchy and arguably led to the French Revolution 15 years after his death.
Louis XVI, Louis XV's grandson, actively supported the Americans, who were seeking their independence from Great Britain (realized in the 1783 Treaty of Paris). The example of the American Revolution and the financial crisis which followed France's involvement in the war were two of the many contributing factors to the French Revolution.
Much of the Enlightenment occurred in French intellectual circles, and major scientific breakthroughs and inventions, such as the discovery of oxygen (1778) and the first hot air balloon carrying passengers (1783), were achieved by French scientists in the 18th century. Famous French explorers, such as Bougainville and Lapérouse, took part in the voyages of scientific exploration through maritime expeditions around the globe. The Enlightenment philosophy, in which reason is advocated as the primary source for legitimacy and authority, undermined the power of and support for the monarchy and helped pave the way for the French Revolution.
Republics and Empires.
After the storming of the Bastille on 14 July 1789, the absolute monarchy was abolished and France became a constitutional monarchy. Through the Declaration of the Rights of Man and of the Citizen, France established fundamental rights for French citizens and all men without exception. The Declaration affirms "the natural and imprescriptible rights of man" to "liberty, property, security and resistance to oppression". It called for the destruction of aristocratic privileges (such as exemptions from taxation) and proclaimed freedom and equal rights for all men, as well as access to public office based on talent rather than birth. The monarchy was restricted, and all citizens were to have the right to take part in the legislative process. Freedom of speech and press were declared, and arbitrary arrests outlawed. The Declaration also asserted the principles of popular sovereignty, in contrast to the divine right of kings that characterized the French monarchy, and social equality among citizens, eliminating the privileges of the nobility and clergy.
While Louis XVI, as a constitutional king, enjoyed broad popularity among the population, his disastrous flight to Varennes seemed to justify the rumors that the king tied his hopes of political salvation to the dubious prospects of foreign invasion. The credibility of the king was deeply undermined and the abolition of the monarchy and the establishment of a republic became an ever increasing possibility.
As European monarchies gathered against the new régime, to restore the French absolute monarchy, the Duke of Brunswick, commanding general of the Austro–Prussian Army, issued a Manifesto, in which he threatened the destruction of Paris if any harm should come to the king or his family. The foreign threat exacerbated France's political turmoil and deepened the passion and sense of urgency among the various factions and war was declared against Austria the 20 April 1792. Mob violences occurred during the insurrection of the 10 August 1792 and the following month. As a result of the spike in public violence and the political instability of the constitutional monarchy, the Republic was proclaimed on 22 September 1792.
Louis XVI (and later his wife Marie Antoinette) was convicted of treason and guillotined in 1793. Facing increasing pressures from European monarchies, internal guerrilla wars and counterrevolutions (like the War in the Vendée or the Chouannerie), the young Republic fell into the Reign of Terror. Between 1793 and 1794, 16,000 to 40,000 persons were executed. In Western France, the civil war between the "Bleus" (the "Blues", supporters of the Revolution) and the "Blancs" (the "Whites", supporters of the Monarchy) last from 1793 to 1796 and cost around 450,000 lives (200,000 "Patriotes" and 250,000 "Vendéens"). Both foreign armies and French counterrevolutionnaries were crushed and the French Republic survived. Furthermore, the French Republic extended greatly its boundaries and established "Sister Republics" in the surrounding countries. As the threat of a foreign invasion receded and that France became mostly pacified, the Thermidorian Reaction put an end to the Terror and to Robespierre's dictature. The abolition of slavery and the male universal suffrage, enacted during this radical phase of the revolution, were cancelled by subsequent governments.
After a short-lived governmental scheme, Napoleon Bonaparte seized control of the Republic in 1799 and was appointed First Consul and later Emperor of the French Empire (1804–1814/1815). As a continuation of the wars sparked by the European monarchies against the French Republic, changing sets of European Coalitions declared wars to Napoleon's French Empire. His armies conquered most of continental Europe, while members of the Bonaparte family were appointed as monarchs in some of the newly established kingdoms. These victories led to the worldwide expansion of French revolutionary ideals and reforms, such as the Metric system, the Napoleonic Code or the Declaration of the Rights of Man and of the Citizen. After the catastrophic Russian campaign, Napoleon was finally defeated and the Bourbon monarchy restored. About a million Frenchmen died during the Napoleonic Wars.
After his brief return from exile, Napoleon was finally defeated in 1815 at the Battle of Waterloo, the monarchy was re-established (1815–1830), with new constitutional limitations. The discredited Bourbon dynasty was overthrown by the civil uprising of 1830, which established the constitutional July Monarchy, which lasted until 1848, when the French Second Republic was proclaimed, in the wake of the 1848 European revolutions. The abolition of slavery and the male universal suffrage, both briefly enacted during the French Revolution were finally re-enacted in 1848. In 1852, the president of the French Republic Louis-Napoléon Bonaparte, Napoleon I’s nephew, was proclaimed emperor of the second Empire, as Napoleon III. He multiplied French interventions abroad, especially in Crimea, in Mexico and Italy, which resulted in the annexation of Savoy and Nice. Napoleon III was eventually unseated following defeat in the Franco-Prussian war of 1870 and his regime was replaced by the Third Republic.
France had colonial possessions, in various forms, since the beginning of the 17th century to the 18th century. But in the 19th and 20th centuries, its global overseas colonial empire extended greatly and culminated as the second largest in the world behind the British Empire. At its peak, between 1919 and 1939, the second French colonial empire extended over 12,347,000 square kilometres (4,767,000 sq mi) of land. Including metropolitan France, the total area of land under French sovereignty reached 12,898,000 square kilometres (4,980,000 sq mi) in the 1920s and 1930s, which is 8.6% of the world's land area.
France was a member of the Triple Entente when World War I broke out. A small part of Northern France was occupied, but France and its allies eventually emerged victorious against the Central Powers, at a tremendous human and material cost: the First World War left 1.4 million French soldiers dead, 4.29% of its population The interbellum phase was marked by intense international tensions an a variety of social reforms introduced by the Popular Front government (Annual leave, working time reduction, women in Government among others). Following the German "Blitzkrieg" campaign in World War II, metropolitan France was divided in an occupation zone in the north and Vichy France, a newly established authoritarian regime collaborating with Germany, in the south. The Allies and the French Resistance eventually emerged victorious from the Axis powers and French sovereignty was restored.
The Fourth Republic was established after World War II and saw spectacular economic growth ("les Trente Glorieuses"). Suffrage was extended to women in 1944. France was one of the founding members of the NATO (1949), which was the Western counterpart of the Warsaw Pact system of collective defence. France attempted to regain control of French Indochina but was defeated by the Viet Minh at the Battle of Dien Bien Phu in 1954. Only months later, France faced a new conflict in Algeria. The debate over whether or not to keep control of Algeria, then home to over one million European settlers, wracked the country and nearly led to civil war. In 1958, the weak and unstable Fourth Republic gave way to the Fifth Republic, which contained a strengthened Presidency. In the latter role, Charles de Gaulle managed to keep the country together while taking steps to end the war. The Algerian War was concluded with peace negotiations in 1962 that led to Algerian independence. France granted independence progressively to its colonies, the last one being Vanuatu in 1980. A vestige of the colonial empire are the French overseas departments and territories.
In the wake of a worldwide series of protests, the May 1968 revolt, although a political failure for the protesters, had an enormous social impact. In France, it is considered to be the watershed moment when a conservative moral ideal (religion, patriotism, respect for authority) shifted towards a more liberal moral ideal.
France has been at the forefront of the European Union member states seeking to exploit the momentum of monetary union to create a more unified and capable European Union political, defence, and security apparatus.
Geography.
Metropolitan France is situated mostly between latitudes 41° and 51° N (Dunkirk is just north of 51°), and longitudes 6° W and 10° E, on the western edge of Europe, and thus lies within the northern temperate zone
While Metropolitan France is located in Western Europe, the French Republic also has a number of territories in North America, the Caribbean, South America, the southern Indian Ocean, the Pacific Ocean, and Antarctica. These territories have varying forms of government ranging from overseas department to overseas collectivity. France's overseas departments and collectivities share land borders with Brazil, and Suriname (bordering French Guiana), and Sint Maarten (bordering Saint-Martin).
The European territory of France covers , having the largest area among European Union members. France possesses a wide variety of landscapes, from coastal plains in the north and west to mountain ranges of the Alps in the south-east, the Massif Central in the south-central and Pyrenees in the south-west.
At above sea level, the highest point in Western Europe, Mont Blanc, is situated in the Alps on the border between France and Italy. France also has extensive river systems such as the Seine, the Loire, the Garonne, and the Rhone, which divides the Massif Central from the Alps and flows into the Mediterranean Sea at the Camargue. Corsica lies off the Mediterranean coast.
France's total land area, with its overseas departments and territories (excluding Adélie Land), is , 0.45% of the total land area on Earth. However, France possesses the second-largest Exclusive Economic Zone (EEZ) in the world, covering , approximately 8% of the total surface of all the EEZs of the world, just behind the United States () and ahead of Australia ().

French Revolution
The French Revolution (; 1789–1799), was a period of radical social and political upheaval in France that had a major impact on France and throughout the rest of Europe. The absolute monarchy that had ruled France for centuries collapsed in three years. French society underwent an epic transformation, as feudal, aristocratic and religious privileges evaporated under a sustained assault from radical left-wing political groups, masses on the streets, and peasants in the countryside. Old ideas about tradition and hierarchy – of monarchy, aristocracy, and religious authority – were abruptly overthrown by new Enlightenment principles of equality, citizenship and inalienable rights.
The French Revolution began in 1789 with the convocation of the Estates-General in May. The first year of the Revolution saw members of the Third Estate proclaiming the Tennis Court Oath in June, the assault on the Bastille in July, the passage of the Declaration of the Rights of Man and of the Citizen in August, and an epic march on Versailles that forced the royal court back to Paris in October. The next few years were dominated by tensions between various liberal assemblies and a right-wing monarchy intent on thwarting major reforms.
A republic was proclaimed in September 1792 and King Louis XVI was executed the next year. External threats also played a dominant role in the development of the Revolution. The French Revolutionary Wars started in 1792 and ultimately featured spectacular French victories that facilitated the conquest of the Italian Peninsula, the Low Countries and most territories west of the Rhine – achievements that had eluded previous French governments for centuries.
Internally, popular sentiments radicalized the Revolution significantly, culminating in the rise of Maximilien Robespierre and the Jacobins and virtual dictatorship by the Committee of Public Safety during the Reign of Terror from 1793 until 1794 during which between 16,000 and 40,000 people were killed. After the fall of the Jacobins and the execution of Robespierre, the Directory assumed control of the French state in 1795 and held power until 1799, when it was replaced by the Consulate under Napoleon Bonaparte.
The modern era has unfolded in the shadow of the French Revolution. The growth of republics and liberal democracies, the spread of secularism, the development of modern ideologies, and the invention of total war all mark their birth during the Revolution. Subsequent events that can be traced to the Revolution include the Napoleonic Wars, two separate restorations of monarchy (Bourbon Restoration and July Monarchy), and two additional revolutions (1830 and 1848) as modern France took shape.
Causes.
Adherents of most historical models identify many of the same features of the "Ancien Régime" as being among the causes of the Revolution. Economic factors included hunger and malnutrition in the most destitute segments of the population, due to rising bread prices (from a normal 8 sous for a four-pound loaf to 12 sous by the end of 1789), after several years of poor grain harvests. Bad harvests (caused in part by extreme weather from El Niño along with volcanic activity at Laki and Grímsvötn in 1783–1784), rising food prices, and an inadequate transportation system that hindered the shipment of bulk foods from rural areas to large population centers contributed greatly to the destabilization of French society in the years leading up to the Revolution.
Another cause was the state's effective bankruptcy due to the enormous cost of previous wars, particularly the financial strain caused by French participation in the American Revolutionary War. The national debt amounted to some 1,000–2,000 million livres. The social burdens caused by war included the huge war debt, made worse by the loss of France's colonial possessions in North America and the growing commercial dominance of Great Britain. France's inefficient and antiquated financial system was unable to manage the national debt, something which was both partially caused and exacerbated by the burden of an inadequate system of taxation. To obtain new money to head off default on the government's loans, the king called an Assembly of Notables in 1787.
Meanwhile, the royal court at Versailles was seen as being isolated from, and indifferent to, the hardships of the lower classes. While in theory King Louis XVI was an absolute monarch, in practice he was often indecisive and known to back down when faced with strong opposition. While he did reduce government expenditures, opponents in the parlements successfully thwarted his attempts at enacting much needed reforms. Those who were opposed to Louis' policies further undermined royal authority by distributing pamphlets (often reporting false or exaggerated information) that criticized the government and its officials, stirring up public opinion against the monarchy.
Many other factors involved resentments and aspirations given focus by the rise of Enlightenment ideals. These included resentment of royal absolutism; resentment by peasants, laborers and the bourgeoisie toward the traditional seigneurial privileges possessed by the nobility; resentment of the Church's influence over public policy and institutions; aspirations for freedom of religion; resentment of aristocratic bishops by the poorer rural clergy; aspirations for social, political and economic equality, and (especially as the Revolution progressed) republicanism; hatred of Queen Marie-Antoinette, who was falsely accused of being a spendthrift and an Austrian spy; and anger toward the King for firing finance minister Jacques Necker, among others, who were popularly seen as representatives of the people.
Pre-revolution.
Financial crisis.
Louis XVI ascended to the throne amidst a financial crisis; the state was nearing bankruptcy and outlays outpaced income. This was because of France’s financial obligations stemming from involvement in the Seven Years War and its participation in the American Revolutionary War. In May 1776, finance minister Turgot was dismissed, after he failed to enact reforms. The next year, Jacques Necker, a foreigner, was appointed Comptroller-General of Finance. He could not be made an official minister because he was a Protestant.
Necker realized that the country's extremely regressive tax system subjected the lower classes to a heavy burden, while numerous exemptions existed for the nobility and clergy. He argued that the country could not be taxed higher; that tax exemptions for the nobility and clergy must be reduced; and proposed that borrowing more money would solve the country's fiscal shortages. Necker published a report to support this claim that underestimated the deficit by roughly 36 million livres, and proposed restricting the power of the "parlements".
This was not received well by the King's ministers, and Necker, hoping to bolster his position, argued to be made a minister. The King refused, Necker was fired, and Charles Alexandre de Calonne was appointed to the Comptrollership. Calonne initially spent liberally, but he quickly realized the critical financial situation and proposed a new tax code.
The proposal included a consistent land tax, which would include taxation of the nobility and clergy. Faced with opposition from the parlements, Calonne organised the summoning of the Assembly of Notables. But the Assembly failed to endorse Calonne's proposals and instead weakened his position through its criticism. In response, the King announced the calling of the Estates-General for May 1789, the first time the body had been summoned since 1614. This was a signal that the Bourbon monarchy was in a weakened state and subject to the demands of its people.
Estates-General of 1789.
The Estates-General was organized into three estates: the clergy, the nobility, and the rest of France. On the last occasion that the Estates-General had met, in 1614, each estate held one vote, and any two could override the third. The "Parlement" of Paris feared the government would attempt to gerrymander an assembly to rig the results. Thus, they required that the Estates be arranged as in 1614.
The 1614 rules differed from practices of local assemblies, where each member had one vote and third estate membership was doubled. For example, in the Dauphiné the provincial assembly agreed to double the number of members of the third estate, hold membership elections, and allow one vote per member, rather than one vote per estate.
The "Committee of Thirty," a body of liberal Parisians, began to agitate against voting by estate. This group, largely composed of the wealthy, argued for the Estates-General to assume the voting mechanisms of Dauphiné. They argued that ancient precedent was not sufficient, because "the people were sovereign." Necker convened a Second Assembly of Notables, which rejected the notion of double representation by a vote of 111 to 333. The King, however, agreed to the proposition on 27 December; but he left discussion of the weight of each vote to the Estates-General itself.
Elections were held in the spring of 1789; suffrage requirements for the Third Estate were for French-born or naturalised males only, at least 25 years of age, who resided where the vote was to take place and who paid taxes.
Assemblée Nationale (French)
Strong turnout produced 1,201 delegates, including: "291 nobles, 300 clergy, and 610 members of the Third Estate." To lead delegates, "Books of grievances" ("cahiers de doléances") were compiled to list problems. The books articulated ideas which would have seemed radical only months before; however, most supported the monarchical system in general. Many assumed the Estates-General would approve future taxes, and Enlightenment ideals were relatively rare.
Pamphlets by liberal nobles and clergy became widespread after the lifting of press censorship. The Abbé Sieyès, a theorist and Catholic clergyman, argued the paramount importance of the Third Estate in the pamphlet "Qu'est-ce que le tiers état?" ("What is the Third Estate?"), published in January 1789. He asserted: "What is the Third Estate? Everything. What has it been until now in the political order? Nothing. What does it want to be? Something."
The Estates-General convened in the Grands Salles des Menus-Plaisirs in Versailles on 5 May 1789 and opened with a three-hour speech by Necker. The Third Estate demanded that the verification of deputies' credentials should be undertaken in common by all deputies, rather than each estate verifying the credentials of its own members internally; negotiations with the other estates failed to achieve this. The commoners appealed to the clergy who replied they required more time. Necker asserted that each estate verify credentials and "the king was to act as arbitrator." Negotiations with the other two estates to achieve this, however, were unsuccessful.
National Assembly (1789).
On 10 June 1789, Abbé Sieyès moved that the Third Estate, now meeting as the "Communes" (English: "Commons"), proceed with verification of its own powers and invite the other two estates to take part, but not to wait for them. They proceeded to do so two days later, completing the process on 17 June. Then they voted a measure far more radical, declaring themselves the National Assembly, an assembly not of the Estates but of "the People." They invited the other orders to join them, but made it clear they intended to conduct the nation's affairs with or without them.
In an attempt to keep control of the process and prevent the Assembly from convening, Louis XVI ordered the closure of the Salle des États where the Assembly met, making an excuse that the carpenters needed to prepare the hall for a royal speech in two days. Weather did not allow an outdoor meeting, so the Assembly moved their deliberations to a nearby indoor real tennis court, where they proceeded to swear the Tennis Court Oath (20 June 1789), under which they agreed not to separate until they had given France a constitution.
A majority of the representatives of the clergy soon joined them, as did 47 members of the nobility. By 27 June, the royal party had overtly given in, although the military began to arrive in large numbers around Paris and Versailles. Messages of support for the Assembly poured in from Paris and other French cities.
National Constituent Assembly (1789–1791).
Storming of the Bastille.
By this time, Necker had earned the enmity of many members of the French court for his overt manipulation of public opinion. Marie Antoinette, the King's younger brother the Comte d'Artois, and other conservative members of the King's privy council urged him to dismiss Necker as financial advisor. On 11 July 1789, after Necker published an inaccurate account of the government's debts and made it available to the public, the King fired him, and completely restructured the finance ministry at the same time.
Many Parisians presumed Louis's actions to be aimed against the Assembly and began open rebellion when they heard the news the next day. They were also afraid that arriving soldiers – mostly foreign mercenaries – had been summoned to shut down the National Constituent Assembly. The Assembly, meeting at Versailles, went into nonstop session to prevent another eviction from their meeting place. Paris was soon consumed by riots, chaos, and widespread looting. The mobs soon had the support of some of the French Guard, who were armed and trained soldiers.
On 14 July, the insurgents set their eyes on the large weapons and ammunition cache inside the Bastille fortress, which was also perceived to be a symbol of royal power. After several hours of combat, the prison fell that afternoon. Despite ordering a cease fire, which prevented a mutual massacre, Governor Marquis Bernard de Launay was beaten, stabbed and decapitated; his head was placed on a pike and paraded about the city. Although the fortress had held only seven prisoners (four forgers, two noblemen kept for immoral behavior, and a murder suspect), the Bastille served as a potent symbol of everything hated under the "Ancien Régime". Returning to the Hôtel de Ville (city hall), the mob accused the "prévôt des marchands" (roughly, mayor) Jacques de Flesselles of treachery and butchered him.
The King, alarmed by the violence, backed down, at least for the time being. The Marquis de la Fayette took up command of the National Guard at Paris. Jean-Sylvain Bailly, president of the Assembly at the time of the Tennis Court Oath, became the city's mayor under a new governmental structure known as the "commune". The King visited Paris, where, on 17 July he accepted a tricolore cockade, to cries of "Vive la Nation" ("Long live the Nation") and "Vive le Roi" ("Long live the King").
Necker was recalled to power, but his triumph was short-lived. An astute financier but a less astute politician, Necker overplayed his hand by demanding and obtaining a general amnesty, losing much of the people's favour.
As civil authority rapidly deteriorated, with random acts of violence and theft breaking out across the country, members of the nobility, fearing for their safety, fled to neighboring countries; many of these "émigrés", as they were called, funded counter-revolutionary causes within France and urged foreign monarchs to offer military support to a counter-revolution.
By late July, the spirit of popular sovereignty had spread throughout France. In rural areas, many commoners began to form militias and arm themselves against a foreign invasion: some attacked the châteaux of the nobility as part of a general agrarian insurrection known as ""la Grande Peur"" ("the Great Fear"). In addition, wild rumours and paranoia caused widespread unrest and civil disturbances that contributed to the collapse of law and order.
Working toward a constitution.
On 4 August 1789, the National Constituent Assembly abolished feudalism (although at that point there had been sufficient peasant revolts to almost end feudalism already), in what is known as the August Decrees, sweeping away both the seigneurial rights of the Second Estate and the tithes gathered by the First Estate. In the course of a few hours, nobles, clergy, towns, provinces, companies and cities lost their special privileges.
On 26 August 1789, the Assembly published the Declaration of the Rights of Man and of the Citizen, which comprised a statement of principles rather than a constitution with legal effect. The National Constituent Assembly functioned not only as a legislature, but also as a body to draft a new constitution.
Necker, Mounier, Lally-Tollendal and others argued unsuccessfully for a senate, with members appointed by the crown on the nomination of the people. The bulk of the nobles argued for an aristocratic upper house elected by the nobles. The popular party carried the day: France would have a single, unicameral assembly. The King retained only a "suspensive veto"; he could delay the implementation of a law, but not block it absolutely. The Assembly eventually replaced the historic provinces with 83 "départements," uniformly administered and roughly equal in area and population.
Amid the Assembly's preoccupation with constitutional affairs, the financial crisis had continued largely unaddressed, and the deficit had only increased. Honoré Mirabeau now led the move to address this matter, and the Assembly gave Necker complete financial dictatorship.
Women's March on Versailles.
Fueled by rumors of a reception for the King's bodyguards on 1 October 1789 at which the national cockade had been trampled upon, on 5 October 1789 crowds of women began to assemble at Parisian markets. The women first marched to the Hôtel de Ville, demanding that city officials address their concerns. The women were responding to the harsh economic situations they faced, especially bread shortages. They also demanded an end to royal efforts to block the National Assembly, and for the King and his administration to move to Paris as a sign of good faith in addressing the widespread poverty.
Getting unsatisfactory responses from city officials, as many as 7,000 women joined the march to Versailles, bringing with them cannons and a variety of smaller weapons. Twenty thousand National Guardsmen under the command of La Fayette responded to keep order, and members of the mob stormed the palace, killing several guards. La Fayette ultimately persuaded the king to accede to the demand of the crowd that the monarchy relocate to Paris.
On 6 October 1789, the King and the royal family moved from Versailles to Paris under the "protection" of the National Guards, thus legitimizing the National Assembly.
Revolution and the Church.
The Revolution caused a massive shift of power from the Roman Catholic Church to the state. Under the "Ancien Régime", the Church had been the largest single landowner in the country, owning about 10% of the land in the kingdom. The Church was exempt from paying taxes to the government, while it levied a tithe—a 10% tax on income, often collected in the form of crops—on the general population, which it then redistributed to the poor. The power and wealth of the Church was highly resented by some groups. A small minority of Protestants living in France, such as the Huguenots, wanted an anti-Catholic regime and revenge against the clergy who discriminated against them. Enlightenment thinkers such as Voltaire helped fuel this resentment by denigrating the Catholic Church and destabilizing the French monarchy. As historian John McManners argues, "In eighteenth-century France throne and altar were commonly spoken of as in close alliance; their simultaneous collapse ... would one day provide the final proof of their interdependence."
This resentment toward the Church weakened its power during the opening of the Estates General in May 1789. The Church composed the First Estate with 130,000 members of the clergy. When the National Assembly was later created in June 1789 by the Third Estate, the clergy voted to join them, which perpetuated the destruction of the Estates General as a governing body. The National Assembly began to enact social and economic reform. Legislation sanctioned on 4 August 1789 abolished the Church's authority to impose the tithe. In an attempt to address the financial crisis, the Assembly declared, on 2 November 1789, that the property of the Church was "at the disposal of the nation." They used this property to back a new currency, the assignats. Thus, the nation had now also taken on the responsibility of the Church, which included paying the clergy and caring for the poor, the sick and the orphaned. In December, the Assembly began to sell the lands to the highest bidder to raise revenue, effectively decreasing the value of the assignats by 25% in two years. In autumn 1789, legislation abolished monastic vows and on 13 February 1790 all religious orders were dissolved. Monks and nuns were encouraged to return to private life and a small percentage did eventually marry.
The Civil Constitution of the Clergy, passed on 12 July 1790, turned the remaining clergy into employees of the state. This established an election system for parish priests and bishops and set a pay rate for the clergy. Many Catholics objected to the election system because it effectively denied the authority of the Pope in Rome over the French Church. Eventually, in November 1790, the National Assembly began to require an oath of loyalty to the Civil Constitution from all the members of the clergy. This led to a schism between those clergy who swore the required oath and accepted the new arrangement and those who remained loyal to the Pope. Overall, 24% of the clergy nationwide took the oath. Widespread refusal led to legislation against the clergy, "forcing them into exile, deporting them forcibly, or executing them as traitors." Pope Pius VI never accepted the Civil Constitution of the Clergy, further isolating the Church in France. During the Reign of Terror, extreme efforts of de-Christianization ensued, including the imprisonment and massacre of priests and destruction of churches and religious images throughout France. An effort was made to replace the Catholic Church altogether, with civic festivals replacing religious ones. The establishment of the Cult of Reason was the final step of radical de-Christianization. These events led to a widespread disillusionment with the Revolution and to counter-rebellions across France. Locals often resisted de-Christianization by attacking revolutionary agents and hiding members of the clergy who were being hunted. Eventually, Robespierre and the Committee of Public Safety were forced to denounce the campaign, replacing the Cult of Reason with the deist but still non-Christian Cult of the Supreme Being. The Concordat of 1801 between Napoleon and the Church ended the de-Christianization period and established the rules for a relationship between the Catholic Church and the French State that lasted until it was abrogated by the Third Republic via the separation of church and state on 11 December 1905. The persecution of the Church led to a counter-revolution known as the Revolt in the Vendée, whose suppression is considered by some to be the first modern genocide.
Intrigues and radicalism.
Factions within the Assembly began to clarify. The aristocrat Jacques Antoine Marie de Cazalès and the abbé Jean-Sifrein Maury led what would become known as the right wing, the opposition to revolution (this party sat on the right-hand side of the Assembly). The "Royalist democrats" or "monarchiens", allied with Necker, inclined toward organising France along lines similar to the British constitutional model; they included Jean Joseph Mounier, the Comte de Lally-Tollendal, the comte de Clermont-Tonnerre, and Pierre Victor Malouet, comte de Virieu.
The "National Party", representing the centre or centre-left of the assembly, included Honoré Mirabeau, La Fayette, and Bailly; while Adrien Duport, Barnave and Alexandre Lameth represented somewhat more extreme views. Almost alone in his radicalism on the left was the Arras lawyer Maximilien Robespierre. Abbé Sieyès led in proposing legislation in this period and successfully forged consensus for some time between the political centre and the left. In Paris, various committees, the mayor, the assembly of representatives, and the individual districts each claimed authority independent of the others. The increasingly middle-class National Guard under La Fayette also slowly emerged as a power in its own right, as did other self-generated assemblies.
The Assembly abolished the symbolic paraphernalia of the "Ancien Régime"— armorial bearings, liveries, etc. – which further alienated the more conservative nobles, and added to the ranks of the "émigrés". On 14 July 1790, and for several days following, crowds in the Champ de Mars celebrated the anniversary of the fall of the Bastille with the "Fête de la Fédération"; Talleyrand performed a mass; participants swore an oath of "fidelity to the nation, the law, and the king"; the King and the royal family actively participated.
The electors had originally chosen the members of the Estates-General to serve for a single year. However, by the terms of the Tennis Court Oath, the "communes" had bound themselves to meet continuously until France had a constitution. Right-wing elements now argued for a new election, but Mirabeau prevailed, asserting that the status of the assembly had fundamentally changed, and that no new election should take place before completing the constitution.
In late 1790, the French army was in considerable disarray. The military officer corps was largely composed of noblemen, who found it increasingly difficult to maintain order within the ranks. In some cases, soldiers (drawn from the lower classes) had turned against their aristocratic commanders and attacked them. At Nancy, General Bouillé successfully put down one such rebellion, only to be accused of being anti-revolutionary for doing so. This and other such incidents spurred a mass desertion as more and more officers defected to other countries, leaving a dearth of experienced leadership within the army.
This period also saw the rise of the political "clubs" in French politics. Foremost among these was the Jacobin Club; 152 members had affiliated with the Jacobins by 10 August 1790. The Jacobin Society began as a broad, general organization for political debate, but as it grew in members, various factions developed with widely differing views. Several of these fractions broke off to form their own clubs, such as the Club of '89.
Meanwhile, the Assembly continued to work on developing a constitution. A new judicial organisation made all magistracies temporary and independent of the throne. The legislators abolished hereditary offices, except for the monarchy itself. Jury trials started for criminal cases. The King would have the unique power to propose war, with the legislature then deciding whether to declare war. The Assembly abolished all internal trade barriers and suppressed guilds, masterships, and workers' organisations: any individual gained the right to practice a trade through the purchase of a license; strikes became illegal.
In the winter of 1791, the Assembly considered, for the first time, legislation against the "émigrés". The debate pitted the safety of the Revolution against the liberty of individuals to leave. Mirabeau prevailed against the measure, which he referred to as "worthy of being placed in the code of Draco". But Mirabeau died on 2 April 1791 and, before the end of the year, the new Legislative Assembly adopted this draconian measure.
Royal flight to Varennes.
Louis XVI, egged on by Marie Antoinette and other members of his family, opposed the course of the Revolution, but rejected the potentially treacherous aid of the other monarchs of Europe. He cast his lot with General Bouillé, who condemned both the emigration and the Assembly, and promised him refuge and support in his camp at Montmédy. On the night of 20 June 1791, the royal family fled the Tuileries Palace dressed as servants, while their servants dressed as nobles.
However, late the next day, the King was recognised and arrested at Varennes (in the Meuse "département"). He and his family were brought back to Paris under guard, still dressed as servants. Pétion, Latour-Maubourg, and Antoine Pierre Joseph Marie Barnave, representing the Assembly, met the royal family at Épernay and returned with them. From this time, Barnave became a counselor and supporter of the royal family. When they returned to Paris, the crowd greeted them in silence. The Assembly provisionally suspended the King. He and Queen Marie Antoinette remained held under guard.
Completing the constitution.
As most of the Assembly still favoured a constitutional monarchy rather than a republic, the various groups reached a compromise which left Louis XVI as little more than a figurehead: he was forced to swear an oath to the constitution, and a decree declared that retracting the oath, heading an army for the purpose of making war upon the nation, or permitting anyone to do so in his name would amount to abdication.
However, Jacques Pierre Brissot drafted a petition, insisting that in the eyes of the nation Louis XVI was deposed since his flight. An immense crowd gathered in the Champ de Mars to sign the petition. Georges Danton and Camille Desmoulins gave fiery speeches. The Assembly called for the municipal authorities to "preserve public order". The National Guard under La Fayette's command confronted the crowd. The soldiers responded to a barrage of stones by firing into the crowd, killing between 13 and 50 people.
In the wake of this massacre the authorities closed many of the patriotic clubs, as well as radical newspapers such as Jean-Paul Marat's "L'Ami du Peuple". Danton fled to England; Desmoulins and Marat went into hiding.
Meanwhile, a new threat arose from abroad: Holy Roman Emperor Leopold II, Frederick William II of Prussia, and the King's brother Charles-Philippe, comte d'Artois, issued the Declaration of Pillnitz, which considered the cause of Louis XVI as their own, demanded his absolute liberty and implied an invasion of France on his behalf if the revolutionary authorities refused its conditions. The French people expressed no respect for the dictates of foreign monarchs, and the threat of force merely hastened their militarisation.
Even before the "Flight to Varennes", the Assembly members had determined to debar themselves from the legislature that would succeed them, the Legislative Assembly. They now gathered the various constitutional laws they had passed into a single constitution, showed remarkable strength in choosing not to use this as an occasion for major revisions, and submitted it to the recently restored Louis XVI, who accepted it, writing "I engage to maintain it at home, to defend it from all attacks from abroad, and to cause its execution by all the means it places at my disposal". The King addressed the Assembly and received enthusiastic applause from members and spectators. With this capstone, the National Constituent Assembly adjourned in a final session on 30 September 1791.
Mignet argued that the "constitution of 1791... was the work of the middle class, then the strongest; for, as is well known, the predominant force ever takes possession of institutions... In this constitution the people was the source of all powers, but it exercised none."
Legislative Assembly (1791–1792).
Failure of the constitutional monarchy.
Under the Constitution of 1791, France would function as a constitutional monarchy. The King had to share power with the elected Legislative Assembly, but he still retained his royal veto and the ability to select ministers. The Legislative Assembly first met on 1 October 1791, and degenerated into chaos less than a year later. In the words of the 1911 Encyclopædia Britannica: "In the attempt to govern, the Assembly failed altogether. It left behind an empty treasury, an undisciplined army and navy, and a people debauched by safe and successful riot." The Legislative Assembly consisted of about 165 Feuillants (constitutional monarchists) on the right, about 330 Girondists (liberal republicans) and Jacobins (radical revolutionaries) on the left, and about 250 deputies unaffiliated with either faction. Early on, the King vetoed legislation that threatened the "émigrés" with death and that decreed that every non-juring clergyman must take within eight days the civic oath mandated by the Civil Constitution of the Clergy. Over the course of a year, such disagreements would lead to a constitutional crisis.
Constitutional crisis.
On the night of 10 August 1792, insurgents and popular militias, supported by the revolutionary Paris Commune, assailed the Tuileries Palace and massacred the Swiss Guards who were assigned for the protection of the king. The royal family ended up prisoners and a rump session of the Legislative Assembly suspended the monarchy; little more than a third of the deputies were present, almost all of them Jacobins.
What remained of a national government depended on the support of the insurrectionary Commune. The Commune sent gangs into the prisons to try arbitrarily and butcher 1400 victims, and addressed a circular letter to the other cities of France inviting them to follow this example. The Assembly could offer only feeble resistance. This situation persisted until the Convention, elected by universal male suffrage and charged with writing a new constitution, met on 20 September 1792 and became the new "de facto" government of France. The next day it abolished the monarchy and declared a republic. The following day – 22 September 1792, the first morning of the new Republic – was later retroactively adopted as the beginning of Year One of the French Republican Calendar.
War and Counter-Revolution (1792–1797).
The politics of the period inevitably drove France towards war with Austria and its allies. The King, many of the Feuillants, and the Girondins specifically wanted to wage war. The King (and many Feuillants with him) expected war would increase his personal popularity; he also foresaw an opportunity to exploit any defeat: either result would make him stronger. The Girondins wanted to export the Revolution throughout Europe and, by extension, to defend the Revolution within France. The forces opposing war were much weaker. Barnave and his supporters among the Feuillants feared a war they thought France had little chance to win and which they feared might lead to greater radicalization of the revolution. On the other end of the political spectrum Robespierre opposed a war on two grounds, fearing that it would strengthen the monarchy and military at the expense of the revolution, and that it would incur the anger of ordinary people in Austria and elsewhere. The Austrian emperor Leopold II, brother of Marie Antoinette, may have wished to avoid war, but he died on 1 March 1792. France preemptively declared war on Austria (20 April 1792) and Prussia joined on the Austrian side a few weeks later. The invading Prussian army faced little resistance until checked at the Battle of Valmy (20 September 1792), and forced to withdraw.
The new-born Republic followed up on this success with a series of victories in Belgium and the Rhineland in the fall of 1792. The French armies defeated the Austrians at the Battle of Jemappes on 6 November, and had soon taken over most of the Austrian Netherlands. This brought them into conflict with Britain and the Dutch Republic, which wished to preserve the independence of the southern Netherlands from France. After the king's execution in January 1793, these powers, along with Spain and most other European states, joined the war against France. Almost immediately, French forces faced defeat on many fronts, and were driven out of their newly conquered territories in the spring of 1793. At the same time, the republican regime was forced to deal with rebellions against its authority in much of western and southern France. But the allies failed to take advantage of French disunity, and by the autumn of 1793 the republican regime had defeated most of the internal rebellions and halted the allied advance into France itself.
The stalemate was broken in the summer of 1794 with dramatic French victories. They defeated the allied army at the Battle of Fleurus, leading to a full Allied withdrawal from the Austrian Netherlands. They followed up by a campaign which swept the allies to the east bank of the Rhine and left the French, by the beginning of 1795, conquering Holland itself. The House of Orange was expelled and replaced by the Batavian Republic, a French satellite state. These victories led to the collapse of the coalition against France. Prussia, having effectively abandoned the coalition in the fall of 1794, made peace with revolutionary France at Basel in April 1795, and soon thereafter Spain, too, made peace with France. Of the major powers, only Britain and Austria remained at war with France.
It was during this time that "La Marseillaise" was first sung. Originally titled "Chant de guerre pour l'Armée du Rhin" ("War Song for the Army of the Rhine"), the song was written and composed by Claude Joseph Rouget de Lisle in 1792. It was adopted in 1795 as the nation's first anthem.
National Convention (1792–1795).
Execution of Louis XVI.
In the Brunswick Manifesto, the Imperial and Prussian armies threatened retaliation on the French population if it were to resist their advance or the reinstatement of the monarchy. This among other things made Louis appear to be conspiring with the enemies of France. On 17 January 1793 Louis was condemned to death for "conspiracy against the public liberty and the general safety" by a close majority in Convention: 361 voted to execute the king, 288 voted against, and another 72 voted to execute him subject to a variety of delaying conditions. The former Louis XVI, now simply named "Citoyen Louis Capet" (Citizen Louis Capet), was executed by guillotine on 21 January 1793 on the "Place de la Révolution", former "Place Louis XV", now called the Place de la Concorde. Royalty across Europe was horrified and many heretofore neutral countries soon joined the war against revolutionary France.
Economy.
When war went badly, prices rose and the "sans-culottes" — poor labourers and radical Jacobins – rioted; counter-revolutionary activities began in some regions. This encouraged the Jacobins to seize power through a parliamentary "coup", backed up by force effected by mobilising public support against the Girondist faction, and by utilising the mob power of the Parisian "sans-culottes". An alliance of Jacobin and "sans-culottes" elements thus became the effective centre of the new government. Policy became considerably more radical, as "The Law of the Maximum" set food prices and led to executions of offenders. 
This policy of price control was coeval with the Committee of Public Safety's rise to power and the Reign of Terror. The Committee first attempted to set the price for only a limited number of grain products but, by September 1793, it expanded the "maximum" to cover all foodstuffs and a long list of other goods. Widespread shortages and famine ensued. The Committee reacted by sending dragoons into the countryside to arrest farmers and seize crops. This temporarily solved the problem in Paris, but the rest of the country suffered. By the spring of 1794, forced collection of food was not sufficient to feed even Paris and the days of the Committee were numbered. When Robespierre went to the guillotine in July of that year the crowd jeered, "There goes the dirty maximum!"
Reign of Terror.
The Committee of Public Safety came under the control of Maximilien Robespierre, a lawyer, and the Jacobins unleashed the Reign of Terror (1793–1794). According to archival records, at least 16,594 people died under the guillotine or otherwise after accusations of counter-revolutionary activities. A number of historians note that as many as 40,000 accused prisoners may have been summarily executed without trial or died awaiting trial.
On 2 June 1793, Paris sections — encouraged by the "enragés" ("enraged ones") Jacques Roux and Jacques Hébert – took over the Convention, calling for administrative and political purges, a low fixed price for bread, and a limitation of the electoral franchise to "sans-culottes" alone. With the backing of the National Guard, they managed to persuade the Convention to arrest 31 Girondin leaders, including Jacques Pierre Brissot. Following these arrests, the Jacobins gained control of the Committee of Public Safety on 10 June, installing the "revolutionary dictatorship".
On 13 July, the assassination of Jean-Paul Marat — a Jacobin leader and journalist known for his bloodthirsty rhetoric — by Charlotte Corday, a Girondin, resulted in further increase of Jacobin political influence. Georges Danton, the leader of the August 1792 uprising against the King, undermined by several political reversals, was removed from the Committee and Robespierre, "the Incorruptible", became its most influential member as it moved to take radical measures against the Revolution's domestic and foreign enemies.
Meanwhile, on 24 June, the Convention adopted the first republican constitution of France, variously referred to as the French Constitution of 1793 or Constitution of the Year I. It was progressive and radical in several respects, in particular by establishing universal male suffrage. It was ratified by public referendum, but normal legal processes were suspended before it could take effect.
War in the Vendée.
In Vendée, peasants revolted against the French Revolutionary government in 1793. They resented the changes imposed on the Roman Catholic Church by the Civil Constitution of the Clergy (1790) and broke into open revolt in defiance of the Revolutionary government's military conscription. This became a guerrilla war, known as the War in the Vendée. North of the Loire, similar revolts were started by the so-called Chouans (royalist rebels).
Davies, Norman. "Europe: A history" Pimlico, (1997). p. 705
Other historians doubt the authenticity of this document and point out that the claims in it were patently false — there were in fact thousands of living Vendean prisoners, the revolt had been far from crushed, and the Convention had explicitly decreed that women, children and unarmed men were to be treated humanely. It has been hypothesized that if the letter is authentic, Westermann may have been attempting to exaggerate the intensity of his actions and his success, because he was eager to avoid being purged for his opposition to "sans-culotte" generals (he was later guillotined together with Danton's group).
The revolt and its suppression, including both combat casualties and massacres and executions on both sides, are thought to have taken between 117,000 and 250,000 lives (170,000 according to the latest estimates). Because of the extremely brutal forms that the Republican repression took in many places, certain historians such as Reynald Secher have called the event a "genocide". This description has become popular in the mass media, but has largely been rejected by mainstream scholars.
Facing local revolts and foreign invasions in both the East and West of the country, the most urgent government business was the war. On 17 August, the Convention voted for general conscription, the "levée en masse", which mobilized all citizens to serve as soldiers or suppliers in the war effort.
The National Convention subsequently enacted more legislation, voting on 9 September to establish "sans-culottes" paramilitary forces, "revolutionary armies", and to force farmers to surrender grain demanded by the government. On 17 September, the "Law of Suspects" was passed, which authorized the charging of counter-revolutionaries with "crimes against liberty." On 29 September, the Convention extended price limits from grain and bread to other household goods and established the Law of the Maximum, intended to prevent price gouging and supply food to the cities.
The guillotine as a symbol.
The guillotine became the symbol of a string of executions. Louis XVI had already been guillotined before the start of the terror; Queen Marie Antoinette, Barnave, Bailly, Brissot and other leading Girondins, Philippe Égalité (despite his vote for the death of the King), Madame Roland and many others were executed by guillotine. The Revolutionary Tribunal summarily condemned thousands of people to death by the guillotine, while mobs beat other victims to death.
At the peak of the terror, the slightest hint of counter-revolutionary thoughts or activities (or, as in the case of Jacques Hébert, revolutionary zeal exceeding that of those in power) could place one under suspicion, and trials did not always proceed according to contemporary standards of due process. Sometimes people died for their political opinions or actions, but many for little reason beyond mere suspicion, or because some others had a stake in getting rid of them. Most of the victims received an unceremonious trip to the guillotine in an open wooden cart (the tumbrel). In the rebellious provinces, the government representatives had unlimited authority and some engaged in extreme repressions and abuses. For example, Jean-Baptiste Carrier became notorious for the "Noyades" ("drownings") he organized in Nantes; his conduct was judged unacceptable even by the Jacobin government and he was recalled.
Another anti-clerical uprising was made possible by the installment of the Republican Calendar on 24 October 1793. Against Robespierre's concepts of Deism and Virtue, Hébert's (and Chaumette's) atheist movement initiated a religious campaign to dechristianize society. The climax was reached with the celebration of the flame of Reason in Notre Dame Cathedral on 10 November.
The Reign of Terror ultimately weakened the revolutionary government, while temporarily ending internal opposition. The Jacobins expanded the size of the army, and Carnot replaced many aristocratic officers with soldiers who had demonstrated their patriotism, if not their ability. The Republican army was able to throw back the Austrians, Prussians, British, and Spanish. At the end of 1793, the army began to prevail and revolts were defeated with ease. The Ventôse Decrees (February–March 1794) proposed the confiscation of the goods of exiles and opponents of the Revolution, and their redistribution to the needy. However this policy was never fully implemented.
In the spring of 1794, both extremist "enragés" such as Hébert and moderate Montagnard "indulgents" such as Danton were charged with counter-revolutionary activities, tried and guillotined. On 7 June Robespierre, who had previously condemned the "Cult of Reason", advocated a new state religion and recommended the Convention acknowledge the existence of the "Supreme Being".
Thermidorian Reaction.
On 27 July 1794, the Thermidorian Reaction led to the arrest and execution of Robespierre, Louis de Saint-Just, and other leading Jacobins. The new government was predominantly made up of Girondists who had survived the Terror, and after taking power, they took revenge as well by persecuting even those Jacobins who had helped to overthrow Robespierre, banning the Jacobin Club, and executing many of its former members in what was known as the White Terror.
In the wake of excesses of the Terror, the Convention approved the new "Constitution of the Year III" on 22 August 1795. A French plebiscite ratified the document, with about 1,057,000 votes for the constitution and 49,000 against. The results of the voting were announced on 23 September 1795, and the new constitution took effect on 27 September 1795.
The Constitutional Republic: The Directory (1795–1799).
The new constitution created the "Directoire" () and the first bicameral legislature in French history. The parliament consisted of two houses: the "Conseil des Cinq-Cents" (Council of the Five Hundred), with 500 representatives, and the "Conseil des Anciens" (Council of Elders), with 250 senators. Executive power went to five "directors," named annually by the "Conseil des Anciens" from a list submitted by the "Conseil des Cinq-Cents". Furthermore, the universal male suffrage of 1793 was replaced by limited suffrage based on property.
With the establishment of the Directory, contemporary observers might have assumed that the Revolution was finished. Citizens of the war-weary nation wanted stability, peace, and an end to conditions that at times bordered on chaos. Those who wished to restore the monarchy and the "Ancien Régime" by putting Louis XVIII on the throne, and those who would have renewed the Reign of Terror were insignificant in number. The possibility of foreign interference had vanished with the failure of the First Coalition. The earlier atrocities had made confidence or goodwill between parties impossible.
The same instinct of self-preservation which had led the members of the Convention to claim so large a part in the new legislature and the whole of the Directory impelled them to keep their predominance. However, many French citizens distrusted the Directory, and the directors could achieve their purposes only by extraordinary means. They habitually disregarded the terms of the constitution, and, even when the elections that they rigged went against them, the directors routinely used draconian police measures to quell dissent. Moreover, to prolong their power the directors were driven to rely on the military, which desired war and grew less and less civic-minded.
Other reasons influenced them in the direction of war. State finances during the earlier phases of the Revolution had been so thoroughly ruined that the government could not have met its expenses without the plunder and the tribute of foreign countries. If peace were made, the armies would return home and the directors would have to face the exasperation of the rank-and-file who had lost their livelihood, as well as the ambition of generals who could, in a moment, brush them aside. Barras and Rewbell were notoriously corrupt themselves and screened corruption in others. The patronage of the directors was ill-bestowed, and the general maladministration heightened their unpopularity.
The constitutional party in the legislature desired toleration of the nonjuring clergy, the repeal of the laws against the relatives of the émigrés, and some merciful discrimination toward the émigrés themselves. The directors baffled all such endeavours. On the other hand, the socialist conspiracy of Babeuf was easily quelled. Little was done to improve the finances, and the assignats continued to fall in value.
The new régime met opposition from remaining Jacobins and the royalists. The army suppressed riots and counter-revolutionary activities. In this way the army and its successful general, Napoleon Bonaparte eventually gained total power.
On 9 November 1799 (18 Brumaire of the Year VIII) Napoleon Bonaparte staged the "coup of 18 Brumaire" which installed the Consulate. This effectively led to Bonaparte's dictatorship and eventually (in 1804) to his proclamation as "Empereur" (emperor), which brought to a close the specifically republican phase of the French Revolution.
Symbolism in the French Revolution.
The French Revolution was a time of upheaval, especially towards traditional ideology, in almost every sense: the current monarch, King Louis XVI, was executed; the Catholic Church was all but abolished; a new calendar was created; and a new Republican government was established. In order to effectively illustrate the differences between the new Republic and the old regime, the leaders needed to implement a new set of symbols to be celebrated instead of the old religious and monarchical symbolism. To this end, symbols were borrowed from historic cultures and redefined, while those of the old regime were either destroyed or reattributed acceptable characteristics. These revised symbols were used to instill in the public a new sense of tradition and reverence for the Enlightenment and the Republic.
Fasces.
Fasces, likes many other symbols of the French Revolution, are Roman in origin. Fasces are a bundle of birch rods containing an axe. In Roman times, the fasces symbolized the power of magistrates who could order the beating of a criminal, representing union and accord with the Roman Republic. The French Republic continued this Roman symbol to represent state power, justice, and unity.
During the French Revolution the fasces image is seen in conjunction with many other symbols. This is seen with many emblems of the French Revolution. Though seen throughout the French Revolution, perhaps the most well known French reincarnation of the fasces is the Fasces surmounted by a Phrygian cap. This image has no display of an axe or a strong central state; rather, it symbolizes the power of the liberated people by placing the Liberty Cap on top of the classical symbol of power.
Liberty cap.
The Liberty cap, also known as the Phrygian cap, or pileus, is a brimless, felt cap that is conical in shape with the tip pulled forward. The cap was originally worn by ancient Romans and Greeks. The cap implies ennobling effects, as seen in its association with Homer’s Ulysses and the mythical twins, Castor and Pollux. The emblem’s popularity during the French Revolution is due in part to its importance in ancient Rome: its use alludes to the Roman ritual of manumission of slaves, in which a freed slave receives the bonnet as a symbol of his newfound liberty. The Roman tribune Lucius Appuleius Saturninus incited the slaves to insurrection by displaying a pileus as if it were a standard. 
The pileus cap is often red in color. This type of cap was worn by revolutionaries at the fall of the Bastille. According to the Revolutions de Paris, it became "the symbol of the liberation from all servitudes, the sign for unification of all the enemies of despotism." The pileus competed with the Phrygian cap, a similar cap that covered the ears and the nape of the neck, for popularity. The Phrygian cap eventually supplanted the pileus and usurped its symbolism, becoming synonymous with republican liberty.
Liberty Tree.
The Liberty Tree, officially adopted in 1792, is a symbol of the everlasting Republic, national freedom, and political revolution. It has historic roots in revolutionary France as well as America, as a symbol that was shared by the two nascent republics. The tree was chosen as a symbol of the French Revolution because it is a symbol of fertility in French folklore, which provided a simple transition from revering it for one reason to another. The American colonies also used the idea of a Liberty Tree to celebrate their own acts of insurrection against the British, starting with the Stamp Act riot in 1765. 
The riot culminated in the hanging in effigy of two Stamp Act politicians on a large elm tree. The elm tree began to be celebrated as a symbol of Liberty in the American colonies. It was adopted as a symbol that needed to be living and growing, along with the Republic. To that end, the tree is portrayed as a sapling, usually of an oak tree in French interpretation. The Liberty Tree serves as a constant celebration of the spirit of political freedom.
Hercules.
The symbol of Hercules was first adopted by the Old Regime to represent the monarchy. Hercules was an ancient Greek hero who symbolized strength and power. The symbol was used to represent the sovereign authority of the King over France during the reign of the Bourbon monarchs. However, the monarchy was not the only ruling power in French history to use the symbol of Hercules to declare its power.
During the Revolution, the symbol of Hercules was revived to represent nascent revolutionary ideals. The first use of Hercules as a revolutionary symbol was during a festival celebrating the National Assembly’s victory over federalism on 10 August 1793. This Festival of Unity consisted of four stations around Paris which featured symbols representing major events of the Revolution which embodied revolutionary ideals of liberty, unity, and power. 
The statue of Hercules, placed at the station commemorating the fall of Louis XVI, symbolized the power of the French people over their former oppressors. The statue’s foot was placed on the throat of the Hydra, which represented the tyranny of federalism which the new Republic had vanquished. In one hand, the statue grasped a club, a symbol of power, while in the other grasping the fasces which symbolized the unity of the French people. The image of Hercules assisted the new Republic in establishing its new Republican moral system. Hercules thus evolved from a symbol of the sovereignty of the monarch into a symbol of the new sovereign authority in France: the French people. 
This transition was made easily for two reasons. First, because Hercules was a famous mythological figure, and had previously been used by the monarchy, he was easily recognized by educated French observers. It was not necessary for the revolutionary government to educate the French people on the background of the symbol. Additionally, Hercules recalled the classical age of the Greeks and the Romans, a period which the revolutionaries identified with republican and democratic ideals. These connotations made Hercules an easy choice to represent the powerful new sovereign people of France.
During the more radical phase of the Revolution from 1793 to 1794, the usage and depiction of Hercules changed. These changes to the symbol were due to revolutionary leaders believing the symbol was inciting violence among the common citizens. The triumphant battles of Hercules and the overcoming of enemies of the Republic became less prominent. In discussions over what symbol to use for the Seal of the Republic, the image of Hercules was considered but eventually ruled out in favor of Marianne. 
Hercules was on the coin of the Republic. However, this Hercules was not the same image as that of the pre-Terror phases of the Revolution. The new image of Hercules was more domesticated. He appeared more paternal, older, and wiser, rather than the warrior-like images in the early stages of the French Revolution. Unlike his 24 foot statue in the Festival of the Supreme Being, he was now the same size as Liberty and Equality. 
Also the language on the coin with Hercules was far different than the rhetoric of pre-revolutionary depictions. On the coins the words, "uniting Liberty and Equality" were used. This is opposed to the forceful language of early Revolutionary rhetoric and rhetoric of the Bourbon monarchy. By 1798, the Council of Ancients had discussed the "inevitable" change from the problematic image of Hercules, and Hercules was eventually phased out in favor of an even more docile image.
Role of women.
Women had no political rights in pre-Revolutionary France; they could not vote or hold any political office. They were considered "passive" citizens; forced to rely on men to determine what was best for them in the government. It was the men who defined these categories, and women were forced to accept male domination in the political sphere. 
The "Encyclopédie", published by a group of philosophers over the years 1751–1777, summarized French male beliefs of women. A woman was a "failed man," the fetus not fully developed in the womb. "Women’s testimony is in general light and subject to variation; this is why it is taken more seriously than that of men" as opposed to men, upon whom "Nature seems to have conferred… the right to govern." In general, "men are more capable than women of ably governing particular matters". 
Instead, women were taught to be committed to their husbands and "all his interests… show attention and care… sincere and discreet zeal for his salvation." A woman’s education often consisted of learning to be a good wife and mother; as a result women were not supposed to be involved in the political sphere, as the limit of their influence was the raising of future citizens.
When the Revolution opened, some women struck forcefully, using the volatile political climate to assert their active natures. In the time of the Revolution, women could not be kept out of the political sphere; they swore oaths of loyalty, "solemn declarations of patriotic allegiance, affirmations of the political responsibilities of citizenship." Throughout the Revolution, women such as Pauline Léon and her Society of Revolutionary Republican Women fought for the right to bear arms, used armed force and rioted.
Even before Léon, some liberals had advocated equal rights for women including women's suffrage. Nicolas de Condorcet was especially noted for his advocacy, in his articles published in the "Journal de la Société de 1789", and by publishing "De l'admission des femmes au droit de cité" ("For the Admission to the Rights of Citizenship For Women") in 1790.
Feminist agitation.
The March to Versailles is but one example of feminist militant activism during the French Revolution. While largely left out of the thrust for increasing rights of citizens, as the question was left indeterminate in the Declaration of the Rights of Man, activists such as Pauline Léon and Théroigne de Méricourt agitated for full citizenship for women. Women were, nonetheless, "denied political rights of ‘active citizenship’ (1791) and democratic citizenship (1793)."
Pauline Léon, on 6 March 1792, submitted a petition signed by 319 women to the National Assembly requesting permission to form a garde national in order to defend Paris in case of military invasion. Léon requested permission be granted to women to arm themselves with pikes, pistols, sabers and rifles, as well as the privilege of drilling under the French Guards. Her request was denied. Later in 1792, Théroigne de Méricourt made a call for the creation of "legions of amazons" in order to protect the revolution. As part of her call, she claimed that the right to bear arm would transform women into citizens.
On 20 June 1792 a number of armed women took part in a procession that "passed through the halls of the Legislative Assembly, into the Tuilleries Gardens, and then through the King’s residence." Militant women also assumed a special role in the funeral of Marat, following his murder on 13 July 1793. As part of the funeral procession, they carried the bathtub in which Marat had been murdered as well as a shirt stained with Marat’s blood.
The most radical militant feminist activism was practiced by the Society of Revolutionary Republican Women, which was founded by Léon and her colleague, Claire Lacombe on 10 May 1793. The goal of the club was "to deliberate on the means of frustrating the projects of the enemies of the Republic." Up to 180 women attended the meetings of the Society. Of special interest to the Society was "combating hoarding grain and other staples and inflation."
Later, on 20 May 1793, women were at the fore of a crowd that demanded "bread and the Constitution of 1793." When their cries went unnoticed, the women went on a rampage, "sacking shops, seizing grain and kidnapping officials."
Most of these outwardly activist women were punished for their actions. The kind of punishment received during the Revolution included public denouncement, arrest, execution, or exile. Théroigne de Méricourt was arrested, publicly flogged and then spent the rest of her life sentenced to an insane asylum. Pauline Léon and Claire Lacombe were arrested, later released, and continued to receive ridicule and abuse for their activism. Many of the women of the Revolution were even publicly executed for "conspiring against the unity and the indivisibility of the Republic".
These are but a few examples of the militant feminism that was prevalent during the French Revolution. While little progress was made toward gender equality during the Revolution, the activism of French feminists was bold and particularly significant in Paris.
Women writers.
While some women chose a militant, and often violent, path, others chose to influence events through writing, publications, and meetings. Olympe de Gouges wrote a number of plays, short stories, and novels. Her publications emphasized that women and men are different, but this shouldn’t stop them from equality under the law. In her "Declaration on the Rights of Woman" she insisted that women deserved rights, especially in areas concerning them directly, such as divorce and recognition of illegitimate children.
De Gouges also expressed non-gender political views; even before the start of the terror, Olympe de Gouges addressed Robespierre using the pseudonym "Polyme" calling him the Revolution’s "infamy and shame." She warned of the Revolution’s building extremism saying that leaders were "preparing new shackles if French people’s liberty were to waver." Stating that she was willing to sacrifice herself by jumping into the Seine if Robespierre were to join her, de Gouges desperately attempted to grab the attention of the French citizenry and alert them to the dangers that Robespierre embodied. In addition to these bold writings, her defense of the king was one of the factors leading to her execution. An influential figure, one of her suggestions early in the Revolution, to have a voluntary, patriotic tax, was adopted by the National Convention in 1789.
Madame Roland (aka Manon or Marie Roland) was another important female activist. Her political focus was not specifically on women or their liberation. She focused on other aspects of the government, but was a feminist by virtue of the fact that she was a woman working to influence the world. Her personal letters to leaders of the Revolution influenced policy; in addition, she often hosted political gatherings of the Brissotins, a political group which allowed women to join. 
While limited by her gender, Madame Roland took it upon herself to spread Revolutionary ideology and spread word of events, as well as to assist in formulating the policies of her political allies. Though unable to directly write policies or carry them through to the government, Roland was able to influence her political allies and thus promote her political agenda. Roland attributed women’s lack of education to the public view that women were too weak or vain to be involved in the serious business of politics. She believed that it was this inferior education that turned them into foolish people, but women "could easily be concentrated and solidified upon objects of great significance" if given the chance. 
As she was led to the scaffold, Madame Roland shouted "O liberty! What crimes are committed in thy name!" Witnesses of her life and death, editors, and readers helped to finish her writings and several editions were published posthumously. While she did not focus on gender politics in her writings, by taking an active role in the tumultuous time of the Revolution, Roland took a stand for women of the time and proved they could take an intelligent active role in politics.
Though women did not gain the right to vote as a result of the Revolution, they still greatly expanded their political participation and involvement in governing. They set precedents for generations of feminists to come.
Counter-revolutionary women.
A major aspect of the French Revolution was the dechristianisation movement, a movement that many common people did not agree with. Especially for women living in rural areas of France, the demise of the Catholic Church meant a loss of normalcy. For instance, the ringing of Church bells resonating through the town called people to confession and was a symbol of unity for the community. With the onset of the dechristianisation campaign the Republic silenced these bells and sought simultaneously to silence the religious fervor of the majority Catholic population. 
When these revolutionary changes to the Church were implemented, it spawned a counter-revolutionary movement, particularly amongst women. Although some of these women embraced the political and social amendments of the Revolution, they opposed the dissolution of the Catholic Church and the formation of revolutionary cults like the Cult of the Supreme Being advocated by Robespierre. As Olwen Hufton argues, these women began to see themselves as the “defenders of faith”. They took it upon themselves to protect the Church from what they saw as a heretical change to their faith, enforced by revolutionaries.
Counter-revolutionary women resisted what they saw as the intrusion of the state into their lives. Economically, many peasant women refused to sell their goods for assignats because this form of currency was unstable and was backed by the sale of confiscated Church property. By far the most important issue to counter-revolutionary women was the passage and the enforcement of the Civil Constitution of the Clergy in 1790. In response to this measure, women in many areas began circulating anti-oath pamphlets and refused to attend masses held by priests who had sworn oaths of loyalty to the Republic. This diminished the social and political influence of the juring priests because they presided over smaller congregations and counter-revolutionary women did not seek them for baptisms, marriages or confession. Instead, they secretly hid nonjuring priests and attended clandestine traditional masses. These women continued to adhere to traditional practices such as Christian burials and naming their children after saints in spite of revolutionary decrees to the contrary.
It was this determined resistance to the Civil Constitution of the Clergy and the dechristianisation campaigns that played a major role in the re-emergence of the Catholic Church as a prominent social institution. In fact, Olwen Hufton notes about the Counter-Revolutionary women: “for it is her commitment to her religion which determines in the post-Thermidorean period the re-emergence of the Catholic Church…”. Although they struggled, these women were eventually vindicated in their bid to reestablish the Church and thereby also to reestablish traditional family life and social stability. This was seen in the Concordat of 1801, which formally reinstated the Catholic Church in France. This act came after years of failed attempts at dechristianisation or state-controlled religion, which were thwarted in part due to the resistance of devout counter-revolutionary women. After the upheaval of the revolutionary period, the reestablishment of the Church was seen by many people as a welcome return to normalcy.
Legacy.
The French Revolution has received enormous amounts of historical attention, both from the general public and from scholars and academics. The views of historians, in particular, have been characterized as falling along ideological lines, with disagreement over the significance and the major developments of the Revolution. Alexis de Tocqueville argued that the Revolution was a manifestation of a more prosperous middle class becoming conscious of its social importance. 
Other thinkers, like the conservative Edmund Burke, maintained that the Revolution was the product of a few conspiratorial individuals who brainwashed the masses into subverting the old order—a claim rooted in the belief that the revolutionaries had no legitimate complaints. Other historians, influenced by Marxist thinking, have emphasized the importance of the peasants and the urban workers in presenting the Revolution as a gigantic class struggle. In general, scholarship on the French Revolution initially studied the political ideas and developments of the era, but it has gradually shifted towards social history that analyzes the impact of the Revolution on individual lives.
Historians widely regard the Revolution as one of the most important events in human history, and the end of the early modern period, which started around 1500, is traditionally attributed to the onset of the French Revolution in 1789. The Revolution is, in fact, often seen as marking the "dawn of the modern era". Within France itself, the Revolution permanently crippled the power of the aristocracy and drained the wealth of the Church, although the two institutions survived despite the damage they sustained. After the collapse of the First Empire in 1815, the French public lost the rights and privileges earned since the Revolution, but they remembered the participatory politics that characterized the period, with one historian commenting: "Thousands of men and even many women gained firsthand experience in the political arena: they talked, read, and listened in new ways; they voted; they joined new organizations; and they marched for their political goals. Revolution became a tradition, and republicanism an enduring option." 
Some historians argue that the French people underwent a fundamental transformation in self-identity, evidenced by the elimination of privileges and their replacement by rights as well as the growing decline in social deference that highlighted the principle of equality throughout the Revolution. The Revolution represented the most significant and dramatic challenge to political absolutism up to that point in history and, despite its failures, spread democratic ideals throughout Europe and ultimately the world. It had a profound impact on the Russian Revolution and its ideas inspired Mao Zedong in his efforts at constructing a communist state in China.

Genocide
Genocide is "the deliberate and systematic destruction, in whole or in part, of an ethnic, racial, religious, or national group", though what constitutes enough of a "part" to qualify as genocide has been subject to much debate by legal scholars. While a precise definition varies among genocide scholars, a legal definition is found in the 1948 United Nations Convention on the Prevention and Punishment of the Crime of Genocide (CPPCG). Article 2 of this convention defines genocide as "any of the following acts committed with intent to destroy, in whole or in part, a national, ethnical, racial or religious group, as such: killing members of the group; causing serious bodily or mental harm to members of the group; deliberately inflicting on the group conditions of life, calculated to bring about its physical destruction in whole or in part; imposing measures intended to prevent births within the group; forcibly transferring children of the group to another group."
Raphael Lemkin in his masterpiece "Axis Rule in Occupied Europe" (1943) invented the term "genocide,"by combining "genos" (race, people) and "cide" (to kill).
"Generally speaking, genocide does not necessarily mean the immediate destruction of a nation, except when accomplished by mass killings of all members of a nation. It is intended rather to signify a coordinated plan of different actions aiming at the destruction of essential foundations of the life of national groups, with the aim of annihilating the groups themselves. The objectives of such a plan would be the disintegration of the political and social institutions, of culture, language, national feelings, religion, and the economic existence of national groups, and the destruction of the personal security, liberty, health, dignity, and even the lives of the individuals belonging to such groups."
The preamble to the CPPCG states that instances of genocide have taken place throughout history, but it was not until Raphael Lemkin coined the term and the prosecution of perpetrators of the Holocaust at the Nuremberg trials that the United Nations agreed to the CPPCG which defined the crime of genocide under international law.
During a video interview with Raphael Lemkin, the interviewer asked him about how he came to be interested in this genocide. He replied; "I became interested in genocide because it happened so many times. First to the Armenians, then after the Armenians, Hitler took action."
There was a gap of more than forty years between the CPPCG coming into force and the first prosecution under the provisions of the treaty. To date all international prosecutions of genocide, the Rwandan Genocide and the Srebrenica Genocide, have been by "ad hoc" international tribunals. The International Criminal Court came into existence in 2002 and it has the authority to try people from the states that have signed the treaty, but to date it has not tried anyone.
Since the CPPCG came into effect in January 1951 about 80 member states of the United Nations have passed legislation that incorporates the provisions of the CPPCG into their domestic law, and some perpetrators of genocide have been found guilty under such municipal laws, such as Nikola Jorgic, who was found guilty of genocide in Bosnia by a German court ("Jorgic v. Germany").
Critics of the CPPCG point to the narrow definition of the groups that are protected under the treaty, particularly the lack of protection for political groups for what has been termed politicide (politicide is included as genocide under some municipal jurisdictions). One of the problems was that until there was a body of case law from prosecutions, the precise definition of what the treaty meant had not been tested in court, for example, what precisely does the term ""in part"" mean? As more perpetrators are tried under international tribunals and municipal court cases, a body of legal arguments and legal interpretations are helping to address these issues.
The exclusion of political groups and politically motivated violence from the international definition of genocide is particularly controversial. The reason for this exclusion is because a number of UN member nations insisted on it when the Genocide Convention was being drafted in 1948. They argued that political groups are too vaguely defined, as well as temporary and unstable. They further held that international law should not seek to regulate or limit political conflicts, since that would give the UN too much power to interfere in the internal affairs of sovereign nations. In the years since then, critics have argued that the exclusion of political groups from the definition, as well as the lack of a specific reference to the destruction of a social group through the forcible removal of a population, was designed to protect the Soviet Union and the Western Allies from possible accusations of genocide in the wake of World War II.
Another criticism of the CPPCG is that when its provisions have been invoked by the United Nations Security Council, they have only been invoked to punish those who have already committed genocide and have left a paper trail. It was this criticism that led to the adoption of UN Security Council Resolution 1674 by the United Nations Security Council on 28 April 2006 which commits the Council to action to protect civilians in armed conflict and to protect populations from genocide, war crimes, ethnic cleansing and crimes against humanity.
Genocide scholars such as Gregory Stanton have postulated that conditions and acts that often occur before, during, and after genocide—such as dehumanization of victim groups, strong organization of genocidal groups, and denial of genocide by its perpetrators—can be identified and actions taken to stop genocides before they happen. Critics of this approach such as Dirk Moses assert that this is unrealistic and that, for example, ""Darfur will end when it suits the great powers that have a stake in the region"".
Genocide as a crime.
International law.
After the Holocaust, Lemkin successfully campaigned for the universal acceptance of international laws defining and forbidding genocide. In 1946, the first session of the United Nations General Assembly adopted a resolution that "affirmed" that genocide was a crime under international law, but did not provide a legal definition of the crime. In 1948, the UN General Assembly adopted the "Convention on the Prevention and Punishment of the Crime of Genocide" which legally defined the crime of genocide for the first time.
The first draft of the Convention included political killings, but the USSR along with some other nations would not accept that actions against groups identified as holding similar political opinions or social status would constitute genocide, so these stipulations were subsequently removed in a political and diplomatic compromise.
Intent to destroy.
In 2007 the European Court of Human Rights (ECHR), noted in its judgement on "Jorgic v. Germany" case that in 1992 the majority of legal scholars took the narrow view that "intent to destroy" in the CPPCG meant the intended physical-biological destruction of the protected group and that this was still the majority opinion. But the ECHR also noted that a minority took a broader view and did not consider biological-physical destruction was necessary as the intent to destroy a national, racial, religious or ethnical group was enough to qualify as genocide.
In the same judgement the ECHR reviewed the judgements of several international and municipal courts judgements. It noted that International Criminal Tribunal for the Former Yugoslavia and the International Court of Justice had agreed with the narrow interpretation, that biological-physical destruction was necessary for an act to qualify as genocide. The ECHR also noted that at the time of its judgement, apart from courts in Germany which had taken a broad view, that there had been few cases of genocide under other Convention States municipal laws and that "There are no reported cases in which the courts of these States have defined the type of group destruction the perpetrator must have intended in order to be found guilty of genocide".
In part.
The phrase "in whole or in part" has been subject to much discussion by scholars of international humanitarian law. The International Criminal Tribunal for the Former Yugoslavia found in "Prosecutor v. Radislav Krstic – Trial Chamber I – Judgment – IT-98-33 (2001) ICTY8 (2 August 2001)" that Genocide had been committed. In "Prosecutor v. Radislav Krstic – Appeals Chamber – Judgment – IT-98-33 (2004) ICTY 7 (19 April 2004)" paragraphs 8, 9, 10, and 11 addressed the issue of "in part" and found that "the part must be a substantial part of that group. The aim of the Genocide Convention is to prevent the intentional destruction of entire human groups, and the part targeted must be significant enough to have an impact on the group as a whole." The Appeals Chamber goes into details of other cases and the opinions of respected commentators on the Genocide Convention to explain how they came to this conclusion.
The judges continue in paragraph 12, "The determination of when the targeted part is substantial enough to meet this requirement may involve a number of considerations. The numeric size of the targeted part of the group is the necessary and important starting point, though not in all cases the ending point of the inquiry. The number of individuals targeted should be evaluated not only in absolute terms, but also in relation to the overall size of the entire group. In addition to the numeric size of the targeted portion, its prominence within the group can be a useful consideration. If a specific part of the group is emblematic of the overall group, or is essential to its survival, that may support a finding that the part qualifies as substantial within the meaning of Article 4 the Tribunal's Statute."
In paragraph 13 the judges raise the issue of the perpetrators' access to the victims: "The historical examples of genocide also suggest that the area of the perpetrators’ activity and control, as well as the possible extent of their reach, should be considered. ... The intent to destroy formed by a perpetrator of genocide will always be limited by the opportunity presented to him. While this factor alone will not indicate whether the targeted group is substantial, it can—in combination with other factors—inform the analysis."
CPPCG coming into force.
After the minimum 20 countries became parties to the Convention, it came into force as international law on 12 January 1951. At that time however, only two of the five permanent members of the UN Security Council (UNSC) were parties to the treaty: France and the Republic of China. Eventually the Soviet Union ratified in 1954, the United Kingdom in 1970, the People's Republic of China in 1983 (having replaced the Taiwan-based Republic of China on the UNSC in 1971), and the United States in 1988. This long delay in support for the Genocide Convention by the world's most powerful nations caused the Convention to languish for over four decades. Only in the 1990s did the international law on the crime of genocide begin to be enforced.
UN Security Council on genocide.
UN Security Council Resolution 1674, adopted by the United Nations Security Council on 28 April 2006, "reaffirms the provisions of paragraphs 138 and 139 of the 2005 World Summit Outcome Document regarding the responsibility to protect populations from genocide, war crimes, ethnic cleansing and crimes against humanity". The resolution committed the Council to action to protect civilians in armed conflict.
In 2008 the U.N. Security Council adopted resolution 1820, which noted that “rape and other forms of sexual violence can constitute war crimes, crimes against humanity or a constitutive act with respect to genocide”.
Municipal law.
Since the Convention on the Prevention and Punishment of the Crime of Genocide (CPPCG) came into effect in January 1951 about 80 member states of the United Nations have passed legislation that incorporates the provisions of the CPPCG into their municipal law.
Criticisms of the CPPCG and other definitions of genocide.
William Schabas has suggested that a permanent body as recommended by the Whitaker Report to monitor the implementation of the Genocide Convention, and require States to issue reports on their compliance with the convention (such as were incorporated into the United Nations Optional Protocol to the Convention against Torture), would make the convention more effective.
Writing in 1998 Kurt Jonassohn and Karin Björnson stated that the CPPCG was a legal instrument resulting from a diplomatic compromise. As such the wording of the treaty is not intended to be a definition suitable as a research tool, and although it is used for this purpose, as it has an international legal credibility that others lack, other definitions have also been postulated. Jonassohn and Björnson go on to say that none of these alternative definitions have gained widespread support for various reasons.
Jonassohn and Björnson postulate that the major reason why no single generally accepted genocide definition has emerged is because academics have adjusted their focus to emphasise different periods and have found it expedient to use slightly different definitions to help them interpret events. For example Frank Chalk and Kurt Jonassohn studied the whole of human history, while Leo Kuper and R. J. Rummel in their more recent works concentrated on the 20th century, and Helen Fein, Barbara Harff and Ted Gurr have looked at post World War II events. Jonassohn and Björnson are critical of some of these studies arguing that they are too expansive and concludes that the academic discipline of genocide studies is too young to have a canon of work on which to build an academic paradigm.
The exclusion of social and political groups as targets of genocide in the CPPCG legal definition has been criticized by some historians and sociologists, for example M. Hassan Kakar in his book "The Soviet Invasion and the Afghan Response, 1979–1982" argues that the international definition of genocide is too restricted, and that it should include political groups or any group so defined by the perpetrator and quotes Chalk and Jonassohn: "Genocide is a form of one-sided mass killing in which a state or other authority intends to destroy a group, as that group and membership in it are defined by the perpetrator." While there are various definitions of the term, Adam Jones states that the majority of genocide scholars consider that "intent to destroy" is a requirement for any act to be labelled genocide, and that there is growing agreement on the inclusion of the physical destruction criterion.
Barbara Harff and Ted Gurr defined genocide as "the promotion and execution of policies by a state or its agents which result in the deaths of a substantial portion of a group ...the victimized groups are defined primarily in terms of their communal characteristics, i.e., ethnicity, religion or nationality." Harff and Gurr also differentiate between genocides and politicides by the characteristics by which members of a group are identified by the state. In genocides, the victimized groups are defined primarily in terms of their communal characteristics, i.e., ethnicity, religion or nationality. In politicides the victim groups are defined primarily in terms of their hierarchical position or political opposition to the regime and dominant groups. Daniel D. Polsby and Don B. Kates, Jr. state that "... we follow Harff's distinction between genocides and 'pogroms,' which she describes as 'short-lived outbursts by mobs, which, although often condoned by authorities, rarely persist.' If the violence persists for long enough, however, Harff argues, the distinction between condonation and complicity collapses."
According to R. J. Rummel, genocide has 3 different meanings. The ordinary meaning is murder by government of people due to their national, ethnic, racial, or religious group membership. The legal meaning of genocide refers to the international treaty, the "Convention on the Prevention and Punishment of the Crime of Genocide". This also includes non-killings that in the end eliminate the group, such as preventing births or forcibly transferring children out of the group to another group. A generalized meaning of genocide is similar to the ordinary meaning but also includes government killings of political opponents or otherwise intentional murder. It is to avoid confusion regarding what meaning is intended that Rummel created the term democide for the third meaning.
A major criticism of the international community's response to the Rwandan Genocide was that it was reactive, not proactive. The international community has developed a mechanism for prosecuting the perpetrators of genocide but has not developed the will or the mechanisms for intervening in a genocide as it happens. Critics point to the Darfur conflict and suggest that if anyone is found guilty of genocide after the conflict either by prosecutions brought in the International Criminal Court or in an "ad hoc" International Criminal Tribunal, this will confirm this perception.
International prosecution of genocide.
By ad hoc tribunals.
All signatories to the CPPCG are required to prevent and punish acts of genocide, both in peace and wartime, though some barriers make this enforcement difficult. In particular, some of the signatories—namely, Bahrain, Bangladesh, India, Malaysia, the Philippines, Singapore, the United States, Vietnam, Yemen, and Yugoslavia—signed with the proviso that no claim of genocide could be brought against them at the International Court of Justice without their consent. Despite official protests from other signatories (notably Cyprus and Norway) on the ethics and legal standing of these reservations, the immunity from prosecution they grant has been invoked from time to time, as when the United States refused to allow a charge of genocide brought against it by Yugoslavia following the 1999 Kosovo War.
It is commonly accepted that, at least since World War II, genocide has been illegal under customary international law as a peremptory norm, as well as under conventional international law. Acts of genocide are generally difficult to establish for prosecution, because a chain of accountability must be established. International criminal courts and tribunals function primarily because the states involved are incapable or unwilling to prosecute crimes of this magnitude themselves.
Nuremberg Tribunal (1945–1946).
Because the universal acceptance of international laws, defining and forbidding genocide was achieved in 1948, with the promulgation of the "Convention on the Prevention and Punishment of the Crime of Genocide" (CPPCG), those criminals who were prosecuted after the war in international courts, for taking part in the Holocaust were found guilty of crimes against humanity and other more specific crimes like murder. Nevertheless the Holocaust is universally recognized to have been a genocide and the term, that had been coined the year before by Raphael Lemkin, appeared in the indictment of the 24 Nazi leaders, Count 3, stated that all the defendants had "conducted deliberate and systematic genocide—namely, the extermination of racial and national groups..."
International Criminal Tribunal for the Former Yugoslavia (1993 to present (2014 is the scheduled end date)).
The term "Bosnian Genocide" is used to refer either to the genocide committed by Serb forces in Srebrenica in 1995, or to ethnic cleansing that took place during the 1992–1995 Bosnian War (an interpretation rejected by a majority of scholars).
In 2001 the International Criminal Tribunal for the Former Yugoslavia (ICTY) judged that the 1995 Srebrenica massacre was an act of genocide.
On 26 February 2007 the International Court of Justice (ICJ), in the "Bosnian Genocide Case" upheld the ICTY's earlier finding that the Srebrenica massacre constituted genocide, but found that the Serbian government had not participated in a wider genocide on the territory of Bosnia and Herzegovina during the war, as the Bosnian government had claimed.
On 12 July 2007, European Court of Human Rights when dismissing the appeal by Nikola Jorgic against his conviction for genocide by a German court (Jorgic v. Germany) noted that the German courts wider interpretation of genocide has since been rejected by international courts considering similar cases. The ECHR also noted that in the 21st century "Amongst scholars, the majority have taken the view that ethnic cleansing, in the way in which it was carried out by the Serb forces in Bosnia and Herzegovina in order to expel Muslims and Croats from their homes, did not constitute genocide. However, there are also a considerable number of scholars who have suggested that these acts did amount to genocide"
About 30 people have been indicted for participating in genocide or complicity in genocide during the early 1990s in Bosnia. To date after several plea bargains and some convictions that were successfully challenged on appeal two men, Vujadin Popović and Ljubiša Beara, have been found guilty of genocide, and two others, Radislav Krstic and Drago Nikolic, have been found guilty of aiding and abetting genocide. Three others have been found guilty of participating in genocides in Bosnia by German courts, one of whom Nikola Jorgic lost an appeal against his conviction in the European Court of Human Rights. A further eight men, former members of the Bosnian Serb security forces were found guilty of genocide by the State Court of Bosnia and Herzegovina (See List of Bosnian genocide prosecutions).
Slobodan Milosevic, as the former President of Serbia and of Yugoslavia was the most senior political figure to stand trial at the ICTY. He died on 11 March 2006 during his trial where he was accused of genocide or complicity in genocide in territories within Bosnia and Herzegovina, so no verdict was returned. In 1995 the ICTY issued a warrant for the arrest of Bosnian Serbs Radovan Karadzic and Ratko Mladic on several charges including genocide. On 21 July 2008, Karadzic was arrested in Belgrade, and he is currently in The Hague on trial accused of genocide among other crimes. Ratko Mladic was arrested on 26 May 2011 by Serbian special police in Lazarevo, Serbia.
International Criminal Tribunal for Rwanda (1994 to present (2012 is the scheduled end date)).
The International Criminal Tribunal for Rwanda (ICTR) is a court under the auspices of the United Nations for the prosecution of offenses committed in Rwanda during the genocide which occurred there during April 1994, commencing on 6 April. The ICTR was created on 8 November 1994 by the Security Council of the United Nations in order to judge those people responsible for the acts of genocide and other serious violations of the international law performed in the territory of Rwanda, or by Rwandan citizens in nearby states, between 1 January and 31 December 1994.
So far, the ICTR has finished nineteen trials and convicted twenty seven accused persons. On 14 December 2009 two more men were accused and convicted for their crimes. Another twenty five persons are still on trial. Twenty-one are awaiting trial in detention, two more added on 14 December 2009. Ten are still at large. The first trial, of Jean-Paul Akayesu, began in 1997. In October 1998, Akayesu was sentenced to life imprisonment. Jean Kambanda, interim Prime Minister, pled guilty.
Extraordinary Chambers in the Courts of Cambodia (2003 to present).
The Khmer Rouge, led by Pol Pot, Ta Mok and other leaders, organized the mass killing of ideologically suspect groups. The total number of victims is estimated at approximately 1.7 million Cambodians between 1975–1979, including deaths from slave labour.
On 6 June 2003 the Cambodian government and the United Nations reached an agreement to set up the Extraordinary Chambers in the Courts of Cambodia (ECCC) which would focus exclusively on crimes committed by the most senior Khmer Rouge officials during the period of Khmer Rouge rule of 1975–1979. The judges were sworn in early July 2006.
The investigating judges were presented with the names of five possible suspects by the prosecution on 18 July 2007.
There has been disagreement between some of the international jurists and the Cambodian government over whether any other people should be tried by the Tribunal.
By the International Criminal Court.
To date all international prosecutions for genocide have been brought in specially convened international tribunals. Since 2002, the International Criminal Court can exercise its jurisdiction if national courts are unwilling or unable to investigate or prosecute genocide, thus being a "court of last resort," leaving the primary responsibility to exercise jurisdiction over alleged criminals to individual states. Due to the United States concerns over the ICC, the United States prefers to continue to use specially convened international tribunals for such investigations and potential prosecutions.
Darfur, Sudan.
There has been much debate over categorizing the situation in Darfur as genocide. The on-going conflict in Darfur, Sudan, which started in 2003, was declared a "genocide" by United States Secretary of State Colin Powell on 9 September 2004 in testimony before the Senate Foreign Relations Committee. Since that time however, no other permanent member of the UN Security Council followed suit. In fact, in January 2005, an International Commission of Inquiry on Darfur, authorized by UN Security Council Resolution 1564 of 2004, issued a report to the Secretary-General stating that "the Government of the Sudan has not pursued a policy of genocide." Nevertheless, the Commission cautioned that "The conclusion that no genocidal policy has been pursued and implemented in Darfur by the Government authorities, directly or through the militias under their control, should not be taken in any way as detracting from the gravity of the crimes perpetrated in that region. International offences such as the crimes against humanity and war crimes that have been committed in Darfur may be no less serious and heinous than genocide."
In March 2005, the Security Council formally referred the situation in Darfur to the Prosecutor of the International Criminal Court, taking into account the Commission report but without mentioning any specific crimes. Two permanent members of the Security Council, the United States and China, abstained from the vote on the referral resolution. As of his fourth report to the Security Council, the Prosecutor has found "reasonable grounds to believe that the individuals identified the UN Security Council Resolution 1593 have committed crimes against humanity and war crimes," but did not find sufficient evidence to prosecute for genocide.
In April 2007, the Judges of the ICC issued arrest warrants against the former Minister of State for the Interior, Ahmad Harun, and a Militia
Janjaweed leader, Ali Kushayb, for crimes against humanity and war crimes.
On 14 July 2008, prosecutors at the International Criminal Court (ICC), filed ten charges of war crimes against Sudan's President Omar al-Bashir: three counts of genocide, five of crimes against humanity and two of murder. The ICC's prosecutors claimed that al-Bashir "masterminded and implemented a plan to destroy in substantial part" three tribal groups in Darfur because of their ethnicity.
On 4 March 2009, the ICC issued a warrant of arrest for Omar Al Bashir, President of Sudan as the ICC Pre-Trial Chamber I concluded that his position as head of state does not grant him immunity against prosecution before the ICC. The warrant was for war crimes and crimes against humanity. It did not include the crime of genocide because the majority of the Chamber did not find that the prosecutors had provided enough evidence to include such a charge.
Genocide in history.
The preamble to the CPPCG states that "genocide is a crime under international law, contrary to the spirit and aims of the United Nations and condemned by the civilized world," and that "at all periods of history genocide has inflicted great losses on humanity."
In many cases where accusations of genocide have circulated, partisans have fiercely disputed such an interpretation and the details of the event. This often leads to the promotion of vastly different versions of the event in question.
Revisionist attempts to deny or challenge claims of genocides are illegal in some countries. For example, several European countries ban denying the Holocaust, whilst in Turkey it is illegal to refer to mass killings of Armenians, Greeks and Assyrians by the Ottoman Empire towards the end of the First World War as a genocide.
Stages of genocide, influences leading to genocide, and efforts to prevent it.
In 1996 Gregory Stanton, the president of Genocide Watch, presented a briefing paper called "The 8 Stages of Genocide" at the United States Department of State. In it he suggested that genocide develops in eight stages that are "predictable but not inexorable".
The Stanton paper was presented at the State Department, shortly after the Rwanda genocide and much of the analysis is based on why that genocide occurred. The preventative measures suggested, given the original target audience, were those that the United States could implement directly or use their influence on other governments to have implemented.
In April 2012, it was reported that Stanton would soon be officially adding two new stages, Discrimination and Persecution, to his original theory, which would make for a 10-stage theory of genocide.
Other authors have focused on the structural conditions leading up to genocide and the psychological and social processes that create an evolution toward genocide. Helen Fein showed that pre-existing anti-Semitism and systems that maintained anti-Semitic policies was related to the number of Jews killed in different European countries during the Holocaust. Ervin Staub showed that economic deterioration and political confusion and disorganization were starting points of increasing discrimination and violence in many instances of genocides and mass killing. They lead to scapegoating a group and ideologies that identified that group as an enemy. A history of devaluation of the group that becomes the victim, past violence against the group that becomes the perpetrator leading to psychological wounds, authoritarian cultures and political systems, and the passivity of internal and external witnesses (bystanders) all contribute to the probability that the violence develops into genocide. Intense conflict between groups that is unresolved, becomes intractable and violent can also lead to genocide. The conditions that lead to genocide provide guidance to early prevention, such as humanizing a devalued group,creating ideologies that embrace all groups, and activating bystander responses. There is substantial research to indicate how this can be done, but information is only slowly transformed into action.
Cultural genocide.
The precise definition of "cultural genocide" remains unclear. The term was proposed by lawyer Raphael Lemkin in 1933 as a component to genocide, which he called "vandalism". The drafters of the 1948 Genocide Convention considered the use of the term, but dropped it under strong opposition from western countries, especially the United Kingdom, who feared that too broad a definition of genocide could implicate its activity in its colonies.

Great Depression
The Great Depression was a severe worldwide economic depression in the decade preceding World War II. The timing of the Great Depression varied across nations, but in most countries it started in 1930 and lasted until the late 1930s or middle 1940s. It was the longest, most widespread, and deepest depression of the 20th century.
In the 21st century, the Great Depression is commonly used as an example of how far the world's economy can decline. The depression originated in the U.S., after the fall in stock prices that began around September 4, 1929, and became worldwide news with the stock market crash of October 29, 1929 (known as Black Tuesday).
The Great Depression had devastating effects in countries rich and poor. Personal income, tax revenue, profits and prices dropped, while international trade plunged by more than 50%. Unemployment in the U.S. rose to 25%, and in some countries rose as high as 33%. 
Cities all around the world were hit hard, especially those dependent on heavy industry. Construction was virtually halted in many countries. Farming and rural areas suffered as crop prices fell by approximately 60%. Facing plummeting demand with few alternate sources of jobs, areas dependent on primary sector industries such as cash cropping, mining and logging suffered the most.
Some economies started to recover by the mid-1930s. In many countries, the negative effects of the Great Depression lasted until the end of World War II.
Start of the Great Depression.
Economic historians usually attribute the start of the Great Depression to the sudden devastating collapse of US stock market prices on October 29, 1929, known as Black Tuesday; some dispute this conclusion, and see the stock crash as a symptom, rather than a cause, of the Great Depression. 
Even after the Wall Street Crash of 1929, optimism persisted for some time; John D. Rockefeller said that "These are days when many are discouraged. In the 93 years of my life, depressions have come and gone. Prosperity has always returned and will again." The stock market turned upward in early 1930, returning to early 1929 levels by April. This was still almost 30% below the peak of September 1929. 
Together, government and business spent more in the first half of 1930 than in the corresponding period of the previous year. On the other hand, consumers, many of whom had suffered severe losses in the stock market the previous year, cut back their expenditures by ten percent. Likewise, beginning in mid-1930, a severe drought ravaged the agricultural heartland of the US.
By mid-1930, interest rates had dropped to low levels, but expected deflation and the continuing reluctance of people to borrow meant that consumer spending and investment were depressed. By May 1930, automobile sales had declined to below the levels of 1928. Prices in general began to decline, although wages held steady in 1930; but then a deflationary spiral started in 1931. Conditions were worse in farming areas, where commodity prices plunged, and in mining and logging areas, where unemployment was high and there were few other jobs. 
The decline in the US economy was the factor that pulled down most other countries at first, then internal weaknesses or strengths in each country made conditions worse or better. Frantic attempts to shore up the economies of individual nations through protectionist policies, such as the 1930 U.S. Smoot–Hawley Tariff Act and retaliatory tariffs in other countries, exacerbated the collapse in global trade. By late 1930, a steady decline in the world economy had set in, which did not reach bottom until 1933.
Economic indicators.
Change in economic indicators 1929–32
Causes.
There were multiple causes for the first downturn in 1929. These include the structural weaknesses and specific events that turned it into a major depression and the manner in which the downturn spread from country to country. In relation to the 1929 downturn, historians emphasize structural factors like major bank failures and the stock market crash. In contrast, monetarist economists (such as Barry Eichengreen, Milton Friedman and Peter Temin) point to monetary factors such as actions by the US Federal Reserve that contracted the money supply, as well as Britain's decision to return to the gold standard at pre–World War I parities (US$4.86:£1).
Recessions and business cycles are thought to be a normal part of living in a world of inexact balances between supply and demand. What turns a normal recession or 'ordinary' business cycle into a depression is a subject of much debate and concern. Scholars have not agreed on the exact causes and their relative importance. The search for causes is closely connected to the issue of avoiding future depressions.
Current theories may be broadly classified into two main points of view and several heterodox points of view. There are demand-driven theories, most importantly Keynesian economics, but also including those who point to the breakdown of international trade, and Institutional economists who point to underconsumption and over-investment (causing an economic bubble), malfeasance by bankers and industrialists, or incompetence by government officials. The consensus among demand-driven theories is that a large-scale loss of confidence led to a sudden reduction in consumption and investment spending. Once panic and deflation set in, many people believed they could avoid further losses by keeping clear of the markets. Holding money became profitable as prices dropped lower and a given amount of money bought ever more goods, exacerbating the drop in demand.
There are the monetarists, who believe that the Great Depression started as an ordinary recession, but that significant policy mistakes by monetary authorities (especially the Federal Reserve), caused a shrinking of the money supply which greatly exacerbated the economic situation, causing a recession to descend into the Great Depression. Related to this explanation are those who point to debt deflation causing those who borrow to owe ever more in real terms.
There are also various heterodox theories that downplay or reject the explanations of the Keynesians and monetarists. For example, some new classical macroeconomists have argued that various labor market policies imposed at the start caused the length and severity of the Great Depression. The Austrian school of economics focuses on the macroeconomic effects of money supply, and how central banking decisions can lead to over-investment (economic bubble).
Demand-driven.
Keynesian.
British economist John Maynard Keynes argued in "General Theory of Employment Interest and Money" that lower aggregate expenditures in the economy contributed to a massive decline in income and to employment that was well below the average. In such a situation, the economy reached equilibrium at low levels of economic activity and high unemployment. 
Keynes' basic idea was simple: to keep people fully employed, governments have to run deficits when the economy is slowing, as the private sector would not invest enough to keep production at the normal level and bring the economy out of recession. Keynesian economists called on governments during times of economic crisis to pick up the slack by increasing government spending and/or cutting taxes.
As the Depression wore on, Franklin D. Roosevelt tried public works, farm subsidies, and other devices to restart the US economy, but never completely gave up trying to balance the budget. According to the Keynesians, this improved the economy, but Roosevelt never spent enough to bring the economy out of recession until the start of World War II.
Breakdown of international trade.
Many economists have argued that the sharp decline in international trade after 1930 helped to worsen the depression, especially for countries significantly dependent on foreign trade. Most historians and economists partly blame the American Smoot-Hawley Tariff Act (enacted June 17, 1930) for worsening the depression by seriously reducing international trade and causing retaliatory tariffs in other countries. While foreign trade was a small part of overall economic activity in the U.S. and was concentrated in a few businesses like farming, it was a much larger factor in many other countries. The average "ad valorem" rate of duties on dutiable imports for 1921–1925 was 25.9% but under the new tariff it jumped to 50% in 1931–1935.
In dollar terms, American exports declined from about $5.2 billion in 1929 to $1.7 billion in 1933; but prices also fell, so the physical volume of exports only fell by half. Hardest hit were farm commodities such as wheat, cotton, tobacco, and lumber. According to this theory, the collapse of farm exports caused many American farmers to default on their loans, leading to the bank runs on small rural banks that characterized the early years of the Great Depression.
Debt deflation.
During the Crash of 1929 preceding the Great Depression, margin requirements were only 10%. Brokerage firms, in other words, would lend $9 for every $1 an investor had deposited. When the market fell, brokers called in these loans, which could not be paid back. 
Banks began to fail as debtors defaulted on debt and depositors attempted to withdraw their deposits en masse, triggering multiple bank runs. Government guarantees and Federal Reserve banking regulations to prevent such panics were ineffective or not used. Bank failures led to the loss of billions of dollars in assets. 
Outstanding debts became heavier, because prices and incomes fell by 20–50% but the debts remained at the same dollar amount. After the panic of 1929, and during the first 10 months of 1930, 744 US banks failed. (In all, 9,000 banks failed during the 1930s). By April 1933, around $7 billion in deposits had been frozen in failed banks or those left unlicensed after the March Bank Holiday.
Bank failures snowballed as desperate bankers called in loans which the borrowers did not have time or money to repay. With future profits looking poor, capital investment and construction slowed or completely ceased. In the face of bad loans and worsening future prospects, the surviving banks became even more conservative in their lending. Banks built up their capital reserves and made fewer loans, which intensified deflationary pressures. A vicious cycle developed and the downward spiral accelerated.
The liquidation of debt could not keep up with the fall of prices which it caused. The mass effect of the stampede to liquidate increased the value of each dollar owed, relative to the value of declining asset holdings. The very effort of individuals to lessen their burden of debt effectively increased it. Paradoxically, the more the debtors paid, the more they owed. This self-aggravating process turned a 1930 recession into a 1933 great depression.
Macroeconomists including Ben Bernanke, the current chairman of the U.S. Federal Reserve Bank, have revived the debt-deflation view of the Great Depression originated by Fisher.
Monetarist.
Monetarists, including Milton Friedman and current Federal Reserve System chairman Ben Bernanke, argue that the Great Depression was mainly caused by monetary contraction, the consequence of poor policy-making by the American Federal Reserve System and continued crisis in the banking system. In this view, the Federal Reserve, by not acting, allowed the money supply as measured by the M2 to shrink by one-third from 1929–1933, thereby transforming a normal recession into the Great Depression. Friedman argued that the downward turn in the economy, starting with the stock market crash, would have been just another recession. 
The Federal Reserve allowed some large public bank failures – particularly that of the New York Bank of the United States – which produced panic and widespread runs on local banks, and the Federal Reserve sat idly by while banks collapsed. He claimed that, if the Fed had provided emergency lending to these key banks, or simply bought government bonds on the open market to provide liquidity and increase the quantity of money after the key banks fell, all the rest of the banks would not have fallen after the large ones did, and the money supply would not have fallen as far and as fast as it did. 
With significantly less money to go around, businessmen could not get new loans and could not even get their old loans renewed, forcing many to stop investing. This interpretation blames the Federal Reserve for inaction, especially the New York branch.
One reason why the Federal Reserve did not act to limit the decline of the money supply was regulation. At that time, the amount of credit the Federal Reserve could issue was limited by the Federal Reserve Act, which required 40% gold backing of Federal Reserve Notes issued. By the late 1920s, the Federal Reserve had almost hit the limit of allowable credit that could be backed by the gold in its possession. This credit was in the form of Federal Reserve demand notes.
A "promise of gold" is not as good as "gold in the hand", particularly when they only had enough gold to cover 40% of the Federal Reserve Notes outstanding. During the bank panics a portion of those demand notes were redeemed for Federal Reserve gold. Since the Federal Reserve had hit its limit on allowable credit, any reduction in gold in its vaults had to be accompanied by a greater reduction in credit. On April 5, 1933, President Roosevelt signed Executive Order 6102 making the private ownership of gold certificates, coins and bullion illegal, reducing the pressure on Federal Reserve gold.
New classical approach.
Recent work from a neoclassical perspective focuses on the decline in productivity that caused the initial decline in output and a prolonged recovery due to policies that affected the labor market. This work, collected by Kehoe and Prescott, decomposes the economic decline into a decline in the labor force, capital stock, and the productivity with which these inputs are used. 
This study suggests that theories of the Great Depression have to explain an initial severe decline but rapid recovery in productivity, relatively little change in the capital stock, and a prolonged depression in the labor force. This analysis rejects theories that focus on the role of savings and posit a decline in the capital stock.
Austrian School.
Another explanation comes from the Austrian School of economics. Theorists of the "Austrian School" who wrote about the Depression include Austrian economist Friedrich Hayek and American economist Murray Rothbard, who wrote "America's Great Depression" (1963). In their view and like the monetarists, the Federal Reserve, which was created in 1913, shoulders much of the blame; but in opposition to the monetarists, they argue that the key cause of the Depression was the expansion of the money supply in the 1920s that led to an unsustainable credit-driven boom.
In the Austrian view it was this inflation of the money supply that led to an unsustainable boom in both asset prices (stocks and bonds) and capital goods. By the time the Fed belatedly tightened in 1928, it was far too late and, in the Austrian view, a significant economic contraction was inevitable. According to the Austrians, the artificial interference in the economy was a disaster prior to the Depression, and government efforts to prop up the economy after the crash of 1929 only made things worse.
According to Rothbard, government intervention delayed the market's adjustment and made the road to complete recovery more difficult. However, Hayek, unlike Rothbard, also believed, along with the monetarists, that the Federal Reserve further contributed to the problems of the Depression by permitting the money supply to shrink during the earliest years of the Depression.
Marxist.
Karl Marx saw recession and depression as unavoidable under free-market capitalism as there are no restrictions on accumulations of capital other than the market itself. In the Marxist view, capitalism tends to create unbalanced accumulations of wealth, leading to over-accumulations of capital which inevitably lead to a crisis. This especially sharp bust is a regular feature of the boom and bust pattern of what Marxists term "chaotic" capitalist development. It is a tenet of many Marxists groupings that such crises are inevitable and will be increasingly severe until the contradictions inherent in the mismatch between the mode of production and the development of productive forces reach the final point of failure. At which point, the crisis period encourages intensified class conflict and forces societal change.
Inequality.
Two economists of the 1920s, Waddill Catchings and William Trufant Foster, popularized a theory that influenced many policy makers, including Herbert Hoover, Henry A. Wallace, Paul Douglas, and Marriner Eccles. It held the economy produced more than it consumed, because the consumers did not have enough income. Thus the unequal distribution of wealth throughout the 1920s caused the Great Depression.
According to this view, the root cause of the Great Depression was a global over-investment in heavy industry capacity compared to wages and earnings from independent businesses, such as farms. The solution was the government must pump money into consumers' pockets. That is, it must redistribute purchasing power, maintain the industrial base, but re-inflate prices and wages to force as much of the inflationary increase in purchasing power into consumer spending. The economy was overbuilt, and new factories were not needed. Foster and Catchings recommended federal and state governments start large construction projects, a program followed by Hoover and Roosevelt.
Productivity shock.
 M. King Hubbert
The first three decades of the 20th century saw economic output surge with electrification, mass production and motorized farm machinery, and because of the rapid growth in productivity there was a lot of excess production capacity and the work week was being reduced.
The dramatic rise in productivity of major industries in the U. S. and the effects of productivity on output, wages and the work week are discussed by Spurgeon Bell in his book "Productivity, Wages, and National Income" (1940).
Turning point and recovery.
In most countries of the world, recovery from the Great Depression began in 1933. In the U.S., recovery began in early 1933, but the U.S. did not return to 1929 GNP for over a decade and still had an unemployment rate of about 15% in 1940, albeit down from the high of 25% in 1933. The measurement of the unemployment rate in this time period was unsophisticated and complicated by the presence of massive underemployment, in which employers and workers engaged in rationing of jobs. 
There is no consensus among economists regarding the motive force for the U.S. economic expansion that continued through most of the Roosevelt years (and the 1937 recession that interrupted it). The common view among mainstream economists is that Roosevelt's New Deal policies either caused or accelerated the recovery, although his policies were never aggressive enough to bring the economy completely out of recession. Some economists have also called attention to the positive effects from expectations of reflation and rising nominal interest rates that Roosevelt's words and actions portended. 
It was the rollback of those same reflationary policies that led to the interrupting recession of 1937. GDP returned to its upward slope in 1938.
According to Christina Romer, the money supply growth caused by huge international gold inflows was a crucial source of the recovery of the United States economy, and that the economy showed little sign of self-correction. The gold inflows were partly due to devaluation of the U.S. dollar and partly due to deterioration of the political situation in Europe. 
In their book, "A Monetary History of the United States", Milton Friedman and Anna J. Schwartz also attributed the recovery to monetary factors, and contended that it was much slowed by poor management of money by the Federal Reserve System. Current Chairman of the Federal Reserve Ben Bernanke agrees that monetary factors played important roles both in the worldwide economic decline and eventual recovery. Bernanke, also sees a strong role for institutional factors, particularly the rebuilding and restructuring of the financial system, and points out that the Depression needs to be examined in international perspective.
Gold standard.
Some economic studies have indicated that just as the downturn was spread worldwide by the rigidities of the Gold Standard, it was suspending gold convertibility (or devaluing the currency in gold terms) that did the most to make recovery possible. On the other hand, economists such as Friedrich Hayek and Murray Rothbard point out that the 19th century panics each had a shorter duration while also having occurred under the international gold standard, and that policies countries followed after casting off the gold standard, and what results followed, varied widely. 
Every major currency left the gold standard during the Great Depression. Great Britain was the first to do so. Facing speculative attacks on the pound and depleting gold reserves, in September 1931 the Bank of England ceased exchanging pound notes for gold and the pound was floated on foreign exchange markets.
Great Britain, Japan, and the Scandinavian countries left the gold standard in 1931. Other countries, such as Italy and the U.S., remained on the gold standard into 1932 or 1933, while a few countries in the so-called "gold bloc", led by France and including Poland, Belgium and Switzerland, stayed on the standard until 1935–1936.
According to later analysis, the earliness with which a country left the gold standard reliably predicted its economic recovery. For example, Great Britain and Scandinavia, which left the gold standard in 1931, recovered much earlier than France and Belgium, which remained on gold much longer. Countries such as China, which had a silver standard, almost avoided the depression entirely. The connection between leaving the gold standard as a strong predictor of that country's severity of its depression and the length of time of its recovery has been shown to be consistent for dozens of countries, including developing countries. This partly explains why the experience and length of the depression differed between national economies.
World War II and recovery.
The common view among economic historians is that the Great Depression ended with the advent of World War II. Many economists believe that government spending on the war caused or at least accelerated recovery from the Great Depression, though some consider that it did not play a very large role in the recovery. It did help in reducing unemployment.
The rearmament policies leading up to World War II helped stimulate the economies of Europe in 1937–39. By 1937, unemployment in Britain had fallen to 1.5 million. The mobilisation of manpower following the outbreak of war in 1939 ended unemployment.
America's entry into the war in 1941 finally eliminated the last effects from the Great Depression and brought the U.S. unemployment rate down below 10%. In the U.S., massive war spending doubled economic growth rates, either masking the effects of the Depression or essentially ending the Depression. Businessmen ignored the mounting national debt and heavy new taxes, redoubling their efforts for greater output to take advantage of generous government contracts.
Effects.
The majority of countries set up relief programs, and most underwent some sort of political upheaval, pushing them to the left or right. In some states, the desperate citizens turned toward nationalist demagoguery — the most infamous example being Adolf Hitler — setting the stage for World War II in 1939.
Australia.
Australia's dependence on agricultural and industrial exports meant it was one of the hardest-hit countries in the Western world. Falling export demand and commodity prices placed massive downward pressures on wages. Further, unemployment reached a record high of 29% in 1932, with incidents of civil unrest becoming common. After 1932, an increase in wool and meat prices led to a gradual recovery.
Canada.
Harshly affected by both the global economic downturn and the Dust Bowl, Canadian industrial production had fallen to only 58% of the 1929 level by 1932, the second lowest level in the world after the United States, and well behind nations such as Britain, which saw it fall only to 83% of the 1929 level. Total national income fell to 56% of the 1929 level, again worse than any nation apart from the United States. Unemployment reached 27% at the depth of the Depression in 1933. During the 1930s, Canada employed a highly restrictive immigration policy.
Chile.
The League of Nations labeled Chile the country hardest hit by the Great Depression because 80% of government revenue came from exports of copper and nitrates, which were in low demand.
Chile initially felt the impact of the Great Depression in 1930, when GDP dropped 14%, mining income declined 27%, and export earnings fell 28%. By 1932, GDP had shrunk to less than half of what it had been in 1929, exacting a terrible toll in unemployment and business failures. 
Influenced profoundly by the Great Depression, many national leaders promoted the development of local industry in an effort to insulate the economy from future external shocks. After six years of government austerity measures, which succeeded in reestablishing Chile's creditworthiness, Chileans elected to office during the 1938–58 period a succession of center and left-of-center governments interested in promoting economic growth by means of government intervention.
Prompted in part by the devastating 1939 Chillán earthquake, the Popular Front government of Pedro Aguirre Cerda created the Production Development Corporation (Corporación de Fomento de la Producción, CORFO) to encourage with subsidies and direct investments an ambitious program of import substitution industrialization. Consequently, as in other Latin American countries, protectionism became an entrenched aspect of the Chilean economy.
France.
The Depression began to affect France around 1931. France's relatively high degree of self-sufficiency meant the damage was considerably less than in nations like Germany. Hardship and unemployment were high enough to lead to rioting and the rise of the socialist Popular Front. Ultra-nationalist groups also saw increased popularity, although democracy prevailed into World War II.
Germany.
Germany's Weimar Republic was hit hard by the depression, as American loans to help rebuild the German economy now stopped. Unemployment soared, especially in larger cities, and the political system veered toward extremism. The unemployment rate reached nearly 30% in 1932, bolstering support for the anti-capitalist Nazi (NSDAP) and Communist (KPD) parties, which both rose in the years following the crash to altogether possess a Reichstag majority following the general election in July 1932. 
Repayments of the war reparations due by Germany were suspended in 1932 following the Lausanne Conference of 1932. By that time, Germany had repaid one eighth of the reparations. Hitler and the Nazi Party came to power in January 1933, establishing a totalitarian single-party state within months and initiating the path towards World War II, the most devastating conflict in world history.
Japan.
The Great Depression did not strongly affect Japan. The Japanese economy shrank by 8% during 1929–31. Japan's Finance Minister Takahashi Korekiyo was the first to implement what have come to be identified as Keynesian economic policies: first, by large fiscal stimulus involving deficit spending; and second, by devaluing the currency. Takahashi used the Bank of Japan to sterilize the deficit spending and minimize resulting inflationary pressures. Econometric studies have identified the fiscal stimulus as especially effective.
The devaluation of the currency had an immediate effect. Japanese textiles began to displace British textiles in export markets. The deficit spending proved to be most profound. The deficit spending went into the purchase of munitions for the armed forces. By 1933, Japan was already out of the depression. By 1934, Takahashi realized that the economy was in danger of overheating, and to avoid inflation, moved to reduce the deficit spending that went towards armaments and munitions. 
This resulted in a strong and swift negative reaction from nationalists, especially those in the army, culminating in his assassination in the course of the February 26 Incident. This had a chilling effect on all civilian bureaucrats in the Japanese government. From 1934, the military's dominance of the government continued to grow. Instead of reducing deficit spending, the government introduced price controls and rationing schemes that reduced, but did not eliminate inflation, which would remain a problem until the end of World War II.
The deficit spending had a transformative effect on Japan. Japan's industrial production doubled during the 1930s. Further, in 1929 the list of the largest firms in Japan was dominated by light industries, especially textile companies (many of Japan's automakers, like Toyota, have their roots in the textile industry). By 1940 light industry had been displaced by heavy industry as the largest firms inside the Japanese economy.
Latin America.
Because of high levels of U.S. investment in Latin American economies, they were severely damaged by the Depression. Within the region, Chile, Bolivia and Peru were particularly badly affected.
Netherlands.
From roughly 1931–1937, the Netherlands suffered a deep and exceptionally long depression. This depression was partly caused by the after-effects of the Stock Market Crash of 1929 in the U.S., and partly by internal factors in the Netherlands. Government policy, especially the very late dropping of the Gold Standard, played a role in prolonging the depression. The Great Depression in the Netherlands led to some political instability and riots, and can be linked to the rise of the Dutch national-socialist party NSB. The depression in the Netherlands eased off somewhat at the end of 1936, when the government finally dropped the Gold Standard, but real economic stability did not return until after World War II.
Portugal.
Already under the rule of a dictatorial junta, the Ditadura Nacional, Portugal suffered no turbulent political effects of the Depression, although Antonio de Oliveira Salazar, already appointed Minister of Finance in 1928 greatly expanded his powers and in 1932 rose to Prime Minister of Portugal to found the Estado Novo, an authoritarian corporatist dictatorship. 
With the budget balanced in 1929, the effects of the depression were relaxed through harsh measures towards budget balance and autarky, causing social discontent but stability and, eventually, an impressive economic growth. The regime outlived Salazar himself before overthrown in the Carnation Revolution in 1974, initiating a road towards the restoration of democracy.
South Africa.
As world trade slumped, demand for South African agricultural and mineral exports fell drastically. The Carnegie Commission on Poor Whites had concluded in 1931 that nearly one third of Afrikaners lived as pauper. It is believed that the social discomfort caused by the depression was a contributing factor in the 1933 split between the "gesuiwerde" (purified) and "smelter" (fusionist) factions within the National Party and the National Party's subsequent fusion with the South African Party. Eventually, the gesuiwerde faction of Daniel Malan would go on to form its own party and take over the government after the 1948 election, bringing about the doctrine of apartheid, instituting and extending racial segregation, which would see an end only in 1994.
Soviet Union.
Many Western intellectuals looked upon Soviet Union with sympathy. Jennifer Burns wrote, "As the Great Depression ground on and unemployment soared, intellectuals began unfavorably comparing their faltering capitalist economy to Russian Communism. ... More than ten years after the Revolution, Communism was finally reaching full flower, according to the "New York Times" reporter Walter Duranty, a Stalin fan who vigorously debunked accounts of the Ukraine famine, a man-made disaster that would leave millions dead."
Spain.
Greatly due to impopular economic policies, Prime Minister Jose Primo de Rivera resigned in 1930, followed by the ousting of King Alfonso XIII in the following year. A fragile democracy was established, torn at by economic problems and social discontent, culminating in the divisive general election of 1936 and the subsequent Spanish Civil War, culminating in an authoritarian regime under general Francisco Franco which was gradually disestablished following his death in 1975, with the first elections since Depression held in 1977.
Sweden.
Taking place in the midst of a short-lived government and a less-than-a-decade old Swedish democracy, events such as those surrounding Ivar Kreuger (who eventually committed suicide) remain infamous in Swedish history. Eventually, the Social Democrats under Per Albin Hansson would form their first long-lived government in 1932 based on strong interventionist and welfare state policies, monopolizing the office of Prime Minister until 1976 with the sole and short-lived exception of Axel Pehrsson-Bramstorp's "summer cabinet" in 1936. During forty years of hegemony, it was the most successful political party in the history of Western liberal democracy.
Thailand.
In Thailand, then known as the Kingdom of Siam, the Great Depression contributed to the end of the absolute monarchy of King Rama VII in the Siamese revolution of 1932.
United Kingdom.
The effects on the northern industrial areas of Britain were immediate and devastating, as demand for traditional industrial products collapsed. By the end of 1930 unemployment had more than doubled from 1 million to 2.5 million (20% of the insured workforce), and exports had fallen in value by 50%. In 1933, 30% of Glaswegians were unemployed due to the severe decline in heavy industry. In some towns and cities in the north east, unemployment reached as high as 70% as shipbuilding fell 90%. The National Hunger March of September–October 1932 was the largest of a series of hunger marches in Britain in the 1920s and 1930s. About 200,000 unemployed men were sent to the work camps, which continued in operation until 1939.
In the less industrial Midlands and Southern England, the effects were short-lived and the later 1930s were a prosperous time. Growth in modern manufacture of electrical goods and a boom in the motor car industry was helped by a growing southern population and an expanding middle class. Agriculture also saw a boom during this period.
United States.
President Herbert Hoover started numerous programs, all of which failed to reverse the downturn. In June 1930 Congress approved the Smoot–Hawley Tariff Act which raised tariffs on thousands of imported items. The intent of the Act was to encourage the purchase of American-made products by increasing the cost of imported goods, while raising revenue for the federal government and protecting farmers. Other nations increased tariffs on American-made goods in retaliation, reducing international trade, and worsening the Depression. 
In 1931 Hoover urged the major banks in the country to form a consortium known as the National Credit Corporation (NCC).
By 1932, unemployment had reached 23.6%, and it peaked in early 1933 at 25%, drought persisted in the agricultural heartland, businesses and families defaulted on record numbers of loans, and more than 5,000 banks had failed. Hundreds of thousands of Americans found themselves homeless, and began congregating in shanty towns - dubbed "Hoovervilles" - that began to appear across the country. 
In response, President Hoover and Congress approved the Federal Home Loan Bank Act, to spur new home construction, and reduce foreclosures. The final attempt of the Hoover Administration to stimulate the economy was the passage of the Emergency Relief and Construction Act (ERA) which included funds for public works programs such as dams and the creation of the Reconstruction Finance Corporation (RFC) in 1932. The RFC's initial goal was to provide government-secured loans to financial institutions, railroads and farmers. Quarter by quarter the economy went downhill, as prices, profits and employment fell, leading to the political realignment in 1932 that brought to power Franklin Delano Roosevelt.
Shortly after President Franklin Delano Roosevelt was inaugurated in 1933, drought and erosion combined to cause the Dust Bowl, shifting hundreds of thousands of displaced persons off their farms in the Midwest. From his inauguration onward, Roosevelt argued that restructuring of the economy would be needed to prevent another depression or avoid prolonging the current one. New Deal programs sought to stimulate demand and provide work and relief for the impoverished through increased government spending and the institution of financial reforms. 
The Securities Act of 1933 comprehensively regulated the securities industry. This was followed by the Securities Exchange Act of 1934 which created the Securities and Exchange Commission. Though amended, key provisions of both Acts are still in force. Federal insurance of bank deposits was provided by the FDIC, and the Glass–Steagall Act. The institution of the National Recovery Administration (NRA) remains a controversial act to this day. The NRA made a number of sweeping changes to the American economy until it was deemed unconstitutional by the Supreme Court of the United States in 1935.
These reforms, together with several other relief and recovery measures, are called the First New Deal. Economic stimulus was attempted through a new alphabet soup of agencies set up in 1933 and 1934 and previously extant agencies such as the Reconstruction Finance Corporation. By 1935, the "Second New Deal" added Social Security (which did not start making large payouts until much later), a jobs program for the unemployed (the Works Progress Administration, WPA) and, through the National Labor Relations Board, a strong stimulus to the growth of labor unions. In 1929, federal expenditures constituted only 3% of the GDP. The national debt as a proportion of GNP rose under Hoover from 20% to 40%. Roosevelt kept it at 40% until the war began, when it soared to 128%.
By 1936, the main economic indicators had regained the levels of the late 1920s, except for unemployment, which remained high at 11%, although this was considerably lower than the 25% unemployment rate seen in 1933. In the spring of 1937, American industrial production exceeded that of 1929 and remained level until June 1937. In June 1937, the Roosevelt administration cut spending and increased taxation in an attempt to balance the federal budget.
The American economy then took a sharp downturn, lasting for 13 months through most of 1938. Industrial production fell almost 30 per cent within a few months and production of durable goods fell even faster. Unemployment jumped from 14.3% in 1937 to 19.0% in 1938, rising from 5 million to more than 12 million in early 1938. Manufacturing output fell by 37% from the 1937 peak and was back to 1934 levels. 
Producers reduced their expenditures on durable goods, and inventories declined, but personal income was only 15% lower than it had been at the peak in 1937. As unemployment rose, consumers' expenditures declined, leading to further cutbacks in production. By May 1938 retail sales began to increase, employment improved, and industrial production turned up after June 1938. After the recovery from the Recession of 1937–1938, conservatives were able to form a bipartisan conservative coalition to stop further expansion of the New Deal and, when unemployment dropped to 2% in the early 1940s, they abolished WPA, CCC and the PWA relief programs. Social Security remained in place.
Political consequences.
The crisis had many political consequences, among which was the abandonment of classic economic liberal approaches, which Roosevelt replaced in the U.S. with Keynesian policies. These policies magnified the role of the federal government in the national economy. Between 1933 and 1939, federal expenditure tripled, and Roosevelt's critics charged that he was turning America into a socialist state. The Great Depression was a main factor in the implementation of social democracy and planned economies in European countries after World War II (see Marshall Plan). Although Austrian economists had challenged Keynesianism since the 1920s, it was not until the 1970s, with the influence of Milton Friedman that the Keynesian approach was politically questioned.
Literature.
The Great Depression has been the subject of much writing, as authors have sought to evaluate an era that caused financial as well as emotional trauma. Perhaps the most noteworthy and famous novel written on the subject is "The Grapes of Wrath", published in 1939 and written by John Steinbeck, who was awarded both the Nobel Prize for literature and the Pulitzer Prize for the work. The novel focuses on a poor family of sharecroppers who are forced from their home as drought, economic hardship, and changes in the agricultural industry occur during the Great Depression. Steinbeck's "Of Mice and Men" is another important novel about a journey during the Great Depression. Additionally, Harper Lee's "To Kill a Mockingbird" is set during the Great Depression. Margaret Atwood's Booker prize-winning "The Blind Assassin" is likewise set in the Great Depression, centering on a privileged socialite's love affair with a Marxist revolutionary. The era spurred the resurgence of social realism, practiced by many who started their writing careers on relief programs, especially the Federal Writers' Project in the U.S.
Naming.
The term "The Great Depression" is most frequently attributed to British economist Lionel Robbins, whose 1934 book "The Great Depression" is credited with formalizing the phrase, though Hoover is widely credited with popularizing the term, informally referring to the downturn as a depression, with such uses as "Economic depression cannot be cured by legislative action or executive pronouncement", (December 1930, Message to Congress) and "I need not recount to you that the world is passing through a great depression", (1931).
The term "depression" to refer to an economic downturn dates to the 19th century, when it was used by varied Americans and British politicians and economists. Indeed, the first major American economic crisis, the Panic of 1819, was described by then-president James Monroe as "a depression", and the most recent economic crisis, the Depression of 1920–21, had been referred to as a "depression" by then president Calvin Coolidge. 
Financial crises were traditionally referred to as "panics", most recently the major Panic of 1907, and the minor Panic of 1910–1911, though the 1929 crisis was called "The Crash", and the term "panic" has since fallen out of use. At the time of the Great Depression, the term "The Great Depression" was already used to referred to the period 1873–96 (in the United Kingdom), or more narrowly 1873–79 (in the United States), which has retroactively been renamed the Long Depression.
Other "great depressions".
Other economic downturns have been called a "great depression", but none had been as widespread, or lasted for so long. Various nations have experienced brief or extended periods of economic downturns, which were referred to as "depressions", but none have had such a widespread global impact.
British economic historians used the term "great depression" to describe British conditions in the late 19th century, especially in agriculture, 1873–1896, a period now referred to as the Long Depression.
The fall of communism in the Soviet Union led to a severe economic crisis and catastrophic fall in the standards of living in the 1990s in the former Eastern Bloc, most notably, in post-Soviet states, that was almost twice as intense as the Great Depression had been in the countries of Western Europe and the U.S. in the 1930s. Even before Russia's financial crisis of 1998, Russia's GDP was half of what it had been in the early 1990s, and some populations are still poorer than they were in 1989, including Ukraine, Moldova, Serbia, Central Asia, and the Caucasus.
Some journalists and economists have taken to calling the late-2000s recession the "Great Recession" in allusion to the Great Depression.
Comparison with the late-2000s recession.
The causes of the Great Recession seem similar to the Great Depression, but significant differences exist, also, as discussed in the above sections of this topic. The current chairman of the Fed, Ben Bernanke, had extensively studied the Great Depression as part of his doctoral work at MIT, and is implementing policies to manipulate the money supply and interest rates in ways that were not done in the 1930s. Bernanke's policies will undoubtedly be analyzed and scrutinized in the years to come, as economists debate the wisdom of his choices. Generally speaking, the recovery of the world's financial systems tended to be quicker during the Great Depression of the 1930s as opposed to the late-2000s recession.
1928 and 1929 were the times in the 20th century that the wealth gap reached such skewed extremes; Half the unemployed have been out of work for over six months, something that wasn't repeated until the late-2000s recession. 2007 and 2008 eventually saw the world reach new levels of wealth gap inequality that rivalled the years of 1928 and 1929.

Green Revolution
Green Revolution refers to a series of research, development, and technology transfer initiatives, occurring between the 1940s and the late 1970s, that increased agriculture production around the world, beginning most markedly in the late 1960s.
The initiatives, led by Norman Borlaug, the "Father of the Green Revolution" credited with saving over a billion people from starvation, involved the development of high-yielding varieties of cereal grains, expansion of irrigation infrastructure, modernization of management techniques, distribution of hybridized seeds, synthetic fertilizers, and pesticides to farmers.
The term "Green Revolution" was first used in 1968 by former United States Agency for International Development (USAID) director William Gaud, who noted the spread of the new technologies and said,

History.
The agricultural development that began in Mexico by Norman Borlaug in 1943 (based on Nazareno Strampelli's studies) had been judged as a success and the Rockefeller Foundation sought to spread it to other nations. The Office of Special Studies in Mexico became an informal international research institution in 1959, and in 1963 it formally became CIMMYT, The International Maize and Wheat Improvement Center.
In 1961 India was on the brink of mass famine. Borlaug was invited to India by the adviser to the Indian minister of agriculture M. S. Swaminathan. Despite bureaucratic hurdles imposed by India's grain monopolies, the Ford Foundation and Indian government collaborated to import wheat seed from CIMMYT. Punjab was selected by the Indian government to be the first site to try the new crops because of its reliable water supply and a history of agricultural success. India began its own Green Revolution program of plant breeding, irrigation development, and financing of agrochemicals.
India soon adopted IR8 – a semi-dwarf rice variety developed by the International Rice Research Institute (IRRI) that could produce more grains of rice per plant when grown with certain fertilizers and irrigation. In 1968, Indian agronomist S.K. De Datta published his findings that IR8 rice yielded about 5 tons per hectare with no fertilizer, and almost 10 tons per hectare under optimal conditions. This was 10 times the yield of traditional rice. IR8 was a success throughout Asia, and dubbed the "Miracle Rice". IR8 was also developed into Semi-dwarf IR36.
In the 1960s, rice yields in India were about two tons per hectare; by the mid-1990s, they had risen to six tons per hectare. In the 1970s, rice cost about $550 a ton; in 2001, it cost under $200 a ton. India became one of the world's most successful rice producers, and is now a major rice exporter, shipping nearly 4.5 million tons in 2006.
IR8 and the Philippines.
In 1960, the Government of the Republic of the Philippines with Ford and Rockefeller Foundations established IRRI (International Rice Research Institute). A rice crossing between Dee-Geo-woo-gen and Peta was done at IRRI in 1962. In 1966, one of the breeding lines became a new cultivar, IR8. IR8 required the use of fertilizers and pesticides, but produced substantially higher yields than the traditional cultivars. Annual rice production in the Philippines increased from 3.7 to 7.7 million tons in two decades. The switch to IR8 rice made the Philippines a rice exporter for the first time in the 20th century. But the heavy pesticide use reduced the number of fish and frog species found in rice paddies.
CGIAR.
In 1970, foundation officials proposed a worldwide network of agricultural research centers under a permanent secretariat. This was further supported and developed by the World Bank; on 19 May 1971, the Consultative Group on International Agricultural Research was established, co-sponsored by the FAO, IFAD and UNDP. CGIAR, has added many research centers throughout the world.
CGIAR has responded, at least in part, to criticisms of Green Revolution methodologies. This began in the 1980s, and mainly was a result of pressure from donor organizations. Methods like Agroecosystem Analysis and Farming System Research have been adopted to gain a more holistic view of agriculture. Methods like Rapid Rural Appraisal and Participatory Rural Appraisal have been adopted to help scientists understand the problems faced by farmers and even give farmers a role in the development process.
Problems in Africa.
There have been numerous attempts to introduce the successful concepts from the Mexican and Indian projects into Africa. These programs have generally been less successful. Reasons cited include widespread corruption, insecurity, a lack of infrastructure, and a general lack of will on the part of the governments. Yet environmental factors, such as the availability of water for irrigation, the high diversity in slope and soil types in one given area are also reasons why the Green Revolution is not so successful in Africa.
A recent program in western Africa is attempting to introduce a new high-yield variety of rice known as "New Rice for Africa" (NERICA). NERICAs yield about 30% more rice under normal conditions, and can double yields with small amounts of fertilizer and very basic irrigation. However the program has been beset by problems getting the rice into the hands of farmers, and to date the only success has been in Guinea where it currently accounts for 16% of rice cultivation.
After a famine in 2001 and years of chronic hunger and poverty, in 2005 the small African country of Malawi launched the "Agricultural Input Subsidy Program" by which vouchers are given to smallholder farmers to buy subsidized nitrogen fertilizer and maize seeds. Within its first year, the program was reported with extreme success, producing the largest maize harvest of the country's history; enough to feed the country with tons of maize left over. The program has advanced yearly ever since. Various sources claim that the program has been an unusual success, hailing it as a "miracle".
Agricultural production and food security.
Technologies.
The Green Revolution spread technologies that had already existed before, but had not been widely used outside industrialized nations. These technologies included modern irrigation projects, pesticides, synthetic nitrogen fertilizer and improved crop varieties developed through the conventional, science-based methods available at the time.
The novel technological development of the Green Revolution was the production of novel wheat cultivars. Agronomists bred cultivars of maize, wheat, and rice that are generally referred to as HYVs or “high-yielding varieties”. HYVs have higher nitrogen-absorbing potential than other varieties. Since cereals that absorbed extra nitrogen would typically lodge, or fall over before harvest, semi-dwarfing genes were bred into their genomes. A Japanese dwarf wheat cultivar (Norin 10 wheat), which was sent to Washington, D.C. by Cecil Salmon, was instrumental in developing Green Revolution wheat cultivars. IR8, the first widely implemented HYV rice to be developed by IRRI, was created through a cross between an Indonesian variety named “Peta” and a Chinese variety named “Dee-geo-woo-gen.”
With advances in molecular genetics, the mutant genes responsible for "Arabidopsis thaliana" genes (GA 20-oxidase, "ga1", "ga1-3"), wheat reduced-height genes ("Rht") and a rice semidwarf gene ("sd1") were cloned. These were identified as gibberellin biosynthesis genes or cellular signaling component genes. Stem growth in the mutant background is significantly reduced leading to the dwarf phenotype. Photosynthetic investment in the stem is reduced dramatically as the shorter plants are inherently more stable mechanically. Assimilates become redirected to grain production, amplifying in particular the effect of chemical fertilizers on commercial yield.
HYVs significantly outperform traditional varieties in the presence of adequate irrigation, pesticides, and fertilizers. In the absence of these inputs, traditional varieties may outperform HYVs. Therefore, several authors have challenged the apparent superiority of HYVs not only compared to the traditional varieties alone, but by contrasting the monocultural system associated with HYVs with the polycultural system associated with traditional ones.
Production increases.
Cereal production more than doubled in developing nations between the years 1961–1985. Yields of rice, maize, and wheat increased steadily during that period. The production increases can be attributed roughly equally to irrigation, fertilizer, and seed development, at least in the case of Asian rice.
While agricultural output increased as a result of the Green Revolution, the energy input to produce a crop has increased faster, so that the ratio of crops produced to energy input has decreased over time. Green Revolution techniques also heavily rely on chemical fertilizers, pesticides and herbicides, some of which must be developed from fossil fuels, making agriculture increasingly reliant on petroleum products. Proponents of the Peak Oil theory fear that a future decline in oil and gas production would lead to a decline in food production or even a Malthusian catastrophe.
Effects on food security.
The effects of the Green Revolution on global food security are difficult to assess because of the complexities involved in food systems.
The world population has grown by about four billion since the beginning of the Green Revolution and many believe that, without the Revolution, there would have been greater famine and malnutrition. India saw annual wheat production rise from 10 million tons in the 1960s to 73 million in 2006. The average person in the developing world consumes roughly 25% more calories per day now than before the Green Revolution. Between 1950 and 1984, as the Green Revolution transformed agriculture around the globe, world grain production increased by over 250%.
The production increases fostered by the Green Revolution are often credited with having helped to avoid widespread famine, and for feeding billions of people.
There are also claims that the Green Revolution has decreased food security for a large number of people. One claim involves the shift of subsistence-oriented cropland to cropland oriented towards production of grain for export or animal feed. For example, the Green Revolution replaced much of the land used for pulses that fed Indian peasants for wheat, which did not make up a large portion of the peasant diet.
Criticism.
Food security.
Malthusian criticism.
Some criticisms generally involve some variation of the Malthusian principle of population. Such concerns often revolve around the idea that the Green Revolution is unsustainable, and argue that humanity is now in a state of overpopulation with regards to the sustainable carrying capacity and ecological demands on the Earth.
Although 36 million people die each year as a direct or indirect result of hunger and poor nutrition, Malthus' more extreme predictions have frequently failed to materialize. In 1798 Thomas Malthus made his prediction of impending famine. The world's population had doubled by 1923 and doubled again by 1973 without fulfilling Malthus' prediction. Malthusian Paul R. Ehrlich, in his 1968 book "The Population Bomb", said that "India couldn't possibly feed two hundred million more people by 1980" and "Hundreds of millions of people will starve to death in spite of any crash programs." Ehrlich's warnings failed to materialize when India became self-sustaining in cereal production in 1974 (six years later) as a result of the introduction of Norman Borlaug's dwarf wheat varieties.
Since supplies of oil and gas are essential to modern agriculture techniques, a fall in global oil supplies could cause spiking food prices in the coming decades.
Famine.
To some modern Western sociologists and writers, increasing food production is not synonymous with increasing food security, and is only part of a larger equation. For example, Harvard professor Amartya Sen claimed large historic famines were not caused by decreases in food supply, but by socioeconomic dynamics and a failure of public action. However, economist Peter Bowbrick disputes Sen's theory, arguing that Sen relies on inconsistent arguments and contradicts available information, including sources that Sen himself cited. Bowbrick further argues that Sen's views coincide with that of the Bengal government at the time of the Bengal famine of 1943, and the policies Sen advocates failed to relieve the famine.
Quality of diet.
Some have challenged the value of the increased food production of Green Revolution agriculture. Miguel A. Altieri, (a pioneer of agroecology and peasant-advocate), writes that the comparison between traditional systems of agriculture and Green Revolution agriculture has been unfair, because Green Revolution agriculture produces monocultures of cereal grains, while traditional agriculture usually incorporates polycultures.
These monoculture crops are often used for export, feed for animals, or conversion into biofuel. According to Emile Frison of Bioversity International, the Green Revolution has also led to a change in dietary habits, as fewer people are affected by hunger and die from starvation, but many are affected by malnutrition such as iron or vitamin-A deficiencies. Frison further asserts that almost 60% of yearly deaths of children under age five in developing countries are related to malnutrition.
High-yield rice (HYR), introduced since 1964 to poverty-ridden Asian countries, such as the Philippines, was found to have inferior flavor and be more glutinous and less savory than their native varieties. This caused its price to be lower than the average market value.
In the Philippines the introduction of heavy pesticides to rice production, in the early part of the Green Revolution, poisoned and killed off fish and weedy green vegetables that traditionally coexisted in rice paddies. These were nutritious food sources for many poor Filipino farmers prior to the introduction of pesticides, further impacting the diets of locals.
Political impact.
The primary objective of the program was geopolitical: to provide food for the populace in undeveloped countries and so bring social stability and weaken the fomenting of communist insurgency.
Citing internal Foundation documents, Dowie states that the Ford Foundation had a greater concern than Rockefeller in this area.
There is significant evidence that the Green Revolution weakened socialist movements in many nations. In countries such as India, Mexico, and the Philippines, "technological solutions" were sought as an alternative to expanding "agrarian reform" initiatives, the latter of which were often linked to socialist politics.
Socioeconomic impacts.
The transition from traditional agriculture, in which inputs were generated on-farm, to Green Revolution agriculture, which required the purchase of inputs, led to the widespread establishment of rural credit institutions. Smaller farmers often went into debt, which in many cases results in a loss of their farmland. The increased level of mechanization on larger farms made possible by the Green Revolution removed a large source of employment from the rural economy. Because wealthier farmers had better access to credit and land, the Green Revolution increased class disparities, with the rich–poor gap widening as a result. Because some regions were able to adopt Green Revolution agriculture more readily than others (for political or geographical reasons), interregional economic disparities increased as well. Many small farmers are hurt by the dropping prices resulting from increased production overall. However, large-scale farming companies only account for less than 10% of the total farming capacity.
The new economic difficulties of small holder farmers and landless farm workers led to increased rural-urban migration. The increase in food production led to a cheaper food for urban dwellers, and the increase in urban population increased the potential for industrialization.
Globalization.
In the most basic sense, the Green Revolution was a product of globalization as evidenced in the creation of international agricultural research centers that shared information, and with transnational funding from groups like the Rockefeller Foundation, Ford Foundation, and United States Agency for International Development (USAID). Additionally, the inputs required in Green Revolution agriculture created new markets for seed and chemical corporations, many of which were based in the United States. For example, Standard Oil of New Jersey established hundreds of distributors in the Philippines to sell agricultural packages composed of HYV seed, fertilizer, and pesticides.
Environmental impact.
Pesticides.
Green Revolution agriculture relies on extensive use of pesticides, which are necessary to limit the high levels of pest damage that inevitably occur in monocropping – the practice of producing or growing one single crop over a wide area.
Biodiversity.
The spread of Green Revolution agriculture affected both agricultural biodiversity and wild biodiversity. There is little disagreement that the Green Revolution acted to reduce agricultural biodiversity, as it relied on just a few high-yield varieties of each crop.
This has led to concerns about the susceptibility of a food supply to pathogens that cannot be controlled by agrochemicals, as well as the permanent loss of many valuable genetic traits bred into traditional varieties over thousands of years. To address these concerns, massive seed banks such as Consultative Group on International Agricultural Research’s (CGIAR) International Plant Genetic Resources Institute (now Bioversity International) have been established (see Svalbard Global Seed Vault).
There are varying opinions about the effect of the Green Revolution on wild biodiversity. One hypothesis speculates that by increasing production per unit of land area, agriculture will not need to expand into new, uncultivated areas to feed a growing human population. However, land degradation and soil nutrients depletion have forced farmers to clear up formerly forested areas in order to keep up with production. A counter-hypothesis speculates that biodiversity was sacrificed because traditional systems of agriculture that were displaced sometimes incorporated practices to preserve wild biodiversity, and because the Green Revolution expanded agricultural development into new areas where it was once unprofitable or too arid. For example, the development of wheat varieties tolerant to acid soil conditions with high aluminium content, permitted the introduction of agriculture in sensitive Brazilian ecosystems as Cerrado semi-humid tropical savanna and Amazon rainforest in the geoeconomic macroregions of Centro-Sul and Amazônia. Before the Green Revolution, other Brazilian ecosystems were also significantly damaged by human activity, such as the once 1st or 2nd main contributor to Brazilian megadiversity Atlantic Rainforest (above 85% of deforestation in the 1980s, about 95% after 2010s) and the important xeric shrublands called Caatinga mainly in the Northeastern Brazil (about 40% in the 1980s, about 50% after 2010s — deforestation of the Caatinga biome is generally associated with greater risks of desertification).
Nevertheless, the world community has clearly acknowledged the negative aspects of agricultural expansion as the 1992 Rio Treaty, signed by 189 nations, has generated numerous national Biodiversity Action Plans which assign significant biodiversity loss to agriculture's expansion into new domains.
Health impact.
The consumption of the pesticides used to kill pests by humans in some cases may be increasing the likelihood of cancer in some of the rural villages using them. Poor farming practices including non-compliance to usage of masks and over-usage of the chemicals compound this situation. In 1989, WHO and UNEP estimated that there were around 1 million human pesticide poisonings annually. Some 20,000 (mostly in developing countries) ended in death, as a result of poor labeling, loose safety standards etc.
Pesticides and cancer.
Long term exposure to pesticides such as organochlorines, creosote, and sulfate have been correlated with higher cancer rates and organochlorines DDT, chlordane, and lindane as tumor promoters in animals. Contradictory epidemiologic studies in humans have linked phenoxy acid herbicides or contaminants in them with soft tissue sarcoma (STS) and malignant lymphoma, organochlorine insecticides with STS, non-Hodgkin's lymphoma (NHL), leukemia, and, less consistently, with cancers of the lung and breast, organophosphorous compounds with NHL and leukemia, and triazine herbicides with ovarian cancer.
Punjab case.
The Indian state of Punjab pioneered green revolution among the other states transforming India into a food-surplus country. The state is witnessing serious consequences of intensive farming using chemicals and pesticide. A comprehensive study conducted by Post Graduate Institute of Medical Education and Research (PGIMER) has underlined the direct relationship between indiscriminate use of these chemicals and increased incidence of cancer in this region. An increase in the number of cancer cases has been reported in several villages including Jhariwala, Koharwala, Puckka, Bhimawali, and Khara.
Environmental activist Vandana Shiva has written extensively about the social, political and economic impacts of the Green Revolution in Punjab. She claims that the Green Revolution's reliance on heavy use of chemical inputs and monocultures has resulted in water scarcity, vulnerability to pests, and incidents of violent conflict and social marginalization.
In 2009, under a Greenpeace Research Laboratories investigation, Dr Reyes Tirado, from the University of Exeter, UK conducted the study in 50 villages in Muktsar, Bathinda and Ludhiana districts revealed chemical, radiation and biological toxicity rampant in Punjab. Twenty percent of the sampled wells showed nitrate levels above the safety limit of 50 mg/l, established by WHO, the study connected it with high use of synthetic nitrogen fertilizers. With increasing poisoning of the soil, the region once hailed as the home to the Green Revolution, now due to excessive use of chemical fertilizer, is being termed by one columnist as the "Other Bhopal".
Organic farming.
About four decades after the Green Revolution widely helped the world to be able to produce food in sufficient levels, a small percentage of farmers in India have chosen to employ organic farming methods in response to side effects from their adoption of modern agriculture techniques.
Norman Borlaug's response to criticism.



Heimatvertriebene
Heimatvertriebene (German for "expellees", literally "homeland displaced person") are those around 12 million German citizens (no matter of which ethnicity) and ethnic Germans (no matter of which citizenship) who fled or were expelled after World War II from parts of Germany annexed by Poland and the Soviet Union (today Russia), and from other countries (the so-called einheitliches Vertreibungsgebiet; i.e. uniform territory of expulsion), who found refuge in both West and East Germany, and Austria. Refugees who had fled voluntarily but were later refused permission to return are often not distinguished from those who were forcibly deported. By the definition of the West German Federal Expellee Law, enacted on 19 May 1953, refugees of German citizenship or German ethnicity, whose return to their home places was denied, were treated like expellees, thus the frequent general usage of the term expellees for refugees alike. 
Distinguished are refugees and expellees who had neither German citizenship nor German ethnicity but as a matter of fact had fled or been expelled from their former domiciles and stranded in West Germany or West Berlin before 1951. They were taken care of – as part of the displaced persons – by international refugee organisations until 1951 and then by West German authorities granting them the extra status of heimatloser Ausländer with preferential naturalisation rules, distinct from other legal aliens or stateless people. Occupational functionaries and other German expatriates, who had moved to German-annexed or German-occupied foreign territory only due to the war were not considered expellees by law unless they showed circumstances (such as marrying a resident of the respective area) providing for the intention to settle abroad also for the time after the war. Besides the narrow legal definition for the Heimatvertriebene, there were also other groups accepted as Vertriebene (expellees) such as the Aussiedler. These comprised refugees and emigrants either originally of foreign citizenship but of German ethnicity, or who themselves or whose ancestors had involuntarily lost German citizenship, coming from the above-mentioned uniform territory of expulsion or from Albania, Bulgaria, China, Romania, the Soviet Union, or Yugoslavia, and arriving only after the end of general expulsions but not later as 31 December 1992. 
In a document signed in 1950 the "Heimatvertriebene" organisations recognised the plight of the different groups of people living in today's Poland who were resettled there by force. The Heimatvertriebene are just one (but by far the largest) of the groups of millions of other people, from many different countries, who all found refuge in today's Germany.
Some of the expellees are active in politics and belong to the political right wing. Many others do not belong to any organizations, but they continue to maintain what they call a lawful right to their homeland. The vast majority pledged to work peacefully towards that goal while rebuilding post-war Germany and Europe.
The expellees are still highly active in German politics, and are one of the major social groups of the nation, with around 2 million members. The president of the Federation of Expellees is a member of the Bundestag.
Although expellees and their descendants were active in West German politics, the prevailing political climate within West Germany was that of atonement for Nazi actions. However the CDU governments have shown considerable support for the expellees and German civilian victims.
Expellee towns.
As a result of the huge influx of expellees, there was a massive increase of population in some areas such as Mecklenburg (where population numbers doubled), and in some places the previous homogeneity of the population was broken by Protestant expellees moving to a purely Catholic area or conversely. The population numbers of a number of small settlements in West Germany exploded permanently due to a refugee camp on their territory or nearby. Examples of this phenomenon include "Neugablonz", a quarter of Kaufbeuren in Bavaria, founded by the expellees and named after Gablonz (Jablonec nad Nisou). Neugablonz nowadays makes up a third of the town's population. An extreme example of the population explosion is Neutraubling (also in Bavaria), which had 53 inhabitants in 1947, 1300 in 1951, and 3800 in 1960. Since the refugee camps were mostly located on the sites of former hidden ammunition factories, most of these "Vertriebenenstädte" are located in a (former) forest. See also Espelkamp. 

Soviet Union
The Union of Soviet Socialist Republics () abbreviated to USSR () or the Soviet Union (), was a constitutionally socialist state that existed between 1922 and 1991, ruled as a single-party state by the Communist Party with its capital as Moscow.William Roseberry (1997) "Marx and Anthropology" Annual Review of Anthropology, Vol. 26: pp. 25–46 (October 1997)  A union of 15 subnational Soviet republics, its government and economy were highly centralised.
The Soviet Union had its roots in the Russian Revolution of 1917, which deposed Nicholas II, ending three hundred years of Romanov dynastic rule. The Bolsheviks, led by Vladimir Lenin, stormed the Winter Palace in Petrograd and overthrew the Provisional Government. The Russian Socialist Federative Soviet Republic was established and a civil war began. The Red Army entered several territories of the former Russian Empire and helped local communists seize power. In 1922, the Bolsheviks were victorious, forming the Soviet Union with the unification of the Russian, Transcaucasian, Ukrainian and Byelorussian republics. Following Lenin's death in 1924, a troika collective leadership and a brief power struggle, Joseph Stalin came to power in the late 1920s. Stalin committed the state ideology to Marxism–Leninism and a centralised planned economy was initiated. As a result, the country underwent a period of rapid industrialisation and collectivisation which laid the basis for its later war effort and dominance after World War II. However, Stalin repressed both Communist Party members and elements of the population through his authoritarian rule.
During World War II, Nazi Germany invaded the Soviet Union in 1941, opening the largest and bloodiest theatre of war in history and violating an earlier non-aggression pact between the two countries. The Soviet Union suffered the largest loss of life in the war, but halted the Axis advance at intense battles such as at Stalingrad, eventually driving through Eastern Europe and capturing Berlin in 1945. Having played the decisive role in the Allied victory in Europe, the Soviet Union consequently occupied much of Central and Eastern Europe and emerged as one of the world's two superpowers after the war. Together with these new socialist satellite states, through which it established economic and military pacts, it became involved in the Cold War, a prolonged ideological and political struggle against the Western Bloc led by the other superpower, the United States.
A de-Stalinisation period followed Stalin's death, reducing the harshest aspects of society. The Soviet Union then went on to initiate significant technological achievements of the 20th century, including launching the first ever satellite and world's first human spaceflight, which led it into the Space Race. The Cuban Missile Crisis in 1962 marked a period of extreme tension between the two superpowers, considered the closest to a mutual nuclear confrontation. In the 1970s, a relaxation of relations followed, but tensions resumed when, after a Communist-led revolution in Afghanistan, Soviet forces entered the country by request of the new regime. The occupation drained economic resources and dragged on without achieving meaningful political results. 
In the late 1980s the last Soviet leader, Mikhail Gorbachev, sought reforms in the Union, introducing the policies of "glasnost" and "perestroika" in an attempt to end the period of economic stagnation and democratize the government. However, this led to the rise of strong nationalist and separatist movements. By 1991, the country was in turmoil as the Baltic republics began to secede. A referendum resulted in the vast majority of participating citizens voting in favour of preserving the Union as a renewed federation. In August 1991, a coup d'état attempt by hardliners against Gorbachev and aimed at preserving the country, instead led to its collapse. On 25 December 1991, the USSR was dissolved into 15 post-Soviet states. The Russian Federation, successor of the Russian SFSR, assumed the Soviet Union's rights and obligations and is recognised as its continued legal personality.
Geography, climate and environment.
With an area of , the Soviet Union was the world's largest state, a status that is retained by the Russian Federation. Covering a sixth of the Earth's land surface, its size was comparable to that of North America. The European portion accounted for a quarter of the country's area, and was the cultural and economic center. The eastern part in Asia extended to the Pacific Ocean to the east and Afghanistan to the south, and was much less populous. It spanned over east to west across 11 time zones, and over north to south. It had five climate zones: tundra, taiga, steppes, desert, and mountains.
The Soviet Union had the world's longest border, measuring over , two-thirds of it a coastline of the Arctic Ocean. Across the Bering Strait was the United States. The Soviet Union bordered Afghanistan, China, Czechoslovakia, Finland, Hungary, Iran, Mongolia, North Korea, Norway, Poland, Romania, and Turkey from 1945 to 1991.
The Soviet Union's highest mountain was the Communism Peak (now Ismail Samani Peak) in Tajikistan, at . The longest river of the Soviet Union was the Irtysh. The Soviet Union also included the world's largest lake, the Caspian Sea, and the world's largest freshwater and deepest lake, Lake Baikal.
History.
The last Russian Tsar, Nicholas II, ruled the Russian Empire until his abdication in March 1917, due in part to the strain of fighting in World War I. A short-lived Russian provisional government took power, to be overthrown in the 1917 October Revolution (N.S. November 1917) by revolutionaries led by the Bolshevik leader Vladimir Lenin.
The Soviet Union was officially established in December 1922 with the union of the Russian, Ukrainian, Byelorussian, and Transcaucasian Soviet republics- each ruled by local Bolshevik parties. Despite the foundation of the Soviet state as a federative entity of many constituent republics, each with its own political and administrative entities, the term "Soviet Russia"strictly applicable only to the Russian Federative Socialist Republicwas often applied to the entire country by non-Soviet writers and politicians.
Revolution and foundation.
Modern revolutionary activity in the Russian Empire began with the Decembrist Revolt of 1825. Although serfdom was abolished in 1861, it was done on terms unfavourable to the peasants and served to encourage revolutionaries. A parliament—the State Duma—was established in 1906 after the Russian Revolution of 1905, but the Tsar resisted attempts to move from absolute to constitutional monarchy. Social unrest continued and was aggravated during World War I by military defeat and food shortages in major cities.
A spontaneous popular uprising in Petrograd, in response to the wartime decay of Russia's economy and morale, culminated in the February Revolution and the toppling of the imperial government in March 1917. The tsarist autocracy was replaced by the Russian Provisional Government, which intended to conduct elections to the Russian Constituent Assembly and to continue fighting on the side of the Entente in World War I.
At the same time, workers' councils, known as Soviets, sprang up across the country. The Bolsheviks, led by Vladimir Lenin, pushed for socialist revolution in the Soviets and on the streets. On 7 November 1917, the Red Guards stormed the Winter Palace in Petrograd, ending the rule of the Provisional Government and leaving all political power to the Soviets. This event would later be known as the Great October Socialist Revolution. In December, the Bolsheviks signed an armistice with the Central Powers, though by February 1918, fighting had resumed. In March, the Soviets ended involvement the war for good and signed the Treaty of Brest-Litovsk.
A long and bloody Civil War ensued between the Reds and the Whites, starting in 1917 and ending in 1923 with the Reds' victory. It included foreign intervention, the execution of Nicholas II and his family, and the famine of 1921, which killed about five million. In March 1921, during a related conflict with Poland, the Peace of Riga was signed, splitting disputed territories in Belarus and Ukraine between the Republic of Poland and Soviet Russia. The Soviet Union had to resolve similar conflicts with the newly established Republic of Finland, the Republic of Estonia, the Republic of Latvia, and the Republic of Lithuania.
Unification of republics.
On 28 December 1922, a conference of plenipotentiary delegations from the Russian SFSR, the Transcaucasian SFSR, the Ukrainian SSR and the Byelorussian SSR approved the Treaty of Creation of the USSR and the Declaration of the Creation of the USSR, forming the Union of Soviet Socialist Republics. These two documents were confirmed by the 1st Congress of Soviets of the USSR and signed by the heads of the delegations, Mikhail Kalinin, Mikha Tskhakaya, Mikhail Frunze, Grigory Petrovsky, and Aleksandr Chervyakov, on 30 December 1922.
On 1 February 1924, the USSR was recognized by the British Empire. The same year, a Soviet Constitution was approved, legitimizing the December 1922 union.
An intensive restructuring of the economy, industry and politics of the country began in the early days of Soviet power in 1917. A large part of this was done according to the Bolshevik Initial Decrees, government documents signed by Vladimir Lenin. One of the most prominent breakthroughs was the GOELRO plan, which envisioned a major restructuring of the Soviet economy based on total electrification of the country. The plan was developed in 1920 and covered a 10-to 15-year period. It included construction of a network of 30 regional power plants, including ten large hydroelectric power plants, and numerous electric-powered large industrial enterprises. The plan became the prototype for subsequent Five-Year Plans and was fulfilled by 1931.
Stalin era.
From its creation, the government in the Soviet Union was based on the one-party rule of the Communist Party (Bolsheviks). After the economic policy of "War Communism" during the Russian Civil War, as a prelude to fully developing socialism in the country, the Soviet government permitted some private enterprise to coexist alongside nationalized industry in the 1920s and total food requisition in the countryside was replaced by a food tax (see New Economic Policy).
The stated purpose of the one-party state was to ensure that capitalist exploitation would not return to the Soviet Union and that the principles of Democratic Centralism would be most effective in representing the people's will in a practical manner. Debate over the future of the economy provided the background for a power struggle in the years after Lenin's death in 1924. Initially, Lenin was to be replaced by a "troika" consisting of Grigory Zinoviev of Ukraine, Lev Kamenev of Moscow, and Joseph Stalin of Georgia.
On 3 April 1922, Stalin was named the General Secretary of the Communist Party of the Soviet Union. Lenin had appointed Stalin the head of the Workers' and Peasants' Inspectorate, which gave Stalin considerable power. By gradually consolidating his influence and isolating and outmaneuvering his rivals within the party, Stalin became the undisputed leader of the Soviet Union and, by the end of the 1920s, established totalitarian rule. In October 1927, Grigory Zinoviev and Leon Trotsky were expelled from the Central Committee and forced into exile.
In 1928, Stalin introduced the First Five-Year Plan for building a socialist economy. While encompassing the internationalism expressed by Lenin throughout the Revolution, it also aimed to build socialism in one country. In industry, the state assumed control over all existing enterprises and undertook an intensive program of industrialization. In agriculture, rather than adhering to the "lead by example" policy advocated by Lenin, forced collectivisation of farms was implemented all over the country.
Famines ensued, causing millions of deaths; surviving kulaks were persecuted and many sent to Gulags to do forced labour. Social upheaval continued in the mid-1930s. Stalin's Great Purge resulted in the execution or detainment of many "Old Bolsheviks" who had participated in the October Revolution with Lenin. According to declassified Soviet archives, in 1937 and 1938, the NKVD arrested more than one and a half million people, of whom 681,692 were shot – an average of 1,000 executions a day. The excess deaths during the 1930s as a whole were in the range of 10–11 million. Yet despite the turmoil of the mid-to-late 1930s, the Soviet Union developed a powerful industrial economy in the years before World War II.
1930s.
The early 1930s saw closer cooperation between the West and the USSR. From 1932 to 1934, the Soviet Union participated in the World Disarmament Conference. In 1933, diplomatic relations between the United States and the USSR were established. In September 1934, the Soviet Union joined the League of Nations. After the Spanish Civil War broke out in 1936, the USSR actively supported the Republican forces against the Nationalists, who were supported by Fascist Italy and Nazi Germany.
In December 1936, Stalin unveiled a new Soviet Constitution. The constitution was seen as a personal triumph for Stalin, who on this occasion was described by "Pravda" as a "genius of the new world, the wisest man of the epoch, the great leader of communism." By contrast, Western historians and historians from former Soviet occupied countries have viewed the constitution as a meaningless propaganda document.
The late 1930s saw a shift towards the Axis powers. In 1938, after the United Kingdom and France had concluded the Munich Agreement with Germany, the USSR dealt with the Nazis as well, both militarily and economically during extensive talks. The two countries concluded the German–Soviet Nonaggression Pact and the German–Soviet Commercial Agreement. The nonaggression pact made possible Soviet occupation of Lithuania, Latvia, Estonia, Bessarabia, northern Bukovina, and eastern Poland. In late November of the same year, unable to coerce the Republic of Finland by diplomatic means into moving its border back from Leningrad, Joseph Stalin ordered the invasion of Finland.
In the east, the Soviet military won several decisive victories during border clashes with the Japanese Empire in 1938 and 1939. However, in April 1941, USSR signed the Soviet–Japanese Neutrality Pact with the Empire of Japan, recognizing the territorial integrity of Manchukuo, a Japanese puppet state.
World War II.
Although it has been debated whether the Soviet Union intended to invade Germany once it was strong enough, Germany itself broke the treaty and invaded the Soviet Union on 22 June 1941, starting what was known in the USSR as the "Great Patriotic War". The Red Army stopped the seemingly invincible German Army at the Battle of Moscow, aided by an unusually harsh winter. The Battle of Stalingrad, which lasted from late 1942 to early 1943, dealt a severe blow to the Germans from which they never fully recovered and became a turning point in the war. After Stalingrad, Soviet forces drove through Eastern Europe to Berlin before Germany surrendered in 1945. The German Army suffered 80% of its military deaths in the Eastern Front.
The same year, the USSR, in fulfillment of its agreement with the Allies at the Yalta Conference, denounced the Soviet–Japanese Neutrality Pact in April 1945 and invaded Manchukuo and other Japan-controlled territories on 9 August 1945. This conflict ended with a decisive Soviet victory, contributing to the unconditional surrender of Japan and the end of World War II.
The Soviet Union suffered greatly in the war, losing around 27 million people. Despite this, it emerged as a superpower in the post-war period. Once denied diplomatic recognition by the Western world, the Soviet Union had official relations with practically every nation by the late 1940s. A member of the United Nations at its foundation in 1945, the Soviet Union became one of the five permanent members of the UN Security Council, which gave it the right to veto any of its resolutions (see Soviet Union and the United Nations).
The Soviet Union maintained its status as one of the world's two superpowers for four decades through its hegemony in Eastern Europe, military strength, economic strength, aid to developing countries, and scientific research, especially in space technology and weaponry.
Cold War.
During the immediate postwar period, the Soviet Union rebuilt and expanded its economy, while maintaining its strictly centralized control. It aided post-war reconstruction in the countries of Eastern Europe, while turning them into satellite states, binding them in a military alliance (the Warsaw Pact) in 1955, and an economic organization (The Council for Mutual Economic Assistance or Comecon) from 1949 to 1991, the latter a counterpart to the European Economic Community. Later, the Comecon supplied aid to the eventually victorious Chinese Communist Party, and saw its influence grow elsewhere in the world. Fearing its ambitions, the Soviet Union's wartime allies, the United Kingdom and the United States, became its enemies. In the ensuing Cold War, the two sides clashed indirectly using mostly proxies.
Khrushchev era.
Stalin died on 5 March 1953. Without a mutually agreeable successor, the highest Communist Party officials opted to rule the Soviet Union jointly. Nikita Khrushchev, who had won the power struggle by the mid-1950s, denounced Stalin's use of repression in 1956 and eased repressive controls over party and society. This was known as de-Stalinization.
Moscow considered Eastern Europe to be a buffer zone for the forward defense of its western borders, and ensured its control of the region by transforming the Eastern European countries into satellite states. Soviet military force was used to suppress anti-communist uprisings in Hungary and Poland in 1956.
In the late 1950s, a confrontation with China regarding the USSR's rapprochement with the West and what Mao Zedong perceived as Khrushchev's revisionism led to the Sino–Soviet split. This resulted in a break throughout the global Communist movement, with Communist regimes in Albania, Cambodia and Somalia choosing to ally with China in place of the USSR.
During this period, the Soviet Union continued to realize scientific and technological exploits: Launching the first artificial satellite, Sputnik 1 in 1957; a living dog, Laika in 1957; the first human being, Yuri Gagarin in 1961; the first woman in space, Valentina Tereshkova in 1963; Alexey Leonov, the first person to walk in space in 1965; the first soft landing on moon by spacecraft Luna 9 in 1966 and the first moon rovers, Lunokhod 1 and Lunokhod 2.
Khrushchev initiated "The Thaw" better known as Khrushchev's Thaw, a complex shift in political, cultural and economic life in the Soviet Union. That included some openness and contact with other nations and new social and economic policies with more emphasis on commodity goods, allowing living standards to rise dramatically while maintaining high levels of economic growth. Censorship was relaxed as well.
Khrushchev's reforms in agriculture and administration, however, were generally unproductive. In 1962, he precipitated a crisis with the United States over the Soviet deployment of nuclear missiles in Cuba. The Soviet Union backed down after the United States initiated a naval blockade, causing Khrushchev much embarrassment and loss of prestige. He was removed from power in 1964.
Brezhnev era.
Following the ousting of Khrushchev, another period of collective leadership ensued, consisting of Leonid Brezhnev as General Secretary, Alexei Kosygin as Premier and Nikolai Podgorny as Chairman of the Presidium, lasting until Brezhnev established himself in the early 1970s as the preeminent Soviet leader. In 1968 the Soviet Union and its Warsaw Pact allies invaded Czechoslovakia to halt the Prague Spring reforms.
Brezhnev presided over a period of "détente" with the West (see SALT I, SALT II, Anti-Ballistic Missile Treaty) while at the same time building up Soviet military might.
In October 1977, the third Soviet Constitution was unanimously adopted. The prevailing mood of the Soviet leadership at the time of Brezhnev's death in 1982 was one of aversion to change. The long period of Brezhnev's rule had come to be dubbed one of "standstill", with an aging and ossified top political leadership.
Reforms and dissolution.
Two developments dominated the decade that followed: the increasingly apparent crumbling of the Soviet Union's economic and political structures, and the patchwork attempts at reforms to reverse that process. Kenneth S. Deffeyes argued in "Beyond Oil" that the Reagan administration encouraged Saudi Arabia to lower the price of oil to the point where the Soviets could not make a profit selling their oil, so that the USSR's hard currency reserves became depleted.
Brezhnev's next two successors, transitional figures with deep roots in his tradition, did not last long. Yuri Andropov was 68 years old and Konstantin Chernenko 72 when they assumed power; both died in less than two years. In an attempt to avoid a third short-lived leader, in 1985, the Soviets turned to the next generation and selected Mikhail Gorbachev.
Gorbachev made significant changes in the economy and party leadership, called "perestroika". His policy of "glasnost" freed public access to information after decades of heavy government censorship.
Gorbachev also moved to end the Cold War. In 1988, the Soviet Union abandoned its nine-year war in Afghanistan and began to withdraw its forces. In the late 1980s, he refused military support to the Soviet Union's former satellite states, resulting in the toppling of multiple communist regimes. With the tearing down of the Berlin Wall and with East Germany and West Germany pursuing unification, the Iron Curtain came down.
In the late 1980s, the constituent republics of the Soviet Union started legal moves towards potentially declaring sovereignty over their territories, citing Article 72 of the USSR constitution, which stated that any constituent republic was free to secede. On 7 April 1990, a law was passed allowing a republic to secede if more than two-thirds of its residents voted for it in a referendum. Many held their first free elections in the Soviet era for their own national legislatures in 1990. Many of these legislatures proceeded to produce legislation contradicting the Union laws in what was known as the "War of Laws".
In 1989, the Russian SFSR, which was then the largest constituent republic (with about half of the population) convened a newly elected Congress of People's Deputies. Boris Yeltsin was elected its chairman. On 12 June 1990, the Congress declared Russia's sovereignty over its territory and proceeded to pass laws that attempted to supersede some of the USSR's laws. The period of legal uncertainty continued throughout 1991 as constituent republics slowly became de facto independent.
A referendum for the preservation of the USSR was held on 17 March 1991, with the majority of the population voting for preservation of the Union in nine out of the 15 republics. The referendum gave Gorbachev a minor boost. In the summer of 1991, the New Union Treaty, which would have turned the Soviet Union into a much looser Union, was agreed upon by eight republics.
The signing of the treaty, however, was interrupted by the August Coup—an attempted coup d'état by hardline members of the government and the KGB who sought to reverse Gorbachev's reforms and reassert the central government's control over the republics. After the coup collapsed, Yeltsin was seen as a hero for his decisive actions, while Gorbachev's power was effectively ended. The balance of power tipped significantly towards the republics. In August 1991, Latvia and Estonia immediately declared the restoration of their full independence (following Lithuania's 1990 example), while the other twelve republics continued discussing new, increasingly looser, models of the Union.
On 8 December 1991, the presidents of Russia, Ukraine and Belarus signed the Belavezha Accords, which declared the Soviet Union dissolved and established the Commonwealth of Independent States (CIS) in its place. While doubts remained over the authority of the accords to do this, on 21 December 1991, the representatives of all Soviet republics except Georgia signed the Alma-Ata Protocol, which confirmed the accords. On 25 December 1991, Gorbachev yielded to the inevitable and resigned as the President of the USSR, declaring the office extinct. He turned the powers that had been vested in the presidency over to Yeltsin, the President of Russia.
The following day, the Supreme Soviet, the highest governmental body of the Soviet Union, dissolved itself. This is generally recognized as marking the official, final dissolution of the Soviet Union as a functioning state. The Soviet Army remained in place in the early months of 1992, but was thereafter absorbed into the different military forces of the newly independent states.
Following the dissolution of the Soviet Union on 26 December 1991, Russia was internationally recognized as its legal successor on the international stage. To that end, Russia voluntarily accepted all Soviet foreign debt and claimed overseas Soviet properties as its own. Since then, the Russian Federation has assumed the Soviet Union's rights and obligations.
Politics.
There were three power hierarchies in the Soviet Union: the legislative branch represented by the Supreme Soviet of the Soviet Union, the government represented by the Council of Ministers, and the Communist Party of the Soviet Union (CPSU), the only legal party and the ultimate policymaker in the country.
Communist Party.
At the top of the Communist Party was the Central Committee, elected at Party Congresses and Conferences. The Central Committee in turn voted for a Politburo (called the Presidium between 1952–1966), Secretariat and the General Secretary (First Secretary from 1953 to 1966), the de facto highest office in the USSR. Depending on the degree of power consolidation, it was either the Politburo as a collective body or the General Secretary, who always was one of the Politburo members, that effectively led the party and the country (except for the period of the highly personalized authority of Stalin, exercised directly through his position in the Council of Ministers rather than the Politburo after 1941). They were not controlled by the general party membership, as the key principle of the party organization was democratic centralism, demanding strict subordination to higher bodies, and elections went uncontested, endorsing the candidates proposed from above.
The Communist Party maintained its dominance over the state largely through its control over the system of appointments. All senior government officials and most deputies of the Supreme Soviet were members of the CPSU. Of the party heads themselves, Stalin in 1941–1953 and Khrushchev in 1958–1964 were Premiers. Upon the forced retirement of Khrushchev, the party leader was prohibited from this kind of double membership, but the later General Secretaries for at least some part of their tenure occupied the largely ceremonial position of Chairman of the Presidium of the Supreme Soviet, the nominal head of state. The institutions at lower levels were overseen and at times supplanted by primary party organizations.
In practice, however, the degree of control the party was able to exercise over the state bureaucracy, particularly after the death of Stalin, was far from total, with the bureaucracy pursuing different interests that were at times in conflict with the party. Nor was the party itself monolithic from top to bottom, although factions were officially banned.
Government.
The Supreme Soviet (successor of the Congress of Soviets and Central Executive Committee) was nominally the highest state body for most of the Soviet history, at first acting as a rubber stamp institution, approving and implementing all decisions made by the party. However, the powers and functions of the Supreme Soviet were extended in the late 1950s, 1960s and 1970s, including the creation of new state commissions and committees. It gained additional powers when it came to the approval of the Five-Year Plans and the Soviet state budget. The Supreme Soviet elected a Presidium to wield its power between plenary sessions, ordinarily held twice a year, and appointed the Supreme Court, the Procurator General and the Council of Ministers (known before 1946 as the Council of People's Commissars), headed by the Chairman (Premier) and managing an enormous bureaucracy responsible for the administration of the economy and society. State and party structures of the constituent republics largely emulated the structure of the central institutions, although the Russian SFSR, unlike the other constituent republics, for most of its history had no republican branch of the CPSU, being ruled directly by the union-wide party until 1990. Local authorities were organized likewise into party committees, local Soviets and executive committees. While the state system was nominally federal, the party was unitary.
The state security police (the KGB and its predecessor agencies) played an important role in Soviet politics. It was instrumental in the Stalinist terror, but after the death of Stalin, the state security police was brought under strict party control. Under Yuri Andropov, KGB chairman in 1967–1982 and General Secretary from 1982 to 1983, the KGB engaged in the suppression of political dissent and maintained an extensive network of informers, reasserting itself as a political actor to some extent independent of the party-state structure, culminating in the anti-corruption campaign targeting high party officials in the late 1970s and early 1980s.
Separation of power and reform.
The Soviet constitutions, which were promulgated in 1918, 1924, 1936 and 1977, did not limit state power. No formal separation of powers existed between the Party, Supreme Soviet and Council of Ministers that represented executive and legislative branches of the government. The system was governed less by statute than by informal conventions, and no settled mechanism of leadership succession existed. Bitter and at times deadly power struggles took place in the Politburo after the deaths of Lenin and Joseph Stalin, as well as after Khrushchev's dismissal, itself due to a coup in both the Politburo and the Central Committee. All Soviet party leaders before Gorbachev died in office, except Georgy Malenkov and Khrushchev, both dismissed from the party leadership amid internal struggle within the party.
In 1988–1990, facing considerable opposition, Mikhail Gorbachev enacted reforms shifting power away from the highest bodies of the party and making the Supreme Soviet less dependent on them. The Congress of People's Deputies was established, the majority of whose members were directly elected in competitive elections held in March 1989. The Congress now elected the Supreme Soviet, which became a full-time parliament, much stronger than before. For the first time since the 1920s, it refused to rubber stamp proposals from the party and Council of Ministers. In 1990, Gorbachev introduced and assumed the position of the President of the Soviet Union, concentrated power in his executive office, independent of the party, and subordinated the government, now renamed the Cabinet of Ministers of the USSR, to himself.
Tensions grew between the union-wide authorities under Gorbachev, reformists led in Russia by Boris Yeltsin and controlling the newly elected Supreme Soviet of the Russian SFSR, and Communist Party hardliners. On 19–21 August 1991, a group of hardliners staged an abortive coup attempt. Following the failed coup, the State Council of the Soviet Union became the highest organ of state power "in the period of transition". Gorbachev resigned as General Secretary, only remaining President for the final months of the existence of the USSR.
Judicial system.
The judiciary was not independent of the other branches of government. The Supreme Court supervised the lower courts (People's Court) and applied the law as established by the Constitution or as interpreted by the Supreme Soviet. The Constitutional Oversight Committee reviewed the constitutionality of laws and acts. The Soviet Union used the inquisitorial system of Roman law, where the judge, procurator, and defense attorney collaborate to establish the truth.
Political divisions.
Constitutionally, the Soviet Union was a union of Soviet Socialist Republics (SSRs) and the Russian Soviet Federative Socialist Republic (RSFSR), although the rule of the highly centralized Communist Party made the union merely nominal. The Treaty on the Creation of the USSR was signed in December 1922 by four founding republics, the RSFSR, Transcaucasian SFSR, Ukrainian SSR and Belorussian SSR. In 1924, during the national delimitation in Central Asia, the Uzbek and Turkmen SSRs were formed from parts of the RSFSR's Turkestan ASSR and two Soviet dependencies, the Khorezm and Bukharan SSR. In 1929, the Tajik SSR was split off from the Uzbek SSR. With the constitution of 1936, the constituents of the Transcaucasian SFSR, namely the Georgian, Armenian and Azerbaijan SSRs, were elevated to union republics, while the Kazakh and Kirghiz SSRs were split off from the RSFSR. In August 1940, the Soviet Union formed the Moldavian SSR from parts of the Ukrainian SSR and parts of Bessarabia annexed from Romania. It also annexed the Baltic states as the Estonian, Latvian and Lithuanian SSRs. The Karelo-Finnish SSR was split off from the RSFSR in March 1940 and merged back in 1956. Between July 1956 and September 1991, there were 15 union republics (see map below).
On 16 November 1988, the Supreme Soviet of the Estonian SSR passed the Estonian Sovereignty Declaration that asserted Estonia's sovereignty and declared the supremacy of Estonian laws over those of the Soviet Union. In March 1990, the newly elected Supreme Soviet of the Lithuanian SSR declared independence, followed by the Georgian Supreme Soviet in April 1991. Although the symbolic right of the republics to secede was nominally guaranteed by the constitution and the union treaty, Soviet authorities at first refused to recognize it. After the August coup attempt, most of the other republics followed suit. The Soviet Union ultimately recognized the secession of Estonia, Latvia and Lithuania on 6 September 1991. The remaining republics were recognized as independent with the Soviet Union's final dissolution in December 1991.
Economy.
The Soviet Union became the first country to adopt a planned economy, whereby production and distribution of goods were centralized and directed by the government. The first Bolshevik experience with a command economy was the policy of War Communism, which involved nationalization of industry, centralized distribution of output, coercive requisition of agricultural production, and attempts to eliminate the circulation of money, as well as private enterprises and free trade. As it had suffered a severe economic collapse caused by the war, in 1921, Lenin replaced War Communism with the New Economic Policy (NEP), legalizing free trade and private ownership of smaller businesses. The economy quickly recovered.
Following a lengthy debate among the members of Politburo over the course of economic development, by 1928–1929, upon gaining control of the country, Joseph Stalin abandoned the NEP and pushed for full central planning, starting forced collectivization of agriculture and enacting draconian labor legislation. Resources were mobilized for rapid industrialization, which greatly expanded Soviet capacity in heavy industry and capital goods during the 1930s. Preparation for war was one of the main driving forces behind industrialization, mostly due to distrust of the outside capitalistic world. As a result, the USSR was transformed from a largely agrarian economy into a great industrial power, leading the way for its emergence as a superpower after World War II. During the war, the Soviet economy and infrastructure suffered massive devastation and required extensive reconstruction.
By the early 1940s, the Soviet economy had become relatively self-sufficient; for most of the period until the creation of Comecon, only a very small share of domestic products was traded internationally. After the creation of the Eastern Bloc, external trade rose rapidly. Still the influence of the world economy on the USSR was limited by fixed domestic prices and a state monopoly on foreign trade. Grain and sophisticated consumer manufactures became major import articles from around the 1960s. During the arms race of the Cold War, the Soviet economy was burdened by military expenditures, heavily lobbied for by a powerful bureaucracy dependent on the arms industry. At the same time, the Soviet Union became the largest arms exporter to the Third World. Significant amounts of Soviet resources during the Cold War were allocated in aid to the other socialist states.
From the 1930s until its collapse in the late 1980s, the way the Soviet economy operated remained essentially unchanged. The economy was formally directed by central planning, carried out by Gosplan and organized in five-year plans. In practice, however, the plans were highly aggregated and provisional, subject to "ad hoc" intervention by superiors. All key economic decisions were taken by the political leadership. Allocated resources and plan targets were normally denominated in rubles rather than in physical goods. Credit was discouraged, but widespread. Final allocation of output was achieved through relatively decentralized, unplanned contracting. Although in theory prices were legally set from above, in practice the actual prices were often negotiated, and informal horizontal links (between producer factories etc.) were widespread.
A number of basic services were state-funded, such as education and healthcare. In the manufacturing sector, heavy industry and defense were assigned higher priority than the production of consumer goods. Consumer goods, particularly outside large cities, were often scarce, of poor quality and limited choice. Under command economy, consumers had almost no influence over production, so the changing demands of a population with growing incomes could not be satisfied by supplies at rigidly fixed prices. A massive unplanned second economy grew up alongside the planned one at low levels, providing some of the goods and services that the planners could not. Legalization of some elements of the decentralized economy was attempted with the reform of 1965.
Although statistics of the Soviet economy are notoriously unreliable and its economic growth difficult to estimate precisely, by most accounts, the economy continued to expand until the mid 1980s. During the 1950s and 1960s, the Soviet economy experienced comparatively high growth and was catching up to the West. However, after 1970, the growth, while still positive, steadily declined much more quickly and consistently than in other countries despite a rapid increase in the capital stock (the rate of increase in capital was only surpassed by Japan).
Overall, between 1960 and 1989, the growth rate of per capita income in the Soviet Union was slightly above the world average (based on 102 countries). According to Stanley Fischer and William Easterly, growth could have been faster. By their calculation, per capita income of Soviet Union in 1989 should have been twice as high as it was considering the amount of investment, education and population. The authors attribute this poor performance to low productivity of capital in the Soviet Union. Steven Rosenfielde states that the standard of living actually declined as a result of Stalin's despotism, and while there was a brief improvement following his death, lapsed into stagnation.
In 1987, Mikhail Gorbachev tried to reform and revitalize the economy with his program of "perestroika". His policies relaxed state control over enterprises, but did not yet allow it to be replaced by market incentives, ultimately resulting in a sharp decline in production output. The economy, already suffering from reduced petroleum export revenues, started to collapse. Prices were still fixed, and property was still largely state-owned until after the dissolution of the Soviet Union. For most of the period after World War II up to its collapse, the Soviet economy was the second largest in the world by GDP (PPP), though in per capita terms the Soviet GDP was behind that of the First World countries.
Energy.
The need for fuel declined in the Soviet Union from the 1970s to the 1980s, both per ruble of gross social product and per ruble of industrial product. At the start, this decline grew very rapidly, but gradually slowed down between 1970 and 1975. From 1975 and 1980, it grew even slower, only 2.6 percent. David Wilson, a historian, believed that the gas industry would account for 40 percent of Soviet fuel production by the end of the century. His theory did not come to fruition because of the USSR's collapse. The USSR, in theory, would have continued to have an economic growth rate of 2–2.5 percent during the 1990s because of Soviet energy fields. However, the energy sector faced many difficulties, among them the country's high military expenditure and hostile relations with the First World (pre-Gorbachev era).
In 1991, the Soviet Union had a pipeline network of for crude oil and another for natural gas. Petroleum and petroleum-based products, natural gas, metals, wood, agricultural products, and a variety of manufactured goods, primarily machinery, arms and military equipment, were exported. In the 1970s and 1980s, the Soviet Union heavily relied on fossil fuel exports to earn hard currency. At its peak in 1988, it was the largest producer and second largest exporter of crude oil, surpassed only by Saudi Arabia.
Science and technology.
The Soviet Union placed great emphasis on science and technology within its economy, however, the most remarkable Soviet successes in technology, such as producing the world's first space satellite, typically were the responsibility of the military. Lenin believed that the USSR would never overtake the developed world if it remained as technologically backward as it was. Soviet authorities proved their commitment to Lenin's belief by developing massive networks, research and development organizations. By 1989, Soviet scientists were among the world's best-trained specialists in several areas, such as energy physics, selected areas of medicine, mathematics, welding and military technologies. Due to rigid state planning and bureaucracy, the Soviets remained far behind technologically in chemistry, biology, and computers when compared to the First World.
Project Socrates, under the Reagan administration, determined that the Soviet Union addressed the acquisition of science and technology in a manner that was radically different from what the US was using. In the case of the US, economic prioritization was being used for indigenous research and development as the means to acquire science and technology in both the private and public sectors. In contrast, the Soviet Union was offensively and defensively maneuvering in the acquisition and utilization of the worldwide technology, to increase the competitive advantage that they acquired from the technology, while preventing the US from acquiring a competitive advantage. However, in addition, the Soviet Union's technology-based planning was executed in a centralized, government-centric manner that greatly hindered its flexibility. It was this significant lack of flexibility that was exploited by the US to undermine the strength of the Soviet Union and thus foster its reform.
Transport.
Transport was a key component of the nation's economy. The economic centralization of the late 1920s and 1930s led to the development of infrastructure on a massive scale, most notably the establishment of Aeroflot, an aviation enterprise. The country had a wide variety of modes of transport by land, water and air. However, due to bad maintenance, much of the road, water and Soviet civil aviation transport were outdated and technologically backward compared to the First World.
Soviet rail transport was the largest and most intensively used in the world; it was also better developed than most of its Western counterparts. By the late 1970s and early 1980s, Soviet economists were calling for the construction of more roads to alleviate some of the burden from the railways and to improve the Soviet state budget. The road network and automobile industry remained underdeveloped, and dirt roads were common outside major cities. Soviet maintenance projects proved unable to take care of even the few roads the country had. By the early-to-mid-1980s, the Soviet authorities tried to solve the road problem by ordering the construction of new ones. Meanwhile, the automobile industry was growing at a faster rate than road construction. The underdeveloped road network led to a growing demand for public transport.
Despite improvements, several aspects of the transport sector were still riddled with problems due to outdated infrastructure, lack of investment, corruption and bad decision-making. Soviet authorities were unable to meet the growing demand for transport infrastructure and services.
The Soviet merchant fleet was one of the largest in the world.
Demographics.
The first fifty years of the 20th century in tsarist Russia and the Soviet Union were marked by a succession of disasters, each accompanied by large–scale population losses. Excess deaths over the course of World War I and the Russian Civil War (including the postwar famine) amounted to a combined total of 18 million, some 10 million in the 1930s, and more than 26 million in 1941–5. The postwar Soviet population was 45 to 50 million smaller than it would have been if pre-war demographic growth had continued.
The crude birth rate of the USSR decreased from 44.0 per thousand in 1926 to 18.0 in 1974, largely due to increasing urbanization and the rising average age of marriages. The crude death rate demonstrated a gradual decrease as well – from 23.7 per thousand in 1926 to 8.7 in 1974. In general, the birth rates of the southern republics in Transcaucasia and Central Asia were considerably higher than those in the northern parts of the Soviet Union, and in some cases even increased in the post–World War II period, a phenomenon partly attributed to slower rates of urbanization and traditionally earlier marriages in the southern republics. Soviet Europe moved towards sub-replacement fertility, while Soviet Central Asia continued to exhibit population growth well above replacement-level fertility.
The late 1960s and the 1970s witnessed a reversal of the declining trajectory of the rate of mortality in the USSR, and was especially notable among men of working age, but was also prevalent in Russia and other predominantly Slavic areas of the country. An analysis of the official data from the late 1980s showed that after worsening in the late-1970s and the early 1980s, adult mortality began to improve again. The infant mortality rate increased from 24.7 in 1970 to 27.9 in 1974. Some researchers regarded the rise as largely real, a consequence of worsening health conditions and services. The rises in both adult and infant mortality were not explained or defended by Soviet officials, and the Soviet government simply stopped publishing all mortality statistics for ten years. Soviet demographers and health specialists remained silent about the mortality increases until the late-1980s, when the publication of mortality data resumed and researchers could delve into the real causes.
Education.
Before 1917, education was not free in the Russian Empire and was therefore either inaccessible or barely accessible for many children from lower-class working and peasant families. Estimates from 1917 recorded that 75–85 percent of the Russian population was illiterate.
Anatoly Lunacharsky became the first People's Commissariat for Education of Soviet Russia. At the beginning, the Soviet authorities placed great emphasis on the elimination of illiteracy. People who were literate were automatically hired as teachers. For a short period, quality was sacrificed for quantity. By 1940, Joseph Stalin could announce that illiteracy had been eliminated. In the aftermath of the Great Patriotic War, the country's educational system expanded dramatically. This expansion had a tremendous effect. In the 1960s, nearly all Soviet children had access to education, the only exception being those living in remote areas. Nikita Khrushchev tried to make education more accessible, making it clear to children that education was closely linked to the needs of society. Education also became important in creating the New Soviet Man.
Only 20 percent of all applicants were accepted. The rest entered the labor market or learned a skill at a vocational technical school or technicum. Students from families of dubious political reliability were barred from higher education. The Brezhnev administration introduced a rule that required all university applicants to present a reference from the local Komsomol party secretary. According to statistics from 1986, the number of students per 10,000 population was 181 for the USSR, compared to 517 for the US.
Ethnic groups.
The Soviet Union was a very ethnically diverse country, with more than 100 distinct ethnic groups. The total population was estimated at 293 million in 1991. According to a 1990 estimate, the majority were Russians (50.78%), followed by Ukrainians (15.45%) and Uzbeks (5.84%).
All citizens of the USSR had their own ethnic affiliation. The ethnicity of a person was chosen at the age of sixteen by the child's parents. If the parents did not agree, the child was automatically assigned the ethnicity of the father. Partly due to Soviet policies, some of the smaller minority ethnic groups were considered part of larger ones, such as the Mingrelians of the Georgian SSR, who were classified with the linguistically related Georgians. Some ethnic groups voluntarily assimilated, while others were brought in by force. Russians, Belarusians, and Ukrainians shared close cultural ties, while other groups did not. With multiple nationalities living in the same territory, ethnic antagonisms developed over the years.
Health.
In 1917, before the Bolshevik uprising, health conditions were significantly behind the developed countries. As Lenin later noted, "Either the lice will defeat socialism, or socialism will defeat the lice". The Soviet principle of health care was conceived by the People's Commissariat for Health in 1918. Health care was to be controlled by the state and would be provided to its citizens free of charge, this at the time being a revolutionary concept. Article 42 of the 1977 Soviet Constitution gave all citizens the right to health protection and free access to any health institutions in the USSR. Before Leonid Brezhnev became head of state, the healthcare system of the Soviet Union was held in high esteem by many foreign specialists. This changed however, from Brezhnev's accession and Mikhail Gorbachev's tenure as leader, the Soviet health care system was heavily criticised for many basic faults, such as the quality of service and the unevenness in its provision. Minister of Health Yevgeniy Chazov, during the 19th Congress of the Communist Party of the Soviet Union, while highlighting such Soviet successes as having the most doctors and hospitals in the world, recognised the system's areas for improvement and felt that billions of Soviet rubles were squandered. 
After the socialist revolution, the life expectancy for all age groups went up. This statistic in itself was seen by some that the socialist system was superior to the capitalist system. These improvements continued into the 1960s, when the life expectancy in the Soviet Union surpassed that of the United States. It remained stable during most years, although in the 1970s, it went down slightly, possibly because of alcohol abuse. At the same time, infant mortality began to rise. After 1974, the government stopped publishing statistics on this. This trend can be partly explained by the number of pregnancies rising drastically in the Asian part of the country where infant mortality was highest, while declining markedly in the more developed European part of the Soviet Union.
Language.
The Soviet government headed by Vladimir Lenin gave small language groups their own writing systems. The development of these writing systems was very successful, even though some flaws were detected. During the later days of the USSR, countries with the same multilingual situation implemented similar policies. A serious problem when creating these writing systems was that the languages differed dialectally greatly from each other. When a language had been given a writing system and appeared in a notable publication, that language would attain "official language" status. There were many minority languages which never received their own writing system; therefore their speakers were forced to have a second language. There are examples where the Soviet government retreated from this policy, most notable under Stalin's regime, where education was discontinued in languages which were not widespread enough. These languages were then assimilated into another language, mostly Russian. During the Great Patriotic War (World War II), some minority languages were banned, and their speakers accused of collaborating with the enemy.
As the most widely spoken of the Soviet Union's many languages, Russian "de facto" functioned as an official language as the "language of interethnic communication" (), but only assumed the "de jure" status as the official national language in 1990.
Religion.
A.L. Eliseev writes that a meeting of the antireligious commission of the Central Committee of the All-Union Communist Party (Bolsheviks) took place on 23 May 1929 under the Chairmanship of E. laroslavskii. There, believers in the country were estimated at 80 percent. It cannot be ruled out that this percentage was somewhat understated, to prove the successfulness of the struggle with religion.
Christianity and Islam had the greatest number of adherents among the Soviet state's religious citizens. Eastern Christianity predominated among Christians, with Russia's traditional Russian Orthodox Church being the Soviet Union's largest Christian denomination. About 90 percent of the Soviet Union's Muslims were Sunnis, with Shiites concentrated in the Azerbaijani Soviet Socialist Republic. Smaller groups included Roman Catholics, Jews, Buddhists, and a variety of Protestant sects.
Religious influence had been strong in the Russian Empire. The Russian Orthodox Church enjoyed a privileged status as the church of the monarchy and took part in carrying out official state functions. The immediate period following the establishment of the Soviet state included a struggle against the Orthodox Church, which the revolutionaries considered an ally of the former ruling classes.
In Soviet law, the "freedom to hold religious services" was constitutionally guaranteed, although the ruling Communist Party regarded religion as incompatible with the Marxist spirit of scientific materialism. In practice, the Soviet system subscribed to a narrow interpretation of this right, and in fact utilized a range of official measures to discourage religion and curb the activities of religious groups.
The 1918 Council of People's Commissars decree establishing the Russian Soviet Federative Socialist Republic (RSFSR) as a secular state also decreed that "the teaching of religion in all where subjects of general instruction are taught, is forbidden. Citizens may teach and may be taught religion privately." Among further restrictions, those adopted in 1929, a half-decade into Stalin's rule, included express prohibitions on a range of church activities, including meetings for organized Bible study. Both Christian and non-Christian establishments were shut down by the thousands in the 1920s and 1930s. By 1940, as many as 90 percent of the churches, synagogues, and mosques that had been operating in 1917 were closed.
Convinced that religious anti-Sovietism had become a thing of the past, the Stalin regime began shifting to a more moderate religion policy in the late 1930s. Soviet religious establishments overwhelmingly rallied to support the war effort during the Soviet war with Nazi Germany. Amid other accommodations to religious faith, churches were reopened, Radio Moscow began broadcasting a religious hour, and a historic meeting between Stalin and Orthodox Church leader Patriarch Sergius I of Moscow was held in 1943. The general tendency of this period was an increase in religious activity among believers of all faiths.
The Soviet establishment again clashed with the churches under General Secretary Nikita Khrushchev's leadership in 1958–1964, a period when atheism was emphasized in the educational curriculum, and numerous state publications promoted atheistic views. During this period, the number of churches fell from 20,000 to 10,000 from 1959 to 1965, and the number of synagogues dropped from 500 to 97. The number of working mosques also declined, falling from 1,500 to 500 within a decade.
Religious institutions remained monitored by the Soviet government, but churches, synagogues, temples, and mosques were all given more leeway in the Brezhnev era. Official relations between the Orthodox Church and the Soviet government again warmed to the point that the Brezhnev government twice honored Orthodox Patriarch Alexy I with the Order of the Red Banner of Labor. A poll conducted by Soviet authorities in 1982 recorded 20 percent of the Soviet population as "active religious believers."
Culture.
The culture of the Soviet Union passed through several stages during the USSR's 70-year existence. During the first eleven years following the Revolution (1918–1929), there was relative freedom and artists experimented with several different styles to find a distinctive Soviet style of art. Lenin wanted art to be accessible to the Russian people. On the other hand, hundreds of intellectuals, writers, and artists were exiled or executed, and their work banned, for example Nikolay Gumilev (shot for conspiring against the Bolshevik regime) and Yevgeny Zamyatin (banned).
The government encouraged a variety of trends. In art and literature, numerous schools, some traditional and others radically experimental, proliferated. Communist writers Maksim Gorky and Vladimir Mayakovsky were active during this time. Film, as a means of influencing a largely illiterate society, received encouragement from the state; much of director Sergei Eisenstein's best work dates from this period.
Later, during Stalin's rule, Soviet culture was characterised by the rise and domination of the government-imposed style of socialist realism, with all other trends being severely repressed, with rare exceptions, for example Mikhail Bulgakov's works. Many writers were imprisoned and killed.
Following the Khrushchev Thaw of the late 1950s and early 1960s, censorship was diminished. During this time, a distinctive period of Soviet culture developed characterized by conformist public life and intense focus on personal life. Greater experimentation in art forms were again permissible, with the result that more sophisticated and subtly critical work began to be produced. The regime loosened its emphasis on socialist realism; thus, for instance, many protagonists of the novels of author Yury Trifonov concerned themselves with problems of daily life rather than with building socialism. An underground dissident literature, known as "samizdat", developed during this late period. In architecture the Khrushchev era mostly focused on functional design as opposed to the highly decorated style of Stalin's epoch.
In the second half of the 1980s, Gorbachev's policies of "perestroika" and "glasnost" significantly expanded freedom of expression in the media and press.

Spanish Inquisition
The Tribunal of the Holy Office of the Inquisition (), commonly known as the Spanish Inquisition ("Inquisición española"), was a tribunal established in 1480 by Catholic Monarchs, Ferdinand II of Aragon and Isabella I of Castile. It was intended to maintain Catholic orthodoxy in their kingdoms, and to replace the Medieval Inquisition which was under Papal control. It became the most substantive of the three different manifestations of the wider Christian Inquisition along with the Roman Inquisition and Portuguese Inquisition.
The Inquisition was originally intended in large part to ensure the orthodoxy of those who converted from Judaism and Islam. This regulation of the faith of the newly converted was intensified after the royal decrees issued in 1492 and 1501 ordering Jews and Muslims to convert or leave.
Various motives have been proposed for the monarchs' decision to fund the Inquisition such as increasing political authority, weakening opposition, suppressing "conversos", profiting from confiscation of the property of convicted heretics, reducing social tensions and protecting the kingdom from the danger of a fifth column.
The body was under the direct control of the Spanish monarchy. It was not definitively abolished until 1834, during the reign of Isabella II, after a period of declining influence in the previous century.
Previous Inquisitions.
The Inquisition was created through papal bull, "Ad Abolendam", issued at the end of the 12th century by Pope Lucius III as a way to combat the Albigensian heresy in southern France. There were a huge number of tribunals of the Papal Inquisition in various European kingdoms during the Middle Ages. In the Kingdom of Aragon, a tribunal of the Papal Inquisition was established by the statute of "Excommunicamus" of Pope Gregory IX, in 1232, during the era of the Albigensian heresy. Its principal representative was Ramon de Penyafort. With time, its importance was diluted, and, by the middle of the 15th century, it was almost forgotten although still there according to the law.
There was never a tribunal of the Papal Inquisition in Castile. Members of the episcopate were charged with surveillance of the faithful and punishment of transgressors. During the Middle Ages, in Castile, little attention was paid to heresy by the Catholic ruling class. Jews and Muslims were tolerated and generally allowed to follow their traditional laws and customs in domestic matters. However, by law, they were considered inferior to Catholics and were subject to discriminatory legislation.
The Spanish Inquisition can be seen as an answer to the multi-religious nature of Spanish society following the reconquest of the Iberian Peninsula from the Muslim Moors. For almost 600 years, much of the Iberian Peninsula was dominated by the Moors following their invasion of the peninsula in 711 until the early 13th century. Following the Christian victory at the Battle of Las Navas de Tolosa (1212), and the fall of Córdoba (1236) and Seville (1248), Christian rule was re-established for most of the peninsula. Only the small region of Granada remained under Muslim rule which also ended with a final Christian victory in 1492. However, the Reconquista did not result in the total expulsion of Muslims from Spain, since they, along with Jews, were tolerated by the ruling Catholic elite. Large cities, especially Seville, Valladolid and Barcelona, had significant Jewish populations centered in Juderia, but in the coming years the Muslims were increasingly subjugated by alienation and torture. The Jews, who had previously thrived under Muslim rule, now suffered similar maltreatment.
Post-reconquest medieval Spain has been characterized by Americo Castro and some other Iberianists as a society of "convivencia", that is relatively peaceful co-existence, albeit punctuated by occasional conflict among the ruling Catholics and the Jews and Muslims. However, as Henry Kamen notes, "so-called convivencia was always a relationship between unequals." Despite their legal inequality, there was a long tradition of Jewish service to the crown of Aragon and Jews occupied many important posts, both religious and political. Castile itself had an unofficial rabbi. Ferdinand's father John II named the Jewish Abiathar Crescas to be Court Astronomer.
Nevertheless, in some parts of Spain towards the end of the 14th century, there was a wave of violent anti-Judaism, encouraged by the preaching of Ferrand Martinez, Archdeacon of Ecija. The pogroms of June 1391 were especially bloody: in Seville, hundreds of Jews were killed, and the synagogue was completely destroyed. The number of people killed was also high in other cities, such as Córdoba, Valencia and Barcelona.
One of the consequences of these programs was the mass conversion of Jews. Forced baptism was contrary to the law of the Catholic Church, and theoretically anybody who had been forcibly baptized could legally return to Judaism; this however was very narrowly interpreted. Legal definitions of the time theoretically acknowledged that a forced baptism was not a valid sacrament, but confined this to cases where it was literally administered by physical force: a person who had consented to baptism under threat of death or serious injury was still regarded as a voluntary convert, and accordingly forbidden to revert to Judaism. After the public violence, many of the converted "felt it safer to remain in their new religion." Thus after 1391 a new social group appeared and were referred to as "conversos" or "New Christians". Many "conversos", now freed from the antisemitic restrictions imposed on Jewish employment, attained important positions in 15th century Spain, including positions in the government and in the Church. Among many others, physicians Andrés Laguna and Francisco Lopez Villalobos (Ferdinand's court physician), writers Juan del Enzina, Juan de Mena, Diego de Valera and Alonso de Palencia, and bankers Luis de Santangel and Gabriel Sanchez (who financed the voyage of Christopher Columbus) were all "conversos". "Conversos" - not without opposition - managed to attain high positions in the ecclesiastical hierarchy, at times becoming severe detractors of Judaism. Some even received titles of nobility, and as a result, during the following century some works attempted to demonstrate that virtually all of the nobles of Spain were descended from Israelites.
Activity of the Inquisition.
The start of the Inquisition.
Alonso de Hojeda, a Dominican friar from Seville, convinced Queen Isabel of the existence of Crypto-Judaism among Andalusian "conversos" during her stay in Seville between 1477 and 1478. A report, produced by Pedro González de Mendoza, Archbishop of Seville, and by the Segovian Dominican Tomás de Torquemada, corroborated this assertion.
The monarchs decided to introduce the Inquisition to Castile to discover and punish crypto-Jews, and requested the Pope's assent. Ferdinand II of Aragon pressured Pope Sixtus IV to agree to an Inquisition controlled by the monarchy by threatening to withdraw military support at a time when the Turks were a threat to Rome. The Pope issued a bull to stop the Inquisition but was pressured into withdrawing it. On November 1, 1478, Pope Sixtus IV published the Papal bull, "Exigit Sinceras Devotionis Affectus", through which he gave the monarchs exclusive authority to name the inquisitors in their kingdoms. The first two inquisitors, Miguel de Morillo and Juan de San Martín were not named, however, until two years later, on September 27, 1480 in Medina del Campo.
The first "auto-da-fé" was held in Seville on February 6, 1481: six people were burned alive. From there, the Inquisition grew rapidly in the Kingdom of Castile. By 1492, tribunals existed in eight Castilian cities: Ávila, Córdoba, Jaén, Medina del Campo, Segovia, Sigüenza, Toledo, and Valladolid.
Sixtus IV promulgated a new bull categorically prohibiting the Inquisition's extension to Aragon, affirming that,
Cited in Kamen, op. cit., p. 49.
In 1483, Jews were expelled from all of Andalusia. Ferdinand pressured the Pope to promulgate a new bull. He did so on October 17, 1483, naming Tomás de Torquemada Inquisidor General of Aragón, Valencia and Catalonia. Torquemada quickly established procedures for the Inquisition. A new court would be announced with a thirty day grace period for confessions and the gathering of accusations by neighbors. Evidence that was used to identify a crypto-Jew included the absence of chimney smoke on Saturdays (a sign the family might secretly be honoring the Sabbath) or the buying of many vegetables before Passover or the purchase of meat from a converted butcher. The court employed physical torture to extract confessions. Crypto-Jews were allowed to confess and do penance, although those who relapsed were burned at the stake.
In 1484 Pope Innocent VIII attempted to allow appeals to Rome against the Inquisition, but Ferdinand in December 1484 and again in 1509 decreed death and confiscation for anyone trying to make use of such procedures without royal permission. With this, the Inquisition became the only institution that held authority across all the realms of the Spanish monarchy, and, in all of them, a useful mechanism at the service of the crown. However, the cities of Aragón continued resisting, and even saw revolt, as in Teruel from 1484 to 1485. However, the murder of "Inquisidor" Pedro Arbués in Zaragoza on September 15, 1485, caused public opinion to turn against the "conversos" and in favour of the Inquisition. In Aragón, the Inquisitorial courts were focused specifically on members of the powerful "converso" minority, ending their influence in the Aragonese administration.
The Inquisition was extremely active between 1480 and 1530. Different sources give different estimates of the number of trials and executions in this period; Henry Kamen estimates about 2,000 executed, based on the documentation of the "autos-da-fé", the great majority being "conversos" of Jewish origin. He offers striking statistics: 91.6% of those judged in Valencia between 1484 and 1530 and 99.3% of those judged in Barcelona between 1484 and 1505 were of Jewish origin. "In 1498 the pope was still trying to...gain acceptance for his own attitude towards the New Christians, which was generally more moderate than that of the Inquisition and the local rulers."
Expulsion of Jews and repression of "conversos".
The Spanish Inquisition had been set up in part to prevent "conversos" from engaging in Jewish practices, which, as Christians, they were supposed to have given up. However this remedy for securing the orthodoxy of "conversos"' religion was eventually deemed inadequate, since the main justification the monarchy gave for formally expelling all Jews from Spain was the "great harm suffered by Christians (i.e. conversos) from the contact, intercourse and communication which they have with the Jews, who always attempt in various ways to seduce faithful Christians from our Holy Catholic Faith". The Alhambra Decree, which ordered the expulsion, was issued in January 1492. Historic accounts of the numbers of Jews who left Spain have varied enormously. Historians of the period give extremely high figures: Juan de Mariana speaks of 800,000 people, and Don Isaac Abravanel of 300,000. Modern estimates, based on careful examination of official documents and population estimates of communities, are much lower: Henry Kamen estimates that, of a population of approximately 80,000 Jews, about one half or 40,000 chose emigration. The Jews of the kingdom of Castile emigrated mainly to Portugal (whence they were expelled in 1497) and to North Africa. However, according to Henry Kamen, the Jews of the kingdom of Aragon, went "to adjacent Christian lands, mainly to Italy", rather than to Muslim lands as is often assumed. The Sefardim or Anusim descendants of Spanish Jews gradually migrated throughout Europe and North Africa, where they established communities in many cities. They also went to New Spain, the Ottoman Empire and North America (the American Southwest), Central and South America.
Tens of thousands of Jews were baptised in the three months before the deadline for expulsion, some 40,000 if one accepts the totals given by Kamen: most of these undoubtedly to avoid expulsion, rather than as a sincere change of faith. These "conversos" were the principal concern of the Inquisition; being suspected of continuing to practice Judaism put them at risk of denunciation and trial.
The most intense period of persecution of "conversos" lasted until 1530. From 1531 to 1560, however, the percentage of "conversos" among the Inquisition trials dropped to 3% of the total. There was a rebound of persecutions when a group of crypto-Jews was discovered in Quintanar de la Orden in 1588; and there was a rise in denunciations of "conversos" in the last decade of the 16th century. At the beginning of the 17th century, some "conversos" who had fled to Portugal began to return to Spain, fleeing the persecution of the Portuguese Inquisition, founded in 1532. This led to a rapid increase in the trials of crypto-Jews, among them a number of important financiers. In 1691, during a number of "autos-da-fé" in Majorca, 36 "chuetas", or "conversos" of Majorca, were burned.
During the 18th century the number of "conversos" accused by the Inquisition decreased significantly. Manuel Santiago Vivar, tried in Córdoba in 1818, was the last person tried for being a crypto-Jew.
The generally accepted number burnt at the stake by the Inquisition (including all categories such as Protestants, blasphemers, bigamists and crypto-Jews) is below 5,000 (see below).
Repression of Moriscos.
The Inquisition not only hunted for Protestants and for false converts from Judaism among the "conversos", but also searched for false or relapsed converts among the Moriscos, forced converts from Islam. The Moriscos were mostly concentrated in the recently conquered kingdom of Granada, in Aragon, and in Valencia. Officially, all Muslims in the Crown of Castile had been forcibly converted to Christianity in 1502. Muslims in the Crown of Aragon were obliged to convert by Charles I's decree of 1526, as most had been forcibly baptized during the Revolt of the Brotherhoods (1519–1523) and these baptisms were declared to be valid.
Many Moriscos were suspected of practising Islam in secret, and the jealousy with which they guarded the privacy of their domestic life prevented the verification of this suspicion. Initially they were not severely persecuted by the Inquisition, but experienced a policy of evangelization without torture, a policy not followed with those "conversos" who were suspected of being crypto-Jews. There were various reasons for this. Most importantly, in the kingdoms of Valencia and Aragon a large number of the Moriscos were under the jurisdiction of the nobility, and persecution would have been viewed as a frontal assault on the economic interests of this powerful social class. Still, fears ran high among the population that the Moriscos were traitorous, especially in Granada. The coast was regularly raided by Barbary pirates backed by Spain's enemy the Ottoman Empire, and the Moriscos were suspected of aiding them.
In the second half of the century, late in the reign of Philip II, conditions worsened between Old Christians and Moriscos. The 1568–1570 Morisco Revolt in Granada was harshly suppressed, and the Inquisition intensified its attention to the Moriscos. From 1570 Morisco cases became predominant in the tribunals of Zaragoza, Valencia and Granada; in the tribunal of Granada, between 1560 and 1571, 82% of those accused were Moriscos. Still, according to Kamen, the Moriscos did not experience the same harshness as judaizing "conversos" and Protestants, and the number of capital punishments was proportionally less.
In 1609 King Philip III, upon the advice of his financial adviser the Duke of Lerma and Archbishop of Valencia Juan de Ribera, decreed the Expulsion of the Moriscos. Hundreds of thousands of Moriscos were expelled, some of them probably sincere Christians. This was further fueled by the religious intolerance of Archbishop Ribera who quoted the Old Testament texts ordering the enemies of God to be slain without mercy and setting forth the duties of kings to extirpate them. The edict required: 'The Moriscos to depart, under the pain of death and confiscation, without trial or sentence... to take with them no money, bullion, jewels or bills of exchange... just what they could carry.' So successful was the enterprise, in the space of months, Spain was emptied of its Moriscos. Expelled were the Moriscos of Aragon, Murcia, Catalonia, Castile, Mancha and Extremadura. As for the Moriscos of Granada, such as the Herrador family who held positions in the Church and magistracy, they still had to struggle against exile and confiscation.
An indeterminate number of Moriscos remained in Spain and, during the 17th century, the Inquisition pursued some trials against them of minor importance: according to Kamen, between 1615 and 1700, cases against Moriscos constituted only 9 percent of those judged by the Inquisition.
Demographic consequences.
In December 2008, a genetic study of the current population of the Iberian Peninsula, published in the "American Journal of Human Genetics", estimated that about 10% have North African ancestors and 20% have Sephardi Jews as ancestors. Since there is no direct link between genetic makeup and religious affiliation, however, it is difficult to draw direct conclusions between their findings and forced or voluntary conversion. Nevertheless, the Sephardic result is in contradiction or not replicated in all the body of genetic studies done in Iberia and has been later questioned by the authors themselves and by Stephen Oppenheimer who estimates that much earlier migrations, 5000 to 10,000 years ago from the Eastern Mediterranean might also have accounted for the Sephardic estimates: "They are really assuming that they are looking at his migration of Jewish immigrants, but the same lineages could have been introduced in the Neolithic". The rest of genetic studies done in Spain estimate the Moorish contribution ranging from 2.5/3.4% to 7.7%.
Control of Protestants.
Despite much popular myth about the Spanish Inquisition relating to Protestants, it dealt with very few cases involving actual Protestants, as there were so few in Spain. The first of the trials against those labeled by the Inquisition as "Lutheran" were those against the sect of mystics known as the "Alumbrados" of Guadalajara and Valladolid. The trials were long, and ended with prison sentences of differing lengths, though none of the sect were executed. Nevertheless, the subject of the "Alumbrados" put the Inquisition on the trail of many intellectuals and clerics who, interested in Erasmian ideas, had strayed from orthodoxy (which is striking because both Charles I and Philip II of Spain were confessed admirers of Erasmus). Such was the case with the humanist Juan de Valdés, who was forced to flee to Italy to escape the process that had been begun against him, and the preacher, Juan de Ávila, who spent close to a year in prison. 
The first trials against Lutheran groups, as such, took place between 1558 and 1562, at the beginning of the reign of Philip II, against two communities of Protestants from the cities of Valladolid and Seville numbering about 120. The trials signaled a notable intensification of the Inquisition's activities. A number of "autos-da-fé" were held, some of them presided over by members of the royal family and around 100 executions took place. The "autos-da-fé" of the mid-century virtually put an end to Spanish Protestantism which was, throughout, a small phenomenon to begin with.
After 1562, though the trials continued, the repression was much reduced, According to Kamen, only about 200 Spaniards were accused of being Protestants in the last decades of the 16th century. "Most of them were in no sense Protestants...Irreligious sentiments, drunken mockery, anticlerical expressions, were all captiously classified by the inquisitors (or by those who denounced the cases) as ‘Lutheran.’ Disrespect to church images, and eating meat on forbidden days, were taken as signs of heresy"
and it is estimated that a dozen Spaniards were burned alive.
Censorship.
As one manifestation of the Counter-Reformation, the Spanish Inquisition worked actively to impede the diffusion of heretical ideas in Spain by producing "Indexes" of prohibited books. Such lists of prohibited books were common in Europe a decade before the Inquisition published its first. The first Index published in Spain in 1551 was, in reality, a reprinting of the Index published by the University of Louvain in 1550, with an appendix dedicated to Spanish texts. Subsequent Indexes were published in 1559, 1583, 1612, 1632, and 1640. The Indexes included an enormous number of books of all types, though special attention was dedicated to religious works, and, particularly, vernacular translations of the Bible.
Included in the Indexes, at one point, were many of the great works of Spanish literature. Also, a number of religious writers who are today considered saints by the Catholic Church saw their works appear in the Indexes. At first, this might seem counter-intuitive or even nonsensical—how were these Spanish authors published in the first place if their texts were then prohibited by the Inquisition and placed in the Index? The answer lies in the process of publication and censorship in Early Modern Spain. Books in Early Modern Spain faced prepublication licensing and approval (which could include modification) by both secular and religious authorities. However, once approved and published, the circulating text also faced the possibility of post-hoc censorship by being denounced to the Inquisition—sometimes decades later. Likewise, as Catholic theology evolved, once-prohibited texts might be removed from the Index.
At first, inclusion in the Index meant total prohibition of a text; however, this proved not only impractical and unworkable, but also contrary to the goals of having a literate and well-educated clergy. Works with one line of suspect dogma would be prohibited in their entirety, despite the remainder of the text's sound dogma. In time, a compromise solution was adopted in which trusted Inquisition officials blotted out words, lines or whole passages of otherwise acceptable texts, thus allowing these expurgated editions to circulate. Although in theory the Indexes imposed enormous restrictions on the diffusion of culture in Spain, some historians, such as Henry Kamen, argue that such strict control was impossible in practice and that there was much more liberty in this respect than is often believed. And Irving Leonard has conclusively demonstrated that, despite repeated royal prohibitions, romances of chivalry, such as Amadis of Gaul, found their way to the New World with the blessing of the Inquisition. Moreover, with the coming of the Age of Enlightenment in the 18th century, increasing numbers of licenses to possess and read prohibited texts were granted.
Despite repeated publication of the Indexes and a large bureaucracy of censors, the activities of the Inquisition did not impede the flowering of Spanish literature's "Siglo de Oro", although almost all of its major authors crossed paths with the Holy Office at one point or another. Among the Spanish authors included in the Index are: Bartolomé Torres Naharro, Juan del Enzina, Jorge de Montemayor, Juan de Valdés and Lope de Vega, as well as the anonymous Lazarillo de Tormes and the Cancionero General by Hernando del Castillo. La Celestina, which was not included in the Indexes of the 16th century, was expurgated in 1632 and prohibited in its entirety in 1790. Among the non-Spanish authors prohibited were Ovid, Dante, Rabelais, Ariosto, Machiavelli, Erasmus, Jean Bodin, Valentine Naibod and Thomas More (known in Spain as Tomás Moro). One of the most outstanding and best-known cases in which the Inquisition directly confronted literary activity is that of Fray Luis de León, noted humanist and religious writer of converso origin, who was imprisoned for four years (from 1572 to 1576) for having translated the Song of Songs directly from Hebrew.
Some scholars indicate that one of the main effects of the inquisition was to end free thought and scientific thought in Spain. As one contemporary Spanish in exile put it: "Our country is a land of ... barbarism; down there one cannot produce any culture without being suspected of heresy, error and Judaism. Thus silence was imposed on the learned." For the next few centuries, while the rest of Europe was slowly awakened by the influence of the Enlightenment, Spain stagnated. However, this conclusion is contested. The censorship of books was actually very ineffective, and prohibited books circulated in Spain without significant problems. The Spanish Inquisition never persecuted scientists, and relatively few scientific books were placed on the Index. On the other hand, Spain was a state with more political freedom than in other absolute monarchies in the 16th to 18th centuries. The backwardness of Spain in economy and science can hardly be attributed to the Inquisition.
Other offenses.
Although the Inquisition was created to suppress heresy, it also occupied itself with a wide variety of offences that only indirectly could be related to religious heterodoxy. Of a total of 49,092 trials from the period 1560–1700 registered in the archive of the Suprema, appear the following: "judaizantes" (5,007); "moriscos" (11,311); Lutherans (3,499); "alumbrados" (149); superstitions (3,750); heretical propositions (14,319); bigamy (2,790); solicitation (1,241); offences against the Holy Office of the Inquisition (3,954); miscellaneous (2,575).
These data demonstrate that not only New Christians ("conversos" of Jewish or Islamic descent) and Protestants faced investigation, but also Old Christians could be targeted for various reasons as well.
Witchcraft.
The category "superstitions" includes trials related to witchcraft. The witch-hunt in Spain had much less intensity than in other European countries (particularly France, Scotland, and Germany). One remarkable case was that of Logroño, in which the witches of Zugarramurdi in Navarre were persecuted. During the "auto-da-fé" that took place in Logroño on November 7 and November 8, 1610, 6 people were burned and another 5 burned in effigy. In general, nevertheless, the Inquisition maintained a skeptical attitude towards cases of witchcraft, considering it as a mere superstition without any basis. Alonso de Salazar Frías, who, after the trials of Logroño took the Edict of Faith to various parts of Navarre, noted in his report to the Suprema that, "There were neither witches nor bewitched in a village until they were talked and written about".
Blasphemy.
Included under the rubric of "heretical propositions" were verbal offences, from outright blasphemy to questionable statements regarding religious beliefs, from issues of sexual morality, to misbehaviour of the clergy. Many were brought to trial for affirming that "simple fornication" (sex between unmarried persons) was not a sin or for putting in doubt different aspects of Christian faith such as Transubstantiation or the virginity of Mary. Also, members of the clergy itself were occasionally accused of heretical propositions. These offences rarely lead to severe penalties.
Bigamy.
The Inquisition also pursued offences against morals, at times in open conflict with the jurisdictions of civil tribunals. In particular, there were numerous trials for bigamy, a relatively frequent offence in a society that only permitted divorce under the most extreme circumstances. In the case of men, the penalty was five years service as an oarsmen in a royal galley (tantamount to a death sentence). Women too were accused of bigamy. Also, many cases of solicitation during confession were adjudicated, indicating a strict vigilance over the clergy.
Sodomy.
Inquisitorial repression of the sexual offence of sodomy, considered, according to Canon Law, as a crime against nature, merits separate attention. This included cases of incidences of heterosexual and homosexual anal sex, rape, and separately bestiality. Civil authorities at times executed those convicted.
In 1506 at Seville the Inquisition made a special investigation into sodomy, causing many arrests and many fugitives and burning 12 persons, but in 1509 the Suprema in Castile declared that crime not within the jurisdiction of the Inquisition deciding that cases of sodomy could not be adjudicated, unless related to heresy. Alleging that sodomy had been introduced to Spain by the Moors, in 1524 the Spanish Ambassador to Rome obtained a special commission from Clement VII for the Holy Office to curb its spread by investigating laymen and clergy in the territories of Aragon, whether or not it was related to heresy; and proceeding according to local, municipal law in spite of the resistance by local bishops to this usurpation of their authority.
The tribunal of Zaragoza distinguished itself for its severity in judging these offences: between 1571—1579, 101 men accused of sodomy were processed and at least 35 were executed. In total, between 1570 and 1630 there were 534 trials (incl. 187 for homosexuality, 245 for bestiality, and 111 with unknown specification of the charges) with 102 executions (incl. 27 for homosexuality, 64 for bestiality and 11 uncertain cases).
The first sodomite was burned by the Inquisition in Valencia in 1572, and those accused included 19% clergy, 6% nobles, 37% workers, 19% servants, and 18% soldiers and sailors. A growing reluctance to convict those who, unlike heretics, could not escape by confession and penance led after 1630 to greater leniency. Torture decreased: in Valencia 21% of sodomites were tortured prior to 1630, but only 4% afterwards. The last execution "in persona" for sodomy by the Inquisition took place in Zaragoza in April 1633. In total, out of about 1,000 convicted of sodomy - 170 were actually burnt at the stake, including 84 condemned for bestiality and 75 for homosexuality, with 11 cases where the exact character of the charges is not known.
Nearly all of almost 500 cases of sodomy between persons concerned the relationship between an older man and an adolescent, often by coercion; with only a few cases where the couple were consenting homosexual adults. About 100 of the total involved allegations of child abuse. Adolescents were generally punished more leniently than adults, but only when they were very young (under ca. 12 years) or when the case clearly concerned rape, did they have a chance to avoid punishment altogether. As a rule, the Inquisition condemned to death only those "sodomites" over the age of 25 years. As about half of those tried were under this age, it explains the relatively small percent of death sentences.
Freemasonry.
In 1815, Francisco Javier de Mier y Campillo, the Inquisitor General of the Spanish Inquisition and the Bishop of Almería, suppressed Freemasonry and denounced the lodges as "societies which lead to atheism, to sedition and to all errors and crimes." He then instituted a purge during which Spaniards could be arrested on the charge of being "suspected of Freemasonry".
Organization.
Beyond its role in religious affairs, the Inquisition was also an institution at the service of the monarchy. The Inquisitor General, in charge of the Holy Office, was designated by the crown. The Inquisitor General was the only public office whose authority stretched to all the kingdoms of Spain (including the American viceroyalties), except for a brief period (1507–1518) during which there were two Inquisitors General, one in the kingdom of Castile, and the other in Aragon.
The Inquisitor General presided over the Council of the Supreme and General Inquisition (generally abbreviated as "Council of the Suprema"), created in 1483, which was made up of six members named directly by the crown (the number of members of the Suprema varied over the course of the Inquisition's history, but it was never more than 10). Over time, the authority of the Suprema grew at the expense of the power of the Inquisitor General.
The Suprema met every morning, save for holidays, and for two hours in the afternoon on Tuesdays, Thursdays and Saturdays. The morning sessions were devoted to questions of faith, while the afternoons were reserved for "minor heresies" cases of perceived unacceptable sexual behavior, bigamy, witchcraft, etc.
Below the Suprema were the different tribunals of the Inquisition, which were, in their origins, itinerant, installing themselves where they were necessary to combat heresy, but later being established in fixed locations. In the first phase, numerous tribunals were established, but the period after 1495 saw a marked tendency towards centralization.
There were only four tribunals in the kingdom of Aragon: Zaragoza and Valencia (1482), Barcelona (1484), and Majorca (1488). Ferdinand the Catholic also established the Spanish Inquisition in Sicily (1513), housed in Palermo and Sardinia, in the town of Sassari. In the Americas, tribunals were established in Lima and in Mexico City (1569) and, in 1610, in Cartagena de Indias (present day Colombia).
Composition of the tribunals.
Initially, each of the tribunals included two inquisitors, a "calificador", an "alguacil" (bailiff) and a "fiscal" (prosecutor); new positions were added as the institution matured.
The inquisitors were preferably jurists more than theologians, and, in 1608, Philip III even stipulated that all the inquisitors must have a background in law. The inquisitors did not typically remain in the position for a long time: for the Court of Valencia, for example, the average tenure in the position was about two years. Most of the inquisitors belonged to the secular clergy (priests who were not members of religious orders), and had a university education.
The "fiscal" was in charge of presenting the accusation, investigating the denunciations and interrogating the witnesses by the use of physical and mental torture. The "calificadores" were generally theologians; it fell to them to determine if the defendant's conduct added up to a crime against the faith. Consultants were expert jurists who advised the court in questions of procedure. The court had, in addition, three secretaries: the "notario de secuestros" (Notary of Property), who registered the goods of the accused at the moment of his detention; the "notario del secreto" (Notary of the Secret), who recorded the testimony of the defendant and the witnesses; and the "escribano general" (General Notary), secretary of the court.
The "alguacil" was the executive arm of the court: he was responsible for detaining, jailing, and physically torturing the defendant. Other civil employees were the "nuncio", ordered to spread official notices of the court, and the "alcaide", jailer in charge of feeding the prisoners.
In addition to the members of the court, two auxiliary figures existed that collaborated with the Holy Office: the "familiares" and the "comissarios" (commissioners). "Familiares" were lay collaborators of the Inquisition, who had to be permanently at the service of the Holy Office. To become a familiar was considered an honour, since it was a public recognition of "limpieza de sangre" — Old Christian status — and brought with it certain additional privileges. Although many nobles held the position, most of the "familiares" many came from the ranks of commoners. The commissioners, on the other hand, were members of the religious orders who collaborated occasionally with the Holy Office.
One of the most striking aspects of the organization of the Inquisition was its form of financing: devoid of its own budget, the Inquisition depended exclusively on the confiscation of the goods of the denounced. It is not surprising, therefore, that many of those prosecuted were rich men. That the situation was open to abuse is evident, as stands out in the memorial that a "converso" from Toledo directed to Charles I: Cited in Kamen, op. cit., p. 151.
Functioning of the inquisition.
Near the outset of the Inquisition, in a letter of April 14, 1482, Pope Sixtus IV instructed the Spanish to ensure due process, allow legal counsel and appeal to Rome. King Ferdinand defiantly rejected Papal control, the Inquisition becoming thereafter a tool of the monarchy, rather than the church. In 1483, Ferdinand made Torquemada the Inquisitor General of most areas of Spain. Its procedures were set out in various "Instrucciones" issued by the successive Inquisitors General, Torquemada, Deza, and Valdés.
Accusation.
When the Inquisition arrived in a city, the first step was the "Edict of Grace". Following the Sunday mass, the Inquisitor would proceed to read the edict; it explained possible heresies and encouraged all the congregation to come to the tribunals of the Inquisition to "relieve their consciences". They were called "Edicts of Grace" because all of the self-incriminated who presented themselves within a "period of grace" (usually ranging from thirty to forty days) were offered the possibility of reconciliation with the Church without severe punishment. The promise of benevolence was effective, and many voluntarily presented themselves to the Inquisition and were often encouraged to denounce others who had also committed offenses, informants being the Inquisition's primary source of information. After about 1500, the Edicts of Grace were replaced by the "Edicts of Faith", which left out the grace period and instead encouraged the denunciation of those guilty.
The denunciations were anonymous, and the defendants had no way of knowing the identities of their accusers. This was one of the points most criticized by those who opposed the Inquisition (for example, the Cortes of Castile, in 1518). In practice, false denunciations were frequent. Denunciations were made for a variety of reasons, from genuine concern, to rivalries and personal jealousies.
Detention.
After a denunciation, the case was examined by the "calificadores" (qualifiers), who had to determine if there was heresy involved, followed by detention of the accused. In practice, however, many were detained in preventive custody, and many cases of lengthy incarcerations occurred, lasting up to two years, before the "calificadores" examined the case.
Detention of the accused entailed the preventive sequestration of their property by the Inquisition. The property of the prisoner was used to pay for procedural expenses and the accused's own maintenance and costs. Often the relatives of the defendant found themselves in outright misery. This situation was only remedied following instructions written in 1561.
The entire process was undertaken with the utmost secrecy, as much for the public as for the accused, who were not informed about the accusations that were levied against them. Months, or even years could pass without the accused being informed about why they were imprisoned. The prisoners remained isolated, and, during this time, the prisoners were not allowed to attend Mass nor receive the sacraments. The jails of the Inquisition were no worse than those of secular authorities, and there are even certain testimonies that occasionally they were much better.
The trial.
The inquisitorial process consisted of a series of hearings, in which both the denouncers and the defendant gave testimony. A defense counsel was assigned to the defendant, a member of the tribunal itself, whose role was simply to advise the defendant and to encourage them to speak the truth. The prosecution was directed by the "fiscal". Interrogation of the defendant was done in the presence of the "Notary of the Secreto", who meticulously wrote down the words of the accused. The archives of the Inquisition, in comparison to those of other judicial systems of the era, are striking in the completeness of their documentation. In order to defend themselves, the accused had two possibilities: "abonos" (to find favourable witnesses, akin to "substantive" evidence/testimony in Anglo-American law) or "tachas" (to demonstrate that the witnesses of accusers were not trustworthy, akin to Anglo-American "impeachment" evidence/testimony).
In order to interrogate the accused, the Inquisition made use of torture, but not in a systematic way. It was applied mainly against those suspected of Judaism and Protestantism, beginning in the 16th century. For example, Lea estimates that between 1575 and 1610 the court of Toledo tortured approximately a third of those processed for heresy. In other periods, the proportions varied remarkably. Torture was always a means to obtain the confession of the accused, not a punishment itself. Torture was also applied without distinction of sex or age, including children and the aged.
Torture.
As with all European tribunals of the time, torture was employed. The Spanish inquisition, however, engaged in it far less often and with greater care than other courts. Historian Henry Kamen contends that some "popular" accounts of the inquisition (those that describe scenes of uncontrolled sadistic torture) are not based in truth. Kamen argues that torture was only ever used to elicit information or a confession, not for punitive reasons. Modern scholars have determined that torture was used in two percent of the cases, and in less than one percent of the cases was it used a second time, never more than that. The torture lasted up to 15 minutes.
Although the Inquisition was technically forbidden from permanently harming or drawing blood, this still allowed for methods of torture. The methods most used, and common in other secular and ecclesiastical tribunals, were "garrucha", "toca" and the "potro". The application of the "garrucha", also known as the strappado, consisted of suspending the victim from the ceiling by the wrists, which are tied behind the back. Sometimes weights were tied to the ankles, with a series of lifts and drops, during which the arms and legs suffered violent pulls and were sometimes dislocated. The "toca", also called "interrogatorio mejorado del agua", consisted of introducing a cloth into the mouth of the victim, and forcing them to ingest water spilled from a jar so that they had the impression of drowning (see: waterboarding). The "potro", the rack, was the instrument of torture used most frequently.
The assertion that "confessionem esse veram, non factam vi tormentorum" (literally: ((a person's)) confession is truth, not made by way of torture.) sometimes follows a description of how, after torture had ended, the subject freely confessed to the offenses. Thus, all confession acquired by means of torture were considered completely valid as they were supposedly made of the confessor's own free will.
Once the process concluded, the inquisidores met with a representative of the bishop and with the "consultores", experts in theology or Canon Law, which was called the "consulta de fe". The case was voted and sentence pronounced, which had to be unanimous. In case of discrepancies, the "Suprema" had to be informed.
According to authorities within the Eastern Orthodox Church, there was at least one casualty tortured by those "Jesuits" (though most likely, Franciscans) who administered the Spanish Inquisition in North America: St. Peter the Aleut.
Sentencing.
Frequently, cases were judged "in absentia", and when the accused died before the trial finished, the condemned were burned in effigy.
The distribution of the punishments varied considerably over time. It is believed that sentences of death were enforced in the first stages within the long history of the Inquisition. According to García Cárcel, the court of Valencia employed the death penalty in 40% of the processings before 1530, but later that percentage dropped to 3%).
The "autos-da-fé".
If the sentence was condemnatory, this implied that the condemned had to participate in the ceremony of an auto de fe (more commonly known in English as an "auto-da-fé"), that solemnized their return to the Church (in most cases), or punishment as an impenitent heretic. The "autos-da-fé" could be private ("auto particular") or public ("auto publico" or "auto general").
Although initially the public "autos" did not have any special solemnity nor sought a large attendance of spectators, with time they became solemn ceremonies, celebrated with large public crowds, amidst a festive atmosphere. The "auto-da-fé" eventually became a baroque spectacle, with staging meticulously calculated to cause the greatest effect among the spectators.
The "autos" were conducted in a large public space (in the largest plaza of the city, frequently), generally on holidays. The rituals related to the "auto" began the previous night (the "procession of the Green Cross") and sometimes lasted the whole day. The "auto-da-fé" frequently was taken to the canvas by painters: one of the better known examples is the painting by Francesco Rizzi held by the Prado Museum in Madrid and which represents the "auto" celebrated in the Plaza Mayor of Madrid on June 30, 1680. The last public "auto-da-fé" took place in 1691.
The "auto-da-fé" involved: a Catholic Mass; prayer; a public procession of those found guilty; and a reading of their sentences (Peters 1988: 93-94). They took place in public squares or esplanades and lasted several hours: ecclesiastical and civil authorities attended. Artistic representations of the "auto-da-fé" usually depict torture and the burning at the stake. However, this type of activity never took place during an "auto-da-fé", which was in essence a religious act. Torture was not administered after a trial concluded, and executions were always held after and separate from the "auto-da-fé" (Kamen 1997: 192-213), though in the minds and experiences of observers and those undergoing the confession and execution, the separation of the two might be experienced as merely a technicality.
The first recorded "auto-da-fé" was held in Paris in 1242, during the reign of Louis IX. However, the first Spanish "auto-da-fé" did not take place until Seville in 1481; six of the men and women subjected to this first religious ritual were later executed. The Inquisition had limited power in Portugal, having been established in 1536 and officially lasting until 1821, although its influence was much weakened with the government of the Marquis of Pombal in the second half of the 18th century. "Autos-da-fé" also took place in Mexico, Brazil and Peru: contemporary historians of the Conquistadors such as Bernal Díaz del Castillo record them. They also took place in the Portuguese colony of Goa, India, following the establishment of Inquisition there in 1562–1563.
The arrival of the Enlightenment in Spain slowed inquisitorial activity. In the first half of the 18th century, 111 were condemned to be burned in person, and 117 in effigy, most of them for judaizing. In the reign of Philip V, there were 125 "autos-da-fé", while in the reigns of Charles III and Charles IV only 44.
Cited in Elorza, "La Inquisición y el pensamiento ilustrado." Historia 16. Especial 10º Aniversario "La Inquisición"; p. 81.
In its new role, the Inquisition tried to accentuate its function of censoring publications, but found that Charles III had secularized censorship procedures and, on many occasions, the authorization of the Council of Castile hit the more intransigent position of the Inquisition. Since the Inquisition itself was an arm of the state, being within the Council of Castile, civil, rather than ecclesiastical, censorship usually prevailed. This loss of influence can also be explained because the foreign Enlightenment texts entered the peninsula through prominent members of the nobility or government, influential people with whom it was very difficult to interfere. Thus, for example, Diderot's Encyclopedia entered Spain thanks to special licenses granted by the king.
Elorza, "La Inquisición y el pensamiento ilustrado." p. 84.
However, inquisitorial activity was impossible in the face of the information avalanche that crossed the border; in 1792
the multitude of seditious papers... does not allow formalizing the files against those who introduce them...
The fight from within against the Inquisition was almost always clandestine. The first texts that questioned the Inquisition and praised the ideas of Voltaire or Montesquieu appeared in 1759. After the suspension of pre-publication censorship on the part of the Council of Castile in 1785, the newspaper "El Censor" began the publication of protests against the activities of the Holy Office by means of a rationalist critique and, even, Valentin de Foronda published "Espíritu de los Mejores Diarios", a plea in favour of freedom of expression that was avidly read in the salons. Also, Manuel de Aguirre, in the same vein, wrote, On Toleration in "El Censor", "El Correo de los Ciegos" and "El Diario de Madrid".
End of the Inquisition.
During the reign of Charles IV of Spain, in spite of the fears that the French Revolution provoked, several events took place that accelerated the decline of the Inquisition. In the first place, the state stopped being a mere social organizer and began to worry about the well-being of the public. As a result, they considered the land-holding power of the Church, in the "señoríos" and, more generally, in the accumulated wealth that had prevented social progress. On the other hand, the perennial struggle between the power of the throne and the power of the Church, inclined more and more to the former, under which, Enlightenment thinkers found better protection for their ideas. Manuel Godoy and Antonio Alcalá Galiano were openly hostile to an institution whose only role had been reduced to censorship and was the very embodiment of the Spanish Black Legend, internationally, and was not suitable to the political interests of the moment:Elorza, "La Inquisición y el Pensamiento Ilustrado". Historia 16. Especial 10º Aniversario "La Inquisición"; pg. 88
The Inquisition was abolished during the domination of Napoleon and the reign of Joseph Bonaparte (1808–1812). In 1813, the liberal deputies of the Cortes of Cádiz also obtained its abolition, largely as a result of the Holy Office's condemnation of the popular revolt against French invasion. But the Inquisition was reconstituted when Ferdinand VII recovered the throne on July 1, 1814. It was again abolished during the three year Liberal interlude known as the Trienio liberal. Later, during the period known as the Ominous Decade, the Inquisition was not formally re-established, although, "de facto", it returned under the so-called Meetings of Faith, tolerated in the dioceses by King Ferdinand. These had the dubious honour of executing the last heretic condemned, the school teacher Cayetano Ripoll, garroted in Valencia on July 26, 1826 (presumably for having taught deist principles), all amongst a European-wide scandal at the despotic attitude still prevailing in Spain. Juan Antonio Llorente, who had been the Inquisition's general secretary in 1789, became a Bonapartist and published a critical history in 1817 from his French exile, based on his privileged access to its archives.
The Inquisition was definitively abolished on July 15, 1834, by a Royal Decree signed by regent Maria Christina of the Two Sicilies, Ferdinand VII's liberal widow, during the minority of Isabella II and with the approval of the President of the Cabinet Francisco Martínez de la Rosa. (It is possible that something similar to the Inquisition acted during the 1833–1839 First Carlist War, in the zones dominated by the Carlists, since one of the government measures praised by Conde de Molina Carlos Maria Isidro de Borbon was the re-implementation of the Inquisition to protect the Church). During the Carlist Wars it was the conservatives who fought the liberals who wanted to reduce the Church's power, amongst other reforms to liberalize the economy. It can be added that Franco during the Spanish Civil War is alleged to have stated that he would attempt to reintroduce it, possibly as a sop to Vatican approval of his coup.
The Alhambra Decree that had expelled the Jews was formally rescinded on December 16, 1968.
Outcomes.
Confiscations.
It is unknown exactly how much wealth was confiscated from converted Jews and others tried by the Inquisition. Wealth confiscated in one year of persecution in the small town of Guadaloupe paid the costs of building a royal residence. There are numerous records of the opinion of ordinary Spaniards of the time that "the Inquisition was devised simply to rob people". "They were burnt only for the money they had", a resident of Cuenca averred. "They burn only the well-off", said another. In 1504 an accused stated, "only the rich were burnt". …In 1484…Catalina de Zamora was accused of asserting that "this Inquisition that the fathers are carrying out is as much for taking property from the conversos as for defending the faith. It is the goods that are the heretics." This saying passed into common usage in Spain. In 1524 a treasurer informed Charles V that his predessor had received ten million ducats from the conversos, but the figure is unverified. In 1592 an inquisitor admitted that most of the fifty women he arrested were rich. In 1676, the Suprema claimed it had confiscated over 700,000 ducats for the royal treasury (which was paid money only after the Inquisition's own budget, amounting in one known case to only 5%). The property on Mallorca alone in 1678 was worth "well over 2,500,000 ducats".
Death tolls.
García Cárcel estimates that the total number processed by the Inquisition throughout its history was approximately 150,000; applying the percentages of executions that appeared in the trials of 1560–1700—about 2%—the approximate total would be about 3,000 put to death. Nevertheless, very probably this total should be raised keeping in mind the data provided by Dedieu and García Cárcel for the tribunals of Toledo and Valencia, respectively. It is likely that the total would be between 3,000 and 5,000 executed.
Modern historians have begun to study the documentary records of the Inquisition. The archives of the Suprema, today held by the National Historical Archive of Spain (Archivo Histórico Nacional), conserves the annual relations of all processes between 1540 and 1700. This material provides information on about 44,674 judgements, the latter studied by Gustav Henningsen and Jaime Contreras. These 44,674 cases include 826 executions "in persona" and 778 "in effigie". This material, however, is far from being complete—for example, the tribunal of Cuenca is entirely omitted, because no "relaciones de causas" from this tribunal have been found, and significant gaps concern some other tribunals (e.g. Valladolid). Many more cases not reported to the Suprema are known from the other sources (e.g. no "relaciones de causas" from Cuenca have been found, but its original records have been preserved), but were not included in Contreras-Henningsen's statistics for the methodological reasons. William Monter estimates 1000 executions between 1530–1630 and 250 between 1630–1730.
The archives of the Suprema only provide information surrounding the processes prior to 1560. To study the processes themselves, it is necessary to examine the archives of the local tribunals; however, the majority have been lost to the devastation of war, the ravages of time or other events. Jean-Pierre Dedieu has studied those of Toledo, where 12,000 were judged for offences related to heresy. Ricardo García Cárcel has analyzed those of the tribunal of Valencia. These authors' investigations find that the Inquisition was most active in the period between 1480 and 1530, and that during this period the percentage condemned to death was much more significant than in the years studied by Henningsen and Contreras. Henry Kamen gives the number of about 2,000 executions "in persona" in the whole Spain up to 1530.
Historiography.
How historians and commentators have viewed the Spanish Inquisition has changed over time, and continues to be a source of controversy to this day. Before and during the 19th century historical interest focused on who was being persecuted. In the early and mid 20th century historians examined the specifics of what happened and how it influenced Spanish history. In the later 20th and 21st century, historians have re-examined how severe the Inquisition really was, calling into question some of the conclusions made earlier in the 20th century.
19th to early 20th century scholarship.
Before the rise of professional historians in the 19th century, the Spanish Inquisition had largely been studied and portrayed by Protestant scholars who saw it as the archetypal symbol of Catholic intolerance and ecclesiastical power. The Spanish Inquisition for them was largely associated with the persecution of Protestants. The 19th century professional historians, including the Spanish scholar Amador de los Rios, were the first to challenge this perception and look seriously at the role of Jews and Muslims.
At the start of the 20th century Henry Charles Lea published the groundbreaking "History of the Inquisition in Spain". This influential work saw the Spanish Inquisition as "an engine of immense power, constantly applied for the furtherance of obscurantism, the repression of thought, the exclusion of foreign ideas and the obstruction of progress." Lea documented the Inquisition's methods and modes of operation in no uncertain terms, calling it "theocratic absolutism" at its worst. In the context of the polarization between Protestants and Catholics during the second half of the 19th century, some of Lea's contemporaries, as well as most modern scholars thought Lea's work had an anti-Catholic bias.
William H. Prescott, the Boston historian, likened the Inquisition to an "eye that never slumbered".
Starting in the 1920s, Jewish scholars picked up where Lea's work left off. Yitzhak Baer's "History of the Jews in Christian Spain", Cecil Roth's "History of the Marranos" and, after World War II, the work of Haim Beinart who for the first time published trial transcripts of cases involving conversos.
Revision after 1960.
One of the first books to challenge the classical view was "The Spanish Inquisition" (1965) by Henry Kamen. Kamen purported that the Inquisition was not nearly as cruel or as powerful as commonly believed. The book was very influential and largely responsible for subsequent studies in the 1970s to try to quantify (from archival records) the Inquisition's activities from 1480 to 1834. Those studies showed there was an initial burst of activity against conversos suspected of relapsing into Judaism, and a mid-16th century pursuit of Protestants, but the Inquisition served principally as a forum Spaniards occasionally used to humiliate and punish people they did not like: blasphemers, bigamists, foreigners and, in Aragon, homosexuals and horse smugglers. There were so few Protestants in Spain that widespread persecution of Protestantism was not physically possible. Kamen went on to publish two more books in 1985 and 2006 that incorporated new findings, further supporting the view that the Inquisition was not as bad as once described by Lea and others. Along similar lines is Edward Peters's "Inquisition" (1988).
One of the most important works in challenging traditional views of the Inquisition as it related to the Jewish conversos or New Christians, was "The Origins of the Inquisition in Fifteenth Century Spain" by Benzion Netanyahu. It challenged the view that most conversos were actually practicing Judaism in secret and were persecuted for their crypto-Judaism. Rather, according to Netanyahu, the persecution was fundamentally racial, and was a matter of envy of their success in Spanish society.

Texas Revolution
The Texas Revolution, also known as the Texas War of Independence, was the military conflict between the government of Mexico and Texas colonists that began October 2, 1835 and resulted in the establishment of the Republic of Texas after the final battle on April 21, 1836. Intermittent conflicts between the two nations continued into the 1840s, finally being resolved with the Mexican–American War of 1846 to 1848 after the annexation of Texas to the United States.
Long-running political and cultural clashes between the Mexican government and the settlers in Texas were exacerbated after conservative forces took control and the Siete Leyes (Seven Laws) of 1835 were approved. It displaced the federal Constitution of 1824 with the 1835 Constitution of Mexico, thereby ending the federal system and establishing a provisional centralized government in its place. The new laws were unpopular throughout Mexico, leading to secession movements and violence in several Mexican states.
Open warfare began in Texas on October 2, 1835, with the Battle of Gonzales. Early Texan Army successes at La Bahía and San Antonio (Battle of Goliad, Siege of Béxar) were soon reversed when the Mexican Army retook the territory a few months later (Battle of Coleto, Battle of the Alamo). The war ended at the Battle of San Jacinto, where the Texian army under General Sam Houston routed the Mexican forces with a surprise attack.
Background.
The Mexican War for Independence (1810–1821) severed control that Spain had exercised on its North American territories, and the new country of Mexico was formed from much of the individual territory that had comprised New Spain. On October 4, 1824, Mexico adopted a new constitution which defined the country as a federal republic with nineteen states and four territories. The former province of Spanish Texas became part of a newly created state, Coahuila y Tejas, whose capital was at Saltillo, hundreds of miles from the former Texas capital, San Antonio de Bexar (now San Antonio, Texas, USA).
The new country emerged essentially bankrupt from the war against Spain. With little money for the military, Mexico encouraged settlers to create their own militias for protection against hostile Indian tribes. Texas was very sparsely populated and in the hope that an influx of settlers could control the Indian raids, the government liberalized immigration policies for the region. The first group of colonists, known as the Old Three Hundred, had arrived in 1822 to settle an empresarial grant that had been given to Stephen F. Austin. Of the 24 empresarios, only one settled citizens from within the Mexican interior; most of the remaining settlers came from the United States.
The Mexican-born settlers in Texas were soon vastly outnumbered by people born in the United States. To address this situation, President Anastasio Bustamante implemented several measures on April 6, 1830. Chief among these was a prohibition against further immigration to Tejas from the United States, although American citizens would be allowed to settle in other parts of Mexico. Furthermore, the property tax law, intended to exempt immigrants from paying taxes for ten years, was rescinded, and tariffs were increased on goods shipped from the United States. Bustamante also ordered all Tejas settlers to comply with the federal prohibition against slavery or face military intervention. These measures did not have the intended effect. Settlers simply circumvented or ignored the laws. By 1834, it was estimated that over 30,000 Anglos lived in Coahuila y Tejas, compared to only 7,800 Mexican-born citizens. By 1836, there were approximately 5,000 slaves in Texas.
Possible Role of Slavery.
One possible issue and motivation for the revolution was Mexico's prohibition of slavery. The Mexican government had invited immigrants to Mexican Texas with the understanding that they would produce food crops, insisting upon production of corn, grain and beef. Former American settlers found such micromanagement of the land use to be opposed to their economic interests in slavery. They tended to ignore their contracts. If these were enforced, Texas slave-owners stood to lose a large investment in slave labor. Cotton was in high demand throughout Europe and so a lucrative export throughout the southern United States. Much of the land being opened up to Anglos in Mexican Texas was well suited for cotton, but raising cotton was a labor intensive endeavor at the time, and many Texans thought that slave-labor was more profitable. Most of the American settlers in Mexico were from southern states, where slavery was still legal. They even brought their slaves with them. Because slavery was illegal in Mexico, these settlers made their slaves sign agreements giving them the status of indentured servants – essentially slavery by another name. The Mexican authorities nominally regulated this practice, and the issue continued to flare up, especially when slaves ran escaped. By the 1830s, many settlers were afraid that the Mexicans would take the slaves away, which made them favor independence. Some non-slave-owning settlers recognized the economic impact of the prohibition, and as potential beneficiaries of the slave-based economy, supported independence as well.
The significance of slavery in the Texas War for Independence is unclear and difficult to determine. It is important to address the fact that the Texas Declaration of Independence of 1836 does not mention slavery, unlike Texas' 1861 Ordinance of Secession. Furthermore, the vast majority of primary-sources from the period do not mention slavery as a cause, but rather focus on issues such as religious freedom, the abrogation of the Mexican Constitution, and land rights. 
Other Issues.
Texans were becoming increasingly disillusioned with the Mexican government. Many of the Mexican soldiers garrisoned in Texas were convicted criminals who were given the choice of prison or serving in the army in Texas. Many Texians were also unhappy with the location of their state capital, which moved periodically between Saltillo and Monclova, both of which were in southern Coahuila, some away; they wanted Texas to be a separate state from Coahuila (but not independent from Mexico) and to have its own capital.
The other interest of the Texans was representation of their interests in the government. They believed a closer location for the capital would help to stem corruption and facilitate other matters of government. Texans continued to lobby to overturn the laws of 1830. In April 1833, settlers called a convention to discuss proposed changes in immigration, judicial, and other political policies. The delegates also advocated separate statehood for Texas and elected Austin to carry a proposed state constitution to Mexico City. The new Mexican President, Antonio Lopez de Santa Anna, approved many of the proposals, but refused to agree to separate statehood; Austin was jailed when he wrote a letter advocating that Texans act unilaterally on statehood.
In 1834, because of perceived troubles within the Mexican government, Santa Anna went through a process of dissolving state legislatures, disarming state militias, and abolishing the Constitution of 1824. He also imprisoned some cotton plantation owners who refused to raise their assigned crops, which were intended to be redistributed within Mexico instead of being exported.
Mexican preparation.
In early 1835, as the Mexican government transitioned from a federalist model to centralism, wary Texans began forming Committees of Correspondence and Safety. A central committee in San Felipe de Austin coordinated their activities. The Texians staged a minor revolt against customs duties in June; these Anahuac Disturbances prompted Mexican President Antonio López de Santa Anna to send additional troops to Texas. In July, Colonel Nicolas Condelle led 200 men to reinforce Presidio La Bahía.
The following month, a contingent of soldiers arrived in Béxar with Colonel Domingo de Ugartechea. Fearing that stronger measures were needed to quell the unrest, Santa Anna ordered his brother-in-law, General Martín Perfecto de Cos to "repress with strong arm all those who, forgetting their duties to the nation which has adopted them as her children, are pushing forward with a desire to live at their own option without subjection to the laws". Cos landed at the port of Copano on September 20 with approximately 500 soldiers.
Austin was released in July, having never been formally charged with sedition, and was in Texas by August. Austin saw little choice but revolution. A consultation was scheduled for October to discuss possible formal plans to revolt, and Austin sanctioned it.
Texan Army offensive.
Before the consultation could happen, however, in accordance with Santa Anna’s nationwide call to disarm state militias, Colonel Domingo Ugartechea, who was stationed in San Antonio, ordered the Texans to return a cannon given to them by Mexico that was stationed in Gonzales. The Texans refused. Ugartechea sent Lieutenant Francisco de Castañeda and 100 dragoons to retrieve it. When he arrived at the rain-swollen banks of the Guadalupe River near Gonzales, there were just eighteen Texans to oppose him. Unable to cross, Castañeda established a camp, and the Texians buried the cannon and called for volunteers. The Texans stalled for several days until reinforcements arrived. The Texan Army attacked early on October 2, 1835. The Battle of Gonzales ended with a Mexican withdrawal. Two Mexican soldiers were killed, and one Texian was injured when he fell off his horse during the skirmish. Over the next several days, The Texian Army continued to gather at Gonzales.
After learning of the Texan Army victory, Cos made haste for Béxar. He left with the bulk of his soldiers on October 5, but because he was unable to find adequate transportation, most of his supplies remained at La Bahía. Unaware of Cos's departure, on October 6 Texans in Matagorda decided to march on the Mexican garrison at Presidio La Bahía in Goliad. They intended to kidnap Cos and, if possible, steal the estimated $50,000 that was rumored to accompany him. On October 10, the Texians stormed the presidio, and the Mexican garrison surrendered after a 30-minute battle. One Texian was wounded, and estimates of Mexican casualties range from one to three soldiers killed and from three to seven wounded. Approximately 20 soldiers escaped. They warned the garrisons at Copano and Refugio of the advancing Texians; those garrisons abandoned their posts and joined the soldiers at Fort Lipantitlán, near San Patricio.
The Texans confiscated over $10,000 in food, blankets, clothing, and other provisions. For the next three months, the provisions were parceled out among companies in the Texian Army. Over the next several days, The Texian Army continued to gather at La Bahia. Austin ordered that 100 men remain at Goliad, under the command of Captain Philip Dimmitt, while the rest should join the Texian Army in marching on Cos's troops in Béxar. Within days of his appointment, Dimmitt began advocating for an attack on Fort Lipantitlán. Dimmitt believed that Texian control of Fort Lipantitlán would "secure the frontier, provide a vital station for defense, create instability among the centralists, and encourage Mexican federalists". The Mexican soldiers at Fort Lipantitlán intimidated the settlers in San Patricio, leaving them afraid to openly support the federalists who defied Mexican president Antonio López de Santa Anna.
On October 31, Dimmitt sent a group of men under Adjutant Ira Westover to take the fort. They arrived at Fort Lipantitlán late on November 3 and took the undermanned fort without firing a shot. The next day, the Texians dismantled the fort. As they prepared to return to Goliad, the remainder of the Mexican garrison, who had been out on patrol, approached. The Battle of Lipantitlán lasted only 30 minutes, and resulted in the retreat of the Mexican soldiers. Their departure left only one remaining group of Mexican soldiers in Texas, those under Cos at Béxar. The Texian Army controlled the Gulf Coast, so all communication with the Mexican interior would now be transferred overland. The long journey left Cos unable to quickly request or receive reinforcements or supplies.
Siege of Bexar.
While Dimmitt supervised the Texan Army forces along the Gulf Coast, Stephen F. Austin worked to organize the men gathered in Gonzales into a cohesive army. On October 13, Austin led the newly formed Texan Army toward Bexar to engage Cos and his troops. One week later, the men reached Salado Creek and initiated a siege of Bexar. The Texians gradually moved their camp nearer Bexar, and on October 27 had made camp at Mission San Francisco de la Espada. That afternoon Austin sent James Bowie and James Fannin with a contingent of men to find a closer campsite. The men realized that Mission Concepción was a good defensive spot. Rather than return immediately to Austin, as their orders specified, Bowie and Fannin instead sent a courier to bring Austin directions to Concepción. The next day, an angry Austin issued a statement threatening officers who chose not to follow orders with court-martial.
Cos had learned that the Texan Army was temporarily divided and sent Ugartechea and troops to engage Bowie and Fannin's men. The ensuing Battle of Concepción, which historian J.R. Edmondson describes as "the first major engagement of the Texas Revolution", was the last offensive against the Texian Army that Cos would order. Although historian Alwyn Barr of Texas Tech University believes that the battle "should have taught ... lessons on Mexican courage and the value of a good defensive position", historian Stephen Hardin believes that "the relative ease of the victory at Concepción instilled in the Texians a reliance on their long rifles and a contempt for their enemies".
The Texan Army volunteers had little or no experience as professional soldiers, and by early November many had begun to miss their homes. As the weather turned colder and rations grew smaller, many soldiers became sick, and groups of men began to leave, most without permission. On November 18, however, a group of volunteers from the United States, known as the New Orleans Greys, joined the Texan Army. Unlike the majority of the Texian volunteers, the Greys looked like soldiers, with uniforms, well-maintained rifles, adequate ammunition, and some semblance of discipline. The Greys, as well as several companies of Texians who had arrived recently, were eager to face the Mexican Army directly. The Texan volunteers, however, were becoming discouraged with the siege. Within days Austin resigned his command to become a commissioner to the United States; Texan Army elected Edward Burleson as their new commander.
On November 26, Burleson received word that a Mexican pack train of mules and horses, accompanied by 50–100 Mexican soldiers, was within of Bexar. After a near mutiny, Burleson sent Bowie and William H. Jack with cavalry and infantry to intercept the supplies. In the subsequent skirmish, the Mexican forces were forced to retreat to San Antonio, leaving their cargo behind. To the disappointment of the Texans, the saddlebags contained only fodder for the horses; for this reason the battle was later known as the Grass Fight.
Although the victory briefly uplifted the Texian troops, morale continued to fall as the weather turned colder and the men grew bored. Burleson proposed that the army lift the siege and retreat to Goliad until spring. His war council was ambivalent until Colonel Ben Milam stood up and yelled, "Who will go with old Ben Milam into San Antonio?" Several hundred soldiers, including the New Orleans Greys, agreed to participate in the attack, which commenced on December 5. Milam and Colonel Frank W. Johnson led two columns of men into the city, and for the next few days they fought their way from house to house towards the fortified plazas where the Mexican soldiers waited. Milam was killed by a sharpshooter on December 7.
On December 9, Cos and the bulk of his men withdrew into the Alamo Mission on the outskirts of Bexar. Cos presented a plan for a counterattack; cavalry officers believed that they would be surrounded by Texians and refused their orders. Possibly 175–soldiers from four of the cavalry companies left the mission and rode south. Sanchez Navarro said the troops were not deserting but misunderstood their orders and were withdrawing all the way to the Rio Grande. The following morning, Cos called Sanchez Navarro to the Alamo and gave him orders to "go save those brave men. ... Approach the enemy and obtain the best terms possible". On December 11, the Texans officially accepted Cos's surrender.
Under the terms of the surrender, Cos and his men would leave Texas and no longer fight against the Constitution of 1824. With his departure, there was no longer an organized garrison of Mexican troops in Texas, and many of the Texans believed that the war was over. Johnson described the battle as "the period put to our present war". Burleson resigned his leadership of the army on December 15 and returned to his home. Many of the men did likewise, and Johnson assumed command of the 400 soldiers who remained. Soon after, a new contingent of Texans and volunteers from the United States arrived with more heavy artillery. According to Barr, the large number of American volunteers "contributed to the Mexican view that Texan opposition stemmed from outside influences".
Within several weeks of the Mexican surrender, Johnson and Dr. James Grant enticed 300 of the Texans to join them in preparing to invade Mexico, leaving Colonel James C. Neill to oversee the remaining 100 Texan Army soldiers garrisoned at the Alamo. Although the Matamoros Expedition, as it came to be known, was but one of many schemes to bring the war to Mexico, nothing came of it. On November 6, 1835, the Tampico Expedition under José Antonio Mexía left New Orleans, intending to capture the town from the Centralists. The expedition failed. These independent missions drained the Texan movement of supplies and men.
Provisional government.
In November 1835 at San Felipe de Austin, the Consultation (Texas) scheduled for the month before finally got underway after enough delegates from the colonies arrived to signify a quorum. After bitter debate, they finally created a provisional government that was not to be separate from Mexico but only to oppose the Centralists. They elected Henry Smith as governor, and Sam Houston was appointed commander-in-chief of the regular Army of Texas. There was no regular army yet; Austin’s army was all volunteers, so Houston would have to build one. Members of the regular army would be paid in land. The provisional government commissioned privateers and established a postal system. A merchant was sent to the U.S. to borrow $100,000. They ordered hundreds of copies of various military textbooks. They gave Austin the option to step down as commander of the Texan Army in Béxar and go to the U.S. as a commissioner. On November 24, 1835, Austin stepped down as general. Elections were held, and Colonel Edward Burleson became Austin’s successor.
Santa Anna's offensive.
Army of Operations.
As early as October 27, Santa Anna had been making plans to quell the unrest in Texas. He stepped down from his duties as president to lead what he dubbed the Army of Operations in Texas, which would relieve Cos and put an end to the Texan revolt. Santa Anna and his soldiers believed that the Texians would be quickly cowed. The Mexican Secretary of War, José María Tornel, wrote: "The superiority of the Mexican soldier over the mountaineers of Kentucky and the hunters of Missouri is well known. Veterans seasoned by 20 years of wars can't be intimidated by the presence of an army ignorant of the art of war, incapable of discipline, and renowned for insubordination."
Foreigners landing on the coast of the Republic or invading its territory by land, armed, and with the intent of attacking our country, will be deemed pirates and dealt with as such, being citizens of no nation presently at war with the Republic and fighting under no recognized flag.
Scott (2000), p. 71.
In this time period, captured pirates were executed immediately. The resolution thus gave the Mexican Army permission to take no prisoners in the war against the Texians. Santa Anna also sent a strongly worded letter to Andrew Jackson, the United States president, warning that any Americans found fighting the Mexican government would be treated as pirates. The letter was not widely distributed, and it is unlikely that most of the American recruits serving in the Texian Army were aware that there would be no prisoners of war.
By December 1835 6,019 soldiers had gathered at San Luis Potosi to march into Texas. Several of Santa Anna's officers argued that the Army of Operations should advance along the coast, so that they would be able to receive additional supplies via sea. Instead, Santa Anna ordered the army inland to Bexar, the political center of Texas and the site of Cos's defeat; Santa Anna wanted to restore the reputation of his family after his brother-in-law's embarrassing surrender. The long march would also provide an opportunity to train the new recruits. In late December, the army began the march north.
Progress was slow. There were not enough mules to transport all of the supplies, and many of the teamsters, all civilians, quit when their pay was delayed. The large number of "soldaderas"–women and children who followed the army–reduced the already scarce supplies. The soldiers were soon reduced to partial rations. After reaching Saltillo, the army halted for two weeks so that Santa Anna could recover from an illness. Officers took advantage of the break to train the men. Many of the new recruits did not know how to use the sights of their guns, and many refused to fire from the shoulder because of the large recoil. The march into Texas resumed on January 26, and the army crossed the Rio Grande on February 12.
Temperatures in Texas reached record lows, and by February 13 an estimated of snow had fallen. A large number of the new recruits were from the tropical climate of the Yucatán, and some of them died of hypothermia. Others contracted dysentery. Soldiers who fell behind were sometimes killed by Comanche raiding parties. Nevertheless, the army continued to march toward Bexar. As they progressed, settlers in their path in South Texas evacuated northward. The Mexican army ransacked and occasionally burned the vacant homes.
Alamo.
The Mexican Army arrived in San Antonio on February 23, 1836. The Texian garrison was completely unprepared for the arrival of the Mexican army and had to quickly gather food from the town to supply the Alamo. By late afternoon Bexar was occupied by about 1500 Mexican troops, who quickly raised a blood-red flag signifying no quarter. For the next thirteen days, the Mexican army besieged the Alamo. Although there were several small skirmishes that provided the defenders with much needed optimism, they had little real impact. In the early hours of March 6, the Mexican army attacked the fort in what became known as the Battle of the Alamo. Almost all of the Texian defenders, estimated at 182–257 men, were killed, including James Bowie, Davy Crockett and William B. Travis. Most Alamo historians agree that 400–600 Mexicans were killed or wounded. This would represent about one-third of the Mexican soldiers involved in the final assault, which Todish remarks is "a tremendous casualty rate by any standards".
From Bexar, Santa Anna divided his army and sent three flying columns across Texas. General Jose de Urrea was to advance eastward on the Texans from the south, Santa Anna and General Joaquin Ramirez y Sesma pushing from the center, and General Antonio Gaona supplied to march north of the Texans to Nacogdoches and then turn to block further retreat toward Louisiana. The objective was to force a decisive battle over the Texian Army, now led by General Sam Houston.
Goliad campaign.
General José Urrea marched into Texas from Matamoros, making his way north following the coast of Texas, thus preventing any foreign aid by sea and opening up an opportunity for the Mexican Navy to land much needed provisions. After surprising Colonel Frank Johnson and his troops at the Battle of San Patricio, Urrea's forces defeated a small Texan force at the Battle of Agua Dulce on March 2, 1836. Urrea then led his troops toward Goliad, where Colonel James Fannin commanded 450 of the only Texian Army troops outside the Alamo.
On March 10, Fannin had divided his force, by sending out 148 Texians with William C. Francis, Amon B. King and William Ward to the Refugio area. In Refugio, the Texians would fall into Urrea's path. The Texians repulsed several attacks and inflicted heavy casualties at the Battle of Refugio. Fannin sent couriers with word to rendezvous with him in Victoria and thus they broke off the attack. However, some couriers had been captured, which ultimately provided Urrea with precious details of Fannin's plans.
Fannin was ordered by General Sam Houston on March 11, 1836, to abandon Goliad and retreat to Victoria, but delayed his retreat until March 19. His force of about 300 men were caught on the open prairie at a slight depression near Coleto Creek and repulsed three charges at a heavy cost in Mexican casualties, during this Battle of Coleto. Overnight, Urrea's forces surrounded the Texans, brought up cannon and reinforcements, and induced Fannin's surrender under terms the next day, March 20. About 342 of the Texian troops captured during the Goliad Campaign were executed a week later on Palm Sunday, March 27, 1836, under Santa Anna's direct orders, widely known as the Goliad Massacre.
According to Harbert Davenport, "The impact of the Goliad Massacre was crucial. Until this episode Santa Anna's reputation had been that of a cunning and crafty man, rather than a cruel one...together with the fall of the Alamo, branded both Santa Anna and the Mexican people with a reputation for cruelty and aroused the fury of the people of Texas, the United States, and even Great Britain and France, thus considerably promoting the success of the Texas Revolution."
Meeting of two armies.
Texan retreat: "The Runaway Scrape".
The term “Runaway Scrape” is used to refer to two aspects of the Revolution upon word spreading of the fall of the Alamo. Both and either may be intended depending upon context. In the first context the term refers to the military retreat of the Texan forces under Houston. In the second, the reference is to the civilian flight toward Louisiana.
Houston immediately understood that his small army was not prepared to fight Santa Anna out in the open. The Mexican cavalry, experienced and feared, was something the Texians could not easily defeat. Seeing that his only choice was to keep the army together enough to be able to fight on favorable grounds, Houston ordered a retreat towards the U.S. border, and many settlers also fled in the same direction. There is speculation that one of the possible scenarios Houston envisioned was to actually lead his Texan army into Louisiana (U.S. territory), whereupon an invading Mexican army could be attacked not only by the retreating Texan army but also by American forces summoned from garrisons in New Orleans. That Sam Houston was an old friend of then U.S. president Andrew Jackson, and possibly had some communication during this crucial period, and Stephen F. Austin was in New Orleans during this time, lend a measure of credence to such speculation. On its way toward Louisiana, the Texan army implemented a scorched earth policy, denying much-needed food for the Mexican army. Soon, the rains made the roads impassable, and the cold season made the list of casualties grow in both armies.
Santa Anna's army, always on the heels of Houston, gave unrelenting chase. The town of Gonzales could not be defended by the Revolutionaries, so it was put to the torch. The same fate awaited Austin's colony of San Felipe. Despair grew among the ranks of Houston's men, and much animosity was aimed towards him. All that impeded Santa Anna's advance were the swollen rivers, which gave Houston a chance to rest and drill his army.
Preceding the Texas Army's eastward movement away from the Mexican Army, was the civilian exodus toward the safety of Louisiana. At Mina, for example, the Texas Ranger unit was divided so that half would protect the civilian evacuation and the remainder would serve as the rear guard and scouts ("spies" they were called) during the military retreat.
During the period of the Runaway Scrape, Gaona's army was re-directed from its original orders (to proceed to Nacogdoches via the San Antonio Road in a flanking maneuver) to, instead, turn southeast and join the main forces of Cos and Sesma at San Felipe. Santa Anna was not aware that Houston and his army were, from March 30 through April 12, camped in the woods along the Brazos only fifteen miles above the main Mexican forces who were camped at San Felipe from April 7 through April 9. Gaona’s Division did not arrive at San Felipe until April 17, having marched past the already deserted Texian camp.
The Texans remained undiscovered for nearly two weeks, allowing the number of volunteers to increase and training them in military discipline. Early on, Houston commandeered the Steamboat Yellowstone so as to facilitate their safe and orderly crossing of the Brazos River when the troops were prepared or should they be discovered. The Mexican Army had no knowledge as to where the main body of Texans was during early April while the Texans knew the location of the three Mexican forces. It was not until Santa Anna arrived in Harrisburg and interrogated civilians there, that he learned Houston had been camped so near his own forces on the Brazos.
After crossing the Brazos, the Texian Army marched due east as Houston received reports from his scouts to the rear. This adds perspective to the speculation that Houston intended to flee into US territory. It was an option, but not Houston's preferred option—he was looking for, and found, a weakness in Santa Anna's tactics. That weakness came in the form of Santa Anna’s rapid pursuit intending to capture the provisional Texan government. Leaving the main body of the Mexican Army behind at the San Bernard River, Santa Anna assembled a smaller unit of his best troops and hurried off toward New Washington on Trinity Bay just below San Jacinto. It was at this time in which Houston turned toward Harrisburg to the southeast at the famed "fork in the road."
It was at that fork in the road at which the Runaway Scrape had ended in military terms, while the civilians continued to flee. From that moment, Houston was no longer in retreat, but rather leading the Army to find a place to confront Santa Anna on Texas soil.
Santa Anna defeated.
Events moved at a quick pace after Santa Anna decided to divide his own flying column and race quickly towards Galveston, where members of the Provisional Government had fled. Santa Anna hoped to capture the Revolutionary leaders, and put an end to the war, which had proven costly and prolonged. Santa Anna, as dictator of Mexico, felt the need to return to Mexico City as soon as possible. Houston was informed of Santa Anna's unexpected move. Numbering about 700, Santa Anna's column marched east from Harrisburg, Texas. 
On April 20, both armies met at the San Jacinto River. Separating them was a large sloping ground with tall grass, which the Texans used as cover. Santa Anna, elated at finally having the Texas Army in front of him, waited for reinforcements, which were led by General Cos. On that same day, a skirmish was fought between the enemies, mostly cavalry, but nothing came of it.
To the dismay of the Texans, Cos arrived sooner than expected with 540 more troops, swelling Santa Anna's army to over 1,200 men. About 3:30 in the afternoon on April 21, after burning Vince's Bridge, the Texans surged forward, catching the Mexican army by surprise. Hours before the attack, Santa Anna had ordered his men to stand down, noting that the Texans would not attack his superior force. Also, his army had been stretched to the limit of endurance by the ongoing forced marches. His force was overwhelmed by Texans pushing into the Mexican camp. An 18-minute-long battle ensued, but soon the defenses crumbled and a massacre ensued.
Santa Anna's entire force of men were killed or captured by Sam Houston's heavily outnumbered army of Texans; only nine Texans died. This decisive battle resulted in Texas's independence from Mexico.
Santa Anna was found in a swamp wearing the uniform of a common soldier and captured. He was brought before Houston, who had been shot in the ankle and badly wounded. Santa Anna agreed to end the campaign. General Vicente Filisola, noting the state of his tired and hungry army, marched a force of 4,273 back to Mexico, but not without protests from Urrea. Santa Anna was forced to sign two treaties, a public treaty and a private stating the exchange of prisoners and to never fight the Texans again. Only Santa Anna had been defeated, not the Army of Operations, and Urrea felt that the campaign should continue, but Filisola disagreed.
Aftermath.
With Santa Anna a prisoner, his captors forced him to sign the Treaties of Velasco on May 14. The treaty recognized Texas' independence and guaranteed Santa Anna's life. The initial plan was to send him back to Mexico to help smooth relations between the two states. His departure was delayed by a mob who wanted him dead. Santa Anna, declaring himself as the only person who could bring about peace, was sent to Washington, D.C., by the Texas government to meet President Jackson in order to guarantee independence of the new republic. But unknown to Santa Anna, the Mexican government deposed him "in absentia"; thus, he no longer had any authority to represent Mexico. The Treaty of Velasco was never ratified in Mexico, and from the end of the revolution to roughly the beginning of the Mexican-American War, the Texas navy was tasked with forcing the Mexican Government to accept Texas independence. Although fighting between the Mexican and Texian armies ceased for the time being, battles on water and on the coast continued. 
Some of the notable naval conflicts were the Battle of Brazos River, the Battle of Galveston Harbor and the Naval Battle of Campeche.
Santa Anna re-emerged as a hero during the Pastry War in 1838. He was re-elected President, and in early 1842 under his orders, expeditions into Texas were led by Ráfael Vásquez with 500 men, then General Adrian Woll with 1,400 men. Mexican troops commanded by Vasquez occupied Goliad, Refugio, and Victoria and, on March 5, entered San Antonio. On March 15, a Texian militia gathered in San Antonio only to find the Mexican troops had left. On September 11, 1842, Woll's troops occupied San Antonio. On September 17 or 18, over 200 Texian militia under Mathew Caldwell ambushed 500 of Woll's troops and won the Battle of Salado Creek. 53 Texians responding to Caldwell's call for reinforcements were surprised near Salado Creek and killed, many in cold blood after surrendering, in the Dawson Massacre. Woll retreated to Mexico with many hostages, including the local judge, clerk, district attorney and all attorneys attending the court session. These hostages remained in captivity for several years. Texian's pursuing the Mexicans and seeking retribution included the ill-fated Mier Expedition.
Small clashes arose between the two countries for several years afterward. The war between Texas and Mexico did not truly come to an end until the Mexican-American War of 1846.
Sam Houston's victory at San Jacinto would earn him the presidency of Republic of Texas twice. He later became a U.S. senator and governor of Texas. Stephen F. Austin, after a lost bid for Texas's presidency in 1836, was appointed Secretary of State but died two months later. Sam Houston eulogized Austin as the "Father of Texas".

The Rape of Nanking (book)
The Rape of Nanking: The Forgotten Holocaust of World War II is a bestselling 1997 non-fiction book written by Iris Chang about the 1937–1938 Nanking Massacre, the massacre and atrocities committed by the Imperial Japanese Army after it captured Nanjing, then capital of China, during the Second Sino-Japanese War. It describes the events leading up to the Nanking Massacre and the atrocities that were committed. The book presents the view that the Japanese government has not done enough to redress the atrocities. It is one of the first major English-language books to introduce the Nanking Massacre to Western and Eastern readers alike, and has been translated into several languages.
The book was a source of fame for Chang but was also controversial; it was received with both acclaim and criticism by the public and by academics. It has been praised as a work that "shows more clearly than any previous account" the extent and brutality of the episode, while at the same time it was criticized as "seriously flawed" and "full of misinformation and harebrained explanations". Chang's research on the book was credited with the finding of the diaries of John Rabe and Minnie Vautrin, both of whom played important roles in the Nanking Safety Zone, a designated area in Nanjing that protected Chinese civilians during the Nanking Massacre.
The book prompted AOL executive Ted Leonsis to fund and produce "Nanking", a 2007 documentary film about the Nanking Massacre.
Inspiration.
When Iris Chang was a child, she was told by her immigrant parents, who had escaped from China via Taiwan to the United States during World War II, that during the Nanking Massacre, the Japanese "sliced babies not just in half but in thirds and fourths". In the introduction of "The Rape of Nanking", she wrote that throughout her childhood, the Nanking Massacre "remained buried in the back of mind as a metaphor for unspeakable evil". When she searched the local public libraries in her school and found nothing, she wondered why nobody had written a book about it.
The subject of the Nanking Massacre entered Chang's life again almost two decades later when she learned of producers who had completed documentary films about it. One of the producers was Shao Tzuping, who helped produce "Magee's Testament", a film that contains footage of the Nanking Massacre itself, shot by the missionary John Magee. The other producer was Nancy Tong, who, together with Christine Choy, produced and co-directed "In The Name of the Emperor", a film containing a series of interviews with Chinese, American, and Japanese citizens. Chang began talking to Shao and Tong, and soon she was connected to a network of activists who felt the need to document and publicize the Nanking Massacre. In December 1994, she attended a conference on the Nanking Massacre, held in Cupertino, California, and what she saw and heard at the conference motivated her to write "The Rape of Nanking". As she wrote in the introduction to the book, while she was at the conference, she was "suddenly in a panic that this terrifying disrespect for death and dying, this reversion in human social evolution, would be reduced to a footnote of history, treated like a harmless glitch in a computer program that might or might not again cause a problem, unless someone forced the world to remember it".
Research.
Chang spent two years on research for the book. She found that raw source materials were available in the US, contained in the diaries, films, and photographs of American missionaries, journalists, and military officers who were in Nanjing at the time of the Nanking Massacre. Additionally, she traveled to Nanjing to interview survivors of the Nanking Massacre and to read Chinese accounts and confessions by Japanese army veterans. Chang did not, however, conduct research in Japan, and this left her vulnerable to criticisms on how she portrayed modern Japan in the context of how it deals with its World War II past.
Chang's research led her to make what one "San Francisco Chronicle" article called "significant discoveries" on the subject of the Nanking Massacre, in the forms of the diaries of two Westerners that were in Nanjing leading efforts to save lives during the Japanese invasion. One diary was that of John Rabe, a German Nazi Party member who was the leader of the Nanking Safety Zone, a demilitarized zone in Nanjing that Rabe and other Westerners set up to protect Chinese civilians. The other diary belonged to Minnie Vautrin, the American missionary who saved the lives of about 10,000 women and children when she provided them with shelter in Ginling College. The diaries documented the events of the Nanking Massacre from the perspectives of their writers, and provided detailed accounts of atrocities that they saw, as well as information surrounding the circumstances of the Nanking Safety Zone. Chang dubbed Rabe the "Oskar Schindler of Nanking" and Vautrin the "Anne Frank of Nanking". Rabe's diary is over 800 pages, and contains one of the most detailed accounts of the Nanking Massacre. Translated into English, it was published in 1998 by Random House as '. Vautrin's diary recounts her personal experience and feelings on the Nanking Massacre; in it, an entry reads, "There probably is no crime that has not been committed in this city today." It was used as source material by Hua-ling Hu for a biography of Vautrin and her role during the Nanking Massacre, entitled '.
The book.
"The Rape of Nanking" is structured into three main parts. The first uses a technique that Chang called "the Rashomon perspective" to narrate the events of the Nanking Massacre, from three different perspectives: that of the Japanese military, the Chinese victims, and the Westerners who tried to help Chinese civilians. The second part concerns the postwar reaction to the massacre, especially that of the American and European governments. The third part of the book examines the circumstances that, Chang believed, have kept knowledge of the massacre out of public consciousness decades after the war.
Atrocities.
The book depicted in detail the killing, torture, and rape that occurred during the Nanking Massacre. Chang listed and described the kinds of torture that were visited upon the residents, including live burials, mutilation, "death by fire", "death by ice", and "death by dogs". Based on the testimony of a survivor of the massacre, Chang also described a killing contest amongst a group of Japanese soldiers to determine who could kill the fastest. On the rape that occurred during the massacre, Chang wrote that "certainly it was one of the greatest mass rapes in world history." She estimated that the number of women raped ranged from 20,000 to as many as 80,000, and stated that women from all classes were raped, including Buddhist nuns. Furthermore, rape occurred in all locations and at all hours, and both very young and very old women were raped. Not even pregnant women were spared, Chang wrote, and that after gang rape, Japanese soldiers "sometimes slashed open the bellies of pregnant women and ripped out the fetuses for amusement". Not all rape victims were women, according to the book, Chinese men were sodomized and forced to perform repulsive sexual acts. Some were forced to commit incest—fathers to rape their own daughters, brothers their sisters, sons their mothers.
Death toll.
Chang wrote of the death toll estimates given by different sources; Chinese military specialist Liu Fang-chu proposed a figure of 430,000, officials at the Nanjing Massacre Memorial Hall and the procurator of the District Court of Nanjing in 1946 stated at least 300,000 were killed, the International Military Tribunal for the Far East (IMTFE) judges concluded that more than 260,000 people were killed, Japanese historian Fujiwara Akira approximated 200,000, John Rabe, who "never conducted a systematic count and left Nanking in February", estimated only 50,000 to 60,000, and Japanese author Ikuhiko Hata argued the number killed was between 38,000 and 42,000.
The book discussed the research of historian Sun Zhaiwei of the Jiangsu Academy of Social Sciences. In his 1990 paper, "The Nanking Massacre and the Nanking Population", Sun estimated the total number of people killed at 377,400. Using Chinese burial records, he calculated that the number of dead exceeded the figure of 227,400. He then added estimates totaling 150,000 given by Japanese Imperial Army Major Ohta Hisao in a confessional report about the Japanese army's disposal efforts of dead bodies, arriving at the sum of 377,400 dead.
Chang wrote that there is "compelling evidence" that the Japanese themselves, at the time, believed that the death toll may have been as high as 300,000. She cited a message that Japan's foreign minister Kōki Hirota relayed to his contacts in Washington, DC in the first month of the massacre on January 17, 1938. The message acknowledged that "not less than three hundred thousand Chinese civilians slaughtered, many cases in cold blood."
Acclaim.
"The Rape of Nanking" sold more than half a million copies when it was first published in the U. S., and according to "The New York Times", received general critical acclaim. Iris Chang became an instant celebrity in the U. S.; she was awarded honorary degrees, invited to give lectures and to discuss the Nanking Massacre on shows such as "Good Morning America", "Nightline", and "The NewsHour with Jim Lehrer", and was profiled by "The New York Times" and featured on the cover of "Reader's Digest". The book was on the "New York Times Best Seller list for 10 weeks and sold more than 125,000 copies in four months. Hillary Clinton invited her to the White House, U. S. historian Stephen Ambrose described her as "maybe the best young historian we've got", and the Organization of Chinese Americans named her National Woman of the Year. The book's popularity prompted a lengthy book tour, with Chang visiting 65 cities in over a year and a half.
The book received praise from news media. "The Wall Street Journal" wrote that it was the "first comprehensive examination of the destruction of this Chinese imperial city", and that Chang "skillfully excavated from oblivion the terrible events that took place". "The Atlantic Monthly" described the book as "a crushing indictment of the Japanese army's behavior". The "Chicago Tribune" called it "a powerful new work of history and moral inquiry" and stated that "Chang takes great care to establish an accurate accounting of the dimensions of the violence." "The Philadelphia Inquirer" wrote that it was a "compelling account of a horrendous episode that, until recently, has been largely forgotten", and that "animals do not behave the way the Japanese troops of the Imperial Army behaved."
According to William C. Kirby, Professor of History at Harvard University, Chang "shows more clearly than any previous account just what Japanese did", and that she "draws connections between the slaughter in Europe and in Asia of millions of innocents during World War II". Ross Terrill, an associate in research at the Fairbank Center for East Asian Research at Harvard University, wrote that the book is "scholarly, an exciting investigation and a work of passion". Beatrice S. Bartlett, Emeritus Professor of History at Yale University, wrote, "Iris Chang's research on the Nanking holocaust yields a new and expanded telling of this World War II atrocity and reflects thorough research."
Criticism.

Jeans continued what he calls "giving the lie to Iris Chang's generalizations about 'the Japanese'" by discussing the clashing interest groups within Japanese society over such things as museums, textbooks, and war memory.
Robert Entenmann, professor of history at St. Olaf College, criticized the work on the grounds that the "Japanese historical background Chang presents is clichéd, simplistic, stereotyped, and often inaccurate." On Chang's treatment of modern Japanese reaction to the massacre, he writes that Chang seemed "unable to differentiate between some members of the ultranationalist fringe and other Japanese", and that "her own ethnic prejudice implicitly pervades her book." Stating that Chang's description of the massacre is "open to criticism", Entenmann further commented that Chang "does not adequately explain why the massacre occurred".
Timothy M. Kelly, professor at Edogawa University, described Chang's work as exhibiting "simple carelessness, sheer sloppiness, historical inaccuracies, and shameless plagiarism." Kelly further criticized Chang for her "lack of attention to detail". Finally, Kelly charged that Chang had plagiarized passages and an illustration from "Japan's Imperial Conspiracy" by David Bergamini.
Kennedy criticized Chang's accusation of "Western indifference" and "Japanese denial" of the massacre as "exaggerated", commenting that "the Western world in fact neither then nor later ignored the Rape of Nanking", "nor is Chang entirely correct that Japan has obstinately refused to acknowledge its wartime crimes, let alone express regret for them." Chang argues that Japan "remains to this day a renegade nation," having "managed to avoid the moral judgment of the civilized world that the Germans were made to accept for their actions in this nightmare time." However, according to Kennedy, this accusation has already become a cliché of Western criticism of Japan, most notably exemplified by Ian Buruma's "The Wages of Guilt" (1994), whose general thesis might be summarized as "Germany remembers too much, Japan too little." Kennedy pointed out that a vocal Japanese left has long kept the memory of Nanking alive, noting the 1995 resolution of Japan's House of Councillors that expressed "deep remorse" ("fukai hansei") for the suffering that Japan inflicted on other peoples during World War II and clear apologies ("owabi") for Imperial Japan's offenses against other nations from two Japanese Prime Ministers.
Sonni Efron of the "Los Angeles Times" warned that the bitter row over Iris Chang's book may leave Westerners with the "misimpression" that little has been written in Japan about the Nanjing Massacre, when in fact the National Diet Library holds at least 42 books about the Nanjing massacre and Japan's wartime misdeeds, 21 of which were written by liberals investigating Japan's wartime atrocities. In addition, Efron noted that geriatric Japanese soldiers have published their memoirs and have been giving speeches and interviews in increasing numbers, recounting the atrocities they committed or witnessed. After years of government-enforced denial, Japanese middle school textbooks now carry accounts of the Nanjing massacre as accepted truth. Fogel also writes: "Dozens of Japanese scholars are now actively engaged in research on every aspect of the war... Indeed, we know many details of the Nanjing massacre, Japanese sexual exploitation of 'comfort women,' and biological and chemical warfare used in China because of the trailblazing research" of Japanese scholars.
"San Francisco Chronicle" staff writer Charles Burress wrote that Chang's quote of a secret telegram sent by Japan's foreign minister in 1938 was incorrectly cited as "compelling evidence" that Japanese troops killed at least 300,000 Chinese civilians in Nanjing. According to Burress, the figure of 300,000 Chinese civilians killed actually came from a message sent by a British reporter, concerning deaths not only in Nanjing but in other places as well. Additionally, Burress questioned Chang's motivation for writing the book - whether she wrote it as an activist or as a historian, stating that the book "draws its emotional impetus" from her conviction to not let the Nanking Massacre be forgotten by the world. Burress also cited Ikuhiko Hata, a Japanese history professor at Nihon University, who argued that 11 photos in the book were misrepresented or fake. One particular photo shows women and children walking across a bridge with Japanese soldiers, and captioned as "The Japanese rounded up thousands of women. Most were gang-raped or forced into military prostitution." Hata stated that the photo originally appeared in 1937 in a Japanese newspaper as part of a series of photos that showed peaceful scenes of Chinese villagers under Japanese occupation.
Chang responded to Charles Burress's criticism in a letter written to the "San Francisco Chronicle", but the letter was not published by the newspaper. In the letter, she offered criticism of her own concerning Burress's article. Chang found a "disturbing tendency" by Burress to quote right-wing Japanese critics "without demanding evidence to back up their allegations". She argued that Ikuhiko Hata, a source cited by Burress, was not "regarded as a serious scholar" in either Japan or in the U. S., because he was a regular contributor to "ultra right-wing" Japanese publications. One such publication had published an article from a Holocaust denier that argued that no gas chambers were used in Germany to kill Jews. This caused the parent publisher to shut down the publication. On Burress's criticism of her inaccurate photo captioning, Chang disputed the contention that the caption was wrong. She wrote that her book dealt with the "horror of the Japanese invasion of China", and that the caption reading "The Japanese rounded up thousands of women. Most were gang-raped or forced into military prostitution" contained two statements of indisputable fact.
Chang also issued a rejoinder to Burress's argument that she incorrectly cited a telegram sent by Japan's foreign minister. She wrote that while the original figure of 300,000 Chinese civilian deaths in Nanjing was reported by a British reporter, this figure was cited in a message that Japan's foreign minister sent to his contacts in Washington, DC. Chang argued that figure's use by a high-ranking Japanese government official was evidence that the Japanese government recognized 300,000 as the number of Chinese civilian deaths. Finally, she criticized Burress for his "nitpick" of small details in order to draw attention away from the scope and magnitude of the Nanking Massacre, writing that such was a "common tactic" of Holocaust deniers.
Reaction in Japan.
"The Rape of Nanking" has caused controversy in Japan. "Los Angeles Times" staff writer, Sonni Efron, reported that Chang was also criticized by both Japanese "ultranationalists", who believe that the massacre in Nanjing never took place, and Japanese liberals, who "insist the massacre happened but allege that Chang's flawed scholarship damages their cause". Associate Professor David Askew of
Ritsumeikan Asia Pacific University stated that Chang's work dealt a "severe blow" to the "Great Massacre School" of thought, which advocates for the validity of the findings at the Tokyo Trials, the tribunal convened to try the leaders of the Empire of Japan for crimes committed during World War II. Askew further argued that "the Great Massacre School has thus been forced into the (unusual) position of criticising a work that argues for a larger death toll."
Following the publication of "The Rape of Nanking", Japanese critic Masaaki Tanaka had his 1987 book on Nanking translated into English. Entitled "What Really Happened in Nanking: The Refutation of a Common Myth", Tanaka stated in his introduction "I am convinced that researchers will arrive at the realization that violations of international law of the magnitude alleged by Iris Chang in "The Rape of Nanking" (more than 300,000 murders and 80,000 rapes) never took place."
Chang's book was not published in a translated Japanese language edition until December 2007. Problems with translation efforts surfaced immediately after a contract was signed for the Japanese publishing of the book. A Japanese literary agency informed Chang that several Japanese historians declined to review the translation, and that one professor backed out because of pressure placed on his family from "an unknown organization". According to Japan scholar Ivan P. Hall, revisionist historians in Japan organized a committee of right-wing scholars to condemn the book with repeated appearances at the Foreign Correspondents' Club in Tokyo and throughout Japan. They prevailed on Kashiwa Shobo, the contracted Japanese publisher of the book, to insist that Chang edit the book for "corrections" they wanted made, to delete photographs and alter maps, and to publish a rebuttal to Chang's book. Chang disagreed with the changes and, as a result, withdrew the Japanese publishing of the book. The rebuttal piece was nonetheless published as a book by Nobukatsu Fujioka and Shudo Higashinakano entitled "A Study of 'The Rape of Nanking'".
Shudo Higashinakano, a professor of intellectual history at Asia University of Japan, argued in "Sankei Shimbun" that the book was "pure baloney", that there was "no witness of illegal executions or murders", and that "there existed no 'Rape of Nanking' as alleged by the Tokyo Trial." He identified 90 historical factual errors in the first 64 pages of the book, some of which were corrected in the 1998 Penguin Books edition.
Chang's death.
The book was the main source of fame for Iris Chang, who was well respected in China for raising awareness of the Nanking Massacre in the Western world. At the same time, Chang received hate mail, primarily from Japanese ultranationalists, threatening notes on her car and believed her phone was tapped. She responded overwhelmingly to any question of the validity of her work. Her mother said the book "made Iris sad". Suffering from depression, Chang was diagnosed with "brief reactive psychosis" in August 2004. She began taking medications to stabilize her mood. She wrote: "I can never shake my belief that I was being recruited, and later persecuted, by forces more powerful than I could have imagined. Whether it was the CIA or some other organization I will never know. As long as I am alive, these forces will never stop hounding me." Succumbing to her battle with depression, Chang took her own life November 9, 2004. A memorial service was held in China by Nanking Massacre survivors coinciding with her funeral in Los Altos California. The Memorial Hall of the Victims in the Nanjing Massacre, a memorial site in Nanjing built to commemorate the victims of the Nanking Massacre, added a wing dedicated to her in 2005.
In the U. S., a Chinese garden in Norfolk, Virginia, which contains a memorial to Minnie Vautrin, added a memorial dedicated to Chang, including her as the latest victim of the Nanking Massacre, and drawing parallels between Chang and Vautrin, who also took her own life. Vautrin exhausted herself trying to protect women and children during the Nanking Massacre and subsequently during the Japanese occupation of Nanjing, finally suffering a nervous breakdown in 1940. She returned to the US for medical treatment, committing suicide a year later.

