Dynamic programming In mathematics, computer science, and economics, dynamic
programming is a method for solving complex problems by breaking them down into
simpler subproblems. It is applicable to problems exhibiting the properties of
overlapping subproblems which are only slightly smaller and optimal
substructure (described below). When applicable, the method takes far less time
than naive methods. The key idea behind dynamic programming is quite simple. In
general, to solve a given problem, we need to solve different parts of the
problem (subproblems), then combine the solutions of the subproblems to reach
an overall solution. Often, many of these subproblems are really the same. The
dynamic programming approach seeks to solve each subproblem only once, thus
reducing the number of computations: once the solution to a given subproblem
has been computed, it is stored or "memo-ized": the next time the same solution
is needed, it is simply looked up. This approach is especially useful when the
number of repeating subproblems grows exponentially as a function of the size
of the input. History. The term "dynamic programming" was originally used in
the 1940s by Richard Bellman to describe the process of solving problems where
one needs to find the best decisions one after another. By 1953, he refined
this to the modern meaning, referring specifically to nesting smaller decision
problems inside larger decisions, and the field was thereafter recognized by
the IEEE as a systems analysis and engineering topic. Bellman's contribution is
remembered in the name of the Bellman equation, a central result of dynamic
programming which restates an optimization problem in recursive form. The word
"dynamic" was chosen by Bellman to capture the time-varying aspect of the
problems, and because it sounded impressive. The word "programming" referred to
the use of the method to find an optimal "program", in the sense of a military
schedule for training or logistics. This usage is the same as that in the
phrases "linear programming" and "mathematical programming", a synonym for
mathematical optimization. Overview. Dynamic programming is both a mathematical
optimization method and a computer programming method. In both contexts it
refers to simplifying a complicated problem by breaking it down into simpler
subproblems in a recursive manner. While some decision problems cannot be taken
apart this way, decisions that span several points in time do often break apart
recursively; Bellman called this the "Principle of Optimality". Likewise, in
computer science, a problem that can be broken down recursively is said to have
optimal substructure. If subproblems can be nested recursively inside larger
problems, so that dynamic programming methods are applicable, then there is a
relation between the value of the larger problem and the values of the
subproblems. In the optimization literature this relationship is called the
Bellman equation. Dynamic programming in mathematical optimization. In terms of
mathematical optimization, dynamic programming usually refers to simplifying a
decision by breaking it down into a sequence of decision steps over time. This
is done by defining a sequence of value functions "V"1, "V"2, ..., "V""n", with
an argument "y" representing the state of the system at times "i" from 1 to
"n". The definition of "V""n"("y") is the value obtained in state "y" at the
last time "n". The values "V""i" at earlier times
"i"Â =Â "n"Â âˆ’1,Â "n"Â âˆ’Â 2,Â ...,Â 2,Â 1 can be found by working
backwards, using a recursive relationship called the Bellman equation. For
"i"Â =Â 2,Â ...,Â "n", "V""i"âˆ’1 at any state "y" is calculated from "V""i" by
maximizing a simple function (usually the sum) of the gain from decision
"i"Â âˆ’Â 1 and the function "V""i" at the new state of the system if this
decision is made. Since "V""i" has already been calculated for the needed
states, the above operation yields "V""i"âˆ’1 for those states. Finally, "V"1
at the initial state of the system is the value of the optimal solution. The
optimal values of the decision variables can be recovered, one by one, by
tracking back the calculations already performed. Dynamic programming in
computer programming. There are two key attributes that a problem must have in
order for dynamic programming to be applicable: optimal substructure and
overlapping subproblems. However, when the overlapping problems are much
smaller than the original problem, the strategy is called "divide and conquer"
rather than "dynamic programming". This is why mergesort, quicksort, and
finding all matches of a regular expression are not classified as dynamic
programming problems. "Optimal substructure" means that the solution to a given
optimization problem can be obtained by the combination of optimal solutions to
its subproblems. Consequently, the first step towards devising a dynamic
programming solution is to check whether the problem exhibits such optimal
substructure. Such optimal substructures are usually described by means of
recursion. For example, given a graph "G=(V,E)", the shortest path "p" from a
vertex "u" to a vertex "v" exhibits optimal substructure: take any intermediate
vertex "w" on this shortest path "p". If "p" is truly the shortest path, then
the path "p1" from "u" to "w" and "p2" from "w" to "v" are indeed the shortest
paths between the corresponding vertices (by the simple cut-and-paste argument
described in CLRS). Hence, one can easily formulate the solution for finding
shortest paths in a recursive manner, which is what the Bellman-Ford algorithm
or the Floyd-Warshall algorithm does. "Overlapping" subproblems means that the
space of subproblems must be small, that is, any recursive algorithm solving
the problem should solve the same subproblems over and over, rather than
generating new subproblems. For example, consider the recursive formulation for
generating the Fibonacci series: "F""i" = "F""i"âˆ’1 + "F""i"âˆ’2, with base
case "F"1Â =Â "F"2Â =Â 1. Then "F"43 =Â "F"42Â +Â "F"41, and "F"42
=Â "F"41Â +Â "F"40. Now "F"41 is being solved in the recursive subtrees of both
"F"43 as well as "F"42. Even though the total number of subproblems is actually
small (only 43 of them), we end up solving the same problems over and over if
we adopt a naive recursive solution such as this. Dynamic programming takes
account of this fact and solves each subproblem only once. Note that the
subproblems must be only "slightly" smaller (typically taken to mean a constant
additive factor) than the larger problem; when they are a multiplicative factor
smaller the problem is no longer classified as dynamic programming. Some
programming languages can automatically memoize the result of a function call
with a particular set of arguments, in order to speed up call-by-name
evaluation (this mechanism is referred to as "call-by-need"). Some languages
make it possible portably (e.g. Scheme, Common Lisp or Perl), some need special
extensions (e.g. C++, see). Some languages have automatic memoization built in,
such as tabled Prolog and J, which supports memoization with the "M." adverb.
In any case, this is only possible for a referentially transparent function.
Example: Mathematical optimization. Optimal consumption and saving. A
mathematical optimization problem that is often used in teaching dynamic
programming to economists (because it can be solved by hand) concerns a
consumer who lives over the periods formula_1 and must decide how much to
consume and how much to save in each period. Written this way, the problem
looks complicated, because it involves solving for all the choice variables
formula_16 and formula_17 simultaneously. (Note that formula_18 is not a choice
variableâ€”the consumer's initial capital is taken as given.) The dynamic
programming approach to solving this problem involves breaking it apart into a
sequence of smaller decisions. To do so, we define a sequence of "value
functions" formula_19, for formula_20 which represent the value of having any
amount of capital formula_21 at each time formula_3. Note that formula_23, that
is, there is (by assumption) no utility from having capital after death. The
value of any quantity of capital at any previous time can be calculated by
backward induction using the Bellman equation. In this problem, for each
formula_1, the Bellman equation is This problem is much simpler than the one we
wrote down before, because it involves only two decision variables, formula_2
and formula_27. Intuitively, instead of choosing his whole lifetime plan at
birth, the consumer can take things one step at a time. At time formula_3, his
current capital formula_7 is given, and he only needs to choose current
consumption formula_2 and saving formula_27. To actually solve this problem, we
work backwards. For simplicity, the current level of capital is denoted as
formula_21. formula_33 is already known, so using the Bellman equation once we
can calculate formula_34, and so on until we get to formula_35, which is the
"value" of the initial decision problem for the whole lifetime. In other words,
once we know formula_36, we can calculate formula_37, which is the maximum of
formula_38, where formula_39 is the choice variable and formula_40. Working
backwards, it can be shown that the value function at time formula_41 is where
each formula_43 is a constant, and the optimal amount to consume at time
formula_41 is which can be simplified to We see that it is optimal to consume a
larger fraction of current wealth as one gets older, finally consuming all
remaining wealth in period formula_49, the last period of life. Examples:
Computer algorithms. Dijkstra's algorithm for the shortest path problem. From a
dynamic programming point of view, Dijkstra's algorithm for the shortest path
problem is a successive approximation scheme that solves the dynamic
programming functional equation for the shortest path problem by the Reaching
method. In fact, Dijkstra's explanation of the logic behind the algorithm,
namely is a paraphrasing of Bellman's famous Principle of Optimality in the
context of the shortest path problem. Fibonacci sequence. In particular,
codice_7 was calculated three times from scratch. In larger examples, many more
values of codice_8, or "subproblems", are recalculated, leading to an
exponential time algorithm. This technique of saving values that have already
been calculated is called "memoization"; this is the top-down approach, since
we first break the problem into subproblems and then calculate and store
values. In the bottom-up approach we calculate the smaller values of codice_8
first, then build larger values from them. This method also uses O("n") time
since it contains a loop that repeats n âˆ’ 1 times, however it only takes
constant (O(1)) space, in contrast to the top-down approach which requires O
("n") space to store the map. In both these examples, we only calculate
codice_7 one time, and then use it to calculate both codice_12 and codice_13,
instead of computing it every time either of them is evaluated. Note that the
above method actually takes formula_50 time for large n because addition of two
integers with formula_51 bits each takes formula_51 time. (The "n"th fibonacci
number has formula_51 bits.) Also, there is a closed form for the Fibonacci
sequence, known as Binet's formula, from which the formula_54-th term can be
computed in approximately formula_55 time, which is more efficient than the
above dynamic programming technique. However, the simple recurrence directly
gives the matrix form that leads to an approximately formula_56 algorithm by
fast matrix exponentiation. A type of balanced 0â€“1 matrix. Consider the
problem of assigning values, either zero or one, to the positions of an matrix,
with even, so that each row and each column contains exactly zeros and ones. We
ask how many different assignments there are for a given formula_54. For
example, when , four possible solutions are There are at least three possible
approaches: brute force, backtracking, and dynamic programming. Brute force
consists of checking all assignments of zeros and ones and counting those that
have balanced rows and columns (formula_59 zeros and formula_59 ones). As there
are formula_61 possible assignments, this strategy is not practical except
maybe up to formula_62. Backtracking for this problem consists of choosing some
order of the matrix elements and recursively placing ones or zeros, while
checking that in every row and column the number of elements that have not been
assigned plus the number of ones or zeros are both at least "nÂ /Â 2". While
more sophisticated than brute force, this approach will visit every solution
once, making it impractical for "n" larger than six, since the number of
solutions is already 116963796250 for "nÂ =Â 8", as we shall see. Dynamic
programming makes it possible to count the number of solutions without visiting
them all. Imagine backtracking values for the first row â€“ what information
would we require about the remaining rows, in order to be able to accurately
count the solutions obtained for each first row values? We consider boards,
where , whose formula_21 rows contain formula_59 zeros and formula_59 ones. The
function "f" to which memoization is applied maps vectors of "n" pairs of
integers to the number of admissible boards (solutions). There is one pair for
each column and its two components indicate respectively the number of ones and
zeros that have yet to be placed in that column. We seek the value of
formula_66 (formula_54 arguments or one vector of formula_54 elements). The
process of subproblem creation involves iterating over every one of formula_69
possible assignments for the top row of the board, and going through every
column, subtracting one from the appropriate element of the pair for that
column, depending on whether the assignment for the top row contained a zero or
a one at that position. If any one of the results is negative, then the
assignment is invalid and does not contribute to the set of solutions
(recursion stops). Otherwise, we have an assignment for the top row of the
board and recursively compute the number of solutions to the remaining board,
adding the numbers of solutions for every admissible assignment of the top row
and returning the sum, which is being memoized. The base case is the trivial
subproblem, which occurs for a board. The number of solutions for this board is
either zero or one, depending on whether the vector is a permutation of
formula_70 and formula_71 pairs or not. For example, in the two boards shown
above the sequences of vectors would be ((2, 2) (2, 2) (2, 2) (2, 2)) ((2, 2)
(2, 2) (2, 2) (2, 2)) k = 4 ((1, 2) (2, 1) (1, 2) (2, 1)) ((1, 2) (1, 2) (2, 1)
(2, 1)) k = 3 ((1, 1) (1, 1) (1, 1) (1, 1)) ((0, 2) (0, 2) (2, 0) (2, 0)) k = 2
((0, 1) (1, 0) (0, 1) (1, 0)) ((0, 1) (0, 1) (1, 0) (1, 0)) k = 1
The number of solutions is Links to the MAPLE implementation of the dynamic
programming approach may be found among the external links. Checkerboard.
Consider a checkerboard with "n" Ã— "n" squares and a cost-function "c"("i",
"j") which returns a cost associated with square "i", "j" ("i" being the row,
"j" being the column). For instance (on a 5 Ã— 5 checkerboard), Thus "c"(1, 3)
= 5 Let us say you had a checker that could start at any square on the first
rank (i.e., row) and you wanted to know the shortest path (sum of the costs of
the visited squares are at a minimum) to get to the last rank, assuming the
checker could move only diagonally left forward, diagonally right forward, or
straight forward. That is, a checker on (1,3) can move to (2,2), (2,3) or
(2,4). This problem exhibits optimal substructure. That is, the solution to the
entire problem relies on solutions to subproblems. Let us define a function "q"
("i", "j") as If we can find the values of this function for all the squares at
rank "n", we pick the minimum and follow that path backwards to get the
shortest path. It should be noted that this function only computes the path-
cost, not the actual path. We will get to the path soon. This, like the
Fibonacci-numbers example, is horribly slow since it spends mountains of time
recomputing the same shortest paths over and over. However, we can compute it
much faster in a bottom-up fashion if we store path-costs in a two-dimensional
array codice_16 rather than using a function. This avoids recomputation; before
computing the cost of a path, we check the array codice_16 to see if the path
cost is already there. Now the rest is a simple matter of finding the minimum
and printing it. Sequence alignment. In genetics, sequence alignment is an
important application where dynamic programming is essential. Typically, the
problem consists of transforming one sequence into another using edit
operations that replace, insert, or remove an element. Each operation has an
associated cost, and the goal is to find the sequence of edits with the lowest
total cost. The partial alignments can be tabulated in a matrix, where cell
(i,j) contains the cost of the optimal alignment of Ato B[1..j. The cost in
cell (i,j) can be calculated by adding the cost of the relevant operations to
the cost of its neighboring cells, and selecting the optimum. Different
variants exist, see Smithâ€“Waterman algorithm and Needlemanâ€“Wunsch
algorithm. "n"Â âˆ’Â 1. If the objective is to maximize the number of moves
(without cycling) then the dynamic programming functional equation is slightly
more complicated and 3"n"Â âˆ’Â 1 moves are required. Konhauser J.D.E.,
Velleman, D., and Wagon, S. (1996). Which way did the Bicycle Go? Dolciani
Mathematical Expositions â€“ No 18. The Mathematical Association of America. To
derive a dynamic programming functional equation for this puzzle, let the state
of the dynamic programming model be a pair s = (n,k), where For instance, "s" =
(2,6) indicates that two test eggs are available and 6 (consecutive) floors are
yet to be tested. The initial state of the process is "s" = ("N","H") where "N"
denotes the number of test eggs available at the commencement of the
experiment. The process terminates either when there are no more test eggs ("n"
= 0) or when "k" = 0, whichever occurs first. If termination occurs at state
"s" = (0,"k") and "k"Â >Â 0, then the test failed. Now, let Then it can be
shown that with "W"("n",1) = 1 for all "n"Â >Â 0 and "W"(1,"k") = "k" for
allÂ "k". It is easy to solve this equation iteratively by systematically
increasing the values of "n" andÂ "k". An interactive online facility is
available for experimentation with this model as well as with other versions of
this puzzle (e.g. when the objective is to minimize the expected value of the
number of trials.
